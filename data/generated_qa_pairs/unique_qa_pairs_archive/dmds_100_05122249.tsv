qid	question	answer	context	document_ids	question_factuality	question_premise	question_phrasing	question_linguistic_variation	question_multi-doc	user_expertise-categorization	generation_timestamp	question_length	answer_length	context_length
1	certification requirements anesthesiologist assistant vs occupational therapist national board exams length	Anesthesiologist assistants must pass a 6-hour certification exam administered by the National Commission for Certification of Anesthesiologist Assistants (NCCAA), while occupational therapists must pass the Occupational Therapist, Registered (OTR) exam given by the National Board for Certification in Occupational Therapy (NBCOT).	"[""Anesthesiologist AssistantsAnesthesiologist assistants complete advanced clinical training to administer anesthetic treatments under the guidance of licensed anesthesiologists (trained doctors who administer anesthesia to people undergoing surgery or struggling with chronic pain). Anesthesiologists assign various pre-surgery duties to anesthesiologist assistants in operating rooms and other hospital environments.\nAnesthesiologist assistants are trained to use sophisticated technology to monitor sedated patients and assist anesthesiologists with other related tasks. Anesthesiologist assistants make it possible for anesthesiologists to administer anesthesia to more patients and work more efficiently.\nAnesthesiologist assistants also collect patient information, assist anesthesiologists with patient evaluations, maintain records detailing scheduled surgeries, and assist anesthesiologists with the development anesthetic care plans. The duties of anesthesiologist assistants are affected by state medical regulations.\nAccording to the American Society of Anesthesiologists (ASA) and the American Academy of Anesthesiologist Assistants the anesthesiologist assistant’s duties include, but are not limited to, the following:\n- Procure a preanesthetic health history, perform an appropriate physical examination, and record relevant patient data.\n- Conduct necessary diagnostic laboratory studies such as drawing arterial and venous blood samples;\n- Adjust and maintain patient anesthesia levels, provide continuity of anesthetic care into and during the post-operative recovery period;\n- Establish monitoring modalities under the direction of a supervising anesthesiologist;\n- Employ advanced monitoring techniques, such as pulmonary artery catheterization, echocardiography, electroencephalographic spectral analysis, and evoked potentials;\n- Employ advanced life support techniques, including intra-arterial cardiovascular assist devices and high frequency ventilation.\n- Recorder post-operative patient progress; compile and record case summaries, and transcribing orders;\n- Assist in the treatment of life-threatening situations, such as cardiopulmonary resuscitation on the basis of industry established protocols.\n- Perform various duties in pain clinics, a intensive care units, and various other settings.\n- Manage various administrative duties relating to personnel, supplies and devices;\n- Participate in the training of staff\n- Administer and monitor regional anesthesia including spinal, IV regional, epidural, etc.\nWorking ConditionsAnesthesiologist assistants work as part of the anesthesia care under the direction of a licensed anesthesiologist. Anesthesiologist assistants typically work within organizations and companies that also employ nurse anesthetists, as their responsibilities are very similar. Anesthesiologist assistants usually work in large medical facilities and hospitals that regularly perform procedures including cardiac surgery, transplant surgery, neurosurgery, and trauma care. Notwithstanding, anesthesiologist assistants can be found working hospitals of all sizes and assist in a large variety of anesthesia related procedures.\nEducation and Training RequirementsThe first step to becoming an anesthesiologist assistant is to complete a four-year college degree that offers a pre-medical curriculum that covers advanced mathematics, biology, chemistry and physics. After completing their bachelor's degree, students will then complete a graduate training program lasts between 2 – 2 ½ years. Most graduate programs will include advanced coursework in biochemistry, anatomy, physiology, and pharmacology with emphasis placed on neuromuscular, respiratory, nervous, cardiovascular, and renal systems. Upon graduation, students will be skilled in patient assessment and monitoring, life support systems, and the delivery of anesthesia.\nAs long as prerequisite courses are completed, students with bachelor’s degrees in any field can be admitted to a graduate training program in anesthesiology assisting. However, most students applying to these programs hold bachelor’s degrees in math, physics, biology, chemistry, nursing, medical technology, respiratory therapy, and other allied health fields.\nWhen considering graduate programs in anesthesia assisting you'll want to find a program that is accredited by the Commission on Accreditation of Allied Health Education Programs (CAAHEP). You'll also want to make sure the program you choose is take by doctors whoare board-certified anthesthesiologists.\nMost graduate anesthesiologist assistant programs require students to complete 600 hours of in-classroom and laboratory coursework, 2,000 hours of clinical training and at least 60 didactic hours. Through clinical training students will become adept at administering anesthetics, operating various anesthesia delivery systems and monitoring patients vitals.\nCertificationFounded in 1989, the National Commission for Certification of Anesthesiologist Assistants (NCCAA), provides a certification process for Anesthesiologist Assistants in the United States. The commission contracts with the National Board of Medical Examiners to assist with the certification process, including development of content grids, task analyses, item editing and writing, and administration of examinations. The certification process includes a 6-year cycle of certifying examination, examination for continued demonstration of qualifications, and registration of continuing medical education. To become certified initially, students must pass a 6 hour exam. To remain certified practicing anesthesiologist assistants must complete continuing medical education (CME).\nJob Outlook and SalaryOf the allied health fields, anesthesiologist assistants are among the highest paid professionals. The average anesthesiologist assistant can expect to make between $110,000 and $120,000 a year - on par with what many medical doctors make. Better yet, job prospects for anesthesiology assistants is high and employment opportunities over the next decade are predicated to be strong.\nSubmit a Resource"", 'Are you interesting in pursuing a career as an occupational therapist? If this field holds your interest, you’ll enjoy this article explain the occupational therapist job description, duties, qualifications and training, essential skills, working hours, and job prospects.\nOccupational therapists provide treatment for patients who cannot perform everyday tasks by themselves. These patients may be injured, ill, or disabled. With the help of an occupational therapist, these patients are able to develop the skills they need in order to improve their daily activities and employment.\nJob Overview: What does an Occupational Therapist Do?\nOccupational therapists work with people across a variety of lifespans in order to help them accomplish daily tasks without being held back by illnesses, injuries, or disabilities. Since they cover so many different types of clients, their work environment varies.\nAn occupational therapist might work in hospitals, private practices, schools, and nursing homes. Their place of employment determines whether they’ll have a typical 9 to 5 work day, and which days of the week they will work. Regardless of where they work, occupational therapist positions require at least a master’s degree, and the salaries range from $70,000 to $90,000 annually.\nOccupational Therapist Job Duties\n- Examine and diagnose patients’ physical condition.\n- Maintain privacy and confidentiality of their clients.\n- Perform patient assessments each time they meet the client.\n- Evaluate whether a client needs specialized seating, wheelchairs, crutches, or additional therapy.\n- Work in conjunction with a variety of other team members, including physical therapists, teachers, doctors, and social workers.\n- Perform customized evaluations on each client, based on their particular needs and strengths.\n- Initiate an intervention designed to improve their clients’ ability to reach desired daily goals and tasks.\n- Design an outcomes evaluation to evaluate whether a clients’ goals are being achieved.\n- Make necessary changes to their intervention plans when clients do not respond to them.\nOccupational Therapist Job Essential Skills\nCommunication Skills. Occupational therapists work with a wide range of clients and other professionals. They must be able to listen well, speak confidentially, and document effectively.\nInterpersonal skills. Working as an occupational therapist means having to deal with a variety of backgrounds and temperaments. Clients will not always be in a cheerful mood, and occupational therapists must be willing and able to deal with a variety of moods.\nProblem Solving Skills. Occupational therapists must have the ability to solve their clients’ problems, and they must recognize problems within their own intervention plans.\nBecoming an Occupational Therapist\nIn order to become an occupational therapist, you need at least a master’s degree. Many occupational therapists hold a doctorate’s degree, which demonstrates an advanced knowledge of their area of specialization. In addition to a graduate level degree, all occupational therapists must be licensed by the National Board for Certification in Occupational Therapy.\nQualifications and Training\nTypically, most occupational therapist begin their education with a bachelor’s degree in occupational therapy. However, some begin with degrees in special education, biology, or even liberal arts degrees. What is important in the pursuit of an occupational therapist career is a background in both physiology and psychology.\nAfter obtaining a bachelor’s degree, a master’s degree in occupational therapy is the next step in entering the field. This may take up to three years. Some educational institutions allow students to enter a dual degree program where they are able to earn their bachelor’s and master’s degree at the same time. At least 24 weeks of fieldwork are required for the master’s degree, during which students complete their clinical work under the supervision of licensed occupational therapists. Doctorate degree programs require an additional 24 weeks.\nAfter getting their degree, prospective occupational therapists must sit for the “Occupational Therapist, Registered” (OTR) exam given by the NBCOT. The NBCOT also offers additional board certifications for anyone interested in getting certified in their area of specialization, which may include pediatrics and mental health.\nThe occupational therapist job description mentions that this is not a field that can be entered without work experience. Before anyone can be granted a license, they are required to have at least 24 hours of clinical experience. In order to be competitive with their peers, many other prospective occupational therapists attempt to gain additional work experience for their resume.\nAlthough they cannot work as a therapist without a license, prospective therapists can gain work experience in other areas. These include becoming an advocate for disability awareness, working in camps for people with disabilities, and volunteering for programs such as the Special Olympics.\nSince occupational therapists work in so many different settings, their actual work hours can vary. Occupational therapists who work with schools must be willing to work within school hours, while therapists who work within nursing homes may be required to work multiple shifts.\nOccupational therapists who have a private practice can largely set their own hours, while those working for a private clinic may enjoy 9 to 5 hours. Occupational therapists can also work on weekends, especially those who help the elderly within their own homes.\nAdditionally, because occupational therapists are paid well (average annual salary of $64,616), many therapists work on a part time basis or on an “as needed” basis. Essentially, therapists are able to choose their own working hours based on where and when they would like to work.\nJob Outlook & Advancement Opportunities\nThe Bureau of Labor Statistics cites that employment of occupational therapists is expected to grow 27 percent by 2024. The reason for the high demand of occupational therapist is that it is an important part of the overall treatment of people with autism, Alzheimer’s, and loss of movement. As the population grows older, there will be an increased need for occupational therapists who develop plans to help the elderly deal with their daily tasks.\nAdvancement opportunities for an occupational therapist depend upon the therapists’ individual areas of interest. Some therapists develop an area of concentration and become board certified. Others may take supervisor positions within hospitals or nursing homes. Some may go on to earn a doctorate degree. Advanced positions may offer additional wages, depending upon where the therapist works. Those working in hospitals or nursing homes typically earn more than those working in the school system.\nOccupational therapy can be an extremely gratifying career. Working in this field allows individuals to make a positive impact upon the daily happiness of another’s life. The salary can be excellent, and therapists have the ability to choose from a variety of work environments.\nAs long as the prospective occupational therapist is able to communicate, work well as part of a team, and solve problems, the occupational therapist job description promises a rewarding career choice.']"	['<urn:uuid:f4723e9c-c9f7-4531-8844-ed6825b9c69e>', '<urn:uuid:bb9c4c5f-7c32-4d88-89da-a6fadea672aa>']	factoid	with-premise	long-search-query	similar-to-document	comparison	expert	2025-05-12T22:49:38.933606	11	41	1901
2	what factors predictable variations circuit breaker operating time	The main influencing factors that can be compensated are ambient temperature (affecting coil resistance and lubricant viscosity), DC operating voltage (affecting plunger operation), and idle time (time between operations, particularly significant in hydraulic mechanisms).	['Introduction to controlled switching system in the grid:\nControlled Switching Systems (CSS) for circuit breakers have become an economical solution and are commonly used to reduce switching surges for various switching applications. Recent developments of transformer switching taking account of the residual flux can realize an effective means of mitigating severe inrush currents and temporary overvoltage that may lead to false operation of protective relays and degradation in power quality.\nCSS combined with metal oxide surge arresters can reduce undesirable overvoltage caused by the energization of a long transmission line to meet the insulation coordination. The limited number of applications for line switching may arise from initial difficulties due to insufficient technical considerations including idle time compensation.\nControlled switching system is based on the synchronization of the mechanical operation of the circuit breaker to the power system in order to switch it at the ideal electrical instant that mitigates undesired power system disturbances and stress on the electrical apparatus. Rather than reducing the transients by adding devices such as pre-insertion resistors and/or surge arresters, the Controlled switching principle is based on the optimum electrical switching instant of the load.\nCircuit breaker mechanical characteristics and dielectric behaviour in Controlled switching systems(CSS):\nThe performance of a controlled switching scheme depends greatly on the consistency of the circuit breaker mechanical characteristics and dielectric behaviour. Also, the ability of the Controlled Switching Device (CSD) to accurately predict the behaviour of the circuit breaker during its lifetime is an important factor.\nDesirable characteristics of a circuit breaker for use in controlled switching applications are:\n- consistent operating (Open/Close) time with mechanical reliability.\n- Excellent dielectric properties i.e. a steep RDDS/RRDS Slope.\nThe circuit breaker is a rather complex and bulky mechanical device. Fortunately, its behaviour based on its operating conditions is quite predictable. Knowledge of a CB’s electrical performance and network electrical operating condition is also of the utmost importance for an optimum CSS. These considerations are a key factor to the success of this mitigation technique to make the arc appear or disappear between the circuit breaker main contacts only by sending the CB mechanical command order at the right timing, taking as a reference the network voltage or load current.\nMechanical operation characteristics of circuit breakers :\nA practical circuit breaker exhibits some variation of its operating times. Since these variations may be relevant for the operating conditions, different approaches for corrections are used since they differ considerably for different types of circuit breakers.\nFirst, it is important to distinguish between predictable and purely statistical changes in operating times since any changes in operating times that can be predicted with sufficient accuracy by the controller do not reduce the effectiveness of controlled switching.\nThe operating time (??????????) of a circuit breaker can be expressed as:\n?????????? = ???????? + ∆???????? + ∆??????????\n∆???????? = ∆????? + ∆??????\nT operating: Operating time predicted by the controller before emitting the command\nT nominal: Mean operating time under nominal operating conditions which are readily measured and programmed into the controller.\nΔTpredict: Predictable variation of the operating time (in relation with T nominal) that can be corrected by the controller\nΔTstatistic: Purely statistical variation of the operating time that cannot be corrected by the controller\nΔTcomp: The variation of the operating time with predetermined features, those depending on the operating conditions\nΔTdrift: The variations of the operating time with adaptive features, such as long term drift and wear-related changes\nThe predictable variations of the operating times (ΔTpredict) can be further split into those variations for which predetermined compensation can be applied (ΔTcomp) and those which can be dealt with adaptive features (ΔTdrift).\nThe following are the main influencing factors that can be compensated:\n* Ambient Temperature: Temperature can influence the open/close coil resistance. Also with temperature variation, the viscosity of lubricants changes resulting in friction between sliding or moving parts in the circuit breaker mechanism.\n* DC Operating Voltage: Opening and closing coil control voltage affect the operating characteristic of the plunger which releases the spring mechanism.\n*Idle Time: This is the amount of time the circuit breaker mechanism has been left idle between operations. This can differ significantly between circuit breaker operating mechanisms. Spring mechanisms have a more consistent operating time typically +/- 1ms while hydraulic mechanisms can deviate above 2ms depending on the idle time.\nInfluence of operating conditions on CB mechanical switching times :\nThe variations related to predetermined compensation (ΔTcomp) are readily measured by appropriate sensors and transducers in the field which result in defined changes of the operating times that can be compensated for. Typical parameters such as control voltage (V control), stored energy of the drive (e.g. hydraulic pressure, Edrive) and ambient temperature (T temp) are often compensated by the controller.\nThe operating time used by the controller on any given occasion is adjusted, on the basis of the sensor inputs, according to a known set of operating characteristics, which has been determined under well-defined operating conditions during the testing for each circuit breaker type.\n∆Tcomp = f(Vcontrol, Edrive, Ttemp)\nThe example shown in Figure 1 illustrates typical variations of the mechanical opening and closing times of a CB with a hydraulic drive according to three independent operating conditions: temperature, voltage and hydraulic pressure.\nFigure1: typical variations of the mechanical opening and closing times of a CB((photo from CIGRE 757 brochure)\nGenerally, the lower the ambient operating temperature, coil voltage or drive mechanism force, the slower is the CB operation time. These characteristics are generally published by CB manufacturers who perform type tests at the factory on a single CB pole.\nEach circuit breaker model and technology behaves differently and has normally a different “mesh map” figure that should be evaluated according to IEC relevant publications. For some types of CBs, modelling is simplified because they are influenced by a smaller number of conditions. This is the case for most currently available spring-type CBs, which are mainly influenced by the ambient temperature and operating voltage.\nIdle time influence on CB mechanical switching times:\nThe idle-time dependence of the drive is another factor that can influence the mechanical switching time of each CB operation. It is one of the major causes of target missing for CBs that exhibit large variation for idle time and where the CSS has no idle time compensation function.\nThis CB characteristic, which is different for the opening and for the closing operation, makes more difficult the extraction of the contribution of each operating condition factor during a timing measurement, especially for some CBs with hydraulic operating mechanisms. A timing deviation estimation method has to be developed for factory and/or field measurement to extract the contribution of each variable.\nCB mechanical timing scatter:\nConsistently repeatable performance of the circuit breaker in relation to open/close times along with excellent voltage withstand properties are of upmost importance when used in conjunction with a control switching device (CSD).\nOperational times probably won’t always be the same as there are a number of external influencing factors such as ambient temperature, control voltage level, idle time of the circuit breaker mechanism as well as the operating mechanism technology that can affect repeatable operation times.\nStatistical scatter of the operating time presents an inherent limitation to the use of controlled switching.\nIt is best described by a standard deviation (σmech) and can be assessed by performing operations under operating conditions identical to those experienced in the field. The maximum scatter may be approximated by ΔTstatistic = 3σmech.\nSome inherent statistical scatter of the operating times will occur even at identical operating parameters and ambient conditions.\nEven though the operating conditions and the idle time are the same, a real CB will not behave exactly the same from one operation to the other: the mechanical operating time will vary slightly. These small variations are normally compiled under a Gaussian distribution curve from which a circuit breaker characteristic could be extracted: the CB scatter. This characteristic is design-dependent and different for the opening and for the closing operations.\nIn probability theory and statistics, “variance” (dispersion or scatter) is a measure of how far a set of numbers are spread out. A small variance indicates that the data points tend to be very close to the mean (expected value) and hence to each other, while a high variance indicates that the data points are very spread out around the mean and from each other. An equivalent measure is the square root of the variance, called the standard deviation (σ). The standard deviation has the same dimension as the data and hence is comparable to deviations from the mean.\nFigure 2: circuit breaker scatter curve (photo from CIGRE 757 brochure)\nWhen selecting a CB for a controlled switching application, the CB scatter should be lower than a specified value of “3σ” where the majority of operating times will fit (99.8%) as shown in Figure 2.\nA typical value of the CB scatter to specify for a CS application is less than ±1ms.']	['<urn:uuid:2892c6ea-9447-4ed3-9ea0-11f71d2ef05b>']	factoid	with-premise	short-search-query	similar-to-document	single-doc	expert	2025-05-12T22:49:38.933606	8	34	1494
3	How do scientists create antibodies that can fight diseases?	Scientists use several methods to create antibodies. One way is through hybridoma technology, where mouse B cells that make specific antibodies are fused with mouse myeloma cells. Another approach uses yeast display systems to engineer antibodies. They also use human antibody technology, where the entire process of antibody selection and production happens in the human immune system, resulting in more effective antibodies.	['Membrane proteins (MPs) tend to be appealing targets for antibody executive. technology straight with entire cells or detergent-solubilized whole-cell lysates antibody libraries could be screened against MP antigens within their near-native conformations. We also describe the way the system can be modified for using MP-containing cell lysates for antibody characterization and antigen recognition. This assortment BSF 208075 of suitable strategies acts as a basis for antibody executive against MPs which is predicted these strategies will adult in parallel with advancements in membrane proteins biochemistry and solubilization technology. . Entire cells and detergent-soluble cell lysates certainly are a immediate powerful solution to the problem so long as they could be integrated into well-known antibody finding platforms. Indeed mainly because antibody executive technology offers matured many good examples have surfaced with entire cells playing the part of antigen. XenoMouse technology and phage screen two trusted systems for antibody finding incorporate entire cells as a way of producing antibodies against membrane proteins. The study and development resulting in panitumimab (Vectibix) [16 17 has an instructional overview of the XenoMouse system where the built animals had been immunized by immediate shot of antigen-expressing cells. Extra flexibility was allowed through the introduction of HEK293 manifestation vectors with the capacity of accepting a number of membrane protein . Phage display as an system is certainly versatile to the usage of entire cells highly. Studies have been successful in determining reactive peptides and antibodies to numerous cells and cells including: mind and kidney  lung  heart  and breast tissue . Recent years have also BSF 208075 seen the 1st phage selection performed in humans . These results briefly focus on the use of whole cells in the prevailing antibody finding platforms. The technology utilized for antibody finding and production however BSF 208075 offers progressed dramatically leading to alternate cell-surface display systems . One of these yeast surface screen (YSD) has obtained in reputation among academic research workers and has Rabbit polyclonal to RABAC1. been commercialized . Right here we describe effective YSD strategies using entire cells (fungus biopanning) or detergent-solubilized cell lysates as resources of MP for antibody anatomist. Yeast-display is one of the many cell-surface screen systems for proteins anatomist so that as will end up being described within this review possesses advantages of antibody anatomist against membrane protein [24 26 Very much like phage screen yeast are constructed expressing peptides or antibody fragments on the surface area while harboring the hereditary information with a plasmid in the cell (Amount 1A). Getting eukaryotes yeast likewise have an endoplasmic reticulum built BSF 208075 with particular enzymes and chaperones that result in high fidelity folding and appearance of mammalian antibody fragments. Enhanced proteins folding when combined with capability to generate large (~1010 clones) libraries  (Amount 1A-ii) network marketing leads to a robust system for the id of book antibodies . Significantly yeast screen also allows the usage of fluorescence-activated cell sorting (FACS) (Amount 1C-iv) which affords an extraordinary mix of quantitative verification and throughput. Contemporary FACS equipment support rates more than 25 0 occasions per second enabling even huge libraries to become screened quickly and specifically. In the normal embodiment nevertheless YSD requires the usage of a soluble antigen (Amount 1C-ii). Two strategies have already been created to overcome this restriction recently. First our laboratory demonstrated a fungus “biopanning” technique where yeast shown single chain adjustable fragments (scFv) had been chosen by successive rounds of incubation on mammalian cell monolayers  (Amount 1A B). Fungus biopanning was afterwards utilized to isolate several exclusive scFv that bind plasma membrane (PM) protein of the rat human brain endothelial cell series (RBE4) and occasionally internalized in to the RBE4 cells . Another YSD-based technique using entire cell contacting strategies integrated lymphoid-derived cells to display a collection of T-cell receptors against indigenous peptide-MHC ligands . Enrichment of high affinity pMHC binders was aided by parting of yeast-lymphoid cell complexes by denseness gradient centrifugation. Although incorporation of entire cells overcame.', 'The Antibodies are secreted by plasma cells transformed from B cells, and each B cell line can produce only one specific antigenic determinant. The antibody, produced from a single cell line, is called the monoclonal antibody (McAb). The first generation of monoclonal antibodies came from hybridoma antibody technology developed by Koehler and Milstein in 1975. On the basis of cell fusion technology, mouse B cells capable of secreting specific antibodies and mouse myeloma cells with unlimited reproductive ability were fused into B cell hybridoma. A specific antibody against an antigenic epitope can be prepared by culturing a group of cells with a single hybridoma cell with this property, as shown in figure 1. However, the human immune system can recognize mouse monoclonal antibodies, which can cause human anti-mouse antibody (HAMA) response. This not only shortens the half-life and weakens the efficacy of therapeutic monoclonal antibodies, but also sometimes causes serious adverse reactions, so the clinical application of the first generation of monoclonal antibodies is greatly limited.\nFigure 1. Illustration showing the production route of hybridoma technology.\nSince the advent of the first mouse monoclonal antibody Muromonab OKT3 in the world in 1986, nearly 80 monoclonal antibodies have been on the market in the world. So far, the monoclonal antibody has developed to the fourth generation: the first generation is mouse monoclonal antibody (momab), the second generation is human-mouse chimeric monoclonal antibody (ximab), the third generation is humanized monoclonal antibody (zumab), the fourth generation is fully human monoclonal antibody (mumab). The advantage of humanized monoclonal antibody and human monoclonal antibody is that it can overcome the reaction of human anti-mouse antibody, prevent the monoclonal antibody molecule from being quickly eliminated by the immune system as heterogenous protein, and improve the biological activity of monoclonal antibody molecule. In particular, the variable and constant regions of human antibodies are human, which can further remove immunogenicity and side effects on the basis of humanized antibodies. Humanized antibodies and human antibodies have the characteristics of high affinity, high specificity and low toxicity and side effects, which greatly overcome the shortcomings of mouse antibodies and chimeric monoclonal antibodies. Therefore, it has become the inevitable trend of the development of therapeutic antibody drugs.\nMonoclonal antibodies usually target disease-related antigens or specific receptors on the cell surface, such as the PD-1 receptor on the surface of tumor cells and the PD-L1 ligand on the surface of T cells. PD-1/PD-L1 inhibitors, which are in the limelight, belong to monoclonal antibodies and are the focus of tumor immunotherapy in recent years. Nivolumab and pembrolizumab, which are on the market, are PD-1 inhibitors and are mainly used in the treatment of melanoma and non-small cell lung cancer. PD-L1 inhibitors atezolizumab (trade name Tecentriq), durvalumab (trade name Imfinzi) and avelumab (trade name Bavencio) have been approved for the treatment of urethral epithelial cancer. On September 28, 2018, FDA approved the listing of Libtayo (cemiplimab-rwlc) jointly developed by Sanofi (Sanofi) and Regenerative. It is used to treat metastatic skin squamous cell carcinoma (CSCC) or locally advanced CSCC patients who cannot receive healing surgery or radiotherapy. This is also the third anti-PD-1 antibody approved by FDA.\nFigure 2. Mechanism of PD-1 receptor and PD-L1/L2 inhibitors mediated cancer immunotherapy.\nUp to now, monoclonal antibody drugs have become an important part of biomedicine and have broad application prospects in medical treatment. It has been successfully used in the treatment of tumors, autoimmune diseases, infectious diseases, transplantation rejection and other diseases. However, there are many bottlenecks in the preparation of monoclonal antibodies. At present, the bottleneck of antibody drug research and development lies in the screening of target molecules, humanization of antibodies and preparation of human antibodies, high-throughput and large-scale screening of antibodies, prediction, modeling and analysis of antigenic epitopes, construction of three-dimensional configuration of antigen-antibody interaction and various techniques to increase the function of antibody effect.\n1.Target Screening of Antibody Drug\nTraditional antibody drugs are developed at the level of a single gene, a single protein, and a single antibody. First of all, it will take many years to study the function of the gene and its coding protein to confirm whether the gene and its encoded protein can be used as antibody drug targets to develop antibody drugs. The main drawback of this method is that the number of antibody drug targets obtained is extremely limited, and these targets were discovered more than a decade ago and it takes a long time, usually 10 to 20 years. With the continuous progress of genomics, transcriptome, proteomics and sequencing technology, more and more new genes and proteins have been found, which is expected to select suitable antibody drug targets.\nWhat are the criteria for screening antibody drug targets? In the case of antineoplastic drug targets, first of all, there should be differences in target expression, such as differences between normal and tumor tissues, or loss of expression in key host organs, or persistent expression in the progress of the disease. Second, the target should play a role, when the use of antibodies for treatment, the antigen cannot be easily degraded by enzymes. The production of high affinity antibodies from known therapeutic targets is not a major obstacle, but the main challenge is to screen target molecules.\nNow, scientists have used humanized antibody technology and fully human antibody technology, hoping to find some better antibody targets through the human immune system, so as to develop better antibody drugs. The fully human antibody technology is optimized by human-mouse hybridoma technology, human-human hybridoma technology, B cell immortalization and high-efficiency and high-throughput fully human antibody library technology. The selection, maturation and production of antibodies are all formed in the human body, so they are all human antibodies in the strict sense. Antibody targeting, antibody production and post-transcriptional modification are all completed by the human immune system after a series of screening. The antibodies produced by this technique have the best natural affinity and binding power, and act more effectively on the human body. High-efficiency and high-throughput fully human antibody library technology will be able to secrete antibodies of the target cell isolation, purification, enrichment and proliferation. The specificity of the antibody secreted by B cell subclone can be screened and identified by ELISPOT, ELISA or hemolytic plaque test. The gene sequence of the target antibody was obtained from the monoclonal cultured cell line, and the prokaryotic or eukaryotic expression vector was constructed and transferred into engineering bacteria or cells to reconstruct the activity of the antibody.\n2.Immunogenicity Analysis of Monoclonal Antibody Drugs\nAt present, the common adverse reactions of monoclonal antibodies are mainly caused by their immunogenicity. The anti-drug antibodies caused by immunogenicity have a great influence on the safety and efficacy of the drug. Immunogenicity is one of the decisive factors in the development of biotech drugs, so their immunogenicity should be taken into account when evaluating drug safety. To this end, scientists have taken measures to improve the immunogenicity of monoclonal antibody drugs, such as humanization of antibodies, improvement of solubility, protein modification (such as protein polyethylene glycol modification) and improvement of effector molecule function.\nFigure 3. Polyethylene glycol modification of antibodies.\nThe current methods for evaluating and analyzing the immunogenicity of monoclonal antibodies include enzyme-linked immunosorbent assay (Elisa), liquid chromatography–mass spectrometry (LC-MS), surface plasma resonance (SPR), electrochemiluminescence (ECL) and radioimmunoassay (RIA). However, these methods have not yet reached a unified conclusion on the critical value of immunogenicity, and the critical value of immunogenicity is different due to different distribution laws and calculation companies, which makes it impossible to unify the acceptance criteria among different drugs. However, with the continuous progress of molecular biology technology, the humanized components of monoclonal antibodies have been improved, and even the whole human antibodies have been reached. Improving the binding and effector molecular function of these antibodies, combined with protein modification, is expected to avoid the immunogenicity of monoclonal antibodies. At the same time, improving the immunogenicity detection method, unifying and standardizing it will make the clinical trial have clear guiding principles, and finally accelerate the clinical application of monoclonal antibody drugs.\n3.High-throughput Animal Cell Expression Technique\nIn terms of protein expression system, in recent years, scientists have developed and optimized the expression system of many antibody molecules, such as bacteria, yeast, insect cells, mammal cells, plant cell expression systems and in vitro expression systems. Among them, mammalian cell expression system has many important advantages, such as high activity and good stability, and has become the most important expression system in the manufacture of antibody biotechnology products.\nFrom the point of view of the scale, speed and function of antibody preparation, the development of high-throughput antibody preparation technology is very important. Large-scale and efficient culture of mammal cells is the main mode of production and key bottleneck technology of biomedical products. At present, there are flow culture technology and perfusion culture technology in the world.\n4.Construction & Optimization of Humanized and Fully Human Antibodies.\nWith the development of immunology and molecular biology, DNA recombination technology is more and more used in antibody construction and optimization. The techniques for the construction and optimization of humanized antibodies include resurfacing antibody and reshaped antibody. Resurfacing antibody refers to the humanization of amino acid residues on the surface of heterogenous antibodies. The principle of this method is to replace only the regions which are obviously different from the surface of human antibody, and to replace amino acids similar to the surface residues of human antibody on the basis of maintaining antibody activity and reducing heterogenicity. In addition, there should not be too many segments to be replaced, and the residues that could affect the size of the side chain, charge, hydrophobicity, or may form hydrogen bonds, which influence the conformation of the complementary determining region (CDR) of antibody, should not be replaced as far as possible. The reshaped antibody refers to the antibody constructed by the splicing of the antigen-binding residues of the heterogenous antibody with the human antibody, including complementary determining region transplantation, partial complement determining region transplantation and specific determining region transplantation.\nFigure 4. Chimeric antibodies and humanized antibodies.\nBoth light and heavy chains of humanized antibodies come from human beings and are the development region of therapeutic antibodies. At present, there are antibody library screening techniques for the construction and optimization of humanized antibodies, such as chain replacement and genetic engineering mice to prepare humanized antibodies. The more mature antibody library screening techniques include phage antibody library, synthetic antibody library and ribosome display technology.\nAntibodomics technology is based on genomics and proteomics, combined with hybridoma technology and genetic engineering antibody technology, after high-throughput screening of antibody targets, the establishment of large-scale antibody library, and finally applied. Compared with the traditional monoclonal antibody technology, the antibody library technology has the advantages of large library capacity, more species screening, easier to obtain highly active monoclonal antibodies against specific antigen epitopes and so on. At the same time, the antibody library technology is more timesaving, labor-saving, efficient and economical in the screening process.\nMice are still the easiest animal species for immunization and subsequent genetic engineering, but the mouse antibody V region gene is still obtained through the mouse antibody library. In order to make it safe for clinical use, follow-up humanized transformation must be carried out. The transgenic mouse technology of fully human antibody developed in the past two years enables us to prepare a human immune antibody library through transgenic mice with a complete set of human antibody genes, from which we can directly screen the V region gene of the fully human antibody with therapeutic value. There is no need for humanized transformation.\n5.Development of New Antibody Drugs\nTraditional antibody drugs inhibit tumor growth by blocking a single signal pathway, and the drug resistance of antibody drugs is easy to appear in clinic. Therefore, bispecific antibody (BsAb) came into being. By means of genetic engineering, two antibody fragments targeting different antigens are combined together, which has two antigen binding sites, which can play a synergistic role and improve the therapeutic effect. This structural design can effectively improve the pharmacokinetic process of antibody drugs in vivo and enhance the clinical therapeutic effect. However, the design of BsAb with good curative effect, high stability and conducive to production still needs to be further studied.\nThe antibody drugs on the market in recent years reflect the new trend of the development of the next generation of antibody drugs. The first direction is to make antibody drugs have a smaller molecular weight, so that they have better pharmacokinetic and pharmacodynamic parameters, and are easier to manufacture on a large scale, such as Fab fragment, Fab’ fragment, F(ab’)2 fragment, Single-chain variable fragment (scFv), single domain antibody (sdAb), diabody, triabody and minibody. The second direction is to connect at least two molecules with certain biological functions to form fusion proteins based on known drug molecules, such as bispecific antibody, trifunctional antibody, synthetic antibody (synbody), antibody-drug conjugate (ADC).\nAntibody-drug couplers are composed of monoclonal antibodies and small molecular drugs with therapeutic effect. These drugs realize the targeted delivery of chemical drugs to tumor tissue with the help of antibodies. The antibody-drug conjugate has high stability in the blood, and the drug molecules will not fall off, so the toxic and side effects are small, but the inhibitory effect on tumor cells is much higher than that of naked antibodies. This design strategy can not only improve the killing ability of antibody drugs, but also improve the treatment window of small molecular chemicals.\nFigure 5. Antibody-drug conjugate.\nMonoclonal antibody drugs provide a new way for the treatment of a variety of diseases. At present, monoclonal antibody drugs have been widely used in the clinical treatment of tumors and other diseases. From the perspective of anti-tumor monoclonal antibody drug development process, it is mainly divided into five parts: target discovery, target selection, antigen preparation, selection of monoclonal antibody preparation technology and antibody function identification. Through the technical characteristics of these links, we can find the risk factors that affect the R&D results, find the risk factors, and use the thinking and methods of risk management to analyze. Different technologies used in the preparation of monoclonal antibodies will encounter different challenges. For this reason, it is necessary for developers to carry out specific analysis of specific problems and constantly overcome these technical challenges in order to develop truly useful monoclonal antibodies and bring new life-saving drugs to patients.']	['<urn:uuid:e2ae95fc-c4d1-4249-922b-571ac00fe47f>', '<urn:uuid:a82fb98f-1152-40f8-b244-572b7d2a13c0>']	factoid	with-premise	concise-and-natural	similar-to-document	three-doc	novice	2025-05-12T22:49:38.933606	9	62	3049
4	which items can be recycled at home list	Several items can be recycled at home including: plastic bottles and containers, glass bottles and containers, cardboard boxes, aluminum beverage cans, household plastic containers like detergent bottles, paper (including envelopes, office paper and junk mail), and metal cans and containers.	['Is your home aging in place ready? If you’re one of the nearly 34 million people who identify as a baby boomer who’s reached retirement… Read More\nRemember the good old days when everything in your household was either recycled or reused? Blouses and dress shirts with missing buttons weren’t just thrown away, but instead fixed with a simple thread and needle. Appliances weren’t just replaced but repaired. Maybe you even remember when leaving empty milk jugs for your milkman to collect was common practice. It wasn’t until the 1950s that milk cartons replaced glass milk bottles altogether.\nWith Earth Day right around the corner, it’s the perfect time to invest in our planet and bring back good recycling habits. Every action you take, no matter how big or small, can help create a more sustainable future. Sharing those habits from the good old days with the next generation can go a long way! Reduce your personal waste and minimize your carbon footprint by recycling materials, donating items you no longer need or use and making simple changes to your daily routine.\nRemember the three R’s\nReduce. Reuse. Recycle.\nWhen you recycle and reduce the amount of trash you generate, you contribute to less waste in the environment and are helping to preserve the planet. BYU reports that recycling one single run of the Sunday New York Times would save 75,000 trees and if every American recycled one-tenth of their newspaper then an astounding 25 million trees would be saved. So, what steps can you and your loved ones take to reduce personal waste and help preserve the planet?\n- Reduce the amount of trash you generate and cut back on how much natural resources like gas you use to heat up your house and fuel your cars.\n- Reuse items that will be thrown away after a single use like plastic bags. Remember to bring your reusable grocery bag(s) on your next trip to the market to help minimize the use of single-use bags.\n- Recycle old items to make new items. You can recycle aluminum cans, glass bottles, paper, plastic and more for upcycling.\nExplore the three Rs of waste management – reduce, reuse, recycle here.\nWhere can I start?\nEven though America is home to only four percent of the world’s population, it accounts for twelve percent of the world’s trash. Roughly 200 million tons of trash is dumped into landfills every year in America alone. There are many things you can do today that can contribute to a better tomorrow. So, where can you start?\nWith good recycling habits, you may even earn a little bit of money, and by donating items that you no longer need you’re helping others gain access to things they may not have been able to afford otherwise. Simple changes to your daily routine may seem minuscule now, but they can play a big part in the overall health and wellbeing of the planet too.\nHere are some tips on how to start:\n- Sort and recycle items around your house into the correct trash and recycling bins.\n- Take many types of plastic bottles and cans, electronic waste, used oil and paint to a collection site near you so they are properly disposed of.\n- Reuse empty jam or pasta jars and glass bottles to store household items or homemade foods. Remember homemade pickles and fresh berry jam? Home canning is popular again! Make a day of it with a family member or neighbor.\n- Walk to the market if it’s nearby or carpool with a friend or family member when possible. Stay mobile, get exercise and limit greenhouse gases produced by running cars on the road.\n- Conserve water by fixing leaks and turning off faucets and drains when not in use. Learn more about water efficiency and how you can start saving today.\n- Turn off lights and electronics when not in use.\n- Donate items you no longer use like books, electronics, furniture, and clothing to programs like Goodwill or The Salvation Army.\nIt might be hard to part with some of your personal belongings, so start small if you need to. If you haven’t done your spring cleaning yet, now is a good time! Clutter around the house can increase the risk of falling, limit your mobility if spaces are inaccessible and even make it harder for you to locate important items like medication or your favorite novel. When you reduce the clutter around your house, you’re creating a safer and more organized home that lets you age in place longer.\nRead more about the benefits of decluttering here.\nRecycling dos and don’ts\nRecycling is easy! More times than not, people aren’t recycling simply because they don’t know what they can or cannot recycle. Here’s a quick guide on how to sort your recyclables at home. Your individual city or county may have different rules or guidelines, but this can help give you a head start. View your local recycling information here.\nAre these items in my home recyclable?\n- Plastic bottles and containers\n- Glass bottles and containers\n- Cardboard boxes\n- Aluminum beverage cans\n- Household plastic containers like detergent bottles\n- Paper (envelopes, office paper and junk mail)\n- Metal cans and containers\n- Food wrappers and bags\n- Bubble wrap and padded mailers\n- Saran wrap and plastic bread bags\n- Foam containers\n- Electrical cords\nYour actions today, no matter how big or small, play a key role in a better tomorrow. With consistency and a little consideration for the environment, you’re on the right path to a more sustainable future. Start recycling today!']	['<urn:uuid:2ee40b36-cc8d-4857-b252-2eb37bdd031f>']	open-ended	with-premise	short-search-query	similar-to-document	single-doc	novice	2025-05-12T22:49:38.933606	8	40	943
5	What guidance is provided during medication dispensing?	The system provides both visual and digital guidance during dispensing. Visual guiding lights illuminate the specific doors, drawers, and compartments where selected medications are stored, directing nurses to the right location. Additionally, there is on-screen guidance showing the exact storage location of the drug. Nurses also have the option to print out a prescription list to aid them during the administration process.	['Reading time: 5 minutes\nProviding quality patient care is the core responsibility of a caregiver, and ensuring the right drugs are given to the right patient at the right time is of utmost importance to positively impact the patient’s recovery journey. However, do you find yourself feeling uncertain of the dispensed drug, wondering if there was an earlier batch at the back of the cupboard? Or the need to recite A-B-C silently when looking for Omeprazole in the drug cupboard of the new emergency room that you have been assigned to? An automated dispensing cabinet could be the relief that you are looking for and even more…\nWhat are automated dispensing cabinets (ADC)?\nAn ADC is a computer-based system for the storage and dispensing of medication at hospital’s points of care such as wards, emergency rooms, and critical care units. They are mainly used by hospitals that practice decentralized medication management: drugs are centrally managed but physically distributed to various points of care within the hospital.\nIn this model of medication management, the ADC takes on the role of a decentralized warehouse to store and track drugs securely while enabling nurses to accurately dispense patient-specific or drug-specific medication on demand.\nThe MedSMART automated dispensing cabinets are a combination of a main tower and an auxiliary tower. The main tower features an integrated touchscreen where caregivers use to log into the system to replenish or dispense medications. The auxiliary tower provides additional shelf or drawer storage for the medication at the point of care. Flexible configurations of an ADC enable secure storage and dispensing of different types of drug forms such as:\n- single doses,\n- multi doses,\n- blister strips,\n- boxed medication,\n- bottled medication,\n- vials, and\nAccurate dispensing with automated dispensing machines\nDuring daily scheduled drug administration timings, nurses log into the ADC. They are granted access to the system to select the patient for whom medication is to be dispensed. The system lists the prescription specific to this selected patient and the nurse selects the drugs to be dispensed, which automates the process of dispensing medications sequentially.\nVisual guiding lights illuminate the doors, drawers, and exact compartments within the drawers where the selected medications are stored. This directs the nurse to the right drawer to pick and dispense the right drug. On top, there is on-screen guidance to show where the exact drug is stored. Once all prescribed drugs specific for that administration timing are dispensed from the ADC, nurses have the option to print out a prescription list that aids them during their administration process.\nThe automated dispensing machines can be programmed to support both patient-specific and drug-specific dispensing modes, catering to emergency responses, especially within the emergency rooms and critical care wards. The drug-specific dispensing process is the same as the patient-specific dispensing process except for the initial patient selection. During an emergency, caregivers will be able to access all drugs stored within the ADC. Simply by searching the drug name and selecting the drug to be dispensed, the automated dispensing process starts.\nHandling narcotics, controlled substances, and high-alert drugs\nNarcotics, controlled substances, high-alert, and sometimes expensive drugs are stored exclusively in the sliding drawers of the MedSMART ADC, which are secure drawers with double-lock access. With ADC credentials and the access locks of both the drawer and the drug’s storage compartment, this physical hardware complies with JCI requirements of implementing a process for reducing the risk and harm of high-alert medications.\nFor an additional layer of security when storing and dispensing narcotics, hospitals have the option to implement the two-man rule to securely dispense controlled drugs only after verification by a second authorized user of the system.\nSo, when nurse A logs in the ADC to retrieve a narcotic, the system will prompt another authorized caregiver B to log into the system as a second set of verification before the system unlocks the drawer and storage location of the narcotic for nurse A to retrieve the drug.\nHandling drug returns\nWhether a drug will be returned to the cabinet stock or the return bin will be set up during the medication definition stage. A drug that is defined as going to the return bin will be sent back to the pharmacy so it can be redistributed to other wards in need of this drug. MedSMART ADC can manage both types of returns within its footprint.\nSteps of returning drugs to the cabinet stock or return bin:\n- After logging into the ADC, the nurse selects the patient whose drugs were un-administered and clicks on the return button.\n- The screen will list previously dispensed medication for this specific patient and the nurse selects the drug to be returned as well as its returned quantity.\n- Select the return button again to confirm the returned drug and quantity.\nThe return bin or the correct drawer will be unlocked (sequentially if returning more than one drug).\n- There will be on-screen and visual guiding lights to direct the nurse to where to return the drug.\nBenefits at a glance\nAutomated dispensing machines digitize the process of medication handling at the hospital’s points of care. An ADC is an intuitive system that enables secure drug storage, supports accurate dispensing, and empowers drug traceability at various points of care within a hospital. This results in:\nIncreased operational efficiency for both the nursing and pharmacy staff\n- Improved medication management practices to increase patient safety\n- Improved drug inventory to reduce medication waste and loss.\nChoosing the right automated dispensing cabinet\nAutomated dispensing machines can be as simple or sophisticated as needed, depending on several factors such as number of line items to be stored, size of all drugs to be stored onsite, quantity to be stored, replenishment schedule, and the list goes on. To simplify the process of selecting an ADC that fits your needs, let’s evaluate the basics:\n- Where would you like to place the ADC?\n- How many line items do you need to be stored at that point of care?\n- Do you need secure storage (double-lock access) for narcotics and controlled substances?\n- Assuming a 5-day replenishment cycle, an ADC can store ~50 liters of liquid medication, do you need more?\nTake the first step with our ADC Configurator to find out what would be a suitable combination based on these four simple questions and to receive a first price indication. If you prefer to speak with someone about your specific needs, book an appointment with your local expert and we can customize a system that meets your needs.']	['<urn:uuid:d4c526f8-6f25-4581-ac2d-7e4a2d89b184>']	open-ended	direct	concise-and-natural	distant-from-document	single-doc	expert	2025-05-12T22:49:38.933606	7	62	1097
6	investing beginner what does options trading mean and what bad stuff can happen	Options trading involves buying contracts that give the right (but not obligation) to buy or sell assets at specific prices. While it offers advantages that trading stocks alone cannot provide, it carries substantial risks. Option buyers pay an upfront fee called premium and can lose their entire investment if the option expires worthless. Sellers of options face even greater risks, as they may sustain losses well in excess of the premium received. Market conditions can make it impossible to execute certain orders meant to limit losses, and the high leverage involved means a small market movement can have a proportionately larger impact on invested funds.	"['When a trader buys an options contract (either a Call or a Put), they have the rights given by the contract, and for these rights, they pay an upfront fee to the trader selling the options contract. This fee is called the options premium, which varies from one options market to another, and also within the same options market depending upon when the premium is calculated. The option\'s premium is calculated using three main criteria, which are as follows:\nIn search of a promising commodity option trade, it is important to look at whether or not the options are priced fairly. Option prices fluctuate according to supply and demand in the underlying commodity market. At times, options on futures prices become inflated or undervalued relative to theoretical models such as Black and Scholes. For example, during the ""crash"" of 2008 the value of put options exploded as traders scrambled to buy insurance for their stock portfolios or simply wanted to wager that the equity market would go down forever. The increase in option premium was partly due to inflated volatility but increased demand for the instruments had a lot to do with it. Those that chose to purchase put options at inopportune times and at overvalued prices, likely didn\'t fair very well.\nFor instance, it is possible to construct an option strategy in the futures markets that is affordable without sacrificing the odds of success...but with the convenience comes theoretically unlimited risk. This is easier than it sounds, similar to the way you would borrow money to pay for a house or a car, you can borrow money from the exchange to pay for long commodity option trades. There are an unlimited number of combinations of self-financed trades but they are typically going to involve more short options than long options, or at least as much premium collected on the sold options than that paid for the longs. In essence, the money brought in through the sale of the short options goes to pay for the futures options that are purchased. The result is a relatively close-to-the-money option with little out of pocket expense but theoretically unlimited risk beyond the strike price of the naked short options.\nOptions markets trade options contracts, with the smallest trading unit being one contract. Options contracts specify the trading parameters of the market, such as the type of option, the expiration or exercise date, the tick size, and the tick value. For example, the contract specifications for the ZG (Gold 100 Troy Ounce) options market are as follows:\nWith this strategy, the trader\'s risk can either be conservative or risky depending on their preference (which is a definite plus). For iron condors, the position of the trade is non-directional, which means the asset (like a stock) can either go up or down - so, there is profit potential for a fairly wide range. To use this kind of strategy, sell a put and buy another put at a lower strike price (essentially, a put spread), and combine it by buying a call and selling a call at a higher strike price (a call spread). These calls and puts are short.\nOptions trading may seem overwhelming, but they\'re easy to understand if you know a few key points. Investor portfolios are usually constructed with several asset classes. These may be stocks, bonds, ETFs, and even mutual funds. Options are another asset class, and when used correctly, they offer many advantages that trading stocks and ETFs alone cannot.\nSimilarly, if you believe the company’s share price is going to dip to $80, you’d buy a put option (giving you the right to sell shares) with a strike price above $80 (ideally a strike price no lower than $80 plus the cost of the option, so that the option remains profitable at $80). If the stock drops below the strike price, your option is in the money.\n• Put Options – Give the buyer the right, but not the obligation, to sell the underlying at the stated strike price within a specific period of time. The seller of a put option is obligated to deliver a short position from the strike price (accept a long futures position) in the case that the buyer chooses to exercise the option. Keep in mind that delivering a short futures contract simply means being long from the strike price.\nOn the other hand, commodity option buyers are exposed to limited risk and unlimited profit potential, but they also face dismal odds of success on each individual speculation. For this reason, we often refer to the practice of buying options in the commodity markets as the purchase of a lottery ticket. It probably won’t pay off but if it does the potential gain is considerable. Conversely to the commodity option seller, an option buyer views the position as an asset (not a liability) until it is sold or expires. This is because any long option held in a commodity trading account has the potential to provide a return to the trader, even if that potential is small.\nA bull call spread, or bull call vertical spread, is created by buying a call and simultaneously selling another call with a higher strike price and the same expiration. The spread is profitable if the underlying asset increases in price, but the upside is limited due to the short call strike. The benefit, however, is that selling the higher strike call reduces the cost of buying the lower one. Similarly, a bear put spread, or bear put vertical spread, involves buying a put and selling a second put with a lower strike and the same expiration. If you buy and sell options with different expirations, it is known as a calendar spread or time spread.\nIf you are buying an option that is already ""in the money"" (meaning the option will immediately be in profit), its premium will have an extra cost because you can sell it immediately for a profit. On the other hand, if you have an option that is ""at the money,"" the option is equal to the current stock price. And, as you may have guessed, an option that is ""out of the money"" is one that won\'t have additional value because it is currently not in profit.\nEspecially when using a custom view, you may find that the number of columns chosen exceeds the available space to show all the data. In this case, the table must be horizontally scrolled (left to right) to view all of the information. To do this, you can either scroll to the bottom of the table and use the table\'s scrollbar, or you can scroll the table using your browser\'s built-in scroll:\n* Sell orders are subject to an activity assessment fee (from $0.01 to $0.03 per $1,000 of principal). Trades are limited to online domestic equities and options and must be used within two years. Options trades are limited to 20 contracts per trade. Offer valid for new and existing Fidelity customers opening or adding net new assets to an eligible Fidelity IRA or brokerage account. Deposits of $50,000-$99,999 will receive 300 free trades, and deposits of $100,000 or more will receive 500 free trades. Account balance of $50,000 of net new assets must be maintained for at least nine months; otherwise, normal commission schedule rates may be retroactively applied to any free trade executions. See Fidelity.com/ATP500free for further details and full offer terms. Fidelity reserves the right to modify these terms and conditions or terminate this offer at any time. Other terms and conditions, or eligibility criteria may apply.\nAlly Financial Inc. (NYSE: ALLY) is a leading digital financial services company. Ally Bank, the company\'s direct banking subsidiary, offers an array of deposit and mortgage products and services. Ally Bank is a Member FDIC and Equal Housing Lender , NMLS ID 181005. Mortgage credit and collateral are subject to approval and additional terms and conditions apply. Programs, rates and terms and conditions are subject to change at any time without notice.\nThe price at which you agree to buy the underlying security via the option is called the ""strike price,"" and the fee you pay for buying that option contract is called the ""premium."" When determining the strike price, you are betting that the asset (typically a stock) will go up or down in price. The price you are paying for that bet is the premium, which is a percentage of the value of that asset.', 'A Simplified Summary on leveraged products and the risks associated with them\nTrading in financial products always involves risk. As a general rule, you should therefore only trade in financial products that you are familiar with and the understand the risk associated with them. You should carefully consider your financial situation and consult your independent professional advisors as to the suitability of your situation prior making any investment.\nThe prices of securities fluctuate, sometimes dramatically. The price of a security may move up or down, and may become valueless. It is as likely that losses will be incurred rather than profit made as a result of buying and selling securities.\nFutures & Options Trading\nThe risk of loss in trading futures contracts or options is substantial. In some circumstances, you may sustain losses in excess of your initial margin funds. Placing contingent orders, such as ""stop-loss"" or ""stop-limit"" orders, will not necessarily avoid loss. Market conditions may make it impossible to execute such orders. You may be called upon at short notice to deposit additional margin funds. If the required funds are not provided within the prescribed time, your position may be liquidated. You will remain liable for any resulting deficit in your account. You should therefore study and understand futures contracts and options before you trade and carefully consider whether such trading is suitable in the light of your own financial position and investment objectives. If you trade options you should inform yourself of exercise and expiration procedures and your rights and obligations upon exercise or expiry\n- Effect of “Leverage” or “Gearing”\nTransactions in futures carry a high degree of risk. The amount of initial margin is small relative to the value of the futures contract so that transactions are “leveraged” or “geared”. A relatively small market movement will have a proportionately larger impact on the funds you have deposited or will have to deposit: this may work against you as well as for you. You may sustain a total loss of initial margin funds and any additional funds deposited with the firm to maintain your position. If the market moves against your position or margin levels are increased, you may be called upon to pay substantial additional funds on short notice to maintain your position. If you fail to comply with a request for additional funds within the time prescribed, your position may be liquidated at a loss and you will be liable for any resulting deficit.\n- Risk-reducing orders or strategies\nThe placing of certain orders (e.g. “stop-loss” orders, or “stop-limit” orders) which are intended to limit losses to certain amounts may not be effective because market conditions may make it impossible to execute such orders. Strategies using combinations of positions, such as “spread” and “straddle” positions may be as risky as taking simple “long” or “short” positions.\n- Options - Variable degree of risk\nTransactions in options carry a high degree of risk. Purchasers and sellers of options should familiarise themselves with the type of option (i.e. put or call) which they contemplate trading and the associated risks. You should calculate the extent to which the value of the options must increase for your position to become profitable, taking into account the premium and all transaction costs.\nThe purchaser of options may offset or exercise the options or allow the options to expire. The exercise of an option results either in a cash settlement or in the purchaser acquiring or delivering the underlying interest. If the option is on a futures contract, the purchaser will acquire a futures position with associated liabilities for margin (see the section on Futures above). If the purchased options expire worthless, you will suffer a total loss of your investment which will consist of the option premium plus transaction costs. If you are contemplating purchasing deep-out-of-the-money options, you should be aware that the chance of such options becoming profitable ordinarily is remote.\nSelling (“writing” or “granting”) an option generally entails considerably greater risk than purchasing options. Although the premium received by the seller is fixed, the seller may sustain a loss well in excess of that amount. The seller will be liable for additional margin to maintain the position if the market moves unfavourably. The seller will also be exposed to the risk of the purchaser exercising the option and the seller will be obligated to either settle the option in cash or to acquire or deliver the underlying interest. If the option is on a futures contract, the seller will acquire a position in a futures contract with associated liabilities for margin (see the section on Futures above). If the option is “covered” by the seller holding a corresponding position in the underlying interest or a futures contract or another option, the risk may be reduced. If the option is not covered, the risk of loss can be unlimited.\nCertain exchanges in some jurisdictions permit deferred payment of the option premium, exposing the purchaser to liability for margin payments not exceeding the amount of the premium. The purchaser is still subject to the risk of losing the premium and transaction costs. When the option is exercised or expires, the purchaser is responsible for any unpaid premium outstanding at that time.\nAdditional Risk Common to Futures and Options\n- Terms and conditions of contracts\nYou should ask the firm with which you deal about the terms and conditions of the specific futures or options which you are trading and associated obligations (e.g. the circumstances under which you may become obliged to make or take delivery of the underlying interest of a futures contract and, in respect of options, expiration dates and restrictions on the time for exercise). Under certain circumstances the specifications of outstanding contracts (including the exercise price of an option) may be modified by the exchange or clearing house to reflect changes in the underlying interest.\n- Suspension or restriction of trading and pricing relationships\nMarket conditions (e.g. illiquidity) and/or the operation of the rules of certain markets (e.g. the suspension of trading in any contract or contract month because of price limits or “circuit breakers”) may increase the risk of loss by making it difficult or impossible to effect transactions or liquidate/offset positions. If you have sold options, this may increase the risk of loss.\nFurther, normal pricing relationships between the underlying interest and the futures, and the underlying interest and the option may not exist. This can occur when, for example, the futures contract underlying the option is subject to price limits while the option is not. The absence of an underlying reference price may make it difficult to judge “fair value”.\n- Deposited cash and property\nYou should familiarise yourself with the protections given to money or other property you deposit for domestic and foreign transactions, particularly in the event of a firm insolvency or bankruptcy. The extent to which you may recover your money or property may be governed by specific legislation or local rules. In some jurisdictions, property which had been specifically identifiable as your own will be pro-rated in the same manner as cash for purposes of distribution in the event of a shortfall.\n- Commission and other charges\nBefore you begin to trade, you should obtain a clear explanation of all commission, fees and other charges for which you will be liable. These charges will affect your net profit (if any) or increase your loss.\n- Transactions in other jurisdictions\nTransactions on markets in other jurisdictions, including markets formally linked to a domestic market, may expose you to additional risk. Such markets may be subject to regulation which may offer different or diminished investor protection. Before you trade you should enquire about any rules relevant to your particular transactions. Your local regulatory authority will be unable to compel the enforcement of the rules of regulatory authorities or markets in other jurisdictions where your transactions have been effected. You should ask the firm with which you deal for details about the types of redress available in both your home jurisdiction and other relevant jurisdictions before you start to trade.\n- Currency risks\nThe profit or loss in transactions in foreign currency-denominated contracts (whether they are traded in your own or another jurisdiction) will be affected by fluctuations in currency rates where there is a need to convert from the currency denomination of the contract to another currency.\n- Trading facilities\nElectronic trading facilities are supported by computer-based component systems for the order-routing, execution, matching, registration or clearing of trades. As with all facilities and systems, they are vulnerable to temporary disruption or failure. Your ability to recover certain losses may be subject to limits on liability imposed by the system provider, the market, the clearing house and/or participant firms. Such limits may vary: you should ask the firm with which you deal for details in this respect.\n- Electronic trading\nTrading on an electronic trading system may differ from trading on other electronic trading systems. If you undertake transactions on an electronic trading system, you will be exposed to risks associated with the system including the failure of hardware and software. The result of any system failure may be that your order is either not executed according to your instructions or is not executed at all.\n- Off-exchange transactions\nIn some jurisdictions, and only then in restricted circumstances, firms are permitted to effect off-exchange transactions. The firm with which you deal may be acting as your counterparty to the transaction. It may be difficult or impossible to liquidate an existing position, to assess the value, to determine a fair price or to assess the exposure to risk. For these reasons, these transactions may involve increased risks. Off-exchange transactions may be less regulated or subject to a separate regulatory regime. Before you undertake such transactions, you should familiarise yourself with applicable rules and attendant risks.\nLeveraged Foreign Exchange Trading\nThe risk of loss in leveraged foreign exchange trading can be substantial. You may sustain losses in excess of your initial margin funds. Placing contingent orders, such as ""stop-loss"" or ""stop-limit"" orders, will not necessarily limit losses to the intended amounts. Market conditions may make it impossible to execute such orders. You may be called upon at short notice to deposit additional margin funds. If the required funds are not provided within the prescribed time, your position may be liquidated. You will remain liable for any resulting deficit in your account. You should therefore carefully consider whether such trading is suitable in light of your own financial position and investment objectives.\nRisk of Client Assets Received or Held Outside Hong Kong\nClient assets received or held by the licensed or registered person outside Hong Kong are subject to the applicable laws and regulations of the relevant overseas jurisdiction which may be different from the Securities and Futures Ordinance (Cap.571) and the rules made thereunder. Consequently, such client assets may not enjoy the same protection as that conferred on client assets received or held in Hong Kong.\nRisk of Providing an Authority to Repledge your Securities Collateral etc\nThere is risk if you provide the licensed or registered person with an authority that allows it to apply your securities or securities collateral pursuant to a securities borrowing and lending agreement, repledge your securities collateral for financial accommodation or deposit your securities collateral as collateral for the discharge and satisfaction of its settlement obligations and liabilities.\nIf your securities or securities collateral are received or held by the licensed or registered person in Hong Kong, the above arrangement is allowed only if you consent in writing. Moreover, unless you are a professional investor, your authority must specify the period for which it is current and be limited to not more than 12 months. If you are a professional investor, these restrictions do not apply.\nAdditionally, your authority may be deemed to be renewed (i.e. without your written consent) if the licensed or registered person issues you a reminder at least 14 days prior to the expiry of the authority, and you do not object to such deemed renewal before the expiry date of your then existing authority.\nYou are not required by any law to sign these authorities. But an authority may be required by licensed or registered persons, for example, to facilitate margin lending to you or to allow your securities or securities collateral to be lent to or deposited as collateral with third parties. The licensed or registered person should explain to you the purposes for which one of these authorities is to be used.\nIf you sign one of these authorities and your securities or securities collateral are lent to or deposited with third parties, those third parties will have a lien or charge on your securities or securities collateral. Although the licensed or registered person is responsible to you for securities or securities collateral lent or deposited under your authority, a default by it could result in the loss of your securities or securities collateral.\nA cash account not involving securities borrowing and lending is available from most licensed or registered persons. If you do not require margin facilities or do not wish your securities or securities collateral to be lent or pledged, do not sign the above authorities and ask to open this type of cash account.\nRisk of Providing an Authority to Hold Mail or to Direct Mail to Third Parties\nIf you provide the licensed or registered person with an authority to hold mail or to direct mail to third parties, it is important for you to promptly collect in person all contract notes and statements of your account and review them in detail to ensure that any anomalies or mistakes can be detected in a timely fashion.\nRisk of Margin Trading\nThe risk of loss in financing a transaction by deposit of collateral is significant. You may sustain losses in excess of your cash and any other assets deposited as collateral with the licensed or registered person. Market conditions may make it impossible to execute contingent orders, such as ""stop-loss"" or ""stop-limit"" orders. You may be called upon at short notice to make additional margin deposits or interest payments. If the required margin deposits or interest payments are not made within the prescribed time, your collateral may be liquidated without your consent. Moreover, you will remain liable for any resulting deficit in your account and interest charged on your account. You should therefore carefully consider whether such a financing arrangement is suitable in light of your own financial position and investment objectives.']"	['<urn:uuid:bcf43d9b-3140-4bd8-876d-3d5e090a97cb>', '<urn:uuid:b064937f-a87d-442e-a379-7d9eef33af0f>']	factoid	with-premise	long-search-query	distant-from-document	multi-aspect	novice	2025-05-12T22:49:38.933606	13	105	3838
7	Are high protein diets beneficial for health and weight management?	The evidence is mixed. While high protein foods can help with weight loss by increasing satiety and building lean muscle mass through exercise, consuming too much protein (like 25% of calories) far exceeds our actual requirements and may be harmful. According to the National Academy of Sciences, humans only need about 10% of calories from protein (0.8g/kg body weight). Multiple animal and human studies caution against excessive protein intake.	['The concepts of personalized medicine and personalized nutrition have really taken off. People are eating according to their blood type, their metabolic type, their Ayurvedic constitution, and their genotype. Scientific research consistently finds that our responses to food may differ in degree, which means that some people can tolerate unhealthy food better than others. However, a misguided extrapolation of this notion leads many people to imagine that our responses also differ in direction, an example being that you need a vegetarian diet while I need a low-carb diet with meat and fish. Popular opinion asserts that “everyone is different” and you need to find “the right diet for your body.”\nThe idea that we are uniquely individual is accurate when it comes to our personalities, our aspirations, our contributions to the world, and to some extent our biology. But it is a big leap from noting that some people’s systems can better handle stress (unhealthy food is one form of stress) to stating that some people require entirely different categories of food than others.\nHuman beings are one species; we are all the same animal, with the same digestive physiology. And, as is true of all species, we do not require personalized nutritional programs unless we are dealing with a specific disease or some other very unusual condition. Even then, our differences are a matter of degree, not direction. One person might be able to handle more fat in the diet without gaining weight or developing heart disease, particularly if they are highly active. Another person might need to follow Dr. Caldwell Esselstyn’s low-fat plant-based diet strictly to reverse their advanced-stage heart disease. But eating a high-fat diet, or a high-protein diet, carries no health advantage for any of us, when compared with the well-documented benefits of eating a variety of whole, plant-based foods, in sufficient quantity to meet our caloric needs.\nHow Much Protein, Fat, and Carbs Do We Actually Need?\nThe National Academy of Sciences has actually written a sourcebook for the nutrient requirements of humans and many other species,[i] including cattle, swine, poultry, fish, dogs, cats, nonhuman primates, and more. These requirements are based on observed symptoms of deficiency at lower levels of consumption. While protein and fat requirements vary a bit depending on gender and life stage (babies and young children need a bit more of each), the recommendations for adults do not vary anywhere near the extent to which we humans currently vary our diets.\nAccording to the National Academy of Sciences, Institute of Medicine’s macronutrient recommendations for humans*, we need:\n- Roughly 10% protein\n- At least 6% essential fats\n- At least 130 grams of carbohydrate\nThe average requirement for protein is set at one basic level for adults of our species: the RDA for protein is 0.8 grams per kilogram of body weight[ii] This translates to around 10% of calories from protein for the average person, a recommendation that is well padded with a safety margin designed to meet the needs of virtually all of the population. A few well-known low-carb diet plans, however, recommend eating 25% of calories from protein—far and away exceeding our requirement![iii] This is in spite of the fact that there are a multitude of animal studies[iv] [v] [vi] and human observational studies[vii] [viii] that caution against eating too much protein. (Many well-known medical authorities do as well[ix] [x].)\nWhere nutrition is concerned, it’s helpful to ask yourself, “Where in nature can I find an example of this?” And in this example of a very wide variation of nutrient intake, the answer is “nowhere.” In other words, you’ll be hard pressed to stumble upon horses that do better with some meat in their diet because of their blood type, or bears that need twice the protein intake of other bears. If they did, the ranchers and zookeepers would have quite a job on their hands, wouldn’t they? Somehow this logic evades us, when it comes to humans.\nOur species has specific nutritional requirements, and we can meet them by eating whole plant foods in sufficient quantity to maintain healthy body weight, just as other animals do, in their natural environments.\n[i] The National Academies Press. Accessed March 14, 2015.\n[ii] USDA Dietary Reference Intakes. Accessed March 14, 2015.\n[iii] A Week of Paleo Meals. Accessed March 14, 2015.\n[iv] Appleton BS, and Campbell TC. “Inhibition of aflatoxin-initiated preneoplastic liver lesions by low dietary protein.” Nutr. Cancer 3 (1982): 200–206.\n[v] Youngman LD, and Campbell TC. “High protein intake promotes the growth of preneoplastic foci in Fischer #344 rats: evidence that early remodeled foci retain the potential for future growth.” J. Nutr. 121 (1991): 1454–1461.\n[vi] Youngman LD, and Campbell TC. “Inhibition of aflatoxin B1-induced gamma-glutamyl transpeptidase positive (GGT+) hepatic preneoplastic foci and tumors by low protein diets: evidence that altered GGT+ foci indicate neoplastic potential.” Carcinogenesis 13 (1992):1607–1613.\n[vii] Levine ME et al. Low Protein Intake Is Associated with a Major Reduction in IGF-1, Cancer, and Overall Mortality in the 65 and Younger but Not Older Population. Cell Metab. 2014 Mar 4;19(3):407–17.\n[viii] Fung TT et al. Low-carbohydrate diets and all-cause and cause-specific mortality: two cohort studies. Ann Intern Med. 2010 Sep 7;153(5):289–98.\n[ix] High-Protein, Low-Carb Diets Explained, accessed January 15, 2015.\n[x] High-Protein Diets, accessed January 15, 2015.\n*DERIVING THE ABOVE MACRONUTRIENT RECOMMENDATIONS:\nTo calculate these numbers, you have to look at the Recommended Dietary Allowance (RDA) for protein and the Adequate Intake, or “AI”, set for essential fats in the Dietary Reference Intake (DRI) tables for macronutrient composition (reference #10). These DRIs are developed by the Institute of Medicine, based on the available relevant evidence. The RDA is a specific recommended level of intake that should be adequate for 97.5% of a normally distributed population. The AI is what most people in the population eat on average and is used when there is not enough evidence to set an RDA.\nUsing the average requirements as target intakes (a strategy even suggested in the DRI tables), a man weighing 175 pounds who eats a 2500-calorie diet would require 63.6g of protein and 18.6g of essential fats per day. The protein requirement is calculated by converting 175 pounds to 79.5 kilograms, and then multiplying 79.5 kilograms by 0.8 grams, the recommended daily protein intake based on body weight. The AI for essential fat is 18.6 grams for adult men. However, because whole plant foods naturally contain fat, if you eat a WFPB diet and don’t overdo the nuts and seeds, you’ll get more than the bare minimum of essential fats – around 40 grams is more likely.\nPROTEIN: 63.6 grams at 4 calories per gram = 254 calories from protein.\nFAT: 40.0 grams at 9 calories per gram = 360 calories from fat.\nCARBS: The remaining calories are carbohydrate, which are calculated by subtraction:\n2,500 (total) – 254 (protein) – 360 (fat) = 1,886 calories from carbohydrate.\nIn terms of percentage of calories, this comes out to approximately 10% protein, 14.5% fat, and 75.5% carbohydrate.', 'The most influential factor to weight loss and maintenance is a sustainable and intentional diet. But finding the right diet for you may be tricky, as there are multiple diet and weight loss plans online that suggest promising results and everybody’s response to these diets are different. Nevertheless, a general rule of thumb in weight loss is to always ensure that your diet is backed up by scientific data and research.\nHere we have prepared a sustainable and viable option that you may incorporate to your diet: eating more protein rich foods.\nEating high protein foods can help people lose weight because it can help you avoid overeating. A high protein diet, containing all essential nutrients, can help build lean muscle when combined with exercise. Lean body mass also helps to burn more calories throughout the day, which can also help with weight loss.\nRead more to learn all about the pros and cons of a high protein diet.\nThe Basics on Protein\nProtein, containing essential amino acids, is one of the three macronutrients found in the body (the other two are carbohydrates and fats), whose primary responsibility is to strengthen, repair, and fuel the muscles. Since proteins are macronutrients or “macros,” they also serve as a source of energy, where 1 gram of protein is equivalent to 4 calories.\nSince proteins fuel the muscles, this is especially important in aiding digestion, thus increasing the metabolism. They also are considered to have the highest thermic effect among the three macros, which means that it requires more calories to break down, avoiding excess calories to be stored in the form of fat. Additionally, proteins provide satiety (the sensation of fullness), thus reducing certain tendencies such as snacking, binge-eating, and a constant craving appetite.\nA Look into the Other Macros\nThe typical recommended diet usually comprises around 50% carbohydrates, 35% protein, and 15% fats, but this is always adjustable according to whatever your body goals are. However, it is important to note why these ratios are such and how the body benefits from this.\nCarbohydrates are the macros responsible for the body’s energy. Carbs are the body’s main source of glucose and energy, which are measured in the form of calories. Thus, carbohydrates such as bread, rice, pasta, and potatoes are known to be calorie dense.\nFats are responsible for energy storage, and they provide a layer of protection to the organs in the body. Although fats are notorious for having negative effects in the body such as weight gain and heart complications, it is still important to intake a healthy and moderate amount of healthy fats (which are unsaturated fats) because these types of fats prevent heart disease and generally contribute to the overall well-being of the body.\nWhy Focus on High Protein Foods?\nCompared to the other two macros, protein intake is not known to contribute to weight gain. This is because proteins are primarily focusing energy on muscle mass whereas carbohydrates and fats are used in the body in terms of storage and energy consumption.\nWhen a person lacks physical activity and consumes less energy throughout the day, the excess calories from carbs may be stored in the form of fat, causing weight gain. Likewise, over intake of fatty foods (especially bad fats) may thicken the protective layer of fat in our body, causing health complications and an increase in weight.\nBut what about high protein foods? Well, protein foods are the most weight loss friendly macros because they quicken the metabolism while preventing you from losing muscle mass, which promotes healthy weight loss. A high protein diet also provide the most satiety compared to the other two macros, preventing a spike in appetite.\nCompared to fats and carbs, protein foods for weight loss are the least likely to increase appetite and cravings. If you take a look at some foods from these food groups, a person may more likely crave fatty foods and carbs such as doughnuts, pizza, processed food, potatoes, and pasta, than protein-dense food such as pork chops, fish, beans, and beef. Although these fatty and high-carb foods are generally not harmful to your body, their addictive quality due to taste, convenience, and marketing undoubtedly makes it harder to control the diet and lose weight.\nThere are multiple options and revisions you can make to your diet to increase protein intake. You can opt to use a protein powder, which can be incorporated in shakes and smoothies, most of which are available in supermarkets and online. You can also opt to switch out some of your regular grocery purchases to a more high-protein and low-fat alternative.\nThe Best High Protein Foods for Weight Loss\nListed below are some of the best protein foods for weight loss.\n1. Whole grains and pulses\nPulses are the edible seeds from legumes that are known to be fiber and protein-rich, containing amino acids. Looking for high quality protein products? Whole grains and pulses are certainly among the best protein foods for weight loss. Examples of pulses are:\nPulses are one of the best options to integrate to a high protein diet if you want to lose weight. This is because they are rich in fiber, which is an essential aid to digestion, promoting a fast and healthy metabolism as well as a strong immune system. Pulses also contain more protein, strengthening the muscles and providing adequate energy for the body’s consumption.\nApart from being a staple food towards weight loss, pulses offer several other health benefits. They are also good for diabetics, as they have a low-glycemic index and generally do not contribute to an increase in blood sugar. Thus, people with diabetes can opt for a pulse-centered diet while still being able to maintain and regulate their blood sugar levels.\nAdditionally, pulses are relatively affordable and convenient. They can be found in every grocery store or marketplace, and are very flexible and easy to cook. There are a variety of different meals ranging from bean dips to a healthy side dish, or lentil soups to beans with pork. A high demand in pulses also may be able to help the environment because legumes and other pulse crops reduce greenhouse gases in the atmosphere, and require less water compared to other agricultural crops, promoting a cleaner and greener earth.\n2. White-meat fish\nMost types of fish contain essential amino acids and other important micronutrients needed for weight loss. They are excellent protein sources. Compared to other kinds of fish though, white-fleshed fish are the most lean and protein-rich; others are fatty fish. While other types of fish also contain a high amount of protein, white-fleshed fish, a high protein food, distinctly healthier since they have a lesser percentage of fat.\nThese types of fish contain about 3 grams of fat and 130 calories per serving (which is about 100 grams per serving). How much protein do these meat have? Approximately 20-25 grams of protein!\nExamples of these types of fish are tilapia, flounder, halibut, cod, and haddock. All of these are highly convenient and accessible at most supermarkets and wet markets. These are also easy to prepare and cook with, allowing a number of different recipes for you to try.\nThis doesn’t mean that you should completely cut off other types of fish from your diet. In fact, it is also important to consume other types of fish from time to time since there are certain nutrients, such as omega-3 fat, that are beneficial to your body that are not so abundant in white-fleshed fish compared to the darker meat fish such as salmon and tuna. Ultimately, it is best to figure out a balance between the two according to what works best for you.\n3. White-meat Poultry\nChicken, turkey, quail, and other poultry are also high protein foods for weight loss, containing amino acids. There’s approximately 30 grams of protein per 100-gram serving. However there are certain parts of these birds that are also packed with fat and may not be weight-loss friendly. This is why it is best to focus on white-meat poultry as your protein sources.\nWhite-meat cuts are usually the leanest, containing the least amount of fat. Examples of these are chicken breast, chicken tenders, and chicken wings.\nIf you’re trying to lose weight, then chicken breast is the best cut for you. It is the leanest part of the chicken, which means high protein but low calories. Chicken breast is also chock full of calcium and phosphorous.\nTheir counterparts, drumsticks and thighs, contain more saturated fat and could highly contribute to weight gain.\nIt is also crucial to avoid eating the skins of these foods, as the poultry skin itself contains 200 calories and 8 grams of fat per 100-gram serving. However, it is completely fine to keep the skin intact during cooking (because it does make the chicken moister and more flavorful) but make sure to set it aside later on when it is time to eat.\nWhite meat poultry is also easy to cook with and easy to find, as they are available in almost every supermarket. It’s one of the most available high protein food. However it is important to also consider that unprocessed meats are always the best and safest option especially to those who intend to lose weight, so stay away from pre-packed and pre-seasoned chicken nuggets and the like, as they might do more harm than good in the long run.\nAvoid saturated fat and switch to these healthy poultry products.\n4. Low-fat Dairy\nSwitch to low-fat dairy products if you want to up your protein intake. The effects may seem minimal but this actually is quite an influential move if you are aiming to lose weight.\nIf we consider the amount of dairy consumed in every bowl of cereal, every serving of white sauce pasta, every grilled sandwich with cottage cheese, and every cup of coffee, you might be consuming more fat in a day than you are aware of.\nThus, switching to low-fat dairy is one of the most sustainable options for weight loss, as they can be incorporated in little areas of your diet such as the above mentioned while containing the same amount of calcium (which is beneficial for bone strength) and cutting off a significant amount of fat in your diet.\nBut how beneficial exactly are the low-fat alternatives to dairy? Well, in comparison to whole milk, low-fat milk contains the same amount of calories with 69% less fat.\nAnother wise revision you might consider making is to switch to low fat greek yogurt instead of regular yogurt. Plain greek yogurt is one of the best protein foods for weight loss. Opting for plain greek yogurt also cuts off the unnecessary sweeteners and added sugar, which makes it easier for you to control as you could always add sweeteners of your own (such as fruit and honey).\nCottage cheese is also one of the best protein foods for weight loss. A single cup of low-fat cottage cheese has a whopping 28 grams of protein and only 163 grams calories.\nIf you need to focus on a high protein diet, consider try tofu! Tofu is one of the most famous alternatives for red meat, especially for those who do not consume animal products. This soft and cheese-like textured food is made up of condensed soy milk and contains about 8 grams of protein, 2 grams of carbohydrates, 1 gram of fiber, and 4 grams of fat per 100 gram serving (as well as other elements such as calcium, iron, zinc, manganese, magnesium, etc.). It also containscontains all nine amino acids that the body can’t make on its own.\nConsidering these ratios, tofu is one of the best options if you are looking for low-fat, nutrient-dense, and high protein foods for weight loss. Apart from that, it is highly flexible in cooking, as you can get it in different textures and is widely used in a variety of different recipes.\nHowever, about 95% of soybeans in the US are genetically modified (GM). Most studies suggest that the GM properties of soybeans are harmless to the body, but if you are against GM food, you can always opt to buy organic tofu, though they can be a little more pricey.\n6. Lean Meat\nMeat are complete sources of protein because they contain all 9 essential amino acids. It’s a complete protein! However, there are specific cuts and parts that you might want to focus on if you are aiming to lose weight.\nLean meats, by definition, are portions of meat with the least fat content. These types of cuts contain the same grams of protein and other beneficial nutrients with other portions of meat, but their fat percentage is significantly less, if not, none at all. These types of foods, because of their low fat content, are especially good for weight loss.\nAs for lean beef, they are normally labelled with “loin” or “round” (i.e. sirloin, eye of round roast, tenderloin, round steak), but there are other cuts of beef that are lean as well such as the flank steak and the brisket flat-half. If you want to buy ground beef, most supermarkets have an option to get it lean as well.\nLean pork is usually indicated with “loin” and “chop” (i.e. pork loin, pork chops, sirloin). The leanest of which is the pork tenderloin. Additionally, if there is still some fat attached to the meat, you could always chop it off before cooking to avoid unnecessary fat consumption, stored body fat, and heart disease risk factors.\nBison or buffalo meat usually have the leanest overall meat. Studies have confirmed that the same cuts of beef had twice as much fat compared to those of the bison. Bison is also considered a healthier meat, as they are more likely to be grass and grain fed, having more organic attributes compared to other types of meat, which is always a good sign.\n7. Egg Whites\nEggs are also perfect if you need to increase your protein intake. They are high in protein, containing all of the essential amino acids. However, they are also high in calories and fat, most of which are found in the egg yolk. The egg white contains about half of the total protein content of the egg.\nThe reason why egg whites are better off in a weight loss diet is because most of the calories and fat are concentrated in the yolk, while the white part contains less of these but still with half the amount of protein of the entire egg.\nIf you worry about wasting an egg yolk every time you cook an egg, there are options in the supermarket that sell only egg-white products, such as powdered egg whites and egg white protein powder which you can mix with water and use like regular egg whites.\n8. Powdered Nut Butters\nAnother healthy revision to your high protein diet is to switch out regular peanut butter with the powdered alternative. It offers a lot of health benefits, hence tagged as one of the best protein foods for weight loss! A regular peanut butter is highly fat and calorie-dense, containing about 190 calories, 16 grams of fat, and 8 grams of protein per 2 tablespoons. Powdered peanut butter on the other hand, a plant based protein, contains about 50 calories, 1.5 grams of fat, and 5 grams of protein per 2 tablespoons.\nThis is mainly due to how it is processed. To make powdered peanut butter, the fat is normally rendered out during the process. If you noticed, regular peanut butter gets its creamy texture from oils, while powdered peanut butter, mostly a plant based protein, can always be mixed with water to accomplish that spreadable texture (however oily peanut butters are always creamier). Always opt for plant proteins whenever possible! These are also perfect if you are doing a vegan diet.\nPowdered peanut butter can also be added to smoothies and shakes to enhance the flavor without adding unnecessary fat to the drink, making it a sustainable and healthier option for weight loss.\nAnother high protein product are potatoes. They have a reputation as a starchy carb but are good sources of nutrients, including protein and other essential nutrients. One medium potato with the skin on contains just over 4 grams of protein. People should use caution when preparing a potato as the extras that people often put on potatoes can increase the calorie count.\nWhat to Remember in High Protein Diets\nNot all foods with several grams of protein are beneficial for weight loss, though most of them are able to maintain a good healthy weight. Some protein rich foods such as pork belly and chicken drumsticks are excellent sources of protein, but are also rich in fat, defeating the purpose of high protein diets that aim for weight loss.\nAdditionally, focusing on a high protein weight loss diet does not mean that you should completely cut off carbohydrates from your diet. Studies have shown that doing so actually increases your vulnerability to certain diseases. Therefore, it is important to still intake carbs and fat in moderation in order for your body to get certain nutrients that may not be available in these types of protein foods. Stay healthy while trying to lose weight following a protein rich diet!']	['<urn:uuid:1bcb9853-3793-4f10-a0fd-3296148fe6d5>', '<urn:uuid:e7de2ca7-3f0d-4a9a-bf3d-7cfada6f5075>']	factoid	direct	concise-and-natural	distant-from-document	multi-aspect	expert	2025-05-12T22:49:38.933606	10	69	4056
8	professional gardener seeking ideal weather conditions performing pruning maintenance shrubs	An ideal condition for pruning is a dry, sunny situation where the cut is clean and the wound can heal correctly. Pruning is not advised if it is damp or wet outside, as this risks spreading diseases and encourages faster microbe growth that can damage the pruning work.	['As the fall comes rolling in, homeowners start the chore of cleaning up their property. They crave getting outside to prepare their gardens and landscape for the upcoming winter and part of their routine is to prune shrubs, trees and plants. Before you ask yourself “Should I prune in the fall” and start hacking away at those bushes, learn a few lessons about pruning in fall that will help you avoid mistakes on your landscape.\nAccording to gardening expert Mike McGrath, author of Mike McGrath’s Book of Compost, and radio host of the show You Bet Your Garden, the rule of pruning is that you should NOT prune in fall. That’s right, nothing and no exceptions.\nWhy Fall is Not Prime Time for Pruning\nAny gardening expert will tell you, (contrary to what you may believe) that pruning encourages new growth just when the plant is trying to go dormant and new growth doesn’t have enough time to harden before the first frost and freezing temperatures hit. Pruning at this time of year will severely weaken the plants.\nThis is disastrous for the plants and all the hard work you did during the year to make your landscape beautiful. If you can wait until all the leaves have fallen, you will allow the trees and shrubs the ability to have better structure and strength to make it through the winter to next spring without any damage. So, put your pruners away for another month or two and let plants go completely dormant. Once the dormancy has settled in, you can prune trees and shrubs after all the leaves have dropped. Pruning during the right time of year for overgrown flowering shrubs or fruit trees will help the plants produce more flowers and fruit when spring rolls around again.\nIt should also be noted that pruning is not advised if it is damp or wet outside. You will run the risk of spreading a lot of diseases in addition to the damp weather encouraging microbes to grow at a considerably faster rate. This growth will wreak havoc on the pruning that you just completed. An ideal condition is a dry, sunny situation where the cut is clean and the wound can heal correctly.\nAny major pruning that you might be considering should be done in late winter-early spring when the wound will heal faster. However, there is one exception to the rule of thumb on pruning during the fall. You can prune any dead, diseased and damaged wood including anything on the property, (like a big branch over the roof) that might be hazardous to you or your home.\nWhat You Can Do Now\nWhat you can and should do is focus your attention on raking up the leaves (don’t leave them on the lawn), mulching and topping up the gardens so that they have a protective bed during the winter months. You can also consider amending the soils so that it is in tip-top shape come spring. Additionally, spring bloomers can be pruned after they have finished flowering.\nThe benefit of pruning is that it allows more sunlight and air to filter through the trees and shrubs, so it’s important to focus first on removing dead or dying branches by cutting between the diseased spot and the main body of the plant. You should also prune when branches are rubbing or crossing each other, cutting the smaller of the two off. Taking off low hanging branches that interfere with foot traffic or lawnmowers is perfectly acceptable as with any branch that might be growing vertically. Always try to cut back to the main stem or body of the plant.\nWhat goes around comes around once again and pruning properly during the correct time of year will produce a healthier and more robust plant for the next season. So set your sights on pruning when it’s appropriate and avoid the pitfall of pruning in the fall for a more beautiful landscape next spring.\nRead some more gardening tips in our gardening blog category.']	['<urn:uuid:79c67ff4-8e67-4516-9450-19e2661cdc70>']	factoid	with-premise	long-search-query	distant-from-document	single-doc	expert	2025-05-12T22:49:38.933606	10	48	672
9	what causes nerve pain neuralgia and which medications best treat postherpetic neuralgia pain management	Neuralgia can be caused by trauma, pressure on nerves, infections (like shingles), chemicals, chronic diseases, and medications. For postherpetic neuralgia specifically, treatment includes multiple approaches: antiviral medications (acyclovir, valacyclovir, famciclovir), topical analgesics (capsaicin cream, lidocaine patches), tricyclic antidepressants (like amitriptyline), opioid analgesics, and gabapentin (up to 3600mg/day). Most patients require a combination of these treatments for adequate pain relief.	['The nerves play an important role in the body by carrying signals to and from the spinal cord and brain (central nervous system). In this way sensory signals can feed back sensations to the central nervous system (CNS) and transmit signals to different parts of the body from the CNS. It is one of the body’s way of getting information about the environment (both internal and external) as well as exerting an influence on the different organs and structures. Sometimes the nerves can be diseased or damaged thereby triggering sensations even without any underlying problem.\nWhat is neuralgia?\nNeuralgia is the term for nerve pain. It must be differentiated from other types of pain because the problem lies in the nerve itself. Normally we feel pain at a certain part of the body when it is injured. Pain warns us that tissue damage is occurring and we must try to act to remove the cause of the injury. It essentially tells us that all is not well in the body. The signals generated from the pain receptors where the damage is occurring is fed back to the CNS through the nerves and perceived as the sensation of pain.\nHowever, when the nerve itself is undergoing some injury or is malfunctioning in some way, pain signals may be generated despite there sometimes being no tissue damage of the surrounding area. We refer to this as nerve pain, or neuralgia. There are many different types of neuralgia classified according the area, nerve involved or cause of the neuralgia. It can be a difficult condition to treat when there is no clear underlying cause that can be targeted. At times a neuralgia can become a chronic disorder leading to months, years or even a lifetime of pain.\nTypes of Neuralgia\nThere are a wide variety of neuralgias. As mentioned, it is classified according to:\n- The area where the neuralgia emanates.\n- The nerve affected in the neuralgia.\n- The cause of the nerve irritation or damage.\nThe three most common types of neuralgias are:\n- Post-herpetic neuralgia, also known as shingles, arises with reactivation of the chickenpox virus. It can then damage the nerve fibers and lead to long periods of pain as well as skin symptoms along the affected areas.\n- Trigeminal neuralgia is nerve pain involving the trigeminal nerve. It is usually a chronic condition involving the trigeminal nerve which relays sensory signals from the face to the brain. Pressure on the nerve is most frequently the underlying cause.\n- Sciatica or sciatic nerve pain is another type of neuralgia. It occurs when there is pressure on the root of the sciatic nerve at the lower back. As a result there is pain along the distribution of the sciatic nerve usually extending from the back down the leg.\nSome of the other types of neuralgia include:\n- Glossopharyngeal neuralgia involving the glossopharyngeal nerve with pain at the back of the tongue, throat and near the ear.\n- Intercostal neuralgia involving the intercostal nerves between the ribs leading to chest wall pain.\n- Occipital neuralgia involving the the occipital nerves in the neck and leads to pain in the neck, upper back and scalp.\nCauses of Neuralgia\nThese are some of the more likely causes of neuralgia. However, there are times where the cause of a neuralgia is unknown and it is termed as idiopathic.\n- Trauma – injury to the nerve with blunt or sharp force trauma, including nerve injury due to surgery.\n- Pressure – compression of the nerve by surrounding structures in the body.\n- Infections – certain viruses and bacteria in particular can infect nerves, like shingles, syphilis HIV, Lyme disease.\n- Chemicals – endogenous (produced within the body) and exogenous (sourced from outside) can irritate nerves.\n- Chronic diseases – chronic kidney disease, diabetes mellitus, porphyria.\n- Medication – a number of drugs may cause neuralgia as a side effect, especially chemotherapeutic (anti-cancer) drugs.\nRead more about types and causes under peripheral neuropathy.\nSigns and Symptoms\nNeuralgia is a symptom and not a disease on its own. The pain varies in nature but is usually described as a burning, shooting or stabbing pain. Pressure on the area like during firm touch may further exacerbate the pain. Sometimes there is only tenderness (pain with pressure). Typically the pain is localized to a specific area although it may extend along the course of the affected nerve. Despite the predominant feature being pain, there may also be numbness in that other sensations are not felt. The pain can be intermittent or constant.\nAlthough neuralgia does not usually affect the functioning of an area, there may be some degree of muscle weakness or spasm in the affected area. In rare instances there can be complete paralysis if corresponding motor nerves (nerves that control muscles) are also affected or if the affected nerve has a combination of sensory and motor fibers (mixed nerves). Paresthesias like tingling, prickling or formication (crawling insect sensation) may precede the onset of pain is some types of neuralgias.\nTreatment of Neuralgia\nThe treatment for neuralgia largely depends on the underlying cause. It may require the use of medication and/or surgery. Ideally the treatment should be directed at the cause of the neuralgia, like medication to treat an infection or surgery to relieve the pressure off the nerve. However, the neuralgia can persist even after the cause is treated. Furthermore the cause cannot be treated in idiopathic cases since the cause is unknown. In these instances the treatment is directed at the nerve pain itself.\n- Over-the-counter and prescription painkillers.\n- Anesthetic patches or injections.\nThese drugs offer symptomatic relief to manage pain until the underlying cause can be treated or resolves on its own. However, neuralgias can become a chronic condition meaning that medication may be necessary to some degree or the other for a long periods of time. Physical therapy may also be helpful in managing the pain. Occupational therapy and psychotherapy may be advisable in order to cope with the pain and continue with daily tasks.\n- Nerve blocks may involve anesthetic injections or temporary disrupting nerve fibers to reduce pain signals.\n- Neurectomy where the nerve is cut or removed to permanently stop pain signals.\n- Other procedures depending on the cause, like to reduce pressure in nerve root compression.', '1University of Texas, Health Sciences Center, Houston, Texas, USA\n2Departments of Dermatology, Microbiology/Immunology, and Internal Medicine, University of Texas, Medical Branch, Houston, Texas, USA\nPostherpetic neuralgia (PHN) is a serious complication of herpes zoster that has a predilection for older individuals. PHN is often associated with significant morbidity, and it can cause insomnia, fatigue, depression and interference with daily activities in affected\nindividuals. Treatment for PHN is initiated with anitvirals during the acute herpes\nzoster outbreak. Acyclovir (Zoviraxr®, GlaxoSmithKline), valacyclovir (Valtrex®, GlaxoSmithKline) or famciclovir (Famvir®, Novartis) can be used to treat herpes zoster, and all three have been shown to reduce the duration of the herpetic rash and zoster-associated pain. These antivirals are most effective when used within the first 72 hours of the onset of the rash. Side-effects of these antivirals are low and include nausea, vomiting, abdominal pain and headache. Other treatment options for PHN include topical analgesics, opioid analgesics, tricyclic antidepressants and gabapentin. Because of the complexity of PHN, most patients require a combination of treatment modalities for adequate pain relief.\nKey Words: postherpetic neuralgia, herpes zoster\nHerpes zoster is initially characterized by a prodromal phase that is associated with pain and paresthesia in the affected dermatome. Hours to days later, a papular rash appears and progresses to vesicles, then pustules and finally crusts and heals 3-4 weeks later. In some patients, the pain persists weeks to months, or years after the rash has healed, hence the term postherpetic neuralgia (PHN). Studies have demonstrated that there are three phases of PHN: acute, subacute, and chronic.1 The acute phase occurs with the onset of the rash and lasts for approximately 30 days, the subacute phase lasts 1-3 months after the onset of the rash, and the chronic phase, or PHN, lasts 3 months or longer after the onset of the rash.2\nRisk factors for PHN include prodromal symptoms and severity of pain at the onset of the rash.5 The most significant risk factor for the development of PHN is age, as the incidence of PHN increases with age. While studies have demonstrated the overall incidence ranges from 10% to 27%,6,7 the incidence for individuals over the age of 50 is 40%, and 75% for those over the age of 75.8,9\nThe persistent pain associated with herpes zoster is variable in nature, and can be characterized as any of the following: (1) burning background pain with fluctuating severity; (2) sudden, sharp shooting pain; (3) mechanical or thermal allodynia (pain produced by non-noxious stimulus).10 As a result of this severe, often debilitating pain, a patient’s quality of life is often adversely affected. In addition to interfering with activities of daily living, PHN may lead to fatigue, insomnia, anxiety, and depression.11 Because of the severity and complexity of the disease, treatment is initiated at the onset of the rash and may be necessary months to years later.\nAntivirals and PHN\nAcyclovir, valacyclovir, or famciclovir can be used to treat acute herpes zoster and to reduce the severity and duration of viral replication. Through this inhibition of viral replication, acyclovir decreases the appearance of new lesions and accelerates crusting of the lesions.12 Despite this highly therapeutic effect of acyclovir in acute herpes zoster, many previously published studies demonstrated that acyclovir had no benefit in reducing the duration or incidence of PHN. However, more recent meta-analysis studies of all placebo-controlled trials with acyclovir for herpes zoster established that there is a significant reduction in zoster-associated pain in patients who received acyclovir.13,14\nSimilar results have also been observed with valacyclovir, as it, like acyclovir, minimizes the severity and duration of the acute herpes zoster outbreak.12 In addition, valacyclovir is more effective than acyclovir at reducing the duration of PHN. Studies have shown an average reduction of the duration of pain from 60 days, as seen with acyclovir, to 40 days with valacyclovir. Similar reductions in pain were also noted at 6 months after healing of the rash, as only 19% of patients taking valacyclovir reported pain, compared to the 26% of patients taking acyclovir.15\nFamciclovir also promotes cutaneous healing and reduces the duration of acute pain. Patients who receive famciclovir have PHN resolve two times faster than those who receive placebo, resulting in a 3.5 month reduction in the average duration of pain.16 When comparing famciclovir to valacyclovir, both drugs equally hasten the resolution of zoster-associated pain and PHN.17\nAll three antiviral agents are approved for the treatment of herpes zoster. The most beneficial effects of the drugs are seen if they are used within the first 72 hours of the onset of the rash. Therefore, early clinical diagnosis and treatment of the disease results in faster cutaneous healing and reduced duration of PHN.\nAntiviral Drug Profile\nAcyclovir, valacyclovir, and famciclovir are highly selective for thymidine kinase (TK), an ezyme encoded by the herpes zoster virus. TK converts acyclovir into acyclovir monophosphate, a substrate that is ultimately modified into acyclovir triphosphate via cellular enzymes. In famciclovir, the active metabolite is penciclovir rather than acyclovir (as in valacyclovir), and it also undergoes phosphorylations via TK and other cellular enzymes to form penciclovir triphosphate. Penciclovir and acyclovir triphosphate inhibit DNA replication of the virus through (1) competitive inhibition and inactivation of viral DNA polymerase; and (2) via incorporation and termination of the growing viral DNA. By inhibiting viral replication, these antivirals reduce viral shedding, hasten cutaneous healing and reduce the severity and duration of pain.\nAcyclovir, valacyclovir, and famciclovir share a similar safety profile. All three are considered very safe, with nausea, vomiting, diarrhea, abdominal pain, and headache being the most commonly reported side-effects. Although extremely rare, nephropathy, and neurotoxicity have been reported in acyclovir.\nThe difference in these antiviral agents lies in the bioavailability and cost. Unlike acyclovir, which has an oral bioavailability of 10%-20%, valacyclovir and famciclovir have an advantage of increased oral bioavailability of 65% and 77%, respectively, over acyclovir.19 As a result of this increased bioavailability, both famciclovir and valacyclovir have a more convenient dosing schedule and both are taken three times daily (see table 1). In addition, since all three antiviral agents reduce the duration of PHN, cost is often a factor when choosing among these drugs. Famciclovir is typically more expensive than valacyclovir, which is more expensive than generic acyclovir.\n|Antiviral Agent||Dosage||Adverse Effects|\n|Acyclovir||800mg, po, 5 times daily for 7-10 days||Nausea, vomiting, headache, diarrhea, dizziness,|\nfatigue, anorexia, edema, and sore throat\n|Valacyclovir||1gm, po, t.i.d. for 7 day||Nausea, vomiting, headache, dizziness, and abdominal pain|\n|Famciclovir||500mg, po, t.i.d. for 7 days||Nausea, vomiting, headache, dizziness, abdominal pain, and fatigue|\nTable 1: Antivirals Approved for Treatment of Herpes Zoster.\nTreatment Modalities for PHN\nTopical analgesics are commonly used for the short-term relief of PHN. Capsaicin cream, applied 3-4 times daily, is commonly prescribed and functions to reduce pain by depleting substance P via neurogenic vasodilatation. Side-effects include intolerable burning pain.20 A topical 5% lidocaine patch can also provide relief of PHN for approximately 12 hours after application.21 Side-effects are mild and include local skin reactions such as erythema.\nTricyclic antidepressants (TCAs) have been used extensively for the treatment of PHN, as they have been shown to provide moderate-to-excellent pain relief.20 Amitriptyline is the most widely prescribed TCA, but other TCAs such as nortriptyline and desipramine can also be used effectively to treat PHN.22 Despite their widespread use, side-effects are common, and careful consideration is often required prior to prescribing TCAs to older patients. TCAs are associated with dry mouth, constipation, urinary retention, blurred vision, glaucoma, and weight gain. Cardiovascular side-effects have also been associated with TCAs and include orthostatic hypotension, arrhythmias, and EKG abnormalities.\nOpioid analgesics are also commonly employed for the treatment of PHN. Short-acting analgesics provide acute relief of pain, but long-acting agents, such as controlled release morphine and oxycodone, can also be used for an extended duration of pain relief.4 Side-effects of these analgesics include drowsiness, nausea, constipation, and loss of appetite. Patients should also be evaluated for a history of substance abuse before they are prescribed these analgesics.\nGabapentin, a second-generation anticonvulsant, has been shown to significantly reduce the duration of PHN.23,24 Patients receiving gabapentin have lower daily pain scores and fewer disturbances in mood and sleep when compared to those recieving placebo. Although there is no standard dosing regimen, recent studies indicate that treatment can be initiated at 900mg/day, and additional titration to 1800mg/day is often necessary for additional efficacy.25 Dosages of up to 3600mg/day may be required in some patients, and it should be noted that doses should be prescribed based on the individual’s tolerance of the medication.25 Gabapentin has a good safety profile, especially among older patients. Side-effects that have been reported include somnolence, dizziness, and gait disturbances such as ataxia. Because both gabapentin and the lidocaine patch are approved by the US FDA for the treatment of PHN and are associated with minimal side-effects, some consider these two agents to be first-line treatments for PHN.4\nAlthough corticosteriods (oral or parenteral) have been used for the prevention of PHN in the past, they are currently not recommended in patients with PHN.26 Recent studies show that while patients treated with corticosteriods, such as prednisone, have a shorter duration of acute pain and faster resolution of the herpes zoster rash, no long-term benefits of PHN have been documented.27 As such, short-term corticosteroid use (i.e., 40-60mg prednisone taper for 15-21 days) can be utilized to reduce the severity of pain and improve quality of life in the acute phase;27,28 however, long-term use of corticosteroids is not recommended as they can facilitate bone loss and impair the host immune system, factors particularly of concern in the elderly.\nPostherpetic neuralgia is a debilitating disease, especially in older individuals. The early use of antivirals (i.e., within the first 72 hours of the onset of the rash) not only reduces the duration of rash, but also reduces the duration of PHN. Thus, treatment of PHN begins with early diagnosis and treatment of herpes zoster. Other treatment modalities such as topical analgesics, TCAs, gabapentin, and opioid analgesics are often necessary, as many patients continue to have pain despite the early use of antivirals. A combination of different treatment modalities is usually implemented, as no single therapy is completely effective. Although most of these therapeutic agents are used after the resolution of the rash, the use of one or more of these treatments (i.e., gabapentin, opioid analgesics, or TCAs) with antivirals during the acute herpes zoster infection may help not only to alleviate acute pain, but also to prevent and reduce the duration of PHN.\n- Arani RB, Soong SJ, Weiss HL, et al. Phase specific analysis of herpes zoster associated pain data: a new statistical approach. Stat Med 20(16):2429-39 (2001 Aug).\n- Dworkin RH, Portenoy RK. Proposed classification of herpes zoster pain. Lancet 343(8913):1648 (1994 Jun).\n- Desmond RA, Weiss HL, Arani RB, et al. Clinical applications for change-point analysis of herpes zoster pain. J Pain Symptom Manage 23(6):510-6 (2002 Jun).\n- Dworkin RH, Schmader KE. Treatment and prevention of postherpetic neuralgia. Clin Infect Dis 36(7):877-82 (2003 Apr).\n- Whitley RJ, Weiss HL, Soong SJ, Gnann JW. Herpes zoster: risk categories for persistent pain. J Infect Dis 179(1):9-15 (1999 Jan).\n- Donahue JG, Choo PW, Manson JE, Platt R. The incidence of herpes zoster. Arch Intern Med 155(15):1605-9 (1995 Aug).\n- Scott FT, Leedham-Green ME, Barrett-Muir WY, et al. A study of shingles and the development of postherpetic neuralgia in East London. J Med Virol 70(Suppl 1):S24-30 (2003).\n- Lancaster T, Silagy C, Gray S. Primary care management of acute herpes zoster: systematic review of evidence from randomized controlled trials. Br J Gen Pract 45(390):39-45 (1995 Jan).\n- Portenoy RK, Duma C, Foley KM. Acute herpetic and postherpetic neuralgia: clinical review and current management. Ann Neurol 20(6):651-64 (1986 Dec).\n- Bowsher D. Factors influencing the features of postherpetic neuralgia and outcome when treated with tricyclics. Eur J Pain 7(1):1-7 (2003).\n- Schmader KE. Epidemiology and impact on quality of life of postherpetic neuralgia and painful diabetic neuropathy. Clin J Pain 18(6):350-4 (2002 Nov-Dec).\n- Beutner KR, Friedman DJ, Forszpaniak C, Andersen PL, Wood MJ. Valaciclovir compared with acyclovir for improved therapy for herpes zoster in immunocompetent adults. Antimicrob Agents Chemother 39(7):1546-53 (1995 Jul).\n- Wood MJ, Kay R, Dworkin RH, Soong SJ, Whitley RJ. Oral acyclovir therapy accelerates pain resolution in patients with herpes zoster: a meta-analysis of placebo-controlled trials. Clin Infect Dis 22(2):341-7 (1996 Feb).\n- Jackson JL, Gibbons R, Meyer G, Inouye, L. The effect of treating herpes zoster with oral acyclovir in preventing postherpetic neuralgia. A meta-analysis. Arch Intern Med 157(8):909-12 (1997 Apr).\n- Beutner KR. Antivirals in the treatment of pain. J Geriatr Dermatol 6(2 suppl):23A-28A (1994).\n- Tyring SK. Efficacy of famciclovir in the treatment of herpes zoster. Semin Dermatol 15(2 Suppl 1):27-31 (1996 Jun).\n- Tyring SK, Beutner KR, Tucker BA, Anderson WC, Crooks RJ. Antiviral therapy for herpes zoster: randomized, controlled clinical trial of valacyclovir and famciclovir therapy in immunocompetent patients 50 years and older. Arch Fam Med 9(9):863-9 (2000 Sep-Oct).\n- Burnette TC, de Miranda P. Metabolic disposition of the acyclovir prodrug valaciclovir in the rat. Drug Metab Dispos 22(1):60-4 (1994 Jan-Feb).\n- Pue MA, Pratt SK, Fairless AJ, et al. Linear pharmacokinetics of penciclovir following administration of single oral doses of famciclovir 125, 250, 500 and 750 mg to healthy volunteers. J Antimicrob Chemother 33(1):119-27 (1994 Jan).\n- Kost RG, Straus SE. Postherpetic neuralgia–pathogenesis, treatment, and prevention. N Engl J Med 335(1):32-42 (1996 Jul).\n- Rowbotham MC, Davies PS, Verkempinck C, Galer BS. Lidocaine patch: double-blind controlled study of a new treatment method for post-herpetic neuralgia. Pain 65(1):39-44 (1996 Apr).\n- Watson CP, Vernich L, Chipman M, Reed K. Nortriptyline versus amitriptyline in postherpetic neuralgia: a randomized trial. Neurology 51(4):1166-71 (1998 Oct).\n- Rowbotham M, Harden N, Stacey B, Bernstein P, Magnus-Miller L. Gabapentin for the treatment of postherpetic neuralgia: a randomized controlled trial. JAMA 280(21):1837-42 (1998 Dec).\n- Rice AS, Maton S. Postherpetic Neuralgia Study Group. Gabapentin in postherpetic neuralgia: a randomised, double blind, placebo controlled study. Pain 94(2):215-24 (2001 Nov).\n- Backonja M, Glanzman RL. Gabapentin dosing for neuropathic pain: evidence from randomized, placebo-controlled clinical trials. Clin Ther 25(1):81-104 (2003 Jan).\n- Ernst ME, Santee JA, Klepser TB. Oral corticosteroids for pain associated with herpes zoster. Ann Pharmacother 32(10):1099-103 (1998 Oct).\n- Whitley RJ, Weiss H, Gnann JW Jr, et al. Acyclovir with and without prednisone for the treatment of herpes zoster. A randomized, placebo-controlled trial. The National Institute of Allergy and Infectious Diseases Collaborative Antiviral Study Group. Ann Intern Med 125(5):376-83 (1996 Sep).\n- Wood MJ, Johnson RW, McKendrick MW, Taylor J, Mandal BK, Crooks J. A randomized trial of acyclovir for 7 days or 21 days with and without prednisolone for treatment of acute herpes zoster. N Engl J Med 330(13):896-900 (1994 Mar).']	['<urn:uuid:a3260317-9546-4fb4-8e18-97cce92702cf>', '<urn:uuid:7e8d4356-4c10-40a2-a6b2-15c3d24af782>']	factoid	with-premise	long-search-query	similar-to-document	multi-aspect	novice	2025-05-12T22:49:38.933606	14	59	3518
10	how many litres milk make emmentaler cheese wheel	A dairyman needs around 1,200 litres of natural unpasteurized milk to make a wheel of Emmentaler AOP cheese weighing around 95 kg. The milk must come from dairy cows left to graze naturally, and no additives or genetically modified organisms are allowed in the production process.	['Gentle lush alpine meadows, idyllic villages, farmhouses tucked in under vast sloping roofs, and sedate richly decorated farmyards characterise the delightful charm of the landscape that produces this great cheese. Each wheel is fashioned in keeping with the artisanal tradition observed in village cheese dairies for centuries. Its tradition, appearance and outstanding quality make Emmentaler AOP the undisputed ‘king of cheeses’ worldwide.\nEmmental (valley of the Emme river in the Canton of Bern)\nProtection of origin:\nAOP Appellation d’Origine Protégée (protected designation of origin) since 2006\nArea of production:\nCantons Aargau, Bern, Glarus, Lucerne, Schwyz, Solothurn, St. Gallen, Thurgau, Zug, Zurich, and parts of Canton Fribourg\nFresh unpasteurised milk from dairy cows left to graze naturally (no silage). The use of any form of additives or genetically modified ingredients is strictly forbidden.\nShape, size, weight:\nRound, flat to slightly convex wheel, 80–100 cm in diameter, 16–27 cm in height, 75–120 kg in weight (average: 95 kg)\nThe characteristic holes are formed as the cheese matures. The natural fermentation produces carbon dioxide which gathers in different places within the cheese and is unable to escape. For a hard cheese, the salt content at 0.5 g / 100 g is extremely low. Emmentaler AOP is lactose-free.\nMinimum 45% fat in dry matter, solid fat\nNaturally matured, firm, golden yellow, branded on one side with the red cheese dairy mark of Emmentaler Switzerland. As it ages the rind becomes dark brown to black in the case of cave-aged Emmentaler AOP, and acquires a patina.\nIvory to light yellow\nSmooth, easy to slice, then fine and crumbly with increasing maturity\nCherry-sized, mostly 2-4 cm in size\nCave-aged: at least 12 months*\n* of which at least 6 months in a natural stone or rock cellar\nAverage nutritional values per 100 g:\nWater 36 g\nProtein 29 g\nFat 31 g\nMinerals 4 g\nCalories 395 kcal\nJoules 1640 kJ\nThe dairyman needs around 1,200 litres of natural unpasteurised milk, rennet, bacteria cultures and plenty of expertise, devotion, and time to make a wheel of cheese weighing around 95 kg. Emmentaler AOP is absolutely free of any additives or genetically modified organisms. It owes its distinctive taste to the milk produced by dairy cows left to graze naturally, traditional processing methods, and the use of propionic bacteria cultures. After the brine bath the cheese is left to mature first in a warm maturation cellar, where the characteristic holes in Emmentaler cheese are formed. The maturation process then takes place in a cool storage cellar.\nThe patented dairy mark is applied to the side of the wheel already at the production stage, allowing this tamper-proof mark to blend permanently with the rind. Each wheel is branded with a radial Emmentaler AOP pattern, along with the operating number of the village cheese dairy. This comprehensive marking means that Emmentaler AOP is easily identified as an original, even when cut and pre-packed, and unambiguously differentiated from any counterfeit cheeses or imitations. Indeed, only Swiss Emmentaler AOP comes from controlled production and satisfies the stringent quality requirements of the trade organisation.\nEmmentaler AOP is tended to in the area in which it was produced for a period of at least four months. With its smooth even rind, its ivory consistency, its cherry-sized holes, and its distinctive nutty and tangy flavour, Emmentaler AOP is a genuine piece of Swiss nature and culture. It is highly prized by cheese connoisseurs as a delicacy capable of enhancing any cheese platter and complementing a full breakfast, but also as the perfect way to round off dinner. It’s also a tasty basic ingredient used in a variety of hot dishes.\nWith eight different varieties, Emmentaler AOP has something to tickle the taste buds of any cheese enthusiast. Depending on the type of maturation and the maturing time, the range covers the full spectrum of flavours, from nutty and mild to tangy and spicy.\nEmmentaler AOP retails as mild once it has aged for a minimum of four months, as mature after eight months, and as full-flavoured after twelve months. With the exception of the cave-aged Emmentaler, all Emmentaler AOP is stored and nurtured in dry cheese cellars. The cave-aged Emmentaler AOP is stored for a minimum of twelve months, six of which are inside a rock cellar. The longer an Emmentaler AOP is left to mature, the stronger its flavour and the darker its rind.\nEmmentaler AOP is highly prized by cheese connoisseurs as a delicacy capable of enhancing any cheese platter and complementing a full breakfast, but also as the perfect way to round off dinner. It’s also a tasty basic ingredient used in a variety of hot dishes.']	['<urn:uuid:b991c830-68a4-45e7-8996-c5e7a1435bd0>']	open-ended	with-premise	short-search-query	similar-to-document	single-doc	novice	2025-05-12T22:49:38.933606	8	46	776
11	definition music medicine vs music therapy	Music therapy is delivered by a trained therapist and involves a therapeutic relationship with interventions tailored to client needs. In contrast, music medicine is defined as listening to pre-recorded music offered by medical staff without a therapeutic relationship.	['- Music therapy is a therapeutic intervention involving the use of music to address physical, emotional, cognitive and social needs.\n- Evidence exists for improvements in cancer-related anxiety, depression, pain, fatigue.\n- Some evidence exists for improvements in quality of life.\n- Most trials were at high risk of bias, so these results need to be interpreted with caution.\n- No safety issues are on record.\nMusic therapy is an established healthcare profession that uses music to address physical, emotional, cognitive and social needs. The interventions used include playing instruments, vocal and instrumental improvisation, singing, composing/song writing, music-guided imagery and music listening. Music therapy is different from music medicine, which is defined as listening to pre-recorded music, offered by medical staff.\nIt has been suggested that music therapy can promote well-being, stress management, pain alleviation, emotional expression, memory enhancement, improved communication and physical rehabilitation.\nEvidence suggests that music therapy may be a helpful supportive care intervention among various cancer populations. Results from the most recent and rigorous systematic review suggested that music interventions may have moderate to strong treatment effects on anxiety, depression, fatigue, pain, and quality of life in people with cancer. Music interventions lead to small improvements in physiological responses such as heart rate, blood pressure and respiratory rate. There is considerable variation between trials with regards to type of music intervention and dosage used and it is therefore not possible to generalise the result.\nNo safety issues are on record.\nFully updated and revised by Joke Bradt in May 2017.\nFully updated and revised by Helen Cooke in December 2014.\nSummary first published in January 2013, authored by Helen Cooke.\nJoke Bradt,Helen Cooke, CAM-Cancer Consortium. Music therapy [online document]. May 20, 2017.\nMusic therapy is an established healthcare profession that uses music to address physical, emotional, cognitive and social needs1,2. Music therapy is delivered by a trained music therapist and is characterized by the presence of a therapeutic relationship and the use of music interventions specifically tailored towards the client’s needs3,4. This is differentiated from music medicine, which has been defined as listening to pre-recorded music offered by a healthcare professional3,4,5. Without the presence of a therapist and a therapeutic relationship, music listening in itself is not music therapy4. It should be noted, however, that there is a lack of consistency in the use of this terminology in the trials reviewed for this summary.\nIn cancer care, music medicine is generally used for symptom management3. In addition to symptom management, music therapists utilize various individualized interventions with cancer patients and their families to address prevailing biopsychosocial and spiritual needs7,8.\nMusic therapists use a variety of music interventions including playing instruments, singing, instrumental and vocal improvisations, song writing, composing, music-guided imagery and listening to live, improvised or recorded music2,3. Music therapy sessions are designed according to the needs of the individual or group and involve a systematic process which includes assessment, treatment and evaluation.\nIn the music medicine trials included in this summary, the pre-recorded music was often selected by the healthcare professionals. However, it has been recommended that patients be encouraged to select their own preferred music3.\nApplication and dosage\nIn cancer care, music therapy is often offered as individual sessions with the patient and may include family members. Music therapy is also offered in group sessions to facilitate social support among patients. In the trials included in this summary, the dosage and frequency greatly varied. The number of sessions ranged from 1 to 40 (e.g. multiple music listening sessions per day for length of hospital stay). Most sessions lasted 30 to 45 minutes. At this time, the relationship between the frequency and duration of treatment and treatment effect remains unclear.\nRecipients of music therapy do not need any prior musical knowledge or experience.\nThe use of music to improve health dates back to ancient times2. Although music therapy is a relatively young health profession, it is well established in both academic and clinical contexts. The first official training program started in Austria in 1959, the UK in 1968 and Norway in 1978. Music therapists often function as a member of an interdisciplinary team in clinical settings but also offer services through private practice. There are many training programs around the world that offer music therapy training at the undergraduate, graduate and doctoral level9.\nClaims of efficacy/alleged indication(s)/mechanism of action\nIt has been suggested that music therapy in cancer care can promote wellbeing, stress management, pain alleviation, emotional expression, improved communication, spiritual support, physical well-being and a sense of control2,3. Research suggests that music therapy interventions may be more effective than music medicine interventions with medical populations for a wide variety of outcomes3. It has been suggested that the difference might relate to how music therapists individualise their intervention to meet patients’ specific needs3.\nPossible mechanisms of actions are framed within a biopsychosocial perspective. Listening to music may reduce anxiety through suppressive action on the sympathetic nervous system, leading to decreased adrenergic activity10,11,12. In addition, research indicates that music offers an escape from stress and worries related to the cancer diagnosis, treatment, and prognosis6. Music also activates the rewards and motivation circuitry in the brain resulting in the release of dopamine which regulates perception of pleasure and mood13. Music making provides opportunities for emotional expressivity which has consistently been linked to mood enhancement14,15. Music experiences offer opportunities to explore and process emotions in a creative process unique from other therapeutic disciplines and facilitate meaning making through music-evoked reflections6.\nImportantly, music provides patients with an aesthetic experience that can offer comfort and peace during times of distress6.\nPrevalence of use\nThe exact prevalence of the use of music therapy for people with cancer is unknown.\nThe World Federation of Music Therapy acts as the international umbrella organization for the profession of music therapy9. In the US, the Certification Board for Music Therapists grants music therapists a national board certification after successfully passing a board certification exam. Music therapists are required to recertify every 5 years. Professional music therapy courses are at postgraduate level in the UK and most of Europe. ‘Music Therapist’ is a protected title in the UK and all practicing therapists must be registered with the Health and Care Professions Council17. All professionally trained music therapists commit themselves to an ethical code as a quality criteria.\nCost(s) and expenditures\nCosts vary depending on the context in which the therapy is given. Some health institutions do not charge for music therapy group sessions.\nFour systematic reviews (including one Cochrane review) and six additional randomised controlled trials (RCTs) were reviewed for this summary. The reviews are described in table 1 and the RCTs in table 2. The results of these reviews and trials suggest that music interventions may be beneficial for cancer-related anxiety, depression, pain, fatigue and quality of life. It should, however, be noted that there is considerable variation in the manner in which the music interventions were conducted including the duration and number of sessions. Some of the interventions which were classified as music therapy simply involved participants listening to pre-recorded music without any additional therapeutic process or involvement of a music therapist. A major issue with music intervention trials is that, in most cases, participants cannot be blinded to the intervention. This introduces a potential for biased reporting of treatment benefits by the study participants. As a result, the evidence of these trials is typically assessed as ‘low’ and the results need to be interpreted with caution.\nThe most recent systematic review, a 2016 Cochrane review examining the effects of music therapy or music medicine interventions on psychological and physical outcomes in patients with cancer included 23 music therapy and 29 music medicine trials (n=52, total 3731 participants)3. The review also compared the effects of music therapy versus music medicine interventions. Results suggest that music interventions may have a moderate to large effect on anxiety (standardized mean difference, SMD = - 0.71), moderate effect on depression (SMD = - 0.40), large effect on pain (SMD = - 0.91), and small to moderate effect on fatigue (SMD = - 0.38). Music interventions lead to small improvements in physiological responses such as heart rate, blood pressure and respiratory rate. A comparison between music therapy and music medicine interventions was possible for a select number of outcomes. The results suggest that music therapy but not music medicine interventions demonstrated a moderate effect on quality of life (SMD = 0.42). No difference was found between the two types if interventions for anxiety, depression and mood.\nA 2013 systematic review included 13 RCTs of music interventions to reduce anxiety for adult cancer patients undergoing medical treatment20. Only 4 RCTs could be included in the meta-analysis with a total of 185 participants. Although the meta-analytic results failed to demonstrate a positive effect on anxiety, the review suggests that music interventions may still offer a degree of clinical utility to mitigate anxiety in adult cancer patients.\nA 2012 systematic review and meta-analysis examined the effect of music interventions on psychological and physical outcomes in adult and paediatric cancer patients21. The review included 32 RCTs with a total of 3181 participants and included studies from both English and Chinese databases. Results suggested that music interventions are accepted by patients and associated with improvements in anxiety, depression, pain and quality of life. The effects of music on vital signs such as blood pressure are small.\nAn additional six RCTs not included in the above reviews have been published22-27. They are also described in Table 2.\nThree trials used music medicine interventions22,23,24 and three music therapy interventions26,27,28. Five RCTs compared the effects of music interventions with standard care and one paediatric trial27 used an audio storybook attention control.\nTwo of the music medicine trials22,24 did not find statistically significant differences between the music listening and the standard care condition for cancer-related symptoms such as pain and anxiety whereas one trial23 reported greater pain reduction in the music listening condition. Reasons for lack of between group differences may be small sample size resulting in insufficient statistical power and unfamiliarity of patients with music delivery technology (e.g. tablet and Spotify), which may possibly increase anxiety or even lead to reduced use.\nThe music therapy RCTs included different cancer populations. One trial included female cancer patients undergoing breast surgery25, one focused on adult cancer patients during high dose chemotherapy27, and one included paediatric cancer patients26. Greater anxiety reductions were reported by the surgical breast cancer patients in the music treatment condition compared to standard care25 whereas chemotherapy patients reported treatment benefits of music therapy for pain but not for anxiety, quality of life, depression or physical functioning27. Unfortunately, the latter study was underpowered. The paediatric trial was a pilot study in preparation of a larger clinical trial26. In this study, parents were trained by a music therapist to engage their child in music activities. Preliminary findings suggest treatment benefits for emotional distress but not child engagement.\nNo adverse events are on record4.\nNo contraindications are on record4.\nNo interactions are on record4.\nIt is important to consider the potential negative impact of the use of headphones during procedures because of hampered communication between the patient and medical personnel. This may increase anxiety in patients3.\n- American Music Therapy Association website. Last accessed 18th May 2017.\n- Richardson MM, Babiak-Vazquez AE, Frenkel MA. Music therapy in a comprehensive cancer center. J Soc Integr Oncol 2008; 6: 76-81.\n- Bradt J, Dileo C, Magill L, Teague A. Music interventions for improving psychological and physical outcomes in cancer patients. Cochrane Database Syst Rev2016; 8: CD006911.\n- Gold C, Erkkila J, Bonde LO, Trondalen G, Maratos A, Crawford MJ. Music therapy or music medicine? [Letter to the Editor]. Psychother Psychosom 2011; 80: 304.\n- Yinger OS, Gooding L. Music therapy and music medicine for children and adolescents. Child Adolesc Psychiatr Clin N Am 2014; 23: 535-53.\n- Bradt J,Potvin N, Kesslick A, Shim M, Radl D, Schriver E, Gracely E, Komarnicky-Kocher LT.The impact of music therapy versus music medicine on psychological outcomes and pain in cancer patients: A mixed methods study. Support Care Cancer 2015, 23: 1261-71.\n- Magill L. Meaning of the music: The role of music in palliative care music therapy as perceived by bereaved caregivers of advanced cancer patients. Am J Hosp Palliat Care 2009; 26: 33-9.\n- McClean S, Bunt L, Daykin N. The healing and spiritual properties of music therapy at a cancer care centre. J Alternat Complement Med 2011; 18: 402-7.\n- World Federation of Music Therapy website. Last accessed 18th May 2017.\n- Gillen E, Biley F, Allen D. Effects of music listening on adult patients’ pre-procedural state anxiety in hospital. Int J Evid Based Healthc2008; 6: 24-49.\n- Nilsson U. Soothing music can increase oxytocin levels during bed rest after open-heart surgery: A randomised control trial. J Clin Nurs2009; 18: 2153-61.\n- Nakayama H, Kikuta F, Takeda H. A pilot study on effectiveness of music therapy in hospice in Japan. J Music Ther2009; 46: 160-72.\n- Salimpoor VN, Benovoy M, Larcher K, Dagher A, Zatorre RJ. Anatomically distinct dopamine release during anticipation and experience of peak emotion to music. Nat Neurosci 2011; 14: 257-62.\n- Livesey L, Morrison I, Clift S, Camic P. Benefits of choral singing for social and mental well-being: Qualitative findings from a cross-national survey of choir members. J Public Mental Health 2012; 11: 10-26.\n- Zakowski S, Valdimarsdottir H, Bobvjerg D. Emotional expressivity and intrusive cognitions in women with family histories of breast cancer: Application of a cognitive processing model. Br J Health Psychol2001; 6: 151-65.\n- Ernst E, Pittler MH, Wider B and Boddy K. Oxford Handbook of Complementary Medicine. Oxford: Oxford University Press, 2008.\n- European Music Therapy Confederation website. Last accessed 18rd May 2017.\n- Wigram T, Pedersen IN, Bonde LO. A Comprehensive Guide to Music Therapy. Theory, Clinical Practice, Research and Training. London: Jessica Kingsley, 2002.\n- Archie P, Bruera E, Cohen L. Music-based interventions in palliative cancer care: a review of quantitative studies and neurobiological literature. Support Care Cancer 2013; 21: 2609-24.\n- Nightingale CL, Rodriguez C, Carnaby G. The impact of music interventions on anxiety for adult cancer patients: a meta-analysis and systematic review. Integr Cancer Ther 2013; 12: 393-403.\n- Zhang JM, Wang P, Yao JX, Zhao MP et al. Music interventions for psychological and physical outcomes in cancer: a systematic review and meta-analysis. Support Care Cancer 2012; 20: 3043-53.\n- Alam M, Roongpisuthipong W, Kim NA, Goyal A, Swary JH, Brindise RT, et al. Utility of recorded guided imagery and relaxing music in reducing patient pain and anxiety, and surgeon anxiety, during cutaneous surgical procedures: A single-blinded randomized controlled trial. J Am Acad Dermatol 2016; 753: 585-9.\n- Arruda M, Garcia M, Garcia J. Evaluation of the effects of music and poetry in oncologic pain relief: a randomized clinical trial. J Palliat Med 2016; 19: 943-8.\n- Mische LL, Glennon C, Fiscus V, Harrell V, Krause K, Moore A, et al. Effects of making art and listening to music on symptoms related to blood and marrow transplantation. Oncol Nurs Forum 2017; 43: E56-63.\n- Palmer JB, Lane D, Mayo D, Schluchter M, Leeming R. Effects of music therapy on anesthesia requirements and anxiety in women undergoing ambulatory breast surgery for cancer diagnosis and treatment: A randomized controlled trial. J Clin Oncol 2015; 33: 3162-8.\n- Robb SL, Haase JE, Perkins SM, Haut PR, Henley AK, Knafl KA, et al. Pilot randomized trial of active music engagement intervention parent delivery for young children with cancer. J Ped Psychol 2017; 42: 208–19.\n- Tuinmann G, Preissler P, Bohmer H, Suling A, Bokemeyer C. The effects of music therapy in patients with high-dose chemotherapy and stem cell support: a randomized pilot study. Psycho-Oncol 2016; 26: 377–84.']	['<urn:uuid:83244082-c595-4779-a336-31aabd15c672>']	factoid	direct	short-search-query	distant-from-document	single-doc	expert	2025-05-12T22:49:38.933606	6	38	2621
12	explain main parts information handling system digital files lifecyle start to end	Information life-cycle management is a comprehensive process that consists of several main components: capturing, classifying, storing, protecting, accessing, and destroying information. The process begins with understanding the asset type, retention periods, and ability to find assets. Information must be captured and classified using metadata tags for proper categorization. Protection involves securing data through backups and archiving. Access controls ensure only authorized individuals can view or modify information. Finally, the cycle ends with proper disposition or destruction of all copies of the information according to regulatory requirements.	['Information life-cycle management is a process that involves capturing, classifying, storing, protecting, accessing, and destroying information.\nBy Steve Kenniston\nne problem with information life-cycle management (ILM) is that it means different things to different vendors. The definition of ILM has ranged from “the ability to ensure that the right information is on the right storage asset at the right time” to the somewhat-vague “ILM is about people, process and technology.” The reality is that ILM is about one thing: best practices for managing information assets. In short, ILM is about process.\nVendors often overlook the fact that processes used to manage information are already in place. In the physical (paper) world, records managers have been making decisions regarding how information assets are managed, as well as implementing policies about how information needs to be retained for a long time.\nThe important components of information assets are the following:\n- The asset type\n- Asset retention periods\n- The ability to find assets\nThe secret to a solid ILM practice is realizing the value of the information assets in your corporation. Understanding the type of information that your company creates, how this information affects your business, and how to manage it properly are the biggest challenges.\nOnce you identify how the information ties in to your business, you can then investigate technologies to help you manage the process of information management.\nIn the records management space, the management of information-although challenging-has been relatively easy because it was contained. In the past, records managers would request that the records management office receive a copy of specific types of records created. At that point the records management department would categorize (assign metadata) and file (store) the asset.\nTwo factors are now making the challenge of managing information more difficult. First, the volume of digital information is growing much more rapidly. Second, the number of rules and regulations that govern how digital information assets are managed is in the thousands. Trying to stay on top of all of these rules and regulations is tough enough, but enforcing them is even more difficult.\nIn the digital world, everything is done electronically and more people are using online tools to manage everything from corporate documents to their own credit card and travel information. This means that a great deal of personal and private information is stored within a company and that the company is responsible for the security of this information. To properly secure and manage this information IT organizations have purchased a wide variety of technologies, which only makes managing the information more challenging. IT management disciplines are colliding (see figure), and it’s time to straighten them out.\nDue to litigation and inadvertent personal privacy disclosures, companies have found that the most difficult challenge is knowing where their information and its copies are and finding the information when they are asked for it. Solving this problem starts with knowing more about the information in your environment.\nIdentify the types of information\nThe first step is to break down any barriers between IT and the lines of business, especially the records managers. There is no reason to reinvent the wheel; the records managers already have processes in place. They already know what assets are typically created in the corporation, how these assets affect the business (including legal implications), and how the assets need to be managed (at least physical documents). Translating this information into the digital world should be a fairly simple process.\nIn the digital world you may want to take some extra steps. For example, perform an assessment of the type of information that is created in your environment. Be sure to look at the different applications in the environment and the information that comes out of them. Look at e-mail, CRM tools, databases, and collaboration tools. Once you understand the applications and how the information that comes from these applications is used, you will be better equipped to make decisions on how to manage the information.\nThe next step is to tie the information to a retention program. Again, records managers can help here because they understand the retention policies for different types of information assets. By working with records managers and informing them of the different digital information assets that are created, they will be able to tell you how long the information needs to be retained, the manner in which the information needs to be retained (e.g., online, nearline, offline), how the information needs to be protected, and how the information needs to be disposed of. And don’t be alarmed: Retention schedules and asset types may sound daunting; however, when you break it down, you probably only need between 4 and 10 asset types. The next task is to tie these to a retention schedule, either via legislation, good corporate governance, or IT best practices.\nThe last thing to take into consideration is information management best practices the corporation may want-or need-to adhere to. This would include recovery time objective (RTO) and recovery point objective (RPO), as well as business continuity and disaster-recovery practices. This is the basis of the process used to manage information.\nCapture and classify information\nUnderstanding the types of information created and how they should be managed is the first step. The next step is to efficiently capture and classify the information.\nInformation can be captured in a number of ways. For example, archiving tools can capture information as it is stored and create a secondary copy. However, capturing the information is only half the battle; classifying the information is the other challenge.\nIt is important to create a classification schema for the information in your environment. For example, information that needs to be retained for legal purposes needs to follow certain criteria. Most of the information needs to be stored securely, with audit trails to prove its authenticity. In addition, information needs to be discoverable and auditable. The main objective behind classifying digital information is to add metadata tags to the files to properly categorize and store the information.\nProtect the information\nInformation protection comes in a variety of forms. The objective is to protect the right class of information using the right tools and processes so that it can be recovered quickly, efficiently, and inexpensively. Keep in mind that backups are only point-in-time snapshots of your information. Backups are good for system-level recoveries, but may miss information that needs to be captured throughout the day. Archiving tools have the ability to capture all information, but you may not need to capture all the information created in your environment. The objective is to not make too many additional copies of information in the process of trying to protect it. Putting the same information on multiple disk drives and/or tapes is costly and makes it difficult to find and dispose of every copy.\nAccessibility and disposition\nProper access controls are essential to ensure information authenticity and security. Information that is protected or archived should be accessed only by the proper individuals. Original copies of information can be viewed, reviewed, and modified by the “owner” of the information or their supervisors. Information that is protected for compliance or corporate governance needs to be tamperproof and have very limited access.\nInformation access deals with who has access and how intruders may gain access to information. For example, is it possible for someone to grab a box of tapes and then have access to the information on the tapes?\nThis brings up the issue of encryption. Ensuring that people outside the “need-to-know” group cannot access information goes a long way to protecting your corporation and your customers.\nThe final component to ILM is what to do at the end of the information life cycle. For information that is compliance-driven, disposition is particularly important.\nYou have to ensure that every copy-no matter where it is stored (tape or disk)-is disposed of properly. Some regulations also control how the information is disposed of. While disposition may be a small part of the process, it is key to controlling storage costs.\nILM = process\nVendors are good at selling technologies that address ILM, but the key component they leave out is the process. ILM is more than just a storage issue and is often driven by compliance.\nHaving the proper access to your information, quickly and efficiently, allows you to get information in the hands of the people who need it. This ranges from finding a contract that a user has lost and ensuring they are up and running and not wasting valuable company time finding and retrieving information, to getting information in the hands of general counsel to ensure your company stays out of trouble.\nOnce you have developed a process around these steps, the right information assets will be on the right storage assets at the right time. And if you are audited, having a good process will ensure you are less vulnerable. Finally, you will save on your storage costs, and when it is time to find a piece of information, you will be able to-quickly and easily.\nSteve Kenniston is a technology partner with the Ridge Partners LLC storage consulting firm. He can be contacted at firstname.lastname@example.org.']	['<urn:uuid:ee34fb62-fba0-4133-8ebd-e35a39b2c876>']	open-ended	direct	long-search-query	distant-from-document	single-doc	novice	2025-05-12T22:49:38.933606	12	86	1528
13	What storage requirements and limitations affect clay usage?	Clay requires specific storage conditions to maintain its properties. It should be kept in tightly sealed bags to retain moisture, preferably in a dark, frost-free place. While clay is cheaper to buy in large quantities, storage space is a main limiting factor in purchase amount. For finished clay products, particularly earthenware, terracotta, and stoneware planters, they must be stored indoors through colder seasons to avoid damage from extreme weather. This is especially important for earthenware and terracotta, which can crack or break if frozen due to their water absorption properties.	"['When starting to work with clay you will have a lot questions. Numerous types of clay are sold with different compositions. How are these clays stored and fired? This excerpt from ""Making Pottery You Can Use: Plates that stack, Lids that fit, Spouts that pour and Handles that stay on"" answers those initial queries that can stop you form getting started.\nClay is generally classified into three main categories— earthenware, stoneware, and porcelain—each is defined by the temperature it is fired to and the consequent density and strength of the clay.\nHowever, when you look in your clay catalog you will see lists of clays that have a very wide firing range, enabling them to be fired at earthenware 2,012–2,102ºF (1,100–1,150ºC), middle temperature 2,156–2,228ºF (1,180–1,220ºC), or stoneware 2,228–2,372ºF (1,220–1,300ºC). So how do you choose?\nCHOOSING A CLAY\nHere are some basic questions to ask yourself to help narrow down your options.\nStandard red earthenware clay\nThis choice will be dictated by the firing capability of your kiln. However, be conscious that the higher the temperature, the more expensive it will be, no matter what fuel is used.\nGrogged red earthenware, half-covered in clear glaze\nDo you want to fire in oxidation (electric) or reduction (gas)? Some clays are more suited to reduction firings than others—use the manufacturer’s catalog to guide you to suitable clays for each type.\nLow temperature white body, half transparent-glazed\nBase your choice on the surface decoration to be applied. Red bodies will influence glaze color response. If you seek a contrast between clay and glaze color, this can be overcome by applying a light slip background. Alternatively, if you want a vibrant color response, choose a white clay and you will not need to apply a slip as a base. Alternatively, there are clays that have additions that give them a speckled appearance when fired. The speckles react with the glaze to produce a very distinctive surface. Manufacturers often suggest glazes that work well with this type of clay.\nBuff stoneware, one quarter transparent-glazed, one quarter tin-glazed\nThe making method will influence the type of clay you choose. For throwing, use a smooth, plastic clay. Hand-building clays benefit from the addition of some grog, which gives increased resistance to warping and cracking. However, be aware that fine detailing or turning can be compromised as a result, adding yet another factor to be considered.\nSmooth white stoneware, half transparent-glazed\nMost catalogs have a suitability code to help you decide. It may read something like this:\n• Clays good for domestic ware\n• Clays suitable for larger domestic ware\n• Clays suitable for big pots—bread crocks, etc.\n• Clays for general-purpose use— throwing, slabbing, coiling, etc.\n• Especially good for throwing\n• Especially good for slabbing and hand building\n• Clays for larger constructions and tiles needing good warp resistance\nHere is an example scenario: “I want to fire to earthenware temperatures, in my electric kiln, using a white body, which will form a great backdrop for color decoration on my handbuilt ware.” From here, you would check the suitability chart and note all the clays that meet your needs. There will probably be fired examples for you to look at\nStandard porcelain, half transparent-glazed\nHaving chosen your clay, you will then need to decide how much to buy. This will depend on your intended output and the way you work. Throwers generally get through clay much quicker than hand builders because the process is faster. In contrast, hand builders can make a few bags of clay last quite a long time, especially if they reclaim all their scraps.\nOne of the main factors dictating the quantity of your purchase will be storage space. You will find that clay is generally cheaper to buy in large quantities. But, if you have not tested the clay, resist the temptation to do this. First ask for a sample and test it to check that it meets your requirements—then buy in quantities that you can practically store.\nKeep clay in tightly sealed bags to retain moisture, preferably in a dark, frost-free place.\nFor more clay advice and projects, check out: ""Making Pottery You Can Use: Plates that stack, Lids that fit, Spouts that pour, Handles that stay on.""', 'Clay Planters ~ earthenware, stoneware & terracotta planters\nShopping for clay planters can be a confusing task. You will find clay pots referred to as terracotta or stoneware or earthenware and ceramic. There are distinct differences between each type that are very important to know when choosing planters for your outdoor decor.\nClay is the raw material of all ceramics, derived from a decomposed rock similar to granite. In its natural state, clay is soft when wet, crusty and brittle when dry. When baked in a high-temperature oven it becomes hard and strong. It is after this firing process that differences among various types of clay become most apparent.\nClay that has been fired (baked in a special oven called a ‘kiln’) to a temperature between 2050 – 2400 will ‘vitrify’—or become impervious to water. At this high temperature, the clay cells have bonded together like glass to prevent absorption of water.\nA second characteristic that varies, is whether or not the clay pot is glazed or not glazed. This is not always as obvious as you might think. While a glassy surface is a sure sign a piece is glazed, some glazes that are transparent and not glossy can be difficult to detect on certain clays. In addition, some pottery manufacturers use a silicone coating which can act like a glaze, but is not ‘fired’ on the pot.\nLet’s explore the differences so you can make the best selection when purchasing clay planters.\nThe term earthenware refers to clay pottery that has been fired to a relatively low temperature (1740 – 2100° Fahrenheit). It remains porous and permeable, so it will still absorb water if not glazed. Earthenware planters absorb moisture from the potting soil, so they must be carefully monitored in hot weather to ensure they do not dry out. It is also a good idea to pre-soak unglazed earthenware prior to planting.\nEarthenware may be glazed or unglazed, and is usually, but not always, buff, red, or brown in color. Red earthenware is a clay given its color by the presence of iron oxide. Earthenware planters are often glazed only on the outside, leaving the inside and bottom unglazed. Check your earthenware planters carefully before planting to identify how much water they will absorb.\nEarthenware is also relatively soft and easily broken. Because earthenware can absorb water, it will crack or break if it freezes. Store your earthenware clay planters out of extreme weather to avoid damage from the cold.\nTerracotta is earthenware made from a clay with a high iron content, which give it a characteristic reddish cast. Terracotta planters are typically not glazed, but new manufacturers are adding a silcone coating to seal the terracotta clay to reduce water absorption and damage from cold weather.\nTerracotta has been used to create containers, statues and tiles dating probably from 3000 BC. It was likely the accidental dropping of a hand-formed clay piece into a fire was the first piece of terracotta as we know it. Terracotta was very popular in Italy and Greece in the production of pots and containers for plants. Artisans carved intricate patterns and decorative elements in clay before firing to create the ornate terracotta urns and planters we love in our gardens today.\nNatural salts within the terracotta clay may gradually seep through the clay to the exterior surface creating a whitish dust finish (often seen on plain terracotta pottery). This is quite normal and all terracotta must “breathe”. If undesired you can simply wash away the salts or allow the rain to do the job!\nImpruneta terracotta planters from Italy are considered one among the best terracotta planters available.\nStoneware, is noticeably stronger, and usually also heavier than earthenware. Fired at higher temperatures than earthenware, it is typically glazed with a glassy color glaze and often given a decorative design or pattern.\nAlthough stoneware is stronger and more durable than earthenware, it is still fragile and stoneware clay planters must be handled carefully to avoid chipping or breaking. Glazed stoneware may also be damaged in extremely cold weather if the glaze is not completely bonded to the clay. As with most earthenware and terracotta planters, it is best to store stoneware and ceramic planters indoors through the colder season.']"	['<urn:uuid:b1b5da57-3da3-4070-9b92-ff16d224532f>', '<urn:uuid:8020d0b4-32ac-436c-b216-bb194af07fb4>']	open-ended	direct	concise-and-natural	distant-from-document	multi-aspect	expert	2025-05-12T22:49:38.933606	8	90	1415
14	How does this groundbreaking viral therapy compare to existing virus-based cancer treatments that have been previously approved?	This treatment, RP2, is described as a 'souped-up version' of T-Vec, a cold-virus-based therapy that the NHS approved for advanced skin cancer a few years ago. The new therapy has additional modifications to the virus so that when it enters cancer cells, it effectively signs their death warrant. Scientists have known about viruses' potential to treat cancer for 100 years, but it has been challenging to harness them safely and effectively.	"['By Michelle Roberts\nDigital wellness editor\nA caller benignant of crab therapy that uses a communal microorganism to infect and destruct harmful cells is showing large committedness successful aboriginal quality trials, accidental UK scientists.\nOne patient\'s crab vanished, portion others saw their tumours shrink.\nThe cause is simply a weakened signifier of the acold sore microorganism - herpes simplex - that has been modified to termination tumours.\nLarger and longer studies volition beryllium needed, but experts accidental the injection mightiness yet connection a lifeline to much radical with precocious cancers.\nKrzysztof Wojkowski, a 39-year-old builder from westbound London, is 1 of the patients who took portion successful the ongoing signifier 1 information trial, tally by the Institute of Cancer Research astatine the Royal Marsden NHS Foundation Trust.\nHe was diagnosed successful 2017 with crab of the salivary glands, adjacent the mouth. Despite country and different treatments astatine the time, his crab continued to grow.\n""I was told determination was nary options near for maine and I was receiving end-of-life care. It was devastating, truthful it was unthinkable to beryllium fixed the accidental to articulation the trial.""\nA abbreviated people of the microorganism therapy - which is simply a specially modified mentation of the herpes microorganism which usually causes acold sores - appears to person cleared his cancer.\n""I had injections each 2 weeks for 5 weeks which wholly eradicated my cancer. I\'ve been cancer-free for 2 years now.""\nThe injections, fixed straight into the tumour, attacks crab successful 2 ways - by invading the cancerous cells and making them burst, and by activating the immune system.\nAbout 40 patients person tried the attraction arsenic portion of the trial. Some were fixed the microorganism injection, called RP2, connected its own. Others besides received different crab cause - called nivolumab - arsenic well.\nThe findings, presented astatine a medical league successful Paris, France, show:\n- Three retired of 9 patients fixed RP2 only, which included Krzysztof, saw their tumours shrink\n- Seven retired of 30 who had combined attraction besides appeared to payment\n- Side effects, specified arsenic tiredness, were mostly mild\nLead researcher Prof Kevin Harrington told the BBC the attraction responses seen were ""truly impressive"" crossed a scope of precocious cancers, including crab of the gullet (oesophagus) and a uncommon benignant of oculus cancer.\n""It is uncommon to spot specified bully effect rates successful aboriginal signifier objective trials, arsenic their superior purpose is to trial attraction safety, and they impact patients with precise precocious cancers for whom existent treatments person stopped working,"" helium said.\n""I americium keen to spot if we proceed to spot benefits arsenic we dainty accrued numbers of patients.""\nIt is not the archetypal clip scientists person utilized a microorganism to combat cancer. The NHS approved a cold-virus-based therapy, called T-Vec, for precocious tegument crab a fewer years ago.\nProf Harrington calls RP2 a souped-up mentation of T-Vec.\n""It\'s had different modifications to the microorganism truthful that erstwhile it gets into crab cells it efficaciously signs their decease warrant.""\nDr Marianne Baker, from Cancer Research UK, said the encouraging findings mightiness alteration the people of crab treatment.\n""Scientists discovered that viruses could assistance to dainty crab 100 years ago, but it\'s been challenging to harness them safely and effectively.\n""This caller viral therapy shows committedness successful a small-scale aboriginal proceedings - present we request much studies to find retired however good it works.\n""Research suggests that combining aggregate treatments is simply a almighty strategy, and microorganism therapies similar this 1 could go a portion of our toolkit for beating cancer.""\nRelated Internet Links\nThe BBC is not liable for the contented of outer sites.']"	['<urn:uuid:c0e8ad74-f0c5-44b6-8aea-a29b64b3bc54>']	open-ended	direct	verbose-and-natural	distant-from-document	single-doc	expert	2025-05-12T22:49:38.933606	17	71	607
15	runoff pollution control methods urban landscapes agricultural areas differences similarities	Both urban and agricultural landscapes require comprehensive approaches to control runoff pollution, but with different specific methods. In urban areas, treatment trains include raingardens, infiltration trenches, treatment swales and detention basins to slow water volume and improve quality. Agricultural landscapes use different combinations like perennial crops, conservation tillage, conservation drainage, cover crops, buffer strips, and wetland restoration. Despite these differences, both approaches share the common goal of treating water close to where it falls to prevent pollutants from reaching water bodies. Both settings also emphasize the use of multiple coordinated practices (treatment trains) and focus on reducing soil erosion, managing nutrients, and promoting infiltration rather than runoff.	"['Basic Information about Nonpoint Source (NPS) Pollution\nNPS pollution generally results from land runoff, precipitation, atmospheric deposition, drainage, seepage or hydrologic modification. NPS pollution, unlike pollution from industrial and sewage treatment plants, comes from many diffuse sources. NPS pollution is caused by rainfall or snowmelt moving over and through the ground. As the runoff moves, it picks up and carries away natural and human-made pollutants, finally depositing them into lakes, rivers, wetlands, coastal waters and ground waters.\n- Excess fertilizers, herbicides and insecticides from agricultural lands and residential areas\n- Oil, grease and toxic chemicals from urban runoff and energy production\n- Sediment from improperly managed construction sites, crop and forest lands, and eroding streambanks\n- Salt from irrigation practices and acid drainage from abandoned mines\n- Bacteria and nutrients from livestock, pet wastes and faulty septic systems\n- Atmospheric deposition and hydromodification\nStates report that nonpoint source pollution is the leading remaining cause of water quality problems. The effects of nonpoint source pollutants on specific waters vary and may not always be fully assessed. However, we know that these pollutants have harmful effects on drinking water supplies, recreation, fisheries and wildlife.\nThe term ""nonpoint source"" is defined to mean any source of water pollution that does not meet the legal definition of ""point source"" in section 502(14) of the Clean Water Act:\nThe term ""point source"" means any discernible, confined and discrete conveyance, including but not limited to any pipe, ditch, channel, tunnel, conduit, well, discrete fissure, container, rolling stock, concentrated animal feeding operation, or vessel or other floating craft, from which pollutants are or may be discharged. This term does not include agricultural storm water discharges and return flows from irrigated agriculture.\nWhat You Can Do to Prevent Nonpoint Source (NPS) Pollution\n- Keep litter, pet wastes, leaves and debris out of street gutters and storm drains—these outlets drain directly to lake, streams, rivers and wetlands.\n- Apply lawn and garden chemicals sparingly and according to directions.\n- Dispose of used oil, antifreeze, paints and other household chemicals properly—not in storm sewers or drains. If your community does not already have a program for collecting household hazardous wastes, ask your local government to establish one.\n- Clean up spilled brake fluid, oil, grease and antifreeze. Do not hose them into the street where they can eventually reach local streams and lakes.\n- Control soil erosion on your property by planting ground cover and stabilizing erosion-prone areas.\n- Encourage local government officials to develop construction erosion and sediment control ordinances in your community.\n- Have your septic system inspected and pumped, at a minimum every three to five years, so that it operates properly.\n- Purchase household detergents and cleaners that are low in phosphorous to reduce the amount of nutrients discharged into our lakes, streams and coastal waters.\n- Become involved in local mining issues by voicing your concerns about acid mine drainage and reclamation projects in your area.\n- Use proper logging and erosion control practices on your forest lands by ensuring proper construction, maintenance, and closure of logging roads and skid trails.\n- Report questionable logging practices to state and federal forestry and state water quality agencies.\n- Manage animal manures to minimize losses to surface water and ground water.\n- Reduce soil erosion and nturient loss by using appropriate conservation practice systems and other applicable best management practices.\n- Use planned grazing systems on pasture and rangeland.\n- Dispose of pesticides, containers, and tank rinsate in an approved manner.\n- Work with conservation partners locally including Soil and Water Conservation Districts to understand local strategies.\nCurrent Fact Sheets about Runoff and NPS Pollution\nYou may need a PDF reader to view some of the files on this page. See EPA’s About PDF page to learn more.\n- Protecting Water Quality from Agricultural Runoff (PDF) (2 pp, 12 K) This is a fact sheet about how agricultural runoff affects water quality (March 2005, EPA 841-F-05-001).\n- Protecting Water Quality from Urban Runoff (PDF) (2 pp, 13 K) This is a fact sheet about how urban runoff affects water quality (February 2003, EPA 841-F-03-003).\n- Brochure: ""After the Storm"" (PDF) (4 pp, 14 K) This brochure provides a broad overview of stormwater pollution, including runoff from residential and commercial properties, farms, construction sites, automotive facilities, forestry operations and others (January 2003, EPA 833-B-03-002).\n- Bookmark: ""10 Things That You Can Do to Prevent Stormwater Runoff Pollution"" (PDF) (2 pp, 14 K) This handy bookmark lists 10 simple things anyone can do to prevent stormwater pollution (February 2003, EPA 841-H-03-003).\n- Stormwater Management at the EPA Headquarters Office Complex (PDF) (4 pp, 10 K) This page highlights the Ariel Rios South Building Courtyard demonstration project at the EPA Headquarters complex that incorporates environmentally sound building and landscaping techniques.\nNPS Pollution Pointers (Legacy Fact Sheets from 1996)\n- Pointer No. 1: Nonpoint Source Pollution: The Nation\'s Largest Water Quality Problem (PDF) (2 pp, 96 K)This fact sheet provides background information on nonpoint source pollution (EPA 841-F-96-004A).\n- Pointer No. 2: Opportunities for Public Involvement in Nonpoint Source Control (PDF) (2 pp, 96 K)This fact sheet provides information on the ways the public can help control nonpoint source pollution (EPA 841-F-96-004B).\n- Pointer No. 3: Programs for Nonpoint Source Control (PDF) (2 pp, 96 K)This fact sheet lists the federal programs that address nonpoint source pollution (EPA 841-F-96-004C).\n- Pointer No. 4: The Nonpoint Source Management Program (PDF)(2 pp, 96 K) This fact sheet provides background on Section 319 of the Clean Water Act (EPA 841-F-96-004D).\n- Pointer No. 5: Protecting Coastal Waters from Nonpoint Source Pollution (PDF) (2 pp, 96 K) This fact sheet provides information on nonpoint source pollution’s impact on coastal areas and the federal actions that have been taken to address this issue (EPA 841-F-96-004E).\n- Pointer No. 6: Managing Nonpoint Source Pollution from Agriculture (PDF)(2 pp, 108 K) This fact sheet addresses the impact of agricultural practices on nonpoint source pollution and the positive steps that can be taken to reduce agriculture’s impact (EPA 841-F-96-004F).\n- Pointer No. 7: Managing Urban Runoff (PDF)(2 pp, 96 K) This fact sheet addresses the impact of urban runoff on waterway health (EPA 841-F-96-004G).\n- Pointer No. 8: Managing Nonpoint Source Pollution from Forestry (PDF) (2 pp, 96 K) This fact sheet addresses the impact of forestry practices on nonpoint source pollution and positive steps that can be taken to reduce forestry’s impact (EPA 841-F-96-004H).\n- Pointer No. 9: Managing Nonpoint Source Pollution from Boating and Marinas (PDF)(2 pp, 96 K) This fact sheet addresses the impact of boating and marinas on nonpoint source pollution and positive steps that can be taken to reduce their impact (EPA 841-F-96-004I).\n- Pointer No. 10: Managing Nonpoint Source Pollution from Households (PDF) (2 pp, 96 K) This fact sheet describes ways a homeowner can reduce nonpoint source runoff from their property (EPA 841-F-96-004J).\n- Pointer No. 11: Managing Wetlands to Control Nonpoint Source Pollution (PDF) (2 pp, 96 K) This fact sheet provides information on the importance of wetlands in preventing nonpoint source pollution from degrading water quality (EPA 841-F-96-004K).', ""Water planning within Minnesota and nationwide has been evolving to emphasize integrated water resources management at a watershed scale to solve soil and water resource issues. Issues related to water planning are wide-ranging and vary between watersheds, including urban stormwater management, agricultural water quality, subsurface sewage treatment, land use practices, plant community management, construction practices and climate change impacts.\nMany types of water planning have been conducted in Minnesota at different levels of government, including watershed district management plans and watershed management organization plans, counties, and other local and regional partners.\nPlanning Methods and Programs\nOne Watershed, One Plan\nOne Watershed, One Plan (1W1P) is a BWSR program that supports partnerships of local governments in developing prioritized, targeted, and measurable implementation plans. Key principles are planning at the major watershed scale and aligning local plans with state strategies. Plans created through the 1W1P program are called comprehensive watershed management plans and are described in §103B.801.\nCounty Comprehensive Local Water Management Planning:\nCounties with their planning and land-use authorities, are uniquely positioned to link many land-use decisions with local goals for surface and groundwater protection and management. Through the Comprehensive Local Water Management Act, counties are encouraged to make this link through the development and implementation of comprehensive local water management plans (county water plans). BWSR's role in local planning is to ensure that county water plans are prepared and coordinated with existing local, and state efforts; and that plans are implemented effectively. BWSR fulfills this role through Board review and approval of the plans while BWSR staff provide overall program guidance, process related grants, and provide plan review and comments. All parts of Minnesota have state-approved and locally-adopted county water plans in place. However, water management in Minnesota has been evolving towards watershed-based, rather than jurisdictionally-based water plans (i.e., One Watershed, One Plan (pdf)).\nThe Nonpoint Priority Funding Plan (NPFP):\nIn 2013, the Minnesota Legislature passed a law requiring the Board of Water and Soil Resources (BWSR) to prepare and post on its website a Nonpoint Priority Funding Plan (pdf) to prioritize potential nonpoint restoration and protection actions based on available Watershed Restoration and Protection Strategies (WRAPS), Total Maximum Daily Load (TMDL) plans and local water plans. The Nonpoint Priority Funding Plan is a criteria-based, systematic process to prioritize Clean Water Fund (CWF) nonpoint implementation investments.\nMinimal Impact Design Standards (MIDS):\nState agencies are focusing on using low impact design, and volume control best management practices (BMPs) to address issues related to large storm events. Impervious surfaces are increasing faster than population growth. This increase in impervious surface coupled with larger storm events will have a significant impact on receiving waters. Minimal Impact Design Standards (MIDS) are being used to increase infiltration and reduce runoff (including green infrastructure like rain gardens, urban forestry/trees, pervious pavement, swales, etc.). These practices are now focusing on volume control in addition to pollutant and rate control. Volume control, and working to mimic natural hydrology helps to result in less dramatic runoff events, which reduces stream erosion and scouring.\nMinnesota Hydrogeology Atlas:\nThe Minnesota Department of Natural Resources (MN DNR), Ecological and Water Resources Division’s Minnesota Hydrogeology Atlas (MHA) is a series of statewide, county, and regional maps and reports that can be used by government agencies in planning efforts to protect and preserve groundwater, to provide information for water appropriations permitting, for source water protection and well sealing programs, and for emergency response to contaminant releases. The MHA expands, compiles, and updates data developed by the County Geologic Atlas Program (CGA) providing more accessibility to information such as regional water pollution sensitivity to bedrock surface and near-surface materials, depth to water table, and water table elevation. The MHA includes a user’s guide, and lists training contacts and funding sources. Numerous links present users with a variety of state and national resources to assist in planning efforts including the DNR’s Watershed Health Assessment Framework, the USDA Web Soil Survey, and the Minnesota Geospatial Commons.\nMinnesota State Hazard Mitigation Plan:\nThe State Hazard Mitigation Plan, updated in 2019 by the Minnesota Division of Public Safety Department of Homeland Security and Emergency Management (HSEM), provides unified guidance to reduce and/or prevent injury and ensure coordination of recovery-related hazard mitigation efforts following major hazard events. The State’s 20 major hazards are identified, including flooding, drought, and ground and surface water supply contamination as they relate to geographic and demographic characteristics, development trends, and climate change. Local governments can use the county by county assessment of mitigation goals, strategies, actions, and initiatives to develop and update their plans. The plan provides information and resources on ranking and criteria for hazard identification, and determining steps to declare an emergency. Resources include a listing of agencies and organizations that may assist with mitigation efforts, and an inventory and brief descriptions of funding programs including the Hazard Mitigation Grant Program. Hazard mitigation success stories are also listed.\n1) Sustainable Regional and Urban Planning. Urban and regional planning that considers protection of natural areas, development of green infrastructure, and minimization of impervious areas during development and re-development can help to treat both water quality and quantity though a variety of practices.\n2) Protecting and Restoring Natural Areas. Protecting and restoring diverse natural habitats provides multiple benefits including water quality protection for groundwater and surface water, stable plant composition to resist invasive species, protect pollinator populations, preserved and improved wildlife habitat, and resiliency to weather extremes. For water planning it is recommended to identify high priority natural habitats including wildlife and water quality complexes and corridors, and promote a combination of agricultural BMPs, buffer programs, conservation plantings, wetland projects and riparian activities that will protect, restore and link water quality and habitat corridors. Minnesota’s Wildlife Action Plan and Prairie Conservation Plan are resources that can be used to aid planning efforts.\n3) Riparian Management. Protecting and restoring riparian areas, including adjacent floodplains brings multiple benefits by reducing soil erosion, increasing stream channel stability, decreasing phosphorus and nitrogen loading, flood attenuation, improving wildlife habitat and wetland functions. Water plans should identify high priority areas for riparian buffer easements, riparian erosion and sediment reduction, wetland restoration and other water storage and nutrient treatment opportunities, and target implementation efforts in those areas.\n4) Treating Water Close to Where it Falls. Higher amounts of rainfall from storm events in recent years increases the need to capture precipitation as close to where it falls as possible; prior to flowing into streams, lakes, and rivers and contributing to erosion and flooding. Stormwater runoff also transports high concentrations of pollutants into water bodies, causing impairment. To reduce these impacts, best management practice methods like cover crops, detention basins, vegetated swales, catch basins, infiltration basins, infiltration trenches, bioretention cells, grass swales, buffer strips, green roofs, etc. can improve water quality.\n5) Using Water Treatment Trains in Agricultural Landscapes. In agricultural landscapes it is beneficial to implement combinations of best management practices that promote soil health and the ability of soils to capture and store rainfall, and store carbon. Examples of key practices for agricultural areas include perennial crops, conservation tillage, conservation drainage, cover crops, buffer strips, and wetland restoration to manage water resources. These practices reduce runoff, recharge groundwater, maintain agricultural productivity, improve water quality, and 9educe flooding.\n6) Using Stormwater Treatment Trains in Urban Landscapes. In urban areas it is beneficial to implement combinations of practices to slow water volume and improve water quality. Practices in urban areas that are commonly combined include raingardens, infiltration trenches, treatment swales and detention basins.\n7) Strategic Site Selection. Water quality practices should be located where they will have the greatest landscape benefits to maximize the value of conservation funding. The Nonpoint Priority Funding Plan (pdf) (NPFP) helps to prioritize potential nonpoint restoration and protection actions based on available Watershed Restoration and Protection Strategies (WRAPS), Total Maximum Daily Load (TMDL) plans and local water plans.\n8) Nutrient Management. Detailed Nutrient Management Plans play a key role as an operational practice along with conservation practices in protecting water bodies from nutrients in agricultural areas.\n9) Wetland Protection and Restoration. Wetland protection and restoration provides benefits for water quality, peak flow reduction, habitat and wildlife. Water plans should support the continued implementation of the Wetland Conservation Act and look for opportunities to improve coordination across jurisdictional boundaries. The plan should also identify high priority areas for wetland restoration and strategically target restoration projects to those areas. The Restorable Wetlands Prioritization Tool is one resource that can be used to help identify areas for wetland restoration.\n10) Protecting Groundwater. It is important to identify priority areas for drinking water/groundwater planning, and management such as source water protection areas, groundwater management areas, and areas of groundwater/surface water interaction; or concerns about groundwater overuse or contamination that need to be addressed in plans. Ineffective septic systems and subsurface treatment practices are also important considerations.\n11) Sustainable Forest Management. Protecting the health of forests by sustainable forestry practices and control of invasive species can maintain the health of forest soils and plant communities that promote the infiltration and filtering of water before it reaches streams, rivers, lakes and wetlands. Long-range forest management plans are an important tool for maintaining healthy forests.\n12) Minimizing Landscape Stressors. Investigate opportunities to improve environmental conditions throughout watersheds to decrease environmental stressors such as flooding, water level fluctuations, sedimentation, environmental pollutants, decreasing water tables, or invasive species that can significantly detract from key ecological functions into the future.\n13) Increasing Perennial Vegetation. Areas of plant diversity supports wildlife species and increases resiliency by helping plant communities function as intact ecological systems during climate variation. Planting native species also prevents the establishment of invasive species. Diverse state seed mixes are available for a variety of project types and the Minnesota Wetland Restoration Guide summarizes restoration strategies for uplands and wetlands. The MPCA publication Plants for Stormwater Design summarizes environmental tolerances of native vegetation.\n14) Preserving and Restoring Soil Health. The use of cover crops and perennial vegetation is recommended to promote good soil structure, organic content and microorganism populations that promote healthy soils and sustain productive ecological and agricultural landscapes. Maintaining more vegetation more of the time increases evapotranspiration during the spring and fall seasons, reduces runoff and erosion and helps recycle nutrients. Root systems increase organic matter in the soil profile, which increases infiltration and water holding capacity for plant available water, and also reduces runoff, erosion and nutrient transport.\n15) Adapting to Climate Change. A major climate trend in Minnesota has been an increase in intense rainfall events that stress aquatic systems, cause erosion, and transport sediment and nutrients. Partners that are working on water plans should consider the potential for more extreme weather events and the implication for water and land resources. BWSR’s Climate Change Trends and Action Plan (pdf) provides details about climate change adaptation for conservation and protection of natural resources. All of the strategies summarized in this Toolbox play a role in climate adaptation efforts. In addition to the strategies already summarized related to water planning it is also important that NOAA Atlas 14 rainfall frequency data and good BMP/landscape planning and design practices are used to address larger storm events. It is also important to identify landscape and populations at risk from climate change trends.\n16) Public Engagement. Finding ways to engage landowners in projects within urban or rural communities can be an important way to promote conservation efforts. This can be accomplished though volunteer events, tours or promoting community gatherings where projects are featured. Having landowners speak about the benefits of projects on their property can be an effective method of convincing other landowners to sponsor projects.\n17) Practicing Adaptive Management. Adjust management practices based on monitoring efforts and experience with successes and failures to improve the long-term effectiveness of management practices and resiliency of plant communities. Practices such as prescribed burning, water level management and prescribed grazing and haying may replicate natural disturbances and promote diversity and resiliency. BWSR’s What’s Working webpages summarize strategies that have been successful for conservation professionals.\n18) Disaster Response. Flooding has caused significant damage to private lands and conservation practice infrastructure in Minnesota. Since 2000, BWSR has distributed $53 million in southeast, northeast and northwest Minnesota under the Disaster Recovery Assistance program to install, repair, or rehabilitate erosion and sediment control and water quality and watershed protection projects damaged by flooding. The Division of Homeland Security and Emergency Management (HSEM) also helps Minnesotans prevent, prepare for, respond to and recover from disasters among its other responsibilities. This includes efforts to reduce the risk to people and property from natural and human-caused hazards by developing and implementing long-term mitigation measures that will reduce or eliminate the severe effects of future disasters.""]"	['<urn:uuid:617f41da-8da4-462a-b057-a7f9617ae819>', '<urn:uuid:c9f9f51c-177b-4378-b726-79f2fb338b80>']	open-ended	direct	long-search-query	similar-to-document	multi-aspect	expert	2025-05-12T22:49:38.933606	10	107	3305
16	Can you explain what makes winter tires different from regular tires when it comes to handling snow and slippery roads?	Winter tires have three key features that make them different: 1) They have more aggressive tread patterns and deeper tread depths that help bite into snow and channel snow and water through the treads. 2) They have numerous small slits called 'sipes' that improve traction on ice and hardened snow. 3) They use special rubber compounds that stay softer and more flexible in cold temperatures. While Light Truck/SUV Studless Ice & Snow tires deliver excellent snow and ice traction without studs, they do trade some handling in dry and wet conditions to achieve this performance.	"[""Light Truck / SUV / Summer See Brands with Tire Models\nLight Truck / SUV - Highway All-Season\nTires for pleasing comfort, predictable handling and all-season on-road traction for your crossover, sport utility vehicle or pickup\nThese tires typically feature independent tread blocks and multiple sipes positioned around the tire to combine good on-road (including gravel and dirt roads) poise with foul-weather traction. They are branded with the M+S symbol and capable of providing all-season versatility, including traction in light snow.\nLight Truck / SUV - Highway Rib Summer\nHeavy-duty tires designed to provide on-road traction in dry and wet conditions.\nThese heavy-duty light truck/SUV tires feature rib-type tread designs developed primarily for street and highway use. They emphasize even wear, low noise and good traction on dry and wet roads, but like all summer tires, are not intended to be driven in near-freezing temperatures, through snow or on ice.\n- Bridgestone / Duravis R410\n- Bridgestone / Alenza LX100\n- Bridgestone / Ecopia MPV-1\n- Bridgestone / Dueler DHPA\n- Bridgestone / Dueler D470\n- Bridgestone / Dueler D400\n- Bridgestone / Duravis R624\n- Bridgestone / Playz PX-RV II\n- Bridgestone / Turanza ER30C\n- Bridgestone / Alenza H/L 33\n- Bridgestone / Dueler H/T D850\nLight Truck / SUV - Light Truck/SUV Studless Ice & Snow\nFor drivers wanting to maximize snow and ice traction from their winter / snow tires without the inconvenience of using winter tire studs.\nThese tires were developed to meet challenging winter driving conditions around the world by delivering studded-like snow and ice traction without employing noisy, road-damaging studs. These tires feature pliable tread compounds molded into purposeful tread designs that trade some handling in dry and wet conditions to deliver excellent snow and ice traction. Available in a wide range of standard and heavy-duty sizes for full-size vans, crossover vehicles, sport utility vehicles and pickup trucks.\nMeet severe snow service standards, branded with mountain/snowflake symbol.\nQ-, R-, S-, T- or H-speed rated.\nMust be installed in sets of four.\nLight Truck / SUV - Off-Road Max Traction\nYour off-road challenges include deep mud, loose soil, slippery rock and the toughest trails.\nThese typically oversize tires feature aggressive tread lugs that bite into loose or muddy surfaces to provide maximum traction that helps propel the vehicle through muddy ruts and over slippery rocks. While many are branded with the M+S symbol and some are even pinned to accept optional metal studs to increase ice traction, their typical oversize applications, use of extra-large lugs and the absence of snow-biting sipes often challenges an Off-Road Maximum Traction tire's on-road wintertime traction in slush, packed snow and on ice.\nLight Truck / SUV - On-/Off-Road All-Terrain\nYour on-road and off-road travels include snow-covered roads, as well as gravel, stone, soil and sandy off-road trails.\nThese tires typically have as much capability off the road as they do on the road. They feature multifaceted tread blocks to help deliver traction in any direction on gravel roads and dirt trails, as well as are branded with the M+S symbol indicating their ability to provide all-season versatility, including traction in snow.\nLight Truck / SUV - Commercial\nMost commercial truck tires are specially designed for increased stability and long-distance driving. Moreover, many offer traction performance for all-weather conditions, including rain, snow, ice, and hot & dry roads.\n- Bridgestone / Ecopia NH100 RV\n- Bridgestone / Duravis R623\n- Bridgestone / ECOPIA R214\n- Bridgestone / L607\n- Bridgestone / Ecopia EX20 C\n- Bridgestone / Duravis R660\n- Bridgestone / Regno GR-VII\n- Bridgestone / Duravis Van\n- Bridgestone / Duravis R611\n- Bridgestone / Ecopia R680\n- Bridgestone / 613V\n- Bridgestone / Ecopia RD613\nLight Truck / SUV - Street/Sport Truck Summer\nThese wide, low profile and large rim diameter tires enhance a vehicle's looks and performance when used to replace most Original Equipment tires. They emphasize traction and handling in dry and wet conditions, but like all summer tires, are not intended to be driven in near-freezing temperatures, through snow or on ice.\n- Continental / ContiSportContact 5 SUV\n- Continental / PremiumContact 6 SUV\n- Continental / ContiSportContact 5 SUV SSR\n- Continental / ContiSportContact 5P SUV\n- Continental / UltraContact UC6 SUV\n- Continental / Conti4x4SportContact\n- Continental / CrossContact UHP\n- Continental / ContiPremiumContact 5 SUV\n- Continental / ContiCrossContact UHP SSR"", 'We touched on the differences between various types of tires in Tires – Everything You Need to Know but now we are going to dig further into some details. As always in Canada, winter is coming. Now is as good a time as any to examine the differences between Winter tires and All-Season tires so that you can be prepared for the incoming harsh driving conditions.\n“ALL SEASON” IS A MISLEADING NAME\nThe first thing to understand when discussing All-Season and Winter tires is that All-Season tires are sometimes not good enough for all seasons. This depends on where you live and drive of course. In many parts of the world, All-Season tires are sufficient for driving year-round thanks to moderate climates.\nIn more extreme winter climates, as we experience in much of Canada, All Seasons struggle to perform. Driving your vehicle in winter climates requires traction on snow, ice, and cold temperatures. If you live in a place where these conditions exist it is time to accept that All-Season tires may not be good enough all year round.\nWHAT “ALL SEASON” ACTUALLY MEANS\nWhen you buy a new vehicle, it will most likely come fitted with a set of All-Season tires. This is an easy choice for manufacturers as All-Season tires are the most versatile option by far. They are the ultimate compromise, offering decent performance in a wide variety of conditions while offering a relatively quiet and smooth ride and reasonable tread life.\nAll-Season tires are designed to handle light winter driving conditions. But the snow, ice, and extreme cold of many Canadian climates are far beyond light winter conditions for much of the year.\nAdditional Read: How Tire Sizes Work\nCOMBATING WINTER CONDITIONS\nWhile All-Season tires are designed with versatility in mind they do not have answers for the three main issues that winter conditions bring. Snow, ice, and cold temperatures. All-Season tires struggle with traction in snow and on ice, and this is made worse by cold temperatures that cause the tires to harden, reducing their traction further. Winter tires address each of these problems with unique design features.\nSnow – As mentioned, All-Season tires can handle very light snow, but driving in anything more than a thin layer of snow becomes a challenge. Winter tires address this problem with more aggressive tread patterns and deeper tread depths. This helps the tires bite into the snow, channeling snow and water through the deep treads.\nIce – The tread channels mentioned above are easy to pick out on any set of tires. If we look a little bit closer we can find smaller slits on the surface of the tread. These little slits are called “Sipes” and they are typically found in great numbers on Winter tires. The reason for this is that they improve traction on ice and hardened snow.\nCold Temperatures – A less obvious feature of Winter tires is that they are made with different rubber compounds than All-Season tires. This allows Winter tires to remain softer and more flexible at colder temperatures, which allows the tread features mentioned above to do their jobs properly and provide improved traction.\nWINTER TIRE COMPROMISES\nAs always, for increased specialized performance, there are sacrifices to be made elsewhere. Winter tires excel in snow, ice, and/or colder temperatures, but outside of these conditions, they are not the best option. On dry pavement and warmer temperatures, it is important to remember that Winter tires do not offer the same performance that you may be used to with All-Season tires.\nThey may feel a bit softer, and less predictable at times. You may also notice increased tire noise compared to All Seasons. There will be warmer, dry days that you will need to drive on your Winter tires which is okay in most cases, but under intense braking or steering the tires may not provide All-Season traction.\nWhen Winter is completely over, it is best to get your All-Season tires back on as soon as possible. Due to their softer compounds, Winter tires wear faster than All-Season tires, so the sooner you get them off, the more tread you will have for next winter!\nAdditional Read: Tire Rotations']"	['<urn:uuid:0e42b730-2e3e-4131-8ca0-4dda364a1a1d>', '<urn:uuid:ac9b7859-3074-4abf-8d8d-00ac23bab4dd>']	factoid	direct	verbose-and-natural	distant-from-document	three-doc	novice	2025-05-12T22:49:38.933606	20	95	1429
17	What's the difference between fontange headdress and muslin wrap styles?	A fontange was a linen cap with layers of lace and ribbon worn flat at the back and rising high above the crown, supported by a wire frame. In contrast, the muslin wrap was a simple rectangular cloth tied around the head that could be styled in different ways - either tied at both ends or twisted into a bun shape at the nape of the neck.	"['A linen cap with layers of lace and ribbon, worn flat and pinned to the back of the head.\nDaniel Delis Hill in The History of World Costume and Fashion (2011) writes:\n“The French fontange, or commode as it was called in England, was a small round or oval cap pinned to the back of the head. Attached to the top of the cap was a tall wire frame over which were arranged tiers of lace, ribbons, cutwork, and linen ruffles.” (413)\nIt became popular in the 1680s and was in fashion both in France and in England. Figure 1 presents Queen Mary II of England wearing a fontange headdress.\nThe Dictionary of Fashion History (2010) defines a fontange as:\n“An indoor linen cap with a small, flat crown behind and a tower of lace or lace and linen frills in front, kept erect by the commode, a tall wire frame.” (83)\nCharlotte de Lorraine-Armagnac (Fig. 2) wears an elaborate fontange in a 1695 print portrait.\nAccording to Fashion, Costume, and Culture: Clothing, Headwear, Body Decorations, and Footwear through the Ages:\n“The style enchanted the king and other women began copying the style. At first the style consisted of a small pile of curled hair with ribbons and bows just above the forehead. The fontange eventually grew into a high tower of curls piled over a wire foundation, sometimes with false curls. The style was so often worn with a starched linen frill in the front that the linen cap came to be called a fontange as well.\nThe height of the fontange related to a general trend in the seventeenth century for fashion to emphasize a vertical line. As the fontange grew taller, women had great difficulty securing it on their heads. Then, when finally secured, the fontange often slipped to one side or another. Women found the instability of the fontange so frustrating that many began suggesting that the heads of infant girls should be flattened to better hold the fontange later in life. No evidence of anyone actually doing this exists and the style fell from fashion in the early eighteenth century.”\nStyles of fontange were carefully picked to match the dress they worn. The woman in Figure 3 wears a fontange that coordinates with the color of her dress.\nSusan Brown in Fashion: The Definitive History of Costume and Style (2012) describes the origin of the term:\n“The fontange cap was worn flat at the back of the head, rising up high above the crown in layers of lace and ribbon, often supported by a wire-frame commode. It was named after Madame Fontange, who originated the ribbon style.” (139)\n- Brown, Susan, ed. Fashion: The Definitive History of Costume and Style. New York: DK Publishing, 2012. http://www.worldcat.org/oclc/840417029.\n- Cumming, Valerie, C. Willett Cunnington, Phillis Cunnington, Charles Relly Beard, and C. Willett Cunnington. The Dictionary of Fashion History. Oxford ; New York: Berg, 2010. http://www.worldcat.org/oclc/1008259246.\n- “Fontange.” Wikipedia, July 20, 2018. https://en.wikipedia.org/w/index.php?title=Fontange&oldid=851208620.\n- “Fontange.” In Fashion, Costume, and Culture: Clothing, Headwear, Body Decorations, and Footwear through the Ages, edited by Sara Pendergast and Tom Pendergast, 530-531. Vol. 3, European Culture from the Renaissance to the Modern Era. Detroit: UXL, 2004. Gale Virtual Reference Library (accessed September 25, 2016).Â http://libproxy.fitsuny.edu:2200/ps/i.do?p=GVRL&sw=w&u=fitsuny&v=2.1&it=r&id=GALE%7CCX3425500331&asid=30953f91b80a6600411422d378a05ef6.\n- Hill, Daniel Delis. History of World Costume and Fashion. Upper Saddle River, NJ: Pearson Prentice Hall, 2011. http://www.worldcat.org/oclc/768100950.', ""A Guide to Hairstyles and Hats for Females\nThis guide is for those War of the Roses Re-enactors who wish to get their head gear to match their dress as well as the task in hand. The ideal would be for us all to have long flowing locks that reached past our waists, which could be neatly plaited and coiled onto our heads, with hats placed on top and pinned or tied into place. Yeah right matey! As this is generally just an ideal, we’ve tried to be sympathetic to modern hairstyles as not all of us wish to, or are able to, grow our hair long! There is always the danger of re-enactors fringe by the end of the day; where hair has been scraped back all day under your hat and is now sticking up in a tuft at the front, and nothing short of washing your hair is going to make it sit right!\nFemale re-enactors generally fit into five groups;\n- Children, preteens and teenagers\n- Those dressed for dirty jobs around the camp such as cooking, nursing etc as well as their camp duties.\n- Those more respectable ladies dressed in gowns, dressed for sewing, music etc\n- Minor nobility and above, i.e. those in posh kit\n- Cross-dressed for battle/working with and riding horses\nEach has it’s own style of hair and headdress and it’s quite important to try to get the look right: for an extreme example, a steeple hennin does not look right with a basic kirtle and apron, nor does a simple linen hat go quite right with a court style gown. Hopefully the following guide will give us all ideas as to how to match things up, on new styles and colours, veils etc. Also, when pinning a hat, try to use authentic pins suitable for your status. I’ve also added modern ‘cheats’ that I’ve found help. If you think anything below is wrong or have further information, please contact the group and let us know; we are always willing to learn!\nChildren, preteens and teenagers\nBabies and Toddlers. As babies, children were generally wrapped in swaddling, which included their head. Modern thinking doesn’t necessarily agree with this, and it makes it awkward for changing nappies! Instead, babies are often dressed as toddlers would be, in long shifts and gowns. Obviously this doesn’t cover the head. Illustrations of the time seem to favour coifs, a soft linen bonnet-like cap that fits to the head. This protects the head while the natural fabric lets the skin breath. During the summer a straw hat (preferably with a stiff brim) can be worn over the top, if the little darlings will tolerate it!\nPreteens. In medieval times youngsters were seen as children until the age of eight, when those not being schooled would start working. Girls would generally wear their hair uncovered; unbraided loose long hair was a sign of virginity and purity and highly fashionable. If your youngster has long hair, then leaving it uncovered is fine, hair can be held off the face with a fillet (a type of alice-band) and/or braided.\nIf she is sporting a haircut that finishes above the shoulders then there are a few options; if it’s all one length then leave it uncovered, a child who was ill or had contracted some sort of lice would often have their hair shorn, so the short haircut can be explained this way. The other option is a linen coif on girls under 5, or a copy of the simple linen hoods. (These can also be worn with long hair, although it’s advisable for the hair to be braided underneath). The linen hoods are generally worn with a fillet and come down over the neck, useful for girls with fair skin as it will protect from sunburn and it’s easy to stick a straw hat over the top!\nTeenagers and those over 8 years old. During the medieval period children over the age of 8 were expected to be miniature copies of their elders. If the girl's kit is just a kirtle then a linen cap or hat is suitable, with the hair braided and caught up inside. If she is wearing a gown, then either a linen hat or a truncated hennin is suitable. However, for those not trying to emulate those older than themselves and wanting to go off to play, this isn’t going to work. The hennin inevitably is going to be taken off and lost somewhere! The best bet is to see what the youngster prefers, and again in the summer, straw hats with wide brims are a must!\nIf the lass is older then she’ll probably be as fashion conscious about her medieval kit as her modern clothes. Her standard of dress and the standing of her family around the camp will designate what type of hat is suitable, so the next few groups are her best reference.\nFor all children, travelling hoods are recommended for cold weather and wide brimmed straw hats for sunny weather. These are both mentioned in the next section. On children we recommend sewing bells to the end of a liripipe of a hood or the ribbons of a sun hat… helps locating the little tearaways!\nFor those dressed in kirtles.\nFor those of us who seem to run round the camp all day doing the dirty jobs we don’t want our hair getting in the way, and for the medieval woman there was the added disadvantage of any hair showing was a sign of loose morals. Therefore some type of linen hat is a good idea. There are a number of types that I shall discuss below. Please remember though, loose weave material is semi transparent so short hairstyles are more noticeable, especially if the hair pokes through the fabric, also dyed hair in unnatural colours can be seen, as the colour will show through.\nThe muslin wrap. Muslin is currently a cheap material and made of cotton, though if you can fine linen muslin that would be preferred. The wrap is excellent for any hairstyle as it can be tied in a number of different ways and will cover the hair entirely. You start with a rectangle of muslin, preferably hemmed along the raw edges by hand. The short end of the rectangle must be long enough to fit around your head like a headscarf and tied at the back. From here there are a number of styles.\nTie the other short end the opposite way round your head so the tied ends are above your brow. The loose triangular flappy bits can either be tucked in underneath or pinned attractively to the sides or crown. If you have long hair you can leave it loose to catch in the ‘bag’ and the style is flat enough to plonk a straw hat over the top! If you make the rectangle long enough the ‘bag’ will cover your exposed neck at the back.\nAt the nape of the neck start twisting the excess fabric (and hair if your's is long enough, ensuring it’s completely covered) in a clockwise direction. From here you have a choice of two styles. The first is to twist the fabric over your temple and forehead, back down over the other temple and securing at the nape of the neck by looping round the start of the twist and tying in place. Try not to get this style too tight as it can cause headaches, or twisting it too loosely as it will all come undone. The second is to keep twisting at the back of the neck until the fabric coils up itself and you can’t twist it any further (be careful if you have long hair as this can hurt). Coil the fabric round itself into a bun shape and secure it by tying it on itself or pinning in place.\nThis style also means you can pin linen kerchiefs over the top to make it look more fashionable. If you like this idea it’s wise to experiment with a mirror at home to get the look and feel right. Show a friend or partner when you have the required look, as they may have to help you achieve it when the mirror has gone missing or isn’t big enough!\nLinen kerchiefs. The other option for pinning linen kerchiefs is using a fillet. If you have short hair it is recommended to pin the bottom of the kerchief to the bottom of the fillet, as when you lean over your hair can become exposed. If you have long hair and don’t want it to bother you, use a hair net to keep it up, then you can either leave your hair loose or plait it and tuck it into the net. I’ve cheated on mine and attached the net to the fillet, and I’ve used modern hairnets, the thicker type that can be found in most supermarkets or chemists. If you want to be authentic you could try making your own hair net and attaching it. I’ve found that the net keeps the hair off the back of my neck (great when it’s hot) and it gives you something to pin your kerchief to.\nLinen hats. These need securing to a fillet, otherwise they are likely to fall off! There are a number of simple, effective designs that are quite attractive; such as the extended semi-circle and the unusual one with the flap that is pinned onto the crown, as featured in Sarah Thursfield’s book, the Medieval Tailor’s Assistant. There is also a hood with a liripipe as seen in many continental sources, where the turn back around the face seems to be quite pointed. There are 2 more well known types: the ‘rabbit’s ear’ hat that sports long pieces which hang down the back of the hat and get taken round the front and tied, the ends looking like rabbit’s ears; and the later version where the ears have become thicker and hang down the back of the neck. This style is similar to a later, more upmarket, style and was probably worn well into the early Tudor period. For a later fifteenth century style that was also worn into the Tudor period, a very simple version of the gable head dress can be found in Sarah Thursfield’s book, the Medieval Tailor’s Assistant.\nSimple hoods as a general rule are spot on, but be careful of making one that is from a later period; like one made with a simple band over the forehead and temples, with a gathered circle covering the rest of the hair, and mob caps are definitely not right! There are many illustrations of a turban style headdress. While being absolutely correct, the style is mostly Germanic in origin and was not really worn in Britain, unless by the wife or widow of a travelling merchant. These are easily spotted by the coloured fringing worn at the nape of the neck and are beautifully shown in literature by the Company of St George and Gerry Embleton.\nStraw hats and Travelling Hoods. These things are a godsend and are two of the few unisex pieces clothing. In the height of summer, or even on a very bright day, pop your straw hat on and shield your eyes from the glare and keep the sun from burning your skin. The wider the brim the better. Some authentic designs have unusual shaped crowns that can still be found occasionally. Straw hats can be accessorised, great if you have a large number of hats in one area. Using ribbon (preferably linen, nothing shiny), feathers or thread you can decorate your hat to the style you like. By stitching the ribbon in place you know you’re not going to loose it and brightly coloured ribbon can be used instead of cord or string to keep the hat on your head. If the brim starts to fray, (or even before) you can put some decorative stitching on to keep the edge strong and tidy, if you get a hole in your hat you can always cover it. A prime example is my sun hat that got an arrow through the brim at a siege. Rather than throw it away I covered it with pheasant feathers. Okay, so it’s nickname is the pheasant caught in a tumble dryer but it looks fabulous and everyone recognises it, even if they don’t recognise me!\nTravelling hoods are excellent for evenings and cold weather. Most fashionable with a liripipe, the skirt of the hood coming down over your shoulders is great for keeping that nippy draught off your neck. The liripipe, rather than being tucked in your belt, can be used as a scarf to keep the neck nice and snug. Usually worn with a linen hat or muslin wrap, they can be of any colour, usually fastened with buttons and can be long enough round the face that when done up it protects the face from any side wind by coming past the nose and fastening under the chin. When undone this can be turned back. Hoods can also be trimmed or lined with fur for that extra bit of wind protection. (Hoods are also useful for playing hoodsmans’ blind, an early form of blind man’s buff; a group of you have travelling hoods, one wearing theirs back to front, undone with the liripipe securing it round the neck. The one is spun round a few times and the rest flick them with their hoods. Whoever is caught is the next one to wear it back to front…this is a great game for during the day, especially if there are children to join in. We don’t recommend this game to be played at night, as you never know what you could fall over).\nFor those dressed in gowns\nThere are a number of ways a well-dressed woman can wear her hair and her hat. Contemporary illustrations show us that these women even kept their hair covered while taking a bath, although this maybe to stop them getting their hair wet. Pictures and portraits from the period more readily show the styles of the merchant and middle class families. Hair was generally plucked to expose a high generous forehead with the hair hidden under a hat or hood. Unless the woman in question was a maid, or it was her wedding day, the hair was always covered. There are illustrations of women with their hair uncovered and worked into braids, coils and ropes, but these are mainly of Mediterranean origin. Although the weather is now generally much warmer in the summer than it was in the fifteenth century, we would recommend sticking to northwest European styles from Britain, France, Burgundy and Flanders.\nLinen and Wool Hats. Linen hats as those described above would be worn in the home. A modern day equivalent is slippers, worn inside the home to be comfortable in. Wool hats were very similar in style and shaped into hoods.\nHennins. Truncated henins were very popular throughout the second half of the fifteenth century. A truncated henin looks like an upturned flowerpot. The current theory is the Henin was made of leather formed into a cone (without the point) and the sides laced together. A cover would be made to fit over the top to correspond with your dress. There are contemporary pictures of women visiting shops wearing henins with simple veils over the top. After trying many different fabrics the closest to those shown in the portraits seems to be that of silk voile. Silk chiffon is not transparent enough and the silk voile seems to have the stiffness required for the folds and creases seen in the portraits. Please don’t use modern synthetic fabrics as these have a different sheen to them and can be spotted a mile off. Although the voile is quite expensive, it’s worth splashing out on, it hand washes and irons well and looks so much better.\nIf you feel that you wouldn’t have been able to afford the silk needed for a veil, don’t worry. There are also many pictures and portraits of women not wearing veils. Having worn them, unless you are inside, they do have a tendency to get in the way and catch the slightest breath of wind. It’s very difficult to be ladylike when you’re trying to talk with a mouthful of silk voile that keeps blowing back into your face.""]"	['<urn:uuid:7bae2af1-a06b-4407-ada3-ba147c7d0fbb>', '<urn:uuid:c30aa361-e93b-4db3-b329-cdfe28d9e2ac>']	factoid	direct	concise-and-natural	similar-to-document	comparison	expert	2025-05-12T22:49:38.933606	10	67	3309
18	specialized nutritionist here heart healthy breakfast recommendations environmental impact	For heart health, oatmeal with 2 tablespoons of mixed unsalted nuts is recommended, or 2 eggs with heated mashed kidney beans with olive oil, garlic powder and cheese, or whole wheat toast with 0-1 gram sugar bread. These plant-based breakfast options also contribute to environmental sustainability by requiring less water, energy, and land compared to animal-based alternatives, and produce fewer greenhouse gas emissions.	['- FoodTrients, originated by Grace O, is a cookbook filled with revolutionary recipes based on current research that positions food as an anti-aging strategy for achieving sustainable health. Studies suggest that by consuming the ingredients in FoodTrients, exercising, and managing your weight, you may add as many as 10 to 20 years to your lifespan.\nDo You Know The Healthiest Foods For Your Heart?\nLike many of my patients you may want to do your best for the health of your heart (and the rest of you) and yet may be confused about which foods are the best. You might think that to protect your heart you have to forgo all your favorite foods for a bland and boring diet that you’ll never be able to stick to. As I explain to my patients, that’s just not true. Within reason, you’d be surprised at how much you can reconcile/modify what you really like to eat with what’s healthy for your heart. Here’s how…\nEATING RIGHT FOR YOUR HEART\nHeart disease is the #1 killer of Americans today. Our diets are the biggest contributor to our levels of heart disease through too much saturated fat and refined sugar levels and too little fiber. The following is what I recommend to my patients to modify their diet and make it more heart healthy without foregoing some favorite foods:\n- Limit sugar. The American diet has far too much refined sugar in it, but it also has a high amount of natural sugars in it. High sugar intake, of both types, can cause type 2 diabetes which can then lead to the development of heart disease. I advise my patients to cut out – or way down – on the amount of refined sugar in their foods. I also tell them to limit the amount of natural sugars to not more than 20-25 grams of total sugar intake from fruits, vegetables, and other foods. Read labels. If you’re trying to lose fat, reduce this level to between 15-20 grams sugar per day to help you burn fat reserves.\n- Eat breakfast: One of the best things you can do for your heart (and the rest of you) is to eat breakfast. Oatmeal with 2 tablespoons mixed, unsalted nuts, is a great heart-healthy breakfast food. If you don’t like oatmeal, opt for 2 eggs with heated, mashed white or red kidney beans, with a little olive oil, garlic powder and grated cheese. Delicious and full of fiber. Or, opt for whole wheat toast with 0-1 gram sugar bread.\n- Fish for lunch or dinner: Salmon, sardines, tuna, mackerel, are all good 1 meal a day choices. These confer Omega-3 fatty acids that preventinflammation and decrease LDL cholesterol. Substitute scallops here and there for chicken or beef which are lighter in saturated fat.\n- Healthier Salads: On your salad, opt for 2 tablespoons of flaxseeds or mixed nuts instead of croutons. These lend heart-healthy, cholesterol-lowering fats to your diet without sugar. Watch the salad dressing though as commercial brands can be high in sugar and fat. Instead use red wine vinegar mixed with olive oil, or just plain lemon juice or balsamic vinegar with spices added. Use Greek yogurt instead of sour cream for added calcium and less saturated fat.\n- Healthy snacks/Fiber: Berries (all types, especially blackberries and blueberries) provide necessary antioxidants that boost heart health. Vegetables like cut up cucumbers, carrots, radishes, celery, edamame, all confer vitamins, minerals and protein that the heart thrives on. They also add fiber that sweeps excess cholesterol out of your bowel before it is absorbed into your blood. Aim for 25-30 grams daily. Special movie night treat: homemade air-popped popcorn with near 90% less saturated fat than potato or tortilla chips and twice the fiber. *Note: If you take thyroid medication or have a history of breast cancer, ask your doctor about eating edamame, a soy product.\n- Drink alcohol sensibly: Substitute red wine for mixed, often-sugary drinks that can boost HDL (good cholesterol) levels.\n- Enjoy meat sparingly: You can still eat red meat on a heart-healthy diet, just do so sparingly. Stick to grass fed beef that is much leaner than grain fed and use it more as a side dish to more vegetables and grains like quinoa, rather than the main course. Try ground turkey for burgers or meat loafs.\n- Ban trans-fats: Trans-fats can really wreak havoc with heart vessels. Currently food manufacturers are working to omit or reduce the amount of these in the foods we buy. Until then, read labels and choose products that say 0 trans fats. However, be sure to read the ingredients too as any vegetable oils that have been “hydrogenated” or “partially hydrogenated” are trans-fats. Even if the percentage per serving is less than 1 gram, eating several servings a day can add up to more than a few grams of trans-fats.\n- Limit/ban soda: Regular soda contains large amounts of both sugar and sodium. Diet soda doesn’t contain sugar but still contains a lot of sodium, and likely aspartame, all of which can drive up blood pressure and decrease heart health. Healthier swap: Switch to a diet soda that contains no sodium or aspartame like Diet Rite brand. Still, limit to 1-2 cans a day.\n- Watch sodium: Many canned foods like tuna, beans, and vegetables contain lots of sodium. Sodium drives up blood pressure which puts strain on your heart. You can decrease their sodium level by pouring foods into a colander and rinsing them with cold water to remove excess salt before eating.\n- Stay hydrated: Did you know that many illnesses, including heart disease, can get their start from just being dehydrated? It’s true. Dehydration can have a negative domino effect throughout the entire body and brain. Drink half your weight in water every day.\nEating right for your heart doesn’t have to be diet drudgery. If you stay within the above guidelines, they will go a long way in helping lower your LDL cholesterol, strengthen your vascular system and decrease your risk for heart attack and/or stroke.\nMark Rosenberg, M.D.\nWhat Do FoodTrients Do?', 'Chronic diseases, including heart disease, diabetes, and kidney disease, have been a consistent public health concern across the globe. Recent health studies have suggested that a shift towards a plant-based diet may contribute significantly to reducing the risk and even reversing these conditions. This post explores the interrelation between a plant-based diet and chronic disease prevention and management, providing you with comprehensive information about the benefits of adopting such a dietary approach.\nThe Connection Between Plant-Based Diets and Chronic Disease\nAdopting a plant-based diet is associated with a lower risk of chronic disease. The underlying rationale is the rich presence of nutrients, antioxidants, and fiber in plant foods that can improve health and mitigate disease risk factors.\nHow a Plant-Based Diet Can Reduce the Risk of Chronic Disease\nA plant-based diet, rich in fruits, vegetables, legumes, whole grains, and lean proteins, can help reduce inflammation, a root cause of many chronic diseases. According to a study published in JAMA Network Open, a plant-based diet is associated with lower biomarkers of inflammation and metabolic health.\nVegan and Vegetarian Diets for Disease Prevention\nA vegan or vegetarian diet can be a healthful plant-based diet that significantly reduces the risk of chronic diseases. These diets are high in fiber, vitamins, minerals, and antioxidants that contribute to overall health and wellness. The health outcomes of vegan or vegetarian diets have been correlated with a decreased risk of cardiovascular disease and diabetes.\nHealthful Plant-Based Diets vs. Unhealthful Plant-Based Diets\nThe quality of the plant-based diet also matters. A healthful plant-based diet, abundant in whole foods like fruits, vegetables, whole grains, legumes, nuts, and seeds, is associated with lower risk of chronic diseases. Conversely, an unhealthful plant-based diet, which relies heavily on processed foods and refined sugars, is associated with an increased risk of health problems.\nAssociations Between Diet Quality and Risk for Chronic Disease\nDiet quality significantly influences the risk of chronic disease. A diet rich in high-quality plant-based foods and lower in less healthy plant foods is linked to a lower risk of chronic health conditions, as supported by the National Health and Nutrition Examination Survey.\nPublic Health Recommendations for Chronic Disease Prevention\nThe Centers for Disease Control and other national health organizations recommend a plant-based diet for preventing chronic disease. They encourage a diet containing a variety of fruits, vegetables, lean proteins, and whole grains to support overall health.\nBenefits of Plant-Based Diets for Cardiovascular Health\nPlant-based diets have significant benefits for cardiovascular health. They can lower the risk of coronary artery disease and stroke and have a positive impact on various cardiovascular risk factors.\nLowering the Risk of Coronary Heart Disease with Plant Foods\nA diet abundant in plant foods such as fruits, vegetables, whole grains, and legumes, can significantly lower the risk of coronary heart disease. This is largely due to the high fiber content and low saturated fat in these foods.\nLowering the Risk of Cardiovascular Disease\nSwitching to a plant-based diet can lead to lower LDL cholesterol levels, lower blood pressure, and reduced inflammation, all of which are key risk factors for cardiovascular disease.\nReducing Risk Factors for Ischemic Heart Disease\nA plant-based diet is associated with a reduced risk of ischemic heart disease. This is due to its positive effects on risk factors, including lowering LDL cholesterol levels and improving blood pressure control.\nHow Whole Grains and Plant-Based Foods Can Reduce Heart Disease\nWhole grains and plant-based foods have been linked to lower risks of heart disease. They contain fibers, phytochemicals, and antioxidants that can help lower cholesterol levels and reduce inflammation.\nPlant-Based Diets and Their Impact on Heart Disease and Stroke\nPlant-based diets have been found to reduce the risk of heart disease and stroke, two of the leading causes of death worldwide. This is associated with a lower risk of high blood pressure, high cholesterol, and obesity, all of which are significant risk factors for these conditions.\nPlant-Based Diets and Diabetes Management\nManaging diabetes effectively involves a balanced diet, and plant-based diets can play a significant role in this regard.\nThe Role of a Plant-Based Diet in Type 2 Diabetes Prevention\nA plant-based diet, rich in fiber and with a low glycemic load, can help prevent type 2 diabetes by improving insulin sensitivity and reducing inflammation.\nLow-Fat Vegan Diets for Diabetes Control\nA low-fat vegan diet can help control blood sugar levels and improve insulin function, as shown in numerous studies. These diets can lead to weight loss, which is beneficial for managing diabetes.\nVegan or Vegetarian Diets for Maintaining Healthy Blood Sugar Levels\nA vegan or vegetarian diet, rich in complex carbohydrates and fiber, can help maintain stable blood sugar levels, which is crucial for diabetes management.\nHow a Healthful Plant-Based Diet Can Reduce the Risk of Diabetes Complications\nA healthful plant-based diet rich in whole grains, fruits, vegetables, and lean proteins can help manage blood glucose levels, reduce inflammation, and thus, lower the risk of diabetes complications.\nNational Health Guidelines on Diet and Diabetes Management\nNational health guidelines recommend a diet high in fiber, low in saturated and trans fats, and full of fruits, vegetables, and whole grains for diabetes management. A plant-based diet fits well into these guidelines.\nImproving Kidney Health Through Plant-Based Diets\nFor those with kidney disease, a plant-based diet can provide significant health benefits. It can help control blood pressure and blood sugar levels, reduce inflammation, and slow the progression of the disease.\nBenefits of Plant-Based Diets for Patients with Kidney Disease\nA plant-based diet can help slow the progression of chronic kidney disease by reducing metabolic acidosis, lowering proteinuria, and maintaining adequate nutrition.\nReducing the Risk of Kidney Disease with Plant-Based Foods and Whole Grains\nDiets high in fruits, vegetables, and whole grains, and low in processed foods and animal proteins can help reduce the risk of developing kidney disease.\nPlant-Based Diet Recommendations for Kidney Disease Prevention\nFor kidney disease prevention, health professionals recommend a diet rich in plant-based foods. These diets are low in sodium and rich in fiber, which can help control blood pressure, a key risk factor for kidney disease.\nThe Impact of Unhealthful Plant-Based Diets on Kidney Health\nWhile a healthful plant-based diet can be beneficial for kidney health, an unhealthful plant-based diet, rich in processed foods, can contribute to obesity, high blood pressure, and diabetes, all risk factors for kidney disease.\nRole of Health Sciences Research in Developing Kidney-Friendly Plant-Based Diets\nHealth sciences research has played a crucial role in demonstrating the benefits of a plant-based diet for kidney health. It has highlighted the importance of consuming whole, unprocessed plant foods for optimal kidney health.\nPlanetary Health and the Sustainability of Plant-Based Diets\nBeyond individual health benefits, plant-based diets also have a positive impact on our planet’s health. They contribute significantly to sustainable food systems and have lesser environmental footprints compared to diets rich in animal products.\nEnvironmental Benefits of Adopting a Plant-Based Diet\nA plant-based diet is beneficial for the environment. It requires less water, energy, and land compared to animal-based diets and contributes less to greenhouse gas emissions.\nHow Plant-Based Diets Contribute to Sustainable Food Systems\nPlant-based diets support sustainable food systems by reducing demand for animal agriculture, which is a major driver of deforestation and biodiversity loss.\nHealth and Nutrition Advantages of Sustainable Plant-Based Diets\nSustainable plant-based diets not only support the environment but also offer health advantages. They are rich in nutrients and antioxidants, lower in saturated fats, and can reduce the risk of chronic diseases.\nCenters for Disease Control Recommendations on Sustainable Eating Habits\nThe Centers for Disease Control recommends adopting sustainable eating habits, including a shift towards plant-based diets, to promote personal health and environmental sustainability.\nLong-Term Planetary Health Impacts from Widespread Adoption of Plant-Based Diets\nWidespread adoption of plant-based diets can have significant long-term impacts on planetary health. It can help mitigate climate change, conserve resources, and protect biodiversity, contributing to a healthier planet.\nA plant-based diet offers numerous health benefits, including lower risks of chronic diseases such as heart disease, diabetes, and kidney disease. Beyond individual health benefits, it also contributes to planetary health and sustainability. The key to reaping these benefits is focusing on a healthful plant-based diet, rich in whole foods. As more research continues to unveil the potential health benefits of plant-based nutrition, it’s clear that adopting such a diet can be a vital part of a healthy lifestyle.']	['<urn:uuid:aef5a4d2-e9c7-4c89-b72b-293e3059322e>', '<urn:uuid:049ae543-de3c-42ec-9cd4-60917e348de9>']	factoid	with-premise	short-search-query	distant-from-document	multi-aspect	expert	2025-05-12T22:49:38.933606	9	63	2418
19	estimated annual lung cancer deaths nonsmokers caused by secondhand smoke exposure	EPA estimates that secondhand smoke (SHS) causes approximately 3,000 lung cancer deaths in nonsmokers each year	['Smoking is not allowed at the John A. Burns School of Medicine (JABSOM) Kaka`ako campus to protect non-smokers from the negative effects of second-hand smoke and to support smokers who wish to reduce or stop smoking. JABSOM’s Kaka`ako complex, opened in 2005, was built with monies the Hawai`i State Legislature appropriated from the Master Settlement Agreement, a fund established to settle legal claims resulting from a lawsuit by the States against cigarette makers over the health consequences associated with smoking. Our MD graduates treat patients who suffer smoking-related disease, while our public health graduates work to educate the public about the dangers of smoking.\nWe hope that the following information from the Hawai`i State Department of Health WEBSITE helps visitors to the JABSOM community understand the problems associated with second-hand smoke and the need for everyone to assist in promoting and enforcing our desire to eliminate smoking on our campus.\nWhat Is Secondhand Smoke (SHS)?\nSecondhand smoke (SHS) is a mixture of the smoke given off by the burning end of a cigarette, pipe, or cigar, and the smoke exhaled from the lungs of smokers. This mixture contains more than 4,000 substances, more than 40 of which are known to cause cancer in humans or animals and many of which are strong irritants. Exposure to secondhand smoke is called involuntary smoking, or passive smoking.\nHow Does Secondhand Smoke Affect My Health?\nThe U.S. Environmental Protection Agency (EPA) has classified SHS as a Group A (human) carcinogen that is known to cause cancer. EPA estimates that SHS causes approximately 3,000 lung cancer deaths in nonsmokers each year.\nWhat About The Risk To Children?\nSecondhand smoke is a serious health risk to children: EPA estimates that passive smoking is responsible for between 150,000 and 300,000 lower respiratory tract infections in infants and children under 18 months of age annually, resulting in between 7,500 and 15,000 hospitalizations each year.\nChildren exposed to secondhand smoke are also more likely to have reduced lung function and symptoms of respiratory irritation like cough, excess phlegm, and wheeze.\nPassive smoking can lead to buildup of fluid in the middle ear, the most common cause of hospitalization of children for an operation. Asthmatic children are especially at risk: EPA estimates that exposure to secondhand smoke increases the number of episodes and severity of symptoms in hundreds of thousands of asthmatic children.\nEPA estimates that between 200,000 and 1,000,000 asthmatic children have their condition made worse by exposure to secondhand smoke. Passive smoking may also cause thousands of non-asthmatic children to develop the condition each year.\nWhat Can I Do To Reduce My Family’s Risk From SHS?\nChoose not to smoke in your home and car. Do not allow family and visitors, who are especially vulnerable to the health risks, to be exposed to secondhand smoke. Do not allow childcare providers or others who work in your home to smoke. Until you can quit, choose to smoke outside.\nFor more information, check out the Secondhand Smoke in Your Car and Home Fact Sheet (Secondhand Smoke Fact Sheet) and the Secondhand Smoke and Heart Disease, Lung Cancer, and Other Health Risks Fact Sheet (Other Health Risks Fact Sheet).\nClean Indoor Air Regulation\nAlthough population-based data show declining secondhand smoke (SHS) exposure in the workplace over time, SHS exposure remains a common public health hazard that is entirely preventable. Most state and local laws on clean indoor air reduce but do not eliminate nonsmokers’ exposure to SHS; smoking bans are the most effective method for reducing SHS exposure. Beyond eliminating SHS exposure among nonsmokers, smoking bans have additional benefits, including reduced smoking intensity and potential cost savings to employers. Optimal protection of nonsmokers and smokers requires a smoke-free environment.']	['<urn:uuid:9a993c23-e3db-4fe3-9826-e133c38afb7e>']	factoid	direct	long-search-query	similar-to-document	single-doc	expert	2025-05-12T22:49:38.933606	11	16	618
20	How do indoor farming and combat sports handle real-world effectiveness?	Both face challenges with real-world effectiveness. Combat sports, even in 'no-holds-barred' matches, occur in controlled environments with single unarmed opponents, which doesn't reflect real-life violent situations involving multiple armed attackers. Similarly, vertical farming's claimed benefits like 95% less water usage and 20-30x crop yields need to be evaluated based on specific locations - they're most effective in areas with water scarcity or extreme climates, but may struggle to compete in regions with established fresh produce networks.	"['Aikido Journal #102, 1995\n“I seriously doubt that the would-be “samurai” of the twentieth century will find a satisfactory solution to their quest for ultimate combative effectiveness through martial arts competition.”\nThe martial art of akido has enjoyed a steady growth since its quiet introduction in Japan following World War II and subsequent spread abroad. While the art has earned much respect for its ethical tenets, the techniques of aikido are often criticized as being too soft and impractical to be of any real use in an actual engagement. I have frequently added my voice to this chorus and maintain that the casual nature of practice in many schools today leaves students with unrealistic expectations of what they can expect to accomplish if their skills should ever be tested in a real-life encounter. I still believe that practice against lifeless, “ceremonial” attacks without the application of atemi and convincing finishing techniques leaves one highly vulnerable in a life-threatening situation.\nThis having been said, how specifically to go about adding a strong element of “realism” to aikido is altogether another question. Various improvements have been proposed such as teaching attacking skills, incorporating liberal use of atemi, adding self-defense techniques, etc., all with the aim of making up for aikido’s perceived technical deficiencies.\nAnother of the most frequently advocated solutions to this thorny issue is the introduction of competition to add a realistic dimension and provide a quantifiable way of measuring one’s skills against an opponent. The argument is often framed in such a way that the measure of a martial system is based on how exponents fare, or presumably would fare, in a match situation. For example, who would come out on top if fifth dans in judo and karate were to match skills? Is taekwondo superior to kung fu? Can an aikidoka with no cross-training in another art hold his own against an exponent of any of these more combat-oriented martial arts? Such speculation is endless and has failed to lead to any sort of consensus.\nThe most prominent example of the concept of competition applied to aikido has been the Tomiki system, which was philosophically inspired by the thinking of Jigoro Kano, the founder of judo. Kenji Tomiki, a prewar disciple of both Kano and Morihei Ueshiba and a successful judo competitor in his own right, devised a sport system of aikido which was launched via the aikido club of Waseda University in the 1950s. Matches in this style consist of one opponent armed with a mock knife while the other acts as the defender. The roles are reversed after a specified time and points are tallied to determine the winner. In addition to matches, this system of sport aikido includes kata competition. Tomiki Sensei experimented with various modifications to his system and, since his death in 1979, his senior students have carried on under the banner of the Japan Aikido Association, There are perhaps one hundred or so schools and clubs that follow the Tomiki system worldwide. The results of this continuing experiment with competitive aikido have been mixed, and even within this system there are those who prefer to emphasize more traditional practice methods and forego matches altogether. The Tomiki method has come under attack from proponents of other aikido schools who hold that the principle of competition itself runs counter to the central principles of aikido. Because of this fact, Tomiki Aikido remains to a certain extent isolated from more mainstream approaches.\nTwo other widely-practiced styles of aikido have embraced competition, albeit to a limited degree, in conjunction with demonstrations. Both the Yoshinkan Aikido and Shinshin Toitsu Aikido organizations conduct demonstrations where participants are graded on their performance, based on the execution of technique, balance, ability to blend, and other such criteria. Winners receive awards at the end of the event much as in other sports. The sort of “friendly competition” this approach has spawned seems to encourage performers to intensify their practice at least in preparation for these events, My impression is that aikido purists who frown at the Tomiki approach are not particularly concerned by these forays into competition by the Yoshinkan and Ki Society since neither conducts matches or bouts that pit two opponents against each other. I doubt very much, however, that this sort of performance competition by itself will be enough to satisfy those who call for training reforms designed to give aikido techniques “teeth” so as to render them effective in a realistic selfdefense situation.\nStill another attempt to restore an “aiki budo-like” dimension to aikido through the introduction of competition has been recently launched by Fumio Sakurai. In the view of Sakurai, a former Yoshinkan Aikido shihan, aikido should rediscover its roots and be practiced with vigor as it was in the prewar days. He recalls the rigorous training undergone by his teacher, the late Gozo Shioda, in the “Hell Dojo” of aikido founder Morihei Ueshiba in the 1930s. In an effort to achieve this goal, Sakurai has begun experimentation with a new form of competition in which two opponents square off in an empty-handed match. Each competitor dons protective padding covering the knees, shins, and feet, and kicking is allowed. Punches are, however, prohibited as are attacks to the face, kicks to the outside of the knee, attacks to the groin, and various other dangerous moves.\nI recently attended the inaugural tournament of Sakurai-ryu Aikido, as this new approach to aikido has come to be called, held on September 15. Sixteen competitors participated in this intraclub tournament and, with one or two exceptions, there were no aikidoka with tournament experience. Most of the attacks were very tentative since atemi were not permitted, and those who fared the best succeeded in closing the distance with their opponents to score points. I saw only one or two clean “aikido-like” techniques, one a kotegaeshi and the other an armbar. The winner in the heavyweight division was the largest, most muscular and well-trained athlete of the lot. However, he sustained an injury during the tournament that afterward kept him sidelined for several weeks.\nThe challenge for Tomiki advocates and people like Sakurai Sensei who favor competition is how to preserve the essential attributes of aikido—taijutsu system with specific ethical principles—while devising a sport that is both safe and interesting to spectators. What if the rules and nature of competition itself do not encourage the execution of aikido techniques? How does one avoid having the objective of “victory above all”—clearly the antithesis of Morihei Ueshiba’s vision—becoming the participants’ main inducement to compete as in so many other sports? If these conditions are not satisfied by these fledgling sports, then what is the justification for calling them “aikido?”\nAs a result of our promotion of Sakurai Sensei’s activities in the Japanese-language Aiki News, I have been recently invited to attend two fighting tournaments that featured exponents of the popular Gracie Jujutsu system. In the first tournament, Rickson Gracie won his three matches effortlessly by forcing his larger opponents to the ground and applying a decisive choke. Everything was over in a matter of seconds. This is the trademark of this unique system, which has gained a widespread and much-deserved reputation for its effectiveness under match conditions.\nWhat impressed me most was the ease with which Rickson downed his adversaries and how his victories resulted in no injury to either his opponent or himself. That should grab your attention! Two of the winners of other bouts managed to break their hands in the process and their victories were rather bloody and artless by comparison. Gracie Jujutsu will surely be of interest to many aikidoka because of its humane approach and effectiveness in certain combat scenarios. The top exponents of this system are experts in grappling and knowledge of this skill would be very complementary to any martial art. Parenthetically, we will have an interview with one of the Gracie brothers in the near future and will do our best to present in detail this innovative martial system.\nThe opportunity to attend these matches was a real revelation for me coming as I do from the aikido world. With the exception of Rickson Gracie’s bouts, I found most of the matches to be animalistic and, quite frankly, repulsive. It occurred to me that competitors are required to develop a particular mindset in order to do well in such tournaments, Such fighters must learn to be aggressive and ruthless, and attempt to exploit the rules fully to achieve victory. I doubt that such character traits can be easily switched on and off. I also wonder if these attitudes, deeply ingrained as they are through rigorous training, might not come to dominate an athlete’s personality and prove a liability in personal interactions. I felt that the controlled, harmonious nature of aikido practice—even though it might not prepare one for tournament fighting—is much preferable to these other dog-eat-dog fighting styles from the standpoint of learning to live peacefully in society.\nI also noted that these athletes, many of whom are or aspire to become professionals, live in constant fear of injury. It was obvious in several matches that certain defensive maneuvers were designed to protect a vital part of the body from attack. Although fatal injuries might be infrequent in these tournaments, the accumulation of physical punishment over a period of time can leave a person with serious medical problems, disabilities, not to mention losing one’s means of livelihood. Shades of boxing and football!\nSeeing these tournaments set my mind thinking along lines I had not explored previously. I asked myself, for example, did the victors in these matches demonstrate an ability to overcome an opponent in a “realistic” situation by besting their rivals in the ring? Surely, there were skilled martial artists in the competition. However, even though the first bouts I saw were billed as “no-holds-barred,” still the opponents fought within the confines of a ring. There was a single opponent, no element of surprise was involved, and naturally no concealed weapons or firearms figured in the fights. So though it was an “anything-goes” situation as far as fighting matches are concerned, the conditions were far removed from reality.\nEven the marvelous skills displayed by Rickson Gracie provide no clue as to how he would handle a “real” situation against multiple attackers who are more than likely to be armed. Obviously his chances could be considered superior to those of an untrained person, but a confrontation involving firearms—the scenario most feared by the average citizen—is an altogether different matter both tactically and psychologically speaking.\nTo sum up my thoughts on this issue, I seriously doubt that the would-be “samurai” of the twentieth century will find a satisfactory solution to their quest for ultimate combative effectiveness through martial arts competition. I believe rather that the skills required to become a peerless warrior in a modern society are far different from those of the earlier and simpler times in which these arts were developed. Today’s warriors are people like the police and elite military instructors who contribute to the “Coping with Violence” section of Aikido Journal. These dedicated individuals have vast knowledge of the many manifestations of violent behavior and what to do about it. They bring to their jobs a detailed understanding of weapons, tactics, and psychology. They are men who have looked death in the face on numerous occasions and who cannot afford to relax their alertness for even a moment in the fulfillment of their duties.\nAikido’s main contribution to the enrichment of individual lives lies not in the mechanics of techniques but rather in its ability to transform and elevate spirits beyond the plane of dualistic thinking. I genuinely believe that those seeking “the ultimate fighting system” are destined to forever pursue an illusion.\nMembers please log in here to continue…\nAlready a member? Login below…', 'Vertical Farming: Location a Key Factor to Success, Says IDTechEx\nVertical farming, the practice of growing crops indoors on vertically stacked layers, has received no small amount of interest over the last few years. Vertical farms commonly tout impressive numbers, such as using 95% less water and providing crop yields 20-30 times that of conventional agriculture. These claims, among many others, have seen many vertical farming start-ups being founded alongside large amounts of industry funding; funding for the industry reached a record high in 2021, with over US$1 billion being raised across the entire industry. The recent IDTechEx report, ""Vertical Farming 2022-2032"", details the economic and technological factors shaping this rapidly growing industry.\nWith crops being grown indoors under controlled environments, a selling point used by multiple vertical farms is that they can grow crops anywhere – even in the heart of a city. This has led to proponents of the industry envisioning ""smart cities"", where vertical farms in city skyscrapers help feed the urban population. While this is achievable in principle, the truth is that the choice of location for vertical farming is much more involved and intricate than it may appear from these claims alone. Choosing an ideal location can be one of the most important factors in determining the success of a vertical farm.\nSome vertical farms may choose to set up their facilities in pre-existing facilities, such as abandoned warehouses. In these cases, identifying the suitability of the venue is the first point of consideration: vertical farms are very energy intensive, and it is important to ensure the facilities chosen can support these energy loads. In addition, the ergonomics of the facility is also important; should the layout not be given proper consideration, this can impede workers and decrease worker efficiency. As labor costs are typically among the largest sources of expenditure for a vertical farm, improving labor efficiency to reduce these costs is of paramount importance.\nWhile growing crops in the center of a city may seem ideal, the reality is that this may be counterproductive. Obtaining and maintaining such a location is expensive and can contribute significantly to the operating expenditure of a vertical farm while presenting logistical challenges in distributing produce; the ""last mile"" of food distribution is often the hardest. Having a farm right next to the consumers themselves may also be less ideal than instead choosing a location near food distribution centers, as this allows for more efficient delivery of produce. As distribution centers are typically located on the outskirts of cities, the cost of land is also much cheaper. This is the approach chosen by UK-based Jones Food Company, which chose Scunthorpe as a location for its vertical farm – this is a relatively low-cost location located near food distribution centers and a network of motorways that could still reach many consumers in a day, even if it isn\'t right in the middle of the capital city. Vertical farms should carefully consider their place in the supply chain before establishing a base.\nOn a larger scale, vertical farms may prove more profitable in different geographical regions. Vertical farms can reduce water usage significantly over conventional agriculture, and the high degree of control over the growing environment allows them to grow crops in extreme climates – where such crops may not otherwise be able to grow. In return, vertical farms demand more energy to carry out growing operations. To maximize their potential, vertical farms would ideally be located in regions of water scarcity, such as Sub-Saharan Africa and the Middle East, or in areas with extreme climates, such as in Scandinavian countries, where the low amounts of sunlight and high costs of regulating greenhouse environments single out vertical farms as an optimal solution. The amount of agricultural land available is also an important factor – regions looking to increase food security and reduce reliance on imports while facing challenges in acquiring sufficient agricultural land would find vertical farms to be ideal. A particularly prominent example of such a country is Singapore, which has demonstrated much interest in vertical farming over the last few years.\nBeyond the considerations of water scarcity and temperature, the general availability of fresh produce and the distribution networks of given countries should also be considered. Vertical farms use the added freshness and higher quality of their crops as a primary selling point, but these are typically offset by higher prices. Should there already be a large supply of high-quality produce made available at lower costs, vertical farms will find it hard to distinguish their own produce and may struggle to establish a significant market share. The converse would also be true; should a country lack easy access to fresh produce, vertical farms are expected to see much demand for their produce. An example of such a region would be the Middle East: leafy greens typically travel several thousand miles to reach stores, resulting in consumers facing high prices and low-quality products. The high price of conventionally farmed leafy greens, alongside government subsidies, makes it easier for vertically farmed produce to approach price parity while providing much fresher, higher-quality products.\nWhile the choice of location is an important consideration, it is only one of many others that must be given proper thought. Only through proper optimization of growing operations to improve efficiency and reduce costs can vertical farms reach their true potential. In the IDTechEx report, ""Vertical Farming 2022-2032"", many further important factors for consideration are discussed in detail, and the future of vertical farming is evaluated through 10-year market forecasts.\nIDTechEx guides your strategic business decisions through its Research, Subscription and Consultancy products, helping you profit from emerging technologies. For more information, contact research@IDTechEx.com or visit www.IDTechEx.com.\nThis post does not have any comments. Be the first to leave a comment below.\nPost A Comment\nYou must be logged in before you can post a comment. Login now.']"	['<urn:uuid:9a37c75e-4fdd-4702-8237-aa2cb02b6eda>', '<urn:uuid:98c0eed7-8d91-42cd-b0d1-cc7c105f9a4d>']	open-ended	with-premise	concise-and-natural	distant-from-document	multi-aspect	novice	2025-05-12T22:49:38.933606	10	76	2952
21	Do you need a fishing rod to catch fish?	No, a fishing rod is not essential for fishing. Methods like casting a fish net, spear fishing, and most forms of commercial fishing don't use rods.	['A fishing rod and reel are not essential for fishing, as casting a fish net, spear, and most forms of commercial fishing are common examples of not using them. A very simple way to catch fish utilizes a hook, line, bait and flat stones. The only other requirement is a boat or a dependable flotation device to fish this way at the ocean.\nGathering flat oval stones is part of the preparation. They do not have to be large, and the ideal size is larger than the palm of the hand. The line should be thick and sturdy, as a fishing rod and reel are not used; the hands substitute for them. Large wooden or plastic spools are useful for storing and releasing the line into the water. The line serves as both the main line and hook line. A very handy item to have is an elastic depth marker that slides along the line. They are colorful, which makes them easy to see and use to set the fishing depth (See Picture 2). If they are not available, tying a Surgeon’s knot with string on the line can serve as a marker. As for bait, a large frozen block of tiny shrimp and a small block of larger shrimp to place on the hook are a good combination. If only one block of larger shrimp is used, set aside the largest shrimp in the block to place on the hook after thawing.\nTo check the depth at the fishing location, attach a sinker to the end of the line and drop it into the water. When it hits the bottom, mark the spot on the line with the depth marker. Next, adjust the marker to the target depth for the fish you want to catch. After that, get the line and sinker out, tie the fishing hook, and begin fishing.\nSet a nice, plump shrimp on the hook and place it in the center of a flat stone (Picture 3). Place half a handful of bait shrimp on top; covering the baited hook. Wrap the line closely and completely around the stone at all angles, up to the marker. This keeps most of your bait shrimp from scattering before reaching the fishing depth. Drop the stone into the water. The stone is now a sinker that delivers the bait and sets the baited hook to the target fishing depth.\nA word of caution about this fishing style: your hands are substituting as a rod and reel to tackle and haul in the fish; be sure to protect them well with thick gloves. Even with the gloves on, it is not a good idea to wind or wrap the line around the hands. A monstrous fish could suddenly come around for a bite. There are times when hauling in the fish is just not possible. This fish will normally snap the line. Otherwise, do not continue the battle into the water. If this should happen, the life vest is truly a lifesaver.']	['<urn:uuid:072e52f2-c3d9-4ff2-bd29-a02ccd2f81b4>']	factoid	direct	concise-and-natural	similar-to-document	single-doc	novice	2025-05-12T22:49:38.933606	9	26	502
22	temple archaeologist comparing petra bosra construction dates which older	Based on the available evidence, Petra is older than the religious structures in Bosra. Petra was built in the early 5th century B.C., while the cult buildings and inscriptions in Bosra date to the 6th century CE (500-600 CE), making Petra approximately 1000 years older.	"[""Saint NameMary, Mother of Christ : S00033\nType of EvidenceInscriptions - Formal inscriptions (stone, mosaic, etc.)\nEvidence not before500\nEvidence not after600\nActivity not before500\nActivity not after600\nPlace of Evidence - RegionArabia\nPlace of Evidence - City, village, etcBosra\nPlace of evidence - City name in other Language(s)Bosra\nSakkaia / Maximianopolis\nSakkaia / Maximianopolis\nCult activities - PlacesCult building - independent (church)\nCult activities - Non Liturgical Practices and CustomsPrayer/supplication/invocation\nSourceThere is no detailed description of the stone on which the inscription was carved, and which is now lost. Maurice Sartre supposes that it must have been a large lintel with a circle containing a cross or a crown in the middle of the inscribed face, as the copy by William Waddington who saw the object indicates the presence of such a decorative motif.\nFound in a church in Izra/Zorava. First seen and copied by Ulrich Jasper Seetzen on 30 May 1805. Later independently recorded by William Waddington in the 1860s, who was probably the last person who saw the inscription. The most recent edition, by Maurice Sartre, is based on the earlier publications.\nSeetzen found another inscription in the same church (see: IGLS 15/1, no. 189). That text praises the greatness of God, His ability to work miracles, and stresses the unique holiness of the Holy Trinity. Based on this, Trombley suggested that the church was dedicated to the Holy Trinity. He also argued that the shrine was probably built soon after the replacement of the cult of an obscure pagan God, Theandrites (see the comments in E01754), by the Christian religion, which he presumed to have happened in the early 6th century. Sartre rightly rejects these hypotheseis as too far fetched and lacking basis in the evidence.\nFor another inscription from Izra/Zorava, probably from a church dedicated to Mary, see: E02114.\nDiscussionThe inscription begins with a popular dedicatory formula which appears in the anaphoras of the Liturgies ascribed to John Chrysostom and Basil of Caesarea (τὰ σὰ ἐκ τῶν σῶν σοι προσφέρομεν / 'thine own from thine own we offer unto thee'); the use of the formula in Late Antiquity is evidenced by a number of inscriptions from Anatolia and the Near East.\nLines 3-4 express the belief that the intercession of Mary (as the influential Mother of Christ) is at least welcomed, or even necessary, for a successful offering, as people can only bring meager goods, compared with the magnificence of God.\nThe inscription ends with a reference to the biblical story of the poor widow whose two copper coins were considered by Jesus to be a much better offering than the large sums brought to the Temple by rich people (see Mark 12,41-44; Luke 21,1-4).\nDating: there is no reliable way to date the inscription. A date in the 6th c. is possible, as other dated texts from Izra/Zorava come from this period.\nSartre-Fauriat, A., Sartre, M., Inscriptions grecques et latines de la Syrie, vol. 15/1: Le plateau du Trachôn et ses bordures (BAH 204, Beyrouth: Institut Français du Proche-Orient, 2014), no. 188.\nFelle, A.E., Biblia epigraphica. La sacra scrittura nella documentazione epigrafica dell'«Orbis christianus antiquus» (III-VIII secolo) (Bari: Edipuglia, 2006), no. 106.\nWaddington, W.H., Inscriptions grecques et latines de la Syrie (Paris: Firmin Didot Frères, Libraires-Éditeurs, 1870), no. 2500.\nKruse, F., Fleischer, H.L., Commentare zu Ulrich Jasper Seetzen's Reisen (Berlin, 1859), 78-79.\nSeetzen, U.J., Reisen durch Syrien, Palästina, Phönicien, die Transjordan Länder, Arabia Petrae und unter-Aegypten, vol. 1 (Berlin, 1854), 115.\nJalabert, L., DACL, vol. 3, 1738, no. 132.\nTrombley, F.R., Hellenic Religion and Christianization c. 370-529, vol. 2, (Leiden - New York - Cologne: Brill, 1994), 362 (English translation)."", 'Jordan’s archaeological sites and natural vistas have been immortalized on their fair share of postcards and travel brochures, so your personal photos should embody a unique perspective of the country’s offerings. If you’re traveling to the Hashemite Kingdom and planning to bring your camera along, check out these tips and tricks to photographing Jordan’s cities, ruins, and markets.\nJordan’s most famous site, Petra is worth visiting for its historical and architectural connotations alone. Built in the early 5th century B.C., the ancient city was thought to have been an ancient trading hub, though it was abandoned in the years following its construction. Rediscovered and shared with the world in the 1800s, the site has remained a highlight for any who visit the country.\nIf you’re interested in photographing the towering facade, be sure to bring a wide-angle lens so that you can capture the enormity of the sandstone structure. Consider visiting at dawn or dusk to avoid harsh shadows, and properly expose your images by “metering” or exposing for the image’s lightest parts. Though the photo may look dark on your camera’s review screen, you’ll be able to balance the exposure in post. Play with perspective and angle as you photograph, and stick around even after the sun has set. At nightfall, hundreds of candles grace the courtyard below Petra, so open your aperture, keep your ISO low, and choose a fast shutter speed (1/500) to capture the glow of the lights without the grain and blur that typically plague low-light photographs.\nVisit this vast, desert expanse and you’ll feel like you’ve dropped onto another planet. Needless to say, it’s no surprise that this Jordanian desert has been used to replicate otherworldly settings in some of Hollywood’s most iconic films.\nTo photograph the dunes and archaeological sites in Wadi Rum, use a wide-angle or zoom lens. That way, you can capture the enormity of the desert expanse while also zeroing in on its gorgeous architectural details. To avoid harsh shadows, photograph during the early morning and evening, when the light is dreamiest. Use a low ISO setting (100-200) to avoid unnecessary grain, and consider utilizing a tripod during times of low light to avoid shaky images. As with most landscape shots, you’ll want the majority of your images to be in focus, so settle for a middle-range f/stop value (f/8-f/11). For high-contrast desert shots, it may also be beneficial to use a polarizing filter, which can minimize glare and maximize the gorgeous tones of this sandy site.\nYou’ll likely fly into Jordan’s capital — and most populous city — but you should stick around and explore the region before you jet off to see the rest of the country’s natural wonders, archaeological sites, and ancient cities. Founded in 7250 B.C., Amman has a rich history and offers much to discover, especially for avid photographers.\nAmman’s monochromaticity and uniform sprawl makes for aesthetically pleasing photographs, so seek out the city’s many viewpoints while you’re there. Your best bet for elevated views of the Jordanian capital is to visit the Roman Theater or the hills that frame the metropolis. This is one instance where midday shadows may act in your favor, as they can create an interesting textural pattern amid the graduated levels of Amman’s sand-colored buildings — so go ahead and sleep in through sunrise! Utilize a wide-angle lens while there to capture the enormity of the cityscape, and photograph with a low ISO (100-200) and a middling aperture value (f/8-f/11) to ensure that the image is properly exposed and in focus.\nRoman Ruins in Jerash\nYou’ll likely feel as though you stepped back in time as you wander among Jerash’s famous Roman ruins: ceremonial gates, colonnades, temples, arches, and theatersy. Due to the Roman conquest (and subsequent construction) in 63 B.C., this Middle Eastern city is home to the world’s second-largest collection of ancient Roman architecture outside of Italy. If you visit, don’t miss photogenic stunners such as Hadrian’s Arch, the hippodrome, the Temple of Zeus, the nymphaeum, or the Temple of Artemis.\nUpon visiting, challenge yourself to photograph with a prime (fixed) lens so that all of your photos have a sense of uniformity, and also so that you have to traverse the entirety of the site to capture a variety of different angles. Experiment with different perspectives and get as close to the ruins as you can, so as to photograph their unique architectural details. For macro shots, shoot in aperture-priority mode, open your aperture as wide as possible (choose an f/stop such as f/1.8), and hone your focus on a particularly interesting element. For landscape shots, be sure to utilize the Rule of Thirds so that your image contains visual interest. We also recommend visiting the area during dawn or dusk, as the strong sun creates a lot of glare on the light-colored stone — there isn’t a lot of shade, so keep this in mind when planning your excursion (remember: the earlier the better!).\nMosaics in Madaba\nMadaba is a site of longstanding religious and historical significance, and most visitors travel there to view the city’s array of stunning, ancient mosaics. Home to myriad multicultural populations since the Bronze Age, Madaba is a site rich in archaeological treasures, including its most cherished, the Map of Madaba — a mosaic that depicts sixth-century Jerusalem with over two million colored fragments.\nTo see and photograph the famous stone map, head to the Greek Orthodox Basilica of Saint George and set your camera to aperture-priority mode. Choose an aperture between f/4 and f/8 and keep your ISO low (100-200) so that your images aren’t fuzzy. Keep your camera stable with a tripod, a steady hand, or another surface, and be prepared to adjust white balance and color profiles in post processing, as the dim light of the church may impact the hues of the mosaic. If you’d like to photograph a smaller section of a mosaic in greater detail, adhere to the rules of macro photography, open your aperture (f/1.8-f/4), focus carefully, and snap away.\nMarkets in Al-Salt\nLocated just 30 minutes outside of Amman, Al-Salt is an ancient Ottoman administrative center and agricultural trading post that plays host to elegant architecture, natural vistas, and bustling markets.\nAs you wander the streets of Al-Salt, you’ll notice the fine architecture and the golden-hued stone buildings for which the area is known best. Be sure to capture these tinted facades when they glow in the early evening with the setting sun. And, if you can, visit on a Saturday, when the markets are especially busy. Once there, venture to Hamman Street and witness a variety of vendors selling fresh produce, meat, household goods, and bags of colorful spices. Experiment with both landscape and portrait orientation to capture the scope of the sales, and vary your perspective to photograph the spectrum of goods available. Although markets are great opportunities for portraiture, remember to always ask before taking someone’s photo. If you plan on strolling while photographing, bring some cash to buy a snack or souvenir from one of the vendors — it’s the best way to make a connection and participate in the energy and tradition of the market.\nHeader image by Ryan Hafey']"	['<urn:uuid:4a6a4227-70fd-44d2-b891-8e76a1f52a2e>', '<urn:uuid:743d8521-cbea-4a87-a0c5-9144e8013dc3>']	factoid	with-premise	long-search-query	similar-to-document	comparison	expert	2025-05-12T22:49:38.933606	9	45	1808
23	medieval tiles cleaning methods conservation	Medieval tiles should be cleaned very rarely and with utmost care. The recommended method is gentle brushing using soft squirrel hair brushes. Hand brushing is preferred over vacuum cleaning to better collect loose fragments. Only dry brushing should be used, and coatings are not desirable. For bat or bird droppings, dabbing with de-ionized water using a soft cloth is sufficient.	['Circa 11th to 13th century\nOn this page you will find guidance on conserving and caring for medieval tiles.\nA Brief History\nThe proliferation and expansion of medieval tile making runs concurrently with the great age of ecclesiastical building in France and England, the first flowering of tile making began at the middle of the twelfth century to the mid thirteenth century; it is likely that tile makers travelled from Europe to England. In the early period only the wealthiest of ecclesiastical houses or Royal patronage were engaged in commissioning tiles.\nSome of the finest early two colour inlaid tiles, dating from around 1260 were made for Henry IIIs Westminster Abbey Chapter House and the Kings Palace at Clarendon, the British Museum also holds some fine tiles found at Chertsey Abbey in Surrey also dating from the early period. Byland, Rievaulx and Fountains Abbeys in Yorkshire all held, some still in situ, intricately cut mosaic or geometric style tile pavements dating from the end of the twelfth century.\nFrom the mid thirteenth century until the dissolution of the monasteries tile making became more widespread. Tile makers were quite often itinerant, building kilns near the religious establishments they supplied, but they also established permanent kilns in many places including Bawsey in North Norfolk and Coventry in Warwickshire. Wealthy merchants became patrons of the industry using tiles for their increasingly comfortable dwellings.\nIt is commonly thought that the Black Death and the Dissolution combined to see the end of tile making in Britain as there is little evidence for further decorative tile making after the mid sixteenth century, however significant numbers of medieval tiles remain in small churches, chapels and dwellings dating from later sixteenth and seventeenth centuries which have their origins in the removal of fabric from the monasteries.\nPractical guidance on simple conservation issues.\nThe information on these pages is for guidance only we do not accept responsibility as a result of any person carrying out any works according to the advice contained in this web site. Always follow Health and Safety measures described on products, tools and materials. Jackfield Conservation Studio is not responsible for the work which you do, the responsibility is yours and yours alone!\nConservation of medieval tiles should be in the hands of an experienced conservator, it is unfortunately all too easy to inadvertently damage these precious items.\nMedieval tile collections should be assessed annually to ensure that the condition is stable. Look for;\n- Damage as a result of fluctuating temperature and humidity levels\n- Excessive surface dirt or grit and infestations from birds, animals and biological growth\n- Fractured or loose tiles\n- Breakdown of mortar\n- Most medieval tiles will have defects due to manufacturing techniques, restoration is not applicable.\nHumidity and temperature levels should remain stable; they must be in a suitable equilibrium. An ideal storage environment would be;\nTemperature Range 19 degrees Cent + -1 degree.\nHumidity Range 50% +-2% relative humidity\nChurches or chapels, for example, require a good air flow to prevent humidity levels from rising too high. Tiles which are wholly unprotected must be covered during the winter months to avoid the freeze thaw cycle.\nMedieval tiles should only be cleaned very rarely using the utmost care. If excessive amounts of dust and grit form on the surface as a result of the location then it should be gently brushed and collected using soft squirrel hair brushes. Brushing by hand is preferable to vacuum cleaning as loose fragments are more easily collected if the surface is friable.\nA small amount of clay dust will be lost from the surface of the tile at every brushing which is why cleaning should be infrequent. Dry brushing in this fashion should be all that is required, coatings of any kind are not desirable, covering or carpets are not recommended as they will prevent absorbed moisture in the atmosphere from evaporating. Droppings from bats or birds should be removed as soon as possible, dabbing using de ionised water with a soft cloth will suffice.\nIf loose tiles require re setting the advice of a conservator should be sought.\nGood maintenance relies on positive action to maintain an ambient environment suitable for medieval tiles. Regular annual inspection which includes recording the condition of the pavements or individual tiles is essential; from that annual inspection it can be determined if the tiles or pavement require any treatment in the form of cleaning or mortar repair or if they are best left untouched. An annual inspection is best carried out by an experience conservator.']	['<urn:uuid:1885221d-a5d4-4d87-bbc5-d3a2a9c667cf>']	open-ended	with-premise	short-search-query	similar-to-document	single-doc	expert	2025-05-12T22:49:38.933606	5	60	760
24	inner outer planets main differences composition structure temperature formation process	Inner (terrestrial) planets are rocky bodies with substantial atmospheres, while outer (Jovian) planets are gas giants composed mainly of hydrogen and helium without solid surfaces. This difference is due to temperature variations in the protoplanetary disk - closer to the protosun, only rocky materials could condense due to high temperatures, while farther out, both icy and rocky materials could form planetesimals, leading to the formation of gas giants through accumulation of large amounts of gas.	"[""Science Lecture for Unit 26: Planetary Systems\n- Topic area: Astronomy: Solar System\n- Terms and concepts to know: Sun, planets, moons, asteroids, comets, jovian planet, terrestrial planet, planetary atmosphere, planetary rings, Red spot\n- See historical period(s): Scientific Revolution , Renaissance (Copernicus)\nThe Solar System\nOur science goal this week is to cover the basics of the modern view of the solar system. There is a ton of information available, so that's a pretty tall order. Our current view of the solar system (except for determining orbits) is largely the product of unmanned space vehicles. From the early 1960s when the first Ranger and Surveyor craft were flung at the moon and inner planets, through the heady days of Voyager and Viking (I worked at JPL during Viking and Voyager and they were heady days), up to the current missions of Cassini and Mars Pathfinder, the world's scientists have been collecting detailed information on the composition of planetary atmospheres, the size and shape of magnetic fields, the details of surface structures, and the lack of any conclusive sign of life other than on earth.\nYou may use an encyclopedia or any of the many excellent web sites or astronomy textbooks available to get the following information. If you are stuck, a good source is\nOriginally, this site was a volunteer effort, but it is now are supported by advertisement popups. You may want to turn off popups in your browser to suppress them..\nRegardless of which site you use, start with introductory material on on the sun, and check out sections or links on sunspots. Study the introductory pages on each of the planets, and also on comets and asteroids.\nThere is a lot of material at this site. The outline below is a suggestion for organizing your notes.\n- Classes and types of objects in the solar system\n- Minor objects\n- Composition and structure, size\n- Source of energy, age\n- Position and movement with respect to the galaxy\n- Solar spot activity (because Galileo observed it--there are many other solar phenomenon of equal interest: solar flares, coronal behavior)\n- Planets: major bodies\n- Terrestrial planets are rocky, with substantial atmospheres\n- Mercury: closest to sun, hot, rare atmosphere\n- Venus: heavy atmosphere with greenhouse effect, very hot\n- Earth: only planet with surface water in liquid state, oxygen/nitrogen atmosphere\n- Mars: similar to earth; signs of water erosion, volcanic activity\n- Jovian planets are gas giants, mostly hydrogen and helium, with no solid surface\n- Jupiter: most massive object, largest object (besides sun), Red Spot, moons interesting (Io has volcanoes)\n- Saturn: second to Jupiter is size; less dense than water, surrounded by spectacular ring system.\n- Uranus: tilted on axis nearly 90 degrees--interesting currents\n- Neptune: has spot similar to Red Spot on Jupiter\n- Pluto: the anomaly, rocky twin object with Charon, orbit at angle to the plane containing the other planets; orbit intersects with Neptune. No longer considered a planet!\n- Minor bodies\n- Moons of planets: rocky, few with atmospheres, range in size. Titan has an atmosphere, Io has volcanoes, some other moons show evidence of having once had surface water.\n- Asteroids: solar system debris? small, rocky bodies, different groups at different orbits from the sun\n- Comets: ice and stone from far out beyond Pluto; two tails\n- Origin of solar system: is planet formation normal part of star formation?\n- All planets have mass, and the size of that mass determines other characteristics, such as whether the planet has an atmosphere. What other basic characteristics to all planets (and maybe their moons!) share? How do differences in the size or amount of these characteristics cause differences in other aspects of the planet? For example -- how do atmospheres vary with the mass and surface temperatures of the planet?\n- Can we induce some general statements about planets from the common characteristics we've identified? What status do these statements have? Are they hypotheses to be tested? Theories? Laws?\nFurther Study/On Your Own\n- Strobel's astronomy course also has a chapter on the solar system which is very good.\n- You may want to look at the truly stunning multi-media astronomy hyper-textbook The Nine Planets from Bill Arnett, who teaches at the University of Indiana. Warning: This site is sponsored by advertisements, so it can be more distracting and difficult to navigate if you click on an advertisement link.\n- Current results of the Mars Pathfinder mission are posted daily at JPL. This small roving unmanned exploration vehicle landed on Mars on July 4, 1997--with well over 5 million Web viewers watching (not to mention TV coverage). JPL also maintains a web-accessible archive of its best pictures from 25 years of planetary expeditions, including photos of asteroids and comets. The site is organized by both object and mission.\n- If you want to see the current positions of the planets, look them up on the online orrery!\n© 2005 - 2019 This course is offered through Scholars Online, a non-profit organization supporting classical Christian education through online courses. Permission to copy course content (lessons and labs) for personal study is granted to students currently or formerly enrolled in the course through Scholars Online. Reproduction for any other purpose, without the express written consent of the author, is prohibited."", '“Facts” that must be accounted for in any theory of solar system formation • All the major planets orbit in almost the same plane • All the planets orbit in the same direction • Almost all the planets rotate in the same direction as they orbit • The inner planets are rocky bodies while the outer planets are gaseous and/or icy bodies • 99% of the mass of the solar system is in the Sun • Most of the angular momentum of the solar system is in the planets, not the Sun • Look at ClassAction Solar System Properties Explorer in the Solar System Characteristics module\nWe start with a cold cloud of gas and dust Because of the internal motions of the gas and dust, the cloud almost always has some slight overall rotation\nThe cloud starts to collapse due to gravity Angular momentum causes the cloud’s initial slow rotation to spin faster and flatten out\nAngular momentum is what causes a skater to “spin-up” Angular momentum depends on both the velocity, V, and the size, R. If R decreases, V must increase. It is also what causes the pizza dough to flatten out when tossed\nThe “Spin-up” causes the cloud to flatten out Angular momentum keeps stuff from falling straight in. Instead, it spirals down onto a disk. This is the pizza toss effect\nAt this point we have something that looks like a star surrounded by a disk of gas and dust The protostellar Sun is getting its energy from gravitational collapse, not from fusion like “normal” stars.\nThe temperature in the protoplanetary disk falls off as you get farther from the protosun Check out planet Formation Temperature Plot on ClassAction website Solar System Characteristics module\nThe solar nebula is composed mostly of hydrogen and helium The most common things to condense will be hydrides of carbon (CH4…methane), nitrogen (NH3…ammonia) and oxygen (H2O…water). These condense at fairly low temperatures. Elements like silicon and iron condense at higher temperatures.\nWhat is found at different distances from the protosun depends on temperature and abundance\nCondensation begins to form dust grains The dust grains are tiny: about the size of particles in smoke. They are also charged with static electricity\nThe dust grains quickly start sticking together Close to the protosun the grains are exclusively silicon, iron and other heavy elements: “rocky” materials. Farther out there are more grains of “icy” materials than rocky ones. Static electricity also plays an important part in making the grains stick together\nEventually Planetesimals are formed Close to the Sun the planetesimals look like asteroids Far from the Sun the planetesimals are a mix of ice and rock\nPlanetesimals merge to form protoplanets The larger the planetesimal, the stronger its gravity is. The stronger its gravity, the more it attracts stuff and the more violent the collisions become.\nThe gas giants form a large core of ice and rock and then grow by sweeping up large amounts of gas\nThe Solar Nebula Stage Condensation starts and planetesimals begin growing\nThe Accretion Stage Planetesimals grow bigger by collisions. There may be hundreds of moon sized protoplanets form in the inner solar system. The outer planets have grabbed up the last of the gas\nThe accretion stage was a violent period with planet smashing collisions\nFinally, we have a new star and new planets The new planets at this stage are nothing like the planets we see today. They will evolve over time to become the eight planets we see now\nThe gas giants were like mini solar systems, forming a system of moons\nFinding extra-solar planets Our theory was designed to explain the formation of our solar system. How does it match up with other planetary systems around other stars?\nWe have seen lots of disks around forming stars confirming some of the nebular theory\nNewton’s 3rd Law applies to the Sun and planets If the Sun tugs on Jupiter, keeping it in orbit, then Jupiter tugs on the Sun, making it orbit. The two actually orbit a common point just outside the surface of the Sun Watch ClassAction Extrasolar Planet module Influence of Planets on the Sun animation\nThe Doppler Effect technique detects the motion of a star caused by a planet Watch ClassAction Extrasolar Planet module Radial Velocity Graph animation\nThe transit method measures a planet directly if it passes in front of its star The planet will be a dark spot passing across the face of the star. The dimming of the light from the star may be tiny but it is measurable if the planet is large enough.\nThe Doppler method is the most prolific but it finds large mass planets close to their star Visit http://exoplanet.eu\nSo what do we do about our solar nebula model? Our model predicted small rocky planets close to the star We are finding large gas giants close to their star! The basic modification is that things move, sometimes they move a lot: Migration theory']"	['<urn:uuid:ef408c96-d948-4595-8f58-f149457cc8a7>', '<urn:uuid:945cd09c-c9c1-4085-8f68-37ff14c14ab3>']	factoid	direct	long-search-query	distant-from-document	multi-aspect	expert	2025-05-12T22:49:38.933606	10	75	1717
25	How does the traditional syllable structure of haiku compare with modern approaches?	Traditional Japanese haiku has 17 syllables spread over three lines in a 5-7-5 pattern. However, in modern practice, especially in English, many poets feel that fewer than 17 syllables is more natural and effective. This is due to differences between Japanese and English syllables and grammar, where English can often carry the same information in fewer syllables. While some writers still use the 'strict form' of 5-7-5, others prefer a 'flexible' or 'organic' style where form is reinvented for each new poem. Most haiku poets arrange their poems in three lines with the middle line longer, though some occasionally use 4, 2, or even 1 line.	"['Haiku is now a worldwide phenomenon, yet when people discuss its nature one is soon aware of different perspectives. Some see it mainly as ""a kind of poetry, to be treated as an artistic creation, mouldable"" (George Swede). For others, it is a source of philosophical inspiration and in particular the basis for meditation according to Zen practice; while for still others it is a window onto the Japanese experience. Most serious readers/writers of haiku adopt more than one of these viewpoints.\nThey also debate the extent to which haiku in English should observe the same rules that are taken to apply to haiku in Japan, noting that in the land where haiku was born there have, in fact, not been constant, undisputed rules. (For a more detailed discussion of this, see the companion paper obtainable from the British Haiku Society, ""The Development and Nature of Haiku in Japan"".)\nThus it proves elusive to reach the description of haiku which all those fascinated by the genre can accept without reservation. With this qualification, that in the present time something like the following represents an informed consensus in the West.\nThe criteria by which we recognise and judge haiku are:-\n- their fidelity to \'haiku spirit\'\n- their sense of \'presence\'\n- the success with which images are juxtaposed\n- the appropriateness of the subject matter\n- the poetic taste they display, and\n- the poets sense of proportion in choosing the right form.\nThere is, naturally, interplay between these ingredients, but the evocation of haiku spirit is generally the paramount consideration. For this reason, most dictionary definitions fall far short of the mark, mentioning little more than formal characteristics of haiku that are open to debate.\nThe haiku poet cultivates awareness so that s/he may experience some unusually forceful impact coming from ordinary life or from everyday surroundings. The poet is apt to think of these perceptions as \'haiku moments\', but without any wish to isolate them, for they are part of the continuous flow of experience and may exemplify life on a timeless scale.\nWe use our senses to observe \'haiku moments\'; from which point they are developed, not by ratiocination, but by intuition and a release of emotion. ""Haiku is the poetry of meaningful touch, taste, sound, site and smell""(RH Blyth).\nIn \'haiku spirit\' the poet adopts a self-effacing and faithful attitude towards the object s/he perceives. S/he does not set out to be moralistic or didactic or judgemental. The haiku form has been used successfully to write adages and epigrams, but because the aim of adages and epigrams is to mould opinion they are not haiku in spirit.\nA Sense of Presence\n\'Haiku moments\' come normally from personal experience. The poets task, when recording such perceptions, is to keep them fresh and authentic, as unique events, avoiding generalisations. This does not preclude remembered \'moments\' and a few haiku will even represent composite experience. To preserve a sense of immediacy, present tense is normally used, as if the situation were now. The term \'presence\' is a mnemonic for this poetic stance.\nThe poet may feel that the ideal wording has come immediately. Some of the best haiku occur this way and never change. But many successful haiku result from a long process of draughting and re-writing, during which the poet clings hard to the original perception.\nThe pain is to give readers the means to feel as the poet her/himself felt at the time, or maybe differently, without any explicit (and so directive) statements about actual feelings. Some typical attitudes are humility, serenity, compassion, acceptance of transience and man\'s lonely state, joy in resurgence and company, wonder, wistfulness, as well as humour of a whimsical and sometimes paradoxical kind.\nJuxtaposition of Images\nIt is concrete images, not abstract words, that carry the meaning and create the tension and atmosphere in haiku. Two (or perhaps three) images juxtaposed in a short poem, without a clear syntactical link, allow a possibility of comparison which the haiku poet would aver is more pregnant than the simile.\nHaiku poets (in the West, at least) have an aversion to glaringly inventive metaphors, which they regard as intrusive, obliging the reader to accept the writer\'s personal view. They offend against the \'directness\' which the writer wishes to achieve, ""like jewels on a finger pointing at the moon"". For the same reason, adjectives are sparse in haiku. A good rule might be to avoid descriptions that readers may easily imagine for themselves.\nThe best haiku do not just recreate the \'moment\' pictorially or in a narrative way. They hint at something beyond, they present a movement. This may be an unexpected twist, or it may be a movement in the mind as the images are registered. Haiku are \'open-ended\' or \'half-said things\', so there will be later realisations. ""Haiku shows us what we knew all the time, but did not know we knew"" (RH Blyth).\nSome slight \'innovation of truth\', stopping short of wilful fantasy, may be appropriate:\nthe frost holds:\nFriesians in the byre\nAppropriateness of Subject Matter\nThe traditional subject matter of haiku is the world of nature of which humans are an integral part. Basho (1644-94) advised haiku writers to ""enter into the object, perceiving its delicate life and feeling its feelings, whereupon a poem forms itself"" (tr. Makoto Ueda).\nWe try to avoid projecting human viewpoints into natural things. So as not to humanise (and so patronise) the things of Nature, the English haiku poet is wary of personification and anthropomorphism, even though their use is tolerated in ancient and even modern Japanese poetry. But only the ultra-purist would have difficulty with the level of anthropomorphism expressed in\nSweeping into the pan\nthe narrow line of dust\nthat defies its edge.\n(James W. Hackett)\nJapanese poets, benefiting from a long cultural tradition, usually include a \'season word\' (known as kigo) or a \'seasonal activity\' (kidai) which creates an ambience for the poem. For the Japanese reader, the season word releases a whole schema of more or less predictable associations. This homogeneity of response is not generally available to the western haiku poet to play upon. Nevertheless, haiku in English often do include an image which enables us to see the chosen season in depth as well as detail. This said, the \'seasonless\' haiku is also common in English.\nHaiku writers, like other poets, accept that ""the trained taste and trained ear are an indispensable part of a poets equipment"" (Francis Stillman). Haiku has its own aesthetic but, like any similar set of principles, however long they have commanded respect, they are subject to fashion and change. This applies to some aspects of the aesthetic more than others.\nOne of the most enduring principles, established by Basho in his maturity, is that of \'lightness\' (karumi). This does not mean that haiku are \'light verse\', jokey little squibs, but that that we can accept all life, even its most dismal and gruesome moments, with a mixture of stoicism and serendipity.\nBecause haiku is modest and finds inspiration in everyday life, it prefers ordinary words and straightforward syntax (as we have said, often incomplete). It abjures words, or stylistic features such as inversions, which may seem consciously poetic.\nThe brevity of haiku reflects the shortness of life, but to lead even a brief life to the full we need to \'make space for ourselves\' to \'stand and stare\'. Thus, even as we pursue concision we use a sense of proportion. Haiku, like other forms of poetry, benefit from melody and rhythm.\nOther matters that to some extent are subject to fashion as well as personal taste for the use of enjambment, titles, rhyme, punning, allusion, punctuation, and lay-out. This is not the place to go into great detail about any of these, but a few pointers to practice at the present time may be useful.\nSkilful enjambment is very effective in Haiku, but cutting a 17-syllable sentence into 5-7-5, like some poor worm is not.\nTitles and rhymes are eschewed, but tasteful alliteration, assonance and onomatopoeia are appreciated.\nPuns and other kinds of ambiguity are acceptable, if the double meanings are congruous, of more or less equal interest, and do not over-elaborate the original perception. \'Pivot lines\' (like the second line of this example) are a popular way of doubling the meaning;\nWillow branches bend\nwith the river current\nducks drift backwards\nAllusions were much favoured by Basho, but are riskier these days, when even well-read people do not all read the same works.\nPunctuation - the minimum seems best.\nLay-out - some writers choose one particular lay-out which they find ideal and use it consistently, others choose one of a variety of lay-outs to try to reinforce the mood or movement of the poem.\nSense of Proportion and Appropriate use of Form\nForm is important in haiku, but it depends on much more than a simple pattern of syllables. Even if it were true that all Japanese haiku were composed in 17, the difference between Japanese and English notions of what is a syllable makes it invalid to apply the same formula to haiku in both languages. Also, differences between English and Japanese grammar mean English can often carry the same amount of information in fewer syllables. Using 17 syllables will sometimes result in an overload of information. The scope for ambiguity is also different in the two languages. Finally, English is a stress-timed language which Japanese is not.\nA large number of poets writing haiku in English, possibly the majority, feel that the haiku length of less than 17 syllables is \'natural\', \'sounds right\', and is \'enough for the purpose\'. They may also try to distribute strong beats in a 2-3-2 or 2-2-2 pattern, while taking care to avoid a too regular, jingly iambic pattern. Their method is to listen with the \'poetic ear\' for an effective short utterance that catches the \'haiku moment\' without any redundancy.\nHaiku written in 5-7-5 syllables are sometimes referred to as being in \'strict form\'. Haiku that depart radically from 5-7-5 are often called \'free form\', though one might well prefer the less licentious-sounding terms \'flexible style\' or \'organic style\', where ""form is reinvented for each new poem/experience"" (Mel McClellan).\nedges the cats ear\nFor the brave quester after minimalism who take the view that ""haiku is poetry tending towards silence"" (Martin Lucas), concision is one of the ultimate challenges:\nWhatever number of syllables they may choose to employ, most haiku poets arrange their poems in three lines, probably with the middle line longer than the other two. A few writers, regularly or occasionally, use 4, 2 or even 1 line, and may exceed 17 syllables. Writing a haiku in one line may add to the ways we can read it;\nmy head in the clouds in the lake\nAlthough the four-line form ""tends to reduce the sense of compactness and tension inherent in the Japanese verse form"" (Makoto Ueda), a few writers can use it very skilfully:\nFurther down the cobble beach,\nThe face of another\nLoses its copper glow\nThe best haiku commonly have a more or less obvious caesura at the end of the first or second line (exceptionally, in mid-line somewhere). Like the Japanese, we feel a pleasant sensation of \'balance despite imbalance\', or of \'golden section\', when two lines are pitted against one, or one against two. A caesura may be marked by punctuation, such as a dash. However, haiku as one continuous sentence are also common, as well as other rhetorical arrangements.\nA senryu is identical in shape to haiku, but it lacks the season word and concentrates on human nature.\nWhereas haiku avoid preaching, senryu are essentially moralistic, but most senryu resemble parables more than aphorisms or proverbs. They are pointed in a way that haiku are not, and well designed to puncture pomposity, yet they are not reduced easily to a single extractable moral. They provoke instant recognition (\'I know someone just like that!\'), but even though the target is some individual\'s foible, the aim is not to ostracise, rather - with humanity - to identify those absurdities that all human flesh is heir to, and accept these with an amused shrug.\nIn the West, we now see the development of a more serious, caring type of senryu, at \'the cutting edge\'. These may hint at some form of commitment, but are too understated to be labelled propaganda. They exemplify an issue for consideration:\nthe pork chops\nshaped like Africa\na bodyguard lifts the child\nto see the snow\nAt the present day, senryu and haiku tend to enjoy equal esteem in the West and are not always clearly distinguishable.\nMany writers of haiku respect the Japanese artistic dictum, ""Learn the rules and then throw away the rule book"". Beginners have often found it beneficial to gain some mastery of \'strict\' form before venturing into \'free\' or \'organic\' form.\nThe Basho scholar Makoto Ueda predicts the future development of haiku and senryu: ""As more and more western poets write haiku or haiku-like poems in their languages, Basho\'s influence on them through the haiku form will become diluted, often to the extent that it will disappear from the poetry. That is what is expected; in fact, that is precisely what Basho wished for. He always encouraged his students to cultivate their individual talents rather than to follow him with blind faith.""\nWaning Moon Press thanks the British Haiku Society for permission to publish this paper on the web.', 'The haiku refers to a type of Japanese poetry. Haiku has several elements that you can develop in the poetries of other cultures and languages, though not by slavish imitation. You can get haiku into other languages by getting into the heart of haiku.\nThis is something that relates to Zen practice as well as practiced observation. You should note that free verse, which is a poetic form, exists for several reasons. This includes the desire for simplicity and minimalism in poetry in the face of iambic pentameter, structured poems, and rigid stanza lengths. This article is a beginner’s guide to haiku.\nUnderstanding a haiku poem\nThe question is what is a haiku? Haiku is simply a traditional art form that originated in Japan and focuses on simplicity. There are a lot of limitations that are put on haiku poems, ensuring that there is simplicity.\nYou need three lines that have a rigid syllable count to create this minimalist poetic form. Remember that there is no room for anything else apart from the direct aim of the haiku itself. Modern haiku as well as traditional haiku in translation don’t usually meet the strict syllable count which is closely related to haiku. Instead, the poetic form tends to depend on the removal of ego and the parsing of the self from your poem as a whole.\nTake note that a traditional Japanese haiku poem has 17 syllables that are spread over three lines, in a 5-7-5 pattern. This is a quite rigid and simple way designed to get rid of many elements from the poem so that there is enough space for the concept shown in the poem.\nThis is the reason why nature poems are quite good in the haiku form as they have few words and just seventeen syllables. Therefore, you need to use these to convey an image, a scene, and a sense of depth.\nAs explained above, haiku poems rely on natural images, but there is no limit to the haiku form that you can use to express them. The haiku poetry form tends to match the natural scenes. You should note that traditional Japanese poems usually have the feeling of tranquility and peace found in nature. But you can find other haiku that are written about everyday life or even which upend any idea of the haiku in a poetic form to celebrate stillness.\nThis means that you can decide to write a haiku poem about anything. But it can be hard to extricate a form that is related to the concept of nature poetry for you to cover any topic. If you are not writing about nature’s tranquility or how the tranquility may easily be fractured, you may find it a huge challenge to utilize the haiku to its fullest. This shouldn’t put you off.\nKeep in mind that many schools of haiku don’t accept that it should be utilized for nature poetry. Instead, they believe that you should use haiku to reflect observations about the globe as a whole.\nAlso, you can write haiku about love. They are commonly known as nature poems, but haiku may also cover just about any topic. The crucial thing you should remember is that while writing haiku poetry, you must make the image simple. This means that you should create a universe in a couple of words and leave space in your poetry for your readers to infer or discover themselves.\nYou can also write haiku poems about death. In Japan, death poetry is traditionally written in a tanka rather than as a haiku. Tanka has five lines with 31 syllables and takes the 5-7-5-7-7 pattern. This type tends to have at least half of surviving death poems in Japan, though this doesn’t mean that a haiku is not suitable for dealing with the death concept.\nIt’s worth mentioning that haiku is not a blank verse. It can have a rigid syllable structure, but it doesn’t fit the iambic pentameter structure, which is crucial for writing blank verse. It does depend on the counting of syllables, though not necessarily to match the standard 5-7-5 pattern. Instead, you can utilize the haiku type to explore and present a few words.\nHow to get started writing haiku poetry\nWriting a haiku is a certain form of art, and you can use it to improve your other forms of writing. The main thing in writing great haiku is to remove your ego from the work. And, you need to write a three-line poem or any form that your modern haiku can take. But you should focus on looking at a single image or a single moment as well as rely on the strength of the minimalist image to discover larger concepts or themes.\nYou can decide to title haiku poems, though traditionally, most poems didn’t have a title. Today, many writers, especially those who usually write many haiku poems, find it convenient to title their poems. The title of a poem can usually be utilized to change the poem’s reading, either by motivating the readers to look at a certain image, filling in the missing pieces of the puzzle, or explaining an image that may not be clear right away.\nYou can choose to use punctuation in haiku, but it’s a good idea to avoid punctuation while writing poems. This means that you should also avoid using capital letters. You should always aim at complexity in a simple form. Therefore, anything which can make your haiku poetry look more complex needs to be avoided. This is because it can be hard for people to relate to haiku poems.\nBesides this, haiku can rhyme, but it doesn’t have to. Many haiku poems don’t rhyme for some good reason. The precision needed when writing haiku usually means that any type of rhyme scheme can just get in the way. Worse still, rhyming can sometimes ruin the good pace of your poem, leading your readers through the 3 line poem too fast. As a result, this can cause your readers to lose on several benefits of the imagery that a haiku poem is known to offer.']"	['<urn:uuid:5e56cbea-c523-4b4f-a566-b4bc70f368af>', '<urn:uuid:d6530841-a869-4f50-888b-949bd864e8b3>']	open-ended	direct	concise-and-natural	similar-to-document	three-doc	expert	2025-05-12T22:49:38.933606	12	106	3271
26	underground detectors davis mcdonald neutrino experiments differences operation setup	Ray Davis Jr. and Arthur McDonald used different underground detection methods in their neutrino experiments. Davis's experiment used a 610-ton perchloroethylene detector located 4850 feet deep in the Homestake gold mine, measuring solar neutrinos through chlorine-37 to argon-37 conversion. McDonald's Sudbury Neutrino Observatory (SNO) used multiple detection methods in the same detector to measure both the total number of neutrinos and specifically electron neutrinos, which proved crucial in demonstrating neutrino flavor transformation.	"['Takaaki Kajita and Arthur McDonald win for discovery of the particles\' shape-shifting nature\nOctober 6, 2015 | Emily Conover\nPhotos: ICRR, SNOLAB\nTakaaki Kajita and Arthur McDonald\nThe Nobel Prize in physics was awarded today for the discovery of neutrino oscillations, an observation that revealed the unusual behavior of these misfit particles, and indicated that neutrinos have mass. The prize honored two scientists who were instrumental in making the discovery: Takaaki Kajita of the University of Tokyo, for his work on the Super-Kamiokande experiment, and Arthur McDonald of Queen\'s University, Kingston, Canada, for his work on the Sudbury Neutrino Observatory (SNO) experiment.\n""Hooray for neutrinos — this is the little particle that punches above weight,"" says Michael Turner of the University of Chicago. ""It\'s truly remarkable how much they\'ve taught us about the universe and elementary particles.""\nNeutrinos, which are produced in a variety of nuclear reactions and were once thought to be massless, come in three types — electron, muon, and tau. But we now know that these identities, known as ""flavors,"" are not fixed. In a series of large-scale particle physics experiments performed deep underground, scientists showed that neutrinos oscillate from one flavor to another. ""That really turned neutrino physics on its head,"" says Stephen Parke of Fermilab, because in order for neutrinos to oscillate, they must have mass. Massless particles travel at the speed of light, and therefore can\'t change: according to special relativity, their clocks don\'t tick.\nIn 1998, the Super-Kamiokande experiment saw a telltale signature of oscillation in muon neutrinos that are produced when cosmic rays interact with the Earth\'s atmosphere. Physicists measured the number of muon neutrinos coming from directly overhead, and compared that to the number from below, which traversed a longer path — through the Earth — to reach the detector. They saw a deficit of muon neutrinos from below, indicating conclusively that the neutrinos changed flavor during their long journey.\nWhen Kajita first presented Super-Kamiokande\'s results during a talk in 1998, ""the entire audience realized that the game had just changed,"" says Boris Kayser of Fermilab. ""Until that point the possibility that neutrinos had nonzero masses was speculation. After that point it was fact."" He adds, ""I have never heard more enthusiastic, more prolonged applause for a physics talk than for that one.""\nIn 2001, SNO clinched the case for oscillation in electron neutrinos produced by the sun. SNO used different detection methods in the same detector, including one that measured the total number of neutrinos, and one that measured only electron neutrinos. The scientists saw fewer electron neutrinos than expected, but the total number of neutrinos matched theorists\' predictions, indicating that a flavor change was responsible for the electron neutrino shortage.\nPrevious experiments had shown hints of oscillations, but none that were convincing. ""We just didn\'t have the smoking-gun evidence,"" says Paul Langacker of the Institute for Advanced Study. But SNO and Super-Kamiokande ""cleaned everything up and made it compelling so that every physicist understood that, yes, that\'s what\'s going on.""\nThe precursor experiments included Ray Davis\'s Homestake experiment, which began in the 1960s. Davis\'s measurements of solar electron neutrinos resulted in the vexing ""solar neutrino problem,"" which took decades to sort out. Davis consistently measured only about a third of the number of neutrinos predicted by theorists, most notably John Bahcall. The SNO result definitively clarified this confusing picture — the predicted numbers of neutrinos were indeed born in the sun, but they oscillated into other flavors, making them unobservable in the detector.\n""It was a heroic experimental task to sort everything out,"" says Langacker.\nThe prize honors the leaders of the two collaborations, who worked with their many colleagues to secure the results. On the phone during a press conference announcing the prize, McDonald repeatedly emphasized the contributions of his collaborators, saying, ""There\'s great camaraderie associated with this work.""\n""These are enormous experiments, and they have now given a Nobel Prize to individuals in these experiments. And that is something that hasn\'t happened that often before, "" says Parke. ""I see these two prizes as not only recognizing these two individuals... but I also see it as a recognition of the two teams.""\nMcDonald, an APS fellow, previously won the APS Tom W. Bonner Prize in Nuclear Physics in 2003. Kajita received the APS W.K.H. Panofsky Prize in Experimental Particle Physics in 2002.\nThe discovery of neutrino oscillations, and hence the implication that they have mass, has led physicists to some intriguing puzzles. In the Standard Model of particle physics, neutrinos are massless. ""That tells us that this amazing model we have of how the world works is incomplete and there\'s more to be discovered,"" says Turner. APS President Sam Aronson said, ""The discovery has major bearing on the structure of the universe as well as the physics of the nucleus.""\nThe exact values of the neutrino masses are still unknown, but physicists do know that neutrino masses are oddly tiny — a millions times smaller than the electron mass. Some physicists believe there may be different physics underlying the masses of the neutrinos than of other particles. Massive neutrinos could also be a key to understanding the source of the matter-antimatter imbalance in our universe. And there may be other types of lurking, undetected neutrinos, known as ""sterile"" neutrinos.\n""This is not the end; this is really the beginning,"" says Turner.\nA number of key papers from the two experiments were published in the APS journal Physical Review Letters and are free to read:\nEvidence for Oscillation of Atmospheric Neutrinos\nMeasurement of the Rate of νe + d → p + p +e− Interactions Produced by 8B Solar Neutrinos at the Sudbury Neutrino Observatory\nDirect Evidence for Neutrino Flavor Transformation from Neutral-Current Interactions in the Sudbury Neutrino Observatory\nPhysics published a Nobel Focus article by Philip Ball: Neutrinos Oscillate\nIn 1998 Physics provided a Focus article by PRL Editor Robert Garisto: Neutrinos Have Mass', 'Raymond Davis Jr, who won the 2002 Nobel Prize in Physics for first observing neutrinos emitted from the nuclear-fusion reactions in the core of the Sun, died on 31 May 2006 at his home in Blue Point, New York.\nDavis’s observations of solar neutrinos not only were the first detection of neutrinos from outside the Earth, but they also experimentally demonstrated that the Sun was powered by the fusion of four protons into helium-4. The solar-neutrino flux measured by Davis was about one-third the expected flux based on the thermal energy emitted by the Sun. For many years, this discrepancy was known as the “solar-neutrino puzzle.” It was not a puzzle at all, but the first indication of neutrino flavor oscillations, the conversion of one neutrino species into another during the flight from the solar core to Earth.\nDavis was born in Washington, DC, on 14 October 1914. In 1938 he received a BS in chemistry from the University of Maryland. After a brief period at the Dow Chemical Co, he pursued graduate work at Yale, where he received a PhD in physical chemistry in 1942. In 1945, after completing his World War II military service, Davis joined the Monsanto Chemical Co. Three years later, he joined the chemistry department at the newly established Brookhaven National Laboratory.\nWhen Davis arrived at Brookhaven in 1948, the existence of neutrinos was still speculative. Looking for a challenging problem that could be addressed with physical-chemistry techniques, he decided to develop and construct a chlorine-based neutrino detector that had been described by Bruno Pontecorvo two years earlier. The concept was that neutrinos interacting with chlorine-37 would produce argon-37, an unstable gas that decays with a 35-day half-life. The use of a chlorine-containing liquid target, perchloroethylene (C2Cl4), made the extraction and measurement of even a small number of argon atoms possible.\nAfter some preliminary tests at Brookhaven, Davis proceeded to construct a 4000-liter perchloroethylene detector at the Savannah River reactor in South Carolina. Concurrently, Frederick Reines and Clyde Cowan were installing a liquid-scintillator antineutrino detector there. The absence of neutrino interaction events in Davis’s chlorine detector at the same time that Reines and Cowan were seeing antineutrino interactions in their detector became the first clear indication that neutrinos and antineutrinos are distinct particles with different lepton numbers.\nIn 1958, just as Davis’s Savannah River experiment was ending, Harry Holmgren and R. L. Johnson of the Naval Research Laboratory measured the rate at which 3He and 4He combine to form beryllium-7. Until then it had been assumed that the only significant neutrino-producing channel in the solar fusion reactions was the fusion of two protons to form a deuteron, a positron, and a neutrino. With energies less than 440 keV, such p–p neutrinos were below the threshold of most detectors, especially the chlorine detector. Holmgren and Johnson’s measurement showed that the 7Be formation rate was about 100 times larger than previously assumed; a significant fraction of the solar fusion reactions would thus form 7Be, and some of the 7Be would then combine with a proton to form boron-8. Electron capture by 7Be produces 862-keV neutrinos, and 8B decay gives multi-MeV neutrinos; neutrinos from both reactions are thus above the 812-keV reaction threshold of37Cl. Both William Fowler of Caltech and Alastair Cameron of Atomic Energy of Canada Ltd urged Davis to use his detector to look for neutrinos produced by fusion in the solar core.\nThe question that Davis was about to address, the source of the Sun’s energy, first arose in 1860 when Lord Kelvin challenged the time scales in Charles Darwin’s On the Origin of Species by pointing out that the Sun’s gravitational potential energy could keep Earth warm for only about 30 million years. By the 1930s, with the recognition of the large amount of energy available from nuclear fusion reactions, it had become clear that the Sun was probably powered by the fusion of hydrogen into helium. However, no one had yet experimentally demonstrated that.\nTo shield the detector from cosmic rays, in 1962 Davis moved his Savannah River apparatus to a PPG Industries limestone mine in Barberton, Ohio, that was 2300 feet (700 meters) deep. The lack of a solar-neutrino signal and the high residual cosmic-ray background at Barberton demonstrated that a much larger and much deeper detector was required.\nTogether with John Bahcall, who was carrying out detailed calculations of the solar-neutrino flux and spectrum, Davis persuaded the Brookhaven administration to support and fund the construction of a 610-ton C2Cl4 detector. The Homestake Mining Co agreed in 1965 to excavate an experimental area at 4850 feet (1480 meters) deep in its gold mine in Lead, South Dakota, and so began a unique academic–industrial cooperation that lasted for 35 years.\nThe first Homestake results, announced in 1968, showed that the solar neutrino signal was less than 3 solar neutrino units (1 SNU = 10–36 interactions per target nucleus per second), compared with a predicted rate of about 8 SNU. As soon as those data became available, Pontecorvo speculated that the reduction in observed flux might be due to transitions of electron neutrinos into muon neutrinos (the tau neutrino had not yet been observed). It took almost three decades to experimentally verify Pontecorvo’s astute explanation.\nWhen the Homestake experiment was being designed, the predicted solar neutrino flux was about 30 SNU, or about five conversions of 37Cl to 37Ar per day, and the expected cosmic-ray background in the 610-ton detector was about 1% of that rate. By the time the detector was in operation, the predicted signal had been reduced to 8 SNU, or slightly more than one 37Ar produced per day. The observed signal, 2.5 SNU, corresponded to one 37Ar atom produced every two days, with a cosmic-ray background of about 10% of that signal. Detecting the signal required a series of upgrades and improvements to the argon extraction, sample purification, counting system, and internal calibrations as well as increased rejection of background signals. Those improvements permitted Davis and his team, of which I was a part, to ultimately measure the solar neutrino flux with a statistical precision of 5%.\nIn 1984 Davis retired from Brookhaven and joined the University of Pennsylvania as a research professor. He remained in that position until his death. The experiment, which transferred with him from Brookhaven to Penn in 1984, continued for another 18 years.\nIn addition to the Nobel Prize, Davis received the National Medal of Science, the Wolf Prize, the Pontecorvo Prize, the National Academy of Sciences’ Com-stock Prize, and numerous other honors.\nI collaborated with Davis for many years. Despite his renown, he always remained an extremely kind, well-liked, sensitive, and unusually modest person, happiest in his laboratory or with his family or his experimental collaborators. He will be missed.']"	['<urn:uuid:a0c1893f-f7af-4cd0-b06a-a52f73ae1f17>', '<urn:uuid:37de3b72-ee7d-4c4e-82d2-eddfed61b05b>']	open-ended	direct	long-search-query	distant-from-document	comparison	novice	2025-05-12T22:49:38.933606	9	72	2113
27	robot design factors affecting elderly acceptance assisted living social interaction technology	Several factors influence elderly acceptance of assistive robots, including the robot's appearance, perceived capabilities, and social intelligence. Studies have shown that matching robot appearance and behavior to specific tasks improves human-robot cooperation. Additionally, research indicates that attributing mind-like qualities to robots enhances trustworthiness and empathy, which are essential for creating good rapport between elderly users and artificial agents. The assessment of these factors has been conducted through various methods, including semantic differential scales and questionnaires measuring perceived agency and experience.	['Semantic Differential Scale Method Can Reveal Multi-Dimensional Aspects of Mind Perception\n- 1Graduate School of Engineering Science, Osaka University, Osaka, Japan\n- 2Faculty of Psychology, Doshisha University, Kyoto, Japan\n- 3Graduate School of Engineering, Osaka University, Osaka, Japan\nAs humans, we tend to perceive minds in both living and non-living entities, such as robots. From a questionnaire developed in a previous mind perception study, authors found that perceived minds could be located on two dimensions “experience” and “agency.” This questionnaire allowed the assessment of how we perceive minds of various entities from a multi-dimensional point of view. In this questionnaire, subjects had to evaluate explicit mental capacities of target characters (e.g., capacity to feel hunger). However, we sometimes perceive minds in non-living entities, even though we cannot attribute these evidently biological capacities to the entity. In this study, we performed a large-scale web survey to assess mind perception by using the semantic differential scale method. We revealed that two mind dimensions “emotion” and “intelligence,” respectively, corresponded to the two mind dimensions (experience and agency) proposed in a previous mind perception study. We did this without having to ask about specific mental capacities. We believe that the semantic differential scale is a useful method to assess the dimensions of mind perception especially for non-living entities that are hard to be attributed to biological capacities.\nLegend has it that Saint Francis of Assisi thought that, like humans, all non-human animals, had minds and he communicated with them (Zanker, 2007). It is not only saints who perceive minds in non-human animals but the rest of us often do so on a day-to-day basis in different animals, such as monkeys, dogs, cats, and so on. Mind perception is not limited to living creatures. A wide variety of artificial entities (e.g., interactive robots) and natural phenomenon (e.g., the north wind and the sun in an Aesop’s fable) are sometimes treated as having a mind. This does not, however, mean that people of different ages and cultures share the same type of concept of the mind and the same attitudes toward the mind. For example, some Japanese people, following traditional Japanese conventions, believe that material objects (e.g., dolls and scissors) that have been used for a long time, develop minds and these people often hold a memorial ceremony for these objects when they dispose of them. By contrast, this idea that “inanimate objects have minds” is hard to make sense of in traditional Christian culture because a mind is considered a special gift from God, and artificial entities are denied a mind. Hence, it is important to investigate how we perceive minds in living and non-living entities for the purpose of understanding the diversity of human cultures (Kraft, 1995).\nQuestionnaire assessments are mainly used in the study of mind perception. One of the landmark studies of mind perception, conducted by Gray et al. (2007), used a large-scale web survey to analyze mind perception styles in over 2000 respondents. In this study, subjects were asked to rate the degree to which each of the 18 mental capacities (e.g., capacity to feel hunger) was suitable for explaining each of the 13 target characters (e.g., adult males, infants, dogs, and gods) on a 5-point Likert scale. The result of the study was that two orthogonal mind dimensions, named “experience” and “agency,” respectively, were found by principle component analyses (PCA). The dimension of “experience” indicates the capacity to sense and feel emotions, whereas the dimension of “agency” indicates the capacity to plan and execute intentional actions. For example, according to Gray et al.’s survey, we perceive strong “experience” but not “agency” in babies and other animals; on the contrary, we perceive “agency” but not “experience” in robots and gods. The multi-dimensional views of mind perception have been confirmed by other studies and several derivative findings, leading to the agreement that this is a good framework for explaining psychological phenomena, such as the “uncanny valley” and cognitive distortions of psychiatric disorders (Gray et al., 2011; Gray and Wegner, 2012).\nAlthough the two mind dimensions proposed by Gray and colleagues are insightful, it is not easy to apply the questionnaire they used to measure mind perception toward non-living entities, e.g., robots. In their questionnaire, subjects were instructed to rate the degree to which a mental (biological) capacity was matched with a character. For example, subjects were asked “To what degree does a robot have a capacity to feel hunger?” The questionnaire, however, does not differentiate between what impression we have of and what we know about an entity. The subjects’ rating may be heavily influenced by their prior knowledge about robots, e.g., knowledge that robots are not capable of feeling hunger. To differentiate between what we mean by “impression” and “knowledge” of an entity, imagine the case in which a person meets a human-like android and has a strong first impression that the android feels hunger. In this case, one may perceive a mind in the android. At the same time, however, one knows that the android is a machine and does not have the capacity to feel hunger. This knowledge may prevent a person from forming a spontaneous mind perception. Most items included in Gray and colleagues’ questionnaire are concerned with mental capacities that only biological entities have. Subjects arguably have knowledge that these capacities are not implemented in non-living entities, and are forced to answer the questionnaire in a biased way. Sometimes we inevitably form an impression of an object and we assume the behavior comes from a mind. Hence, we need to exclude the effects of prior knowledge to investigate mind perception toward non-living entities, insofar as mind perception is associated with impression. The questionnaire used by Gray et al. is designed to measure one’s general conceptions of mental capacities of entities. A different questionnaire may be appropriate for assessing our mind perception.\nWe suggest that a semantic differential scale method could reveal multidimensional aspects of mind perception (Bradley and Lang, 1994). This scale does not include questions concerning mental capacities and is capable of assessing subject’s non-verbal impressions of various objects, events, and concepts on the basis of how they rate the matching between multiple adjectives and entities. In this method, an adjective is paired with its antonym and the two adjectives are assigned numbers on a scale. For example, “cold” is paired with “warm,” and they are given 1 and 7, respectively. Subjects were asked to evaluate where an entity is placed on the scale. In a previous study, we found that mind perception varies along two mind dimensions by using a questionnaire that included 21 paired-adjectives (Takahashi et al., 2014). The questionnaire we used was limited in generality and target; it mainly focused on brain activities in mind perception. The sample size in this previous study was small (n = 20) and the mean age of sample (university students) was a little biased. More importantly, we did not show that the two dimensions we found (i.e., mind-holderness and mind-readerness) corresponded to the two dimensions of “experience” and “agency” introduced by Gray and colleagues. By showing that the former dimensions correspond to the latter, we propose that our semantic differential scale is an effective way to detect the dimensions of “agency” and “experience” of mind perception.\nIn the current study, we performed a large-scale web survey in subjects of varying ages to generalize the two dimensions of our questionnaire. In this survey, subjects evaluated seven target characters by both the questionnaires of Gray et al. (2007) and of Takahashi et al. (2014). The results of the study suggest that the two dimensions found in our questionnaire correspond to the two mind dimensions of “experience” and “agency.” Our semantic differential scale can therefore be regarded as an effective way to intuitively assess multidimensional aspects of mind perception without asking questions about evident mental capacities.\nMaterials and Methods\nFive hundred healthy Japanese subjects were recruited through an Internet survey service (Cross Marketing Co., Japan). The ages of subjects were uniformly distributed in the range of 17–75 years (mean = 45.0, SD = 18.9) and the gender ratio of subjects were equally divided regardless of their ages. This study was carried out with written informed consent from all subjects in accordance with the Declaration of Helsinki.\nSubjects were asked to evaluate mind capacities and impressions of seven targets, respectively (an adult friend, a baby, a frog, a tree, a communication robot, a super computer and a god) by using both the questionnaires by Gray et al. (2007) and by Takahashi et al. (2014) on the internet website specially designed for this survey. Information of these targets was presented only using words, without pictures and the orders of the target presentation were randomized among subjects. In the questionnaire used by Gray et al. (2007), the measurement included 18 questions and subjects rated the degree to which eighteen mental capacities were suitable to explain the capacity of a target character on a 5-point Likert scale where 1 was “not suitable” and 5 was “very suitable.” In the questionnaire used in Takahashi et al. (2014), 21 pairs of two opposing adjectives were presented and subjects rated on a 7-point Likert scale ranging from 1 (a left side adjective is well matched) to 7 (a right side adjective is well matched) to express the suitable impression of target characters.\nWe performed a PCA for rating scores of the two questionnaires to identify dimensions of each. PCA is a statistical procedure for an orthogonal transformation to convert a set of original multidimensional data into small number of orthogonal factors called principal components (details are seen in Holand, 2008). This method is suitable to extract specific factors related to mind perception from multiple questions in questionnaires. We found two factors with eigenvalues over 1.0 in the questionnaire by Gray et al. (2007), a factor corresponding to “Experience” (eigenvalue = 11.4) accounted for 63.4% and a second factor, “Agency” (eigenvalue = 2.2), accounted for 12.3% of the variance (detail loads of questions in each component are reported in Table 1). Furthermore, three factors with eigenvalues over 1.0 were found in the questionnaire used by Takahashi et al. (2014) a factor named “Emotion” (eigenvalue = 11.6) accounted for 55.1% of the variance, a second factor named “intelligence” (eigenvalue = 3.0), accounted for 14.3% of the variance and a third factor (eigenvalue = 1.0), accounted for 4.9% of the variance (detail loads of questions in each component are reported in Table 2). Results of semantic differential scale methods are often compressed into three components by using factor analysis. However, there were no significant correlations between this third component and the other two components in Gray et al. (2007). Hence, we do not discuss the third component in this paper.\nTABLE 1. Two components in Takahashi et al., 2014 (eigenvalues over 1.0).\nTABLE 2. Three components in Takahashi et al., 2014 (eigenvalues over 1.0).\nWe plotted mean scores of the PCA of the two questionnaires (Figure 1). We found that the locations of all characters in the two dimensions were similar between the two questionnaires. We calculated the correlation coefficients between “experience” and “emotion” and between “agency” and “intelligence,” respectively. Both values are positive and stochastic (“experience” and “emotion” r = 0.80, p < 0.00001, “experience” and “emotion” r = 0.75, p < 0.00001) and we concluded that the two dimensions revealed by the semantic differential scale method were similar to the two dimensions revealed from questions about mental capacities.\nFurthermore, we investigated whether subject’s ages were correlated with these PCA components in each target and we found there were no significant correlations between ages and any dimensions of mind perception.\nIn this study, we directly compared two different types of questionnaires used for assessing mind perception. One asked about mental capacities and the other asked about impressions of targets by using the semantic differential scale method. From our results, we suggest that the two mind dimensions “emotion” and “intelligence” revealed in our questionnaire correspond to the dimensions “experience” and “agency” in Gray et al. (2007) questionnaire. This means that we can assesses mind perception without asking questions about mental capacities but by using the semantic differential scale method.\nWe consider the semantic differential scale method useful, especially when it comes to assessing multidimensional aspects of mind perception for artificial agents such as robots that are difficult to attribute mental (biological) capacities to but that we sometimes feel have a mind. Various new types of robots are being developed that are expected to communicate with us as living partners (Imai et al., 2003). We also know that attributing minds to inanimate agents improves trustworthiness and empathy toward these agents (Riek et al., 2009; Harrison and Hall, 2010; Waytz et al., 2014). These social emotions are essential to creating a good rapport between human and artificial agents. Hence, when we develop a social agent, it is important to evaluate how people perceive the mind in the agent. As our questionnaire does not include questions about mental capacities, our questionnaire can be broadly applied to the assessment of mind perception for various agents in human-robot or human-agent interaction studies.\nOur study can be considered a Japanese retest of Gray et al. (2007) mind perception survey. Although the results obtained by Gray et al. (2007) and our results are relatively similar, results in artificial, inanimate objects were different between these two surveys. In our study, scores of “agency” (intelligence) in robots and super computers are higher than those in adult humans. Contrastingly, the scores of agency in robots were underestimated in Gray et al. (2007, 2011). We hypothesize that Japanese people might attribute stronger agency (intelligence) to artificial entities when compared to westerners. In some cultures, including Japan, people tend to believe non-living things have a mind, even if these things cannot be attributed to evident biological capacities. Furthermore, regardless of culture, young children tend to attribute mental states to non-living entities. For example, many children treat stuffed animals as their friends (Moriguchi et al., 2015). Moreover, some children have invisible friends called “imaginary companions” and communicate with them much like with actual human friends (Moriguchi and Shinohara, 2012). These beliefs about minds in non-living entities are often called “animism” (Harvey, 2005). Animism is the cultural attitude toward nature and external objects. Hence, this concept is strongly linked to views of life and religions in various cultures and the assessment of mind perception is quite important to understand cultural difference of these views. However, the sense of animacy is intuitive feeling and this sense cannot be explained logically. Therefore, the questionnaire that directly asks about mental capacities might not be appropriate for the assessment of mind perception in animism culture. We believe that the assessment of mind perception by using the semantic differential scale method is an intuitive way to assess subject’s impressions and this method is suitable to assess mind perception universally regardless of cultural differences. Further, because the abilities for processing other’s mind are often distorted in various psychiatric disorders (e.g., schizophrenia), our intuitive method might be useful for assessing these patient’s symptoms (Matsumoto et al., 2015).\nHT, MB, and MA designed the research. HT and MB performed the research. HT wrote this paper.\nThis study was supported by a Grant-in-Aid for Specially Promoted Research (No. 24000012), a Grant-in-Aid for Scientific Research on Innovative Areas “Cognitive Interaction Design, A Model-based Understanding of Communication and its Application to Artifact Design (No. 4601)” (No.15H01618), rant-in-Aid for Challenging Exploratory Research (No. 26560415).\nConflict of Interest Statement\nThe authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\nThe authors thank Masashi Kasaki for his helpful comments on our manuscript.\nHarrison, M. A., and Hall, A. E. (2010). Anthropomorphism, empathy, and perceived communicative ability vary with phylogenetic relatedness to humans. J. Soc. Evol. Cult. Psychol. 4, 34–48. doi: 10.1037/h0099303\nMatsumoto, Y., Takahashi, H., Murai, T., and Takahashi, H. (2015). Visual processing and social cognition in schizophrenia: relationships among eye movements, biological motion perception, and empathy. Neurosci. Res. 90, 95–100. doi: 10.1016/j.neures.2014.10.011\nMoriguchi, Y., Sakata, Y., Ishibashi, M., and Ishikawa, Y. (2015). Teaching others rule-use improves executive function and prefrontal activations in young children. Front. Psychol. 6:894. doi: 10.3389/fpsyg.2015.00894\nRiek, L. D., Rabinowitch, T. C., Chakrabarti, B., and Robinson, P. (2009). “How anthropomorphism affects empathy toward robots,” in Proceedings of the 4th ACM/IEEE International Conference on Human Robot Interaction (New York, NY: ACM), 245–246.\nTakahashi, H., Terada, K., Morita, T., Suzuki, S., Haji, T., Kozima, H., et al. (2014). Different impressions of other agents obtained through social interaction uniquely modulate dorsal and ventral pathway activities in the social human brain. Cortex 58, 289–300. doi: 10.1016/j.cortex.2014.03.011\nKeywords: mind perception, non-living entities, robots, semantic differential scale method, agency, experience, animism\nCitation: Takahashi H, Ban M and Asada M (2016) Semantic Differential Scale Method Can Reveal Multi-Dimensional Aspects of Mind Perception. Front. Psychol. 7:1717. doi: 10.3389/fpsyg.2016.01717\nReceived: 22 June 2016; Accepted: 18 October 2016;\nPublished: 02 November 2016.\nEdited by:Mohamed Chetouani, Université Pierre et Marie Curie, France\nReviewed by:Kurt Gray, University of North Carolina at Chapel Hill, USA\nAli Oker, Télécom ParisTech, France\nCopyright © 2016 Takahashi, Ban and Asada. This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) or licensor are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.\n*Correspondence: Hideyuki Takahashi, firstname.lastname@example.org', 'OECD, Ageing: Debate the Issues. OECD Insights, OECD Publishing, 2015.\n Pollack M., Intelligent technology for an aging population: the use of AI to assist elders with cognitive impairment, AI Magazine, Volume 26, Number 2, 2005.\n Ezer N., Fisk AD., Rogers WA., More than a servant: self-reported willingness of younger and older adults to having a robot perform interactive and critical tasks in the home. Poster presented at: 53rd Annual Meeting of Human Factors and Ergonomics Society, San Antonio, TX, 2009.\n Broekens J., Heerink M., Rosendal H., Assistive social robots in elderly care: a review, Gerontechnology, Vol.8, No.2, 2009, pp. 94– 103.\n Smarr C., Mitzner T., Beer J., Prakash A., Chen T., Kemp C., Rogers W., Domestic Robots for Older Adults: Attitudes, Preferences, and Potential, Int J Soc Robot, Vol.6, No.2, 2014, pp. 229–247.\n Ziefle M., Calero V.A., Human Aspects of IT for the Aged Population. Aging, Design and User Experience, Springer, 2017.\n Goetz J., Kiesler S., Powers A., Matching robot appearance and behavior to tasks to improve human-robot cooperation. In: Proceedings of the 12th IEIIT Workshop on Robot and Human Interactive Communication (ROMAN 2003), San Francisco, CA, 2003, pp. 55-60.\n Kaplan F., Everyday robotics: robots as everyday objects, In: Proceedings of Soc- Eusai, Grenoble, France, 2005, pp. 59-64.\n Lohse M., Hegel F., Wrede B., Domestic applications for social robots: an online survey on the influence of appearance and capabilities, Journal of Physical Agents, Vol.2, No.2, 2008, pp. 21-32.\n Wu Y., Wrobel J., Cornuet M., Kerhervé H., Damnée S., Rigaud A., Acceptance of an assistive robot in older adults: a mixed-method study of human–robot interaction over a 1- month period in the Living Lab setting, Clinical Interventions in Aging, Vol.9, 2014, pp. 801–811.\n Van der Heijden H., Users acceptance of hedonic information systems, Manag Inf Syst Q, Vol.28, No. 4, 2004, pp. 695-704.\n Broekens J., Heerink M., Rosendal H., Assistive social robots in elderly care: a review, Gerontechnology, Vol.8, No.2, 2009, pp.94– 103.\n Toshiharu M., Shinya H., Hiromichi N., Yo K., Yuki S., Shijie G., Shigeyuki H., Development of a Nursing-Care Assistant Robot RIBA That Can Lift a Human in Its Arms, The 2010 IEEE/RSJ International Conference on Intelligent Robots and Systems, 2010, pp.18-22.\n Graf B., Hans M., Schraft R.D., Care-O-bot II—Development of a Next Generation Robotic Home Assistant, Autonomous Robots, Vol.16, 2004, pp. 193-205.\n Coradeschi S. et al., Human-Computer Systems Interaction: Backgrounds and Applications 3. Advances in Intelligent Systems and Computing, Vol. 300, 2014.\n Wada K., Shibata T., Saito T., Tanie K., Effects of robot assisted activity to elderly people who stay at a health service facility for the aged, In: Proceedings of IROS 2003: The IEEE/RSJ International Conference on Intelligent Robots and Systems, 2003, pp. 2847-2852.\n Ferretti M., Morgavi G., Veruggio G., The ACCEPTABILITY of Caregiver Robots in Elderly People, In Proceedings of the 4th International Conference on Information and Communication Technologies for Ageing Well and e-Health, Vol. 1, 2018, pp. 111-118.\n Giulini MV., Scopelliti M., Fornara F., Elderly people at home: Technological help in everyday activities. Proceedings of the 2005 IEEE international workshop on robots and human interactive communication, 2005, pp. 365–370.\n De Ruyter B., Saini P., Markopoulos P., Van Breemen A., Assessing the effects of building social intelligence in a robotic interface for the home, Interacting with Computers, Vol. 17, No.5, 2005, Pages 522-541\n Ezer N., Fisk A.D., Rogers W.A., Attitudinal and intentional acceptance of domestic robots by younger and older adults. Lecture Notes in Computer Science, 2009, pp. 39–48.']	['<urn:uuid:2c7f1324-3fcd-46f1-a6b1-af724d1d7e41>', '<urn:uuid:26270bf5-ddad-4e56-a6df-5cfa44f9964e>']	factoid	direct	long-search-query	distant-from-document	three-doc	expert	2025-05-12T22:49:38.933606	11	80	3509
28	What prompted the V4 countries to rethink their defense strategy?	The aggression of Russia against Ukraine and the subsequent annexation of Crimea changed the security environment in Europe and made the V4 countries re-think their defense posture. These events provided stimulus for further cooperation among the Visegrád countries.	['The beginnings of a European Army? Only time will tell.\nWe, the Prime Ministers of the Czech Republic, Hungary, Poland and Slovakia, recognize that current security trends in Europe call for even closer regional defence cooperation and multinational programs deeply rooted in NATO and EU policies. The Visegrád Cooperation continues to serve as a platform for coordination of our countries in all European and transatlantic security policy fora.\nIn our statement in October 2013 we tasked our Defence Ministers to deepen defence cooperation among our countries by drafting a Long Term Vision specifying our shared strategic objectives, strengthening cooperation in the field of training and exercises of the armed forces in the V4 format, and creating a framework for an enhanced defence planning cooperation. We thereby endorse the results achieved and, in particular, welcome the adoption of the Long Term Vision this March. The areas of cooperation stipulated in the Long Term Vision, and subsequently identified opportunities for common V4 defence projects and cooperative ventures provide the sufficient foundation for the New Opening in our defence relations. We encourage further efforts in implementing these forward-looking ideas.\nIn accordance with the Long Term Vision and other documents approved during the Hungarian V4 Presidency we are committed to make further progress in our defence cooperation. We will use the recently designed structures to identify areas of practical cooperation and pursue specific projects in the field of defence capability development including joint development projects and military equipment acquisitions. In this process we support the involvement of V4 national defence industries as much as possible. At the same time we are open to cooperation with other partners outside the V4 where and when useful.\nWe will continue preparation for the V4 EU Battlegroup (V4 EU BG) to be on stand-by in the first half of 2016. The Visegrád Battlegroup serves as a linchpin for our defence cooperation in the area of training, exercises and capability development. The current security situation in Europe underlines our intention to link the V4 EU Battlegroup certification exercise with NATO’s Trident Juncture 2015 exercise. Based on the experience gained during the creation of our EU Battlegroup, we see merits in establishing a permanent V4 multinational force.\nWe endorse the commitment of our Defence Ministers to organize annual V4 military exercises starting from 2015 focused also on collective defence according to Article 5 of the North Atlantic Treaty. These exercises will be essential for our armed forces to remain interoperable. In this context, involvement of other regional partners, as well as the U.S. forces is desirable. This is our contribution to NATO’s Connected Forces Initiative and also supports the implementation of reassurance measures to enhance our collective defence and deterrence.\nThe aggression of Russia against Ukraine and the subsequent annexation of Crimea have changed the security environment in Europe and made us re-think our defence posture. We are determined to actively and substantially contribute to reassurance measures within the Alliance. These events could also provide stimulus for further cooperation. We recognize the increasing importance of Multinational Corps Northeast (MNC NE) in the region. We also welcome the MNC NE framework nations’ work to enhance its operational capabilities and usability as a platform for regional defence cooperation.\nThe V4 brand is already recognized by our Allies and Partners. We are committed to continue our common efforts to be a visible element of the global security environment in line with the EU strategic tasks set up by the European Council in December 2013, as well as part of the “European share” in the transatlantic relations by generating our own creative defence solutions.\nTherefore, we, the Prime Ministers of the Visegrád countries, task our Defence Ministers to further enhance our defence cooperation by:\n– preparing the Action Plan of the V4 defence cooperation during the Slovak Presidency;\n– elaborating the V4 Training and Exercise Strategy during the Slovak Presidency;\n– exploring the possibility of strengthening cooperation among V4 defence industries in the field of research and development and production;\n– exploring options of the common development and procurement project of universal modular tracked platform and wheeled armoured personal carrier;\n– exploring the possibilities of forming a permanent V4 modular force which could be used as a Visegrád contribution to NATO and EU rapid reaction forces as well as in crisis management operations, building on the experience and knowledge gained through the preparation of the V4 EU BG.\nWe, the Prime Ministers of the Visegrád countries, task our Defence Ministers to report back to us at the end of the Slovak V4 Presidency about the progress achieved in these areas.\nFull article: Visegrad Countries May Turn EU Battlegroup into Permanent V4 Rapid Reaction Force (Atlantic Council)']	['<urn:uuid:6ab4c67b-3d16-4aec-996d-fbbd9f4def0c>']	open-ended	direct	concise-and-natural	distant-from-document	single-doc	expert	2025-05-12T22:49:38.933606	10	38	782
29	What are the main differences between how experienced and inexperienced birdwatchers identify rare birds, and what tools should both groups use to improve their bird identification skills?	Experienced and inexperienced birdwatchers approach rare bird identification quite differently. Experienced birdwatchers act like forensic detectives, studying details like size, shape, and 'jizz,' making comparisons with nearby species, taking detailed field notes, and often capturing photographic evidence through digiscoping. They typically alert other birdwatchers quickly and write up their observations promptly. In contrast, inexperienced birdwatchers often struggle with identification, may not recognize a bird's rarity status, and frequently don't take field notes, making it harder to submit detailed descriptions later. However, both groups can improve their identification skills by using essential tools: a good field guide with over 100 species that includes range maps, size indicators, and photos of both male and female birds; and quality binoculars with at least 8x zoom and 25mm lens diameter. When identifying birds, both groups should focus on key aspects like the bird's approximate size, overall shape, prominent field marks, and bill shape.	"['RECENT DECISIONS BY THE ARGYLL BIRD RECORDS COMMITTEE (ABRC):\nJim Dickson will contact the person who submitted the rare bird report by email or phone after the Argyll Bird Records Committee have assessed it. This process can take 2-3 months. If you have not heard about the outcome of your record please contact Jim at [email ] or 01546 603967. Decisions on Scottish and British committee level rarities can also be seen on the SOC and BBRC websites.\nRare Birds to report to the Argyll Rare Bird Recorder\nWhat should you do if you are fortunate to find a rare or unusual species of bird in Argyll?\nJust imagine you have seen something quite rare and exciting but are unsure what to do next. Most people will probably consult a field guide to confirm the bird’s identity. For a minority of people the story ends there, preferring to keep the sighting to themselves. More commonly it is natural to want to share your experience with others and often, if unsure about the bird’s identity, to ask for help. Occasionally finders of rare birds refuse to submit their records on the basis that they are happy with it and that’s all that counts! Unfortunately in this situation, such records cannot be used in any bird recording database and will not be used in bird reports or books. It is interesting that some such individuals have the most ‘incredible’ lists of birds! Other birdwatchers have reported what appear to be perfectly good records, but for some reason never get around to writing them up. As time goes on the ability to write up such a record becomes impaired, especially if no field notes were taken at the time. Unless submitted, these rare bird sightings are lost for ever!\nIt is therefore of the utmost importance to submit your rare birds sightings.\nDetails of all rare bird sightings should be sent in as soon as possible after the sighting to Jim Dickson using the standard rare birds form (a link is at the bottom of this page to the “rare bird record form”). Once you have filled this in, you can email the form along with any jpeg photos and if possible scanned field notes to Jim Dickson. If possible, please scan the filled in form and email it along with any jpeg photos and if possible scanned field notes to Jim Dickson as soon as possible.\nSubmitted records will be judged locally by the Argyll Bird Records Committee (whose members are listed in the latest Argyll Bird Report), sent on to the Scottish Birds Records Committee (SBRC), or sent on to the British Birds Rarities Committee (BBRC), as appropriate. In general any claims of birds belonging to unusual races e.g. the races of Yellow Wagtail (Blue-headed, Grey Headed etc) must be supported by a description and any species not already on the Argyll list will also require a description before being accepted.\nIt has become clear that experienced and inexperienced birdwatchers generally deal with a rare bird sighting in quite different ways. For an experienced birdwatcher, used to finding rare birds, the discovery of such a species usually triggers a response more akin to a forensic detective investigating a crime scene, only a bit more uplifting! Collecting evidence becomes the name of the game where the observer is looking for all sorts of detail and clues to work out the bird’s identity, while being intensely aware that the subject could fly off at any moment! Size, shape and ‘jizz’ are studied. Comparisons are made with nearby species; notes are made on plumage details, specific feathers are studied to try and age or sex the species and calls are described.\nWith the advent of digiscoping, photographic evidence is frequently obtained, often allowing distant birds to be ‘shot for the record’. An experienced birdwatcher will also take good field notes and sketches as well as putting ‘the word out’ to other birdwatchers, often within minutes of the find, to give them the best chance of sharing and confirming the sighting. Ideally such an observer will write up the record while it is still fresh in his or her mind and then e-mail the completed rare bird report form along with jpeg photographs and scanned field notes to the rare bird committee.\nUnderstandably, less experienced and non-birdwatchers are more prone to making mistakes with their identification. They are often unaware of the rarity status of a species seen for the first time and unsure whether a description of their observations is required. Often it is days or weeks later before word of the sighting comes to light, by which time the suspected rarity has long gone! Most people in this situation are usually keen to be helpful and submit their record. However, they often struggle to give a detailed enough description as field notes are rarely taken, and as such, the record is often in danger of not being accepted due to lack of evidence. Nevertheless, in the last few years even inexperienced birdwatchers are sending in photographs that can be very useful where a description is lacking detail. Photographs are also useful for sorting out mistakes. On occasions the description has been relatively good, but the accompanying photograph tells a different story.\nPoints to remember when recording a rare bird in Argyll:\nHave an awareness of which species are rare in Argyll. Species requiring descriptions for the Argyll and Scottish Rare Bird Committees (SRBC) are listed under Rare Bird Species.\nGather as much evidence as possible during the time you had the bird in view, including field notes, sketches, photographs, weather details etc.\nInform others! This may be a neighbour, but also try to contact someone with experience, and phone Jim Dickson 01546 603967 or Paul Daw 01546 886260\nWrite up your observation. Send the record to Jim Dickson, 11 Pipers Road, Cairnbaan, Argyll PA31 8UF, ideally within a day or two of the find.\nIf you are unsure about anything contact Jim or Paul for advice.\nRare birds in an Argyll context includes all those species on the current ABRC (Argyll Rare Birds Committee) and SBRC (Scottish Rare Birds Committee) lists (see below). Also any species or races on the BBRC (British Birds Rarities Committee) list (see BBRC website\nhttp://www.bbrc.org.uk/currentrarespecies.htm and any species not on the current list of species on the Argyll List.\nNo record of any of the species and plumage phases listed below will be published unless adequate supporting details (including a description) are available. In addition, brief details may be requested for occurrences of scarce species not on the list where the circumstances appear to warrant this.\nRare bird reporting form;\nThe list below details rare species whose occurrence in Argyll needs to be fully documented. It is made up of the ABRC list of Argyll rarities and the SBRC list of Scottish rarities (those considered by SBRC marked *) as at January 2011.\nEuropean White-fronted Goose (race albifrons)\nGarganey (lone females/juveniles)\nSurf Scoter (except adult males)\nEurasian Bittern (Bittern)\nGreat White Egret*\nEurasian Spoonbill (Spoonbill)\nLittle Ringed Plover\nAmerican Golden Plover\nRed-necked Phalarope (away from traditional breeding areas)\nLong-tailed Skua (except adult)\nMediterranean Gull (except adult)\nWhite-winged Black Tern*\nLesser Spotted Woodpecker*\nRock Pipit (race littoralis)\nYellow Wagtail (all races)\nPallas’s Leaf Warbler\nGreat Grey Shrike\nCommon Redpoll (all races)\nClick on the link below to access the “Rare Bird Record Form” so you can submit a record', 'This page contains all of the basic information needed to get you started bird watching. The topics covered on this page range from the most common species that you will likely encounter in the field to how to ID a bird.\nBefore you get started trying to see and/or attract birds to your yard, you will first need to fulfill a few basic requirements. The first of which is getting a good field guide.\nHow to choose a field guide\nA field guide is probably the most important things a birder can have with him on a birdwatching expedition, after binoculars. A good field guide is terribly important becuase nothing is harder than seeing a bird that you don\'t recognize and then having to try and remember its physical features the entire rest of the trip until you get home. If you have gone on trips without a field guide and this has happened to you, you will know that it is much easier to look up the bird on the spot while the physical characteristics are still fresh in your mind.\nThe main key to choosing a field guide is choosing the field guide that is right for you. While some field guides, such as the Peterson Field Guide to Birds, have become wildly popular, this guide is not right for everyone. Each birdwatcher has his own preferences on field guides. Personally, I prefer photos of the species instead of paintings, but others may prefer paintings over photos. So the best thing to look for in a field guide is one that you like.\nThe next most important thing to look for is the species included in the book. While some field guides cover only birds in certain regions of the US, most do not. An ordinary field guide covers many species, both from the eastern and western halves of the country. However, when choosing a field guide be sure that it includes birds in your area of the country. You wouldn\'t have a very good field guide if it is for the wrong part of the country. The most helpful field guide in the country would be the worst in the world if it didn\'t include birds for your region.\nAfter checking the range covered by the field guide, check to see what species are covered in the guide. A good field guide should list upwards of 100 species at least. This ensures that not only are you purchasing a field guide that will include common species that you will easily recognize without the aid of a guide, but it will also include a large number of species that you do not know at first sight. The third main key to a good field guide is that it must include many species which you do not recognize easily on your own. This is very important because what good does a field guide that lists 50 species do you if you can easily recognize 30 of those 50? Not very much good at all.\nLook at what information is included with each species. Most larger field guides (200> species) include little information for each species so that they can fit the maximum number of species in the guide. Usually, however, smaller guides (<200 species) include more information with each species. One important point to examine when considering a field guide is male/female differentiation photos. In most (but not all) bird species, the male and female birds look quite different. Does the field guide that you are considering include photos of both the male and female of each species? This is important because some field guide include photos of just the male or just the female. This isn\'t helpful if you see a male Baltimore Oriole but you can\'t identify it in your guide because just a female is pictured in the guide.\nThe \'big guides\' usually try to squeeze by with the mare minimum ammount of info so, as stated before, they can fit the maximum ammount of birds into their book. While extra information is handy, it isn\'t a must. There are a few ""musts"" to look for, though. There are two main points that every field guide should contain for general birding purposes (picture ID not included, because it wouldn\'t be a field guide.without those!). The first is a range map. This will help you decide if you did see the bird you thought you saw, because in birding, rage in everything. While a bird might live in most of your state, it may not live in all of it. The second is a size indicator. If you see a dinky yellow bird, you can rule out the other bird species you may be considering because it is larger than the bird you saw. Make sure the guide is in either English or metric, depending on what you desire.\nDon\'t be fooled by a name! Even though a highly trusted name in birding (ie. Cornell Lab of Ornithology or the National Audubon Society) is on the book, do not think that it will be a great field guide. I once had the opportunity to look at a field guide of a friends. I was naturally impressed because of the name on the book, and I was not dissapointed as I flipped through the book and looked at the high-quality photos and the large number of information listed with each species. My enthusiasm quickly deteriorated when I noticed a major flaw... The photo ID for the White-Crowned Sparrow showed a juvenile bird, which didn\'t have a white crown! I was very dissapointed. The big-time birding organization that published this guide should have known better than to publish a photo of a juvenile for an adult. I know that it is hard for a beginning birder to pick out flaws like this, but it is important to try.\nSumming it up-\nThe main points to look for in a good field guide are:\n- It includes birds in your region.\n- It includes >100 species.\n- Includes good photo ID\'s of both the male and female bird.\n- It includes at least a range map and size indicators for species information.\n- It is a field guide that you like.\nIf you follow this guide and all of the points above have been succesfully met, then chances are good that you will get a good field guide that will work for you.\nNow you have a good field guide, but what comes next? The answer is very simple: binoculars. Every good birdwatcher knows the importance of a high-quality pair of binoculars. That close-up look at the Yellow-Warbler perched 40 feet infront of you is so much more amazing than the view you would ordinarily have without them. The worth of a quality pair of binoculars is also magnified when you are trying to ID that bird that you don\'t recognize. Instead of a distant view of the mystery bird, why not get a close-up view? Chances are you will notice some details that will aid you later in the identification process that you wouldn\'t have noticed without your binoculars. The question is, what do you need to look for in a good pair of binoculars? Just like with a field guide, there are certain features you should look for with any pair of binoculars that you are considering purchasing.\nWhen choosing a pair of binoculars, the first thing you should look for is the level of zoom. Most binoculars display the zoom and lens width on the focus wheel. These two numbers will be displayed in a manner like his: 10x25. Now what do these numbers mean? The first number is the magnification level, so a pair of binoculars with this pair of numbers would have a 10 times zoom level. I would reccomend getting at least a pair of 8x zoom binoculars. Remember, the higher the number the more the zoom.\nThe next most important thing to look for is the lens width. This is the width of the lens at the back side of the binoculars. Using the pair of example numbers above, the lens width would be the second number. Be sure to note that lens width is always listed in millimeters. Thus, the lens width would be 25 millimeters. You may be asking, ""Why is lens width important?"". The answer is simple. The larger the width of the lens, the more light gets through, which results in a brighter image. That is why for birdwatching a large lens width is important. When comparing a pair of binoculars with a 25mm lens to a 50mm lens, the amazing is difference. When testing the two pairs at dusk, the 25mm piar is so dark that it is almost no good. The pair with the 50mm lenses, however, boast a much brighter image, so that you can see quite well at dusk.\nSo, what is the \'best\' zoom level and lens diameter? The answer to that question can only be answered by you. I would reccommend no less than 10x zoom, and I personally prefer a larger lens diameter for brighter images, but those are only my personal opinions. It is best to try out multiple types of binoculars before purchasing them to see what specifications are best for you. Remember to try out not only different zoom levels and lens diameters, but also be sure to try out different brands. Many outdoor gear stores will let you try out binoculars before you make the final decision, which can be extremely helpful when investing in something that can be as pricey as binoculars can be.\nLast but definately not least is the image clarity. Look for a pair of binoculars with sharp images. No one wants a pair of binoculars with an unclear image. As a general rule of thumb, a more expensive pair of binoculars will be more clear than a less expensive one (although this isn\'t always true). Unless you test them before purchasing them, there is really no way of telling how clear they will be. Also be sure to buy a quality brand, not some off brand that you have never heard of.\nSumming it up-\nThe main things to remember when shopping for binoculars are:\n- The zoom level is at least 8x.\n- The lens diameter is at least 25x.\n- Look for a quality brand.\nNot only do you need to keep the above items in mind when shopping for binoculars, but don\'t forget to try out different pairs at the store before you make the final decision. The period of trying out and comparing different pairs can be essential for finding the right pair of binoculars.\nHow to identify a bird\nNow that you are equipped with a field guide and binoculars, you need to learn the skills required to go about identifying the birds you find. While the task may seem pathetically easy since you have a book including photo ID\'s of over 100 bird species, the process actually isn\'t that simple. Let\'s say that you saw a small bird that was mostly gray above and white below with some gray streaks on the chest and a yellow patch on the side and rump. Does this sound like enough information to ID the bird? Actually, for a beginning birdwatcher this examples probably includes more information than he would probably gather on the birds outward appearance. He would more likely take a good look at the bird without trying to remember any specific details about the birds appearance, and hope to recognize a picture of the bird if he happened to come across it in his field guide. But the good news is, there is a much easier approach to identifying a mystery bird.\nWhenever an experienced birdwatcher comes across a bird that is unknown to them, they almost always automatically notice sevral physical as well as environmental and behavioral factors relating to the bird. The first thing you should quickly note is the birds size. Is the bird small like a sparrow or large like a blackbird? This can help you to eliminate many species which are strikingly similar to the one you saw. The bird in the example is about the size of a finch, so you can rule out all larger or smaller birds.\nAfter quickly noting the approximate size of the bird, take a look at the overall shape of the bird. Many times, by shape alone you can rule out similar species. Most birds in the same family are shaped basically the same way. After you get some practice you will be able to tell what family a bird is in just by looking at the shape of it. This can be a great time saver and make the task of identifying the bird much easier. For instance, if the bird is shaped like a finch then you can automatically rule out all other families of birds, which makes the process a whole lot easier. The bird in the example is shaped like a warbler, so you can eliminate all other bird families.\nNow that you have assessed the size and shape of the bird, it is finally time to look at the field marks. Field marks are basically just any markings on the bird that are prominent and easy to remember. On the bird in the example the most prominent field marks that you should note would be an overall gray back, white throat, a black-streaked breast, and a white belly. The bird also has bright yellow patches on the flanks and rump, and a short tail. With those notes in mind, you can remove all birds of a different color from the possibilities list (plus birds with long tails).\nThis next step is extremely helpful when deciding what family a bird belongs to. Take a look at the shape of the bill. Is it short and stout? Long and slender? Short and slender? Just this little piece of information can give you an entirely new way of looking at the species. With this information you can tell what the bird eats, and also aid in, as said before, deciding which family the bird belongs to. With the bird in the example, the bill would be short and slender, which tells us two things. First, the bird\'s diet consists mostly of insects, and second, this also supports the belief that the bird is in the warbler family, which brings us to the final steps of the identification process.\nTake a moment to look around you. What habitat is the bird in? At the edge of a forest, in an open grassland, or at the city park? This small piece of information can rule out many species which may appear similar otherwise, simply because they are not found in the same habitat as this bird was seen in. The example bird was found in the forest around dense undergowth. This further supports the belief that the bird is in the warbler family.\nLast but not least, if the bird is singing or calling, try to remember the song or calls so that when you have the bird narrowed down to just two or three species you can compare song and call recordings to help differentiate between the species you saw and the look-alikes. Often (but not always) the songs of birds vary greatly, even among birds in the same family. Oh, one last thing. If you haven\'t figured out what the example bird is yer, the answer is a female yellow-rumped warbler.\nSumming it up-\nThe main points to look for when trying to ID a bird are:\n- Approximate size.\n- Overall shape of the bird.\n- Prominent field marks.\n- Shape of the bill.\nIf you keep these things in mind when looking at a bird you will need to identify later on, the actual identifying process will be much easier than it would without this information.\nThe Parts of a Bird-\nMost Common Ohio Birds-\nNow that you have the basic knowledge you need to identify a bird, a short list of Ohio\'s most common bird species has been compiled below. There is a photo ID for both the male and female of both species. This list will help you \'get off the ground\' by helping you learn what the common birds of Ohio look like. The male of each species is pictured first, and the female second. If there is only one photo for a species, then the male and female of that species look alike.\n*Though male and female American Robins are not identical, a photo for the female has been omitted because the only difference is the shade of red on the breast and belly feathers.\nAll bird photos above from the Wikimedia Commons\nDid you know?\n- The Bald Eagle became the national bird on June 20th, 1782.\n- Many people, most notably Benjamin Franklin, thought that the Wild Turkey was a more fitting national bird.\n- The Bald Eagle only beat the Wild Turkey by one vote in the race for national bird.\nOhio\'s State Bird-\nDid you know?\n- The Northern Cardinal was adopted as Ohio\'s state bird in 1933.\n- The Northern Cardinal is the state bird of seven states, but Ohio was the third state to adopt it as it\'s state bird.\n- While male cardinals are entirely bright red with a black mask, female cardinals lack the brilliant colors and are mostly a drab brown with some pink or red highlights on the wings, crest, and tail.']"	['<urn:uuid:df2941bc-3249-4e0c-acd6-13d56eb6f5ab>', '<urn:uuid:e1e9e87b-ea47-463e-96d1-9b6942b71c94>']	open-ended	direct	verbose-and-natural	similar-to-document	multi-aspect	novice	2025-05-12T22:49:38.933606	27	149	4174
30	reflection researcher wondering if plane mirror images reversed which direction top bottom left right	Images in a plane mirror are reversed left and right but are not reversed top and bottom. For example, when a person uses their left hand, their mirror image appears to use the right hand.	"[""Is this a picture of one girl in front of a mirror or is this a picture of twins designed to look like a mirror image? The writing on the shirt is properly mirror reversed, and, as in plane mirror images, the right hand of the object becomes the left hand of the image. However, if you look closely, you will see that in the picture one girl is wearing a ring and the other isn’t.\nImage in a Plane Mirror\nThe sketch below shows how we see an image in a plane mirror. Plane mirrors work because the light rays create a virtual image behind the mirror. Light rays from the object strike the mirror and reflect according to the law of reflection. When some of the light rays enter our eye, our eye and brain interpret these rays as having traveled in a straight line path. Therefore, our eye and brain track the light rays backward to a position from which they appear to have come. At this position, we see an image.\nIn a plane mirror, the image will be the same size as the object and will be the same distance behind the mirror as the object is in front of the mirror. This image is called a virtual image because the light does not actually pass through the image.\nExample Problem: A person 1.80 m tall stands in front of a plane mirror. What is the minimum height of the mirror, and how high must its lower edge be above the floor for the person to be able to see his/her whole body? Assume the person’s eyes are 6.0 cm below the top of the head.\nSolution: The law of reflection tells us that the angle of incidence equals the angle of reflection. From this, we know that the light ray leaving the person's toes will strike the mirror halfway between his toes and his eyes. The distance from the person’s toes to eyes is 1.74 m, so the bottom of the mirror must be 0.87 m above the floor. The light ray that leaves the top of the person’s head and reflects from the mirror into his eyes must strike the mirror 3.0 cm below the top of his head.\nTherefore, the top of the mirror is 1.77 m above the floor and the bottom of the mirror is 0.87 m above the floor. The height of the mirror is .\nIt doesn’t take much analysis to recognize that the distance the person stands from the mirror does NOT affect the results. If you can’t see your feet in a mirror, getting closer or farther away from the mirror won’t make any difference.\nWhen you look at an image of yourself in a plane mirror, there are some differences that are apparent. In the image below, you see a woman cleaning a mirror. The object woman has the cleaning cloth in her left hand. The image woman, however, is holding the cleaning cloth in her right hand. Images in a plane mirror are reversed left and right but are not reversed top and bottom.\n- Our eye and brain interpret any light rays that enter an eye as having traveled in a straight line path.\n- For a plane mirror, the image will be the same size as the object and will be the same distance behind the mirror as the object is in front of the mirror.\n- Since the light forming the image does not pass through the image, it is called a virtual image.\n- Images in a plane mirror are reversed left and right but are not reversed top and bottom.\nFollow up questions:\n- Who is the movie star whose photo appears in the video?\n- Are the images in the plane mirror upside down?\n- Are the images in the plane mirror reversed left and right?\nA virtual image is one:\n- toward which light rays converge but do not pass through.\n- from which light rays diverge but do not pass through.\n- from which light rays diverge as they pass through.\n- toward which light rays converge and pass through.\n- with a ray normal to a mirror passing through.\nAn object is 2.0 m in front of a plane mirror. Its image is:\n- virtual, inverted, and 2.0 m behind the mirror.\n- virtual, inverted, and 2.0 m in front of the mirror.\n- virtual, erect, and 2.0 m in front of the mirror.\n- real, erect, and 2.0 m behind the mirror.\n- virtual, erect, and 2.0 m behind the mirror.\nIf the angle of incidence for an object and a plane mirror is 30°, what is the angle between the object and its image?\nIf the angle of a car’s windshield is 45° to vertical, what position of the sun is most likely to reflect into oncoming driver’s eyes?\n- Low in the sky behind the oncoming driver’s car\n- Low in the sky opposite the oncoming driver’s car\n- Directly overhead\nA 50. cm tall object is 3.0 m from a plane mirror.\n- How tall will the image be?\n- How far from the mirror will the image be?\n- Will the image be real or virtual?\n- Will the image be upright or inverted?\nWhich statement is true about the image produced by a plane mirror?\n- It appears to be located on the same side of the mirror as the object.\n- It appears to be larger than the object.\n- It appears to be inverted relative to the object.\n- It appears to be reversed left and right.\n- A light ray strikes a plane mirror at an angle of 80° to the normal. What is the angle that the reflected ray makes with the surface of the mirror?\n- A laser beam strikes a plane mirror with an angle of incidence of 38°. What is the angle between the incident beam and the reflected beam?""]"	['<urn:uuid:4c098326-058f-4718-8b4a-782f98cdf37f>']	factoid	with-premise	long-search-query	similar-to-document	single-doc	expert	2025-05-12T22:49:38.933606	14	35	998
31	Which is more significant in religious texts: Laylat ul Qadr or Navratri?	Both nights hold great religious significance, but Laylat ul Qadr has special prominence in religious texts. While Navratri is important in Hindu tradition, Laylat ul Qadr has an entire surah dedicated to it in the Quran, plus six additional verses in Surah Dukhaan. The Quran states that Laylat ul Qadr is 'better than a thousand months' and marks the beginning of Quran's revelation. In contrast, Navratri, while a major nine-day festival celebrating Goddess Durga's victory over evil, is not specifically highlighted in sacred texts to the same degree.	"['Navratri is a nine-day festival dedicated to Goddess Durga. One of the prominent Hindu festivals celebrated in a different region with different names, Navratri holds great significance for the devotees. The word ‘Navratri’ in Sanskrit means ‘nine nights’. For the nine days ‘Nine Forms of Maa Durga\' is worshipped.\nNavratri generally falls four times a year, but only two- Chaitra Navratri (March-April) and Sharad Navratri (September-October) are celebrated widely with grandeur. The Shardiya Navratri celebrated during Autumn is one of the most awaited ones. This year, Shardiya Navrati will commence on October 07, 2021, and end on October 14, 2021. This will be followed by Vijayadashami on October 15, 2021. Shardiya Navratri falls in the auspicious month of Ashwin as per the Hindu calendar. Why the festival is celebrated?\nNavratri or Maha Navratri symbolises the victory of good over evil. For nine long days, Goddess Durga fought the battle with demon king \'Mahishasura\' and killed him, marking the victory of good over evil. Navratri also marks the beginning of the festival season in India, which is followed by Dussehra, Diwali and Bhai Dooj. The nine forms of Goddess Durga\nOn the occasion of the Navratri, the nine forms of Goddess Durga are worshipped, which are collectively known as Navdurga. Each day of the Navratri is dedicated to an incarnation of Ma Durga. The first day is for Mata Shailputri, then Brahmacharini, Chandraghanta, Kushmanda, Skanda Mata, Katyayani, Kaalratri, Mahagauri and Siddhidatri on the ninth day. Each form of Maa Durga is also associated with a specific colour and has a special meaning. Wearing these colours on the specific days of the Navratri is considered auspicious. Here is the significance of each colour of Ma Durga. Day 1: Yellow\nThe festival of Navratri begins with the worship of the form of Goddess Durga, which is Mata Shailputri- the daughter of the mountains. The day is associated with yellow colour which is said to bring brightness, happiness, and cheer in our lives. Shailputri symbolises Mother nature. As per Hindu mythology, she was born after Goddess Sati self-immolated. Hence, she is also known as Parvati. Day 2: Green\nThe second day of Navratri is for the invocation of Goddess Brahmacharini. This day is devoted to the colour green, which is associated with renewal, nature, and energy. Wearing this colour on the second day of Navrati brings growth, harmony and fresh energy into life.\nThe second form of Maa Durga is also believed to govern Lord Mangal, who is the provider of all fortunes. Day 3: Grey\nThe third day is dedicated to the third form of Goddess Durga known as Mata Chandraghanta. The Devi carries the half-moon on her forehead and her favourite colour is grey. Chandraghanta is referred to as the married form of Devi Parvati. This is a dark hue and often associated with negativity, but grey also symbolises zeal and determination to destroy evil. Day 4: Orange\nThe fourth day is dedicated to Goddess Khushmanda, Credited with creating the world with her divine smile. She is also referred to as the ""smiling goddess"". That\'s the reason she is associated with the cheerful colour orange. This colour represents brightness, happiness and positive energy.Day 5: White\nSkandamata is the fifth form if of Goddess Durga that is seen holding Lord Kartikeya in her right arm. Worshipping this form of the Devi also gives the benefit of worshipping Lord Kartikeya. If you want to get more blessing from the deity don a white colour attire on this day, which represents purity, peace and meditation.Day 6: Red\nThe sixth form of Goddess Durga is called Katyayani. She is the most powerful form of Goddess Durgaso as she is also hailed as the warrior-goddess or Bhadrakali. Being once of the fiercest form the Goddess Durga she is represented by the colour red. The hue represents the anger of the Goddess towards the enemies and fearlessness. Day 7: Royal blue\nKalaratri is the seventh avatar of Navdurga. The word Kalaratri means the One who is “the Death of Kaal” and over here it is referred to as death. The Devi\'s immense power is represented by the dark blue colour. This form of Goddess is believed to be the destroyer of all demons and has a dark complexion and a fearless posture. The Royal Blue colour associated with it symbolises immense power. Day 8: Pink\nThe eight-day is dedicated to Goddess Mahagauri. This form of Goddess Durga has the power to fulfil all the desires of her devotees. The one who worships this form of the Devi gets relief from all the sufferings in life. This day is associated with pink colour which represents hope, self-refinement and social upliftment.Day 9: Purple\nThe last day of Navratri is all about worshipping Goddess Siddhidatri. It is made up of two words \'Siddhi\' means supernatural power and \'Dhatri\' means the awarder. This form of the Devi is a giver of knowledge and helps you achieve your aspirations. Hence, the day is associated with the colours purple, which represents ambition and power.', 'Etymologically the word Laylat ul Qadr means the Night of Importance. However, Muslim scholars translate it in many other ways as well. For instance, this night is called as the Night of Decree, Night of Destiny, Night of Forgiveness, Night of Power, and so on and so forth.\nSignificance of Night of Qadr In Holy Quran\nThere are many other significant dates in the Islamic calendar that have been mentioned in the Quran but never have been a whole surah been dedicated for a day. Even, if we see Surah jummah, only three ayats in the final conclusion openly speak about it, the preceding ayats don’t have any mention of Jummah.\nHad it been of any lesser significance, Allah would not reveal an entire surah explaining the value of this night. As a matter of fact, the revelation of the Holy Quran began this night. Hence, this night has great significance. Allah underpins the value of the Night in Surah AL-Qadr, in the following words.\n- Undoubtedly, We sent it down in the blessed and valuable night.\n- And what you know, what the blessed night is?\n- The blessed and valuable Night is better than a thousand months.\n- Therein descend angels and Jibril (the Spirit) by the command of their Lord for every affair.\n- That is all peace till the rising of the dawn.\nMuslims all around the world spend these nights in Rukooh and Sujood. They ask for forgiveness for their sins. They ask for Duas, their unfulfilled wishes. They serve Allah with Ibadah and they serve themselves with loads of Duas. Therefore, Duas are an imperative part of this night.\nAs if the revelation of one surah did not suffice its importance, Allah dedicates six more verses of the beginning of Surah Dukhaan to endorse the importance of this night. The Quran says:\nIn the name of Allah, Most Gracious, Most Merciful.\n- By the Book that makes things clear;-\n- We sent it down during a Blessed Night: for We (ever) wish to warn (against Evil).\n- In the (Night) is made distinct every affair of wisdom,\n- By command, from Our Presence. For We (ever) send (revelations),\n- As Mercy from thy Lord: for He hears and knows (all things).\nWhat Is The Night Of Decree?\nHow To Spend The Last 10 Days Of Ramadan?\nThere are several traditions of duas from Prophet Muhammad (SAWW) which educates us with the importance of this night. Some of them have been mentioned in the points below. May Allah enlighten our hearts with the noor of emaan. Ameen\n↓ 1. Seek Forgiveness:\nThere is also a special link between this night and seeking forgiveness from God. A’isha asked the Prophet, “O Messenger of Allah! If I knew which night is Laylatul-Qadr, what should I say during it?” And he instructed her to say:\nWe also recommend that you go through these Islamic Quotes on Forgiveness.\n↓ 2. Offer Maximum Prayers:\nThe Prophet said: “Whoever prays during the night of Qadr with faith and hoping for its reward will have all of his previous sins forgiven.” (Bukhari and Muslim recorded from Abu Huraira).\nAisha (RA) reported: With the start of the last ten days of Ramadan, the Prophet (SAWW) used to tighten his waist belt (i.e. work harder) and used to pray the whole night, and used to keep his family awake for the prayers. (Bukhari) The nafli prayers are given below\nIbn ‘Uthaymeen said: “A person would attain the reward of the night, even if he has no knowledge of it. This is because the Prophet said ‘whoever stands (in prayer) during Laylatul-Qadr, with faith and hope, will be forgiven,’ and the Prophet did not make knowledge of the night a condition of their forgiveness. And had knowledge of the night become a necessary factor, the Prophet would have made this clear.”\n↓ 3. Ask for Goodness\nThe companion Anas ibn Malik reported: “Ramadan approached, so the Messenger of God said: ‘This month has come to you, and in it there is a night that is better than a thousand months. Whoever is deprived of it is deprived of all goodness, and no one is deprived of its goodness except one who is truly deprived.’ Sunan Ibn Majah, 1644. Here are Islamic Duas For Success That Every Muslim Should Know.\n↓ 4. Stay Energised & Don’t Overeat\nIf you want to stay up the whole night, it’s important that you take a nap either in the day time or after iftar.\n↓ 5. Give Charity\nTry giving a little charity every night because if you give charity on night of qadr, it will be similar to giving it every day for 84 years.\n↓ 6. Read Surah Ikhlas\nTry to read surah ikhlas every day in the last ten days at least three times, because that is equivalent to reading one-third of the Quran. If you get the chance to do this on the night of power, the reward will be multiplied for you.\n↓ 7. Pray Tahajjud\n↓ 8. Do Dhikr\nHere are some dhikr recommendations for laylatul qadr:\n↓ 9. Wake Your Family For Ibadat\nHow Should Menstruating Women Spend Laylatul Qadr?\nSigns of Night of Qadr\nThe Prophet Muhammad (SAWW) is reported to have said that the Night of Qadr is a gentle night and it is not hard, nor cold. It is a comforting night. Then he added, the sun rises on this day with soft rays and reddish complexion. Prophet Muhammad (SAWW) said that the amount of angels sent down on the Night of Qadr dulls the sun because the Arsh/ sky is filled with angels.\nBeing a person of sanity, one may ask how would we know about a night on the basis of the signs during the next day. The Prophet Muhammad (SAWW) explained that this night has been left mysterious, one should therefore never give up hope on the upcoming odd days. This way we\nWhen is Laylat ul Qadr 2020?\nAlthough according to different traditions the night of Qadr may fall in any of the odd dates of the last ten days of Ramadan, meaning it may be, 21st, 23rd, 25th, 27th, and 29th. However, the majority of traditions call the 27th night to be the most probable night. Having said that, according to the Georgian calendar Laylat ul Qadr will be Inshallah on the 19th of May 2020.\nPrayers for Night of Qadr:\nThere are specific namaz/prayers for the Nights of Qadr. In the book, Majmooa-e-oraad-o-wazaaif, authored by Molvi Ismat Ullah Hassan Zai, the following pattern of namaz is given as per the tradition of Messenger of Allah, Muhammad (SAWW).\n|Total number of rakats||Surahs to be recited in every rakat||Recitations after namaz|\n|Surah fatiha proceeded by Surah Qadr||Proceeded by Surah Surah Ikhlaas|\n|21st||Two||Once||Once||Durood shareef 70 times|\n|23rd||Four – two each||Once||Three times||–|\n|25th||Four- two each||Once||Five times||Kalima e Tayyiba 100 times|\n|27th||Twelve-four each||Once||Fifteen times||Recite istaghfaar 70 times|\n|29th||Four- two each||Once||Three times||Surah Al-Inshirah 70 times|\nYou may contact the author in the comment section for any confusion in the prayer procedure.\nMay Allah accept our prayers, forgive us and keep us under His blessings. Ameen']"	['<urn:uuid:ce29f2c2-6aa8-4f98-9d4e-c3cd70109958>', '<urn:uuid:ee24522a-9874-4f88-951a-dd88e8b851fd>']	open-ended	with-premise	concise-and-natural	similar-to-document	comparison	novice	2025-05-12T22:49:38.933606	12	88	2036
32	How long do the ocean eddies last before disappearing?	The eddies usually drift westward and disappear within two years in deep waters in the Gulf of Alaska.	"['|Inside an Eddy|\nWhitneys salinity and temperature measurements in August 1998 showed the waters in Haida-1998 to be to be fresher and warmer than surrounding waters below 100-m depth (see previous page). Above 100 m in depth, both salinity and temperature in the eddy were slightly lower than in surrounding waters. Dynamic height calculations, which use seawater density profiles to determine how high the eddy surface ""sits"" above the surrounding ocean surface, reveal that sea surface in the core of the eddy was 30 cm higher than outside the eddy. This calculation matches the altimetry measurements from TOPEX/Poseidon. Nutrient levels in its thermocline were substantially higher than in surrounding waters. (Here, ""thermocline"" refers to the temperature gradient across the width and depth of the eddy.) The ocean water type of this eddy matches that found near the Queen Charlotte Islands in winter (53°N, 133°W).\nIn February and June 1999, Crawford sent the web-generated images to Whitney at sea on the John P. Tully to direct him to the eddys location for sampling. His measurements taken in September 98, February 99, and June 99 show the steady erosion of the nutrient excess in the eddy waters, and a three-fold enhancement of phytoplankton in the September 1998 samples around the perimeter of the eddy. Whitneys measurements demonstrate that the eddy provided nutrient to a nitrate-starved region of the Gulf of Alaska (Whitney, Wong, and Boyd 1998).\nAccording to Crawford and Whitney, the eddies usually drift westward\nand disappear within two years in deep waters in the Gulf of Alaska.\nThese rotating masses of water average up to a two hundred kilometers in\ndiameter, and a large eddy can contain up to 5,000 cubic kilometers of\nwater, which is about the volume of Lake Michigan.\nThe Canadian Coast Guard Offshore Research & Survey Ship, John P. Tully. (Image courtesy Canadian Coast Guard)\nCrawford notes that in 1999, colleagues of theirs published a paper showing that Sitka and Haida eddies are frequently created in their computer simulations of wind-driven currents along this coast (Melsom 1999). The researchers believe it is baroclinic instability of the coastal flow that triggers the set up of eddies. (""Baroclinic instability"" may occur in a flow in which there are density gradients along surfaces where the pressure is constant. Such instabilities are typically produced in rotating systems where there is ample potential energy being converted into kinetic energy.)\nBased on calculations of dynamic heights of the 100-m surface relative to the 1000-m surface, using archived water property data, two of the highest-elevation eddies were Haida-1998, and Haida-1983, both generated in severe El Niño winters. This finding supports the calculations by Melsom et al. (1999), based on their numerical model.\nSo whats up with these eddies now? By mid-June 2000, new Haida and Sitka eddies had drifted away from shore, and the final remnants of Haida-1998 were merging into the surrounding seas, as shown on the previous page. The eddies of 1999 were weak and by June 2000, had either disappeared or were barely visible. Whitney is senior scientist on another cruise of the John P. Tully to sample Haida-2000 in June 2000. Its position shown in places it over Bowie Seamount, a potential Canadian Marine Protected Area. ""We now have a combined eddy and seamount study, with too little time to sample both,"" says Whitney. The cruise was set up to examine nitrate and iron concentrations in the eddy, and to map their depletion in time and impacts on surrounding biota. He hopes to examine eddy water ""upstream"" of the seamount, and than run a quick survey over the seamount on the way home.\nThe first satellite images solved a previous mystery. Canadian scientists had wondered why Bowie Seamount biota could be so similar to coastal species, when no prevailing currents flowed from shore to the seamount. However, the track of Haida-1998, passing directly over Bowie Seamount, provided the missing link. The eddies had carried coastal species away from shore right to the seamount.\nCherniawsky, J.Y., M.G.G. Foreman and W.R. Crawford, Ocean Tides from TOPEX/ POSEIDON sea level data, submitted to Journal of Atmospheric and Oceanic Technology.\nCrawford, W.R., J.Y. Cherniawsky and M.G.G. Foreman, 2000: Multi-year meanders and eddies in Alaskan Stream as observed by TOPEX/Poseidon altimeter, Geophysical Research Letters, 27(7), 1025-1028.\nCrawford, W.R. and F. Whitney, 1999: Mesoscale eddies aswirl with data in Gulf of Alaska Ocean, EOS, Transactions of the American Geophysical Union, 80(33), 365, 370.\nForeman, M.G.G., W.R. Crawford, J.F.R. Gower, L. Cuypers and V.A. Ballantyne, 1998: Tidal correction of TOPEX/POSEIDON altimetry for seasonal sea surface elevation and current determination off the Pacific Coast of Canada. J. Geophys. Res. 103:(C12) 27,979-27,998.\nForeman, M.G.G. W.R. Crawford, J.Y. Cherniawsky, R.F. Henry, and M. Tarbotton,: A high-resolution assimilating tidal model for the Northeast Pacific Ocean, submitted to J. Geophys. Res.\nGower, J. F. R., and S. Tabata, 1993: Measurement of eddy motion in the northeast Pacific using the Geosat altimeter, in Satellite Remote Sensing of the Oceanic Environment, edited by I. S. F. Jones, Y. Sugimori and R. W. Stewart, pp 375-382, Seibutsu Kenkyusha, Tokyo.\nMelsom, A., S. D. Meyers, H. E. Hurlburt, E. J. Metzger, J. J. O\'Brien, 1999: ENSO effects on Gulf of Alaska eddies, Earth Inter., 3, pap. 001, (Available at http://EarthInteractions.org.)\nTabata, S., 1982: The anticyclonic, baroclinic eddy off Sitka, Alaska, in the Northeast Pacific Ocean, J. Phys. Oceanogr., 12, 1260-1282.\nThomson, R. E., and J. F. R. Gower, 1998: A basin-scale oceanic instability event in the Gulf of Alaska, J. Geophys. Res., 103, 3033-3040.\nWhitney, F. A., C. S. Wong, and P. W. Boyd, 1998: Interannual variability in nitrate supply to surface waters of the Northeast Pacific Ocean, Mar. Ecol. Prog. Ser., 170, 15-23.\n|This schematic shows an idealized eddy in the Gulf of Alaska. ""Isotherms"" are lines connecting points of equal temperature, as on a weather map. Warm, nutrient-rich coastal water spirals clockwise, forming the core of the eddy. Phytoplankton grow in the edges of the eddy near the ocean surface, nourished by the nutrient-rich eddy water. (Image by Robert Simmon)|']"	['<urn:uuid:61c12759-be41-4f56-aaa8-07164ac283e8>']	factoid	with-premise	concise-and-natural	similar-to-document	single-doc	novice	2025-05-12T22:49:38.933606	9	18	1007
33	consequences of satirical art criticizing leaders	Artists who criticized leaders through satire often faced severe consequences. For example, Honoré Daumier was charged with slander for his satirical representations of King Louis-Philippe and sentenced to six months in prison, split between state prison and a mental hospital. Similarly, George Grosz was heavily fined for 'insulting the army' and 'offending public morality'. During the Nazi regime, artists who criticized the political elite risked persecution and work bans, yet many German artists continued to speak out despite these risks.	['Museum der Moderne, Rupertinum, Salzburg\n30 July – 20 November 2016\nby ANNA McNAY\nFollowing the Charlie Hebdo massacre in January 2015, in which 12 people died when the satirical magazine’s office in Paris was attacked by terrorists, and, most recently, the killing of Nahed Hattar, outside a court in Amman where he was being tried for sharing an Isis-themed cartoon on Facebook, the subject of satire as a means of artistic expression is more salient than ever. These events have raised the question of just how far an artist ought to be allowed to go in his exaggeration and mockery of others, as a means of reflecting and questioning – and sometimes even working through – controversial issues of the time.\nDrawing about 200 works from its own collection, the Museum der Moderne in Salzburg has, accordingly, decided to put on a thorough and timely exhibition, exploring this freedom of expression, from the 18th century to the present day. A roll call of powerful critics – William Hogarth (1697-1764), Francisco Goya (1746-1828), Honoré Daumier (1808-79), James Ensor (1860-1949), Otto Dix (1891-1969), George Grosz (1893-1959) and Ronald Searle (1920-2011), to name but a few – and publications, the exhibition offers a rip-roaring ride through turbulent events of politics, religion and gender battles.\nThe artist deservingly most exhibited is Daumier, whose adoption of the newly developed lithographic technique allowed for more speed and mass distribution. During his lifetime, he produced about 4,000 lithographs, 600 drawings and watercolours and 300 paintings. An eight-minute film, Man of his Time (1985), brings together a number of these works as a very successful, informative and entertaining moving image overview of his life and times in Paris, including the French Revolution, the struggle for a republic, the development of the bourgeoisie – a group that never failed to amuse the artist – and new inventions such as the train, which he claimed was “shrinking Europe”. Daumier sold his first drawings to Paris newspapers at the age of 14 and his success, thanks to his outrageous criticisms of the king, brought him confidence. In 1832, however, he was charged with slander for his satirical representations of King Louis-Philippe, and sentenced to six months in prison, two of which he spent in the state prison and four in a mental hospital. Nevertheless, after his release, Daumier continued to criticise the rich and mighty as vociferously as ever, albeit through the creation of fictional characters.\nGrosz, too, was punished for his wit. He was heavily fined for “insulting the army” and “offending public morality”. During the Nazi regime, criticism of the political elite risked both persecution and a ban from working. Nevertheless, German artists took their chances and continued to speak out. Works by Dix and Albin Egger-Lienz (1868-1926) reflect, in turn, the horrors and atrocities of the first world war, and the latter’s Soldier & Death (no date) – very like a Käthe Kollwitz piece – haunts with its hollow, featureless face: shadowy, ghostly and ghastly. Dix, on the other hand, produced a series of 50 etchings, aquatint and drypoints (The War, 1924), from which four etchings are on display, capturing feelings of horror, fear, violence, death, hatred, ugliness and monstrosity. His work shows how satire can be used not only to poke fun at banalities and social differences, but also to help make something horrific and overwhelming somehow palatable – as a means of processing or coming to terms with things.\nOn a more banal level, Searle’s colour etching, Study For An Urban Project (1972), is an “Hommage à Mickey Mouse” and depicts a decrepit, old, crippled, wrinkled, beer-bellied, whiskered Mickey, placed on a plinth in a city square, marked: “Born 19 Sept 1928.” For his ridiculing of the human tendency to glorify the banal, Searle was described by the Swiss writer and painter Friedrich Dürrenmatt as “Jonathan Swift with an artist’s pen”.\nThe most recent work in the exhibition is a site-specific installation by the Romanian artist Dan Perjovschi (b1961, Sibiu), similarly picking up on common banalities in contemporary society. In a David Shrigley-esque manner, he has painted words, comments and pictures on the walls throughout the museum foyer and main hall, with statements such as “from Big Bang to Big Mac” and queries including “Middle Class Have Middle Dreams?”\nGoya is represented by his Los Disparates series (also known as Los Proverbios, 1815-23), which some art historians believe represents Spanish proverbs, but, given the individual titles of the works, handwritten by the artist on the prints, seems more likely to refer to the famous satire The Praise of Folly (1509), by the Dutch scholar Erasmus of Rotterdam (c1466-1536) – a text in which the personification of folly mocks humanity’s foolishness and vices. Goya’s draughtsmanship is simply fantastic, creating grotesque and horrific imagery with tortured expressions and an almost painterly appearance. Hogarth, on the other hand – whose works A Harlot’s Progress (1732) and its masculine counterpart, A Rake’s Progress (1735), as well as the later Marriage-à-la-Mode (1745) are on display – seems far more illustrative, in comparison, but nevertheless captures some equally horrified expressions. His portfolio of six engravings comprising the Marriage-à-la-Mode series pokes a moralising finger at the upper echelons of society, while, in the same section of the exhibition, 14 works by Daumier laugh at the “joys” of marriage and paternity. In a similar frame, Daumier’s Les bas-bleus (The Bluestockings) (1844) mocks the independent-minded woman, who neglected home and children. The name derives from a woman who attended a London salon in the mid-18th century wearing blue stockings instead of black, and became a term used to insult women who were no longer content with their expected role in society.\nCaricatures about the work of artists and art critics have been found in European satirical magazines since around 1830. Daumier’s Les illusions d’artistes (1842) mocks the established Salon, while 88 years later, Karl Rössing’s Raffael and the Bauhaus Disciples (1930) – from a portfolio of 100 woodcuts called My Prejudice Against This Time (published in 1932 in Berlin) – pokes at the same wound. The Exhibition Reviewer (1931), from the same portfolio, is seen on rollerskates, speeding past the works on show with his notebook, while Carry Hauser’s The Art Critic (1920), hanging next door, is seen to be scribbling away, his arm thrust through several canvases – clearly nothing has changed in the respect (or lack thereof) attributed to those of us who in turn comment on the work of artists – we are popular targets of ridicule, also repeatedly shown to be bewildered by the innovations in avant-garde art.\nThere is much to be seen and ingested in this rich and impressive exhibition and even the earliest work still resonates in today’s socio-political climate. Take your time to look around, read the small print, and expect to laugh out loud on more than one occasion.']	['<urn:uuid:014e147c-05df-44ef-94c7-cfcb310d33a9>']	open-ended	direct	short-search-query	distant-from-document	single-doc	expert	2025-05-12T22:49:38.933606	6	80	1144
34	how prepare food safety assessment random audit	To prepare for a Food Safety Assessment (FSA), you should: 1) Be ready for an assessment at any time, 2) Use the EIAO draft tools which show what to expect during the assessment, 3) Review the FSA methodology presentations provided by FSIS, and 4) Make sure your food safety documents (HACCP, SSOPs) are in order since they will be reviewed during the audit.	['What’s an FSA?\nA Food Safety Assessment (FSA), done randomly or in response to a problem, is an audit done by FSIS at federally inspected plants to assure that food safety procedures are effective. According to FSIS, a central goal of the FSA process is to “reduce recalls and enforcement actions by providing valuable information to plants about their food safety systems.”\nAn FSA is done by an FSIS Enforcement Investigations & Analysis Officer (EIAO) who visits your plant to review your food safety documents (HACCP, SSOPs, etc.) and to assess your plant in action.\nCurrent FSIS practice is that every federally-inspected establishment will receive an FSA at least once every 4 years. BUT, an FSA can be justifiably requested at the district level for a long list of reasons, including:\n- Positive (showing pathogens) laboratory findings\n- To determine whether a plant has reassessed its HACCP plan or evaluated its SSOP.\n- Food-borne illness outbreaks, recalls, or consumer complaints.\n- Randomly selected by district office officials.\n1. Be prepared for an FSA at any time.\n2. Ask the EIAO why the FSA is being performed: FSIS does want you to know. You may be completely unaware of “issues” the inspector has communicated to the supervisor.\n3. Request the regulatory basis for all findings made during the FSA. If the EIAO’s explanation is not sufficient, call the FSIS Office of Policy and Program Development (OPPD) in Omaha: (402) 344-5000. OPPD is available to comment on all matters related to the interpretation and application of current agency policy.\nAccording to FSIS, OPPD should be the only FSIS unit contacted to settle disputes related to the interpretation and application of Agency policy. Do not start with your USDA district office. In some cases, a three way call (plant, district office, and OPPD) may help assure agreement on interpretation of regulations.\nHow to prepare for an FSA\nThe “EIAO draft tools,” designed to assist EIAOs in supporting FSA findings, can help you know what to expect during a FSA. The EIAO will use any relevant versions of these tools during an FSA, responding to each question as appropriate.\nFind the tools here: EIAO draft tools\nFSIS has also posted a series of presentations (ppt/pdf) to explain the FSA methodology. Find them here: FSA methodology presentations\nOne Mobile Unit’s FSA experience\nThe Island Grown Farmers Cooperative Mobile Slaughter Unit (Island Grown Farmers Cooperative case study), in Washington State, has gone through two food safety assessments (FSA) since it began operating in 2002: the first in 2008 and the second in 2009.\nThis schedule is unusual in two ways: (1) the first FSA didn’t happen for the first 6 years of operation, and (2) the second happened so soon after the first, when there had been no food safety issues or complaints.\nIGFC passed both FSAs, but the two were very different.\nThe first, done by an EIAO from the USDA Denver office, went quickly. The EIAO spent a day with Barbara Thomas, IGFC’s HACCP Coordinator, going over their HACCP plan and other food safety documents and observing the MSU and plant in action. He wrote his report and then discussed his findings with IGFC, explaining the few changes he required them to make, which were minor. And that was it.\nThe second FSA began in mid-January 2009 and lasted until mid-April. The EIAO, from the USDA office in Bothell, WA, also went over the plans and observed the MSU and plant. He then continued to ask Barbara questions by email multiple times a week for many weeks, all of which she answered meticulously. The EIAO had two main concerns: IGFC’s testing lab and the Sanitary Standard Operating Procedures (SSOPs) for the IGFC cutting room.\nIGFC had been using a lab that had been recommended by USDA and had always done a great job. But the EIAO required IGFC to ramp up its testing program for E.coli 0157:H7, saying that new USDA testing requirements were coming. IGFC’s lab wasn’t able to do the increased testing (the required equipment was too costly). The EIAO strongly encouraged IGFC to do their own testing, in-house.\nBarbara looked into in-house testing and even found a testing kit manufacturer willing to donate the equipment to IGFC so they would only have to buy supplies. One of IGFC’s members, a cheesemaker, had her own lab, extremely clean and sanitary, where IGFC could have done the testing. Yet even with the equipment donated, in-house testing would still cost more using an outside lab, even including shipping.\nFortunately IGFC’s original lab was able to recommend another lab, which has worked out very well.\nThe EIAO was also concerned that the SSOPs for IGFC’s cutting room, which relied on time and temperature to assure product safety, were not adequate. However, Barbara was able to find research done by Dr. Steve Ingham, at the University of Wisconsin, that backed up this method in the specific way IGFC was doing it.\nAdditional concerns were minor, including small wording changes in the plans themselves. Barbara, a careful wordsmith herself, disagreed with a few of these suggestions, but they eventually worked through all of them. “It just takes time,” she says.\nKey lessons for plant operators\n- Always be prepared for an FSA, even if you had one recently.\n- EIAOs are not all alike and may interpret the same regulation differently.\n- Answer each of the EIAO’s questions fully and carefully. Think about everything you write and document it all.\n- If you don’t know the answer, say, “I’m not sure, I’ll get back to you.” And then do your homework.\n- Ask WHY: if you don’t understand an EIAO’s interpretation or requirement, ask for clarification. What is the specific regulation? What is the reasoning behind that regulation? “Because USDA says so” is not good enough.\n- Once you understand the “why,” ask for guidance to solve the problem.\n- Befriend your interlibrary loan librarians – you’ll need their help tracking down all the research papers you need for back up.\n- Call on university extension meat scientists – in your state and beyond. Visit the State Affiliates page on the Niche Meat Processor Assistance Network website.']	['<urn:uuid:6002a4c7-ec53-4d37-81fd-7349eea25663>']	open-ended	with-premise	short-search-query	similar-to-document	single-doc	novice	2025-05-12T22:49:38.933606	7	63	1030
35	boeing 747 shuttle carrier aircraft main cabin modifications for shuttle transport	Boeing removed everything in the main cabin, including the insulation, except the first-class seats for NASA guests. They also added three exterior mounting struts for attaching the shuttle orbiter and strengthened the fuselage interior accordingly.	['With a little help, a space shuttle took to the skies briefly on August 14 in Houston, Texas. Space Shuttle Independence was hoisted by the smallest of Mammoet Holding’s cranes, a 440 ton behemoth stabilized by 980,000 pounds of counterweights (more than the International Space Station would weigh on Earth). As hundreds of onlookers watched, the 171,860 pound (86 ton) replica orbiter gently rose off its mobile transporter and moved into place on the back of the NASA905 Shuttle Carrier Aircraft.\nExpected to open in March 2015, the eight-story tall Shuttle Carrier Aircraft and Independence Complex at Space Center Houston will provide visitors with an unprecedented opportunity to tour inside both a full-size replica shuttle orbiter, and a historic Shuttle Carrier Aircraft. “It will be a one-of-a-kind visitor experience to educate, engage, and inspire the next generation of explorers,” said former shuttle commander and retired USAF Col. Eileen Collins.\nCiting a 2010 economic impact study, University of Houston-Clear Lake President Dr. William Staples said that Space Center Houston provides a $45 million per year impact to the greater Houston area. It is the Official Visitor Center of NASA Johnson Space Center, and is one of Houston’s top tourist attractions. More than 100,000 students and teachers visit Space Center Houston annually. Referring to the Shuttle Carrier Aircraft and orbiter Independence, Staples said “the ‘big draw’ is about to get much bigger. We must be in Texas!”\nTwo Shuttle Carrier Aircraft (SCAs) — heavily modified Boeing 747 airliners – were used during the space shuttle program to transport the shuttle orbiter between NASA centers. Space Center Houston now owns NASA905 (registered N905NA), a Boeing 747-100 acquired in 1974 and originally manufactured for American Airlines. The other Shuttle Carrier Aircraft, NASA911 (N911NA), is a short range model Boeing 747-100SR. NASA911 is also retired and resides at Dryden Aircraft Operations Facility where it serves as a source of parts for Stratospheric Observatory for Infrared Astronomy (SOFIA). NASA905’s engines also went to the SOFIA program, and Space Center Houston is working on sourcing some display engines for its exhibit.\nAmong the modifications required for each Shuttle Carrier Aircraft, Boeing removed everything in the main cabin, including the insulation, except the first-class seats for NASA guests. Additionally:\n- Three exterior mounting struts were added (two aft, one forward) on which the shuttle orbiter is attached, and corresponding interior strengthening of the fuselage was added.\n- The standard horizontal stabilizer was paired with two large vertical stabilizers, one on each end, to improve directional stability.\n- Instrumentation was added for the flight crew and engineers to monitor orbiter electrical loads during ferry flights.\nNASA905 was used for the approach and landing test flights of Space Shuttle Enterprise in 1977. The first SCA to fly, NASA905 logged a total of 11,017 flight hours and ferried shuttles 222 times over 42 years. The aircraft “is the largest artifact from the shuttle program, and played a key part in its development,” according to Dr. Ellen Ochoa, the Director of NASA’s Johnson Space Center. Space Center Houston acquired the aircraft in April after it was painstakingly disassembled by Boeing’s Aircraft On Ground (AOG) team. According to John Elbon, Vice President and General Manager of Space Exploration for Boeing, the team responsible for moving NASA905 from Ellington Field (EFD) to Space Center Houston “had a blast doing it.” They are normally called in to rescue aircraft that have slid off runways or run into similar misfortune, so working on a historic aircraft was special. The team removed the aircraft’s wings, stabilizer and tail cone so it could be moved the eight miles via city streets from Ellington to Space Center Houston and put back together. It is notable that, although the main landing gear beam was cut for transport, the reassembled 747 structure is still flight certified.\nSpace Center Houston has also done extensive work on the orbiter replica Independence after acquiring it June 1, 2012, from Kennedy Space Center Visitors Complex. When completed, visitors will have access to previously restricted areas of the replica, including the mid-deck and flight deck, which is now outfitted with a glass cockpit similar to what the actual orbiters were using by the end of the shuttle program. Exhibits aboard Independence will highlight artifacts from the Space Shuttle Program (SSP) and examples of innovation from the program, as well as focus on science, technology, engineering and math (STEM) initiatives.\nThe Manned Space Flight Education Foundation, Space Center Houston’s non-profit organization, needs to raise an additional $2.2 million of the $12 million for its impressive Shuttle Carrier Aircraft and Shuttle Independence Complex project. Donations can be made by texting “Shuttle747” to 41444 or by visiting Space Center Houston’s web site: spacecenter.org/giving\nMore photos from the event:\nFor more aviation news, visit NYCAviation.com.']	['<urn:uuid:209864db-6688-474d-befa-9b37894a1fea>']	factoid	with-premise	long-search-query	similar-to-document	single-doc	expert	2025-05-12T22:49:38.933606	11	35	795
36	revenue growth american tourists portugal versus pre covid numbers	Tourist revenues from the US market showed an increase of 48% between January and September 2022 compared to the same period of the last pre-pandemic year. In September alone, revenues from the US market grew by 63.7%.	['Portugal occupied Times Square for an hour: Portuguese landscapes took over New York\nThere was a countdown, a message from Cristiano Ronaldo, and sixty minutes of Portuguese landscapes on the main screens in Times Square. Portugal took over the panels of the most famous square in New York this Fridayin an initiative that lasted an hour and which marked the start of a new plan to promote the country in the North American market.\n“This is better than the end of the year”, commented Luís Araújo, president of Turismo de Portugal, at the top of the famous red stairs in the square – where New Year’s Eve is also celebrated. oh call to assume of digital billboards in Times Square, including the important One Times Square (the building with the famous ball at the top), had started a few seconds ago and the feeling was still one of emotion – after a first moment centered on Cristiano Ronaldo, who goes on to figure in wax at Madame Tussauds Museum🇧🇷\nThe new year is still over a month away, but the Portugal tourism is already preparing it and decided to bet on 24 landscapes for this initiative, “with all regions developed during the same period of time”, guarantees Luís Araújo. The head of the national tourist authority does not hide his desire to repeat the success of the Nazaré giant wave videos, presented in 2018, but that did not lead the team to opt for the easy way out. This time, one choice fell on a visually less impactful workbut which has diversity and a sense of community as its greatest assets.\nThe medieval village of Óbidos, Ericeira, the schist village of Cerdeira, Serra da Estrela, Porto (Casa da Música and Serralves), Douro, Lisbon (MAAT, Arco da Rua Augusta and Miradouro Sta. Luzia), Sintra , the Algarve (Praia dos 3 Irmãos and Sete Vales Suspensos) and the Alentejo (Alqueva, wine tourism, Monsaraz and Comporta) are the areas represented in mainland Portugal, to which are added the Azores – with Lagoa das Sete Cidades, Salto do Cabrito, such as Furnas and Praia do Moinho – and Madeira, with Pico Ruivo, Pico do Arieiro and Levada do Larano.\nREACH 500 MILLION PEOPLE\nTo Expresso, Luís Araújou said that, with this promotion of Portugal in the United States, a reach 500 million people worldwide – something that should leverage sales of Portuguese tourism in the North American territory, at a time when it is gaining increasing weight in Portugal.\nUntil September of this year, there was a growth in the number of guests (21.6%) and overnight stays (22.4%), compared to 2019, which made the US market the fourth main source for Portugal and the fifth in terms of overnight stays. With regard to tourist revenues, the market registers in the year (between January and September 2022) an increase of 48% compared to the same period of the last pre-pandemic year. In September alone, revenues from the US market grew by +63.7% and it is this trend that Turismo de Portugal wants to take advantage of, encouraging the acceleration of growth in this market.\nON ALL SCREENS\nNicknamed “Close to US” (taking advantage of the double meaning “Close to us”/“Close to the United States”), the campaign that started this Friday gains a celebrated expression in the coming days, with a strong focus on digital marketing. The idea is to promote Portugal “as an inspiring destination that knows how to receive, demonstrating the privileged geographical position and connectivity” between North America and the country, highlights Turismo de Portugal in a press release.\nAt a time when the number of North Americans in transit is growing – due to the Thanksgiving at the end of the month – and that there is a greater predisposition to book vacations and travel, Portugal will be present in a network of 3,000 digital billboards at airports with direct connections to Portugal🇧🇷 The “Close to US” campaign has an expected impact of 55 million impressions, to which must be added the media impact and views of around 12 million users of JFK, La Guardia and Newark airports🇧🇷']	['<urn:uuid:8fb5820e-160e-49ae-a32e-2f120b97eaf4>']	factoid	direct	long-search-query	distant-from-document	single-doc	expert	2025-05-12T22:49:38.933606	9	37	686
37	Which structure offers more employee independence: formal organizations or matrix organizations?	Matrix organizations offer more employee independence compared to formal organizations. Formal organizations have strict hierarchical structures with complex normative behaviors and official procedures, while matrix organizations promote employee participation in decision-making, remove hierarchical links, and enable staff mobility and internal collaboration within teams.	"['Types of organisation\n|Types of organisation|\n|Methods and techniques|\nThe basic types of organisation are:\n- formal organisation which has complex, normative action and behaviour patterns specific to organization members connected with official procedures, division of labour, hierarchic system and communication methods. Features: official, impersonal, hierarchic, functional specialization, formalization.\n- informal organisation is mostly build from personal and social relationships which will not be determine by regulations or status. Features: action flexibility, direct contact, unlimited duration.\nOrganizations can also be divided into:\n- voluntary organisations – people can voluntarily join or leave them, for instance: foundations, committees, associations,\n- compulsory organisations – separate their members form the society and strictly control adherence to specific behaviour, for instance: prisoners, patients of mental hospitals, soldiers,\n- utilitarian organisations – people join its hierarchic structure because of certain intentions or the future profits which may receive, for instance: companies, education systems, trade unions.\nOrganisation as a system\nOrganisation is the system made up of people and technical resources, materials, whose interaction is characterized by:\n- presence of clearly defined goals of the system,\n- correspondence between the structure and functions of the system,\n- interdependence of the system and its environment,\n- interdependence between system elements,\n- autonomy to decide and direct own actions.\nThe term “organization” comes from Greek word organizo which means to create the harmonious and orderly whole. The organization is formed and developed by people who cooperate in order to achieve established goals. The basic organization components are: people, aims and resources. Organizations with help of employees (people) try to accomplish specific aims, using various resources (strengths and weaknesses of the organization). The organization as specific system, operates in certain environment.\nMeaning of the term organisation\n- As an attribute - special kind of relationship between various elements to each other and to a whole, based on the fact that all parts acts to achieve goals of a whole,\n- As a thing - concrete object having above mentioned attributes (eg. team of people, company, research institute),\n- As a function - activity based on the ability to select, acquire and transform various resources and organizational units themselves towards achieving particular goal.\nCharacteristics of organisations\nEach organization has:\n- common aim specific for whole organization and its employees,\n- border which separates organization from surroundings,\n- leadership which regulates relationships between members and organization structure,\n- organizational culture – values, standards and rules which regulate organization members behaviour, for instance: joining, participation and leaving the organization,\n- organizational structure – internal system and arrangement of organization components,\n- cooperation between certain organization members and organization components for achieving goals.\nAbove mentioned features determine type of organisation and dependencies between elements of complex organizational system.\n- Barnard, C. I., & Thompson, K. (2003). Organization and management: Selected papers (Vol. 7). Psychology Press.\n- Garvin, D. A. (1998). The processes of organization and management. MIT Sloan Management Review, 39(4), 33.\n- Kast, R. E., & Rosenzweig, J. E. (1974). Organization and management. New York.\n- Likert, R. (1967). The human organization: its management and values.\n- Milgrom, P., & Roberts, J. (1992). Organization and management. Englewood Cliffs.\nAuthor: Krzysztof Wozniak', 'The administrative structures\n|Cours||Administration and Public Policy|\n- What is a public administration?\n- Classical authors: Weber, Taylor and Fayol\n- The Swiss Federal Administration: an overview\n- Sociological criticism of the bureaucratic model: Crozier and Friedberg\n- Psychosocial Critics: The School of Human Resources and theories of motivation\n- The administrative structures\n- The Public Service\n- Administration and political decision\n- Administration and Interest Groups\n- Administration and implementation of public policies\n- Auditing public administration: the Court of Auditors within the Geneva system\n- The New Public Management\nWe will see how Weber thought about the structure and now how we see the structure in the light of Weberian light and according to the contributions of Crozier and psychosociological criticism. There are different types of administrative structures and organizations. We will try to see what their limitations and benefits are. The first two types can be described as ideal-typical or building blocks that will be used in the other three types.\n- 1 Organization by function\n- 2 Organisation by product, operation or customer\n- 3 Functional and operational organization\n- 4 Matrix organization\n- 5 Organizing by Process\n- 5.1 Similarities with Objective Based Management (OBM)\n- 5.2 Steps to follow for an organization by process: Thom and Ritz\n- 6 Conclusion\n- 7 Annexes\n- 8 References\nOrganization by function[edit | edit source]\nTwo main ideas govern this type of organization: the idea of specialization, people need to concentrate on a task they master, and the idea of strict hierarchy with a very centralized and pyramid-like view of the organization of public administration. Coordination between departments is done through hierarchical channels. The Directorate-General is responsible for coordinating between the various departments. Very often, it is a mode of organization used for the functional services of public administration:\n- personnel management;\nThe organization by function is often found where functional services are found, but it is possible to imagine a public service organized solely by function with specialties that exercise competence in matters of concern to it. It is a model that is quite similar to the idea of a Weberian ""steel cage"" with specialized people, hierarchies and coordination through the summit.\n- Take advantage of the specialization of tasks: skills, professionalization and standardization. The objective is to give a quality of service that is the same for everyone;\n- reduction of vertical coordination costs: centralisation of the decision by the Directorate-General. The question of coordination is resolved vertically. Consistency in public administration could be more easily guaranteed. In other words, consistency is guaranteed by the decision-making centre;\n- No duplication of work: there is one service that does not duplicate skills in each of the departments and departments.\n- risk of compartmentalization between functional divisions:""baronnies"", selfishness and esprit de corps, there is no overall vision. Everyone is concerned about his or her department and there is no overall view of what is happening in the administration;\n- slow decision-making processes, cumbersome coordination and bottlenecks at the top: especially if there are different points of view between divisions;\n- lack of autonomy and little clear accountability from the various divisions: the risk is that people behave passively and simply do what they are asked to do * lack of generalists;\n- no overall customer vision.\nThrough this model, there is an attempt to deny the political responsibilities of public administration. Only one actor with a political function is the Directorate-General. The three political roles as presented by Bezes are not taken into account. It is a component found in almost all jurisdictions.\nOrganisation by product, operation or customer[edit | edit source]\nA hierarchy remains unique, but below it, there is not more functional service, but on the contrary divisional directorates from which there will be much more autonomy given to managers through operational divisions. The executive management will define broad strategic objectives and within the division, the broad strategic objectives will be translated into more rational objectives. Political power is not confiscated by the Directorate-General, but can also be exercised at the level of the operational division, which can be articulated in four different ways:\n- division by product: division by political object, there is an autonomy to define strategic objectives;\n- division by client: we will create different divisions according to the clients of the public administration. Divisions are no longer organized around a political object, but around the public and public administration in particular;\n- division by region: in some countries administrations, sections or services are available for certain regions;\n- division by process: the divisions will set up a specific process. For example, the budget process must follow a certain number of steps and the division by process will allow the necessary skills to be focused on completing the budget process.\nThe main difference with the organization by function is that there is a given autonomy at the divisional level.\n- relieves management of operational tasks: it can concentrate on the overall policy strategy and leave the division\'s translation of strategic issues into the working method;\n- facilitates coordination and accelerates decision making within each division: this is a division-specific strategy;\n- flexibility for the division manager: adapting to changes in the environment, customer proximity;\n- promotes delegation and performance monitoring;\n- reorganizations without transforming the entire administration.\n- risk of inconsistencies between divisions: too much empowerment of divisions;\n- risk of increased costs: duplication of functional skills, lack of synergies between divisions;\n- lack of consideration of general or transversal problems affecting the whole administration: risk of capture by clients or regional interests. The risk of capture is that the organization or division that is supposed to be working for the public interest, instead of working for the public interest, will work for the particular public it is supposed to be dealing with;\n- possible difficulties linked to the lack of centralisation of the decision: for example, if there is no willingness to cooperate between the divisions and the Directorate-General.\nWhat solutions are being discussed to get out of each of these two types of organization and to reconcile and combine the benefits? How can the advantages of hierarchy be combined with the advantages of autonomy, specialization and a global vision? How can we promote equal treatment by ensuring that public administration is not captured by vested interests in a context where cost and efficiency control is important? We are in a context where the emphasis on effectiveness and efficiency is dominant. Solutions have been proposed to meet this challenge.\nFunctional and operational organization[edit | edit source]\nIt is a type of organization that we find regularly, it is the most frequent. The idea is to say that we are going to introduce central agencies into the public administration that will be in charge of so-called ""functional"" services. One centralized unit will deal with human resources management, another unit will deal with information, etc. managing all the crosscutting elements found in all departments of the public administration.\nCentral services also called ""staff agencies"" will help to provide the necessary support so that people who are closer to the field and can perform their duties. These are services which will ensure cooperation between services which will also be more operational. Staff agencies make sure that the different divisions pull well together, that there is no conflict and that they follow the same objectives. Two functions are important: providing central and necessary services and avoiding operational duplication. A third function is that of ""adviser to the Prince"", adviser to the General Administration. There will also be a business planning function. These functions have been assigned within the framework of this structure assigned to the staff agencies.\nThe operational level is responsible for delivering benefits and is responsible for the day-to-day running of the public service. Staff agencies have a ""back office"" role and those in the field are the line agencies, i. e. those who are in contact with the public. The risk is that everything at the operational division level will be designed according to the business unit model.\nThe risk is that ""staff agencies"" become operational service controllers and will monitor what is happening at the operational level, which could create a barrier to autonomy that should be left to the operational division. There is a risk of significant conflict between staff agencies and line agencies in the field. This risk of conflict arises in the following way: very often,""staff agencies"" will assume that the operational level resists coordination in line with their own interests, and ""line agencies"" would be captive of the public interest. There would be a natural tendency to be spendthrift, to have a corporatist vision of an administration and to be concerned only with its interests. Line agencies that tend to see functional services as being in a form of ""ivory tower"". The ""line agencies"" will call into question the skills of ""staff agencies"" and they will denounce the tendency of ""staff agencies"" to confiscate power.\nThis structure can have drawbacks and limitations in the way public administration structures are managed. Political power is largely reserved for staff management and line agencies. We are in an implementation where operational autonomy is highly regulated.\nMatrix organization[edit | edit source]\nThe idea is to say that we are not going to put a hierarchical link between staff agencies and line agencies, we are putting them on the same level. We will create an organizational matrix, at each intersection, this will give rise to collaborations between the departments concerned. The important point is that there is no hierarchy between the departments that collaborate at the intersection of a row and a column. We are trying to remove the question of hierarchy, which was the problem in the functional and operational organization. The matrix structure offers a less hierarchical organization by interlinking services.\n- A more global view of problems due to the inclusion of diverse points of view: it is a system that makes it possible to reduce the tendency to compartmentalize public administration;\n- fluidity of the structure: avoids the compartmentalisation between management and services and enables innovative solutions to be invented;\n- ability to adapt to customer and competitive requirements;\n- development, staff motivation, internal collaboration within teams, staff mobility: employee participation in decision-making;\n- decisions based on specialist knowledge rather than on the formal authority of the decision-making centre: unloading of central management.\nThe benefits are largely derived from the idea of promoting the idea of autonomy and decompartmentalization of public administration. Disadvantages arise from the same source as advantages.\n- Two-dimensional flow of authority: at a crossroads, the risk is to have two chiefs, there will be no clearly established decision-making responsibility between these two services, one obeys two chiefs. This goes completely against Fayol\'s principles. In the matrix approach, there is a two-dimensional approach to authority whereas in other types of structures, there is only one direction. Thus, there may be contradictory instructions and possible power struggles;\n- conflicts between functional managers and managers by operation, region and project: rejection of responsibilities in the event of failure;\n- slower decision-making process due to the number of people involved;\n- Paradoxically, there is a tendency for more bureaucratization to set up projects and resolve conflicts: the matrix organization, when it fails, can paradoxically lead to a re-bureaucratization of the organization.\nOrganizing by Process[edit | edit source]\nThis model was put forward by two Swiss authors Thom and Ritz in Public Management: innovative Konzepte zur Führung im öffentlichen Sektor, published in 2006, who are trying to find a refined and elaborate mode to answer the previous questions. We are entering a model that is complicated. The idea is to find an organization chart that addresses all of the combined problems in order to exploit their advantages and eliminate their disadvantages. This model has inspired a number of reforms in the Swiss federal administration.\nBeyond the functional, operational, functional-operational or matrix organization: Thom and Ritz will talk about the organization by process. Public administration must be reformed to concentrate forces by identifying central processes (Kernprozesse). Central processes are chains of activities that result from the choices, objectives and strategic missions of the administration. On the other hand, they take into account all the players involved (from upstream suppliers to downstream customers) and define and delineate the clear responsibilities of each actor in the chain.\nSimilarities with Objective Based Management (OBM)[edit | edit source]\nManagement by objective is an idea taken over from management. In The Practice of Management published in 1954, Drucker shows that process organisation will integrate the idea of objective organisation. Organizational management will be organized around the allocation of objectives by providing (quantified) targets to be achieved, by giving employees the opportunity to contribute to the definition of objectives, and by evaluating the results in relation to the objectives set. The idea of organization by process has strong similarities with the idea of direction by objectives. This means giving more operational autonomy to people on the ground.\nSteps to follow for an organization by process: Thom and Ritz[edit | edit source]\nThree steps must be followed in order to find the most appropriate solution to the problems identified.\nDefinition of administration processes according to their usefulness for clients[edit | edit source]\nClients may be internal to government, but most of the time they are external clients. When trying to define administrative processes, three types of processes should be defined:\n- management process: strategic and operational activities. Questions will be asked about how to implement management processes and how to manage them. A general mission will be defined at the political level and operational activities will indicate how this general objective is to be achieved and what instruments are to be used to steer it. The mission must be established by objective agreements that will be signed with the people responsible for implementing the objective agreements.\n- central processes: what are the processes that will be identified as essential? This follows rules with the first criterion being social utility, the second one being non-substitutability, the third criterion being the idea of non-imitability. It is not a question of multiplying central processes, but it is necessary to limit ourselves to a maximum of five central processes. The aim is to analyse the work done in public administration and focus on the achievement of central processes.\n- support processes: these are the supports that will be needed by central processes to ensure that they are properly implemented, such as information technology, law, etc.\nOrganizational structuring of processes[edit | edit source]\nDepending on the functions, complexity and, or clients, they think about how the central processes will be structured. Partial processes can be organized in different ways depending on the client, the complexity of what to do, the functionality and complexity of the tasks.\nResponsible for central process management: managers and their teams[edit | edit source]\nThere are two central characteristics: proximity to the customer  and wide margin of manoeuvre . The diagram describes how the partial processes should be organized. For each of the sub-processes, the idea is to set up teams that will make it possible to achieve the desired objectives as well as possible. What becomes important at the sub-process level is no longer the structure, no longer the organizational chart, but the people and people who must be available to cooperate, versatile, ready to share with others and in teams, there is no hierarchy that can be put in place. There will be a team manager, but not a hierarchy per se. There is the ""job enlargement"" because we broaden the skills and missions and the ""enrichment job"" is the fact of giving people decision making skills in the team concerned, and the ""self-control"", these people would be motivated and will necessarily act and give the best of themselves to achieve these objectives.\n- process speed: direct sequencing of all tasks;\n- reduction of complexity: by the limited number of central processes:\n- customer focus: more strategic and customer-focused;\n- Cost reduction: by eliminating tasks that are not essential to the processes;\n- Improving quality and innovation: through customer orientation.\n- may underestimate the need for specialized knowledge and expertise, as well as the need for competent staff for certain functions;\n- risk of conflict between several (teams of) processes involving the same clients;\n- risk of process overpiloting: with the fiction of continuous optimisation down to the smallest details;\n- too great a reduction in hierarchy: may lead to new conflicts.\nConclusion[edit | edit source]\nThe search for the structure of an ideal administration faces three obstacles that hinder the establishment of an ideal administrative science or administrative structure according to Dahl in The Science of Public Administration: Three Problems, published in 1947:\n- « Writers on public administration often assume that they are snugly insulated from the storms of clashing values [...] The doctrine of efficiency is a case in point » ;\n- « The field of organizational theory serves as an extreme example, for it is there particularly that the nature of man is often lost sight of in the interminable discussions over idealized and abstract organizational forms » ;\n- « There should be no reason for supposing, then, that a principle of public administration has equal validity in every nation-state, or that successful public administration in one country will necessary prove successful in a different social, economic, and political environment ».']"	['<urn:uuid:1ac65655-a101-4638-8031-3a5a1ab8508b>', '<urn:uuid:6dcc71b6-15fb-40c9-88ff-92e99fc490e8>']	factoid	with-premise	concise-and-natural	distant-from-document	comparison	novice	2025-05-12T22:49:38.933606	11	43	3440
38	What changed between old anime dubbing and modern practices?	Early anime dubbing heavily localized content by removing Japanese cultural elements, changing names and locations, and sometimes drastically altering plots, like making a boy the main character in Cardcaptors. Modern dubbing, especially through Disney's handling of Studio Ghibli films, is more respectful - they include original Japanese tracks alongside English dubs, though they still sometimes modify dialogue for American audiences. However, modern dubbing faces challenges with fair voice actor wages and short streaming catalog retention periods.	['This debate crops up with some regularity. First of all, it’s pointless and stupid to tell you which you should prefer. But there are some interesting things about brain science and anime history that can be added to the mix.\nLet’s take a look at the data:\nI’ve had the impression that older anime fans like me were the only ones who preferred subs, but apparently that’s not the case. The International Anime Research Team has been surveying anime fans at conventions and online since 2014, and studying other aspects of fandom as well. They publish the results of their surveys, and wrote a book in 2021: Transported To Another World: The Psychology of Anime Fans that you can download for free. Here’s the result of their question about subs and dubs:\nThat’s a surprise. Over 60% of the people surveyed preferred subtitles. Maybe this is older fans? Nope! They show age data for 2021 Survey (They vary the questions each year):\nSo what’s going on?\nObviously it’s not age or how long you’ve been an anime fan that’s driving this subtitle preference. If you’re over 30 you’re practically invisible. I’m guessing there are fewer older people going to anime cons, but a big draw at most anime cons seems to be meeting the dub voice actors. I suspect their online notices may not be reaching older fans, but there’s no arguing that anime has become a lot more popular in the last few years.\nHere’s my guess: Cons and streaming services want to bring in new people all the time. More people = more profits, and you need new viewers/attendees to replace ones you lose to attrition for various reasons. Even nonprofit cons have to bring in new members or they’ll gradually die out.\nNew and casual fans are less likely to view subtitled anime. They’ll start out with what’s new and popular, that they see promos for, or their friends recommend. Maybe later there might be something more specialized that isn’t dubbed yet, or it never will be dubbed. But the growth for new anime fans is with dubs, so that’s what gets promoted.\nMost of the scientific studies I’ve found are about subtitles for language learning and education, with only a few about watching fiction. None of the studies I’ve seen use anime specifically. Two I found used French or another European language with English subtitles. One hypothesis was that viewers would remember less from a subtitled viewing because their attention was divided between the text and the images. This turned out not to be the case- the first study found that subtitle viewers remembered more about the movie.\nAnother study looked at what viewers remembered, comparing “bridging references” with “outside references”. Bridging references were connections within the film. You might remember that earlier a character said they were afraid of heights, and now they’re faced with the challenge of crossing a swinging rope bridge. Or that bag of money is lost in the park, and later someone chases their frisbee into the bushes and finds a bag. You know it’s the money. “outside references” link to things outside the film. It might be to a trope (in a horror movie, teens that enter the basement one at a time are going to die ) or a symbolic reference (wilted flowers might symbolize a relationship ending, or death). They’re any sort of connection you make to something outside the film.\nThe study found that those who viewed a dubbed version of the film made more outside references, and the subtitle watchers made more bridging references. They didn’t give a reason, but I suspect it’s because the subtitle viewers kept their eyes on the screen more than the dub viewers did. More bridging references means they remembered more about the film.\nI think all of this is mostly because subtitled anime forces you to pay attention to what you’re watching. Maybe the people who prefer subs are getting more out of their viewing experience, even if they’re not consciously aware of it. You can multitask during most English-language series, texting or folding laundry and occasionally checking the screen. You can follow along with the dialog, This is also a reason why shows with complex plots are rare and get canceled on American TV- people can’t follow them.\nHistory of anime subtitles\nIn the old days you had few choices if you wanted to watch anime. Very little came to the US. Most of the commercial releases were “localized” to remove any trace of Japanese-ness. Names and locations were changed and episodes were chopped up or eliminated entirely. To this day, other cultural references to history, Buddhism, Shinto, or Ancestor Veneration routinely are cut or sanitized. In the case of Card Captor Sakura, they edited the show to make the boy the main character in “Cardcaptors.” Many of the dubbed shows sounded like they handed random people the script and said “Here, read this.” Anime was ultra-niche, so the main commercial anime genres were shows for children and ultra-violent ones.\nThe other choice was fan-subtitled works – fansubs. While some were undeniably bad, sometimes hilariously so, some were excellent. One reason for the high-quality ones is that they were totally non-commercial and escaped the “Time is Money” trap. Most fansubbers put in a lot of work, and they wanted to earn a reputation for quality. Their ‘handle’ was their personal brand.\nFansubs could be almost any genre. The down side is that fansub groups often wouldn’t deal with you unless you had shows they wanted for trade. No money changed hands. You mailed them a tape and return postage. If you were lucky there was a university anime club near you, like Animania at University of Michigan, that screened hours of fansubs at their monthly meetings.\nEventually fans pestered Cartoon Network and SciFi to show anime, and we got some stellar dubs like Cowboy Bebop.\nNow in the streaming era with the firehose of new anime, the old “Time is Money” has returned and they don’t want to pay voice actors a fair wage. They also drop most shows from their catalog after a short run, never to be seen again, so if you don’t watch quickly enough you may not get to the end of a series.\nSometimes a dub takes a while to appear. Miyazaki’s Nausicaa was released in 1984, but a dubbed version didn’t appear until 21 years later! (I saw a fansubbed version at an Animania screening in 1993). Totoro was released in 1988, with the Disney dub finally appearing in 2006!\nI’m not sure if Kimagure Orange Road from 1987 was ever dubbed, and that was a big fantasy/romance favorite. It may be one of the many shows that will never receive a dub because there aren’t separate sound/music and voice tracks. That’s a problem for a lot of older shows. And dubbing can be expensive. Nozomi’s kickstarter for dubbing the 26 episodes of Dirty Pair needed $275,000 minimum. The live-action Korean movie Parasite (2019) by Bong Joon-ho apparently hasn’t been dubbed into English either, and it won Academy Awards for Best Picture, Best Director, Best Original Screenplay, and Best International Feature Film.\nThe other factor to consider is that using subtitles is a skill, like playing the violin or ice skating. It’s going to be harder when you first try, just like any new activity, but you’ll get better with practice. Older fans learned to watch subtitles out of necessity, and by now we’re pretty good at it. If you want to learn, avoid shows with fast-paced dialog.\nThe 2nd paper is The Impact of Subtitles on Comprehension of Narrative Film by Mina Lee , Beverly Roskos & David R. Ewoldsen', 'The greatest animation studio in the world, bar none—and yes, that includes Pixar—Japan’s Studio Ghibli is largely dedicated to the work of two brilliant directors, Hayao Miyazaki and Isao Takahata, who co-founded the animation house in 1985 with producer Toshio Suzuki. Thanks to movies like My Neighbor Totoro and Princess Mononoke, as well as a sustained publicity campaign by Ghibli’s U.S. distributor, Disney, Miyazaki’s name is well-known to animation buffs, as well as the parents of many a delighted preteen. Takahata’s work isn’t as well known, in no small part because he hasn’t directed a feature in 13 years. But in the studio’s first decade and a half, the two traded masterworks on a regular basis, working in disparate but complementary styles.\nFor those who have fallen under Ghibli’s spell, it’s difficult to choose a favorite, but for the uninitiated, the obvious starting point is 1988’s My Neighbor Totoro, which perfectly encapsulates the beguiling mystery of Miyazaki’s films. The story is simple: 9-year-old Satsuki and her little sister Mei move to the country with their father to be nearer the hospital that houses their ailing mother. They pass their time investigating the surrounding woods, which turn out to be full of all manner of magical creatures, including a round, fuzzy forest spirit Mei names Totoro, in imitation of its earth-shaking voice. (Miyazaki compares the creature to an owl or a bear; it also resembles a plump, neckless rabbit.) But as is often the case in Miyazaki’s films, the plot is only a pretext to explore a magical world, sometimes located right under the noses of inattentive grownups. Wait by a bus stop long enough, and the mundane forms of public transport will be replaced by a sentient, many-legged, cat-shaped bus whose route quickly leaves the earth’s surface behind.\nNow enshrined as Studio Ghibli’s mascot, Totoro is an iconic (and, inevitably, marketable) character. But Miyazaki never cedes the film to his non-human creations. Rather than standing in for the magic of the natural world, Totoro merely embodies the qualities already present in the sisters’ surroundings. There’s as much enchantment in ordinary activities, like the girls chasing each other around the house, as in any flight of fancy. My Neighbor Totoro has its roots in Miyazaki’s own life—his mother was hospitalized when he was a child—and the movie is informed by the texture of memory, so reality and imagination become indistinguishable.\nIn Miyazaki’s films, the characters are rendered in cartoon fashion, but the world around them is painted in more realistic hues, more closely resembling an impressionist painting than a comic strip. The evident care with which Miyazaki depicts the texture of a clump of grass or a tree is a subtle but persistent reminder of one of his great themes: the power and fragility of the natural world. In Princess Mononoke, his ecological bent crystallizes into an environmentalist parable, but it also has deep roots in Japanese tradition, where seemingly inanimate objects like rocks and trees are inhabited by living spirits.\nPrincess Mononoke was Ghibli’s beachhead in the U.S., the movie that got the studio the mainstream recognition and theatrical audiences it deserved. (For a glimpse at the bad old days, seek out the dubbed, panned-and-scanned Fox DVDs of Totoro and Kiki’s Delivery Service—or, better yet, don’t.) With an English script by Neil Gaiman and a high-profile voice cast, it seemed poised for a Stateside breakthrough. Though box-office returns in the U.S. were modest—and a drop in the bucket compared to those in Japan, where it was the highest-grossing film in the country’s history until it was dethroned by Titanic—the notion that Studio Ghibli made animated films that culturally literate adults could attend without a pint-sized companion as pretext had been firmly planted in the nation’s mind. In the context of Miyazaki’s other films, Mononoke’s story of a wandering warrior who gets caught in the battle between an angry forest spirit and a mining town seems slightly ponderous, and a tad too aware of its own epic scope, but it is undeniably a majestic work, a lyrical vision with metaphorical weight.\nCertain aspects of Ghibli’s films inevitably get lost in translation. While it’s commendable that Disney’s DVDs regularly include the original Japanese-language tracks as well as their star-studded English dubs, it’s unfortunate that the subtitles (or rather, “dubtitles”) simply replicate the English dialogue, which is sometimes significantly tweaked in order to make the films more palatable to an American audience. It’s far better treatment than Ghibli got in earlier decades; Disney learned its lesson from the fan outcry that arose when Miramax announced plans to release Princess Mononoke with only the English audio track. But the movies still suffer from schizophrenic treatment at Disney’s hands. Pixar’s John Lasseter, who has been Miyazaki’s most vocal champion, pays tribute in video introductions on some of the discs, but Miyazaki’s presence is otherwise ignored in favor of highlighting the films’ American voice talent. The dubbed versions are fine—and, needless to say, much easier on younger viewers—but even without access to a literal translation, the Japanese-language tracks convey an emotional volatility that better matches the characters’ actions. (And yet the English dubs are sometimes better matched to the characters’ lip movements, since in the Japanese tradition, dialogue is added after the film has been animated, where most animators match the characters’ mouths to a prerecorded vocal track.)\nWhile it’s a blessing to have nearly all Ghibli’s features available on DVD in the U.S., it’s clear that Disney still thinks their primary audience is children, which is presumably why it’s never released the adult-themed Only Yesterday and Ocean Waves. Fortunately, Isao Takahata’s Grave Of The Fireflies is excluded from Disney’s holdings, which allowed Sentai Filmworks to bring the sobering film back into print earlier this year. Although the movie’s protagonists, 14-year-old Seita and his 4-year-old sister, Setsuko, are children, the film is hardly fit for preteen audiences. Even adults may find the story of a boy and his sister trying to fend for themselves amid the rubble of immediately post-World War II Japan difficult to endure, at least without shedding copious amounts of tears along the way.\nWhile Miyazaki often approaches the same themes from different angles, Takahata is Ghibli’s wild card, an inventive, versatile craftsman whose talents lend themselves to a wide range of approaches. Grave Of The Fireflies is part memoir and part ghost story, beginning with Seita homeless and near death, his only apparent possession a small tin full of ash and bone fragments. Where Totoro uses animation to envision a world that doesn’t exist, Grave uses animation to tell a story that would be unbearable in a more realistic medium. The opening scene foreshadows the inevitable tragedy, but that hardly makes the sorrowful forward march of time easier to weather. Even amid the ashes of a defeated, disheartened nation, though, Takahata finds moments of beauty, like the incandescent insects of the film’s title. But few films, animated or otherwise, have the courage to pursue such a bleak, fatalistic view of the world, to say nothing of one that so determinedly casts its native country’s past in such a dour light.\nThe breadth of Takahata’s sensibilities becomes clear a few frames into Pom Poko, which is as rich and complex a fable as any of Miyazaki’s more familiar works. The film’s protagonists are the tanuki, a race of raccoon tricksters familiar from Japanese mythology. With a story that pits the manmade destruction of the tanukis’ natural habitat against the species’ out-of-control overpopulation, the movie roughly parallels Miyazaki’s environmentalist concerns. But the tanuki are hardly a benevolent or wise race. In a bid to stop the development of Tama New Town, an enormous housing development built outside Tokyo in the mid-1960s, the tanuki use their shape-changing abilities to infiltrate humankind and cause sometimes deadly mischief. As they watch the news on a trash-picked TV set, the tanuki cheer a delay in construction, their cries drowning out the announcement of several human deaths. The historical setting means the tanuki are doomed to failure—Tama New Town, which houses some 200,000 Japanese, will be built no matter what they do—so the film isn’t the story of underdog triumph so much as a referendum on the tanukis’ character, and that of their human counterparts. Both are found wanting.\nMiyazaki’s films are characterized by their artistic discipline, but Takahata’s is a more protean, unpredictable gift. Like the tanuki themselves, Pom Poko frequently shifts form, depicting the ravages of construction by picturing bulldozers as pests eating away at a leaf, or interrupting the fluid animation with a sequence in the style of an 8-bit videogame. Only Yesterday, never released on Region 1 DVD, is similarly slippery in its shifts between past and present, moving between the life of a disillusioned 27-year-old Tokyo woman and her memories of her childhood. The film’s vision of the past is more bittersweet than nostalgic, befitting a director who rarely gives in to unbridled sentiment.\nMy Neighbors The Yamadas, Takahata’s final feature to date, is an oddity even for him. Adapted from a popular comic strip, the film takes on a similar style, with two-dimensional characters presented in a sea of white space. The only Ghibli film to be produced entirely with digital technology, it lacks the fluidity and grace of the studio’s hand-drawn efforts, and the episodic narrative is only fitfully satisfying. That said, it’s rare to find a film so squarely focused on the familiar ins and outs of family life, and there’s a low-key charm to its ebullient vignettes, although even at its best, it feels like a well-crafted sitcom.\nMiyazaki’s features split, very roughly, into two strands, indicated by their protagonists’ age (and, less exactly, gender). The fables, which include Totoro, Kiki’s Delivery Service, Spirited Away, and Miyazaki’s most recent feature, Ponyo, are episodic in form, concerned with delineating a world and defining the characters, mostly preteen girls, through their understanding of it. The adventures—Howl’s Moving Castle, Princess Mononoke, Porco Rosso, and Castle In The Sky (a.k.a. Laputa)—are oriented around conflict, generally featuring older male characters in the lead.\nMiyazaki’s films overlap to such a degree, and are of such high quality across the board, that differentiating between them is difficult and not especially desirable. Kiki’s Delivery Service ranks second only to Totoro as a blissful children’s adventure, a lighthearted story of an apprentice witch who puts her talents to good use. But for Miyazaki, the boundaries of childhood are always porous, and encompass subjects that many present-day filmmakers (and parents) consider beyond young viewers’ ability to assimilate or comprehend. His movies are truer to the way children understand the world, as well as to their impetuous, irrational, sometimes-petulant selves, than the imaginary innocents who are the target audience for most diluted, denatured kiddie entertainment.\nFollowing a girl named Chihiro into a bathhouse for wayward spirits, Spirited Away is poised between the relatively carefree world of childhood and the dangerous territory of adult life. The world Chihiro encounters—looking for her parents, who have been turned into pigs—is full of wonder and danger as well, notably a witch named Yubaba who evokes John Tenniel’s Red Queen. Ponyo, a loose adaptation of Hans Christian Andersen’s “The Little Mermaid,” skews younger with its story of a goldfish (depicted as a blobby toddler) who falls in love with a human boy, but the threat of catastrophe still lurks. Ponyo’s father is a powerful sorcerer, and her actions unleash a power that could be devastating.\nMiyazaki is obsessed with flight, enough so that Studio Ghibli’s name comes from a WWII-era nickname for Italian spy planes. Castle In The Skyis one of many films where characters find a entire world hidden in the clouds, in this case one that takes its name, Laputa, from Jonathan Swift’s Gulliver’s Travels. A more obvious, though still highly eccentric, homage to his preoccupation with flight is the delightfully bonkers Porco Rosso, in which a WWI flying ace does battle with rogue bands of “air pirates” in the Adriatic Sea. Miyazaki’s films rarely take place in a recognizable world, let alone a specific time period, but the film’s modest realism is more than offset by the fact that its main character is a bipedal pig. Originally commissioned as an in-flight film for Japan Airlines, the film grew into a feature but retains some of the casual lightness of a short subject.\nMiyazaki often takes his inspiration from literature, although even in the case of explicit adaptations, the source material has been thoroughly absorbed. Howl’s Moving Castle bears little resemblance to Diana Wynne Jones’ source novel, but even she was taken enough with the results to proclaim her full support. As in many of Miyazaki’s adventures, the world is pushed to the brink of war, but here, the origins and even the nature remain unclear, as if from the perspective on the ground, it hardly matters who’s fighting whom. Miyazaki’s later films are more leisurely in their pacing, often because they dawdle to take in the texture of a leaf or patterns of light, but here, the pace is seasoned with something like dread.\nThe studio has released a number of films by directors other than Miyazaki and Takahata, though those titles don’t entirely measure up to the work of Ghibli’s grand masters. The most recent, and one of the best, is The Secret World Of Arrietty, directed by Ghibli key animation veteran Hiromasa Yonebayashi. Loosely based on Mary Norton’s The Borrowers—though it follows the novel’s storyline much more closely than Howl’s Moving Castle sticks to its own source material—the movie follows its doll-sized heroine into the strange, threatening world of humankind, a nifty twist on Ghibli’s usual habit of placing human heroes in unfamiliar surroundings. The movie is particularly acute when it comes to representing the texture of Arrietty’s world, like the way a water droplet looks to a creature only slightly larger than it, or the booming echo of sounds that humans typically pay no mind. Less successful: Tales From Earthsea, based on the fantasy series by Ursula K. Le Guin, and directed by Hayao Miyazaki’s son, Goro Miyazaki. The visuals, unsurprisingly, are splendid, but the movie feels disorganized and uninspired, as if the younger Miyazaki was unsure whether to follow the plot of Le Guin’s saga, or simply replicate its atmosphere.\nWhisper Of The Heart was meant to introduce director Yoshifumi Kondô as Ghibli’s next great director, but he died of an aneurysm a few years after its release. It’s an odd hybrid, poised uncomfortably between Takahata’s Only Yesterday and Miyazaki’s whirling fantasies. The story begins in domestic mode, following a schoolgirl whose most pressing current problem is devising a workable Japanese translation of John Denver’s “Country Roads” for school. (In a playful alteration, she replaces the word “country” with “concrete,” a subtle comment on how urbanization has transformed Japanese life.) But then, almost out of nowhere, a dapper, top-hatted cat figure called the Baron shows up and starts guiding her toward her dreams. The Cat Returns, directed by Hiroyuki Morita, is an extremely loose sequel in which a girl saves a cat from traffic, and is drafted to be married to the son of the King Of Cats. In some ways, the ideas at work aren’t so different from Miyazaki’s, but the movie’s uncertain touch is a reminder of just how difficult it is to bring Miyazaki’s special sort of magic to life.\nOcean Waves, directed by Tomomi Mochizuki, is a tender, acutely observed tale of a young man’s transition to adulthood, very much in the vein of Only Yesterday. The movie is likewise unavailable in the U.S., but diehards will find a way to see it, legal gray areas or no. To fill in some background, it’s also worth seeking out some pre-Ghibli features by the same talents, especially Miyazaki’s epic Nausicaä Of The Valley Of The Wind, whose success paved the way for Ghibli’s founding, and The Castle Of Cagliostro, the boisterous tale of a legendary thief that rivals some of Hitchcock’s most feather-light entertainments.\n1. My Neighbor Totoro\nGhibli’s best-known film, and the ideal introduction for viewers young and old.\n2. Grave Of The Fireflies\nThe darkest film in Ghibli’s library, and one of its most moving, as well as a landmark that shatters preconceptions about the animation medium’s potential.\n3. Pom Poko\nThe other side of Takahata: playful where Grave is somber, chaotic where it’s controlled. A giddy, flawless lark that reveals more serious themes as it progresses.\n4. Howl’s Moving Castle\nIt’s neck-and-neck with Castle In The Sky and Princess Mononoke, but it takes the edge among Miyazaki’s tales of epic struggle for the way it balances world-shaking developments and character interaction.\n5. The Secret World Of Arrietty\nProof that Ghibli isn’t synonymous with Miyazaki and Takahata, although there’s certainly a wide overlap. Yonebayashi follows ably in his mentor’s footsteps by seeing our world though the eyes of a tiny protagonist, making the mundane world seem full of new wonder and fascination.']	['<urn:uuid:c41c1118-d997-4218-8717-35e4785b3f1f>', '<urn:uuid:4f49dcc9-617b-46b8-9d88-63c05e2e113f>']	open-ended	direct	concise-and-natural	similar-to-document	comparison	expert	2025-05-12T22:49:38.933606	9	76	4116
39	Can I get a free flight to medical treatment?	Angel Flight West provides free, non-emergency air transportation through a network of more than 1,400 volunteer pilots. They serve the 13 western states and flights can be arranged with a week's notice through a doctor's office, nurse, or social worker.	"['- Doctors & Departments\n- Conditions & Advice\n- Your Visit\n- Research & Innovation\nLearning how to manage life with epilepsy can be challenging for patients and their families. That\'s why we\'ve compiled this list of resources to help you and your family find additional information and support along the way.\nWe hope these resources, along with our care and support, help you gain a stronger understanding of your child\'s condition, build a community and make life with epilepsy more manageable.\nThe Epilepsy Foundation of Colorado (EFCO) is committed to leading the fight to overcome the challenges of living with epilepsy. Their website highlights local support groups, which are a great resource for helping you build a community with other families who are impacted by epilepsy. They also provide information that can help your child and family better understand epilepsy.\nEFCO offers an entire section with information on everything from treatment options to seizure first-aid tips. They also provide opportunities to train your community and school personnel. EFCO hosts several events for people living with epilepsy and their families. Visit their website to learn more about these initiatives.\nSeizure Tracker is an app designed to help you log and track seizure activity, appointments and medication schedules through an easy-to-use computer or mobile application. This online seizure diary empowers people living with epilepsy to become active leaders in their own treatment.\nThis app gathers the information you provide and puts it into a customized report that includes graphs comparing seizure activity and medication dosages. This tool can help patients and their families, as well as their medical providers, understand the relationships between seizure activity and medications.\nThe American Epilepsy Society (AES) is an extensive resource that is tailored to promote interdisciplinary communications, scientific investigation and an exchange of clinical information about epilepsy. This website offers resources about current evidence-based guidelines and parameters around quality care for patients and families.\nAES is also committed to research. The society holds an AES Annual Meeting in Washington D.C. that brings together professionals from all over the country to discuss everything epilepsy. AES also provides resources for patients on epilepsy benefits, International Epilepsy Day and advice on how to maintain an epilepsy diary.\nFACES funds research to improve epilepsy care, advances new therapies, and fosters a supportive community for children, families and caregivers. It is affiliated with the NYU Langone Medical Center and its Comprehensive Epilepsy Center.\nThe FACES website also offers a resource called The Parent Network. This network connects parents who have children with epilepsy with ""support parents."" These support parents have experienced similar issues surrounding care for a child with epilepsy. The organization also offers the first online support group for teens with epilepsy, which provides an opportunity for teens to share their experiences with other young adults to help them manage their seizures in their daily lives.\n4 Paws for Ability is a non-profit organization whose mission is to place quality service dogs with children with disabilities and veterans. 4 Paws offer trainings for Seizure Assistance Dogs and many other specially-trained dogs.\nEach trained dog can provide a level of emotional support and the ability to alert parents to seizures when they occur. 4 Paws will accept any child with a disability and does its best to work with families to meet their financial need. You can learn more about what it’s like to have a Seizure Assistance Dog on their website.\nAngel Flight West is a network of more than 1,400 volunteer pilots who offer flights to and from medical treatment, at no cost. Angel Flight West has arranged free, non-emergency air transportation for children and adults with serious medical conditions or other compelling needs since 1983. This organization serves the 13 western states and tries to fulfill the transportation needs of families who may not be able to afford the costs of commercial airline tickets.\nYou can request an angel flight through a doctor\'s office, nurse, or social worker. Flights can be arranged in a week\'s notice. Visit their website for a more detailed explanation of the process.\nThe ParentSmart Healthline provides access to pediatric care and peace of mind 24 hours a day, seven days a week. When you call Children\'s Hospital Colorado ParentSmart Healthline (720-777-0123), you can receive free healthcare advice from registered nurses.\nThe nursing staff provides information and healthcare advice about more than 290 pediatric topics. They can help provide direction for parents caring for an ill child in their home. The ParentSmart Healthline nurses receive more than 30,000 calls a year. This service is available to all families in the Rocky Mountain Region.\nThe Centers for Disease Control (CDC) is a comprehensive resource for children, teens and people living with epilepsy. It is also a great resource for parents and caregivers who help people with epilepsy.\nFrom daily basics like first aid to how to handle epilepsy during a natural disaster, the CDC has a lot to offer. You can also find information on the latest research, progress in the field of pharmaceuticals, and more.']"	['<urn:uuid:4c236410-9fa1-4e86-87de-21f5a89c7c0a>']	factoid	direct	concise-and-natural	distant-from-document	single-doc	novice	2025-05-12T22:49:38.933606	9	40	842
40	Which Formula 2 and Formula 3 drivers from last season have made impressive moves, with Yuki Tsunoda graduating to F1 while Theo Pourchaire showed strong performance in F3?	Yuki Tsunoda successfully graduated from Formula 2 to Formula 1, becoming one of three F2 graduates last season. Meanwhile, Theo Pourchaire demonstrated impressive talent in Formula 3, becoming the series' youngest ever race winner at age 16 and showing continued strong performance as evidenced by his 5th place finish in the Spa sprint race.	"[""5 reasons why you should be excited about the new Formula 2 season\nArmed with a new format, new tracks and new title challengers, the fifth season of Formula 2 is set to kick into gear at the Bahrain International Circuit this weekend.\nLast season saw the second tier produce three more Formula 1 graduates after the tightest title fight in F2’s history, so you won’t want to miss a second of the latest instalment as the greatest young racing talents on the planet go toe-to-toe for a seat in the pinnacle of motorsport.\nHere are five reasons to get excited ahead of the new season…\n1. More races at each round\nThis season sparks the start of a new era for Formula 2 with an increase from two to three races per round. There will now be two reverse grid Sprint Races on a Saturday, while the Feature Race has switched to Sunday – a move designed to whet your appetite directly before the Grand Prix itself.\nA move made in part to cut costs and safeguard the future of the series, the addition of more action at each round is certainly a welcome development for fans.\nRemaining unchanged from last year, Friday’s 30-minute qualifying session will still determine the starting grid for the Feature Race – F2’s main attraction, with mandatory pit-stops, more points and more laps.\nThe key changes for this year are in the Sprint Races, with the line-up of the first determined by reversing the top 10 finishers of qualifying, and the starting grid for the second determined by reversing the top 10 finishers of the first Sprint Race.\nPut simply, another reverse grid means more overtaking. How teams and drivers deal with the new changes should also prove thrilling in the opening rounds, with strategy set to play a bigger part than ever.\nAlthough, as CEO Bruno Michel has said himself, “the best drivers will always win.”\n2. The next generation\nMick Schumacher, Yuki Tsunoda and Nikita Mazepin are the latest in a growing list of graduates to Formula 1 from the second tier, increasing the number to eight in four years since GP2 re-branded to become FIA F2.\nThat’s a remarkable number and proof that the system works. F1 teams aren’t afraid to place their trust in a rookie and the next F1 graduate will more than likely be lining up on the 22-strong grid in Bahrain this weekend.\nRobert Shwartzman and Christian Lundgaard are just two of the names gunning to follow in the tyre tracks of Schumacher and co., but know that they need successful seasons if they’re to convince those on the other side of the paddock to hand them a deal.\nThe duo showed flashes of their potential in 2020 – see Shwartzman’s dramatic win in Budapest and Lundgaard’s dominance in Mugello – but both saw their title charges falter due to a lack of consistency.\nFix this and they stand a great chance of taking that graduation tally to double figures.\n3. New tracks and returning favourites\nDespite featuring fewer circuits overall, the F2 calendar has a much more worldly feel about it this season, with five ‘flyaways’ and just three rounds in Europe.\nAs well as the return of Azerbaijan, Abu Dhabi and Monaco to the calendar, F2 will also join F1 in Saudi Arabia for the very first time, on a circuit that’s been hailed as the ‘fastest street track in F1 history.’\nThe sheer amount of overtaking that occurs during F2 races makes this a tantalizing prospect on its own…\n4. F1 driver academy battles\nThe ultimate aim of the second tier is to produce ready-made talent for F1, but with so many different teams represented across the grid in the form of driver academies, rivalries are bound to form. After all, winning is in the nature of every racing driver.\nFerrari dominated last season with Mick Schumacher, Callum Ilott and Robert Shwartzman all featuring in the top four – a feat that won’t have gone unnoticed by those at Red Bull or Alpine. Shwarztman is back to lead the charge for the Scuderia this time around at PREMA, as is his former F3 team mate, Marcus Armstrong, who will turn out for DAMS.\nAs well as Ferrari, Alpine, Red Bull, Williams and Sauber are all represented on the F2 field. Alpine trio Christian Lundgaard, Guanyu Zhou and Piastri will all feel that they’re in with a shout, as will Red Bull’s contingent, Jehan Daruvala, Liam Lawson and Juri Vips, with the latter two set for a fascinating intra-team battle at Hitech.\n5. Exciting newcomers\nThose who kept a keen eye on the second-tier last season will already know all about Shwartzman, Lundgaard and Felipe Drugovich, but there are also a host of new faces on the grid for fans to become acquainted with.\nThere’s plenty of excitement surrounding F3’s top two from last year, Oscar Piastri and Theo Pourchaire, who took the championship by storm in their rookie seasons. Pourchaire in particular set tails wagging, becoming the series’ youngest ever race winner at the age of just 16.\nRed Bull junior Lawson was the most impressive of the new blood in pre-season testing, consistently punching in top five lap times and finishing second on the final day – despite running the second fewest laps.\nF3 race-winners Lirim Zendeli, Bent Viscaal and David Beckmann will also all make the step-up, as will Matteo Nannini and Alessio Deledda, but one name who few may not know too much about is Gianluca Petecof.\nThe Brazilian – who is the Formula Regional European Champion and a former member of the Ferrari Academy – is highly-rated and was expected to join Formula 3, but opted to bypass the third tier all together and jump straight into F2.\nGiven the rapid emergence of AlphaTauri star Yuki Tsunoda, you’d be foolish to rule out a rookie starring this season.\nThe F2 season will kick off on the same weekend as F1, 26-28 March, in Bahrain. Don't want to miss a minute? Subscribe to F1 TV Pro for every single session live and visit the official F2 website for more."", 'Title contender Logan Sargeant bounced back after engine problems in yesterday’s feature race to take victory in the Formula 3 sprint race at Spa.\nReverse grid polesitter Richard Verschoor held the lead into the first corner, while Sargeant rose to second ahead of Olli Caldwell due to Liam Lawson having a slow start and dropping back to fifth.\nBut despite getting off the line well, Verschoor was unable to drop Sargeant in the opening laps as he struggled again with straight line speed for his MP Motorsport car. Sargeant stayed within a few tenths of Verschoor until lap 3, when he made the move for first and took the lead of the race.\nMeanwhile, Sargeant’s teammate Frederik Vesti was moving up through the order from fifth on the grid. After taking third from Caldwell while Sargeant was passing Verschoor, Vesti then overtook Verschoor himself for second on lap 4.\nThe race was neutralised shortly after when Hitech’s Pierre-Louis Chovet went into the barriers and brought out the virtual safety car for two laps. When the caution was withdrawn on lap 6, Verschoor continued to fall down the order. The Dutchman lost third to Theo Pourchaire on lap 9, then dropped behind Lawson, Aleksandr Smolyar and Oscar Piastri in quick succession.\nMeanwhile, Vesti was making strong progress to catch Sargeant. After being 2.1 seconds behind his teammate after the virtual safety car restart, Vesti cut the gap down to four tenths by lap 14 as Sargeant complained of fading tyres on the radio.\nHowever, Sargeant was able to regroup in the final few laps and opened the gap back up to a second. Vesti made one final charge on the final lap, but couldn’t close up enough to make a move for the lead and finished runner-up across the line.\nLawson recovered from his poor start to finish third behind the Premas. After passing Verschoor for fourth, the Hitech driver put significant pressure on Pourchaire who was struggling with his tyres, and took third away on lap 12.\nPourchaire lost another place to his ART teammate Aleksandr Smolyar, who finished fourth for the second race in succession. On lap 15 Pourchaire was also passed for fifth by Oscar Piastri, who was charging forward from his own slow start to minimise the damage done by Sargeant’s win.\nBut just after moving into fifth, Piastri was given a five second time penalty for leaving the track and gaining an advantage when passing Pourchaire, dropping him to sixth behind the Frenchman in the final order.\nVerschoor stabilised in seventh place by the chequered flag, finishing ahead of yesterday’s race winner Lirim Zendelli. His Trident teammate Caldwell had been running eighth, but fell out of the points after colliding with Alex Peroni. David Beckmann took ninth, and Sebastian Fernandez benefitted from the collision ahead to finish tenth.\nAfter taking 17 points for victory and the fastest lap, Sargeant returns to the top of the drivers’ standings by seven points from Piastri, while Beckmann stays third ahead of Lawson by just half a point. Find the full F3 drivers’ and teams’ standings here.\nFIA Formula 3 returns next week at Monza for the penultimate round of the season.\nFull race result:\n|1||Logan Sargeant (FL)||Prema Racing||17|\n|2||Frederik Vesti||Prema Racing||12|\n|3||Liam Lawson||Hitech Grand Prix||10|\n|4||Aleksandr Smolyar||ART Grand Prix||8|\n|5||Theo Pourchaire||ART Grand Prix||6|\n|6||Oscar Piastri||Prema Racing||5|\n|7||Richard Verschoor||MP Motorsport||4|\n|10||Sebastian Fernandez||ART Grand Prix||1|\n|12||Enzo Fittipaldi||HWA Racelab|\n|13||Lukas Dunner||MP Motorsport|\n|14||David Schumacher||Carlin Buzz Racing|\n|15||Clement Novalak||Carlin Buzz Racing|\n|16||Bent Viscaal||MP Motorsport|\n|17||Jake Hughes||HWA Racelab|\n|18||Dennis Hauger||Hitech Grand Prix|\n|19||Roman Stanek||Charouz Racing System|\n|20||Federico Malvestiti||Jenzer Motorsport|\n|21||Andreas Estner||Campos Racing|\n|22||Alex Peroni||Campos Racing|\n|23||Cameron Das||Carlin Buzz Racing|\n|24||Alessio Deledda||Campos Racing|\n|25||Calan Williams||Jenzer Motorsport|\n|26||Matteo Nannini||Jenzer Motorsport|\n|27||Igor Fraga||Charouz Racing System|\n|Ret.||Michael Belov||Charouz Racing System|\n|Ret.||Pierre-Louis Chovet||Hitech Grand Prix|\n|Ret.||Jack Doohan||HWA Racelab|']"	['<urn:uuid:02dc3a6f-a2ce-4423-a191-2985c7602567>', '<urn:uuid:1310fa81-50f2-4206-976e-524b0109106d>']	factoid	direct	verbose-and-natural	similar-to-document	comparison	expert	2025-05-12T22:49:38.933606	28	54	1657
41	Which companies focus on helping others: Rendever or Desert Valley Tech?	Both Rendever and Desert Valley Tech focus on helping others. Rendever helps reduce social isolation among seniors through virtual reality experiences, while Desert Valley Tech developed a blood-preservation device called Hemaporter to save lives on the battlefield by keeping blood properly chilled for 72 hours.	"['About Kyle Rand & Rendever:\nKyle Rand is the co-founder and CEO of Rendever, a company pioneering virtual reality connectivity for seniors. He grew up volunteering at a senior living community and later went on to study cognitive decline in the aging population at Duke University.\nHe was recently named to Forbes 30 Under 30 and his company was just listed to Time’s list of 100 most influential companies in 2022, outstanding achievements both. When you meet him, you’ll understand why. His company has raised millions in funding pursuing a truly noble cause, empowering the elderly to form communities through virtual reality.\nIn case you didn’t know, loneliness and isolation are two of the biggest problems facing us as we age, and he’s found a life and career of meaning solving that challenge.\nFull Unedited Audio Conversation:\nKyle Rand & Rendever Links:\nIf you enjoy the show, please rate it 5 stars on Apple Podcasts, subscribe, and leave a nice review!\n2:40 – “At Rendever, as a company, we are on a mission to reduce social isolation through the power of positive shared experiences. And the primary way we do that is through virtual reality.”\n4:02 – “When you look at this demographics specifically, it’s really dangerous. We’re talking about a 30% increase in risk of hypertension and stroke, a 50% increase in risk of dementia, a lot of premature cognitive decline. We’re talking about immunosuppression, risk of infection goes up. We’re talking about even an increase in risk of diabetes…depression, anxiety, risk of suicide. All of these things together create a picture in which people have 30% higher mortality rates when they’re at a significant rate of social isolation.”\n5:29 – “The very first moment that always stuck with me was while I was volunteering at a community as a kid…We would go in and we’d scoop ice cream; it had an in-house ice cream parlor…and there’s this one day where this gentleman walked in and I locked eyes with him, I pointed at him and said, ‘You want rum raisin with chocolate sprinkles.’ And the smile that spread across his face in that little moment of recognition is something that just has stuck with me through this day.”\n7:27 – “As a society, we don’t have a healthy relationship with aging. We think about aging, we think about old people, we think about death, and we push it away. It’s not something that we want to lean into and talk about or think about. But it’s so odd because the two things that are guaranteed in our life is that we’re getting older, second by second, and at some point we’re going to die. If we don’t have the capacity to think about it, to have conversations about it, to ideate and think about how can we make that process better, knowing that that’s a process we’re all going to go through, then we’re not only selling the current demographic short, we’re also selling ourselves short.”\n8:11 – (Ross) “I live in the greater Los Angeles area, and you won’t go broke making a business that offers facial fillers, Botox, uplift, anything to make us look younger…It’s not just the Kardashians, but it’s anybody like them. Here’s what they posted on Instagram and here’s how they actually looked before it was so heavily edited and Photoshopped …what is presented on Instagram is essentially more of a painting than it is a photograph. But that’s the world where we all feel like we have to present this youthful image at all times and I’ve always taken issue with that. I’ve always felt that aging doesn’t have to be something that we have to fight. It can be something that we can embrace, but we don’t.”\n11:36 – “One of the things that…creates these situations in which it’s easy to call someone old is when technology comes into play. Someone is introduced to technology and they don’t get it, they get frustrated by it, they’re like, ‘Nah, that’s not for me.’ And that creates an immediate divide between people who are tech-adaptive and people who want to push away tech because it frustrates them and that’s so unfortunate, and it’s been really formative in how we’ve built this company… saying tech doesn’t have to be something that divides and creates an Us versus Them but actually can allow people to connect if it’s approached in the right way.”\n16:09 – [On the early days of VR] “What can we do with this technology? Can we use it? And everyone’s looking to kids, everyone’s looking at video games…And we took a step back and were like ‘Look, you think about this headset, you hold that up there, all of a sudden you can go anywhere in the world and you can do anything.’ Think about the aging demographic…no matter where they are in their aging process, who along each step, their access to the world becomes more and more limited. Think about the opportunity to all of a sudden reopen all those doors and expand their worlds. And we got super excited, and the moment we did our first set of demos, it became super clear that there is definitely magic to uncover here, and we had to turn to: ‘how do we actually make this work?’”\n19:22 – “One of my favorite stories is…there was one person who I think they were about to celebrate their 100th birthday and they had a plan where they were going to go skydiving…the resident got sick and wasn’t able to go – and what the staff member at her community did was say, ‘hey, we can do this in VR.’ And so strapped her into a Rendever headset, loaded up the skydiving experience and then counted down: 3, 2, 1, turned on a giant fan, the wind was blowing in her face…and it was amazing. It was magic.”\n21:32 – “Understanding who that human is, what their desires are, what their idea of purpose and passion, and the life that they want to live in that day, in that moment, is and then figuring out how to approach it, deliver it, enable them to experience what they want to experience and do so in a way that is building a bond…The experience is one thing but our approach as a company has been really to empower staff, volunteers, family members, anybody who is working with this population, to deliver magical moments. And through doing that, we’re inspiring connection to happen. And that’s really where the magic is.”\n29:08 – “We saw the impact. We saw just how significant it was when you put a headset on someone who might have spent months depressed, you bring them to Italy and this huge smile spreads across their face and they just light up.”\n31:34 – (Ross) “I’m glad that you’re able to pass that gratitude and humility on and instill those values in your company, because that’s so important. I’ve talked about values a lot with other people…if you’re building your own thing, why build the wrong values into it?…If you’re coming into somebody else’s thing, you don’t have a choice – you’ve got to follow their rules. But when you’re building your own thing, to recognize and reprioritize, that’s huge.”\n34:09 – “Since we don’t have the external pressure and since everything is so internal, what we’ve built is a company that is really high on gratitude. One of my favorite parts about our company is that we kickstart every single all-hands meeting with a kudos session where everybody just gives kudos to everybody. I think that the last meeting, it lasted a full 25 minutes. In an hour-and-a-half-long meeting, 25 minutes was people just delivering kudos to each other and expressing gratitude. And that’s really unique.”\n37:53 – “Our approach is so relationship driven that we are constantly getting partners, every single day, who will send us a note or send us a video or a photo of ways in which they’ve used Rendever to change somebody’s life. And then that obviously gets shared all over our internal Slack messages and it allows us to stay so close to the mission, and again, to wake up every single day and know without a doubt what we’re doing is making really significant positive impact and you can remove everything else – that makes life a ten.”\n43:25 – [On a story from a Rendever partner] “They had a stage four pancreatic cancer patient who spent her whole life involved in music…We need to figure out how to bring her something unique. And so we partnered with the Colorado Symphony and went on stage at Red Rocks Amphitheatre, filmed the entire symphony experience during sunset at Red Rocks, and then brought this patient as the first person to get to experience it. And it was unforgettable. At one point, she said, ‘Music has always been my medicine.’ And one of the hardest parts about navigating this journey is her access to being able to experience live music is just totally cut and to be able to put on a headset and all of a sudden be on stage at one of the most spectacular music venues in the entire world with the Colorado Symphony. It was just it was incredible.”\n47:02 – “We found that after just two weeks of daily shared experiences in Rendever our participants had statistically significant decreases in their depression scores and increases in multiple measures of social health. Most interestingly, people actually started to trust each other more. When we think about what it means to build a relationship, one of the fundamental elements is trust…This isn’t just people having fun together using technology. This is people who are presented with a unique opportunity to really, authentically, genuinely connect. And they’re taking it and they’re running with it.”\n49:10 – “As an early entrepreneur, everybody wanted to give advice. The advice to everybody is: you’re not the first person to do something. Go out there, figure out who did what? What can you learn from? While there’s truth to that, I think the thing that I really stuck to as an early entrepreneur was: everyone has advice, but that advice is 100% informed by their personal experiences. And if you take somebody’s advice without actively figuring out how big of a grain of salt you need to put on that piece of advice, you’re going to be sent in every single which way direction…If you’re fully confident what you’re doing and the approach you have in your why, then take as much advice as you can, but understand that you need to be adding grains of salt to all of it.”\n51:09 – [Advice to care-givers] “One of the things that is tough to navigate is caregiver guilt and caregiver burden. You experience these things hand-in-hand as your duties as a caregiver go up. Whether or not you’re alone, you have help with home care, you have a loved one in senior living…Remember that it’s a relationship they you are a part of. It’s really easy to get wrapped up in the caregiving side of the relationship but there is another element to that relationship. Figure out how to set up time/space opportunities to be a part of the relationship as it exists outside of your caregiver duties. And that makes everything better.”', 'Entrepreneurs create solutions to big and small problems\nDozens of entrepreneurs in the Arizona State University community are working on life-changing startup ventures, and on Friday, several were rewarded with thousands of dollars in investment capital at the Demo Day pitch competition.\nSome of the winning projects were:\n• Emily Karlzen, a senior majoring in business entrepreneurship with a minor in construction management, invented a helmet for tourists to wear in space. Her company, Arch Rift, won $15,000 in the eSeed Challenge.\n• Travis Witzke, an Army veteran and ASU alum, won $10,000 in the Ashton Family Venture Challenge for his company, Desert Valley Tech. Haunted by his experiences during deployment to Iraq, he invented a device to preserve whole blood on the battlefield to increase the chances of saving lives.\n• Pauline Nalumansi, a graduate student in the Thunderbird School of Global Management, won $5,000 for the Pauline Foundation, a nonprofit she created to help empower at-risk youth in Uganda, her home country.\nThey were among 80 startups that won more than $150,000 in investment funding Friday through Venture Devils, a program in the office of Entrepreneurship and Innovation at ASU that provides space, mentorship and access to funding to ASU students, faculty, staff, alumni and community members. The teams pitched their ventures to a panel of judges in six funding competitions at the event, held at SkySong in Scottsdale.\nSome of the winners have already won investments from previous pitch competitions. EnKoat, a company that invented energy-efficient building coatings, was the biggest winner of the day with $20,000 from the Edson Student Entrepreneur Initiative, and also won $15,000 at Demo Day last spring. EnKoat’s co-founders, Aashay Arora and Matthew Aguayo, engineering doctoral students at ASU, were named to the Forbes “30 under 30” list earlier this month. ASU engineering alumni Kevin Hale and Grayson Allen developed GateSense, a technology that allows users to lock and unlock gates from anywhere through a mobile app. Their company, Halen, won $15,000 at Demo Day last year and then $10,000 on Friday\nTravis Witzke (third from left) and members of the Desert Valley Tech team won $10,000 in funding for their blood-preservation device. Witzke, a U.S. Army veteran, was inspired by his battlefield experiences to invent the Hemaporter.Photo by Charlie Leight/ASU Now\nRicky Johnson, who earned a degree in computer engineering at ASU, pitched his boxing-training invention, the Barrage sleeve, to the judges at Demo Day. He won $3,000.Photo by Charlie Leight/ASU Now\nMechanical engineering systems freshman Seth Altobelli (left) and graduate engineering student Cole Brauer talk about the motor they invented that provides a power boost to mountain bikes. Their venture, Accelerated Cycles, won $2,000.Photo by Charlie Leight/ASU Now\nASU alum Jennifer Walter pitched her company, Serving Glamour, in the new Retail Devils competition at Demo Day. She designs clothing for transgender women, with broader shoulders and adjustable waistlines.Photo by Charlie Leight/ASU Now\nLeandres Christopher, who earned an MBA at ASU, talks about her company, Knotbox, a subscription beauty service devoted to natural hair for black women that includes products from black-owned businesses.Photo by Charlie Leight/ASU Now\nWhile pitching to the judges, several of the entrepreneurs shared how they learned hard lessons during the startup process. Ricky Johnson, an ASU alum, is CEO of Barrage Training Tech, and invented a pressure-sensitive sleeve that wraps around a punching bag so workouts can be done without a trainer. He described how he took the first prototype to some local boxing gyms for boxers to try out.\n“It was horribly ugly and it had duct tape and hot glue on it and batteries were flying everywhere,” he said.\nSo Johnson, who earned a degree in computer engineering at ASU in 2017, spent months and a lot of money to refine his prototype, and on Friday, he won $3,000 in the Global Sport Venture Challenge competition.\nRetail Devils, a new competition funded by Follett, awarded a total of $10,000 in seed grants to several ventures on Friday. The initiative was created earlier this year to ease the way for students to sell products at the Sun Devil Marketplace stores, according to Tracy Lea, assistant director of venture development in Entrepreneurship and Innovation at ASU.\n“A point of pride at ASU is our collaboration. So we started to think about how we unencumber the process. We lowered the barrier to entry,” said Lea, who added that two “pop-ups” have been held to sell students’ merchandise.\nAnother new funding competition this year is the Sarsam Family Venture Challenge, which awarded $15,000 in grants, including $10,000 to RIVIS Surgical, a startup that was created by a team of biomedical engineering students and aims to prevent medical complications.\nThe winners will use the investment cash to create or refine prototypes, file for patents or market their startups. Karlzen has mockups of her positive-pressure space helmet but wants to use her winnings toward creating a functioning prototype. She is planning to sell her space-tourism helmet to space-suit manufacturers by 2022. Last month, Arch Rift won the NewSpace Business Plan Competition for space ventures in Texas.\n“I’m a giant space nerd and I was concerned about the safety systems on commercial spacecraft,” she told the judges. “This is a good way of protecting people and making it comfortable and making it weigh less for the people launching the rockets. I want to make this industry a reality.”\nWitzke, who invented the Hemaporter blood-preservation canister, said he’ll use his winnings to test his device in the field. Currently, whole blood must be kept between 33 and 40 degrees to be used on wounded people at remote locations, and current devices can only hold the temperature for 18 to 24 hours. The Hemaporter, which is set in a docking station, can keep whole blood chilled for 72 hours in temperatures over 100 degrees.\nWhen Witzke was in Iraq, he frantically tended to a civilian who was shot in the face. The man died in the helicopter on the way to hospital.\n“I always wonder if I could have done more to save his life,” he told the judges.\nJi Mi Choi, associate vice president of Knowledge Enterprise Development at ASU, told the crowd that Entrepreneurship and Innovation has raised more than $25 million in the last four years to support the pitch competitions and other programs across the Valley.\n“We hustle the same way you do. I know what it’s like to stand up and pitch,” she said.\n“We believe in you and we believe in your ideas.”\nTop image: ASU Thunderbird graduate student Pauline Nalumansi talks about her Pauline Foundation after winning $5,000 at the Fall 2019 ASU Venture Devils Demo Day pitch competition on Friday. She told the crowd: ""I didn\'t know who I was until I came to America and to ASU, and now I\'m helping to change the lives of students in Uganda."" Photo by Charlie Leight/ASU Now']"	['<urn:uuid:f6acb0e3-5552-4fc9-b7d8-31d57739ef26>', '<urn:uuid:00f7fbf6-7859-4739-8876-222366c59ab1>']	factoid	with-premise	concise-and-natural	similar-to-document	comparison	novice	2025-05-12T22:49:38.933606	11	45	3052
42	authentication privacy risks scanning methods	Authentication testing involves examining various security and privacy risks. From a privacy perspective, different authentication scopes carry varying risk levels - for example, phone number claims have high security (5) and privacy (5) risk scores, while profile access has moderate security (2) and privacy (4) risks. The testing process includes thorough authentication testing, identity management testing, and session management testing as part of the attack and exploitation phase. Organizations perform both passive information gathering using OSINT tools and active testing to identify vulnerabilities in authentication mechanisms.	"[""Full Title or Meme\nA request for Claims is expressed as a set of Scopes.\n- Scopes were introduced in OAuth 2.0 as a means to request a collection of claims. They have since been called to fill a large number of other functions.\n- The primary reason to be concerned with Scopes here is as a means to inform the user which User Information is requested by the Relying Party.\nClaims typically go through a series of steps, for example:\n- A User will go to a Web Site hosting a Resource that the user wants to access.\n- The Web Site will send a collection of Scopes to a User asking for Claims to authorize access.\n- The User Agent should know, a priori, where to send the Claims for verification. In the case of OpenID Connect the request is automatically redirected to the OpenID Provider (OP) associated with the choice made by the user at the Relying Party Web Site, called the client by the OpenID specifications.\n- The user will need to stipulate a User Consent showing which Scopes they which to release to the Web Site.\n- The source of the User Consent may offer to retaining the user's choice for a limited time and apply it again if request for the same scope in made by the same Web Site.\n- The verified claims will be collected and forwarded to the Web Site.\n- The Web Site will evaluate the verified claims and determine whether to authorize access to the resource.\n- Optionally the Web Site will request additional claims to meet the needs to authorize access.\n- In computer networking a variety of statements can be made by a user to acquire authorized access to a resource.\n- There seems to be little agreement around the industry on what a scope really is  since if was first used in OAuth 2.0.\n- also SAML 2.0 scopes\nThe name of the scope is followed by two scores for the risk to the user: (1) user security applies for both loss of access loss of control, (2) user privacy applies to the impact if the data is made public. These scores are not based on data, but are merely examples to show the concept.\n|Name||Sec Value||Priv Risk||Notes|\n|openid||5||0||requests access to the user_id (sub) Claim which is assumed to be pair-wise unique for the privacy score.|\n|profile||2||4||requests that access to the End-User’s profile Claims excluding the address and email Claims.|\n|4||4||requests that access to the email and verified Claims|\n|Email validated||2||0||more significant for AuthN - needed if noticed desired|\n|address||3||4||requests access to address Claim|\n|addr validated||3||0||for example by AAMVA|\n|phone||5||5||requests that access to the phone_number Claim (assumed SMS capable)|\n|phone validated||2||0||more significant for AuthN - needed if noticed desired|\n|user device location||4||4||request for location of device used for this interaction (note that IP addresses leak a fairly good approximation of this)|\nThe above canonical scopes will be extended over time as new types of request for user claims are understood.\n- Vittorio Bertocci, On The Nature of OAuth2’s Scopes. (2018-09-04) Auth0 https://auth0.com/blog/on-the-nature-of-oauth2-scopes/"", 'Web Application Penetration Testing Services\nLocate and Remediate Your Application Security Flaws\nOWASP Top 10\nWeb Application Testing Exceeding the OWASP Top 10\nThe OWASP Top 10 provides a way to rank and remediate the top 10 most critical web application security risks. Below is a list of the most current release for OWASP Top 10:\nCurrent OWASP Top 10 List Released for 2021-2022:\n- Broken Access Control\n- Cryptographic Failures\n- Insecure Design\n- Security Misconfiguration\n- Vulnerable and Outdated Components\n- Identification and Authentication Failures\n- Software and Data Integrity Failures\n- Security Logging and Monitoring Failures\n- Server-Side Request Forgery (SSRF)\nAutomated vs. Manual Web Application Penetration Testing\nThe expert penetration testers at Artifice Security use automated scanners at the beginning of the assessment (10%) and then pivot into manual penetration testing for the remaining part (90%). Knowing the web application’s context, we can provide penetration tests geared to your individual security needs and make it relevant to your user base.\nWeb Application Penetration Test Methodology\nAfter years of performing penetration testing, Artifice Security has created a proven, repeatable methodology that will meet your organizational needs. As a manually-performed penetration testing company, we guarantee that no false positives will be in your report, and we provide proofs-of-concept that you can verify.\nOur security experts are diverse with experience working as system administrators, web developers, network engineers, and cloud specialists to military veterans and former NSA employees who held Top Secret clearances. Artifice Security consultants have also taught and spoken at cybersecurity conferences and created tools used by many penetration testers today. Each of our consultants is not only highly passionate about security, but they are also highly credentialed.\nDefine the Scope\nBefore the start of the penetration test, Artifice Security will collaborate with your team to determine the exact scope of your web application. We will communicate with your team to assess your application’s size, complexity, framework, roles, and how it is supposed to function normally.\n- Determine which applications are needed for testing to include domains and IP addresses for the host systems\n- Evaluate which directories or files, if any, are excluded from testing\n- Determine penetration testing performed in production or test/QA environment\n- Determine testing dates and times for the penetration test\n- Exchange key personnel and emergency contact information for any critical findings found.\nInformation Gathering / Recon Phase\nDuring the information-gathering phase of the assessment, Artifice Security will perform passive information gathering against your organization using Open Source Intelligence (OSINT) tools and techniques. This public dat a can help us determine undiscovered risks to your business and show you what anonymous information is out there on the Internet. This targeted intelligence includes the following checks:\n- Searches for documents such as PDF, DOCX, XLSX, and PPT documents that may contain exposed sensitive or customer information without your knowledge\n- Searches on the Internet and Darkweb for leaked credentials contained in password breach databases\n- Searches in repositories such as Github and other developer forums that may contain sensitive data related to your web application or organization\n- Checks to find similar domain names as yours to determine your risk to phishing (risks to domain spoofing)\n- Exposed robots.txt file to find potential hidden directories and files.\n- Map out and crawl through the application using a proxying tool\n- Enumerate all directories and subdomains\n- Search for possible hidden directories and files\n- Perform subdomain takeover checks\n- Check cloud services for misconfigurations (e.g., publicly exposed S3 buckets)\n- Check all possible open ports and services on the host server\n- Determine frameworks in use and associated software and libraries in use\n- Research and correlate known vulnerabilities for libraries and services used by the application\nAttack and Exploitation Phase\n- Configuration and Deployment Management Testing\n- Identity Management Testing\n- Authentication Testing\n- Authorization Testing\n- Session Management Testing\n- Data Validation Testing\n- Error Handling Testing\n- Cryptography Testing\n- Business Logic Testing\n- Client-Side Testing\n- API Testing\nThe report begins with an executive summary which gives a layman’s explanation of the findings and conveys the overall risk to your web application(s) and organization. In addition to a summary of findings, we also provide a list of positive results found during testing. Next, the report explains how we determine criticality and risk for each discovery so you can better understand how we prioritize findings and how we rate severity for each vulnerability.\nFurther in the report, we break down each vulnerability in technical detail, including a summary of the finding, affected location(s), proofs-of-concept, and remediation steps. Each detailed proof-of-concept has easy-to-follow steps for your team to recreate the process of how we exploited the vulnerability.\nIn addition to the report, Artifice Security also provides you with a customer-facing report and attestation letter if needed.\nRemediation Testing (Retesting)\nAs part of your penetration test, Artifice Security includes performing remediation testing (retesting) against your web application after your team remediates all findings. This retesting helps ensure your organization has adequately implemented changes to fix all vulnerabilities. Remediation and retesting also give compliance auditors and customers proof of your lowered or eliminated risk. After remediation testing completes, we will provide you with an updated report that reflects the current state of your web application.\nFrequently Asked Questions\nWhat information is needed for a web application penetration test?\nTo start a web application penetration test, we need to scope the application properly. The scoping process determines how long it will take to perform the penetration test based on the size and complexity of the web application. We need access to the web application and credentials if it is an authenticated web application for testing. Additionally, it helps to know if your organization hosts the application in the cloud and if there are any third-party APIs or connections within the web application.\nWhy is manual penetration testing important for a web application penetration test?\nMany areas of a web application need manual techniques performed. For example, the information-gathering phase needs to be done manually by a consultant when starting a web application penetration test. This information can reveal potential vulnerabilities such as past compromises or exposures that were made public.\nIf you solely rely on automated scanners, your results will also have many false positives and worse, false negatives. With manual penetration testing, all findings are 100% proven.\nAdditionally, an automated scanner might determine if anti-CSRF (Cross-Site Request Forgery) tokens are used. However, there are no ways to determine if CSRF vulnerabilities exist without manually exploiting the web application.\nWhen testing session management vulnerabilities, the consultant will attempt to exploit cookies to move into other accounts or to escalate privileges as an administrator.\nLastly, automation of business logic abuse cases is not possible. Business logic testing includes uploading malicious payloads to the web application, forged requests, integrity checks, process timing attacks, and circumvention of workflows.\nWill the penetration test affect the performance of my web host server?\nIs it best to perform the web application penetration test against a production or test environment?\nWhile a test environment is preferred, Artifice Security regularly performs web application pentests against production environments without issues. Artifice Security has vast experience testing both types of environments.']"	['<urn:uuid:d2dba15a-824f-4eb6-817c-7fdc7abc6c0c>', '<urn:uuid:064a0195-f58c-47ff-bc5e-71314a0c9e27>']	open-ended	direct	short-search-query	distant-from-document	multi-aspect	novice	2025-05-12T22:49:38.933606	5	86	1724
43	Why did some women join conservative religious movements?	Women joined religious fundamentalist movements due to complex motivations including: a desire to end their sense of loneliness and lack of power, a wish to adopt aspects of modernity while maintaining traditional connections, and to gain authority over others.	['Portraits of Two Islamist Women: Escape from Freedom or from Tradition?1\nIn the last two decades as the political landscape of the Middle East, North Africa, and Southeast Asia increasingly has become identified with conservative Islamist discourses, a number of feminist historians have tried to probe the contradictions in an attempt to understand the underlying reasons for the growth of Islamism. Most of these studies, including writings by this author, have adopted a broad historical, political, or sociological lens through which gender relations and the concerns of women of the region have been analyzed. In this article on Islamist women of Iran, however, I wish to adopt a somewhat different perspective. I am not looking at rank-and-file women who, willingly or not, acquiesced to the Islamist movement after the 1979 Revolution. Rather, I am interested in a more intimate, almost personal, exploration of the lives of two women who assumed leadership roles in the Islamist movement before the Revolution.\nMy point is that religious fundamentalist movements often have women in prominent positions, and their role is to help develop and popularize the movement’s gender ideology. These women are hardly subordinate in the obvious sense. Many join the movement as a result of a complicated series of motivations, including a desire to end their own sense of loneliness and lack of power, a wish to appropriate certain aspects of modernity without alienating their traditional milieu, or to gain authority over others.\nThis type of study has been explored for other historical periods, and other countries, as will be seen below. However, it has not been easy for Iranian academic feminists to carry out because of political considerations inside Iran. Outside Iran, it has been emotionally wrenching due to the wide ideological, political (and geographical) gulf that has separated us for over twenty years. And yet the changes that have been going on in Iran since 1997, the emergence of a strong Reformist movement that includes many advocates of women’s rights who have ties to the Islamist movement, and the new discourse on Islamic feminism, all make it imperative to conduct precisely this type of study.\nI also wish to draw on the particular insight I have gained from years of studying and teaching Erich Fromm and other theorists of the Frankfurt School. I believe that Fromm’s analysis of authoritarianism in the 1930s and 1940s, together with more recent studies on the religious right in the United States, can help shed new light on the complex phenomenon of Islamism in Iran and some reasons for its growth in the 1970s and 1980s.\nAt the same time, an exploration of Islamism in Iran, particularly with an emphasis on gender, can enrich theories of authoritarianism by pointing to sites of changes and resistance and by showing that the decision to join these movements stems from a desire to both “escape from tradition” and “escape from freedom.” Women who join right-wing Islamist movements gain a number of rights that the traditional patriarchal society does not offer them. These privileges, however, come at a heavy cost to others, especially secular advocates of women’s rights who have suffered immensely under the Islamic theocracy of Iran.\nModern Individualism and Rise of the Right\nIn his studies on fascist and totalitarian societies in the twentieth century, Fromm argued that the growth of individualism in modern Europe resulted in psychological trauma with significant political ramifications. Fromm held a doctorate in sociology, was a practicing psychoanalyst, and became a founding member of the Frankfurt School of Critical Theory, which forged a new synthesis of Marx, Freud, and Nietzsche in its studies of the family and authoritarianism. Fromm wrote about the disruption of the traditional family in urban Western societies and the sense of insignificance and loneliness that the individual felt as a result. Modernity had freed human beings from the highly hierarchical mold of medieval life, with its rigid guild structure and well-known patterns of family obligations, and introduced the possibility of “freedom from” traditional society. But this more hierarchical medieval social order also had given human beings a relative sense of security since everyone’s place in society was predetermined. Thus, the modern notion of freedom became an unbearable burden for some, to whom freedom of choice meant insecurity and loss of identity.2 The loss of status of the father in the modern family was a contributing factor to the growth of fascism in several ways. First, it contributed to an anxiety over rapid downward mobility as well as anger toward those deemed responsible for this social and economic loss. Second, the loss of status of the traditional patriarch, due to a myriad of socio-economic factors, helped fascist movements because they could claim to be the defenders of traditional patriarchy. They symbolically took the place of the father by calling for a restoration of national “pride and dignity.”3\nThe basic human desire for identity and rootedness now manifested itself in extreme forms of nationalism and fascism. One type of response for individuals was “to become one with the world by submission to a person, to a group, to an institution, to God.”4 It was to transcend one’s loneliness and individual existence “by becoming part of some body or something bigger than” oneself.5 A second way was to express one’s desire for connectedness by moving in the opposite direction, toward domination over others. An individual could “try to unite himself with the world by having power over it, by making others a part of this constructed world and thus transcending a sense of individual existence through domination.”6 Through this symbiotic relation of submission/domination, a form of sadomasochism, the individual gained a sense of attachment, direction, and power, though not necessarily a sense of integrity.7 Andrea Dworkin and Elinor Burkett, who have studied right-wing women in the United States, suggest a similar pattern of uprootedness, loss of integrity, and ultimately symbiotic attachment to a conservative movement. The individual completely submits to a higher principal, while also dominating others. Dworkin argues that women who have been kept “ignorant of technology, economics, most of the practical skills to function autonomously” find themselves mystified in married life, especially in an abusive and lonely one. Women such as Marable Morgan and Anita Bryant, who later became stars in the religious right, regularly lectured on how they transformed their sense of helplessness by total submission to Jesus (the church). At the same time, their new responsibilities and their need to travel, preach, and “carry out the work of God” relieved them from many domestic chores, additional pregnancies, and even a confining marriage, but without experiencing divorce and its stigma.8 My focus in this article is the complex underlying patterns of submission/domination that compelled two Iranian women, Zahra Rahnavard and Marziyeh Dabbagh, to become followers of Ayatollah Ruhollah Khomeini and join the leadership of the religious right before the 1979 Revolution.9 I am not suggesting that every woman who became an Islamist leader fits the same pattern as these women; the phenomenon of the religious right is far too complex to fit any single model. I do think, however, that despite geographical, historical, and cultural differences between the phenomena studied by Fromm/Dworkin (European, American, and Christian) and the women in this article (Iranian and Muslim), a somewhat similar pattern can be detected. For example, some of the followers of the Islamist movement in the 1960s and 1970s were highly ambitious women who were caught in the dichotomy between tradition and modernity. They seemed to gain a new sense of purpose and identity as a result of submitting to the Islamist movement and its ethico-political structure. As they gradually became leading members of the Islamist movement, their relatives recognized their superior position, including their husbands and fathers. In this way they gained another benefit, respect and authority within the family and the community. Eventually they were also relieved of many of the burdens of a traditional life. Paradoxically, then, their allegiance to a conservative patriarchal movement that advocated women’s subordination actually allowed them to be more ambitious, to gain more power and exercise extensive leadership over others, and to live much more gratifying personal lives. After the 1979 Revolution, their highly conservative political activity resulted in severe restrictions on numerous other women who lost their positions either because they rejected the strict orthodoxy of the Islamist state or because they did not fit the patriarchal mold the new government was constructing. Others left the country and chose a lonely life in exile rather than live under the Islamic Republic.10']	['<urn:uuid:cf202c66-6c7e-4741-be34-c43ad409b8a6>']	factoid	direct	concise-and-natural	distant-from-document	single-doc	novice	2025-05-12T22:49:38.933606	8	39	1419
44	What's the basic concept behind the slingshotting technique in PVP?	Slingshotting is a PVP tactic that involves faking out your opponent by making them think you're going in one direction, then suddenly going in another. The technique involves flying in a certain direction, then flipping 180 degrees and flying back. As your enemy adjusts their course to catch up, you momentarily gain a range advantage that can be used to either apply or escape from a warp scrambler or disruptor.	['Slingshotting is an extremely useful strategy in PVP that involves changing directions to control range in a fight, allowing you to tackle/web your opponent, or break out of point range. A thorough understanding of the tactic can save your ship and win fights. It can also teach you to recognize the tactic, and correct yourself if it is being applied to you. In this guide, we will explore the applications of slingshotting, both to point a kiter, and to escape from one.\nWhat is Slingshotting?\nSlingshotting involves faking out your opponent, making them think you’re going in one direction, then suddenly going in another. This is one of the most useful tactics in PVP because it can be used on either side of the fight. A properly executed slingshot can be used to put a warp scrambler on a kiting ship to disable its microwarpdrive and give you the edge. The slingshot can also be used to remove a kiting ship’s point and escape a losing fight.\nThe process is easy to understand, but a little more difficult to master. However, a proper understanding of this technique can win fights, and prevent enemies from slipping away.\nHow to Slingshot\nThe Slingshot technique is very straightforward. Again, it involves flying in a certain direction, then flipping 180 degrees and flying back. As your enemy adjusts course to catch up, you momentarily gain a range advantage. This advantage can be used to apply or escape from a warp scrambler or disruptor.\nApplying a Point to a Kiter\nA kiter will likely have you pointed with a warp disruptor, and keep a range of 15+km with a microwarpdrive. This means that he is out of range of your warp scrambler/stasis webifier, so you can’t disable his microwarpdrive and lock him down.\nFirst, have a look at your opponent. Analyze his direction of travel and velocity to predict where he’ll be in about 5 seconds. Activate your propulsion mod, turn your camera 180 degrees, and double click in space roughly opposite to this location. (Note: For an easier but slightly less effective method, choose the Keep At Range option with a large distance, like 100km.) You will begin burning away from your opponent. Your opponent’s ship will begin to correct for this in order to maintain his orbit range, and begin flying towards you. Once your opponent nears facing you, choose Approach to burn towards his ship. Your ship will perform a 180 degree turn and rapidly close on your opponent, while his ship begins to slow down and turn later.\nFor just a moment, you will begin to close the gap on your opponent. Overheat your warp scrambler/stasis webifier and keep a watchful eye on your range. Activate your warp scrambler the moment you’re close enough. Once his microwarpdrive is disabled, you’ll have control over the range of the fight. Bring your ship into a tight orbit of his, and don’t forget to remove overheating from your scrambler, or you’ll burn out your point. With range control against a kiting opponent, it becomes only a matter of time before his pod is floating through space.\nBreaking Point from a Kiter\nBreaking point from a kiter is similar to the strategy above, but in reverse order. If a kiter is keeping you at long range with a warp disruptor, you may have trouble fighting back. If you feel that you’re too weak to pin him down, or you have no warp scrambler to disable his microwarpdrive, disengaging may be your best option.\nAs in the previous strategy, analyze your opponent’s direction of travel and velocity. Keep an eye on the space behind you, looking for warpable objects. Once a warpable object is behind you, predict where your enemy will be in about 5-7 seconds and double click on that point in space. DO NOT click Approach — you will lose precious time flying in circles and may end up dead. You’ll find that as you near your opponent’s ship, it will begin to correct for your course and fly close to parallel with you. As your opponent burns away, turn your camera 180 degrees and find the warpable object you selected earlier. Press Align To, and your ship will flip 180 degrees and begin burning a straight line away from your opponent. During the precious seconds your opponent attempts to turn and catch up, you will begin to pull away. Spam the Warp To button so that as soon as you break out of range of your opponent’s warp disruptor, your ship warps to safety. Note: Try to pick a cluster of objects, so that your final destination is ambiguous. Varying the range at which you warp can also be a useful tactic, in case your opponent tries to chase you down.']	['<urn:uuid:48db013f-b4f9-461d-9cb6-17ea675fb9ec>']	open-ended	with-premise	concise-and-natural	similar-to-document	single-doc	expert	2025-05-12T22:49:38.933606	10	70	798
45	rand function powerapps definition	The Rand function in PowerApps returns a pseudo-random number.	['PowerApps Formula reference for PowerApps\nFormula reference for PowerApps\nWhen building PowerApps I have found the below from Microsoft incredibly really helpful, an index of awesomeness for all things related to PowerApp formulas. I have lifted this from the Microsoft page but kept all the hyper links to allow you to drill into each piece of functionality.\nAbs – Absolute value of a number.\nAcceleration – Reads the acceleration sensor in your device.\nAcos – Returns the arccosine of a number, in radians.\nAcot – Returns the arccotangent of a number, in radians.\nApp – Returns information about the currently running app, such as which screen is currently displayed.\nAsin – Returns the arcsine of a number, in radians.\nAtan – Returns the arctangent of a number, in radians.\nAtan2 – Returns the arctangent based on an (x,y) coordinate, in radians.\nAverage – Calculates the average of a table expression or a set of arguments.\nBack – Displays the previous screen.\nBlank – Returns a blank value that can be used to insert a NULL value in a data source.\nCalendar – Retrieves information about the calendar for the current locale.\nChar – Translates a character code into a string.\nClock – Retrieves information about the clock for the current locale.\nCoalesce – Replaces blank values while leaving non-blank values unchanged.\nCollect – Creates a collection or adds data to a data source.\nColor – Sets a property to a built-in color value.\nColorFade – Fades a color value.\nColorValue – Translates a CSS color name or a hex code to a color value.\nCompass – Returns your compass heading.\nConcat – Concatenates strings in a data source.\nConcatenate – Concatenates strings.\nConnection – Returns information about your network connection.\nCount – Counts table records that contain numbers.\nCos – Returns the cosine of an angle specified in radians.\nCot – Returns the cotangent of an angle specified in radians.\nCountIf – Counts table records that satisfy a condition.\nCountRows – Counts table records.\nDataSourceInfo – Provides information about a data source.\nDate – Returns a date/time value, based on Year, Month, and Day values.\nDateAdd – Adds days, months, quarters, or years to a date/time value.\nDateDiff – Subtracts two date values, and shows the result in days, months, quarters, or years.\nDateTimeValue – Converts a date and time string to a date/time value.\nDateValue – Converts a date-only string to a date/time value.\nDay – Retrieves the day portion of a date/time value.\nDefaults – Returns the default values for a data source.\nDegrees – Converts radians to degrees.\nDistinct – Summarizes records of a table, removing duplicates.\nDownload – Downloads a file from the web to the local device.\nDropColumns – Returns a table with one or more columns removed.\nEditForm – Resets a form control for editing of an item.\nEndsWith – Checks whether a text string ends with another text string.\nErrors – Provides error information for previous changes to a data source.\nEncodeUrl – Encodes special characters using URL encoding.\nExit – Exits the currently running app.\nExp – Returns e raised to a power.\nFilter – Returns a filtered table based on one or more criteria.\nFind – Checks whether one string appears within another and returns the location.\nFirst – Returns the first record of a table.\nFirstN – Returns the first set of records (N records) of a table.\nForAll – Calculates values and performs actions for all records of a table.\nGroupBy – Returns a table with records grouped together.\nHashTags – Extracts the hashtags (#strings) from a string.\nHour – Returns the hour portion of a date/time value.\nIf – Returns one value if a condition is true and another value if not.\nIfError – Detects errors and provides an alternative value or takes action.\nIsEmpty – Checks for an empty table.\nIsMatch – Checks a string against a pattern. Regular expressions can be used.\nIsNumeric – Checks for a numeric value.\nIsToday – Checks whether a date/time value is sometime today.\nLanguage – Returns the language tag of the current user.\nLast – Returns the last record of a table.\nLastN – Returns the last set of records (N records) of a table.\nLaunch – Launches a web address or an app.\nLeft – Returns the left-most portion of a string.\nLen – Returns the length of a string.\nLn – Returns the natural log.\nLoadData – Loads a collection from PowerApps private storage.\nLocation – Returns your location as a map coordinate by using the Global Positioning System (GPS) and other information.\nLookUp – Looks up a single record in a table based on one or more criteria.\nLower – Converts letters in a string of text to all lowercase.\nMax – Maximum value of a table expression or a set of arguments.\nMid – Returns the middle portion of a string.\nMin – Minimum value of a table expression or a set of arguments.\nMinute – Retrieves the minute portion of a date/time value.\nMod – Returns the remainder after a dividend is divided by a divisor.\nMonth – Retrieves the month portion of a date/time value.\nNavigate – Changes which screen is displayed.\nNewForm – Resets a form control for creation of an item.\nNow – Returns the current date/time value.\nParam – Provides access to parameters passed to the app when the user opened it.\nParent – Provides access to a container control’s properties.\nPatch – Modifies or creates a record in a data source, or merges records outside of a data source.\nPi – Returns the number π.\nPlainText – Removes HTML and XML tags from a string.\nProper – Converts the first letter of each word in a string to uppercase, and converts the rest to lowercase.\nRadians – Converts degrees to radians.\nRand – Returns a pseudo-random number.\nRefresh – Refreshes the records of a data source.\nRemove – Removes one or more specific records from a data source.\nRemoveIf – Removes records from a data source based on a condition.\nRenameColumns – Renames columns of a table.\nReplace – Replaces part of a string with another string, by starting position of the string.\nReset – Resets an input control to its default value, discarding any user changes.\nResetForm – Resets a form control for editing of an existing item.\nRevert – Reloads and clears errors for the records of a data source.\nRGBA – Returns a color value for a set of red, green, blue, and alpha components.\nRight – Returns the right-most portion of a string.\nRound – Rounds to the closest number.\nRoundDown – Rounds down to the largest previous number.\nRoundUp – Rounds up to the smallest next number.\nSaveData – Saves a collection to PowerApps private storage.\nSearch – Finds records in a table that contain a string in one of their columns.\nSecond – Retrieves the second portion of a date/time value.\nSet – Sets the value of a global variable.\nShowColumns – Returns a table with only selected columns.\nShowError – Displays an error message to the user.\nShuffle – Randomly reorders the records of a table.\nSin – Returns the sine of an angle specified in radians.\nSort – Returns a sorted table based on a formula.\nSortByColumns – Returns a sorted table based on one or more columns.\nSplit – Splits a text string into a table of substrings.\nSqrt – Returns the square root of a number.\nStartsWith – Checks if a text string begins with another text string.\nStdevP – Returns the standard deviation of its arguments.\nSubstitute – Replaces part of a string with another string, by matching strings.\nSubmitForm – Saves the item in a form control to the data source.\nSum – Calculates the sum of a table expression or a set of arguments.\nSwitch – Matches with a set of values and then evaluates a corresponding formula.\nTable – Creates a temporary table.\nTan – Returns the tangent of an angle specified in radians.\nText – Formats a number as a string for display.\nThisItem – When in a gallery or form, returns the data for the current item from the container.\nTime – Returns a date/time value, based on Hour, Minute, and Second values.\nTimeValue – Converts a time-only string to a date/time value.\nTimeZoneOffset – Returns the difference between UTC and the user’s local time in minutes.\nToday – Returns the current date/time value.\nTrim – Removes extra spaces from the ends and interior of a string of text.\nTrimEnds – Removes extra spaces from the ends of a string of text only.\nUngroup – Removes a grouping.\nUpdate – Replaces a record in a data source.\nUpdateIf – Modifies a set of records in a data source based on a condition.\nUpper – Converts letters in a string of text to all uppercase.\nUser – Returns information about the current user.\nValidate – Checks whether the value of a single column or a complete record is valid for a data source.\nValue – Converts a string to a number.\nVarP – Returns the variance of its arguments.\nViewForm – Resets a form control for viewing of an existing item.\nWeekday – Retrieves the weekday portion of a date/time value.\nYear – Retrieves the year portion of a date/time value.']	['<urn:uuid:166e9ee3-1f46-4db2-96f2-c92e49addc5b>']	open-ended	direct	short-search-query	similar-to-document	single-doc	novice	2025-05-12T22:49:38.933606	4	9	1556
46	Why do scientists think alien life must exist somewhere?	Scientists believe alien life is inevitable based on the sheer probability of its existence, given that our Galaxy has 100 billion stars and our Universe has upwards of 100 billion galaxies. Additionally, with the increasing discovery of extrasolar planets, the chances of finding life beyond Earth seem more likely.	['As astronomical instrumentation becomes more sophisticated, we are rapidly approaching a crossroads in the search for extraterrestrial life, according to a leading planetary scientist. It’s also “inevitable” that alien life exists in the universe given the preponderance of extrasolar planets that are being discovered — it’s up to us to seek out the extraterrestrial biosignatures.\nThese conclusions are outlined by Sara Seager, Professor of Planetary Science and Physics at the Massachusetts Institute of Technology (MIT), in a paper published in the journal Proceedings of the National Academy of Sciences on Aug. 4.\n“In the coming decade or two, we will have a lucky handful of potentially habitable exoplanets with atmospheres that can be observed in detail with the next generation of sophisticated space telescopes,” writes Seager, pointing out that NASA’s James Webb Space Telescope (JWST) and a planned direct-imaging space telescope will be able to seek out biosignatures (i.e. chemicals created by extraterrestrial biology) in the atmospheres of nearby exoplanets. The JWST is set for launch in 2018.\n“Life can be inferred by the presence of atmospheric biosignature gases — gases produced by life that can accumulate to detectable levels in an exoplanet atmosphere,” she writes.\nTo date, a handful of exoplanetary atmospheres have been studied through the analysis of their host star’s light passing through their atmospheres. As an alien world orbits its star, from our perspective, it may block some of the starlight from view and be registered as a “transit.” The transit method is used by NASA’s Kepler space telescope and has so far confirmed the detection of hundreds of exoplanets. But this method can also help us analyze the chemicals contained in exoplanetary atmospheres.\nDuring a transit, if that exoplanet has an atmosphere, some of the starlight is filtered through its atmosphere. Some wavelengths of that light are absorbed by specific chemicals, leaving a spectroscopic ‘fingerprint’ in the starlight we detect. Although only the largest class of exoplanets have so far had their atmospheres analyzed in this way (gas giants with tight orbits around their stars known as “hot-Jupiters”), Seager argues that with the advent of advanced space telescopes, the composition of smaller worlds’ atmospheres could also studied. Habitable “super-Earths” fall into this category.\nOnce this happens, we can begin to observe small rocky worlds, potentially detecting spectroscopic signatures of chemicals associated with life.\nAlthough the next generation of space telescopes may be able to detect biosignatures in nearby exoplanets, Seager urges caution.\n“(M)any different gases are produced by life, but the anticipated diversity of exoplanet atmosphere composition and host star environments may yield different detectable biosignature gases than the terrestrial examples. Even with excellent data, false positives will drive a permanent ambiguity in many cases,” she adds.\nMolecules such as methane can be generated through biological (methanogenic) and geological (volcanic) processes, so the detection of methane in an exoplanetary atmosphere may not indicate life. To find out what is generating that gas, astronomers will need to study the atmosphere in its entirety to avoid jumping to conclusions about that world’s biological potential. The identification of these “false positives,” using advanced instrumentation, will be critical when seeking out genuine biosignatures.\nThe advances in space-based observatories are tantalizing and, with the launch of JWST and other advanced direct imaging telescopes (such as the “star shade” concept), we could start studying small habitable worlds with atmospheres and teasing hints as to any biosignatures within the next couple of decades.\nBut to fully investigate this exciting class of exoplanet, “we require the ability to directly image exoplanets orbiting 1,000 or more of the nearest sun-like stars.” Such an endeavor would require a huge space-borne observatory — an optical telescope with a diameter exceeding 10 meters. Considering the Hubble Space Telescope is only 2.4 meters in diameter, the exoplanetary atmosphere telescopes of the future will require some huge innovative leaps before they become a reality.\nOne thing seems certain, however. The longer we gaze into the stars, the more certain we become about the possibility for life beyond Earth.\n“Our own Galaxy has 100 billion stars, and our Universe has upwards of 100 billion galaxies — making the chance for life elsewhere seem inevitable based on sheer probability,” writes Seager. “We can say with certainty that, for the first time in human history, we are finally on the verge of being able to search for signs of life beyond our solar system around the nearest hundreds of stars.”\nvia The Guardian']	['<urn:uuid:cc1685cf-3414-4001-9237-220a29dbfb93>']	open-ended	direct	concise-and-natural	similar-to-document	single-doc	novice	2025-05-12T22:49:38.933606	9	49	741
47	I just got some cherry shrimp and I'm curious about their reproduction. What's the difference between the number of eggs a ghost shrimp and a cherry shrimp typically lay?	A female ghost shrimp typically lays between 50-75 eggs per breeding cycle, while a female cherry shrimp lays fewer eggs, typically between 20-30 eggs at a time. Both species can breed multiple times throughout the year.	['Cherry shrimp and ghost shrimp are both freshwater shrimp that are an excellent addition to your aquarium. Cherry shrimp has become one of the most popular varieties today because they’re inexpensive, but both have some common similarities.\nThere are many similarities between cherry shrimp and ghost shrimp. Cherry shrimp’s lifespan ranges between six months and one year, similar to ghost shrimp’s one to two-year lifespan. They both live in freshwater and have similar diets.\nRead on to discover the differences and similarities between ghost shrimp and cherry shrimp. We’ll discuss their diets, lifespans, and breeding habits, as well as their tank requirements.\nTank Requirements of Ghost Shrimp Vs. Cherry Shrimp\nGhost shrimp and cherry shrimp are both freshwater aquarium creatures. They have different requirements to live in an aquarium.\nGhost shrimp require a tank that is about one-fifth the size of cherry shrimp requirements. They also have different light needs: ghost shrimp are nocturnal, while cherry shrimps require bright lights.\nThe cherry shrimp is the smaller of the two and may be more suitable for a small tank. Ghost shrimp can live in larger tanks with other non-aggressive animals like snails or fish that require less light, such as ghost shrimps’ nocturnal habitat requirements.\nTank Requirements of Cherry Shrimp\nCherry shrimps require a tank with a water temperature between 70 – 80 degrees Fahrenheit, while ghost shrimp need the temperature to be kept at 64- 72 degrees Fahrenheit.\nThe cherry shrimp grows up to one inch long from its tail, whereas the ghost shrimp can grow up to three inches in length, including their tails. The cherry shrimp is smaller than most ghost shrimp and is pink compared to white or transparent ghost shrimp.\nGhost shrimp are nocturnal, while cherry shrimps are diurnal. This means that ghost shrimp usually come out at night, but cherry shrimps can be seen during the daytime.\nCherry shrimp also require a tank with high levels of dissolved oxygen. They move faster than most other aquatic creatures in low-oxygen environments and need more surface area for gas exchange because their metabolism is fast. Ghost shrimp don’t have these requirements to live comfortably in an aquarium environment.\nTank Requirements of Ghost Shrimp\nTheir timid nature means that ghost shrimp need only a small tank. They are not aggressive and do not grow very large, so you can keep them in various tanks depending on the size of your living space.\nGhost shrimp respond well to substrate at the bottom of your tank and gentle water movement near their home. Ghost shrimp care is straightforward because they’re a hearty species that respond well to extremes, such as acidic waters with pH as low as 3.0.\nGhost shrimp have no special lighting requirements and can be kept alongside other freshwater fish if the tank space isn’t small or crowded.\nDiet & Feeding of Ghost Shrimp Vs. Cherry Shrimp\nThe diet of cherry shrimp and ghost shrimp is straightforward. They will eat almost anything that floats by in your tank, from sinking pellets to vegetables and snails.\nCherry shrimp are more resilient than ghost shrimp and will most likely not have any problems with the food you feed them. On the other hand, Ghost shrimps can be picky eaters (especially during their early stages) and may need additional snacks to maintain a healthy diet.\nGhost shrimp keepers often offer them fresh vegetables, like spinach or lettuce, and many forms of protein.\nDiet & Feeding of Cherry Shrimp\nThe cherry shrimp diet is simpler because it only needs the occasional meal of fresh veggies such as cucumbers or zucchini slices cut into thin strips.\nCherry shrimp should be fed a small amount every other day with plenty of food leftover after feeding, so there’s always something to nibble on. It can also help remove any uneaten food from the aquarium a couple of hours after feeding.\nCherry shrimps are not as active as ghost shrimps, making cherry shrimp ideal for beginners who want an easy-care freshwater pet. When you first bring cherry shrimp home, it is essential to give them time out of the water every day until they acclimate to their new environment.\nMost experts recommend keeping your cherry shrimp in one gallon or less fresh water with plenty of hiding places like plants or caves. As cherry shrimp need a balanced diet to stay healthy, you must give them food like vegetables, meaty foods, or sinking pellets every day.\nFeeding your cherry shrimps once a day will keep their tank clean as the uneaten food will float over after feeding, so there’s always something to nibble on. It can also help remove any uneaten food from the aquarium a couple of hours after feeding.\nDiet & Feeding of Ghost Shrimp\nGhost shrimp will always need fresh food, unlike Cherry shrimp, which can survive without any nutrients. Ghost shrimp cannot live for more than two days without being fed.\nYou will have to make sure their tank is clean at all times. Otherwise, bacteria growth starts to take over, which means your water quality goes down, and eventually, everything dies. The ghost shrimp diet is not just about what they eat either; you must provide the right amount of calcium in the tank so that their shells grow big and strong!\nGhost shrimp are carnivores and much larger than cherry shrimps. Unlike their smaller counterparts, ghost shrimp do not feed primarily on plant matter – they require a meat-based diet to survive.\nLifespan And Size of Ghost Shrimp Vs. Cherry Shrimp\nCherry shrimp and ghost shrimp have similar life spans. Ghost shrimp will tend to live a bit longer than cherry shrimp, especially if they are well taken care of. Both species have a lifespan of one to two years or less.\nLifespan And Size Ghost Shrimp\nGhost shrimp are an ideal size for feeder fish to prey on. Ghost shrimp can reproduce sexually and grow quickly to about two inches long. Ghost shrimp make excellent aquarium creatures because of their peaceful nature and appearance.\nGhost shrimp typically come in small sizes (averaging about one inch). The average ghost shrimp’s lifespan is one to two years at most.\nThis shrimp species is made up to a large degree out of water and air, making it possible for light from external sources to pass through all parts of the shrimp with ease. As such, they have become known as glass shrimp due to their transparency -which means you can see their insides quite plainly.\nLifespan And Size Cherry Shrimp\nThe lifespan of a cherry shrimp is between six months and one year. The cherry shrimp grows on average between two to three inches.\nCherry shrimps typically come in small sizes (averaging about one to two-inch inches). This makes cherry shrimp popular additions to fish tanks because they don’t need food very often or grow too big.\nGhost Shrimp Vs. Cherry Shrimp Breeding\nCherry shrimps have been around longer than ghost shrimps. Still, because of their delicate nature, cherry shrimp babies tend to die before reaching adulthood. Cherry shrimp populations are much lower today than they were 30 years ago.\nGhost shrimp eggs usually produce many baby ghost shrimp per egg mass, making them easier to find at your local pet store or online aquarium retailer. It all boils down to care requirements vs. breeding needs when deciding which one might be right for you.\nCherry Shrimp Breeding\nThe cherry shrimp is delicate and sensitive to changes in water quality, temperature fluctuations, overcrowding, or crowded tank space. One of the advantages that cherry shrimps have over ghost shrimps is their ability to breed and produce many offspring at one time without much effort on your part beyond feeding them occasionally.\nIn contrast, a ghost shrimp’s mating process can be difficult due to the male’s tendency to latch onto the female for extended periods of time. This may discourage other males from trying again later if she doesn’t release him within 30 seconds after his first try.\nIt’s important not to let too many females near one male because they could end up badly injured if he won’t detach himself.\nGhost Shrimp Breeding\nFemale Ghost shrimp are too small to carry eggs, so they need more time to mature sexually than males. Female shrimp become fertile at nine months of age, and the 50-75 hatchlings she lays will not need parental care before dispersal.\nProvide them with a lower tank with some water to breed in when the female has laid her eggs. To remove the eggs for hatching, quickly scoop out all of the egg clusters after fertilization and put them into another container while preserving as much water as possible.\nSimilarities of Cherry Shrimp and Ghost Shrimp\nThere are many similarities between cherry shrimp and ghost shrimp. For example, cherry shrimp and ghost shrimps are approximately the same sizes. They have similar lifespans; both eat a lot of food in one sitting.\nGhost shrimp can live anywhere between one to twenty-four months, with an average lifespan being twelve months. The ghost shrimp grows about two inches long on average. A cherry shrimp is smaller than ghost shrimps (averaging around one to two inches).\nThese two shrimp species are similar in size and live for roughly around the same amount of time. They are also similar in the types of food they eat.\nCherry shrimp and ghost shrimps often stand apart because cherry shrimp have a pinkish color, while ghost shrimps tend to be transparent so that you can see their organs on the insides of their body.\nThe largest difference between these species of crustaceans is that cherry shrimps like to stay close to land because they do not swim as well as the other species do when it comes to water movement (ghosts).\nThere are many varieties of freshwater shrimp in the market today, but two popular types are cherry shrimp and ghost shrimp. These small creatures make great additions to aquariums because they’re inexpensive, colorful, easy to maintain, and live for around one year.\nCherry shrimp are a smaller variety of freshwater shrimp, and they’re usually pink in color. They have been popularized by their ability to breed quickly under warm water conditions. This type of shrimp is perfect for newbie aquarists because they typically have the best survivability rate and stay small enough to be eaten by fish or other shrimp.\nGhost Shrimp live for a short time in the wild because they are prey to many predators. With some simple adjustments, you can make your aquarium environment more stable and give these shrimp plenty of food sources at all times.', 'Cherry shrimp with eggs is a sight to behold! These tiny creatures are fascinating to watch, and it’s even more rewarding to help them hatch and grow into healthy adults. If you’re thinking about breeding cherry shrimp, here are seven quick steps to help you get started:\nIf you’re a passionate aquarium enthusiast, you’ve probably seen the adorable and vibrant cherry shrimp.\nThese small, fascinating creatures are not only a delight to observe in your aquarium but also offer the opportunity for a rewarding breeding experience.\nOne of the most captivating moments in a cherry shrimp owner’s life is witnessing shrimp eggs hatch into baby shrimp.\nIn this article, we’ll take you through the essential steps to ensure a successful hatching process and guide you toward happy hatchlings. So, let’s dive into the world of cherry shrimp breeding!\nDo Red Cherry Shrimp Give Birth or Lay Eggs?\nYes, cherry shrimp lay eggs. They do not give birth to live young. The female cherry shrimp will carry her eggs under her abdomen for about 2-3 weeks until they hatch.\nThe eggs are initially clear but will turn dark brown or black as they mature. The female will fan the eggs with her swimmerets to keep them oxygenated and clean.\nOnce the eggs hatch, the baby shrimp (called “shrimplets”) will be free-swimming. They are about the size of a grain of rice and are very vulnerable to predators. Providing the shrimplets with plenty of hiding places, such as plants and rocks, is important.\nA female cherry shrimp can lay 20 to 30 eggs at a time. She can breed multiple times throughout the year. The number of eggs shrimp lays will depend on her age, health, and water conditions.\n7 Quick Tips to Successful Cherry Shrimp Breeding\n1. Understanding Cherry Shrimp and Their Reproduction\nLet’s understand the basics before we embark on this exciting journey of nurturing baby shrimp. Cherry shrimp, scientifically known as Neocaridina heteropoda var. red, are a popular freshwater shrimp species that come in various colors, with the red cherry shrimp being particularly popular among enthusiasts.\nCherry shrimp are known for their fascinating reproductive behavior. Female shrimp carry eggs under their tail, known as a “saddle,” these shrimp’s eggs can develop into tiny, adorable hatchlings under the right conditions.\n2. Creating the Optimal Environment\nTo encourage successful breeding, providing the right conditions in your shrimp tank is crucial. Maintaining stable water parameters, including temperature, pH, and hardness, is essential. Aim for a temperature around 72-78 degrees Fahrenheit (22-26°C) and a pH level of 6.5-7.5.\n3. The Mating Process and Fertilization\nWhen the time is right, female cherry shrimp release pheromones to attract males for mating. Once a male shrimp mates with a female, he fertilizes the eggs under her tail. The fertilized eggs turn a darker color, indicating successful fertilization.\n4. Eggs Development and Care\nThe female shrimp will carry the fertilized eggs under her tail for about three to four weeks. It’s important to provide the shrimp with a healthy diet of biofilm, algae, and plankton to ensure the eggs receive proper nutrition.\n5. The Exciting Hatching Process\nAs the eggs develop, you’ll notice subtle changes in their egg color and appearance. The eggs will darken and eventually turn a dark black or brown color. This is a sign that the eggs are close to hatching. Patience is key during this phase, as the hatching process can take a few hours to a day.\n6. Welcoming the Newborn Shrimp\nOnce the eggs hatch, you’ll be greeted with tiny, translucent baby shrimp. These young shrimp are incredibly delicate and require a gentle environment. Maintain stable water parameters and provide hiding spots for the baby shrimp to find safety.\n7. Ensuring Survival and Growth\nVarious factors, including water quality, temperature, and food availability, can influence newborn shrimp’s survival rate. Keep in mind that baby shrimp are quite small and might require specialized shrimp food or crushed flakes to ensure they receive adequate nutrition.\nHow to Tell if Cherry Shrimp is Pregnant?\nIf you have cherry shrimp in your aquarium and suspect one of them may be pregnant, there are a few signs you can look out for. First, check the shrimp’s abdomen. A pregnant cherry shrimp female will have a rounder and larger abdomen than the males.\nAnother sign to look for is the presence of a saddle. A saddle is an orange or yellowish patch on the back of the female shrimp. This saddle is a cluster of green eggs waiting to be fertilized.\nOnce the shrimp eggs are fertilized, they will develop into a darker shade and become visible inside the saddle. Finally, keep an eye out for tiny white dots that appear on the female shrimp’s abdomen. These dots are the eggs, and they will hatch into baby shrimp after a few weeks if suitable conditions are suitable.\nHow Long Do Red Cherry Shrimp Carry Their Eggs?\nCherry shrimp, a popular freshwater aquarium shrimp, are known for their ability to reproduce in captivity. After mating, the female cherry shrimp will carry the eggs underneath her body until they hatch.\nThe time that cherry shrimp carry their eggs can vary, ranging from two to four weeks. During this time, the female shrimp carefully tends to the eggs, ensuring they receive sufficient oxygen and protection from predators.\nIt is fascinating to observe the development of the shrimp eggs as they gradually change color, indicating that the hatching process is nearing. Once the eggs hatch, tiny juvenile shrimp emerge, completing the reproductive cycle.\nCherry shrimp are highly prized for their vibrant red color and peaceful demeanor, making them popular among aquarium enthusiasts.\nHow Often Do Cherry Shrimp Lay Eggs?\nCherry shrimp, or Neocaridina shrimp, are freshwater shrimp commonly kept in aquariums. They are known for their bright red coloration, hence the name “cherry” shrimp. When it comes to reproduction, cherry shrimp lay eggs regularly.\nA mature female red cherry shrimp can lay eggs once every three to four weeks. The survival rate of these eggs greatly depends on the conditions provided in the aquarium. Once the eggs hatch, baby shrimp emerge and begin their journey to adulthood.\nCherry shrimp can breed every 3-5 months if favorable conditions are present. During the breeding cycle, the female shrimp releases hormones into the water, mate with the male shrimp, lay their eggs, and repeat the process. Overall, the reproduction rate of cherry shrimp is relatively high, making them popular among aquarium enthusiasts.\nHow Many Eggs Do Cherry Shrimp Lay?\nCherry shrimp, known as Neocaridina heteropoda var. “red,” are prolific breeders. They are known to lay many eggs, typically around 20 to 30 at a time. The female shrimp carry the eggs until they hatch, which usually occurs after two to three weeks.\nHowever, it’s important to note that not all eggs will hatch successfully. The survival rate of the shrimp larvae depends on various factors such as water parameters, food availability, and overall shrimp health.\nThe survival rate can be relatively high in optimal conditions, resulting in many cherry shrimp offspring. These tiny creatures are fascinating to observe and breed as their breeding habits and ability to reproduce ensure a continuous population in home aquariums.\nDo Cherry Shrimp Care for Babies?\nCherry shrimp, also known as Neocaridina heteropoda, care for their babies. After mating, the female cherry shrimp attaches the eggs to her swimmerets until they hatch.\nThis process usually takes around three to four weeks. Once the eggs hatch, the newborn shrimp are tiny replicas of their parents and are fully capable of fending for themselves.\nHowever, they stay close to their mother for some time, benefiting from her presence and protection. As they grow, the baby shrimp molt several times to accommodate their increasing size.\nTo ensure proper cherry shrimp care, the aquarium shrimp needs to have plenty of hiding spots, plants, and moss for the newborn shrimp to take refuge in.\nAdditionally, it is essential to provide a well-balanced diet for the small shrimp, including specialized shrimp food or algae. With proper care and a suitable environment, cherry shrimp can successfully breed red cherry shrimp and care for their babies in an aquarium.\nPregnant Cherry Shrimp Stages\nCherry shrimp, scientifically known as Neocaridina heteropoda var. red, are a popular freshwater shrimp species in the aquarium hobby. If you’re interested in cherry shrimp breeding, it’s important to understand the various stages involved in the pregnancy of female cherry shrimp. Here’s a breakdown of the key stages:\n- Saddle Formation: Female cherry shrimp exhibit a saddle-shaped structure called a “saddle” on their backs, resulting from eggs developing within their ovaries. This is a visible sign that the female shrimp is preparing for reproduction.\n- Mating: In the next stage, the female shrimp will be receptive to mating. Male shrimp will approach the female and transfer sperm to fertilize the eggs inside her. Successful mating will lead to the fertilization of the eggs.\n- Egg Development: After successful fertilization, the female cherry shrimp will carry the fertilized eggs with her until they hatch. The eggs will be visible beneath her abdomen, appearing as small clusters or berries.\n- Hiding and Protection: The female shrimp will become more protective and cautious as the eggs develop. She may retreat to hiding spots within the aquarium, such as plants, decorations, or crevices, to safeguard the developing eggs from potential predators.\n- Release of Shrimp Eggs: Once the eggs have matured and are ready to hatch, the female shrimp will release them into the water. These tiny shrimp eggs will be suspended in the water column or attached to surfaces using a sticky substance.\n- Hatching: The shrimp eggs will hatch into miniature larvae, which are initially very small and almost transparent. These larvae have yet to develop and have different dietary requirements than adult shrimp.\n- Feeding on Biofilm and Plankton: Newly hatched shrimp larvae will instinctively seek out biofilm and plankton present in the aquarium water as their primary source of nutrition. Biofilm is a slim layer of microorganisms that naturally grows on surfaces within the tank. Providing enough biofilm and plankton is crucial to the survival of the shrimp larvae during this early stage.\n- Growing and Development: Over the following weeks, the shrimp larvae will undergo multiple molts as they grow and develop. They shed their exoskeleton with each molt and emerge slightly larger and more developed.\n- Transition to Miniature Shrimp: As the larvae grow and molt, they will gradually resemble miniature adult cherry shrimp. Their coloration will become more distinct, and they will start displaying behaviors typical of adult shrimp.\nUnderstanding cherry shrimp’s breeding cycle and pregnancy stages is essential for successfully raising healthy generations of these fascinating aquatic creatures. Providing a suitable environment, sufficient food sources, and proper care will contribute to successfully breeding cherry shrimp in your aquarium.\nCaring for Cherry Shrimp with Eggs\nTaking care of pregnant cherry shrimp requires special attention and consideration. These vibrant-colored shrimp are known for their ability to reproduce quickly in the right conditions.\nTo ensure successful breeding, it is crucial to maintain proper water parameters in the shrimp tank. This includes keeping the water clean and providing ample algae as a food source.\nPregnant cherry shrimp may become aggressive towards other shrimp in the colony, so it is advised to separate them in a separate breeding tank. The gestation period of cherry shrimp varies, but it typically lasts around 30 days.\nThe female shrimp will mate and carry the fertilized eggs until they hatch during this time. It is vital to provide a suitable environment with sufficient hiding spots and shrimp food to support the development of the fry.\nBy understanding and implementing the necessary steps for pregnant cherry shrimp care, enthusiasts can enjoy a thriving and flourishing aquarium.\nCommonly Asked Questions About Red Cherry Shrimp Eggs (FAQs)\nHow often do cherry shrimp lay eggs?\nFemale cherry shrimp can lay eggs once every few weeks under the right conditions.\nWhat do baby shrimp eat?\nBaby shrimp feed on biofilm, algae, plankton, and specialized shrimp food designed for their tiny size.\nCan I keep cherry shrimp with other fish?\nWhile cherry shrimp can coexist with some peaceful fish, it’s important to choose tankmates that won’t prey on the shrimp or compete for their food.\nHow many eggs can a female shrimp carry?\nA female shrimp can carry 20 to 30 eggs under her tail.\nAre there any specific tips for ensuring a high survival rate among baby shrimp?\nProviding stable water parameters, offering hiding spots, and supplying proper nutrition are key to ensuring the survival and growth of baby shrimp.\nWhat are fertilized eggs?\nFertilized eggs are eggs that the sperm of a male shrimp have fertilized. In the case of cherry shrimp, the female shrimp will mate with a male shrimp, and the eggs will be fertilized during breeding.\nWhat do cherry shrimp with eggs look like?\nCherry shrimp eggs are small and transparent. They are usually attached to the female shrimp’s abdomen, forming a cluster. The eggs are spherical and can be easily distinguished from unfertilized eggs.\nHow long will it take for cherry shrimp eggs to hatch?\nIt generally takes 2 or 3 weeks for cherry shrimp eggs to hatch. The exact time might vary depending on the water temperature and other environmental conditions.\nHow can I breed red cherry shrimp?\nYou will need male and female shrimp to breed red cherry shrimp. Create a suitable tank environment with plenty of hiding places and a stable water temperature. The female shrimp will carry the eggs until they hatch, and the breeding process will occur naturally.\nWhat should I do with the eggs once my shrimp lays them?\nIt is best to leave the eggs undisturbed with the mother shrimp. She will move the eggs to a safe location and take care of them until they hatch. Attempting to move the eggs yourself may cause damage or stress to the mother shrimp.\nCan cherry shrimp lay unfertilized eggs?\nYes, it is common for cherry shrimp to lay unfertilized eggs. This can happen if a female shrimp has not mated with a male shrimp or the eggs were not successfully fertilized during the breeding process.\nHow can I help the eggs to hatch successfully?\nTo help the eggs hatch successfully, providing a stable and suitable tank environment is important. Maintain proper water quality, temperature, and provide hiding places for the mother shrimp and eggs. Avoid disturbances or sudden changes in the tank that may stress the shrimp or disrupt the hatching process.\nWhat happens to the male shrimp after the eggs are laid?\nAfter the eggs are laid, the male shrimp’s role is complete. He has no further involvement in caring for the eggs or the hatching process. The female shrimp will take care of the eggs until they hatch.\nCan I separate the eggs from the mother shrimp?\nIt is generally not recommended to separate the eggs from the mother shrimp. The mother shrimp knows how to care for the eggs and will provide the necessary nurturing conditions. Separating the eggs may lead to a lower chance of successful hatching or harm to the eggs.\nWhat should I do if the eggs do not hatch?\nIf the eggs do not hatch after the expected period, it is possible that they are not viable. In such cases, waiting and observing for a little longer is best. If the eggs remain unchanged for an extended period, likely, they will not hatch. At that point, you can remove the eggs from the tank.\nBreeding cherry shrimp and witnessing the hatching of their eggs is a truly rewarding experience for any aquarium enthusiast. Understanding the intricacies of shrimp reproduction, creating a suitable environment, and providing proper care is essential for a successful breeding journey. In the intricate underwater world of aquarium enthusiasts, the wonder of new life takes center stage with the captivating sight of cherry shrimp with eggs. These tiny creatures have proven to be a mesmerizing addition to any tank, offering their vibrant color and a sense of thriving vitality.\nAs we’ve explored the nurturing care and optimal conditions required for these shrimps to reproduce successfully, it’s evident that a delicate balance must be struck. The sight of those tiny eggs nestled among the dwarf shrimp speaks to the harmonious relationship we’ve developed with nature in our own living spaces. So, whether you’re a seasoned hobbyist or just dipping your toes into the aquatic realm, cherishing the miracle of cherry shrimp with eggs reminds you of life’s beauty and fragility in its most intricate forms.\nYou might also like\n- Shrimp Breeding Setup 101 (Setup, Size, Mates & Requirements)\n- Red Cherry Shrimp Breeding: 5 Hacks for Rapid Success!\n- Freshwater Shrimp Breeding 101: (A Comprehensive Guide)\n- Do Shrimp Eggs Hatch All at Once? The Answer Will SHOCK You!\n- Do Shrimp Molt Their Skin? 3 Surprising Facts About Molting!\n- What Do Cherry Shrimp Eat: 7 Astonishing Foods They Crave!\n- Ideal Neocaridina Shrimp Water Parameters: Boost Growth 3x Faster\n- Caring for Cherry Shrimp 101: A Comprehensive Beginner Guide\n- Pregnant Cherry Shrimp: 3 Easy Secrets to Healthy Babies!\n- How Many Times Do Cherry Shrimp Molt: A Comprehensive Guide\n- How Long Do Cherry Shrimps Live for: Shocking Truth Revealed!\n- Female Cherry Shrimp Saddle: 3 Proven Signs of Pregnancy!\n- Orange Sakura Shrimp 101: Price, Care, Breeding & More']	['<urn:uuid:8d12b0f7-7af0-441b-b473-067dfb582b09>', '<urn:uuid:51d69c4f-3ce4-4cad-8647-aac9ce0ce6d1>']	factoid	with-premise	verbose-and-natural	similar-to-document	comparison	novice	2025-05-12T22:49:38.933606	29	36	4685
48	looking for info philippine economy remittances foreign workers share gdp	Remittances from foreign workers make up about a tenth of the Philippines' gross domestic product - the highest share in the region.	['How many ladies trying to find jobs within and beyond the Philippines is increasing because harsh climate conditions make life in the home harder. These females usually have small help once they migrate, and tend to be at the mercy of abuse and wages that are low.\nOnce the rains failed in 2015 and drought gripped southern Mindanao within the Philippines, Corazon Vegafria knew just just just what she needed doing: go on to the town of Koronadal, about an hour or so away by coach, and locate act as a domestic helper to help her household.\nHer spouse cared for the youngsters while Ms. Vegafria delivered house the majority of the 2,000 pesos ($38) she received every cooking and cleaning at her employer’s home month.\n« We had no choice I could easily find a job in the city, » she said– we needed the money, and. 6 months later on, she returned home « when the specific situation enhanced. «\nInto the previous two years, the Philippines has emerged among the earth’s leading source nations for migrant employees, specially as more effective typhoons along with other harsh weather make life in the home harder.\nSignificantly more than 10 million Filipinos presently work abroad, based on the Philippine Statistics Authority. However in the very last years that are few the sex stability has shifted, with about 55 per cent of overseas workers now women, its information shows.\nSuspense-free impeachment may reverberate for years yet in the future\nWhich makes the Philippines an outlier in a global where many migrant employees are guys.\nGlobally, migration keeps growing, particularly among families struck by catastrophes, conflict or weather changes – and therefore development doesn’t constantly abide by old-fashioned habits.\nIn a few places, regular migration is gradually ultimately causing permanent moving. In other people, migrants are going to destinations that are new. Within the Philippines, one of the greatest modifications is the fact that migration is slowly dealing with a face that is female.\nEach hundreds of rural women pack their bags for jobs as maids and caregivers, largely in the Middle East and the United States day. Other people head to Singapore and Hong Kong.\nA large number of women also flock to Philippine cities including Manila, Davao, and Koronadal, where it works as domestic helpers or in malls and restaurants, giving cash house to cover kids’s education or even to spend money on farms their husbands tend.\n« Migration is related to low productivity that is agricultural normal catastrophes such as for example droughts and typhoons, failed deals to secure land legal rights, and disputes, » said Alvin Chandra, an investigation other during the University of Queensland in Australia.\n« Increasingly, it really is a coping technique for women to diversify family members earnings and conquer poverty, » stated Mr. Chandra, who’s got examined migration in Mindanao, where an armed conflict has raged for a long time.\nThe top destinations, according to the World Bank across Southeast Asia, people are migrating in rising numbers, with the wealthier countries of Singapore, Malaysia, and Thailand.\nSingapore’s average wage that is monthly significantly more than 30 times compared to Cambodia, while Malaysia’s is triple compared to Indonesia as well as the Philippines, it stated.\nMigration plays an outsize part within the Philippines’ economy, where remittances from international workers compensate in regards to a tenth of gross domestic item – the share that is highest in your community.\nWomen can be making house in greater figures, as they possibly can get jobs that are long-term effortlessly. Guys, in contrast, frequently land short-term, regular work.\nSome migrants, like Vegafria, move for some months at any given time to obtain their own families through a period that is lean. But the majority of wind up staying on, as a period of frequent storms and drought causes it to be harder to reside from the land.\nElisabeth Pacaldo, for example, relocated to Manila in 2002 to the office as a nanny after earnings from fishing and agriculture dropped within the Visayas area where she arrived from. Her spouse remained behind to take care of their five young ones.\nAfter four years, Ms. Pacaldo, managed to deliver for three of her young ones. Her spouse relocated to Manila in 2008 to focus being a motorist.\n« It is easier for ladies to get work with the town, therefore the salaries are greater. I can not return back, » stated Pacaldo, who now works being an administrative associate in a nonprofit.\nWorsening extreme weather is a significant motorist of migration in rural areas of the Philippines, a nation seen by specialists as very susceptible to climate change.\n« There are climate impacts where adaptation and danger decrease efforts are no longer an option that is feasible. Folks have to create choices that are extreme and migration is certainly one of them, » Chandra stated.\nThe Philippines along with other developing countries must acknowledge migration as you method of coping, and develop « a comprehensive strategy that ensures the security and dignity of the many vulnerable individuals, » he told the Thomson Reuters Foundation.\nThe Philippines includes a system that is well-established employees seeking to go offshore: The government lists work possibilities while your brides org offering orientation courses.\nRecruitment agents running in the united states must go to a seminar prior to getting a permit, and a course that is refresher renewing.\nBut there is however small help for – or data on – the millions of ladies who move in the nation, friends vulnerable to punishment and low wages, relating to Gabriela, a liberties team situated in Manila that documents situations of punishment.\nThere are also complaints concerning the remedy for Filipino maids offshore. President Rodrigo Duterte early in the day this year banned employees from planning to Kuwait following a development regarding the human anatomy of the Filipino worker in a fridge.\nPreviously this month, the 2 countries reached an agreement regulating conditions for domestic employees.\nA year ago, Indonesia decided to carry on delivering domestic helpers offshore, after temporarily banning them from likely to 21 Middle Eastern nations after instances of punishment.\nSome great benefits of migration are undeniable for some Filipino families – as well as the united states’s economy.\n« Even users of family members that do perhaps maybe maybe not benefit that is migrate remittances that boost budgets and lower poverty, » the entire world Bank stated in a October report.\n» when you look at the Philippines, households that can deliver an associate abroad have actually two-fold or three-fold greater probability of escaping poverty, » it included.\nFilipinos overseas delivered home a record $28 billion in money remittances year that is last cash that helped fuel spending and maintain expansion in another of the planet’s fast-growing economies.\nNevertheless the motion of females can be having an impact that is unhappier households in a nation where males have traditionally been the primary earners, and sometimes had a larger say into the household.\n« Using The migration of females, there clearly was a shift in community values, lifestyles, and sex relations who has resulted in greater domestic disputes and violence, » Chandra stated.\n« With females being away, their straight to take part in community life and decisionmaking is challenged. They are in danger of trafficking and abuse, » he stated.\nMr. Duterte has stated their long-term aim is always to slow the exodus of employees by boosting the domestic economy and creating jobs that offer adequate earnings.\nIn Sultan Kudarat district in Mindanao, some migrants have found methods to get back home – and remain.\nWhenever Geneline Castillo, got in after working seven years being a helper that is domestic the center East, she joined up with a cooperative that trains farmers in natural growing techniques.\nShe now cultivates rice and veggies from the 2-hectare (5-acre) plot she along with her spouse rent, and has now purchased a motorbike for trips towards the market.\n« It is better here with all the household, and I also are in possession of a livelihood choice, even though the money is less, » she stated.\nHave the Monitor tales you worry about sent to your inbox.\n« But my child went to Dubai to the office. I really could maybe maybe not stop her – there’s nothing on her behalf right here, » she stated.\nThe Thomson reported this story Reuters Foundation.']	['<urn:uuid:60425cc8-5398-4b3a-b94f-4099a5ee7920>']	factoid	with-premise	long-search-query	distant-from-document	single-doc	novice	2025-05-12T22:49:38.933606	10	22	1406
49	unique features ancient greek legal development compared other early systems writing purpose laws	The Greeks were unique in using writing extensively to make their laws accessible to a large segment of the community, while other early communities wrote codes of law mainly for academic or propaganda purposes. Additionally, unlike other cultures, Greeks made minimal use of writing in litigation processes, which prevented their legal system from becoming overly technical and avoided the development of a specialized legal profession.	"['Other available formats:\nLooking for an examination copy?\nThis title is not currently available for examination. However, if you are interested in the title for your course we can consider offering an examination copy. To register your interest please contact email@example.com providing details of the course you are teaching.\nThe use of writing in the development of Greek law was unique. In this comparative study Professor Gagarin shows the reader how Greek law developed and explains why it became so different from the legal systems with which most legal historians are familiar. While other early communities wrote codes of law for academic or propaganda purposes, the Greeks used writing extensively to make their laws available to a relatively large segment of the community. On the other hand, the Greeks made little use of writing in litigation whereas other cultures used it extensively in this area, often putting written documents at the heart of the judicial process. Greek law thereby avoided becoming excessively technical and never saw the development of a specialised legal profession. This book will be of interest to those with an interest in the history of law, as well as ancient historians.Read more\n- Was the first book to cover the whole of ancient Greek law in English\n- Alternative approach to understanding the uniqueness of ancient Greek law\n- Explains how law began and developed its unique nature in ancient Greece\nReviews & endorsements\n""...an engaging study that is brimming with original insights. ...Gagarin offers a valuable, thought-provoking and welcome contribution to the growing body of literature on Greek law."" --BMCRSee more reviews\n""""...this is a stimulating and thought-provoking book. Gagarin concludes with the observation that future study of ancient Greek law will require both \'new ideas and new perspectives\' to remain healthy\'. In Writing Greek Law he has offered refreshing examples of both."" --New England Classical Journal\nNot yet reviewed\nBe the first to review\nReview was not posted due to profanity×\n- Date Published: June 2011\n- format: Paperback\n- isbn: 9780521297288\n- length: 296 pages\n- dimensions: 229 x 152 x 16 mm\n- weight: 0.4kg\n- availability: Available\nTable of Contents\nIntroduction: writing Greek law\n1. Law before writing\n2. Writing and written laws\n3. Why the Greeks wrote laws\n4. Why Draco wrote his homicide law\n5. Oral and written in archaic Greek law\n6. Writing laws in fifth-century Gortyn\n7. Writing the Gortyn code\n8. Writing law in classical Athens\n9. Writing Athenian law: a comparative perspective\n10. Writing law in Hellenistic Greece\nConclusion: writing Greek law.\nSorry, this resource is locked\nPlease register or sign in to request access. If you are having problems accessing these resources please email firstname.lastname@example.org Sign in\nYou are now leaving the Cambridge University Press website. Your eBook purchase and download will be completed by our partner www.ebooks.com. Please see the permission section of the www.ebooks.com catalogue page for details of the print & copy limits on our eBooks.Continue ×\nAre you sure you want to delete your account?\nThis cannot be undone.\nThank you for your feedback which will help us improve our service.\nIf you requested a response, we will make sure to get back to you shortly.×']"	['<urn:uuid:b44bd805-8bb2-4c51-8bac-a2f823641fa8>']	factoid	direct	long-search-query	distant-from-document	single-doc	expert	2025-05-12T22:49:38.933606	13	65	535
50	How do small businesses get help in understanding and preparing for climate-related risks in their area?	Small businesses can receive assistance from local governments through data and information sharing, as most small businesses don't have the expertise or resources to assess climate change risks on their own. Local governments share information from their vulnerability assessments and climate change scenario planning to help small businesses understand potential risks and prepare for extreme events. For example, in California, an initiative called the Capital Region Business Resiliency Initiative has been developed to help engage the small business community in resilience planning. This effort connects small businesses with local stakeholders to understand potential risks and provides resources to help these businesses plan for disaster resilience.	['The year 2017 will stay on the record as one of the most expensive years to date for climate and weather disaster events. The U.S. experienced 16 weather and climate disasters that caused over $1 billion in damages, tying the record year of 2011 for the most billion-dollar disasters. From summer through the fall, wildfires in various parts of California led to fatalities, destruction of entire communities, and damage costs of $18 billion, with economic consequences that will continue to impact the region. These events have highlighted that climate change has already begun to and will continue to impact local communities and businesses, and that local economies will benefit from more coordinated resilience planning.\nCommunities across the U.S. are taking steps to identify their climate change risks and enhance their resilience to changing climate conditions. Many local governments have assessed their vulnerabilities and are developing resilience plans with support from local stakeholders. However, a key set of stakeholders are often not at the table: businesses. Collaboration between local governments and the business community on climate change resilience remains limited. As local and regional climate change planning continues, it becomes increasingly important for local governments to engage with businesses, both large and small, on these issues.\nThe success of businesses and communities is intertwined\nMany larger companies recognize the impacts of climate change on their operations, including risks to physical assets, disruptions to supply chains, and impacts on their workforce. In fact, some businesses, like Google, are examining how to develop company resilience strategies that address changing climate conditions. Businesses are also dependent on public infrastructure and local government services, and climate risks on these “outside the fence” components are much harder for businesses to evaluate. In fact, a number of companies have highlighted these uncertainties as a major barrier in addressing adaptation.\nLocal governments are dependent on the private sector in many ways. Businesses are essential to the economic health and growth of communities. Business interruptions can affect the quality of life for residents, disrupt the local economy, and reduce tax revenues. The costs of Hurricane Harvey are still being evaluated, but preliminary estimates suggest that lost economic output from this storm was in the range of $9 billion to $11 billion, including $540 million for goods-producing industries and $141 million for oil and gas industries. The October 2017 wildfires in California’s wine country are estimated to have caused economic losses between $6 and $8 billion dollars due to property damage and business interruptions alone, with $789 million in commercial property claims. These costs do not include the potential losses to the wine industry for many years to come.\nLocal governments have a strong interest in ensuring that businesses are resilient and remain operational as the climate continues to change. Companies will also benefit from engaging with the public sector on community resilience to enhance their business continuity plans and support their employees. In addition to better protecting their employees and operations, this type of collaboration will help businesses better understand community needs.\nBusinesses can assist local governments with expertise and solutions\nLarger businesses often already understand local risks because of internal risk management processes. Risk management and emergency management plans, along with drills and training exercises with employees, help businesses prepare for extreme events. Local governments can coordinate with businesses on risk management, including participating in drills and trainings, to build and maintain community resilience.\nLocal governments can also use larger companies’ expertise and data on risk. Businesses may be monitoring information that could be relevant to local resilience planning. For example, utilities often track potential risks to their assets, such as those related to storms (e.g., wind, precipitation, flooding), wildfire, and temperature impacts on energy demand. This information can be helpful to local decision-makers in both emergency management and long-term resilience planning.\nThe private sector also offers opportunities in services and solutions. Businesses are often interested in developing and improving technologies, engineering approaches, technical assistance, and opportunities to connect with their communities. For example, Airbnb offered disaster relief to people impacted by the California wildfires, connecting displaced residents to available housing. The company also worked with the City of San Francisco’s Department of Emergency Management to share their lessons learned from Superstorm Sandy. Airbnb is also partnering with various local governments to help communities prepare for and recover from disasters. Local governments’ suggestions for climate change solutions and services can help businesses tailor their products to best serve the community.\nIn addition, financing for implementing community resilience can often be a challenge for local governments. The private sector can offer financing solutions to help fund climate change resilience. For example, Pacific Gas and Electric Company (PG&E) is investing $1 million over five years through their Better Together Resilient Communities grant program to support local climate resilience initiatives in California.\nLocal governments can share data and information with businesses\nSome local governments have undertaken vulnerability assessments and climate change scenario planning for their regions. The data and results from these studies can be shared with businesses to help them understand what assumptions are being used by local governments, and whether their scenarios align, which will be increasingly important to ensure regional coordination as conditions change.\nWhile larger companies may undertake scenario planning and vulnerability assessments, most small businesses do not. However, small businesses can also benefit from data and information sharing. Small companies do not often have the expertise or resources to adequately assess climate change risks and undertake resilience planning. Local governments can share information with small businesses to help them better understand their potential risks and prepare for extreme events. In California, Valley Vision has developed the Capital Region Business Resiliency Initiative to help engage the small business community in resilience planning. This effort helps small businesses engage with local stakeholders to understand potential risks and provides resources to help these businesses plan for disaster resilience.\nLocal governments can engage with businesses through existing networks or by creating new processes to assist with engagement\nLocal governments can engage with both small and large businesses through networks and organizations for the private sector, like local chambers of commerce, trade associations, and other business networking groups. For example, the City of Annapolis has engaged the Anne Arundel County Chamber of Commerce and the Downtown Annapolis Partnership in its Weather It Together initiative, which is focused on adapting the historic community to minimize the risks associated with flooding. Through this effort, local businesses are part of the planning process to help the community become more resilient. The City of Cambridge, Massachusetts has also engaged businesses in long-term planning efforts like the Cambridge Compact and the city’s Climate Change Preparedness & Resilience Plan. Establishing public-private partnerships focused on climate resilience will also help to facilitate conversations and collaboration between these two sectors.\nLocal governments may already engage with businesses individually, but it can be helpful to set up an ongoing process for involving the private sector in resilience planning. For example, business representatives can participate in local planning and advisory committees, contributing their perspectives and identifying any key issues for the business community. Effectively engaging the business community will often require targeted outreach and potentially different strategies, as businesses may not be aware of ongoing stakeholder processes or may not realize their relevance to company needs. Some communities have incorporated businesses into resilience planning through regional climate collaboratives. Several regional climate collaboratives in California focus on engaging different stakeholder groups, including businesses, to further climate change planning. For example, the Sierra Climate Adaptation and Mitigation Partnership was founded by the Sierra Business Council and has various business members, including ski resorts and forestry companies.\nEffectively preparing for climate change’s impacts requires that cities coordinate with many different stakeholders. Businesses, public agencies, community groups, and citizens are all important to the discussion on community resilience, as they will all be impacted by climate change and have important ideas to contribute. Engaging the private sector is an important way for local governments to improve community resilience, and will benefit both the public and private sector through information sharing, aligning needs and goals, and developing multi-sector networks.']	['<urn:uuid:abac6898-51b0-42fd-a5b1-b5052c4a2b07>']	open-ended	direct	verbose-and-natural	similar-to-document	single-doc	novice	2025-05-12T22:49:38.933606	16	105	1353
51	brick patio sloped drainage installation and material durability advantages	For brick patio installation, a proper slope of 1/8 to 1/4-inch per foot away from the house is essential for drainage. The installation process requires a solid base of 9-10 inches depth, filled with compacted angular gravel layers. As for material durability, brick paving is suitable for all climates and offers classical, warm aesthetics. However, it's crucial to thoroughly prepare the base course beforehand to prevent brick lifting and weed growth between them.	['Preparing the Patio Base\nDesign the layout of the patio. Allow adequate room for your family’s activities. Consider what patio furniture you plan to place on the new patio as well as where you intend to set the barbecue grill. If you want to use the house as shade, work that into your design.\nMark the boundary of the brick patio with stakes and string. Allow 6 to 8 inches more than you included in your design. This gives you some room to work with the bricks as you set them. As you set the string on the stakes at the level you intend to lay the bricks, allow for a slope of 1/8- to 1/4-inch per foot away from the house to allow for drainage.\nDig out the patio area with a shovel. If you have a large area, rent a skid steer loader. A depth of 9 to 10 inches provides a solid base and puts the bricks at or slightly above grade level.\nCompact the subsoil with a plate compactor. Cover the soil with 2 to 3 inches of angular gravel. Rake the stones until they create a level surface. Dampen the gravel with a garden hose. Compact it in place with the compactor. Add another 2- to 3-inch layer of gravel, rake it level and compact it. Continue adding gravel until the gravel surface gets to within 3 inches of the string guide you set up in Step 2.\nSet up parallel lines of 1-inch conduit pipes to use as screed guides on the gravel base. Screeding is the process of leveling the base by filling low spots and lowering high spots by rubbing a long, straight board over two parallel pipes. Space these pipes no more than 7 feet, 6 inches apart. Try to arrange them so that you can do the screed work from the edge of the patio. Once you have a pattern established, press the pipes into the gravel base about 3/4 inch. If you set a paver on top of the screed pipes, the paver’s top should extend 1/8 to 1/4 inch above the string line. If it doesn’t, raise or lower the pipes accordingly.\nPlace several shovels of gravel between two screed pipes closest to the house. Set a straight 8-foot length of 2-by-4 on the pipes. Work the board back and forth as you pull it toward you to level the gravel. Keep adding gravel until you complete that section. Add gravel and screed it in the remaining sections of the brick patio.\nRun the plate compactor over each section of the patio. Do not disturb the screed pipes. At this point your base should be solid enough to not leave a hand print.\nPull the screed pipes. Try not to disturb the gravel as you do so. Lay additional gravel in the trenches left by the pipes. Compact it into place.\nLaying the Brick Patio\nSnap a straight line parallel with the wall of the house, using a chalk line. Snap a second line perpendicular to the first. This gives you a right angle to lay all your brick from.\nSet the bricks, starting at the right angle. After you set the first brick, bring the edge of the next brick up to the first and drop it into place as close as possible to the first brick. Avoid scuffing the gravel underneath as you lay bricks in the pattern you selected for the patio. Extend bricks beyond the boundary where the curved edges are to be.\nLay 1/2-inch conduit pipe on top of the set bricks in the shape of the curved edge. Use a sharp metal object, such as a chisel, to score along the line marked by the pipe. Remove the pipe.\nCut along the scored line with a cutoff saw. In most cases you don’t need to remove the brick from the base to make the cut.\nLay a soldier course of bricks along the entire perimeter of the patio. Place the short edge of the bricks firmly against the last row of bricks you laid. If you prefer, lay a sailor course, by placing bricks end to end along the perimeter.\nSet the flanged edge of the paver edge restraint firmly against the soldier course. Drive the pins that come with the edging into the gravel base, using a hammer. Cover the remaining opening between the brick patio and the lawn with topsoil.\nSprinkle sand over the entire patio. Use a push broom to work it into the cracks between bricks. Set a protective pad underneath the plate compactor and go over the entire patio with the compactor to settle the sand. Add more sand and compact the patio again.\nThings You Will Need\n- Skid steer loader\n- Plate compactor\n- Garden hose\n- 1-inch conduit pipe\n- 2-by-4, 8 feet long\n- Chalk line\n- 1/2-inch PVC pipe\n- Cutoff saw\n- Paver edge restraint\n- Push broom\n- Contact the local utility companies before you dig. They can mark the location of any buried lines on your property so you don’t accidentally hit them.', 'Picking the best patio paving material for your project can be challenging. Many factors must be considered, and the variety of paving materials available can make the decision even harder. Adding to the pressure is the fact that patio paving is costly and-labour-intensive, so you will likely be living with your choice for many years to come.\nFactors to Consider when Picking Patio Paving\nThere is really no “right” or “wrong” choice of patio paving material; only what is best for your situation.\n- What is the overall look and feel of your house and garden? Does it call for traditional or contemporary patio paving?\n- How will the patio be used? For informal or formal dining and entertaining? Relaxing? Pet kennels or sports practice?\n- Existing and future vegetation: perhaps your patio paving will be incorporating established trees, or you’d like to include flower beds, or even some raised herb or vegetable plantings.\n- Budget and personal preferences: do you or a family member have your heart set on a certain finish? Is local sourcing or a low carbon footprint an important factor?\nStone patio paving adds character, as no two pieces are exactly the same, and allows for a more natural-looking, informal paving layout. Soft stone can be porous and hard to clean, and tends to become mossy with age. Blue limestone, or Kilkenny limestone, is said to absorb less dirt than other soft stones. Indigenous stone can prove to be more expensive than imported, but it has a lower environmental impact and carbon footprint. Slate withstands cooler climates and temperature fluctuations well.\nActually a hard stone, granite patio paving looks luxurious but can also be porous, although it tends to keep cleaner than stone. Chinese granite tends to be softer, whereas Portuguese granite is said to be harder-wearing.\nConcrete can be poured on site, or purchased in precast pieces in a variety of shapes, sizes and colours. A polished eco-concrete, which can give a lovely natural look, is now also available. Concrete patio paving need not be boring: a mixture of different shapes and sizes can be most effective. If you are considering coloured concrete, check how long the colour is guaranteed for, as it can fade over time with exposure to light and the elements.\nGravel is often overlooked as a possible patio paving material, but it is excellent for introducing warmth and texture and invaluable when it comes to accommodating tricky shapes or existing trees. Gravel will need an edging, such a brick, to keep it in place, which can make for a nice contrast. Loose gravel can be prone to weeds, but self-binding gravel is now available, which is suitable for wheelchairs and prams.\nBrick patio paving looks warm and classical, is suitable for all climates, and lends itself to a variety of patterns and combinations. It is vital that the course on which the bricks will be laid is thoroughly prepared beforehand, or very soon the bricks will start lifting up and sprouting weeds between them.\nAvailable in an almost unlimited variety of shapes, sizes, colours and textures, tiles can be laid in regular or mosaic-like patterns to make bold visual statements. They can also be a slipping hazard when wet and the grouting between them will require maintenance.\nTraditional cobbles can look charming, but their uneven surface can make them impractical. They are slippery when damp and almost impossible for prams and wheelchairs to navigate. They need to be laid so that they won’t work loose from the concrete, which looks messy and creates a tripping hazard.\nMaking the Final Selection\nOnce you’ve drawn up a shortlist of options, it can be well worthwhile to spend some time walking around your neighbourhood and observing existing patios. If possible, talk to friends and relatives with patios about the pros and cons of their patio paving. Consider investing a couple of weekends in visiting showrooms and asking questions. Then you will be fully equipped to choose the best patio paving materials for your project.']	['<urn:uuid:7a1e7755-96d4-4203-bd1d-6b16e3a3cf8a>', '<urn:uuid:76244533-1ac3-4848-aa61-a72d8782128b>']	open-ended	with-premise	long-search-query	similar-to-document	multi-aspect	expert	2025-05-12T22:49:38.933606	9	73	1524
52	climate change threats bog flora coastal ecosystems	Climate change poses significant threats to both bog flora and coastal ecosystems. In bogs, climate change affects plant species through alterations in hydrology and temperature patterns, impacting their growth and survival. Similarly, coastal ecosystems face challenges from rising sea levels and temperatures, which can lead to ecosystem loss. Both environments also experience increased frequency of extreme weather events, which threatens their long-term conservation. These impacts are particularly concerning as both ecosystems are crucial for biodiversity and carbon storage.	['Bogs are unique and fragile ecosystems that support endangered plant species. Habitat loss, pollution, and climate change have put many rare bog flora species at risk. To conserve these plants, various strategies can be employed. This includes habitat restoration, creating protected areas, ex situ conservation, raising public awareness, and fostering collaboration and research. Bogs are important for conservation due to their biodiversity and carbon storage. Invasive species can be controlled through manual removal or introducing natural predators. Climate change affects bog flora through changes in hydrology and temperature. Individuals can contribute to conservation efforts by supporting organizations, participating in restoration activities, and spreading awareness.\nConserving Rare Bog Flora: Strategies for Protecting Endangered Plant Species\nBogs are unique and fragile ecosystems that support a wide range of plant species. However, due to habitat loss,\npollution, and climate change, many rare bog flora species have become endangered. Conserving these plants is\ncrucial to maintaining biodiversity and preserving the delicate balance of these ecosystems. This article will\ndiscuss various strategies and initiatives that can be taken to protect and conserve rare bog flora species.\nUnderstanding the Threats\nBefore diving into conservation strategies, it is important to understand the primary threats faced by rare bog\nflora. These threats include habitat degradation, drainage, invasive species, pollution, and climate change. Each\nthreat contributes to the decline of rare bog flora species and must be addressed through conservation efforts.\n1. Habitat Restoration\nRestoring and protecting degraded bog habitats is crucial for the survival of rare bog flora. This can involve\nremoving invasive species, controlling pollution sources, and reestablishing natural hydrological processes.\n2. Establishing Protected Areas\nCreating protected areas, such as national parks or nature reserves, helps safeguard rare bog flora species from\nhuman activities. These areas can provide a safe haven for these plants to thrive without disturbance.\n3. Ex Situ Conservation\nIn situations where the natural habitat is severely damaged or at risk, ex situ conservation can be employed. This\ninvolves collecting seeds or plant specimens and cultivating them in controlled environments like botanical gardens\nor seed banks. This strategy ensures the survival and potential reintroduction of endangered plant species.\n4. Public Awareness and Education\nRaising public awareness is essential for protecting rare bog flora. Educating communities about the importance of\nbogs, their role in the ecosystem, and the need for conservation efforts can foster a sense of responsibility and\ndrive action to protect these fragile environments.\n5. Collaboration and Research\nCollaboration between scientists, conservation organizations, and local communities is vital. Conducting research\non rare bog flora, studying their ecology, and monitoring their populations can provide valuable insights for\neffective conservation strategies.\nFrequently Asked Questions (FAQs)\nQ: Why are bogs important for conservation?\nBogs are crucial for conservation due to their unique biodiversity. They support rare and endangered plant species,\nprovide habitat for various wildlife, and contribute to global carbon storage.\nQ: How can invasive species be controlled?\nInvasive species can be controlled through methods such as manual removal, herbicide application, or introducing\nnatural predators. However, it is essential to carefully assess the potential impacts and implement appropriate\nQ: How does climate change affect bog flora?\nClimate change can lead to changes in bog hydrology and temperature, affecting the growth and survival of bog flora\nspecies. Rising temperatures, altered precipitation patterns, and increased frequency of extreme weather events\npose significant challenges for their long-term conservation.\nQ: How can individuals contribute to bog flora conservation?\nIndividuals can contribute to bog flora conservation by supporting local conservation organizations, participating\nin habitat restoration activities, spreading awareness, and avoiding activities that harm bog ecosystems, such as\nillegal peat extraction or dumping of pollutants.', 'When we think about carbon and climate change, our minds often go to fossil fuels, deforestation, and greenhouse gas emissions. However, there’s another side to the carbon story that’s just as important – the role of coastal ecosystems in storing and sequestering carbon. This is where the concept of “Blue Carbon” comes into play.\nThe Role of Blue Carbon in Climate Change\nCarbon Sequestration in Coastal Ecosystems\nBlue carbon refers to the carbon captured and stored by the world’s coastal and marine ecosystems. These ecosystems, including mangroves, seagrasses, and salt marshes, act as carbon sinks, capturing and storing large amounts of carbon dioxide from the atmosphere. In fact, they can sequester carbon at a rate up to 35 times faster than tropical rainforests.\nThe Blue Carbon Initiative\nRecognizing the importance of these ecosystems, the Blue Carbon Initiative was launched to promote their conservation and restoration. The initiative brings together governments, research institutions, NGOs, and communities to protect and restore these vital ecosystems, which not only help in climate change mitigation but also provide numerous other ecosystem services such as biodiversity conservation, water purification, and coastal protection.\nCoastal Ecosystems and Blue Carbon\nMangroves are one of the most important blue carbon ecosystems. These unique trees, which grow in intertidal zones, have complex root systems that trap sediments, slowing down water flow and allowing organic material to settle. This creates a carbon-rich soil that can store significant amounts of carbon.\nSeagrasses, another vital blue carbon ecosystem, are flowering plants that grow in shallow coastal waters. They have the ability to capture and store large amounts of carbon in their roots and sediment, making them highly efficient carbon sinks.\nSalt marshes, found in the intertidal zone of coastal areas, are another important blue carbon ecosystem. These marshes are highly productive, with plants that capture and store carbon in their biomass and soil.\nThreats to Blue Carbon Ecosystems\nOne of the main threats to blue carbon ecosystems is coastal development. As coastal areas become more developed, these ecosystems are often destroyed or degraded, leading to the release of stored carbon back into the atmosphere.\nPollution, especially nutrient runoff from agriculture and sewage, can also harm blue carbon ecosystems. Excess nutrients can lead to algal blooms, which deplete oxygen levels in the water, harming seagrasses, mangroves, and other organisms.\nClimate change poses a significant threat to blue carbon ecosystems. Rising sea levels and temperatures can lead to the loss of these ecosystems, while increased storm intensity can cause physical damage.\nConservation Efforts for Blue Carbon Ecosystems\nTo counter these threats, various restoration projects are underway to bring back lost or degraded blue carbon ecosystems. These projects involve planting mangroves, seagrasses, and salt marshes, and are often done in collaboration with local communities.\nPolicy measures, such as designating protected areas and creating incentives for conservation and restoration, are also crucial in protecting blue carbon ecosystems. By recognizing the value of these ecosystems, we can ensure their conservation and restoration, leading to long-term benefits for the climate and biodiversity.\nThe Future of Blue Carbon\nThe concept of blue carbon is still relatively new, but it’s gaining recognition and momentum. As we continue to understand the importance of these ecosystems in climate change mitigation, we can expect more efforts to conserve and restore them. With collaboration between governments, researchers, NGOs, and communities, we can protect and enhance these vital ecosystems for future generations.\n- Biology Niche: Exploring the Fascinating World\n- Biofuels: The Future of Sustainable Energy\n- Biodiversity: Exploring Nature’s Tapestry\nIn conclusion, blue carbon is a crucial part of the global carbon cycle, with coastal ecosystems playing a key role in capturing and storing carbon. By conserving and restoring these ecosystems, we can mitigate climate change while also enjoying other ecosystem services. The future of blue carbon is promising, and with continued efforts, we can ensure these ecosystems are protected for generations to come.\nWhat is blue carbon?\nBlue carbon refers to the carbon captured and stored by the world’s coastal and marine ecosystems, including mangroves, seagrasses, and salt marshes. These ecosystems act as carbon sinks, helping to mitigate climate change by sequestering large amounts of carbon dioxide from the atmosphere.\nWhy are coastal ecosystems important in capturing carbon?\nCoastal ecosystems, such as mangroves, seagrasses, and salt marshes, are crucial for capturing carbon because they have unique properties that allow them to trap and store carbon in their biomass and sediments. These ecosystems can sequester carbon at a rate up to 35 times faster than tropical rainforests, making them highly efficient carbon sinks.\nWhat is the Blue Carbon Initiative?\nThe Blue Carbon Initiative is a global program that aims to promote the conservation and restoration of coastal and marine ecosystems to enhance their capacity to capture and store carbon. The initiative brings together governments, research institutions, NGOs, and communities to work towards protecting and restoring these vital ecosystems for climate change mitigation and other ecosystem services.\nWhat are some threats to blue carbon ecosystems?\nCoastal development, pollution, and climate change are the primary threats to blue carbon ecosystems. Coastal development can lead to the destruction or degradation of these ecosystems, while pollution, especially nutrient runoff, can harm their health. Climate change, with rising sea levels and temperatures, can also result in the loss of these ecosystems and increased storm intensity can cause physical damage.\nHow can we protect and restore blue carbon ecosystems?\nTo protect and restore blue carbon ecosystems, conservation efforts include restoration projects, policy measures, and community involvement. Restoration projects involve planting mangroves, seagrasses, and salt marshes, often in collaboration with local communities. Policy measures, such as designating protected areas and creating incentives for conservation and restoration, are crucial in protecting these ecosystems. Additionally, raising awareness and involving local communities in conservation efforts are essential for the long-term success of these initiatives.']	['<urn:uuid:db6af85b-8909-4544-86bf-fa0d13c9cfd8>', '<urn:uuid:98890e9d-0424-4365-bfae-27add36ce21c>']	open-ended	direct	short-search-query	similar-to-document	comparison	expert	2025-05-12T22:49:38.933606	7	78	1571
53	As a mechanic specializing in exhaust systems, I often wonder what the main causes of muffler damage are and how does the internal structure of a muffler actually work to reduce noise?	Muffler damage is primarily caused by corrosion from moisture, road salt, and debris, along with issues like corroding parts, worn rubber hangers, slack or sheared bolts, and heat shield damage. As for noise reduction, mufflers work in two ways: one type uses baffled chambers where sound waves bounce off and lose energy, while the other type uses a perforated pipe containing sound-absorbing materials like metal or fiberglass to reduce noise while minimizing back pressure.	"['A vehicle’s exhaust system is designed to direct harmful gases away from the driver and passengers, reduce the emissions the vehicle releases into the environment, control the delivery of hot exhaust, provide information to the vehicle’s computer to improve vehicle performance, and significantly reduce the amount of noise the vehicle makes.\nThe only component of the exhaust system that can easily be seen is the tailpipe, located under the back of the vehicle. The entire system, however, is actually much larger and more complex. The exhaust system begins at the engine combustion chambers and runs along the undercarriage of the vehicle, eventually ending with the visible tailpipe.\nThe major components of the exhaust system include the exhaust manifold(s), oxygen sensors, catalytic converter(s), resonator, exhaust pipes, muffler, and tailpipe.\nThe exhaust manifold is connected directly to the engine and has the job of harnessing the combustion gases into the exhaust system. It is possible, depending on the size of the engine, for there to be two exhaust manifolds. The manifold, comprised of smooth curving passages to improve the flow of exhaust, can be made of steel, aluminum, stainless steel, or more commonly, cast iron. Cracking, warping, and leaking due to broken mounting bolts are common manifold ailments.\nAll modern fuel injected cars utilize oxygen (O2) sensors to measure how much oxygen is present in the exhaust. From this information, the computer can add or subtract fuel to obtain the correct mixture for maximum fuel economy and optimal performance. In most cases, there are two O2 sensors in a four-cylinder engine. One is located on the exhaust manifold before the catalytic converter. The other is located after the catalytic converter on the exhaust pipe. In V6 or V8 engines there are four O2 sensors. Two O2 sensors are located before the catalytic converter on each cylinder bank. The other two O2 sensors are located after the catalytic converter on respective banks.\nThe catalytic converter reduces harmful emissions from engine exhaust. The converter, mounted between the exhaust manifold and the muffler, uses a combination of heat and metals that act as catalysts. A catalyst is a metal, or sometimes a chemical, that causes other chemicals to go through a reaction without being affected itself. The inside of the catalytic converter consists of materials such as platinum, palladium, and rhodium. These materials are the catalyst that causes the carbon monoxide and hydrocarbons to react and produce water vapor and carbon dioxide which are much less harmful to the atmosphere.\nThe resonator is like a mini muffler with less restriction. It is an empty echo chamber the exhaust travels through where the exhaust energy bounces around, resonates, and some of the noises cancel each other out. A resonator doesn’t just remove sound, it changes it to be more acceptable. The resonator can be either before or after the muffler in the exhaust system.\nExhaust pipes connect all the components of the exhaust system. They are designed to route the exhaust in the most efficient way possible as it travels toward the rear of the vehicle, and to keep the hot exhaust away from heat sensitive components in the engine compartment and along the undercarriage of the vehicle. Exhaust piping is usually made of steel, but can be aluminized steel tubing, or stainless steel, which lasts longer due to its corrosion resistance. Connections are generally made with clamps, gaskets, or welds.\nThe muffler quiets the noise of the engine. There are two kinds of mufflers. One uses baffled chambers to reduce noise. As sound waves move through this type of muffler, they bounce off the baffles and expend their energy inside the muffler, losing force and volume. The other type forces the exhaust straight through a perforated pipe that contains metal, fiberglass, or some other kind of sound-absorbing material. This type of muffler is designed to reduce back pressure, which occurs when exhaust travels back up the pipes toward the engine, and consequently makes more noise.\nThe tailpipe comes out of the muffler, past the rear bumper of the vehicle, and directs exhaust gases away from the vehicle. Some vehicles may have more than one tailpipe. The tailpipe often ends with just a straight or angled cut, but may include a fancy tip. The tailpipe is often larger in diameter than the rest of the exhaust system. This produces a final reduction in exhaust pressure, and is sometimes used to enhance the appearance of the vehicle.\nThe worst enemy of an exhaust system is corrosion, more commonly known as rust. Moisture or water vapor is present in the exhaust as a by-product of combustion and the catalytic converter. Corrosion may also result from outside elements such as rain, snow, and salt. If you live in an area where road salt is used during the winter, make sure to wash the underside of your vehicle with water every few weeks. Salt speeds up the corrosion process and getting it off as soon as possible will help stop the corrosion.\nOther symptoms of exhaust system problems may include decreased power, decreased fuel economy, hissing noises, metallic rattling noises, an overly loud engine, exhaust fumes, the presence of a check engine light, and physical damage due to the system hanging low beneath the vehicle.\nMany factors, such as climate and driving conditions, can affect the life of your exhaust system. The cleaner the engine runs, the cleaner the exhaust traveling through your exhaust system will be, which will help prevent catalytic converter and O2 sensor failures. It is important to have your exhaust system inspected by an ASE certified technician at least annually, or whenever you experience symptoms possibly related to the exhaust system. Each component should be inspected for damage, rust, leaks, broken bolts, cracks, noises, secure mounting, and to make sure all critical components are present.\nIf you are buying a used vehicle, make sure the entire exhaust system has been thoroughly inspected before you make your purchasing decision. Having the exhaust system inspected will ensure the vehicle is operating efficiently, will help keep your passengers safe, and may help you avoid costly repairs.', ""Exhaust problems are common. When you are driving around, one situation you never want to encounter is hearing strange noises underneath your vehicle. Should you begin to hear a loud rattling, chances are this means there is an issue with your muffler.\nWhile you’ll be wondering what causes mufflers to rattle and is there damage, other concerns will also present themselves, including how to fix the muffler and whether or not it needs to be replaced. If you find yourself asking these and other questions at the moment, we’ve got the answers you need right here.\nModern car exhaust systems can cause an expensive repair bill or even a new car in the worst cases. Getting on top of these issues can help prevent costs from adding up, as well as reducing excess exhaust gases from being released into the atmosphere. This page hopefully will help you to stop replacing the whole vehicles’ exhaust and fixed simply.\nWhen a loose muffler develops internal rattles an annoying noise usually follows and typically with very loud sounds and potentially a banging noise.\nWe will investigate what causes loud noises from muffler rattling and what you need to do to prevent your vehicle’s engine from damage.\nTable of Contents\n- What Causes Muffler Rattle?\n- Is My Muffler Damaged?\n- Can I Drive with a Rattling Exhaust?\n- Does My Exhaust System Need to be Replaced?\n- Can the Rattling Sound Come From the Inside of a Muffler?\n- How Is a Muffler Fixed?\n- How Come Modern Exhaust Systems Go Bad?\n- FAQs (Frequently Asked Questions)\nWhat Causes Muffler Rattle?\nWhile you may think the vehicle’s exhaust is comprised only of a muffler and tailpipe, the fact is this system is one of the more complex found on any vehicle. Stretching from your car’s engine all the way to the exhaust pipe, there can be numerous reasons why you hear a rattle in and around your exhaust pipe.\nMain Causes of Muffler Noise\n- Corroding parts\n- Worn rubber hanger\n- Slack bolts\n- Sheared bolts\n- Damaged muffler\n- Heat shield damage\n- Unsecure heat shield\n- Loose bracket and mountings\nIn most cases, you’re likely to hear sounds indicating metal is hitting against metal, which means something is hitting against your vehicle’s exhaust pipe. Once you look underneath your car and examine your car exhaust, you may find a bracket or connector that is loose or broken due to corrosion.\nWhen this occurs, your exhaust system gets misaligned, causing the rattling sound. Should your loose muffler hang too low, this will also cause a rattling. This is caused by bouncing up and down as you drive along, especially on bumpy roads or going over railroad tracks.\nQuite often Brackets and bolts securing tailpipes, heat shields above catalytic converters, and other components can come free or shear off. Left unattended, this can cause excessive movement and the catalytic converter to develop internal rattles in baffled chambers/ the perforated tubes.\nIs My Muffler Damaged?\nOnce you realize there is a rattle, your next thought will be wondering if it is damaged. Since you’ve heard plenty of loud noises, chances are you are suspecting the worst. To find out for sure, you’ll need to closely examine your car’s exhaust system. To begin with, look at the exhaust pipes to see if you notice anything is loose, rusted, or cracked If there is excessive movement this is a key sign of a muffler problem.\nAlso, you should be paying attention to the muffler and the heat shield to see if either is damaged. If you see holes or cracks, you’ll know where the problem is originating. Keep paying attention to any decreases you notice in your vehicle’s fuel efficiency or ability to properly accelerate since these are usually signs of an exhaust leak or muffler damage.\nA final point is to always double-check the system, you may think you’ve found the only cause but there may be damage to other components.\nCan I Drive with a Rattling Exhaust?\nWhile you can drive, you may be putting yourself at risk of getting a ticket from the police. Since most localities have laws to keep motor vehicles operating safely and at acceptable noise levels while on the road, having a muffler that is damaged is usually considered to be illegal.\nAlong with this, left unattended driving around with a damaged muffler puts unnecessary stress on your exhaust system and even your engine, which over time could lead to the development of additional problems that result in expensive repair bills. Therefore, to avoid paying a traffic ticket and large repair bills, get your vehicle repaired by auto professionals as soon as possible.\nDoes My Exhaust System Need to be Replaced?\nTo answer this question, it comes down to the extent of the damaged muffler. Should the problem just be a loose bracket or connector, your current muffler should continue to be fine once everything is once again tightened up. However, if you look at your muffler and see visible signs of corrosion and rust that have produced cracks or holes in your muffler, it will need to be replaced. While not a terribly complex job, it is still one that is best left to an experienced auto mechanic.\nCan the Rattling Sound Come From the Inside of a Muffler?\nIt sure can. In fact, while the majority of people assume the problem is external, there are many times when the problem is coming from the muffler’s interior. Contrary to what you may have thought, the inside of your muffler is comprised of such things as baffles(perforated tubes), and numerous other parts. Should any of these become loose or get damaged, the result will be internal rattling that will have you rattled upon hearing these unsettling noises.\nHow Is a Muffler Fixed?\nAs stated earlier, the fix can be either a very easy job or one that will be complex and should only be tackled by auto mechanics who have a thorough understanding of exhaust problems. If you are lucky, all that will be needed is to tighten one or two bolts or replace a broken hanger, which is something you may be able to do yourself. But should you see signs of rust that have led to holes and cracks in the pipes and muffler, leave this to the pros.\nAlso, remember that even if there is a rattling muffler, it is possible this may not be the actual source of the rattle. From brackets and bolts that secure tailpipes and heat shields to catalytic converters that develop rattles when they go bad, these are just a few of the possibilities when trying to unravel your mystery.\nHow Come Modern Exhaust Systems Go Bad?\nWhile the systems on today’s vehicles are state-of-the-art, the stainless or aluminized steel from which they are made can’t last forever. Since the exhaust system is constantly subjected to high levels of heat and moisture, road salt during winter, and various types of debris on the road, even the best of vehicles on the road today can’t withstand this forever.\nOnce you start to notice a rattling noise connected to your muffler, have it examined as soon as you can. While the noise may be annoying, it could also indicate your vehicle’s exhaust fumes may not be exiting your vehicle properly. In the worst-case scenario, an exhaust leak can result in fumes coming back inside your car, which puts your health at tremendous risk.\nDue to the many reasons why your muffler may be rattling, don’t put off getting it checked out by a mechanic you trust. Even if it turns out to be only a bolt or two that needs to be tightened, you will have instant peace of mind as you get back behind the wheel and start the engine.\nFAQs (Frequently Asked Questions)\nWhat other names are Mufflers called?\nHow to Reduce Road Noise in Car (Soundproofing Car Road Noise)\nIn this article, we have shared information on How to Reduce Road Noise and How to Soundproof a Car. This includes Car or Automotive Sound Deadening and Soundproofing.\n7 Best Sound Deadening Materials for Cars\nIn this article, we have listed 10 best car or automotive sound deadening materials that are available in the market. We have also listed their unique features and why you should buy them.\n10 Best Oil Additives to Quiet Noisy Lifter with Reviews\nLooking for the best lifter noise additive for your vehicle? If you’re unsure which additives for noisy lifters is best, then read on!\nWhat does an Exhaust Leak sound like and How to fix it?\nSince motor vehicles are made up of many parts, it's only natural that along the way some of them begin to experience problems. One of the most common areas...\nHow Long Will a Wheel Bearing Last After it Starts Making Noise\nVehicles need a good set of tires to keep them performing optimally. But there is more to the wheel than the tire; beyond the visible rubber is an intricate...\nHow to Make Your Car Quieter Inside\nIf you want to be able to hear a pin drop while behind the wheel of your vehicle, here are some of the best ways you can go about making your car quieter inside.""]"	['<urn:uuid:d18ede61-ba1a-41a7-9dee-f8068a61c1d2>', '<urn:uuid:b7928ff4-dcfa-4cca-b754-54f91fd7a15b>']	factoid	with-premise	verbose-and-natural	similar-to-document	multi-aspect	expert	2025-05-12T22:49:38.933606	32	74	2571
54	What is the meaning of Thaba Bosiu?	Thaba Bosiu means 'mountain of the night' - Thaba meaning mountain and Bosiu meaning at night.	['The Mokorotlo – A Symbol of Unity\nUpdated: Apr 21, 2021\nThe Basotho hat, or Mokorotlo, is a widely recognized symbol of Lesotho and often seen being worn by locals and visitors alike. You’ll find these conical headpieces in various shapes and styles in curio shops, at traditional ceremonies and gatherings, as presents to visiting dignitaries (along with the Basotho blanket), and in everyday wear.\nIts conical shape with the distinctive topknot is a symbol of the country’s unification and is said to depict the mountaintop, Mount Qiloane (or the Qiloane Pinnacle) that sits upon the Thaba Bosiu mountain plateau. This mountain top is also known as ’modianyewe’, which means ‘he who executes judgement in court’. This makes sense as the Mokorotlo was the object which was used to cast rulings in customary courts, similar to the symbolism of a gavel which is seen in western societies. Interestingly the name Mokorotlo also refers to the traditional male dance performed by male initiates and elders.\nLegend has it that the Basotho looked down onto Qiloane from Thaba Bosiu and started weaving grass growing on top of the mountain – that’s how the first hats came about.\nTo better understand how this hat became a national symbol we need to explore a little into the importance of Thaba Bosiu itself. Thaba Bosiu (Thaba meaning mountain and Bosiu meaning at night) holds an important place in Leotho’s history as it acted as Moshoeshoe’s headquarters and stronghold during the various Basotho Wars.\nThe name mountain of the night comes because of the local belief that Moshoeshoe’s people made it here in the evening, almost 200 years ago, and it never failed in its promise to protect those who looked up to it.\nAt an elevation of nearly 120 meters above the surrounding area, the plateau formed a natural fortress to gather the Basotho people in times of danger. Its sandstone plateau has an area of approximately 2 km2 and a height of 1,804 meters above sea level. The plateau’s large area meant it could hold enough livestock and provisions to support the people during a lengthy siege.\nThe mountain was said to grow during the night, leaving enemies who tried scaling it exhausted and besieged . Enemies claimed that the mountain felt as if it was growing as they climbed.\nDuring the first Free State / Basotho War against the Orange Free State in 1858, the Free State’s commandos tried assaulting the stronghold, but met with little success. During the third war against the Free State in 1868, Thaba Bosiu was the only stronghold that wasn’t stormed by the Free State forces. In the time the stronghold remained manned, it was never taken by the enemy. When Chief Moshoeshoe 1 died in 1870, he was buried on Thaba Bosiu.\nThe ruins and the graves of various chiefs is all that remain of the settlement on Thaba Bosiu. As a national monument, it is protected land and a well known tourist destination.\nThe origins of Mokorotlo hat are unclear. A similarly shaped hat has been identified among the descendants of the Cape Malays, former slaves from the East Indies, and it is believed that the Sotho may have adopted the Mokorotlo through exposure to these slaves, but this is speculation.\nThe Mokorotlo became infamous in the early 1900s when a forerunner of this hat was worn by tribal chiefs, who chanted a combat/praise song known as ‘Mokorotlo’ while making their way to the chiefs’ court. It is from this early connection that the hat became known as Mokorotlo. It was exclusively worn by males to these gatherings. However, in the 1950s, new designs were developed to cater to women.\nThe Sotho people display the Mokorotlo in their homes indicating that they uphold the customs and acknowledge their bonds with their ancestors. It also serves to protect the home against danger and other evil influences.\nThe hat’s design, as we know it today, first appeared at the end of the 1930s, and its growing prominence was closely associated with the development of national identity.\nDevelopments in hat design and mass production for a European market contributed to an increase in popularity of the Mokorotlo hat among the Basotho people (as did the Basotho blanket).\nIts growing importance as a symbol of Lesotho was strengthened by its association with royalty, key political parties and political figures who wore the hats to rallies and public functions during the 1950s and 1960s.\nIn 1966, the mokorotlo was chosen as the symbol on the national flag of a newly independent Lesotho. Its image is found on everything from car number plates, to mass produced printed fabric, to the shape of the craft centre building in the capital of Lesotho, Maseru.\nTrue Basotho hats are manufactured from an indigenous grass known as “mosea” or “lehodi” Next time you see a mokorotlo at a craft market, recognise it as more than just a curio, but is a symbol of pride, unification, peace and strength.\nThis article was curated and written by Andrew Knapp of The Design Train for Clarens Butterfly Beds.\nReasonable permission to use this article can be obtained from the author\n©Andrew Knapp 2018']	['<urn:uuid:d3578b15-d839-4016-98b7-71300c348095>']	factoid	direct	concise-and-natural	similar-to-document	single-doc	novice	2025-05-12T22:49:38.933606	7	16	864
55	Which music pieces are reconstructions of older works?	While Mahler's 10th Symphony is a reconstruction and re-orchestration of Mahler's unfinished work by Michelle Castelletti, Sardelli's Trio Sonatas are new original compositions written in Baroque style, not reconstructions of older pieces.	['Composer: Federico Maria Sardelli\nPerformer: Stefano Bruni – violin, Giovanni Battista Scarpa – violin, Paola Talamini – organ, Lorenzo Parravicini – cello, Bettina Hoffmann – cello\nNumber of Discs: 1 CD\nFormat: FLAC (tracks)\nBit Depth: 24bit / 44,1kHz\nNumber of channels: 2.0\nLabel: Brilliant Classics\nSize: 704 MB\nScan: yes (PDF)\nStefano Bruni – Sardelli – 6 Sonate a Tre (2019)\nFederico Maria Sardelli (b.1963)\n01. Sonata I in B-Flat Major: I. Allegro\n02. Sonata I in B-Flat Major: II. Larghetto\n03. Sonata I in B-Flat Major: III. Allegro molto\n04. Sonata II in D Minor: I. Largo\n05. Sonata II in D Minor: II. Allegro\n06. Sonata II in D Minor: III. Andante\n07. Sonata II in D Minor: IV. Allegro molto\n08. Sonata III in E Major: I. Allegro ma d’un mezzo tempo\n09. Sonata III in E Major: II. Adagio\n10. Sonata III in E Major: III. Allegro e spiritoso\n11. Sonata IV in A Minor: I. Andante\n12. Sonata IV in A Minor: II. Allegro\n13. Sonata IV in A Minor: III. Andante\n14. Sonata IV in A Minor: IV. Allegro\n15. Sonata V in C Major: I. Andante\n16. Sonata V in C Major: II. Allegro\n17. Sonata V in C Major: III. Largo e cantabile\n18. Sonata V in C Major: IV. Allegro\n19. Sonata VI in G Major: I. Allegro\n20. Sonata VI in G Major: II. Largo\n21. Sonata VI in G Major: III. Allegro\nThe ‘living Baroque’ idiom of Federico Maria Sardelli has been extensively documented on Brilliant Classics, with albums of concertos (BC94749), cantatas (BC95068) and harpsichord music (BC95488) that have advanced the reputation of this modern composer and scholar and won international attention, with 5-star reviews in Diapason and elsewhere.\nNow Sardelli turns his imagination to the genre of the trio sonata that exemplified chamber music-making in the Baroque era. The collection of six presented here divides into two sub-genres, of the church sonatas (Nos. 2, 4, 5) and chamber sonata (Nos. 1, 3, 6) which would have been heard in a domestic, albeit aristocratically appointed, context. Sardelli makes passing and subtle allusions to poignant melancholy (in the Larghetto of the First Sonata), to an infernalrhythmic impulse (the second movement of the Fifth), to more profound meditations on mortality (such as the Adagio without bass of the Third), and even to declarations of love (the opening of the Sixth) – though the subject of Sardelli’s affection is surely Vivaldi himself.\nAccording to the composer, this is not Baroque pastiche. Rather, as a noted scholar of Vivaldi, he seeks to recreate such music in his own image with music of the present which ‘regains its own original language and adheres to its own original criteria, expressing vibrant new ideas that are in keeping with its identity.’ It would be quite possible to think that the trio sonatas here had been written with a goose quill in 17th-century Venice, but they are by no means dry exercises in imitation. Rather they are full of an authentically Venetian vibrancy and colour from any age, sparkling with a variety of knowing brilliance that belongs to the temperamental character of the city.\nThe performances here are given by musicians who have long worked with Sardelli in his Modo Antiquo ensemble which has made highly praised recordings of ‘real’ Vivaldi as well as Sardelli.\nFollowing on the success of his instrumental music (5 star in Diapason) and Sacred Music this new recording presents “Sonate a tre”, Trio Sonatas for two violins, cello and a continuo of cello and organ, composed in Baroques style by present day composer and conductor Federico Maria Sardelli.\nSardelli is one of the foremost conductors of Baroque music, his pioneering performances with his group Modo Antiquo have received glowing reviews in the international press. As a composer he has been inspired by the great Baroque masters, notably Vivaldi, and his compositions in this style seem to have been penned with a goose quill in 18th century Venice. His works are no dry exercises on the basis of the rules of the day, but are vibrant, alive, bursting with energy, passion and brilliance.', 'Gustav Mahler: 10. Symphonie (Arranger: Michelle Castelletti)\nGustav Mahler: 10. Symphonie (Arranger: Michelle Castelletti)\n- Year of composition:\n- Scored for:\n- for chamber orchestera\n- Gustav Mahler\n- Michelle Castelletti (2012)\n- 1 1 1 1 - 1 1 0 0 - perc, hp, pno, vln, vln, vla, vc, cb\n- Instrumentation details:\nclarinet in Bb\nhorn in F\ntrumpet in Bb\n- for Angèle\nThe re-creation of Mahler’s Tenth Symphony through a new performing edition made in the contemporaneous tradition of the Verein für Musikalische Privataufführungen as established at the beginning of the 20th century.\n‘It should be one‘s sole endeavour to see everything afresh and create it anew.’1 Gustav Mahler\nPossibly one of Mahler’s most passionate emotional outbursts and autobiographical creations, Mahler’s Symphony No. 10 is a fascinating journey, not only for performance aspects, but also for musicological and analytical ones, providing a deep psychological pathway into the genius that was Mahler – a mesmerising voyage for the composer, performer and conductor.\nThe issue of re-orchestration has been a long-discussed debate amongst music scholars and performing musicians. My work relates to, and complements, existing musicological studies, as well as several reconstructions for full orchestra that have been made of Mahler’s last symphony.\nAlthough there are many versions, I focussed my investigation on the following: Derek Cooke (in collaboration with Berthold Goldschmidt, Colin Matthews and David Matthews); Rudolf Barshai; Alexander von Zemlinsky’s completion of movements 1 [&] 3 (with Alban Berg, Ernst Krenek and Franz Schalk); Clinton Carpenter; Remo Mazzetti and Joseph Wheeler.\nWhile the basic material remains intact, there are very significant differences in each of these orchestrations. Deryck Cooke’s version is arguably the most ‘faithful’ one, primarily representing Mahler’s own notes, to make the symphony performable. The edited score also contains a copy of most of Mahler’s annotations and sketches, together with the corresponding short-score in smaller print on every page, where it exists; and thus, I found this version particularly helpful, especially with regard to thematic continuity.\nMy intention was to re-create this symphony for chamber orchestra, retaining the authenticity found in the Mahler manuscripts, combining it with the fuller orchestral palette achieved by Rudolph Barshai, rather than the thinner textures realised in the Cooke version. This approach allowed for the various contrapuntal and timbral lines and colours to form one coherent structure, imbued within Mahler’s voice. Whether fully orchestrated in specific passages, or a sole melody in others, there is one continuous line throughout the surviving manuscript pages.\nThe original manuscripts were published in two separate facsimiles (Paul Zsolnay Verlag, 1924: 116 pages) and a more complete version in 1967 (160 pages) published by Walter Ricke under the aegis of the International Mahler Society, edited by Erwin Ratz.2 This edition included the Adagio and the Scherzo in full draft score, short score and sketch (with completion of varying degrees), 30 bars of full score of the Purgatorio, together with a short score and sketch; and short scores and sketches for the final two movements. Other pages were published in the 1976 score of the performing version by Deryck Cooke.\nThrough the collection of various facsimiles and scores of previous symphonies, I became very familiar with Mahler’s calligraphy, modus operandi, level of detail, instruction and intention. I also acquired the extant sketches of his ‘unfinished’ symphony, including the orchestral draft, the preliminary short score, Ricke’s and Zsolnay’s facsimiles of Mahler’s manuscript, a separate, solitary sketch-page, the surviving short score by Mahler, and, thanks to the National Library of Austria in Vienna, all existing Mahler’s sketches (including previously ‘lost’ pages) found at the Österreichische Nationalbibliothek.\nThis new performing edition for chamber forces is scored for single woodwind (with flute doubling piccolo), horn, trumpet, percussion, harp, piano/harmonium and single strings. The score gives ossia lines for double-bass, for the option of the C-string extension. It also gives the option of ossia lines for the timpani, just in case the 32’ one is not available.\nThe harmonium of choice is the Mustel 1902 Harmonium, with two manuals and with 4’, 8’ 16’ and 32’ stops. This is contemporaneous with the period, as used in Erwin Stein’s chamber orchestra version of Mahler‘s Symphony No. 4 and Schoenberg’s chamber orchestra version of Mahler’s Das Lied von der Erde. Specifically, this instrument is a double manual, with the full complement of expressive devices on a harmonium with 20 stops, and a 5-octave range.\nThe percussion instruments called for are the following: Timpani (a set of 5 would allow the solo at the end of Movement IV to be played with ease), 2 Cymbals (suspended: large, small*), 2 Triangles (large, small*), Glockenspiel, Xylophone, Tam-Tam, Bass Drum, Snare Drum, Tambourine, Whip/Slapstick, Finger cymbals*, Military Drum and Ratchet. The instruments marked with an asterisk are those played by the pianist, in part.\nColour and instrumentation, including Mahler’s use of unusual percussion instruments in symphonic literature to date; his use of con legno, mutes, gestopft and portamento; the culture of vibrato around the fin-de-siècle period; weight, balance, register, texture, and dynamic proportions3, had to be meticulously analysed.\nThe architecture and over-arching form and shape of the symphony, as well as the complexity of emotion this work carries, helped inform my interpretation. These fundamental factors also influenced the reconstruction and orchestration, and, perhaps above all, what I believe Mahler was attempting to say through this music, which is, in my opinion, overwhelmingly autobiographical, excitingly bipolar and plainly futuristic.\nI have taken the decision that this edition will be treated as a performing score. There are no dotted lines, square brackets, small notes – in fact, no editorial markings whatsoever. The doctoral thesis upon which this score is based4 contains all the explanations, footnotes, annotations etc. The fact that this score is already not what Mahler intended instrumentation-wise, would make the exercise of distinguishing between what was in the score and what not, almost futile, and impossible to read. This work is being published to be performed as a version for chamber orchestra.\nIn her forward to the 1924 facsimile edition of the Symphony No. 10, Alma Mahler wrote:\n‘While I initially considered it my absolute right to keep the treasure of the Tenth Symphony hidden, I now know it is my duty to reveal to the world the last thoughts of the master. […] It proclaims not only the last music of the master, but it shows in the impassioned strokes of his handwriting, the enigmatic self-image of the person with perpetuating effect. Some will read in these pages as if in a book of magic, while others will find themselves faced with magic symbols to which they lack the key; none will escape the power which continues to emanate from this handwritten music and scribbled verbal ecstasies.’5 There is endless debate about the ‘ethical’ issues which surround this.\nDo we have the right to do this? However, when one knows that this was being done at the time through the Verein itself, and adds to that, the admiration Schoenberg himself had for Mahler, as well as how Mahler encouraged the ‘creating anew’, I think that while such discussion is legitimate, there is enough evidence to support this endeavor. One need only turn to works like Mozart’s Requiem, Elgar’s Symphony No. 3, Bruckner’s Symphony No. 9, Puccini’s Turandot or even Mahler’s own completion of Carl Maria von Weber’s Die drei Pintos; as well as the very many works arranged for chamber version by the society itself, which gave 353 performances of 154 works in a total of 117 concerts, during its existence.\nEven Sir Georg Solti, who never claimed to be a composer, wanted to attempt reconstructing Mahler’s Symphony No. 10. Sadly, this was never to be, as Solti passed away in the summer of 1997.\n‘My performances of the opening movement of the Tenth Symphony made me want to attempt to conduct a reconstructed version of the whole work. [...] The melodic invention [...] is heartbreakingly beautiful. [...] The English musicologist Deryck Cooke made the first reconstruction of the symphony, but I have not used it as I think it lacks the contrapuntal element in Mahler’s writing. Three further versions of the Tenth Symphony exist or are in preparation and in the summer of 1999 I would like to work on a solution to the symphony, putting together the different reconstructions that are available and adding points of my own.’6 For my reconstruction there were many compositional decisions that had to be made based on colour and timbre to capture the essence of what was intended by Mahler within the chamber instrumentation I chose to work with.\nThere are ‘mistakes’ or ‘oversights’ in the orchestral draft – pitch, rhythm, omission of change of clef, two different (wrong) key signatures at the same time, no indication of time signature etc., as well as unclear instructions, and opposing or contradictory passages in different sketches. There are also instances of contrapuntal vacuums, in which case, the study of the different performing editions proved essential.\nIn places, some performing versions have made decisions to change what Mahler wrote in the orchestral draft, assuming that these were mistakes. My version tries to remain as faithful as possible to the orchestral draft, short score and extra sketches, especially harmonically, even when the language used is not conventional. Like Michael Kennedy, I believe that Mahler was stretching the harmonic palette as far as he possibly could.7\nI believe the stark contrast of an idyllic Toblach in South Tyrol, shattered by the discovery of Alma Mahler’s affair with the architect Walter Gropius8 is fully represented in Mahler’s language, colour, texture and form in this symphony. Desperate Mahler scribbles are found throughout the manuscript: Der Teufel tanzt es mit mir Wahnsinn, fass mich an, Verfluchten! vernichte mich dass ich vergesse, dass ich bin! dass ich aufhöre, zu sein dass ich ver [. . .]9 ending with ‘für dich leben! für dich sterben! — Almschi!’10 on its final pages.\nIt is, in my opinion, the epitome of the pain/beauty paradox, as described by Immanuel Kant.11 This is a work of excruciating beauty; a constant search for the sublime, which is found in the final movement.\nMahler is evidently distraught, as seen and heard through the pages of his manuscript. It feels like reading Mahler’s personal diary, invading his privacy and witnessing his innermost emotions being exposed to the world. It almost feels wrong. The autobiographical content of this most passionate cry in Mahler’s last symphony haunted me as much as the work itself. Yet, is there hope?\nWhat I have attempted to give is a faithful and stylistic re-creation of Mahler’s Symphony No. 10 – a correct representation of a large-scale work, retaining its profoundness, impact and magnificence; creating clarity of lines, but revealing the intimacy of the work.\nFor a conductor, to delve as deep as this, not only re-orchestrating, but rebuilding an unfinished, yet completely structured work, gives an extraordinary insight into the process of how to interpret a composer’s work – even one as complex as Mahler. One explores the symphony’s inner workings, practically and physically, but, more than that – especially in this particular work – psychologically.\nEven in his most impassioned symbolic tenth symphony, Mahler, the man of contrasts, remains unfaltering … the cruelty of the situation, the hurt, the anger, the tenderness, the anguish and torment … and the clinging on to hope and the longing for the beauty to re-emerge, and the acceptance of what is.\nMahler’s ‘scribbled verbal ecstasies’ are almost as powerful as his music – maybe to be read by the one who has caused him so much pain – his ‘immortal beloved’? – The Beethoven of the 20th century.\n‘It is absurd for any conductor in the twenty-first century to proclaim the Tenth unperformable [...] The Tenth exists as Mahler’s last word. It reveals Mahler, in his favoured metaphor, wrestling with his angel, refusing to let go without a blessing. If the symphony reveals nothing else, it is that Mahler did not surrender to fate, nor to depression at his wife’s betrayal, nor to health fears, nor to any other force except his mission to compose. In these final pages he surmounted the fickleness of love and life in a way that only Mahler could, with a never-say-die symphony that offers in its last unfinished page a glimmer of hope. No knowledge of Mahler is complete without the live experience of his Tenth Symphony.’12\n23 September, 2015\n1 H-L. La Grange, Mahler, Volume I, Garden City, NY, Doubleday [&] Co, 1973.\n2 T-L. Chew, Performing Versions of the Tenth Symphony, Naturlaut, Vol. 1 (2), 2002.\n3 This includes individual [opposing] dynamics for different instruments which was revolutionary for the time.\n4 I conducted the premiere of this editorial score as part of my PhD on November 23, 2012.\n5 D. Cooke, Gustav Mahler – a Performing Version of the Draft for the Tenth Symphony, London Faber Music, 1989.\n6 Sir Georg Solti, [with the assistance of Harvey Sachs], Solti on Solti – A Memoir. Vintage, 1998. It is the analyst/musicologist inside the conductor who takes over. Solti is well-known for discovering the right tempo marking of the second movement of Bartók’s Concerto for Orchestra. This has forever changed conductors’ interpretations of this work.\n7 Michael Kennedy, The Master Musicians – MAHLER, [from the series edited by Stanley Sadie] Oxford University Press, 2000.\n8 J. Bruck, MAHLER, G.: Symphony No. 10, Wheeler, 1966 version. Polish National Radio Symphony, Olson, 1999. [NAXOS CD].\n9 ‘The devil dances it with me / Insanity grasp me, the cursed one! / destroy me / so that I may forget that I exist / that I cease to be / that I ver [. . .]’\n10 ‘To live for you! To die for you! – Almschi!’\n11 Kant, I., Critique of Pure Reason, Guyer P. [&] Wood, A.W. (trans.) Cambridge University Press, 1999.\n12 N. Lebrecht, Why Mahler – How one man and Ten Symphonies Changed the World, Faber and Faber, London, 2001.\nGustav Mahler: 10. Symphonie\nfor chamber orchestera , 75’\nInstr.: 1 1 1 1 - 1 1 0 0 - perc, hp, pno, vln, vln, vla, vc, cb\n- Canterbury Chamber Orchestra\n- Michelle Castelletti']	['<urn:uuid:b3504f9c-69bc-4223-bff5-f64902108bbf>', '<urn:uuid:66649320-b5e4-4127-aad7-9beca0b1bcc9>']	factoid	direct	concise-and-natural	similar-to-document	comparison	novice	2025-05-12T22:49:38.933606	8	32	3061
56	how brady list works against prosecutor misconduct what consequences for lying prosecutors	The Brady List helps track prosecutorial misconduct by recording time-stamped data about evidence disclosures, allowing comparison with official case records to demonstrate misconduct. When prosecutors lie or commit misconduct, the consequences can include case dismissal, sentence reduction, conviction reversal, or ordering a new trial. In extremely rare cases, prosecutors may be disciplined, prosecuted, or sued. Additionally, prosecutors who fail their Brady obligations to disclose evidence can face discipline up to being disbarred by the State Bar, meaning they can never practice law again.	"['The Brady List can be used as a tool to overcome prosecutorial and judicial misconduct in cases of wrongful conviction. It is useful to recall a few specifics about Brady v. Maryland in order to help understand the strengths for those wrongfully convicted as well as the vulnerabilities of the powers-that-be.\n- Brady is not about \'law enforcement accountability\' or \'police misconduct\'. It is merely a record of material that must be disclosed to defendants in the interests of justice and fair trials.\n- Brady is about evidence. In fact, The Brady List is an example of a proactive disclosure evidence handling system that also happens to be public-facing for the purposes of accessibility to Pro Se/Pro Per defendants. Cases and jurisdictions subject to expedited protocols [infractions, traffic, plea bargains] do not relieve the prosecutor of their obligations under the Brady doctrine.\n- Brady creates a Constitutional obligation upon all prosecutors in all criminal cases to disclose exculpatory evidence, specifically including impeachment and mitigating evidence. Brady states that a prosecutor must disclose ""any information about all individuals upon whose testimony will be relied.""\n- Brady obligations upon prosecutors specifically includes \'expedited\' protocols: plea bargains, infractions, traffic tickets, etc..\n- Brady actively prohibits the application of discretion by law enforcement, prosecutors, and judges. Brady states ""in the event of a question arising about the materiality of the evidence in question, the evidence must be viewed in the light most favorable to the defendant.""\n- Each criminal case has an official record; but, not all evidentiary disclosures are in the official record; so, the original case file with the full list of disclosures will be required to determine whether or not the prosecutor satisfied their disclosure requirements with regard to police misconduct and use-of-force records. Know ahead of time: most prosecutors do not disclose nearly enough evidence to be in compliance.\n- Departmental policies of prosecutors and/or law enforcement do not relieve the prosecutor of their Constitutional obligations, even if they claim that to be so. In fact, policies of this nature are a solid indicator that the refusal to disclose is in fact intentional, malicious, and systemic.\n- Brady is perpetual: the obligations under Brady, upon the prosecutor, to disclose any and all exculpatory evidence under the premise that the Justice System will go to great extremes to avoid convicting a single innocent person. By example: if and individual is convicted of a crime and the prosecutor later becomes aware of another individual having actually committed a crime, the prosecutor is obligated to prosecute the second person and provide for the evidence for the exoneration of the first person. This does not always happen, but that is where the obligation lies.\n- Brady is retroactive: For example: check out this article on Officer Chauvin being convicted for the murder of George Floyd: Derek Chauvin is a Brady Cop: Now What?\nNow that we have been reminded about the details of Brady, let\'s talk about the impact of the Brady List upon the accountability of the criminal justice system.\n- All data on the Brady List is time date stamped allowing for \'what should have been known; and, when it should have been known\'.\n- All data on the Brady List is severally entered and jointly analyzed by organization and jurisdiction.\n- Proof of prosecutorial and judicial misconduct does not come from the Brady List; but, it is comparable to the official record and files of a case. Most misconduct is demonstrable by the comparison of the two.\n- File a complaint against police, prosecutors, and/or judges under the concept of the court of public record.\n- Brady disclosure obligations do not require, nor rely upon, a finding, ruling, or discretionary determination of guilt or innocence.\n- Get the Discovery. Brady requires certain material evidence be disclosed automatically. The obligation is on the prosecutor; and, if they fail [in any way] it is demonstrable as active, intentional, and malicious. The disclosure must contain either: a) records of police misconduct and use-of-force for every single officer involved; or, b) a confirmation that no such records exist. If the prosecutor fails or refuses in any way - move for an immediate dismissal.\n- Prepare for an Appeal. If a defendant gets stonewalled with regard to Brady disclosures, the Court of Appeals is far more likely to identify and act on the judicial and prosecutorial misconduct at the trial court level.\n- Keep the Case File. Brady is both perpetual and retroactive; so, if an officer is ever proven to be untruthful or is convicted of a crime of moral turpitude - then that is evidence that their testimony in the current case can be impeached. This evidence will also strongly support expungement efforts.\n- Compare the Discovery to the Current Record. As the Brady disclosures must include records of police misconduct and use-of-force records, check the officers file [even years later] for evidence that can be used as impeachment evidence in requesting a new trial. An officers name appearing on the Brady List years after a conviction is still very much applicable to a past case.\n- Check Other Cases by the Same Prosecutor. \'Problem prosecutors\' rarely commit the misconduct only once. It is far more likely that an appeal, request for a new trial, or an expungement request would be granted if the prosecutor has been identified as having committed the misconduct multiple times or that the prosecutor\'s office has adopted policies that are inherently flawed.\nIn all cases: dismissal is the goal, not revenge. Brady is about fair trials. If the trial is not fair than their can be no justice.\n- Prosecutorial misconduct is rampant. Prosecutors rarely commit prosecutorial misconduct only once, inadvertently, or by accident. While this may make you angry or exasperated, there is good news: the more you look into the history of a prosecutor - the more likely you will find something that can have them disbarred.\n- Don\'t Defend, Attack the Prosecutor. There are rules to being a prosecutor. One of them is Rules of Professional Conduct 3.8(g): Special Responsibilities of a Prosecutor. Look it up; learn it; and, know: if/when the prosecutor fails - they can be disciplined up to and including being disbarred by the State Bar which means the will never practice law again.\nIf you run into a \'problem judge\': attack their egos; embarrass them in front of their peers; and, put their history of bias on display.\n- Judges have egos. Egos do not belong on the bench. Crush them. Remind the judge that they will be held accountable for their actions.\n- Judges have bosses. No judge can go unchallenged; and, judges that review other judges behavior always want themselves to appear even more unbiased and committed to justice. Point out the justice at the lower level and the higher judge will take the opportunity to exalt themselves.\n- Judges were prosecutors. More than 90% of judges at the District and Superior Court level have a background in prosecution. That means they also have cases in their own history that can demonstrate their own bias via prosecutorial misconduct to support a claim of judicial misconduct resulting in active, intentional, and malicious behavior.\nAll politicians are just politicians. They lie and then they posture, and then they beg. Hold them accountable. Make them commit to fair trials and transparency - then, remind them every day of their commitments. The good ones will not run from disclosures.\n#Transparency = #Accountability\nPast the level of individual involvement and action, their exist groups of people that have united behind a common goal... Justice. These groups have taken many forms and have also subdivided based on any number of factors. We need not worry about what divides them; but, we can facilitate what drives them.\nThis is a list or \'workflow\' or just some ideas about how groups of regular individuals can come together to accomplish great things in criminal justice reform.\nOrganize & Mobilize\n- Social Media\n- eMail Campaigns\nComplaints by them selves do very little; but, organized complaints en masse are impossible to ignore; so, if you have a single issue...file a complaint; but, if you have a \'problem\' officer, prosecutor, or judge - do some research. If they are treating your case badly, chances are they have done this before and they will do it again.\nI cannot emphasize this enough: make friends with the Public Defender! They now who the problem individuals are; and they will have direct access to the files necessary to prove the misconduct is ongoing, intentional, systemic, and malicious.\nUse their power against them: if you see something, say something!\nPublish & Distribute the Results\nAt the bottom of each organization and state\'s Brady List there are some buttons - use them.\nPDF - this button produces a time/date stamped copy of the list you are viewing. This can be printed and emailed. It demonstrated what was known about who and when.\nRSS - this button can be integrated into a \'feed\' program that will notify users whenever there is a new addition or edit to the List.\nVote, vote, and then vote again!\nJust like your car or home needs maintenance, so does our government.\nThere are plenty of \'good\' candidates out there, and so-called progressive prosecutors are now everywhere; but, none of them have fully embraced their obligation to the people. They are still functioning in the realm of zero accountability; but, we are now in the information age and we can keep track of their conveniently forgotten campaign promises. If they promise to be transparent - recall them, even if they seem to moving in the right direction. You, me, and our loved ones do not have the time to wait for them to come to the conclusion that they need to fulfill their obligations.', 'In terms of prosecutorial misconduct?\nLast Update: April 20, 2022\nThis is a question our experts keep getting from time to time. Now, we have got the complete detailed explanation and answer for everyone, who is interested!Asked by: Tod Breitenberg\nScore: 4.7/5 (71 votes)\nIn jurisprudence, prosecutorial misconduct is ""an illegal act or failing to act, on the part of a prosecutor, especially an attempt to sway the jury to wrongly convict a defendant or to impose a harsher than appropriate punishment."" It is similar to selective prosecution.\nWhat are the four types of prosecutorial misconduct?\nProsecutorial Misconduct in California\n- failing to disclose exculpatory evidence,\n- introducing false evidence,\n- using improper arguments, and.\n- discriminating in jury selection.\nWhat is considered prosecutorial misconduct?\nActions that courts have labeled prosecutorial misconduct include: Using improper investigative techniques, such as “entrapment” – inducing a person to commit a crime who was not otherwise disposed to commit it. ... Knowingly presenting false witness testimony or other false evidence to a court or grand jury.\nWhat is the most frequently occurring type of prosecutorial misconduct?\nThe most common incidence of prosecutorial misconduct involves the suppression or fabrication of exculpatory evidence, or evidence that might lead to the exoneration of the person suspected of the crime. ... At a minimum, a prosecutor may downplay or simply ignore exculpatory evidence.\nWhat happens if a prosecutor lies?\nIf prosecutorial misconduct occurs, the charges may be dismissed, the sentence may be reduced, or the conviction may be reversed. The judge may order a new criminal trial for the defendant. The prosecutor may be disciplined or, in extremely rare cases, prosecuted and/or sued.\nProsecutorial Misconduct: What it is and What can be Done When it Occurs\nWhat are 3 examples of prosecutorial misconduct?\n- Failure to Disclose Exculpatory Evidence. ...\n- Improper Argument. ...\n- Improper Use of the Media. ...\n- Introduction of False Evidence. ...\n- Discrimination in Jury Selection.\nCan you sue for abuse of process?\nA plaintiff can sue for abuse of process when a defendant starts legal proceedings with the intention of obtaining results for which the process was not designed.\nWhat are the types of prosecutorial misconduct?\n- Failure to disclose exculpatory evidence. ...\n- Introduction of false evidence. ...\n- Improper argument. ...\n- Discrimination in jury selection. ...\n- Interference with a defendant\'s right to representation. ...\n- Improper communications with a judge or juror. ...\n- Improper use of the media.\nWhy is it so difficult to prove prosecutorial misconduct?\nProsecutorial misconduct occurs when a prosecutor intentionally breaks a law or a code of professional ethics while prosecuting a case. ... It is difficult to know the full extent of the problem, in part because prosecutors often are the ones who control access to evidence needed to investigate a claim of misconduct.\nWhy is prosecutorial misconduct bad?\nWhy Prosecutors Might Succumb to Misconduct\nSometimes, prosecutors find evidence that may exonerate the person they are trying to convict. Because prosecutors are charged with presenting the truth, the prosecution is obligated to turn over all exculpatory evidence to the defense. This can be difficult.\nWhat constitutes vindictive prosecution?\nVindictive prosecution has been defined by the United States Court of Appeals for the Seventh Circuit as behavior that results from ""specific animus or ill will"" or that occurs when a prosecutor ""charges a more serious violation . . . in retaliation for the exercise of a legal or constitutional right in connection with ...\nHow common is prosecutorial misconduct?\nPolice or Prosecutor Misconduct Is at Root of Half of Exoneration Cases, Study Finds. ... The study, which is based on 2,400 exonerations recorded in the registry from 1989 until early 2019, found that prosecutors and police officers committed misconduct at comparable rates (30 percent and 34 percent).\nWhat happens when a prosecutor is unethical?\nUnethical Prosecutors are Never Prosecuted\nA prosecutor\'s refusal to reveal exculpatory evidence may be immoral, unethical and illegal – and it may result in the imprisonment or death of innocent individuals – but the unethical prosecutor is never prosecuted.\nWhat are common ethical violations of a judge?\nCommon complaints of ethical misconduct include improper demeanour; failure to properly disqualify when the judge has a conflict of interest; engaging in ex parte communication and failure to execute their judicial duties in a timely fashion. Behaviour outside of the courtroom can also be at issue.\nWhat are types of judicial misconduct?\nActions that can be classified as judicial misconduct include: conduct prejudicial to the effective and expeditious administration of the business of the courts (as an extreme example: ""falsification of facts"" at summary judgment); using the judge\'s office to obtain special treatment for friends or relatives; accepting ...\nWhat can be done to reduce prosecutorial misconduct?\n- Require open file discovery. ...\n- Adopt standardized, rigorous procedures for dealing with the government\'s disclosure obligations. ...\n- Adopt standardized, rigorous procedures for eyewitness identification. ...\n- Video record all suspect interrogations.\nCan you sue the DA?\nAlthough it\'s possible, prevailing in a ""malicious prosecution"" or similar lawsuit against a district attorney or equivalent government lawyer for the act of filing charges is usually a tall task. A criminal defendant turned civil plaintiff must typically prove outrageous conduct by the lawyer(s) in question.\nWhat is exculpatory evidence?\nExculpatory evidence includes any evidence that may prove a defendant\'s innocence. ... Exculpatory evidence might include proof that the defendant stayed in a hotel too far away from the crime scene to have committed the crime.\nWhat ethical obligations should prosecutors have to those charged with a crime?\n(a) The prosecutor should act with diligence and promptness to investigate, litigate, and dispose of criminal charges, consistent with the interests of justice and with due regard for fairness, accuracy, and rights of the defendant, victims, and witnesses.\nCan you sue a prosecutor for damages?\nIf a prosecutor files such a case and the charges are dismissed, the defendant can sue for malicious prosecution and seek financial damages. The law that allows a malicious prosecution suit is aimed at preventing and addressing abuse of the legal process.\nWhat is considered misconduct by a judge?\n“Misconduct” is “conduct prejudicial to the effective and expeditious administration of the business of the courts.” A “disability” is a temporary or permanent condition, either mental or physical, that makes the judge “unable to discharge all the duties” of the judicial office.\nWhat is abuse of process of court?\nThe Court observed that FIR can be only quashed in order to prevent abuse of process of law or to secure the ends of justice. In cases where an innocent person is subject to unnecessary prosecution or an investigation is initiated without proper materials to make out a prima facie case, an FIR can be quashed.\nHow do you prove abuse of process?\n- The existence of an ulterior motive or purpose in using the process, and.\n- An act in the use of the process that is not proper in the regular prosecution of the legal proceedings.\nWhat is an example of abuse of process?\nA wrongful use of processes such as attachment of property, unjustified arrest, subpoenas to testify, executions on property, unfounded criminal prosecution, and garnishee orders are considered as abuse of process.\nCan prosecutors be held accountable?\nProsecutors are absolutely immune from liability, which means that they cannot be sued for their decisions as prosecutors, no matter how outrageous their conduct. The Supreme Court has held that absolute immunity protects prosecutors who knowingly used false testimony and suppressed evidence in a murder trial.']"	['<urn:uuid:85f20965-1658-491e-8c91-de077e7ad274>', '<urn:uuid:582c7ea4-0291-404c-8a68-4f376f0f3f59>']	factoid	direct	long-search-query	similar-to-document	multi-aspect	novice	2025-05-12T22:49:38.933606	12	83	2905
57	Which diamonds look colorless and what affects clarity?	Most jewelry stores carry colorless (D grade) and near-colorless diamonds, with near-colorless stones appearing white to the naked eye while being much cheaper. The setting metal affects color appearance - platinum and white gold make color more apparent, while yellow gold makes diamonds appear whiter. Regarding clarity, most diamonds have inclusions (internal flaws) and blemishes (surface imperfections), but these are typically only visible under 10X magnification with a loupe, except for imperfect (I1-I3) grade diamonds which most jewelers don't carry.	['When it comes to diamonds, many novice shoppers believe that bigger is better. In reality, the carat is only one of four very important characteristics to consider when picking out the perfect stone. Together these are called the 4 C’s: carat, cut, color and clarity.\nThe carat weight refers to the total mass of a diamond. One carat is 200 grams, and a diamond is generally measured to a hundred-thousandth of a carat, then rounded to the nearest hundredth. A diamond’s carat doesn’t consider how the weight is distributed. Because of this, a poorly cut diamond might appear smaller than it actually is.\nWith everything else being equal, the diamond with the highest carat will be the most expensive. It is also the easiest quality to pick out with the naked eye. This is why so many shoppers go straight to the carat when picking out a stone, rather than considering the other qualities. This is a mistake; if a large stone has imperfections, they are more obvious than they would be on a smaller stone.\nDiamonds are cut in a specific way, intended to create the greatest brilliance, fire, and scintillation. A diamond’s brilliance is the amount of light reflected from the diamond, its fire is the dispersion of light into the colors of the spectrum, and its scintillation is the sparkle created when it is moved.\nIn a diamond that is well-cut light reflects within, from facet to facet, before reflecting back to the eye. In a diamond that is cut too shallow or too deep, the light will leak out of the stone. This affects the stone’s brilliance, fire, and scintillation.\nEvery diamond is different, and it is the diamond cutter’s job to make the most of each stone. If a diamond is not an ideal cut, it doesn’t mean the cutter did a bad job. Rather, the stone may have been cut to highlight other qualities; to maximize the carat weight, for example.\nIf a diamond has a fair or poor cut grade, it was likely to cut for size rather than brilliance. Premium and ideal cut diamonds are the most brilliant, though they are usually smaller. Diamonds with a good or very good cut grade are in the middle; in these cuts, the cutter tried to balance the size and cut of the stone.\nEven if they appear glassy and clear, most diamonds have a yellow tinge. The amount of yellow in the stone is measured by color grade.\nColor grades range from D to Z, with D being colorless and Z being the most yellow. The color grade of a diamond is measured by comparing it to a stone with a known color graded under controlled lighting conditions.\nMost jewelry stores carry only colorless and near-colorless stones. Colorless diamonds are much more expensive. Near colorless diamonds do not appear yellow to the naked eye, and are much cheaper than colorless stones.\nThe stone’s setting should also be considered when choosing a color grade. When choosing the color grade of your diamond you might also want to consider the setting. The color is most apparent when set in platinum, white gold or silver. If a diamond is set in yellow gold, the color grade becomes less important. The reason for this is because your eyes would be seeing a strong yellow color setting, it will play a psychological role on the diamond making it appear whiter than it is.\nMost diamonds have inclusions (internal flaws) and blemishes (surface imperfections). The more imperfections a stone has, the lower its clarity grade. A diamond’s clarity is graded on a scale from flawless (FL) to imperfect (I3).\nA diamond’s clarity grade is determined under 10X magnification with a device called a loupe. With the exception of imperfect diamonds, the blemishes and inclusions are only available under this device. For this reason, many consumers find the clarity grade to be the least important of the 4 C’s – as long as the stone is not I1, I2 or I3. Most jewelers do not carry stones with these imperfect clarity grades.\nMy Final Tips:\nGet the best color you can afford because your eyes can see color. For clarity get an SI2 clarity grade as these diamonds are considered eye-clean. (GIA states that imperfections can not be seen with the naked eye until this clarity level).', 'If you’re asking, “What is the most important C?”, chances are you’re already well into the process of purchasing a diamond engagement ring. When it comes to diamond quality, the answer is simple, but not necessarily straightforward.\n“Which is the most important of the 4Cs?” – well, it depends. It depends on your taste and budget, and what you and your partner deem most important. Like buying a car, a house, or anything else, your choices when buying a diamond will be determined by your budget. The goal is to get the best diamond quality you can afford. But there will be trade offs. Knowing your preferences is the first step in defining what’s most important to you, and where you’ll compromise. So, what are your diamond priorities?\nIs Diamond Size Important?\nDiamond size is measured in carat weight. Small differences in carat weight can sometimes mean price differences of hundreds—even thousands—of dollars, depending on the size and overall diamond quality.\nIf the appearance of size is important, you can create the illusion of size by picking the right diamond shape. Fancy shapes tend to look bigger for their carat weight, especially elongated shapes such as a ovals, rectangles, and marquise. An engagement ring with a narrow band and a bezel or halo setting can also accentuate a diamond’s size.\nIf size were the only thing that mattered, you could, theoretically, buy a five-carat diamond for a few dollars. Of course, it would not be gem quality. It would be so heavily included that you couldn’t see through it, and its color might be brown or gray. Its cut quality would be irrelevant, since light doesn’t pass through it at all. The diamond would certainly be big, but friends, family, and your fiancée might be hard pressed to recognize it as diamond.\nThat’s why it’s important to know that carat weight alone isn’t everything. Diamond quality is determined by a combination of all the 4Cs.\nIs Diamond Color Important?\nSubtle differences in diamond color can dramatically affect diamond value. Two diamonds of the same clarity, weight, shape and cutting style can differ in value based on color alone. Even the slightest hint of color can make a difference in what you may pay for the diamond.\nGIA determines the degree of colorlessness in a diamond by comparing it under controlled lighting and viewing conditions to a set of masterstones of established color grades. The GIA D-to-Z diamond color grading scale, or diamond color chart, begins with the letter D, representing colorlessness, and continues with increasing presence of color to the letter Z, for light yellow, light brown or light gray. The 23 color grades on the GIA Color Scale are subdivided into five subcategories: colorless (D-F); near colorless (G-J); faint (K-M); very light (N-R); and light (S-Z). Each letter grade has a clearly defined narrow range of color appearance.\nThe more colorless the diamond, the more rare it is, which is why you’ll spend top dollar on a D-color diamond. Once set in a mounting and worn on a hand or dangling from an ear, it’s less likely that you can easily see the difference between a D and G color diamond.\nAs you shop, look at diamonds with different color grades. You might be surprised at the range of color that you find acceptable. You might find (as some do) that a diamond with a little color (J or K for example) has some warmth that you like.\nRemember that a diamond is made up of tiny reflective surfaces, so its color appearance will be influenced by its surroundings. This includes natural and artificial light, the color of the clothing you’re wearing, and even the color of the metal in which the diamond is set. White metals, like platinum, can accentuate diamonds with higher color grades of H and better. At about J, K, or L, the contrast starts to become noticeable if the metal is very white (platinum). The slightly yellowish body color of diamonds with a lower color grade is less noticeable when they are set in yellow gold.\nIs Diamond Clarity Important?\nFlawless diamonds are so rare that it’s possible to spend a lifetime in the jewelry industry without ever seeing one. At the other end of the diamond clarity scale are diamonds with inclusions that can be easily seen by the unaided eye. Between the two extremes are diamonds with inclusions visible only under 10× magnification. Stones in this middle range make up the bulk of the retail market.\nDo you wander through the day carrying a 10× jewelers’ loupe examining people’s diamonds? No one else does either.\nThe GIA Clarity Scale, or diamond clarity chart, has 11 clarity grades: Flawless (FL), Internally Flawless (IF), two categories of Very, Very Slightly Included (VVS), two categories of Very Slightly Included (VS), two categories of Slightly Included (SI), and three categories of Included (I). A diamond’s clarity grade is determined by the size, number, position, nature, and color or relief of any inclusions or blemishes.\nA diamond with no inclusions visible under 10× magnification, is graded IF: the very rare end of the clarity scale and therefore the priciest. As you move down the scale, it’s unlikely you’ll see the very tiny inclusions of a VS2 or SI1 diamond. And unless examined closely, some people won’t even notice the inclusions of an I1 diamond.\nLook at diamonds with different clarity grades to narrow down your preferences. Note where surface reaching blemishes are located. If you have your heart set on an emerald cut diamond, you may want to consider the highest clarity grade you can afford, since the traditional step-cut faceting style tends to make inclusions more obvious in lower clarity diamonds.\nIs Diamond Cut Important?\nEvery diamond quality factor matters to someone. If you’re looking for sparkle and those unmistakable flashes of color and light that telegraph “diamond” across a crowded room, then a diamond’s cut quality is very important.\nThis diamond quality factor refers to how skillfully the diamond was cut. A diamond’s cut grade represents a range of proportion sets and diamond appearances – all of which combine to deliver the magnificent return of light that’s only possible with a diamond.\nGIA developed the cut grading system for standard round brilliant cut diamonds based on thousands of observations of actual diamonds by jewelers and consumers like you. While the GIA Cut Grading Scale contains five grades going from Excellent to Poor, it’s important to keep in mind that each grade represents a range. Diamonds with different face-up appearances may have the same cut grade. And because the grades were established by determining what most people preferred in each range, a given cut grade may not necessarily deliver the diamond that you prefer.\nake your time in finding your preference. As with color, a diamond’s highly reflective surface causes light to affect its face-up appearance. Look at diamonds in three different kinds of light:\n- Diffused lighting: common in many offices, the overhead light source is generally white with no spots of bright light. You don’t see many flashes of color (fire) in the diamond under this type of lighting, but you can easily see a pattern of light and dark areas caused by reflections within the diamond (scintillation).\n- Spot lighting: this is becoming more common as people adopt LED light sources and ubiquitous in jewelry stores. You will see lots of fire, obscuring the pattern you saw in diffused light. Direct sunlight, the most common lighting condition is a form of spot lighting—one single spot source. Make sure to view the diamond outside to make sure that it “performs” as you expect it to.\n- Combination of spot and diffused lighting: you should still see the pattern in the diamond easily, with the addition of fire. This env is often the most pleasing overall.\nAs with color and clarity, the higher the cut grade, the more expensive the diamond when all other factors are the same.\nThe Most Important Diamond Quality Factor of All\nNow that you’ve taken the time to figure out your diamond priorities, there’s one more factor to consider: cleanliness. A diamond is like a collection of tiny mirrors reflecting light and its surroundings. Its color, clarity, and cut will matter little if the diamond is dirty. You will need to keep your diamond clean (free from oil and dirt) if you want it to sparkle as much as it did when you first saw it.\nReady to start looking at diamonds? Before you head into a jewelry store, brush up on the lingo with this guide to common engagement ring terms and make your shopping a little easier.']	['<urn:uuid:f6ab53b7-0815-41f5-a05e-8c1736127d8e>', '<urn:uuid:a882eca3-065f-40de-a9ad-411d9c286a96>']	factoid	direct	concise-and-natural	distant-from-document	multi-aspect	novice	2025-05-12T22:49:38.933606	8	80	2175
58	As someone who's worked extensively in both religious and tax matters, I'm curious about the practice privileges - are both priests and United States Tax Court Practitioners limited in what they can practice and advise on?	Yes, both priests and United States Tax Court Practitioners (USTCP) have specific limitations on their practice areas, though in different ways. Priests are authorized specifically to carry out Christian ministry and perform religious/pastoral duties. Similarly, USTCP counsels are limited strictly to the practice and advisement of tax law and cannot practice or provide advisement in any other area of law. This contrasts with regular attorneys who can practice in multiple areas like family law, real estate law, business law, civil law, criminal law, and others.	"['- a person ordained to the sacerdotal or pastoral office; a member of the clergy; minister.\n- (in hierarchical churches) a member of the clergy of the order next below that of bishop, authorized to carry out the Christian ministry.\nverb (used with object)\nLEARN THE SPANISH WORDS FOR THESE COMMON ANIMALS!\nOrigin of priest\nOTHER WORDS FROM priest\nWords nearby priest\nExample sentences from the Web for priest\nAfter abandoning his training as a priest, he spent the rest of his life reading voraciously.Did Stalin’s rise to power foretell the butchery that came next?|Robert Service|October 30, 2020|Washington Post\nInitially, I and another parishioner helped our priest record services ahead of time that would be uploaded on the church’s YouTube page for Sunday morning.How a funeral inspired the pandemic’s hottest hardware|Daniel Bentley|October 18, 2020|Fortune\nThose days that I had to go to various priests for deliverance and guidance.How Young, Queer Nigerians Use Twitter To Shape Identity And Fight Homophobia|LGBTQ-Editor|October 14, 2020|No Straight News\nKolfage has unleashed his growing army of followers on critics and opponents of those projects, including local elected and wildlife refuge officials and a priest.\nHe and the other priests at his observatory were particularly adept at reading the clouds for storm intensity and trajectory, and he tried to warn Texans about the incoming threat.\nHe speaks with the authority of a native of this land as well as the authority of priest.\nThe priest for the Creole ceremony was Father Marcel Saint Jean.\nAnd he is to give this permission only to a priest “who has piety, knowledge, prudence and integrity of life.”Pope Francis Gives Blessing to Exorcist Conference|Barbie Latza Nadeau|October 29, 2014|DAILY BEAST\nTellingly, Rieux finds common ground with every character except the priest.\nHe concentrates on a handful of characters that includes a doctor, a bureaucrat, a criminal, a priest, and a journalist.\nHun answered that the infant had no propertie in the shet, wherupon the priest ascited him in the spiritual courte.\n""The devil is strong in them,"" exclaimed a distant voice, which appeared to be that of a priest.\nIn some places it is common for the same ring to be used for many marriages, which ring remains in the custody of the priest.Finger-Ring Lore|William Jones\nThe next time we saw my uncle, the priest\'s reasonings had prevailed.Devereux, Complete|Edward Bulwer-Lytton\nThe priest, to whom she had confessed, could not be forgiven for having doubted whether she were a good Christian.The Life of Joan of Arc, Vol. 1 and 2 (of 2)|Anatole France\nBritish Dictionary definitions for priest\nOther words from priestRelated adjective: hieratic\nDerived forms of priestpriestlike, adjective\nWord Origin for priest\nCultural definitions for priest\nOne who is designated an authority on religious matters. In some churches, especially the Anglican Communion, Eastern Orthodox Church, and Roman Catholic Church, the ordained church leader who serves a congregation of believers is called a priest. The priests in these churches administer the sacraments, preach, and care for the needs of their congregations. (See also minister and pastor.)', 'UNDERSTANDING TAX PROFESSIONALS CREDENTIALS\nWhat are the differences between EAs and CPAs?\nEnrolled Agents are specialized tax professionals federally licensed by the U.S. Treasury Department.\nEnrolled Agent status is the highest credential the IRS awards.\nEAs are governed by the Internal Revenue Service Office of Professional Responsibility with strict adherence to the rules and regulations of the Treasury Department Circular 230, Title 31 Code of Federal Regulations, Subtitle A, Part 10 that are the Regulations Governing Practice Before the Internal Revenue Service.\nEAs generally have completed undergraduate studies in business management, accounting or other specialized fields. Many EAs have graduate-level master’s degrees in taxation.\nTo meet the enhanced education criteria necessary, EAs complete extensive study exclusively in taxation and pass a three-part Special Enrollment Examination (SEE).\nAll three parts of the Special Enrollment Examination includes questions in the areas of taxation and ethics:\n- Individuals Taxation\n- Business Taxation\n- Representation Practices and Procedures\nThe education necessary to pass the three-part examination questions includes:\n- Individuals Taxable Income and Tax-Exempt Income\n- Preliminary Work and Taxpayer Data\n- Individuals Assets\n- Deductions and Credits\n- Taxation and Advice\n- Estate and Trust Taxation\n- Gift Taxation\n- Foreign Income Reporting Requirements\n- Business Entities Formation (Sole Proprietorships, Partnerships, Corporations and S Corporations)\n- Business Financial Information\n- Business Income\n- Business Expenses\n- Business Deductions and Credits\n- Business Compensation For Officers and Employees\n- Worker Classification\n- Business Payroll Tax Liabilities\n- Business Inventory\n- Business Assets Depreciation and Dispositions,\n- Analysis of Financial Records,\n- Advisement For The Business Taxpayer\n- Exempt Organizations Qualifications\n- EO Maintaining Tax Exempt Status\n- EO Income and Expense Reporting Requirements\n- EO Unrelated Business Taxable Income\n- Retirement Plans Contributions\n- Retirement Plans Distributions\n- Retirement Plans Prohibited Transactions\n- Qualified and Non-qualified Plans\n- Representation Practices and Procedures\n- Due Diligence Requirements\n- Conflicts of Interest\n- Standards For Written Advice\n- Covered Opinions and Tax Return Positions\n- Sanctionable Acts\n- Information Shared With Taxpayer\n- Records Maintenance\n- Rules and Penalties\n- Identification of Tax Issues With Supporting Details\n- Supporting Documentation\n- Taxpayer Financial Situations\n- Potential Criminal Aspects\n- Competence and Expertise\n- Power of Attorney and Declaration of Representative\n- Representing Taxpayer In Audit/Examination\n- Representing Taxpayer Before Appeals\n- Representing Taxpayer In The Collection Process\n- Collection Alternatives and Settlement\n- Data Security and Protection of Taxpayer Information\nEnrolled Agents must also meet good moral and ethical character standards for licensing and renewal to continue their privilege of Unlimited Rights to Represent Taxpayers Before the Internal Revenue Service and maintain Continuing Professional Education specifically in areas of:\n- Federal Tax Updates\n- Federal Tax Law\n- Professional Ethics\nAn Enrolled Agent credential may also be earned as a former employee of the Internal Revenue Service.\nOnly Enrolled Agents, Certified Public Accountants and Attorneys have Unlimited Rights To Practice.\nThis means only these professionals are unrestricted as to which taxpayers they can represent, what types of tax matters they can advise or represent, and which IRS offices they can represent taxpayer clients before.\nClick on the link below to review the Internal Revenue Service information\nClick on the link below to review the U.S. Treasury Department Circular 230\nClick on the link below to review the EA Special Enrollment Exam SEE Part 1 Individuals Tax Topics\nClick on the link below to review the EA Special Enrollment Exam SEE Part 2 Businesses Tax Topics\nClick on the link below to review the EA Special Enrollment Exam SEE Part 3 Representation Practices and Procedures\nAlthough the letters CPA are commonly known by people, most members of the general public do not understand that these letters do not specifically mean the person has specialized current knowledge in taxation, any specialized current expertise in tax laws, tax planning, income tax returns preparation or tax case representation.\nCPAs have generally completed undergraduate study in accounting at a college or university which may include some general coursework in taxation. Some CPAs have graduate-level master’s degrees.\nCPAs must pass the four-part Uniform CPA Examination to be licensed by state boards of accountancy.\nOne part of the Uniform CPA Examination (Regulation -REG) that is ¼ of the examination includes questions in the areas of:\n- Professional Responsibilities\n- Federal Tax Procedures\n- Business Law\n- Federal Taxation of Property Transactions\n- Federal Taxation of Individuals\n- Federal Taxation of Entities\nTo meet State boards of accountancy license and renewal requirements, CPAs also are required to meet experience, good character standards, peer review and maintain specified levels of Continuing Professional Education.\nEach state’s requirements for Continuing Professional Education vary.\nThe State of Texas does not have any specified requirement for Continuing Professional Education in taxation.\nCPE in the areas of taxation is at the option of the CPA.\nAs listed in the State of Texas Administrative Code, Continuing Professional Education for a CPA may include technical courses in:\n- Management advisory service\n- Computer information technology\n- Regulatory ethics\n- or other areas of benefit to the licensee or their employer\nAs listed in the State of Texas Administrative Code, Continuing Professional Education for a CPA may include non-technical courses in:\n- Computer software\n- Behavioral ethics or science\n- Business management and organization\n- Advanced foreign languages\nTo determine if the CPA you are working with has current Continuing Professional Education and knowledge in the specialized area of taxation, it is in your best interest to specifically ask to see their Certificates of Continuing Professional Education courses in taxation including Annual Federal Tax Updates, Federal Taxation, Business Tax Matters, Individuals Tax Matters, Estates and Trusts Tax Matters.\nWe would be happy to show you ours.\nClick on the link below to review the continuing professional education requirements specified in the Texas Administrative Code\nClick on the link below to review the Internal Revenue Service information\nClick on the link below to review the Uniform CPA Exam parts topics\nWhat are the differences between a State Bar Licensed Attorney and a United States Tax Court Practitioner counsel?\nAttorneys have extensive education in various practice areas of law and have passed a rigorous bar examination administered by their state for admission to the State Bar.\nAttorneys may also be admitted to practice by other state or federal courts.\nThey have a general right to practice in their choice of law or specialty. They are unrestricted and can practice in a single area or multiple areas such as family law, real estate law, business law, civil law, criminal law, tax law, tax planning, tax preparation or a variety of other specialty areas.\nAttorneys who choose to represent taxpayers before the United States Tax Court are only required to pay a separate nominal fee to the court for admission to the U.S. Tax Court Bar if they hold an active State Bar license that is active and they are deemed in good standing.\nFor license renewal, attorneys similarly are required to participate in extensive Continuing Legal Education for credits that vary per state.\nUnited States Tax Court Practitioner counsels are admitted to the U.S. Tax Court Bar by means of passing a rigorous examination administered by United States Tax Court in Washington, DC bi-annually in even-numbered years.\nThe examination candidates eligible to sit for the examination are Enrolled Agents, Certified Public Accountants and other professional types.\nThe examination is a four-part, four hour written essay type examination covering topics of:\n- Tax Court Rules of Practice and Procedure\n- Substantive Tax Law\n- Federal Rules of Evidence\n- American Bar Association Model Rules of Professional Conduct\nEach examination part must be passed with a score of 70% or higher.\nThe examination is extremely challenging for even the most knowledgeable tax experts. The passing rate is extremely low.\n2000 16.67% 17 Passed of 102 Exam Candidates\n2002 14.89% 7 Passed of 47 Exam Candidates\n2004 5.56% 4 Passed of 72 Exam Candidates\n2006 10.34% 6 Passed of 58 Exam Candidates\n2008 14.81% 8 Passed of 54 Exam Candidates\n2010 9.64% 8 Passed of 83 Exam Candidates\n2012 14.29% 11 Passed of 77 Exam Candidates\n2014 18.25% 23 Passed of 126 Exam Candidates\n2016 13.45% 16 Passed of 119 Exam Candidates\nUpon passing an examination candidate must also meet strict moral, ethical and professional character expectations of the court and be sponsored by at least two persons admitted to practice as members of the U.S. Tax Court Bar.\nUnited States Tax Court Practitioner (USTCP) counsels must maintain extensive Continuing Professional Education in the areas of taxation and Continuing Legal Education in the areas of law.\nA United States Tax Court Practitioner (USTCP) counsel is limited to the practice and advisement of tax law and cannot practice or provide advisement in any other area of law.\nClick on the link below to review the criteria for the U.S. Tax Court Non-Attorney Examination\nClick on the link below to review the U.S. Tax Court Non-Attorney Examination Statistical Information Numbers Who Passed\nMy CPA (or EA) told me they can take my case to Tax Court, can they?\nThis is a significant problem.\nThe immediate answer is NO! Unless that CPA or EA has also been admitted to the United States Tax Court Bar.\nUnderstand that only State licensed attorneys who are also admitted to the U.S. Tax Court Bar or United States Tax Court Practitioner’s who are also admitted the U.S. Tax Court Bar can legally petition your case to Tax Court and directly represent you!\nThese professionals must sign the petition and list their U.S. Tax Court Bar Number.\nThis fact is of substantial importance for taxpayers!\nA tax professional with the designations as Unenrolled Preparer, a preparer with the former registration designation (RTRP), a preparer with current tax year approval (AFSP), an Enrolled Agent (EA) or a Certified Public Accountant (CPA) whom is NOT admitted to the U.S. Tax Court Bar CANNOT directly represent your tax controversy case before the judges of United States Tax Court.\nKnow that these designated professionals do not possess the qualifications or knowledge necessary of the procedural rules of the court, rules of evidence or rules of ethics to adequately represent a taxpayer before the court.\nKnow that any advisement received from any of these persons is the unauthorized practice of tax law.\nThey do not possess the recognized knowledge or qualifications to render proper advisement.\nThey do not have the authority under the law to sign a Tax Court Petition because they do not hold an active bar license in good standing with the court.\nAny Tax Court Petition prepared and filed to the U.S. Tax Court by these designated professionals will be docketed by the court as a Pro Se case. This is the Latin phrase meaning “for oneself” or “on one’s own behalf”.\nThis means that YOU are self-representing before the court.\nSadly, we hear of these circumstances quite often which is a direct compromise of the plaintiff taxpayer’s case when unlicensed persons attempt to advise innocent unknowing taxpayers. This is the Unauthorized Practice of law.\nWhen the unknowing taxpayer’s case actually is heard before the judges of the court, the CPA (or EA) cannot litigate the case, cannot confer with IRS counsel and cannot speak to the judge.\nKnow that generally the Commissioner of the IRS will have at least 2, and sometimes more, attorneys on the case.\nYou need the knowledge and experience of a properly licensed professional to advocate on your behalf.\nWhy do they say they can do something that they can’t really do?\nBecause you, the innocent taxpayer, doesn’t know any different. You have trusted that they have the knowledge and did not verify otherwise.\nThe second reason is that they are “banking” on the fact that the IRS Office of Appeals retains jurisdiction on Small Tax Cases up to the time of trial and retains jurisdiction on Regular Tax Cases for the first six months after the petitioned case is docketed for trial. During this period, the court may remand a case back to IRS Appeals that either was not previously subject to an Office of Appeals review or the court may remand a case back to IRS Appeals if the case administrative record is insufficient or incomplete.\nIn these circumstances, the CPA (or EA) is hoping that they can continue to advocate the case because under their active license they do have Unlimited Rights To Represent taxpayers before the IRS Office of Appeals.\nProblem is not all cases, or all matters of the case, can be resolved within the IRS Office of Appeals and subsequently will necessitate a trial.\nThe other substantial problem is that the CPA (or EA) has no qualified knowledge of the various procedural rules of the court, rules of evidence or trial mechanics, therefore they fail to properly plead all matters as required, fail to file proper motions and fail to complete many other case management requirements.\nIf you need a surgery, anyone can tell you they’ll save you money because they can purchase scalpels at any medical supply store, buy bandages, gauze and surgical tape. This does not make them a surgeon!\nDon’t be confused by the terms “Litigation Support”!\nAlthough the state’s boards of accountancy permit CPAs to advertise and promote “Litigation Support” this does not mean that they can practice law, tax law or represent any taxpayer before the U.S. Tax Court.\nLitigation support is the act of serving as an Expert Witness at trial on matters related to accountancy or the capability to provide assistive information relating to accountancy to a licensed attorney or USTCP.\nThe Taxpayer Advocate Service provides an Annual Report to Congress. This special report includes substantial matters relating to the IRS. In most years the TAS report shows that the IRS prevailed in over 80% of Pro-se cases tried before U.S. Tax Court.\nClick on the link below to read the TAS most recent report to Congress\nIf you are still not convinced that it’s a bad idea to have a CPA petition your case to U.S. Tax Court, we encourage you to click on the link below to read the “blunders” of a case in which the taxpayer was poorly advised from the day of the income tax return preparation to the day of trial and even during trial.\nTax Court Summary Opinion 2017-93\nMARY A. COLLIVER, Petitioner v. COMMISSIONER OF INTERNAL REVENUE, Respondent\nDocket No. 15307-16S. Filed December 26, 2017.\nWith all this being said, is it worth risking tens of thousands of dollars to the IRS to save a few hundred dollars on your tax returns preparation, tax representation case before the Internal Revenue Service or tax litigation before the United States Tax']"	['<urn:uuid:f9b8b42b-d3c3-432d-9b53-9f1bf6fdc33f>', '<urn:uuid:50d0c07f-db24-4f81-a3fe-36bdea2f6c1c>']	open-ended	with-premise	verbose-and-natural	similar-to-document	comparison	expert	2025-05-12T22:49:38.933606	36	85	2958
59	rest duration after preshaping bread dough before final shaping begins	After pre-shaping, the dough needs to rest for 10 to 20 minutes. This short rest relaxes the dough and makes final shaping easier.	['Once your dough has risen, it will feel slightly billowy and much more extensible than when you first mixed it. The dough is now ready to move on to the next step – dividing. This recipe will yield two large loaves, three medium-sized loaves, or four small loaves. Just keep in mind the size of your oven and how much time you have to bake before dividing. Also, shaping a wet dough like this is particularly hard. You will get frustrated. This skill is acquired only through practice, but having the right tools helps abundantly.\nTo start, lightly flour a large, smooth area with white flour. Using a wet, plastic dough scraper, pull all of your dough onto the floured surface. Lightly flour the top of the dough. Using a bench knife, go around the perimeter of the dough and lightly scrape under the edges of the dough. The goal is to get the dough into an evenish circle. This will help in portioning the dough.\nTake your bench knife and cleanly cut down the middle of the dough. If you plan on baking two loaves, then you are ready for pre-shaping. Portioning three pieces is a little more difficult. After you get the dough into a circle, take your bench knife and cut halfway down the middle of the dough. From here, you’ll have to eyeball it. Cut diagonally on each side so that you have three equal pieces. Don’t fret if they’re not perfect. You can cut a little piece of dough off a bigger one and add it to a smaller piece. Once you’re satisfied, you can begin pre-shaping. Portioning four pieces is a cinch. Cleanly cut down the middle of the dough and cut each half in half.\nOnce you have divided your dough into however many loaves you want, you are ready for pre-shaping. This step transforms the random pieces of dough into more workable shapes. The desired action is a light rounding; quickness and floured hands are your best allies. Clear an area that will hold your preshaped doughs about 2 inches apart and lightly flour it. On a lightly floured surfaced with floured hands, take a piece of dough and fold the edges into the middle. Try to incorporate as little flour into the dough as possible. Turn the dough over. The next technique executes two actions at the same time: use your fingers (mainly pinkys) to tuck the back of the dough in on itself while pulling the dough towards you. Turn the dough a quarter turn and repeat. Be careful not to tear the dough. Repeat this action until the dough takes on a rounded form, and don’t worry if the seem won’t close on the bottom of the loaf. If the dough seems too wet and sticks to your hands while pre-shaping, use your dough knife in place of your fingers when tucking the dough in on itself. That should do the trick. Place the pre-shaped dough seam side up (upside down) on your pre-floured surface. Continue pre-shaping the other loaves and place them all seam side up, about 2 inches apart. Lightly flour the loaves and cover with a kitchen towel or old t-shirt.\nNow that the loaves have been pre-shaped, they will need to rest for 10 to 20 minutes. This short rest relaxes the dough and makes final shaping easier. This is a good time to wash up and get your baskets ready for proofing. To assess when your dough is ready for final shaping, look to see if it has spread out, yet retained a round edge. Give it a poke with your finger. It should slowly spring back. If not, give it another 5 minutes.\nGather your baskets or bowls for proofing. Place a kitchen towel or old t-shirt in the bowl and heavily flour it. The final shaping involves a series of folds. The goal is a formed round with a tight “skin.” Proper shaping results in a more dramatic rise and decorative crust when scored.\nVery lightly flour your work surface. It is better to have floured hands and floured dough than a floured surface. Take a preshaped round and put it seam side up on the work surface. Grab it at the top and bottom and pull into a rectangular shape, being careful not the tear the dough. Fold the bottom of the dough 2/3rds of the way up. Next, grab the right side of the dough and stretch it out until you feel tension. Fold this flap 2/3rds of the way to the left side of the dough. Grab the left side of the dough and pull until you feel tension. Fold this flap 2/3rds of the way to the right side of the dough. Grab the top of the dough and pull up until you feel tension. Fold this flap down until it covers the top of the dough. You should be left with a nice, neat package. The remaining movements are the same as in the preshaping. Being careful not to expel any gas, pull the dough towards you while tucking the back of the dough in on itself. Continue until you have a tight ball. Place the shaped dough seam side up (upside down) in the floured basket or bowl. Flour the dough lightly and cover with the edges of the towel or shirt.\nProofing is the phase between shaping and loading the dough into the oven. Time is the biggest influence at this point. After about 2 hours, your bread will be ready to bake. This will produce a mildly acidic bread, and it is a pleasure to eat. Or you can choose to delay the bake overnight. This is known as retarding, and the long fermentation will result in a more flavorful, complex bread. To retard, just put the shaped dough into the refrigerator, basket and all. In the morning, take the loaves out of the refrigerator right before you load them into the oven. The only hazard in retarding is overproofing, which can result in a sunken loaf with a poor crust. Retard your bread for a maximum of 8-12 hours, and you’ll be good.\nAs you can see, this is a lot of work in a short amount of time. Part of being a successful baker is being efficient in your movements. Don’t expect to get it right in your initial attempts. As you develop a feel for the dough, your motions will become more fluid and purposeful. It just takes practice.\nThe last page will cover scoring and baking. Please leave me a comment if you have any questions or need clarification (or encouragement!).']	['<urn:uuid:137a864a-9ffd-4fb6-b3ac-b609931414c2>']	factoid	direct	long-search-query	distant-from-document	single-doc	expert	2025-05-12T22:49:38.933606	10	23	1111
60	I'm concerned about food safety and health - what are the main differences between pesticide use in organic farming compared to conventional farming, especially regarding their effects on human health?	Organic and conventional farming have very different approaches to pesticide use with distinct health implications. Conventional farming uses harsh synthetic pesticides that have raised health concerns - for example, long-term exposure to chemicals like Roundup weedkiller has been linked to increased cancer risk according to the WHO. Organic farming certified by the USDA prohibits these harsh chemical pesticides. However, organic farming does allow some 'organic' pesticides like copper and sulfur, which are used at rates of 4 and 34 pounds per acre respectively. While these organic pesticides can still impact environment and health, organic produce overall contains fewer harmful chemical residues. The USDA has strict guidelines that organic farms must follow to earn certification and ensure their produce is free from harsh chemical effects.	['Whether you purchase your vegetables from an organic vegetable farm, or if you wish to try your hand at your own organic vegetable garden, everyone agrees that organic vegetables are healthier, heartier, and better for you\nTo receive the USDA Organic Seal, vegetables grown organically will be free of the use of harsh chemicals and pesticides. In fact,\norganic farms rely on many methods that produce strong, disease and pest resistant plants. By using these types of natural methods\nfor farming, the overall result is produce that is free from the\nharmful effects of harsh chemicals.\nOrganic vegetables are not only better for you, but they are better\nfor the earth. The United States Department of Agriculture has strict\nguidelines that a farm must follow if they want their produce to bear the official Organic Seal. These farms not only restrict the\nuse of pesticides and other chemicals, they also utilize farming\nmethods that help restore the balance of the soil. However, you\ndon’t have to be a farmer inspected by the USDA to grown organic\nvegetables. Every homeowner or gardener can grow their vegetables\norganically by incorporating a few simple steps.\nFirst, it is important to change the way you think about gardening.\nThe main areas where you will need to implement changes to ensure\nyour garden is organic are the areas of fertilization as well as\nWhen choosing a fertilizer for your organic garden you will want\nto choose natural methods. It is a good idea to add organic fertilizer\nand matter to your soil at least three weeks before you begin planting\nyour vegetables. This will ensure that the matter has had plenty\nof time to decompose and release its nutrients into the soil. Some\nof the organic matter that you will want to consider using includes:\n· Animal Manure\n· Mixed Organic Fertilizer\nOrganic fertilizers improve the condition of your soil before you\nbegin to plant your vegetable garden. It also helps the soil with\nthe ability to retain nutrients and water. When the soil is improved,\nyour vegetables will grow stronger and they will be more resilient.\nAnimal manure also makes an excellent organic fertilizer. These\nmanures include cow, horse, hog, poultry, sheep, rabbit, goat, and\nother grass-eating animals. Fertilizing with manure is a wonderful\nway to maintain the health and vitality of your vegetable garden,\nhowever it may be necessary to add potash or ground rock phosphate\nto your fertilizer to ensure that it has all of the proper nutrients\nComposting is a great way to create organic fertilizer. Adding\norganic materials to your compost pile will ensure that you have\nenough organic fertilizer to maintain your vegetable garden. You\ncan add just about any thing that is organic to your compost pile.\nSome of the most common items added to the compost pile include\nleaves, banana peels, corn stalks, rotten eggs, coffee grounds,\nfruit peels, lawn and shrub clippings, and oak leaves. You can use\ncompost in the same manner as you would use animal manure. It is\na good idea to use your compost at least three weeks before you\nbegin planting your vegetable garden. By using organic fertilizers\nyou can ensure that your vegetable garden will flourish.', 'Organic food is a big growth area for consumer demand. Once thought to be the preserve of the wealthy or eco-eccentrics, organic food is going mainstream with many people from across the spectrum wishing to purchase organic food.\nOrganic farming avoids the use of artificial fertilisers and pesticides but relies on more traditional methods of fertilisation and pest control, such as crop rotation, barrier nets and natural pest control.\nDespite the demand for organic food growing strongly, In the US only 0.7% of farms are organic (2012 census). It means that for organic food, the US (and UK) are reliant on food imports.\nThis increase in demand greater than supply is helping organic food to be more profitable.\nAdvantages of organic farming\nMinimises the external cost of farming. The use of artificial pesticides and fertilisers can have side effects to the local environment. For example, there are concerns about a decline in the bee population, due to the increased use of toxic pesticides.\n“America’s agricultural landscape is now 48 times more toxic to honeybees, and likely other insects, than it was 25 years ago, almost entirely due to widespread use of so-called neonicotinoid pesticides”(6 Aug, 2019, Nat. Geographic)\nBees are vital to the well-being of the planet’s ecosystem. Organic farming helps bees and insects by not using pesticides and providing more pollen from land which isn’t kept as monoculture. The neotoxins currently used can stay in the environment for 1,000 days and are proving very damaging to insect population.\nEfficient use of resources. A principle of organic farming is to recycle resources. Rather than importing chemical fertilisers from abroad, organic farming seek to improve the soil through crop rotation, the use of animal manure, compost and natural byproducts.\nSoil and the environment is a public good. There is concern that conventional farming methods are steadily eroding the quality of soil. The soil is never rotated or given a chance to re-incorporate organic matter. As a result, farmers become more reliant on fertilisers and ever-heavier mechanical rotation to provide nutrition. A lack of organic matter also makes the soil more prone to drought. Conventional farming ignores the long-term impact on soil quality and is storing problems for future generations. Organic farming provides a long-term solution to soil management. It is estimated a third of the world’s global soil is now degraded.\nThe JRC noted that decreasing productivity can be observed on 20% of the world’s cropland, 16% of forest land, 19% of grassland, and 27% of rangeland.\n“Industrial agriculture is good at feeding populations but it is not sustainable. It’s like an extractive industry, said Louise Baker, external relations head of the UN body.Guardian Sep 2017\nHealthier food. Organic food grown in richer more organic soils has higher levels of micronutrients.\nHigher levels of total protein and higher levels of 8 out of 13 essential minerals analyzed—including magnesium, zinc, phosphorus, and potassium—than conventional oats\nA study claimed the yield was up to 40% more in times of droughtRodaleinstitute, 2018\nAlso, there is a link between some chemicals and increased cancer risk for humans. Long-term exposure to chemicals, such as ‘Roundup weedkiller’ show a link to increased cancer risk. Organic veg reduces the long-term risk of repeated exposure to these chemicals. (WHO – glyphosate probably cancerous to humans)\nHealthier animals. In conventional farming, animals are often kept in close proximity and fed antibiotics as a matter of course. This mass-use of antibiotics is contributing to increased resistance. In organic farming, antibiotics are only allowed if animals are sick.\nPotential profits. Currently, the demand for organic food is growing faster than supply. Countries like the UK and US have to import organic food from abroad. (often developing economies) Some organic methods are more costly (labour-intensive weeding) but also some costs are saved (cost of chemicals)\n“Overall, organic farms tend to have better soil quality and reduce soil erosion compared to their conventional counterparts. Organic agriculture generally creates less soil and water pollution and lower greenhouse gas emissions, and is more energy efficient. Organic agriculture is also associated with greater biodiversity of plants, animals, insects and microbes, as well as genetic diversity.”Professor Reganold\nCons of organic farming\nTime involved. Converting to organic farming takes three years and requires expensive scrutiny and regulation to prove the farm is meeting organic standards. The drawback is that during this period, the farmer cannot sell goods as organic, so they have the higher costs, but not the higher prices.\nMore labour intensive. Aspects of organic farming are more labour-intensive, weeding by hand. Less dense methods of animal farming. As a result farmers have greater costs.\nPotential loss of crops. Could lose crops to pest/disease that cannot be dealt with by organic methods.\nOrganic pesticides. Organic still involves some ‘organic’ pesticides. In the US, organic farmers are allowed to spray ‘organic’ pesticides – including copper and sulfur. On organic farms, the quantity of pesticide is not monitored.\nAccording to the National Center for Food and Agricultural Policy, The two organic fungicides, copper and sulfur, were used at a rate of 4 and 34 pounds per acre in 1971.American Scientific (2011)\nThese organic pesticides are not trouble-free and can damage both the environment and health.\nSupermarkets profit more than farmers. The price mark-up on organic farming is mostly gained by the supermarket. Profit margins for supermarkets on organic fruit and veg is 96% higher than conventional products. Whilst organic food is more expensive, the price difference does not lead to higher revenue for farmers. A French study found: “Only half of the price difference between organic and non-organic food finds its way back to farmers.” (Euractiv, Sep 2017.)\nDecline in crop yields. Crop yields can be up to 20% less than none organic farms. There is a concern that if all farmland was converted to organic it would reduce food supply and increase prices.']	['<urn:uuid:4ce56b5a-2fd6-46c6-b5d1-341889fa1339>', '<urn:uuid:7104acf2-54f9-4759-8541-73f522ecff23>']	open-ended	with-premise	verbose-and-natural	similar-to-document	comparison	novice	2025-05-12T22:49:38.933606	30	124	1510
61	Are Hindu divorce laws and Dana principles focused on the same concept of charity?	No, they are different concepts. Hindu divorce is regulated by the Hindu Marriage Act of 1955 which allows divorce for reasons like infidelity and cruelty, while Dana refers to the universal virtue of charitable giving that brings joy to the giver, as illustrated in Hindu scriptures through stories like the Rainbow Fish.	['Due to the fact Jewish couples signal a ketubah, otherwise matrimony bargain, when they wed, a legal file less than Jewish rules is necessary to possess splitting up under specific denominations. That’s called a “get,” in addition to cases where it can be given were points regarding infidelity, punishment, otherwise irreconcilable differences. Into the Orthodox Judaism, a religious separation must go through procedures in advance of a great rabbinical court just before an effective “get” is supplied.\nBeginning in India, Hinduism isn’t just one, unitary religion, but, rather, a set of standards sensed a life. There is no one sacred text message such a beneficial Bible or Torah, but some Hindus have confidence in dharma, the religious password that governs your perform and you will obligations.\nDivorce is allowed in Hinduism, but it appears to be unusual in that faith in comparison to anybody else. And since Hinduism considers ent and life-long promise made in the presence of several gods, divorce was never an option. However, the Hindu Marriage Act of 1955 in India allowed divorce under certain conditions, including infidelity, abandonment, cruelty, and absence of communication, among other reasons.\nIslam, the world’s 2nd-prominent faith, believes in a single God, Allah, along with his prophet, Muhammad. Muslims believe they need to yield to the will off Allah, and proceed with the Qur’an, its central and you can sacred religious text message. Like many religions, Islam enjoys multiple organizations, also Sunni and Shi’a, and these organizations possess variations.\nLike with many other religions, divorce case PЕ™eДЌГst ДЌlГЎnek is invited when you look at the Islam, however it is believed a last hotel. In reality, the latest Prophet Muhammad apparently told you, “One particular detestable regarding legal some thing before Allah try breakup.” Very, Islamic lovers tends to be motivated to work with its mosque to take care of one distinctions prior to taking steps so you can split up.\nWhen it comes to remarriage, additional rules affect everyone. Variations range from the concept you to definitely men can also be quickly remarry shortly after a legitimate split up whereas a lady should not remarry for a good particular time frame (constantly three months).\nSince Buddhism doesn’t have rigid tenets on the wedding, divorce proceedings is acceptance regarding religion which is open-ended. Splitting up could actually be necessary in the event the an unsatisfied relationship causes be concerned otherwise distress.\nStudies have shown that religious involvement can reduce divorce rates (from the around 14 per cent based on you to). And at least one study reported that people that attended chapel together have been less likely to want to separation and divorce. But that doesn’t make the process any easier or less complicated for those considering going through it.\nAfter all, no matter your religion, divorce can be a touchy subject. Though views on divorce have changed with time, there can be a stigma associated with it that’s hard to shake. Some people undoubtedly worry a divorce will cause judgment or even shame from others in a religious community. Or they might be concerned that it will cause a loss of friends or push them away from their faith. According to the study referenced above, people can experience a drop when you look at the spiritual involvement just after a split up, especially in middle age.\nHowever,, to a lot of, that require maybe not influence how some one browse her relationship demands. Exactly like just how religion was a highly individual decision, separation and divorce was a different thing to each private, no you to definitely-size-fits-every answer. Never assume all people in the same denominations have the same thinking, and viewpoints for the divorce may vary ranging from someone within this a religious class. In addition to, opinions in this religions and you can people fundamentally can also be develop.\nLike of numerous Christian denominations, divorce was invited for the Judaism, even when it is really not advised. Considering antique Jewish rules, only the husband is divorce proceedings their partner, however,, though some Orthodox Jews nonetheless abide by one convinced, very Jewish communities have a tendency to now accommodate a divorce proceedings started by the both a man otherwise a lady.', 'Hindu Scriptures stress on values that are universal and can be cultivated by all. The virtues of Dama- Self Restraint, Dana- Charity or giving and Daya- Compassion can be practiced by all easily. Read on to understand the essence of the 3D’s as they are collectively called in this article.\nSanathan Dharma has always stressed on the cardinal virtues of compassion, charity and self restraint. The values espoused by this religion are universal and is not limited to people of any one age or time. One need not be a Bharathiya or for that matter a Hindu to appreciate the message of the Scriptures. This is perhaps why the great poet T.S. Eliot dedicated an entire section ‘What the Thunder said’ in his magnum opus The Waste Land to an instruction that appeals to humanity.\nThen spoke the thunder\nDatta: what have we given?\nMy friend, blood shaking my heart\nThe awful daring of a moment’s surrender\nWhich an age of prudence can never retract\nBy this, and this only, we have existed\nHere the poet alludes to the wonderful episode in the Brihadaranyaka Upanishad. Three kinds of beings – devas, manushyas and asuras- that is the divine beings, men and the demons lived under the tutelage of their father and Creator Prajapati. At the end of their period of study, each class wanted a specific instruction from their preceptor to which Prajapati uttered the syllable DA. Each took it to mean a different virtue based on their understanding and experience. The devas said they had to observe self restraint and exercise control to which Prajapati the Wise One said “so be it”. It was the turn of the mortal men and they took it to mean Give, Give in Charity wholeheartedly. The Wise One again nodded in approval. Now it was the turn of the demons, they took the syllable DA to represent Compassion or daya. Thus the enigmatic sound DA took on diverse meanings to different classes of beings and all were right in their own way.\nThis allegory could in fact represent the different natures within each one of us the Sathwic, the Rajasic and the Tamasic each represented by the Devas, the Manavas and the Asuras respectively. Viewed in this light the message is very powerful as these three virtues have to be cultivated by us gradually throughout our lives. After all, life is an interplay of emotions and we need to observe control over our indulgences and senses whenever such excesses are seen. Sense control is a personal discipline and our religion stresses on Yama – Ethical Discipline which includes Ahimsa (Non-violence), Satya ( Truthfulness), Brahmacharya (Control of the senses and celibacy) Asteya( Non-stealing) Aparigraha (Non-covetousness)and Niyama – Personal Discipline that includes Saucha (Purity, cleanliness), Santosha (Contentment), Tapas (Austerity), Swadhyaya (Self-study, study of scriptures) Ishwara Pranidhana (Surrender to God’s will).\nSimilarly Charity is a virtue that man has to remember at all times and the act of giving is not aimed at the beneficiary but is in fact a step towards progress for man himself. This message is all the more relevant in this age of crass materialism and the I-ME-MINE culture that has seeped into our lives. The rainbow fish by Marcus Pfister is a beautiful story that brings out the virtue of Giving.\nThe Rainbow Fish is the most beautiful fish in the ocean. His shining scales sparkle and shimmer. The other fish ask him to play with them, but all he wants to do is show off his beauty. One day a little fish asks Rainbow Fish to share one of his scales with him, but Rainbow Fish refuses. His selfishness and greed leave him friendless and sad. A wise octopus advises the lonely fish to give away his beauty, which he reluctantly decides to do. With each scale that Rainbow Fish gives away, he grows happier and happier. The Rainbow Fish learns the importance of sharing and reaps the joy from giving. The giver becomes joyful and happy. A very poignant message indeed.\nThe message sent out to the demonic beings was to show Compassion- another virtue sorely lacking in the world today. Compassion is born out of a heart filled with love and mercy. As the Bard of Avon, Shakespeare puts it\nThe quality of mercy is not strain’d.\nIt droppeth as the gentle rain from heaven\nUpon the place beneath. It is twice blest:\nIt blesseth him that gives, and him that takes.\n‘Tis mightiest in the mightiest; it becomes\nThe throned monarch better than his crown.\nHis scepter shows the force of temporal power,\nThe attribute to awe and majesty,\nWherein doth sit the dread and fear of kings;\nBut mercy is above this sceptered sway;\nIt is enthroned in the heart of kings;\nIt is an attribute to God himself;\nAnd earthly power doth then show likest God’s\nWhen mercy seasons justice.\nToday we find people in various spheres perform their tasks without this vital quality of compassion. Imagine a doctor, a teacher, a parent or for that matter just about anyone in the world go about their tasks devoid of compassion. Not everything can be related to commerce and gain.\nThis particular episode in the Upanishads is thus a powerful message to humanity to cultivate, cherish and nurture these wonderful virtues of Daya, dama and dana. When Bharat Ratna M.S. Subbalakshmi, the Queen of Bhakthi Music was invited to perform at the United Nations on the occasion of its 50th anniversary, she concluded the performance with an Ode to Friendship Maithreem Bhajatha. This prayer was specially written for the occasion by the Saint of Kanchi, Paramacharya Chandrasekharendra Saraswati and dealt with universal brotherhood and peace as enshrined by Sanathana Dharma. The sage brings out the same message that we have seen above when he says\nMaithreem Bhajatha , Akhila Hruth Jethreem,\nAtmavat eva paraan api pashyatha\nYuddham thyajatha , Spardhaam Tyajata ,\nthyajatha Pareshwa akrama aakramanam\nJananee Prthivee Kaamadughaastey\nJanakO Deva: Sakala Dayaalu\nDaamyata Datta Dayathvam Janathaa\nSreyo Bhooyaath Sakala Janaanaam\nSreyo Bhooyaath Sakala Janaanaam\nSreyo Bhooyaath Sakala Janaanaam\nTranslated into English\nWith friendship please serve,\nAnd conquer all the hearts,\nPlease think that others are like you,\nPlease forsake war for ever,\nPlease forsake competition for ever,\nPlease forsake force to get,\nSomeone else’s property,\nFor mother earth yields all our desires,\nAnd God our father is most merciful,\nRestrain, donate and be kind,\nTo all the people of this world\nLet all the people, live with bliss,\nLet all the people live with bliss,\nLet all the people live with bliss.\n“Live and let live”']	['<urn:uuid:e79a99f9-0184-4c47-87f5-69a6215ee177>', '<urn:uuid:0a6426af-2bd6-4b93-bed0-9f2293670470>']	factoid	with-premise	concise-and-natural	distant-from-document	comparison	expert	2025-05-12T22:49:38.933606	14	52	1801
62	taxonomic ranks definition present day usage	Taxonomic ranks represent hierarchical levels in biological classification, with species being the basic rank. The main ranks from highest to lowest are: domain, kingdom, phylum/division, class, order, family, genus, and species. While traditional Linnaean classification used these ranks, modern taxonomy is experiencing significant changes due to cladistic approaches and DNA analysis. Present-day biological classification combines both Linnaean and cladistic principles, leading to ongoing discussions and alternative classifications.	"['In biological classification, rank is the level (the relative position) in a taxonomic hierarchy. Examples of taxonomic ranks are species, genus, family, and class. Each rank subsumes under it a number of less general categories. The rank of species, and specification of the genus to which the species belongs is basic, which means that it may not be necessary to specify ranks other than these. The International Code of Zoological Nomenclature defines rank as:\nThe level, for nomenclatural purposes, of a taxon in a taxonomic hierarchy (e.g. all families are for nomenclatural purposes at the same rank, which lies between superfamily and subfamily)\n""2.1. Every individual plant is treated as belonging to an indefinite number of taxa of consecutively subordinate rank, among which the rank of species (species) is basic.""\nIn his landmark publications, such as the Systema Naturae, Carl Linnaeus used a ranking scale limited to: kingdom, class, order, genus, species, and one lower rank, below species. Today, nomenclature is regulated by the Nomenclature Codes, which allow names divided into an indefinite number of ranks. There are seven main taxonomic ranks: kingdom, phylum or division (see table), class, order, family, genus, species. In addition, the domain (proposed by Carl Woese) is now widely used as one of the fundamental ranks, although it is not mentioned in any of the Nomenclature Codes.\nNotes to table\nA taxon is usually assigned a taxonomic rank (in a hierarchy), usually when it is given its formal name. The basic rank is that of species. The next most important rank is that of genus: if an organism is given a species name it will at the same time be assigned to a genus, as the genus name is part of the species name. The third-most important rank, although it was not used by Linnaeus, is that of family.\nThe species name is sometimes called a binomial (a two-term name). For example, the zoological name for the human species is Homo sapiens: this is usually italicized in print (and underlined when italics are not available). In this case, Homo is the generic name and refers to the genus; it is capitalized; sapiens indicates the species: it is written in lower case.\nRanks in zoology\nThere are definitions of the following taxonomic ranks in the International Code of Zoological Nomenclature: superfamily, family, subfamily, tribe, subtribe, genus, subgenus, species, subspecies.\nThe International Code of Zoological Nomenclature divides names into ""family-group names"", ""genus-group names"" and ""species-group names"". The Code explicitly mentions:\nThe rules in the Code apply to the ranks of superfamily to subspecies, and only to some extent to those above the rank of superfamily. In the ""genus group"" and ""species group"" no further ranks are allowed. Among zoologists, additional terms such as species group, species subgroup, species complex and superspecies are sometimes used for convenience as extra, but unofficial, \'ranks\' between the subgenus and species levels in taxa with many species (e.g., the genus Drosophila).\nAt higher ranks (family and above) a lower level may be denoted by adding the prefix ""infra"", meaning lower, to the rank. For example infraorder (below suborder) or infrafamily (below subfamily).\nNames of zoological taxa\n* A taxon above the rank of species gets a scientific name in one part (a uninominal name)\nThere are definitions of the following taxonomic ranks in the International Code of Botanical Nomenclature: kingdom (regnum), subregnum, division or phylum (divisio, phylum), subdivisio or subphylum, class (classis), subclassis, order (ordo), subordo, family (familia), subfamilia, tribe (tribus), subtribus, genus (genus), subgenus, section (sectio), subsectio, series (series), subseries, species (species), subspecies, variety (varietas), subvarietas, form (forma), subforma.\nThere are definitions of following taxonomic ranks in International Code of Nomenclature for Cultivated Plants: cultivar group, cultivar.\nAccording to Art 3.1 of the ICBN the most important ranks of taxa are: kingdom, division or phylum, class, order, family, genus, and species. According to Art 4.1 the secondary ranks of taxa are tribe, section, series, variety and form. There is an indeterminate number of ranks. The ICBN explicitly mentions:\ndivision or phylum (divisio, phylum)\nThe rules in the ICBN apply primarily to the ranks of family and below, and only to some extent to those above the rank of family. Also see descriptive botanical names.\nNames of botanical taxa\nOf the botanical names used by Linnaeus only names of genera, species and varieties are still used.\nTaxa at the rank of genus and above get a botanical name in one part (unitary name); those at the rank of species and above (but below genus) get a botanical name in two parts (binary name); all taxa below the rank of species get a botanical name in three parts (ternary name).\nFor hybrids getting a hybrid name, the same ranks apply, preceded by ""notho"", with nothogenus as the highest permitted rank. (The hybrid\'s nothotaxon is an alias for a list of all of the taxa which are ancestral to the hybrid.)\nClassifications of five species follow: the fruit fly so familiar in genetics laboratories (Drosophila melanogaster), humans (Homo sapiens), the peas used by Gregor Mendel in his discovery of genetics (Pisum sativum), the ""fly agaric"" mushroom Amanita muscaria, and the bacterium Escherichia coli. The eight major ranks are given in bold; a selection of minor ranks are given as well.\n* The ranks of higher taxa, especially intermediate ranks, are prone to revision as new information about relationships is discovered. For example, the traditional classification of primates (class Mammalia — subclass Theria — infraclass Eutheria — order Primates) has been modified by new classifications such as McKenna and Bell (class Mammalia — subclass Theriformes — infraclass Holotheria) with Theria and Eutheria assigned lower ranks between infraclass and the order Primates. See mammal classification for a discussion. These differences arise because there are only a small number of ranks available and a large number of branching points in the fossil record.\nTaxa above the genus level are often given names based on the type genus, with a standard termination. The terminations used in forming these names depend on the kingdom, and sometimes the phylum and class, as set out in the table below. Pronunciations given are the most Anglicized; more Latinate pronunciations are also common, particularly /ɑː/ rather than /eɪ/ for stressed a.\n* In botany and mycology names at the rank of family and below are based on the name of a genus, sometimes called the type genus of that taxon, with a standard ending. For example, the rose family Rosaceae is named after the genus Rosa, with the standard ending ""-aceae"" for a family. Names above the rank of family are formed from a family name, or are descriptive (like Gymnospermae or Fungi).\nThe following is an artificial synthesis, solely for purposes of demonstration of relative rank (but see notes), from most general to most specific:\nOf these many ranks, the most basic is species. However, this is not to say that a taxon at any other rank may not be sharply defined, or that any species is guaranteed to be sharply defined. It varies from case to case. Ideally, nowadays, a taxon is intended to represent the phylogeny of the organisms under discussion, but in itself this is not a requirement.\n1. ^ International Code of Botanical Nomenclature Online, Vienna Code, 2005, articles 2 and 3\n* Benton, Michael J. 2005. Vertebrate Palaeontology, 3rd ed. Oxford: Blackwell Publishing. ISBN 0-632-05637-1. ISBN 978-0-632-05637-8\nRetrieved from ""http://en.wikipedia.org/""', ""The best-known kind of taxonomy is used for the classification of lifeforms (living and extinct). Each organism has a scientific name. This name is part of the biological classification of that species. The name is the same all over the world, so scientists from different places can understand each other. In addition, a species has a position in the tree of life. Thus the crow is Corvus corone, a member of the Corvidae family, and they are passerine birds. That is well agreed, but the classification of some groups is not agreed at present, and often several classifications are being discussed.\nLiving things are classified into three domains: bacteria, archaea and eukaryotes. The highest rank in a domain is the kingdom. Each kingdom has many smaller groups in it, called phyla. Each phylum has more smaller groups in it, called classes. This pattern looks like branches on a tree with smaller branches growing from them. Each species is put into a group because of what it does, how and what it eats, special body parts, and so on. At the end of the pattern, the groups (genera) are very small. Then each species in the genus is given its own name.\nWhen someone writes about a living thing and its formal scientific name, they write the genus and species name. This is known as binomial nomenclature, because it uses two names for each organism. The first is the genus name, and the second is the species in that genus. The scientific name of the domestic cat is Felis catus. Sometimes it is enough to write F. catus.\nSome mnemonics (sayings to help a person remember something):\n- King Phillip Came Over From Greater Spain\nWhen people started naming species, Latin was a language widely used in Europe. All species names are still written in Latin. This has some advantages. Since Latin is no longer spoken, it is unchanging, and is owned by no-one. It gets over the problem of every language having its own names for animals and plants.\nScientists used to write the official description of each new species in Latin. On 1 January 2012, the International Botanical Congress changed to allow English (as well as Latin) for describing new plant species. The International Code of Zoological Nomenclature recommends choosing a language that is widely used, and that is used in the places where the species lives.\nAn important modern approach to taxonomy is cladism. This approach is based on the branching (tree-like) course of evolution. Like traditional Linnaean classification, it uses traits to decide on the branches of the classification. It insists on groups being monophyletic. This has the effect that birds are not a class but a sub-group of dinosaurs. It also means the ranking system described above would be abolished.\nSo cladism has different principles of taxonomy, and produces a different kind of taxonomy. Decisions, where possible, are supported by DNA sequence analysis. Present-day biological classification is a mixture of the old Linnaean and the modern cladistic principles of taxonomy. In parts, it is changing rapidly. The classifications presented in Wikipedia at present are often a compromise between the two systems. The details are regularly discussed.\nTurmoil in taxonomyEdit\nToday, there are many changes in the classification of living things. This turmoil in taxonomy has led to many alternative classifications. It is caused partly from the move from Linnaean to cladistic principles, and partly by the use of DNA sequence data in taxonomy. An example is: the way derived groups like birds should not be classified at the same level as the group they evolved from. Yet birds have traditionally been a class under the Linnaean system.\nThe turmoil sometimes results in differences between related pages. Pages may rely on different references and different authors' opinions as to the present best arrangement.\nThe following source is good on the differences between cladistic and taxonomic classification systems:\n- Grant, Verne 2003. Incongruence between cladistic and taxonomic systems. American Journal of Botany. 90 (9) 1263-1270. \n- Taxonomy Citizendium""]"	['<urn:uuid:4f5f4df8-3f7f-4b2f-83a6-2ba116014a21>', '<urn:uuid:80fc750f-3210-42f1-8b7a-fbad41b9556b>']	open-ended	direct	short-search-query	similar-to-document	multi-aspect	expert	2025-05-12T22:49:38.933606	6	67	1903
63	shark artwork australia how preserve formaldehyde	The shark artwork uses formaldehyde solution as a preservation technique associated with natural science museums. The formaldehyde solution hardens the tissue, making the bodies seem like rubber. While this preservation method doesn't completely stop deterioration, it slows it down to a point where decay is hardly detectable. The solution needs regular maintenance - it must be refilled when evaporated or completely replaced when too cloudy.	['This paper focuses on unstable organic materials and artistic strategies relating to conservation and replication. In 2004 Damien Hirst’s The Physical Impossibility of Death in the Mind of Someone Living 1991, hit the headlines when the work was sold to an American collector. However, the media attention did not focus on the selling price alone but on the fact that the shark, once caught in Australia, faced a second death: the original animal was showing advanced signs of decay and Hirst had substituted it with a fresh specimen. This is an example of the problem unstable materials pose in contemporary art. Since the 1960s especially, ephemeral substances have been used by many artists and Hirst’s substitution provokes a now familiar set of questions. How should one deal with the short-term durability of certain materials? And how does replacement affect the meaning and value of the work?\nIn this paper I should like to argue from a perspective of the ‘iconography of materials’, looking at the processes of production, the history of the materials, and techniques used to preserve works. As part of his artistic strategy, Hirst aims to use or reflect the operating modes of the global economy and its commodity flows. In 1991 he ordered by telephone the tiger shark from a professional Australian fisherman. The captured animal was deep-frozen and sent to London. Comparing this piece to similar works, one could argue perhaps that this specimen incorporated a singular history and that its substitution would affect the nature and identity of the work. But the artist chose a very specific mode of presentation – the technique of so-called wet preparation associated with natural science museums founded in the nineteenth century. Although this scientific mode of presentation suggests that the animal was an authentic material, as it were, this is not the case: the inconspicuous but powerful formaldehyde solution is predestined to convert ephemeral corpses into more resistant forms, hardening tissue so that after the treatment the bodies seem to consist of rubber. At this point, the animal can be regarded no longer as an individual entity with a specific history but an object of knowledge, a representative of its species. This way of working perpetuates an old hierarchy found in aesthetic theory from the time of Plato in which the form is regarded as of higher value than the material, and everything is done to preserve the form for posterity, no matter what happens to the materials.\nHirst’s shark was always meant to present the physical results of death and the inherent instability of organic material was therefore not unanticipated – it was not a vice but part of the work. As the artist knew that the chosen solution could not prevent the shark from rotting, it was always his intention to show the processes of decay. Hirst’s methods of preservation do not stop the deterioration; they slow it down to a point were it is hardly detectable. However, the material is not allowed an uncontrolled life of its own. The shark – and the many other animals of Hirst’s Natural History – are kept in a zombie-like undead state of abeyance. Decomposition, in the sense of much process-based art of the 1960s, is not the goal; Hirst’s unstable materials do not revolt against the enshrining walls of its steel and glass cases, or the institution of the museum, and nor does the artist refuse the creation of a tradable object.\nIn 2003 the formaldehyde solution of The Physical Impossibility of Death in the Mind of Someone Living was so cloudy that the animal within the case could hardly be seen. It was therefore not surprising that the dealer Larry Gagosian announced that the substitution of the shark should be seen in much the same way as the replacement of a broken neon tube in an installation by Dan Flavin. To a certain extent, this might be true: like all wet specimens prepared for the collections of the natural sciences, Hirst’s object has to be taken care of regularly, and the evaporated solution has to be refilled or the whole fluid has to be replaced. If the processes of decay have proceeded so far that the animal has become a highly visible corpse and is no longer undead, it is legitimate, from the perspective of the artist, to substitute the animal.\nAlthough Damien Hirst is concerned with preservation in his Natural History series, the concept of originality as something singular has become obsolete. If one looks at the many works in the shark’s wake which use farm animals in minimalist display cases, it appears obvious that seriality is employed as an artistic strategy to counteract the model of uniqueness and notions of artistic subjectivity. The substitution of the shark does not contradict the concept of this group of works at all – on the contrary, it strengthens the desired effect of mass production. The substitution of the animal should thus not be rated as a surrogate of an original but as a remake. The original frame and concept and a similar shark – these do guarantee not authenticity but rather a continuity of the performance. However, in contrast to works by, for instance, Sarah Lucas, which use fresh fruit that the particular owner or exhibitor should exchange regularly, it obviously matters who is substituting the shark. Damien Hirst’s company Science Ltd offers to replace any animal that is older than ten years.\nPerhaps this case could open discussion about how useful it is to look solely at artists’ intentions to solve questions regarding conservation. If the shark is not substituted, the art work, in the sense of Damien Hirst, dies, though it could be argued that at this point it would be set free for other usages and meanings. Maybe one should raise the question: at what point is it no longer reasonable to make a remake?']	['<urn:uuid:b38f15ad-5721-4b8b-b1ef-ce8bb25f4d59>']	open-ended	with-premise	short-search-query	similar-to-document	single-doc	novice	2025-05-12T22:49:38.933606	6	65	979
64	gallbladder inflammation without stones testing procedures	For diagnosing acalculous cholecystitis, radiological tests like ultrasound and CT scan are primarily used. Ultrasound is the most common and best diagnostic test, showing an enlarged and edematous gallbladder, wall thickening, fluid in the bile duct, and mucosal sloughing. CT scan is used when ultrasound findings are unclear or to narrow down from differential diagnoses. Nuclear imaging tests like HIDA scan can also be used, though its specificity and sensitivity are lower than ultrasonography and CT scan.	['Acalculous cholecystitis is an inflammatory health condition of the gallbladder in which there is no evidence of gallstones on the routine testing.\nIt commonly occurs in critically ill patients and who are on artificial ventilation or suffering from sepsis. Other risk factors include diabetes, human immunodeficiency virus infection, total parenteral nutrition, prolonged fasting, or being an ICU patient. It is usually a complication of other health conditions.\nIt has a higher risk of perforation and gangrene when compared to calculus cholecystitis. The overall incidence of acalculous cholecystitis is 5% in all cases of cholecystitis.\nThe acalculous cholecystitis can present with similar symptoms and signs as that of calculus cholecystitis. Common symptoms manifesting in this condition are:\n- Nausea and/or vomiting\n- Pain in the right upper quadrant of the abdomen that usually appears after meals.\n- Food intolerance\n- Abnormal bowel movements and abdominal distension.\nThe differential diagnoses that need to be considered while diagnosing acalculous cholecystitis are:\n- Calculus cholecystitis\n- Ascending cholangitis\n- Acute pancreatitis\n- Gastric issues like a stomach ulcers\n- Liver conditions like hepatic abscesses and hepatitis\n- Kidney diseases like pyelonephritis.\nHow to diagnose?\nIn acalculous cholecystitis, biochemical lab tests don’t provide comprehensive and conclusive clues towards establishing a diagnosis. Generally, radiological tests like ultrasound and CT scan are used to diagnose acalculous cholecystitis, and sometimes nuclear imaging tests like HIDA (hepatobiliary iminodiacetic acid, also called cholescintigraphy) scan can also be used.\nIt is the most common and best diagnostic test for acalculous cholecystitis. On ultrasound, an enlarged and edematous gallbladder is seen. There is also thickening of the wall of the gallbladder, presence of fluid in the bile duct, and mucosal sloughing.\nComputer tomography is usually indicated when there is a need to narrow down diagnosis from a broad list of differential diagnoses or no clear findings on ultrasound. Usually, similar findings are observed on a CT scan. Overall, the sensitivity and specificity of the CT scan are similar to the ultrasound.\nThis test has no significant advantage over other diagnostic modalities. The specificity and sensitivity of this test are generally lower than ultrasonography and CT scan.\nCommon surgical and nonsurgical treatment options for acalculous cholecystitis are as follow:\n- Percutaneous Cholecystostomy: It is the treatment of choice. It is a minimally invasive procedure. During this procedure, a catheter is placed in the gallbladder lumen and it is used for drainage. This treatment option is usually used in patients who are unstable and unfit for general anesthesia that is required for cholecystectomy. It can also be used as an adjunct therapy with cholecystectomy.\n- Cholecystectomy: This is a surgical treatment option. In this surgery, the whole gallbladder is removed by doing open or laparoscopic surgery. It is the definitive treatment and its need is increased if there is an indication of gangrene or perforation of the gallbladder.\n- Antibiotics: Antibiotics are indicated in patients who have a superimposed infection. Commonly, broad-spectrum antibiotics are used.\nInternet book of critical care, Acalculous cholecystitis, Accessed April 30, 2021, https://emcrit.org/ibcc/acalculous-cholecystitis/\nSciencedirect, Acalculous cholecystitis, Accessed April 30, 2021, https://www.sciencedirect.com/topics/medicine-and-dentistry/acalculous-cholecystitis\nUptodate, Acalculous cholecystitis: Clinical manifestations, diagnosis, and management, Accessed April 30, 2021, https://www.uptodate.com/contents/acalculous-cholecystitis-clinical-manifestations-diagnosis-and-management']	['<urn:uuid:89fcaff9-a63b-49ad-90f6-a87996a20b41>']	open-ended	direct	short-search-query	distant-from-document	single-doc	expert	2025-05-12T22:49:38.933606	6	77	524
65	I'm researching the history of dog breeds and I'd like to know how the origins of Poodles and Salukis compare in terms of their geographic regions and original purposes?	The Poodle originated in Germany, not France as commonly believed, and was bred to be a water retriever for hunters. Their name comes from the German word 'Pudeln' meaning 'to splash in water.' In contrast, the Saluki has much more ancient origins, being one of the oldest known domesticated dog breeds. They originated in the Middle East region, with evidence of Saluki-like hounds appearing in Iranian petroglyphs dating back to 8000-10000 BCE and in ancient Egyptian tombs from 2134 BCE. Salukis were historically used by nomadic tribes throughout the Middle East and along the Silk Road for hunting fast game like gazelles, hares, and foxes. While both breeds were developed for hunting, they had different specialties - Poodles as water retrievers and Salukis as swift pursuit hunters.	"[""The next featured breed in our Getting to Know your Dog Breed series is the Poodle. The Poodle is part of the Non-Sporting group of the AKC and ranks #7 in the AKC most popular breed list.\nLife expectancy: Poodles life expectancy varies greatly – mostly due to variations in size of poodles. Range is from 10-18 years. Size: Poodles come in three different sizes, Toy (4-6 lbs), Miniature (10-15 lbs) and Standard (50-60 lbs).\nColor: The most typical colors for poodles are black or white, but their coloring can range from apricot to silver/grey. They may also have colored markings of white, black or tan.\nOrigins: Poodles originated in Germany, not France like many folks think. They were bred and trained to be water retrievers for hunters. Their name is a derivation of the German word Pudeln which means “to splash in water”. They are related to the Irish Water Spaniel and Portuguese Water Dog. French and English breeders developed the different sizes of Poodles, resulting in the three recognized sizes.\nPersonality: Poodles have a reputation as being one of the smartest breeds, although the miniature tends to be shyer, quite vocal and possessive of their owner. The Standard size needs a fair amount of exercise due to its sporting dog roots, but they are easy to train and make great family dogs as well as good watchdogs.\nThe poodle is known for its fanciful grooming, with all those poufs and bouffant hairdos. Obviously, these grooming techniques are ornamental and really have nothing to do with the personality or health of the breed. They are purely for show, so if you like the breed, a nice “crew cut” works just fine.\nHealth Issues: Health issues prevalent in poodles include: hip dysplasia, progressive retinal atrophy (PRA), epilepsy, Addison's disease, thyroid issues, hypoglycemia, bloat, and collapsed trachea. These are found through all three sizes.\nFitness/energy level: Standard poodles like to have a job. They do have roots in retrieving and make good retrievers. They also love to be active with their families, so be sure and include them in your outings. Toy and Miniature sized Poodles are less active, but they still need daily exercise and mental challenges.\nNative foods for the Poodle: The Poodles origins are Germany and their native foods might have been:\n- Wild boar\nFun facts about the Poodle: Poodles do not shed in the same manner as other dogs and are therefore considered ‘hypoallergenic’. That’s a bit of mistaken belief as allergies are driven by the dog’s dander and other allergens they carry in their hair. It’s not the hair itself, but their hair carries the allergens and when they shed, you have all of these allergens in the air and around your house. Logically, if the dog sheds less, there is less dispersal of the allergy producing matter, and less suffering on the part of the owner.\nEven though the Poodles origins are in Germany, they have been named the national dog of France.\nThe Poodle has racked up 9 Westminster Best in Show wins (4 for Standard, 3 for Miniature and 2 for Toy)"", 'Saluki Info & Saluki Breeders\nThe Saluki, also known as the Royal Dog of Egypt is one of the oldest known breeds of domesticated dog. There are petroglyphs and rock arts in Golpaygan and Khomein in central Iran that shows saluki-like hounds and falcons accompanying hunters chasing preys (ca. 8000–10,000 BCE). Also on the potteries found in Susa, Iran (ca. 4200 BCE) are images of saluki-like hounds chasing ibex or lying next to pools. and from the period of the Middle Kingdom onwards, Saluki-like animals appear on the ancient Egyptian tombs of 2134 BCE. They have connections to the Avesta, Bible, Koran and Imperial China. Modern breeding in the west began in 1895 when Florence Amherst imported a breeding pair of Salukis from Lower Egypt and began working to popularize the breed. The first registered Salukis in the western studbook were Cyrus and Slongha Peri imported from Iran and registered with the DWZRV.\nThe Saluki is a sighthound and historically traveled throughout the Middle East and through Silk road with caravans and nomadic tribes over an area stretching from the Sahara to the Caspian Sea and China. They have been used to hunt quarry such as gazelles, Hares and ibex (mostly in North Iran). Shaped like a typical sighthound, they come in two varieties, smooth and feathered. Though they are an independent breed that needs patient training, they are gentle and affectionate with their owners. Health issues in salukis include cancer and cardiac problems but it is less common in countries of origin.\nHistorically, Salukis were used by nomadic tribes for hunting. Typical quarry included gazelles, hares, foxes and jackals. In one Bedouin method of hunting hares, the hunter rides close to the quarry on a camel while holding the Saluki, which he throws towards the prey while at speed, giving the dog a running start. Another method, primarily used in hunting gazelles, involved the use of a hawk to gouge out the eyes of the prey, so that a Saluki can then bring down the blinded animal.\nA true modern Saluki retains the qualities of hunting hounds and may seem reserved to strangers. An independent and aloof breed, but gentle and affectionate, they can be difficult to train and any such training should be gentle and patient. They can get bored easily, and should not be left at home unattended for long periods. Sensitive and intelligent, the Saluki should never be trained using force or harsh methods, and typically does not enjoy rough games or typical dog games such as chasing sticks. Early socialization is required to prevent timidity and shyness in later life. Given their hunting instincts, they are prone to chasing moving objects.\nWhile the Greyhound is credited as being the fastest dog breed up to distances of around 800 metres (2,600 ft), both the Saluki and Whippet breeds are thought to be faster over longer distances. The 1996 edition of the Guinness Book of Records lists a Saluki as being the fastest dog, reaching a speed of 68.8 kilometres (42.8 mi) per hour. Due to its heavily padded feet being able to absorb the impact on its body, it has remarkable stamina when running.']"	['<urn:uuid:1ba20fc8-2691-4b2d-b54a-082c08fe9d30>', '<urn:uuid:993b999f-68ea-4537-ae68-8939917d1184>']	open-ended	with-premise	verbose-and-natural	distant-from-document	comparison	novice	2025-05-12T22:49:38.933606	29	127	1048
66	What was the historical context and purpose behind the writing of the book 1984 during the time it was published?	1984 was written in an age of Nazism and Stalinism, when totalitarian and fascist governments controlled and terrorized their citizens in every aspect of their lives. It was written as a warning to make readers question the authority and integrity of their governments and news stations, and to ensure they protect people's inalienable rights.	"[""In 1949, Eric Blair published one of the most thought-provoking books, 1984. Under his pseudonym, George Orwell became one of the most famous authors of his time. George Orwell expressed a society that had lost its ability to think for oneself. The Party in the book uses different methods to control every facet of their citizens. In the process of doing that George Orwell portrays psychological torture and manipulation of human nature in 1984, in order to emphasize how the government retained complete sovereignty over the citizens.\nGeorge Orwell 's views on totalitarian governments were not concealed from public view. He expressed his thoughts and opinions through his books. Among these books were Nineteen - Eighty -Four and Animal Farm, which were his works that most obviously portrayed his disfavor for totalitarian governments. Totalitarian governments are controlled by political authorities who have control of all aspects of society. Nineteen-Eighty-Four and Animal Farm are two different books that have different ways of expressing the same theme. For example, Animal Farm is constructed on a farm and the characters are animals and Nineteen - Eighty - Four is set in a society with actual people. However, they still express how totalitarian governments are\nAnimal Farm and 1984, both by George Orwell, revealed to me how awful of a world I used to live in. Having lived for 15 years in a totalitarian regime, I had no idea something was wrong. I was crammed with shallow and heavily theoretical education; I was fed with corrupt morality, ambiguous justice, and ridiculous common sense; I was surrounded by uninspired children, unimaginative students, inept adolescents, and indifferent adults. I was like Boxer the horse from Animal Farm, working diligently with only misery in return. I was also Winston Smith from 1984, who bears burning thoughts about the rightness of what he does and what society does. When I finally moved to a democracy, I realized: someone who lives by a garbage dump never knows\nTotalitarian governments strive for power and total control over their people. In George Orwell’s dystopian novels, Animal Farm and 1984, the governments in each novel are very manipulative and depressing. In Animal Farm a rebellion sparked a change in leadership over the animals. Napoleon, the ruler, doesn’t actually turn the farm around after he becomes the leader. In 1984 Winston goes against the ways of the party. With Big Brother watching over all Winston has a hard time trying to conceal his feeling towards the party. In both dystopian settings, hopelessness stands out because of Orwell’s use of irony, tone, and anaphora.\nNapoleon, the leader of all the animals of the Rebellion, can be compared and contrasted with Big Brother, the leader of all the people of 1984. Both Big Brother and Napoleon show the qualities of a cruel ruler. Similar to Big Brother, Napoleon is a secretive plotter who works behind the scenes rather than openly. However, unlike Napoleon, Big Brother periodically appears on the television screen. Napoleon and Big Brother both work continually to weaken their rivals, whether it is by removing Snowball or eliminate Rutherford. Both place importance on complicated ceremonies and parades to prevent their workers from thinking about their schemes. Napoleon’s control over animal farm is not as powerful as Big Brother's\nGeorge Orwell, the pseudonym of english author Eric Arthur Blair, was an influential author of novels, novellas, and essays that criticized the rise and practices of authoritarian governments. One of his most revered works, Animal Farm, is hailed as a brilliant piece that satirizes the statues of Stalinism by allegorizing its tumultuous rise and the harsh, often lethal loyalty Stalinism demands of its followers. One of the hallmarks of Stalinist rule is its frequent use of propaganda. In his novella, Animal Farm, Orwell presents the use of propaganda in a Stalinist society through the deification of a leader, the use of scapegoating against an exiled revolutionary and against the vices of man; and exposes the practice of engendering fear into the population of Animal Farm.\nAnimal Farm by George Orwell which is an allegory of the Russian Revolution and the film adaptation of George Orwell’s novel 1984, which is set in a futuristic dystopian society, directed by Michael Radford uses Symbolism, foreshadowing and irony to convey the central ideas of power, politics, control, fear and they both also portray the dangers of totalitarianism. 1984 follows one main character (Winston) which shows how the society is being controlled whereas Animal Farm does not follow one character specifically. Though there are differences, Animal Farm and 1984 use the language techniques of symbolism, foreshadowing and irony in very similar ways.\nIn the midst of a world completely blind to the truth, there was a man who’s seditious thoughts opened our eyes to a destructive future. Eric Blair, most commonly known as George Orwell, was born in Bengal and brought up in a society divided by social classes. Orwell graduated from Eton and decided to drop out of college to join the Indian Imperial police in Burma, where he experienced the cruelty of the world. He had an epiphany after returning back to England and was suddenly consumed in translating his fervent emotions of hatred and anger into words. World War II has just ended after a long period of constant war over land, minerals and weapons when Orwell began\nThe Animal Farm book is a well-known novel that uses allegory and satire to make light of the Soviet Union during the mid-1940’s. The author George Orwell has been known for many famous and well know novels such as 1984, Animal Farm and Down and Out in Paris and London. George Orwell is the known author for these novels, but many don’t know that it was a stage name. The author’s real name was Eric Arthur Blair, Eric was a novelist, political writer and journalist. These occupations he had explains the reason his novels tend to relate and depict certain political situations, and figure in society. Eric lived from 1903 to 1950,\nIn the novels, Animal Farm and 1984 written by George Orwell, the totalitarian leaders take over their societies. Napoleon, the leader in Animal Farm, takes his control to an extreme by changing the ways of the farm to benefit himself. Big Brother, the leader in 1984, maintains complete control by changing history and watching his citizens every move and thought. Although Napoleon and Big Brother illustrate an intense hold in their totalitarian rule, Napoleon uses manipulation and control whereas Big Brother flourishes by obtaining trust and love from his citizens.\n1984 was written in an age of Nazism and Stalinism, where those totalitarian and fascist governments had their fists clenched around their citizens, controlling and terrorizing them at every move and within every aspect of their lives. The English author, Eric Arthur Blair, better known under his pseudonym George Orwell, wrote 1984 as a warning, to provoke a sense of fear from his audience, which, in turn, makes his purpose, to persuade and inform his readers to question the authority and integrity of their governments and news stations and make certain they do not infringe upon people’s inalienable rights, all the more impactful. Orwell propels his purpose through means of rhetorical devices, such as allusion, colloquialism, and paradoxes in order to build up fear in his audience, which in turn more adeptly and meaningfully develops his purpose.\nGeorge Orwell was a writer of numerous books, the most well known being 1984 and Animal Farm. George’s real name was Eric Blair, which was later changed to George Orwell so his work would be more noticed. Eric was born in India, but at a young age moved to England with his mother and sister. Eric later moves to Burma to work in the Imperial Police Force which inspired the book “Burmese Days.” Eric then moved back to England, then to Spain, and back again to England. Eric’s extensive traveling led to him seeing the different political views from all around the world and the negative effects of certain political parties. 1984\n1984 and Animal farm are acutely similar books. They both revolve around a dictatorship government. There are two main dictators in these stories, Big Brother and Napoleon. The pigs are aggressive and big brother is always watching what the people do. In these novels the leaders start out with using the ruling to use it for good but then focus on corruption of power that Napoleon and Big Brother use it for the worse and not the good. 1984 and Animal farm the totalitarian governments used dehumanizing tactics like using television to hypnotize the animals, take away rights and using fear to show the people and animals that the government has the power.\nThe totalitarian lead government like setting in both 1984 and Animal Farm impacts the overall feeling of hopelessness in the novels. In 1984 Big Brother controls every aspect of everyone’s lives at every moment. Similarly, in Animal Farm Napoleon and the pigs control everything the animals do, when they do it, and how they do it. Hopelessness stands out in Orwell’s dystopian novels, 1984 and Animal Farm, due to his use of irony, anaphora, and tone.\nEvery writer has their own signature writing style. However, few get recognized for their literary brilliance. George Orwell stands out as one of the few authors that has withstood the test of time through his literary works. Born at the beginning of the twentieth century, Eric Arthur Blair, more commonly known as George Orwell, started his path of excellence, not as a writer, but as a part of the British Imperial Police. Stationed in Burma, Orwell gained much insight on life through his experiences with the Burmese people. His stories inspired one of his first works, “Burmese Days.” After his travels in Burma, Orwell focused more on society in Europe. He gained interest in politics through serving in wars and broadcasting propaganda through a radio channel. Many of Orwell writings confronted his concerns about imperialism. Readers thrived on his eye-opening novels and essays. Such insightful literature has earned Orwell a name as one of the greatest political authors of all time. This not only comes from the content of his literature, but also from the style in which he writes. This has led to the creation of the “Orwellian” style, in which one would write like Orwell in modeling his content and form. His focus on politics in his literature appears in most of his essays and novels. This content of anti-imperialism has led him to be globally known as one of the most influential authors of the twentieth century and has been noted as the second greatest author since 1945 by""]"	['<urn:uuid:995a1ec5-2e6e-4aec-96df-36de29a7b2bf>']	factoid	direct	verbose-and-natural	similar-to-document	single-doc	novice	2025-05-12T22:49:38.933606	20	54	1783
67	who controlled law making ancient greece before democracy rich poor conflict	Early Greek law was predominantly controlled by the aristocracy. Law was viewed as something handed down from Zeus to the aristocrats, along with their scepters and divine descent. However, this elite control of law became a source of social tension, leading to conflicts between the powerful and the weak. This tension is particularly evident in traditions about early lawgivers, such as Solon, Charondas, and Zaleucus. Eventually, there was a gradual shift as 'ordinary' Greeks wrested control of law away from the aristocracy, moving toward the democratic system seen in classical Athens.	"['Zinon Papakonstantinou, Lawmaking and Adjudication in Archaic Greece. London: Duckworth, 2008. Pp. xiv, 233. ISBN 9780715637296. $50.00.\nReviewed by Alex Gottesman, Union College\nIt has been over 20 years since the publication of Gagarin\'s Early Greek Law. The study of Greek law has flourished in the meantime, but archaic Greek law, owing to the paltriness of the relevant sources, has not received proportional attention. The main sources for archaic law amount to a few literary texts and a few stones, and they do not tell a consistent story. As a result, we can only speculate about how social contexts and processes influenced, or were influenced by, the development of Greek law. The aim of Papakonstantinou\'s book is to rekindle interest in this field of speculation.\nGagarin influentially argued that early law\'s emphasis on procedure over substance was evidence of an interest in making sure disputes between individuals did not become dangers to the community. For Gagarin, developments in legal history track closely the rise of the polis as a community of citizens. The inscription of law is part of that story.1 The aim was to give the community\'s decisions the force of law, and thus make them authoritative in controlling disputes. Eventually, this development would pave the way for greater control by the citizen in his community\'s legal and political institutions.\nThe story Papakonstantinou tells is quite different, contrasting with Gagarin\'s at several points. The central point of contrast is on how much emphasis they each place on social class. Papakonstantinou sees early Greek law from a critical legal studies perspective. This perspective views law as a tool which the powerful use at the expense of the weak, and which the weak try to use to resist the powerful. Law is essentially a site of class tensions. Gagarin\'s view, informed by the legal anthropological literature on dispute resolution sees law less as a weapon of class warfare, and more as a process tending towards social equilibrium. This fundamental difference leads to other points of contrast. For instance, whereas Gagarin (and most legal scholars of Greece) insists that Greek law was an amateur business, Papakonstantinou sees signs of professionalization in the archaic Greek ""judiciary."" Gagarin sees Greek written laws as using common language, in order to be accessible to as many members of the community as possible. On the other hand, Papakonstantinou sees the language of the Greek laws as specialized, consistent with their tacit intention to help the elite maintain a monopoly over the making and interpretation of law. According to Papakonstantinou, the story of archaic Greek law is the eventual wresting of law by ""ordinary"" Greeks away from the clutches of the aristocracy.\nHow well does his reading of the sources support his story? After an initial chapter which lays out his theoretical methodology and attacks that of unnamed scholars who, in his view, suffer under ""contemporary preconceptions and misconceptions regarding the role and status of law within pre-modern societies"" (2), Papakonstantinou turns to the literary sources, namely Homer and Hesiod. He considers Homer as accurately reflecting a strand of legal thought and practice in the 7th century. This was a time during which law, for the most part, was seen as the exclusive domain of the aristocracy. Law was seen as something that was handed down from above (the themistas of Zeus) to the aristocrats, along with their scepters and their descent from the gods. Key scenes in Homer reflect this idea: the quasi-legal dispute of Iliad 23, in which Menelaus challenges Antilochus to an oath-contest, and the trial scene of Achilles\' shield (both being passages which have inspired mountains of legal scholarship).\nFor Papakonstantinou, these passages illustrate the idea that the right to speak in a legal context was originally seen as the preserve of the aristocracy (whereas Hesiod shows that this idea was also coming under criticism). He points out, uncontroversially, that Menelaus and Antilochus are both members of the aristocracy, and, somewhat more controversially, that the trial scene likewise shows the elite in the position of settling disputes. It wouldn\'t be surprising if Homer actually shared the ""hegemonic"" view of law (Papakonstantinou\'s term), but I am not convinced that these passages necessarily show that. If the gerontes of the trial scene are indeed members of the same class as the heroes, it is certainly worth stressing that they are competing against each other over who can make the ""best"" judgment, and the judgment of the crowd is clearly instrumental in deciding that. Nor is the Menelaus-Antilochus dispute much proof for the dominance of the hegemonic view of law in the archaic period. Given epic conventions, we wouldn\'t expect Menelaus to drag off Antilochus to a magistrate, or demand a trial by a jury of the people.2\nThe next chapter deals with inscriptions and traditions of the early lawgivers. Scholars have pointed out that early inscriptions do not seem to reflect the social tensions that are part of the stories of archaic lawmaking, such as Solon\'s in Athens.3 Papakonstantinou disagrees. He senses such tensions in the different sanctioning authorities archaic inscriptions tend to list. For example, he finds them in the Dreran law that limits the frequency of the magistracy of kosmos to no more than once every ten years (Meiggs and Lewis 2). Papakonstantinou highlights the fact that three bodies of officials are to swear the relevant oath (the kosmoi, the demos, and the ikati, whoever they were), and interprets this to mean that Dreros was probably faced with ""an unstable political situation"" (53) in which legal authority was ""multiple, overlapping, and sometimes conflicting"" (63). Different institutions, representing the interests of different classes, sought to make law, and stones such as this one are the product of their ""negotiation."" Thus they paper over the social tensions out of which they were produced. He finds similar tensions in the ""Spensithios Inscription"" from Crete (SEG 27.631), in the so-called ""Pappadakis Bronze"" (IG IX 1 3.609), and in the Spartan Great Rhetra as preserved by Plutarch (Lyc. 6. 1), among other archaic sources. What all these have in common is that they list different bodies of officials as authorities. Papakonstantinou\'s interpretation here is not very compelling. Different authorities does not necessarily mean conflicting authorities, any more than a mention of boule and demos in Athenian documents means that council and assembly represented different social or class interests.\nPapakonstantinou is on somewhat safer ground when dealing with the traditions of early lawgivers, such as Solon, Charondas and Zaleucus. While there are very few (if any) signs of social conflict in the archaic inscriptions, it is certainly true that some traditions of the foundations of legal systems represent them as being born out of social or class conflict. On the other hand, even apparently secure evidence of social tensions behind archaic lawmaking, such as Solon\'s poetry, is not as secure as Papakonstantinou assumes. For example, it is debatable to what extent we have Solon\'s actual words, and how greatly later political struggles fundamentally helped shape the text.4 More attention is needed to the problems in using later sources as evidence for the archaic period.\nThe next chapter returns to inscriptions, and examines the evidence for archaic courts. Papakonstantinou suggests that archaic courts were something like a halfway point between the hegemonic control of law he finds in Homer and Hesiod and the democratic system of law we see in classical Athens. Papakonstantinou interprets attempts to publicize law as meaning that the common people had become more engaged in the law. The aristocracy had caved into pressure somewhat, and had allowed courts to be created, but they were still controlling them through dikastai, whom he considers to be aristocratic ""legal specialists."" This is one of his weakest claims.5 He asserts that the Spensithios whom an archaic Cretan community hired as its official legal scribe was an elite member of the community (78), whereas most scholars assume that he was a foreigner, since he receives honors that were later typically given to foreigners. It is important for Papakonstantinou to make this point, because if Spensithios was a foreigner this would fly in the face of his argument that the archaic elite aimed to control the legal system, since here we seem to have a case in which an archaic community is delegating the ""recording and remembering"" (poinikazein te kai mnamoneuwein) of its legal affairs to someone who was not a member of it, let alone a member of its aristocracy.\nPapakonstantinou further asserts that the institution of the jury was a popular response to elite attempts to control law through aristocratic specialists. He therefore argues that aristindan at IG IX 1 3. 717 should be translated as ""according to merit."" This inscription, a no-plunder agreement between two communities in central Greece, stipulates that in case of dispute a jury should be drawn aristindan (97). Most scholars take this simply as ""from the aristocracy,"" but Papakonstantinou suggests the translation ""according to merit."" Doing so allows him to maintain the strict distinction he wishes to draw between popular juries and elite judges, but it is unconvincing.\nThe final chapter considers how ""ordinary"" Greeks\' reacted to the legal system which they faced. Papakonstantinou draws evidence from archaic poetry, especially Solon and Theognis, and from epigraphic texts involving the regulation of oaths and magistrates, and judicial curses. He asserts, ""The fact that Solon lingers so extensively on the theme of abuse of law and justice, especially by the aristocracy, indicates that this issue was a major grievance on the part of the lower social orders"" (107). He similarly finds evidence of class warfare behind Theognis\' laments about the kakoi who have taken over the city and are handing down judgments for the unjust (Theognis, 45-6). He argues that these texts raise the possibility that class interests might manipulate the legal system. Archaic enactments regulating oaths and magistrates similarly suggest the awareness that individuals might try to abuse the legal system for their benefit. Judicial curses, on the other hand, he argues, ""can be seen as unorthodox and resistant legal narratives challenging the fabric of a complex and at times uneven... legal system"" (125).\nIn short, Papakonstantinou wants to paint a picture of archaic law as a site of contest and negotiation between class interests, and finds evidence to support this claim. Despite my doubts about specific readings of that evidence, I think Papakonstantinou makes an important point, that legal historians ought to consider more carefully the intersection of law and class in archaic Greece. On the other hand, his notion of class is severely under-theorized, ultimately reproducing the concept (the aristocracy vs. the rest) which the ancient texts start with, but without discussing the social or poetic ends to which they used it. Nonetheless, this project is worth the consideration of scholars working on Greek law.6\n1. The debate about the development and meaning of written law is a warm one. See K.-J. Hölkeskamp ""Written Law in Archaic Greece."" PCPS 38 (1992): 87-117; R. Thomas, ""Written in Stone? Liberty, Equality, Orality and the Codification of Law."" BICS 40 (1995): 59-74. See also Gagarin\'s recent Writing Greek Law (Cambridge, 2008).\n2. Papakonstantinou does not mention Douris\' famous illustration of the vote deciding the fate of the arms of Achilles (Vienna 3695). It seems that at least one late archaic Greek could imagine the heroes ""taking their rivals to court.""\n3. For example, R. Osborne. Greece in the Making (Routledge, 1996), p. 175.\n4. See A. Lardinois, ""Have we Solon\'s Verses?"" in J. Blok and A. Lardinois, eds. Solon of Athens (Brill, 2006).\n5. The main evidence is the notice in Ath. Pol. 16. 5 about Peisistratus\' itinerant arbitrators, whom he assumes to be aristocratic, and the place of the Areopagus in Athenian legal history. The latter is problematic, owing to the Areopagus\' central role in the dispute concerning the patrios politeia in the late 5th/4th century, which Papakonstantinou does not discuss.\n6. This could be an intimidating book for those who are not specialists in Greek law. Most of the Greek is translated, but some is merely paraphrased, including some in archaic non-Attic dialects.']"	['<urn:uuid:8996b6f7-f749-4437-83ee-4e95e6ce8529>']	open-ended	with-premise	long-search-query	distant-from-document	single-doc	novice	2025-05-12T22:49:38.933606	11	91	2017
68	classical music audience engagement challenges solutions	The BBC addressed audience engagement through programming previously neglected British works, creating memorable concerts like Howells's Hymnus Paradisi. For diversity, organizations developed outreach initiatives including pop-up performances in shopping malls, fusion concerts combining classical with other genres at the Barbican, and education schemes targeting underrepresented communities.	['If any recent BBC executive embodied the idea of public service broadcasting to an exemplary degree it was Roger Wright, who until last July was controller of Radio 3 and director of the Proms. Wright now runs the Aldeburgh Festival, and Aldeburgh is lucky to have him. He always had a mission to rectify a shocking deficiency in the programming both of his network and of the Proms by including a substantial number of works from the English musical renaissance of the late 19th and 20th century. This creative flourishing will come to be seen as one of the most culturally significant events in the history of our country. Wright knew that the Proms was a British festival of music and not a festival of British music, but he also understood that if the state broadcaster – especially when running the most important music festival in these islands – doesn’t promote the national canon, then it is highly unlikely that anyone else will.\nThe mad thing about the neglect of British music by the BBC from the era of William Glock 50 years ago until the advent of Wright was that it was rooted in prejudice. The music itself is frequently stunning, but too many people got it into their heads that since it wasn’t up to Bach or Beethoven it was hardly worth bothering with. Well, I would contend that some of it jolly well is up to Bach and Beethoven. Wright made a point of putting on at the Proms great works that had never been performed there, and in doing so created some of the most memorable and moving concerts heard there in recent years – notably Herbert Howells’s Hymnus Paradisi in 2012, and John Foulds’s Dynamic Triptych a couple of years earlier. Also, in 2010, Wright programmed several works of Sir Hubert Parry, who normally only features each year when Jerusalem is played on the last night. His Fifth Symphony was a revelation to those who heard it for the first time; another of his masterpieces, the Symphonic Variations, was also heard for the first time since 1936.\nWright has gone, but some of his programming is yet to be heard. Next Thursday we shall hear the first performance at the Proms of Ralph Vaughan Williams’s oratorio Sancta Civitas. Completed in 1925, it was the composer’s favourite of his choral pieces, and it is beyond question one of the greatest English choral works ever written. Mark Elder will conduct the Hallé Orchestra and the Hallé’s choirs: he and his orchestra are the finest exponents of English music around today, and there is the bonus of Elgar’s magnificent Second Symphony in the second half. The concert is long since sold out, but it is being broadcast, and ought to be regarded as unmissable.\nSancta Civitas is a dark work, indicative of the shift away from the pastoral and contemplative tone that marked RVW’s music before the Great War, and a harbinger of the brooding, solemn, often angry tone that would come into his music in the second half of his life, notably in his Job: A Masque for Dancing of 1930, his Fourth Symphony of 1935 and his Sixth Symphony of 1948. Too many people imagine that RVW’s sound world stretches little beyond that of the Tallis Fantasia and The Lark Ascending, but half an hour spent with Sancta Civitas will tell them differently.\nThe late Michael Kennedy, the leading authority on RVW’s music, called the oratorio the most personal of the composer’s works, not least because it seems to fulfil a vision RVW had set out in 1920: “The object of all art is to obtain a partial revelation of that which is beyond human sense and human faculties – of that in fact which is spiritual… the human, visible, audible and intelligible media which artists (of all kinds) use are symbols not of other visible and audible things but of what lies beyond sense and knowledge.” And the composer also chose not just a stirring text from the Book of Revelation and Taverner’s Bible, but prefaced the work with a quotation from Plato about immortality and the soul: RVW was an agnostic, and spent his life searching for meaning. He also had a brilliant understanding of the musicality of words and of which texts sounded best when set to music.\nI suspect that you, like me, will wonder, should you hear this work on Thursday, why it has taken 90 years for our greatest music festival to embrace this utter masterpiece.\nProm 17, featuring Sancta Civitas, is broadcast on BBC Radio 3 at 6:30pm on July 30', 'Racial diversity in classical music: A daunting experience for non-white professionals working in the industry today\n“Going into a concert hall, you see an entirely white orchestra, a white audience and a white soloist”. I am talking to Julian Lloyd-Webber about the lack of black and ethnic minority people in the cut-throat world of classical music. He describes a common scene; by his own admission a “daunting” one for the handful of non-white professionals working in classical music today.\nCurrently, just five per cent of classical music professionals working in the UK identify as black and minority ethnic – and this figure shows no sign of rising, according to the Arts Council Staff Survey. Compare this to the 12 per cent slice of the UK population made up by the same group, and the under representation in British classical music speaks for itself and it speaks volumes.\nThe problem of racial diversity in classical music has long been the elephant in the room. Anecdotally, the stories are prolific. Only last year Hollywood screenwriter Candace Allen (the ex-wife of conductor Sir Simon Rattle) branded the British classical world “racist”.\nAllen claimed that a combination of discrimination and lack of exposure to classical at an early age meant that black people were unlikely to make it to the concert hall (be that in the audience or in the pit) so when they did, their sense of alienation made the experience not one to be repeated. On this second point, Allen can’t be faulted.\n“People need role models,” Lloyd-Webber tells me. “They need to see someone like themselves out there”. It’s long been accepted that one’s relationship with music starts at a young age. That counts for any genre of music, so any suggestion that classical isn’t ‘relevant’ is absurd. Listening to Mozart might seem odd for a young black kid living in an estate, but no more so than listening to a K-Pop star speaking in Korean while he dances like a horse; it’s all about exposure.\nHearing it at home, in school, visits to concerts, a few friends with the same interest, all these factors contribute to one’s sense of community in music, and without this sense of community, forming a meaningful bond to any kind of sound is nigh impossible.\nTo this end, a number of outstanding outreach programs have developed. There’s over 20 years of the London Symphony Orchestra Discovery Program, a music education scheme that touches 60,000 children with a particular focus on East London. At the Barbican, the famous avant-garde programming has actively (and successfully) sought new audiences by breaking boundaries in concert hall convention, be that by fusing classical musicians from India with a jazz band or by giving Aphex Twin a remote control orchestra. Orchestras Live are creating pop-up performances in shopping malls to recontextualise how we see classical, and perhaps most moving of all, is Julian Lloyd-Webber’s In Harmony El Sistema project in Liverpool and London, modelled on its Venezuelan namesake.\nEl Sistema was a social project initiated under Hugo Chavez that encouraged community activity and adolescent discipline by providing poor children with lessons in an orchestra. Venezuela now boasts over 300,000 children in the program and one of the best orchestras in the world. “The conductor [Gustavo Dudamel] is as famous as any footballer”, Gabriel Prokofiev (grandson of Sergei and composer) tells me.\n“The audiences are young, the players are young, the performances feel like a party”. Here in the UK, Lloyd-Webber’s program has reported equally outstanding results. “I am positive that for most of the kids in our program, they have had little to no exposure to classical,” Lloyd-Webber tells me. “And now it is their life”.\nSo why, after all this, is classical music as white as it has ever been?\n“Traditionally, most people in the classical world have grown up in a family where classical music was played,” Prokofiev tells me “and as far as I can see, that hasn’t changed”. The outreach work of any number of organisations may have helped to engage audiences – but without sustained exposure, and, if the child wants, the costs of lessons and instruments, the status quo cannot and will not change. This is particularly true of BME communities where classical music – a largely Western movement – can be perceived as alien.\nThese changes cannot, and should not come from non-elected bodies such as orchestras and community projects. They should, and can only, come from the government. Music education funding was shredded to ribbons under Thatcher; Michael Gove’s National Plan for music education has been in full swing for just under a year, and it is perhaps too early to say whether it has succeeded or not. But the instances of ‘theory-only’ music classes to meet curriculum requirements, or no music programme at all, compounded with the challenge of giving a child continued access to an instrument, remain widespread.\nIf you happen to live in an area where people like In Harmony, LSO and others are working, then your child might just fulfil their musical potential regardless of their colour or class. If not, the postcode lottery of music education might get the better of you. But what does it all matter if classical music still looks set to stay white? According to Kathryn McDowell, director of the LSO, “If we’re in receipt of public subsidy we have a responsibility”. Responsibility, if only that was a classic.Tagged in: Candace Allen, Classical music, El Sistema, Gabriel Prokofiev, Julian Lloyd-Webber, London Symphony Orchestra Discovery Program, Racial diversity\nRecent Posts on Arts\n- Indian rickshaw fetches £100,000 for wild elephants at Prince Charles hosted auction\n- Vennart Interview and album stream: ‘This album is more focused on vocals and guitar rather than pounding your head and complex riffs’\n- India’s old moderns keep the art auctions buoyant\n- Scottish Book Trust: Ask the Illustrator with Debi Gliori\n- Dialects: LTKLTL - EP Stream\nLatest from Independent journalists on Twitter']	['<urn:uuid:794ea342-7092-4c15-ad6a-9d7bd0dfbcde>', '<urn:uuid:4ea45122-2e19-4112-8a39-cebc48e7c5d6>']	factoid	direct	short-search-query	similar-to-document	multi-aspect	expert	2025-05-12T22:49:38.933606	6	46	1766
69	insulin tgf beta assay specificity protocol	For insulin measurement, samples are run in duplicate using an ELISA kit, requiring 5μl of sample per well with 75μl Working Strength Conjugate, followed by 2-hour incubation with shaking. Regarding TGF beta 1 specificity, the antibody recognizes both natural and recombinant TGF beta 1, reacting with dimeric and monomeric natural forms under reducing and non-reducing conditions. It has confirmed reactivity with sheep, human, and pig samples, while rat reactivity is predicted but has mixed customer feedback. The antibody demonstrates neutralizing activity against TGF beta 1 in cell proliferation assays.	"[""Anti-TGF beta 1 antibody [TB21] (ab27969)\n- Product nameAnti-TGF beta 1 antibody [TB21]See all TGF beta 1 primary antibodies ...\n- DescriptionMouse monoclonal [TB21] to TGF beta 1\n- SpecificityThis antibody recognises natural and recombinant TGF beta 1. It reacts with both dimeric and monomeric natural forms under reducing and non reducing conditions.\n- Tested applicationsIHC-Fr, IHC-P, ELISA, ICC/IF, Neutralising, WB more details\n- Species reactivityReacts with: Sheep, Human, Pig\nPredicted to work with: Rat\nHuman TGF Beta 1 from human platelets.\n- Positive controlHuman breast carcinoma.\n- General notesWe have mixed feedback from customers about the Rat specificity so the Rat species has been moved to predicted as we can't guarantee it. The antibody has been successfully used with Rat samples in publication PMID 22471627 and PMID 19820199 though.\nThis clone (TB21) demonstrates neutralising activity against TGF beta 1 in cell proliferation assays. Removal of sodium azide is recommended prior to use in functional assays.\n- Storage instructionsStore at +4°C short term (1-2 weeks). Aliquot and store at -20°C long term. Avoid repeated freeze / thaw cycles.\n- Storage bufferPreservative: 0.09% Sodium Azide.\n- Concentration information loading...\n- PurityImmunogen affinity purified\n- Primary antibody notes This clone (TB21) demonstrates neutralising activity against TGF beta 1 in cell proliferation assays. Removal of sodium azide is recommended prior to use in functional assays.\n- Clonality Monoclonal\n- Clone numberTB21\n- Light chain typekappa\nOur Abpromise guarantee covers the use of ab27969 in the following tested applications.\nThe application notes include recommended starting dilutions; optimal dilutions/concentrations should be determined by the end user.\n|IHC-Fr||IHC-Fr: Use at an assay dependent dilution.|\n|IHC-P||IHC-P: Use at an assay dependent dilution.|\n|ELISA||ELISA: Use at an assay dependent dilution.|\n|ICC/IF||ICC/IF: Use at an assay dependent dilution.|\n|Neutralising||Neut: Use at an assay dependent dilution. PubMed: 8237223|\n|WB||WB: 1/2000. See Abreview. We recommend using BSA in blocking solution.|\n- FunctionMultifunctional protein that controls proliferation, differentiation and other functions in many cell types. Many cells synthesize TGFB1 and have specific receptors for it. It positively and negatively regulates many other growth factors. It plays an important role in bone remodeling as it is a potent stimulator of osteoblastic bone formation, causing chemotaxis, proliferation and differentiation in committed osteoblasts.\n- Tissue specificityHighly expressed in bone. Abundantly expressed in articular cartilage and chondrocytes and is increased in osteoarthritis (OA). Co-localizes with ASPN in chondrocytes within OA lesions of articular cartilage.\n- Involvement in diseaseDefects in TGFB1 are the cause of Camurati-Engelmann disease (CE) [MIM:131300]; also known as progressive diaphyseal dysplasia 1 (DPD1). CE is an autosomal dominant disorder characterized by hyperostosis and sclerosis of the diaphyses of long bones. The disease typically presents in early childhood with pain, muscular weakness and waddling gait, and in some cases other features such as exophthalmos, facial paralysis, hearing difficulties and loss of vision.\n- Sequence similaritiesBelongs to the TGF-beta family.\nThe precursor is cleaved into mature TGF-beta-1 and LAP, which remains non-covalently linked to mature TGF-beta-1 rendering it inactive.\n- Cellular localizationSecreted > extracellular space > extracellular matrix.\n- Camurati Engelmann disease antibodyCED antibodyDiaphyseal dysplasia 1 progressive antibody\n- DPD1 antibodyLAP antibodyLatency-associated peptide antibodyTGF beta 1 antibodyTGF beta antibodyTGF beta 1 protein antibodyTGF-beta 1 protein antibodyTGF-beta-1 antibodyTGF-beta-5 antibodyTGF-beta1 antibodyTGFB 1 antibodyTGFB antibodyTgfb-1 antibodyTGFB1 antibodyTGFB1_HUMAN antibodyTGFbeta antibodyTGFbeta1 antibodyTransforming Growth Factor b1 antibodyTransforming Growth Factor beta 1 antibodyTransforming growth factor beta 1a antibodytransforming growth factor beta-1 antibodytransforming growth factor, beta 1 antibody\nAnti-TGF beta 1 antibody [TB21] images\nab27969 staining TGF beta 1 in rat kidney tissue sections by Immunohistochemistry (frozen sections). Tissue was fixed with acetone and then blocked with 2% BSA for 2 hours at 25°C followed by incubation with the primary antibody, at a 1/200 dilution, for 9 hours at 4°C. The secondary antibody used was a goat anti-mouse IgG conjugated to Alexa Fluor® 594 (red) used at a 1/500 dilution.\nab 27969 staining TGF beta 1 in human 293ft cells by Immunocytochemistry/ Immunofluorescence.The 293 FT cells were cultured for 3 days then fixed with 3.7% formaldehyde for 10 minutes and blocked with 5% BSA in PBS for 1 hour at +4°C. The cells were incubated with the primary antibody at 1/200 dilution overnight at +4°C. The secondary antibody (green) was Alexa Fluor® 555 Goat anti-Rabbit IgG used at a dilution of 1/200.\nab27969 staining TGF beta 1 in Human ureter tissue sections by Immunohistochemistry (IHC-Fr - frozen sections). Tissue was fixed with paraformaldehyde and blocked with 1% serum for 30 minutes at 20°C. Samples were incubated with primary antibody (1/150) for 16 hours at 4°C. A Cy2®-conjugated Goat anti-mouse polyclonal (1/200) was used as the secondary antibody.\nReferences for Anti-TGF beta 1 antibody [TB21] (ab27969)\nThis product has been referenced in:\n- Du JX et al. Ingredients of Huangqi decoction slow biliary fibrosis progression by inhibiting the activation of the transforming growth factor-beta signaling pathway. BMC Complement Altern Med 12:33 (2012). IHC-Fr ; Rat . Read more (PubMed: 22471627) »\n- Ishikawa K et al. Development of a preclinical model of ischemic cardiomyopathy in swine. Am J Physiol Heart Circ Physiol 301:H530-7 (2011). WB ; Pig . Read more (PubMed: 21551276) »"", 'Primary beta islet insulin ELISA Measured in Cell-Based System Using Plate Reader - 2061-09_Inhibitor_Dose_DryPowder_Activity\nThis assay measures glucose-induced insulin secretion, the gold standard for beta-cell function. The insulin stimulatory index can be measured by ELISA, after 1-hour incubation with ""high glucose"" (typically 16.7 mM) in the experimental buffer, in comparison with ""low glucose"" (typically 1.67 mM). The rat INS-1E cell line is derived from a clone selected for high levels of insulin secretion in more ..\nBioActive Compound: 1\nKeywords: insulin, beta cell, ELISA, primary human pancreatic beta islets\nThis assay measures glucose-induced insulin secretion, the gold standard for beta-cell function. The insulin stimulatory index can be measured by ELISA, after 1-hour incubation with ""high glucose"" (typically 16.7 mM) in the experimental buffer, in comparison with ""low glucose"" (typically 1.67 mM). The rat INS-1E cell line is derived from a clone selected for high levels of insulin secretion in response to glucose, and thus serves as a good model of beta-cell function. Beta cells treated with cytokines lose their insulin secretory response to glucose. Small molecules that can promote beta-cell survival should restore insulin secretion.\nCell and Human Islet Culture. Human islets were obtained through the Islet Cell Resource Consortium (http://icr.coh.org/) and through the National Disease Research Interchange (http://www.ndriresource.org/). The purity and viability of human islets are reported to be 70-93% and 70-98%, respectively, and the average age of cadaveric donors was 40.7 +/- 9.0 y (range 32-57 y; n = 6). Islets were washed with PBS and incubated in CMRL medium supplemented with 10% FBS, 2 mM glutamine, 100 U/mL penicillin, and 100 ug/mL streptomycin. Islets were gently dissociated into a cell suspension by incubating in Accutase (37 deg C, 10 min), and seeded in 96-well plates containing extracellular matrix secreted by the HTB-9 human bladder carcinoma cell line.\nPrimary human islets were incubated for 6 days in 100 uL of fresh RPMI containing 1% FBS and the cytokine cocktail, in the presence or absence of compounds. Media was refreshed after 3 days. Cells were washed and incubated for 2 h in KRBH (135 mM NaCl, 3.6 mM KCl, 5 mM NaHCO3, 0.5 mM NaH2PO4, 0.5 mM MgCl2, 1.5 mM CaCl2, 10 mM HEPES, pH 7.4, 0.1% BSA) without glucose. Cells were subsequently incubated with KRBH containing 2 or 15 mM glucose for 1 hour. The supernatant was taken for measurement of released insulin. Insulin was measured with a rat insulin ELISA kit (Alpco).\nALPCO INSULIN ELISA PROTOCOL\nBring all reagents and microplate strips to room temperature prior to use. Gently mix all reagents before use. A standard curve must be performed with each assay and with each microplate if more than one is run at a time. All standards, samples, and the control should be run in duplicate.\n1. Ensure that microplates are at room temperature prior to opening foil pouch. Designate enough microplate strips for the standards, desired number of samples, and control. The remaining strips should be stored at 2-8 deg C in the tightly sealed foil pouch containing the desiccant.\n2. Pipette 5 ul of each standard, reconstituted control (see Reagent Preparation), or sample into its respective wells.\n3. Pipette 75 ul of Working Strength Conjugate (see Reagent Preparation) into each well.\n4. Incubate for 2 hours, shaking at 700-900 rpm on a horizontal microplate shaker at room temperature (18-25 deg C).\n5. Wash the microplate 6 times with Working Strength Wash Buffer (see Reagent Preparation) with a microplate washer. Alternatively, use a wash bottle to fill the wells, and then discard the liquid, inverting and firmly tapping the microplate on absorbent paper towels between washes. After the final wash with either the microplate washer or wsah bottle, remove any residual Wash Buffer and bubbles from the wells by inverting and firmly tapping the microplate on absorbent paper towels (See Microplate Locking Diagram below).\n6. Pipette 100 ul of TMB Substrate into each well.\n7. Incubate for 15 minutes at room temperature (18-25 deg C) on a horizontal microplate shaker (700-900 rpm).\n8. Pipette 100 ul of Stop Solution into each well. Gently shake the microplate to stop the reaction. Remove bubbles before reading with microplate reader.\n9. Place the microplate in a microplate reader capable of reading the absorbance at 450nm with a reference wavelength of 620-650nm. The microplate should be analyzed within 30 minutes following the addition of Stop Solution.\nPRESENCE OF CONTROLS: Neutral control wells (NC) and positive control wells (PC) were included on every plate. The positive control condition was absence of cytokine.\nEXPECTED OUTCOME: Active compounds result in increasing readout signal.\nACTIVE CONCENTRATION LIMIT:\nFor each sample, the highest valid tested concentration (HVC) was determined and the active concentration limit (AC_limit) was set to equal (10)(HVC).\nA standard curve run was run on each assay plate using reference material provided in the ELISA kit. Background-subtracted absorbance values were calculated for each well as (Abs450 - Abs620), and used to extrapolate quantity of insulin secreted in micro International Units (uIU) from the standard curve. No further data normalization methods were applied.\nPATTERN CORRECTION: No plate pattern correction algorithm from Genedata Condoseo (v.7.0.3) was applied.\nMEASUREMENT USED TO DETERMINE ACTIVE CONCENTRATION(AC): AC50\nAC values were calculated using the curve fitting strategies in Genedata Screener Condoseo (7.0.3).\nAC values were calculated up to the active concentration limit described for each sample.\nActivity_Outcome = 1 (inactive) when:\na) curve fit is constant where activity is > -30% and < 30% at all tested concentrations, or\nb) AC > AC_limit, or\nc) compound shows activity but in a direction opposite to the expected outcome\nin these cases, values describing curve fitting parameters (Sinf, S0, Hill Slope, log_AC50, log_AC50_SE) are set to null\nActivity_Outcome = 2 (active) when:\nAC <= AC_limit\nActivity_Outcome = 3 (inconclusive) when:\na) Curve fitting strategy resulted in a constant fit with activity >= 30% but <= 70%, or\nb) The fit was not valid due to poor fit quality.\nPUBCHEM_ACTIVITY_SCORE = 0 when PUBCHEM_ACTIVITY_OUTCOME = 1 (inactive) or 3 (inconclusive)\nPUBCHEM_ACTIVITY_SCORE = (-10)[Log(AC)], where AC is in molar, when PUBCHEM_ACTIVITY_OUTCOME = 2 (active)\nScores relate to AC in this manner:\n120 = 1 pM\n90 = 1 nM\n60 = 1 uM\n30 = 1 mM\n0 = 1 M\nPUBCHEM_ACTIVITY_SCORE = 100 when the curve fit is constant and showing full inhibition at all tested concentrations.\nThe individual dose data point columns (\'Activity_at_xxuM\') reported here represent the median of valid (unmasked) replicate observations at each concentration. These values are the inputs to a curve fitting algorithm.\nAll other data columns represent values which are derived during the curve fitting algorithm; this may sometimes include automatic further masking of some replicate data points.\nOccasionally this results in perceived inconsistencies: for example, between the derived \'Maximal_Activity\' and the apparent most active data point.\nCategorized Comment - additional comments and annotations\n* Activity Concentration. ** Test Concentration.\nData Table (Concise)']"	['<urn:uuid:ae44ce40-028c-421d-b346-b8e59d9bbdbc>', '<urn:uuid:aa02dce2-1a5d-4501-b68a-0e3172610c3b>']	open-ended	direct	short-search-query	distant-from-document	multi-aspect	expert	2025-05-12T22:49:38.933606	6	89	1996
70	As an architect interested in healthcare facilities, I'm curious about how many internal courtyards were incorporated into the new Dumfries hospital design for therapeutic purposes?	The design creates 17 courtyards and gardens which function as places of rest and healing as well as provide views from inside.	['UK’s ‘garden hospital’ welcomes first patients in time for 70th anniversary of the NHS\nRyder Architecture and NBBJ have collaborated on the design of the newly-completed Dumfries and Galloway Royal Infirmary as part of the High Wood Health consortium for NHS Dumfries and Galloway.\nThe new 63,500sq m replacement hospital is located on a greenfield site on the outskirts of the Scottish town of Dumfries and includes 344 beds, day case and inpatient surgical suites, an emergency care centre, ambulatory care centre, specialist oncology, maternity and paediatric facilities.\nThe opening of the new hospital coincides with the 70th anniversary of the NHS next year.\nThe £212m project is designed to meet the increasingly-sophisticated healthcare needs of the region’s ageing population.\nIt is conceived as a ‘garden hospital’, with a design focused on light and landscape made possible by its rural setting.\nThe low-rise design with pitched roofs breaks up the mass of the building, allowing it to sit harmoniously within its surroundings.\nThe design also creates 17 courtyards and gardens which function as places of rest and healing as well as provide views from inside.\nThe emphasis on outdoor spaces is based on scientific research that shows a connection between natural elements and positive health outcomes, including lower stress levels, reduced blood pressure, the need for patients to take less medication, and even-faster healing times.\nThe hospital is person-centred, considering staff as well as patients and promoting an uplifting, positive experience for all who use the building. This is achieved through an emphasis on natural daylight and intuitive wayfinding throughout the hospital.\nThe main entrance atrium is a welcoming civic space, lit from above by a long row of skylights, along with a large bay window providing sweeping views across the surrounding countryside.\nLight courts throughout the inpatient pavilions allow for clear views across wards for both patients and staff, opening up interiors and filling spaces with natural daylight, avoiding a sense of isolation for patients.\nLandscape design, in collaboration with Fira, promotes integration between the external and internal spaces.\nWards are surrounded by garden spaces, some of which play an integral part in therapeutic practice, and palliative care bedrooms have their own private gardens, with dedicated space for beds to be wheeled outside, allowing patients to experience the external environment.\nPaul Bell, partner at Ryder Architecture and design team leader, said: “The new hospital is a great example of what can be achieved by effective collaboration, a pioneering approach to technology, and a passion to deliver to the highest quality.\n“That approach has delivered our collective vision for a new hospital without compromise, an uplifting people-centred environment connected to its wonderful landscape setting for the effective and efficient delivery of healthcare for the people of Dumfries and Galloway.’’\nJane McElroy, principal at NBBJ and lead clinical designer for the new hospital, added: “Hospitals are increasingly focused on creating environments that improve the experience for patients, families and staff.\n“With the themes of comfort and wellbeing foremost in our minds, we have designed a therapeutic and inspirational new hospital for Dumfries, one that serves as a prototype for other healthcare developments in the future.”\nThe building comprises three distinct elements:\nExternally the building has been designed to be sympathetic to its rural Scottish environment.\nThe facades of the central block are clad in honey-coloured pre-cast panels that mirror the local Glasgow Blonde stone, while the inpatient pavilions and the women and children’s centre feature a reconstituted stone finish reminiscent of white ‘Galloway’ granite, in a nod to the region’s heritage.\nIn the central building, medical facilities include an Integrated Emergency Care Centre, comprising an accident and emergency facility (A&E), a combined assessment unit, and fracture and orthopaedic unit; critical care units, an oncology centre, an ambulatory care centre, and a surgical complex with eight operating theatres and four endoscopy procedure suites.\nOpen, social spaces have been designed to encourage patients to move around, and circulation routes include rest spaces for older patients, as well as areas intended to promote interaction between staff from different departments.\nOutdoor space is key to the design of the new hospital\nCirculation routes in the hospital are segregated by floor to facilitate maximum efficiency, avoiding clashes, so that outpatient and visitor flow is largely confined to the ground floor, while inpatient flow, linking the maternity and surgical wards to the operating suites and critical care centre, is on the first floor.\nTraffic from facilities and hospital management happens on the lower-ground level. These circulation routes are designed with clear wayfinding features, which facilitate efficient movement of traffic both inside and out.\nThe entrances to the main block and the accident and emergency centre can both be seen clearly upon approaching the hospital, creating a ‘decision point’ for people arriving at the campus, providing a clear route to those needing to access emergency care.\nThe hospital, constructed by Laing O’Rourke, with WSP acting as structural engineer and Hoare Lea as mechanical and electrical engineer, will serve many small, widespread and diverse communities within the 2,400 square miles covered by NHS Dumfries and Galloway in Scotland’s South West.\nThe hospital is on track to achieve a BREEAM Excellent rating.']	['<urn:uuid:4a309366-dddc-4ab0-9786-176418712690>']	factoid	with-premise	verbose-and-natural	distant-from-document	single-doc	expert	2025-05-12T22:49:38.933606	25	22	862
71	As someone dealing with mortgage defaults, I'd like to know what options are available to mortgage bond investors when borrowers default, and how does this compare to traditional lender foreclosure rights?	When borrowers default on mortgages backing mortgage bonds, investors can choose to foreclose on the home and sell the property to recover the debt, since mortgage bonds are backed by real property. Similarly, in traditional lending, when borrowers fail to make two or more monthly mortgage payments (default), lenders have the right to initiate foreclosure proceedings and take possession of the property, though many lenders try to find solutions first since foreclosure is expensive.	['Real Estate Glossery\nListed below are brief descriptions of some common terms used in real estate transactions. These are general terms and definitions and are not intended to apply to all possible uses of a term. Please let us know if you have any questions regarding these items.\nAccelerated Clause: Loan verbiage that provides the lender with the right to demand payment of the entire outstanding balance on your home loan, if you miss a monthly payment, sell the home, or otherwise fail to perform as promised under terms of your mortgage.\nAdjustable Period: The length of time between interest rate changes on an ARM. For example, a loan with an adjustable period of one year is called a one-year ARM, which means that the interest rate can change once per year.\nAdjustable Rate Mortgage (ARM): A mortgage that permits the lender to adjust the interest rate periodically on the basis of changes in a specified index. See Fixed-rate Mortgage.\nAdjustment Period: How often the rate of an adjustable rate mortgage adjusts (see Adjustable Rate Mortgage).\nAffidavit: A sworn statement in writing, made before an authorized official.\nALTA: Abbreviation for the American Land Title Association.\nAmortization: Repayment of a loan in equal installments of principal and interest rather than interest only payments.\nAnnual Percentage Rate (APR): The total finance charge (interest, loan fees, points expressed as a percentage of the loan amount).\nAppraisal: A written analysis of the estimated value of a property prepared by a qualified appraiser.\nAppreciation/depreciation: Refers to either the increase (appreciation) or the decrease (depreciation) in a home’s value.\nAssessed value: The value of a property according to your local tax assessor; determines how much you will pay in property taxes.\nAssessments: Specific and special taxes (in addition to normal taxes) imposed on real property to pay for public improvements within a specific geographic area.\nAssumption of Mortgage: A buyer’s agreement to assume the liability on an existing note that is secured by a mortgage or deed of trust. The lender must approve the buyer in order to assume the loan.\nAttorney-in-Fact: An agent authorized to act for another under a power of attorney.\nBalloon Loan: Requires level payments just as a 15-year or 30-year fixed rate loan. But well before the date it becomes due, the full remaining balance of the loan comes due. Though they can be economical at the outset, beware of balloon loans – you may not be able to refinance the loan.\nBalloon Payment: A lump sum principal payment due at the end of some mortgages or other long-term loans.\nBinder: Sometimes known as an offer to purchase or an earnest money request. A binder is the acknowledgement of a deposit along with a brief written agreement to enter into a contract for the sale of real estate.\nBiweekly payment mortgage: A mortgage requiring payments every two weeks instead of the standard monthly payment. The result is a substantial savings in interest.\nBridge loan: If you close on a home before completing the sale of your existing home (not an ideal circumstance by anyone’s estimation), you may need to obtain a bridge loan.\nBroker: A person who, for a commission or fee, brings parties together and assists in negotiating contracts between them.\nBuydown: A Veteran’s Administration loan plan available only in some new housing developments. A builder agrees to pay part of the mortgage for the first few yeas. Sellers also may create buydowns by paying lenders a predetermined amount of money so lenders will reduce their interest rates.\nBuyer’s agent: A person licensed to negotiate and transact the sale of real estate on behalf of the buyer. The buyer’s broker or agent owes allegiance only to the buyer and does not have an agent relationship with the seller.\nCap: The limit of how much the interest rate or monthly payment can change either at each adjustment or over the life of the mortgage.\nCash reserves: Lenders typically require buyers to have enough cash left over after purchasing a home to make two mortgage payments, to cover a financial emergency.\nCertificate of Reasonable Value (CRV): A document that establishes the maximum value and loan amount for a VA guaranteed loan.\nCertificate of Title: A statement provided by an abstract company title or attorney stating that the title to real estate is legally held by the current owner.\nClosing: A meeting at which a sale of a property is finalized by the buyer signing the mortgage documents and paying closing costs.\nClosing Costs: Generally total from 2 percent to 5 percent of the home’s purchase price; separate from the down payment. Covers a number of costs including loan document processing fees, appraisal report fees, credit report fees, etc.\nClosing Statement: The financial disclosure statement that accounts for all of the funds received and expected at the closing of the escrow, including deposits or taxes, hazard insurance and mortgage insurance.\nCollateral: An asset (such as a car or home) that guarantees the repayment of a loan.\nCommission: The fee charged by a broker or agent for providing services related to a real estate transaction such as procuring the property, bringing the parties together and negotiating a purchase contract or loan.\nCommunity Property: One way to hold title to your home.\nCondominium: A form of real estate ownership. The owner receives title to a particular unit and has a proportionate interest in certain common areas. The unit itself is generally a separately owned space whose interior surfaces (walls, floors, and ceilings) serve as its boundaries.\nContingencies: Conditions, contained in the Purchase Agreement, which outline the obligations the seller and buyer must fulfill before sale of the property is completed. Can concern the results of your effort to obtain financing, an inspector’s opinion of the condition of the property, etc. For instance, a sales agreement may be contingent upon the buyer obtaining financing.\nConventional Loan: A mortgage loan, which is not insured or guaranteed by a governmental agency.\nConversion Clause: A provision in some ARMs that enables you to change an ARM to a fixed-rate loan, usually after the first adjustment period. The new fixed rate is generally set at the prevailing interest rate for fixed rate mortgages. This conversion feature may cost extra.\nCooperative: A form of multiple ownership in which a corporation or business trust entity holds title to a property and grants occupancy rights to shareholders by means of proprietary leases or similar agreements.\nCosigner: If your credit is less than stellar, it may be necessary for you to have a cosigner – that is a friend or relative willing to assume the risk (and actual indebtedness for) your mortgage.\nCredit Report: The main basis for a lender to determine your “credit worthiness.” A historical list of your credit use and bill payment performance.\nDebt-to-income Ratio: When you apply for a mortgage, the lender looks at the amount of debt you will have relative to your income. Acceptable limits generally range from 33 to 40 percent.\nDeed: Written instrument by which the ownership of land is transferred from one person to another.\nDefault: You are officially in default when you fail to make two or more monthly mortgage payments on time. This does not automatically indicate that you will lose your home, however. Many lenders will help you work to find a solution, as foreclosure is expensive for the lender.\nDelinquency: Comes before default. Your loan is in delinquency when you fail to provide one month’s mortgage payment on time.\nDeposit Receipt: Used when accepting “Earnest Money” to bind an offer for property by a prospective purchaser; also includes terms of a contract.\nDown Payment: Percentage of the purchase price you will provide in cash up front.\nDue on Sale Clause: An acceleration clause that requires full payment of a mortgage or deed of trust when secured property changes ownership.\nEarnest Money: The portion of the down payment delivered to the seller or escrow agent by the purchaser with a written offer as evidence of good faith.\nEasement: A right created by grant, reservation, agreement, prescription, or necessary implication, which one has in the land of another.\nEscrow: A procedure in which a third party acts as a stakeholder for both the buyer and the seller, carrying out both parties’ instructions and assuming responsibility for handling all of the paperwork and distribution of funds.\nExclusive listing: A written contract that gives a licensed real estate agent the exclusive right to sell a property for a specified time, but reserving the owner’s right to sell the property himself without the payment of a commission.\nFair Credit Reporting Act: A consumer protection law that regulates the disclosure of consumer reports by consumer/credit reporting agencies and establishes procedures for correcting mistakes on one’s credit record.\nFederal National Mortgage Association: Popularly known as Fannie Mae. A privately owned corporation created by Congress to support the secondary mortgage market. It purchases and sells residential mortgages insured by FHA or guaranteed by VA, as well as conventional home mortgages.\nFee Simple: An estate in which the owner has unrestricted power to dispose of the property as he wishes, including leaving by will or inheritance. It is the greatest interest a person can have in real estate.\nFHA Loan (Federal Housing Administration): A federal agency, created by the National Housing Act of 1934, for the purpose of expanding and strengthening home ownership by making private mortgage financing possible on a long-term, low down payment basis. The vehicle is a mortgage insurance program, with premiums paid by the homeowner, to protect lenders against loss on these higher risk loans. Since 1965, FHA has been part of the newly created department of Housing and Urban Development (HUD).\nFinance Charge: The total cost a borrower must pay, directly or indirectly, to obtain credit.\nFixed-rate Mortgage: A mortgage whose interest rate is locked in for the life of the loan, which commonly ranges from 15 to 30 years in duration. See Adjustable Rate Mortgages (ARMs).\nForeclosure: The legal process of the mortgage lender taking possession of and selling the property. When you default on a loan and the lender determines you are incapable of making payment, you may lose your house to foreclosure.\nFormula: The way in which interest rates are calculated on Adjustable Rate Mortgages. Add the margin to the index to get the interest rate.\nGraduated Payment Mortgage: A residential mortgage with monthly payments that start at a low level and increase at a predetermined rate.\nGrant: A transfer of real property.\nGrantor: The person who makes a grant.\nHome Inspection: A thorough inspection that evaluates the structural and mechanical condition of a property.\nHome Inspection Report: A qualified inspector’s report on a property’s overall condition. The report usually covers an evaluation of both the structural and mechanical systems.\nHomeowner’s Insurance: Absolutely required to obtain a mortgage, it covers the cost to rebuild your home.\nIndex: The measure of interest rate changes used to determine adjustments in an ARM’s interest rate over the term of the loan.\nInterest Rate: The percentage fee lenders charge you to use their money. The higher the rate of interest, the higher the risk. For fixed rate mortgages, the interest rate has a corresponding relationship with the points. A high number of points will lower the rate and vice versa. With an adjustable rate mortgage, understand the formula (the index plus the margin) that determines how the interest rate is calculated, after the teaser rate expires.\nLate Charge: What the mortgage company will add on to your payment if it is received late. Can be as high as 5 percent of the total payment.\nLien: A legal hold or claim on property as security for a debt or charge.\nLife Cap: Determines the total amount that your adjustable mortgage interest rate and monthly payment can fluctuate during the duration of the loan. Different from the Periodic Cap, which limits the extent to which your interest rate can fluctuate during a predetermined adjustment period.\nLoan Commitment: A written promise to make a loan for a specified amount on specific terms.\nLoan to Value Ratio: The relationship between the amount of the appraised value of the property, expressed as a percentage of the appraised value.\nLock-in: A written agreement in which the lender guarantees a specified interest rate if a mortgage goes to closing within set period of time.\nMargin: The number of percentage points the lender adds to the index rate to calculate the ARM interest rate at each adjustment.\nMortgage: A legal document that pledges a property to the lender as security for payment of a debt.\nMortgage Banker: A company or individual engaged in the business of originating mortgage loans with its own funds, selling those loans to long term investors, and servicing the loans for the investor until they are paid in full.\nMortgage Broker: A person who buys mortgages wholesale from lenders and then sells them to buyers. Can “shop your loan around” to find the best rate. Good for people with less-than-stellar credit histories.\nMortgage Insurance: A contract that insures the lender against loss caused by a mortgagor’s default on a government mortgage or conventional mortgage.\nMultiple Listing Service (MLS): A cooperative listing of nearly all the homes on the market for real estate agents.\nNegative Amortization: Occurs when monthly payments fail to cover the interest cost. The interest not covered is added to the unpaid principal balance so that even after several payments, you could owe more than you did at the beginning of the loan.\nPartnership: Way in which unmarried individuals can take title to a property. Can include domestic partners or business partners. It’s recommended that a real estate lawyer first draw up a written partnership agreement before the purchase.\nPeriodic Cap: Limits the amount that the interest rate of an Adjustable Rate Mortgage can change in one adjustment period.\nPlanned Unit Development (PUD): A zoning designation for property developed at the same or slightly greater overall density than conventional developments, sometimes with improvements clustered between open, common areas.\nPoint: An amount equal to one percent of the principal amount of the investment or note. The lender assesses loan discount points at closing to increase the yield on the mortgage to a position competitive with other types of investments.\nPre-Payment Penalty: A fee charged to a mortgagor who pays a loan before it is due. Not allowed for FHA or VA loans.\nPrime rate: The interest that banks charge to their preferred customers.\nPrincipal: The amount borrowed or remaining unpaid.\nPrivate Mortgage Insurance (PMI): Insurance written by private companies protecting the lender against loss if the borrower defaults on the mortgage.\nProbate sale: Sale of a home after a homeowner dies and the property is to be divided among inheritors or sold to pay debts. The executor of the estate organizes the sale, and a probate court judge oversees the process. The highest bidder receives the house.\nProperty Tax: Averages between 1 and 2 percent of a home’s value but may vary by county.\nProrations: Items that must be prorated between you and the seller at the close of escrow. Can include Homeowner’s dues, property taxes and other expenses. Generally, you will be responsible for paying a percentage of these taxes and fees beginning on the day you take title.\nReal Estate Agent: Real estate salespeople who are supervised by a real estate broker. Licensed by the state; typically receive income from commissions.\nRealtor®: A real estate broker or associate active in a local real estate board affiliated with the National Association of Realtors®.\nRecordation: Filing for record in the office of the county recorder.\nRefinance: Taking out a new mortgage loan to receive more favorable terms. Generally recommended for fixed-rate mortgages if rates drop below 1 percent of what you’re currently paying. However, refinancing can be expensive and time-consuming, so you’ll want to consider this action carefully, and to ask yourself how long you plan to own the property.\nShort Sale: A property that sells for less than the balance owing on its mortgage. A short sale can be an underwater home, an apartment building or even vacant land. If there is a mortgage balance that is greater than the market value of the home, that property is a short sale.\nTax Deductible: Payments that you may deduct against your federal and state taxable income; includes the interest portion of your mortgage payments, loan points and property taxes.\nTeaser Rate: Introductory, lower rate on an adjustable rate mortgage. The loan’s formula is a better way to determine its affordability, however.\nTitle: Evidence of a person’s right or the extent of his or her interest in the property.\nTitle Insurance Policy: A policy that protects the purchaser, mortgagee or other party against loss arising from disputes over title to the property.\nTruth in Lending: A federal law that requires lenders to fully disclose, in writing, the terms and conditions of a mortgage, including the annual percentage rate and other charges.\nVA Loan: A loan that is partially guaranteed by the Veterans Administration but is made by a private lender.\nVeterans Administration (VA): An independent agency of the federal government created by the Service Men’s Readjustment Act of 1944 to administer a variety of benefit programs designated to facilitate the adjustment of returning veterans to civilian life. Among the program’s benefits is the home loan guaranty program designated to encourage mortgage lenders to offer long term low down payment financing to eligible veterans by guaranteeing the lender against loss on these higher-risk loans.', 'Mortgage Bonds: Definition, Function And Guide To The Mortgage Bond Market\nKatie Ziraldo3-minute read\nMay 24, 2021\nThose who are new to financial investments may be surprised to learn just how many investment opportunities are out there. The wide range of options can be exciting, but also overwhelming when you’re trying to make the best use of your money.\nOne relatively safe, secure investment option lies in the mortgage bond market. But what exactly are mortgage bonds and how do they work? In this article, we will explore the basic pros, cons and overall impact of purchasing mortgage bonds.\nWhat Is A Mortgage Bond?\nBecause mortgage bonds are backed by real property, they are often considered a low-risk investment, because in the case of foreclosure, the property can be sold to recover the debt. The sale of your mortgage usually occurs immediately after your home’s closing. When this happens, your mortgage is bundled with others, and shares of the bundle are sold to investors.\nInvestors can make money from mortgage bonds in a few ways. In addition to collecting interest on mortgage payments, investors can also earn money from payments toward the principal balance. And if the borrower defaults, the investor can even choose to foreclose on the home.\nHow Do Mortgage Bonds Work In The Real Estate Market?\nIt’s very rare for lenders to retain ownership of a mortgage. More likely, the lender secures mortgages into mortgage-backed securities (MBS) to sell in the secondary market, typically to investment banks or government-sponsored enterprises (GSE).\nGSEs are financial services corporations that were created by the U.S. government in order to boost the flow of credit within the economy. The most notable of these GSEs are Fannie Mae and Freddie Mac, which assist the real estate market by helping investors and homeowners securely invest in real estate. Once the GSE is in possession of the mortgage, it packages it within a pool of other loans and begins issuing bonds with the mortgages as the backing.\nHow Can Bonds Affect Mortgage Rates?\nAlthough corporations can issue private bonds, it is much more common for bonds to be provided by the federal government, referred to as Treasury bonds. Treasury bonds affect more than just the investor, as the bond market has a direct impact on mortgage rates. There is an inverse relationship between mortgage rates and the bond market – meaning if bond prices are low, rates will be high and vice versa.\nThis has to do with the supply and demand of the bond market. Most mortgage lenders aim to keep their interest rates a few notches higher than bond interest rates, as they tend to attract similar investors. But when bond prices drop, bond interest rates rise – which will ultimately lead to a rise in mortgage rates as well.\nShould You Invest In The Mortgage Bond Market?\nNow that you understand mortgage bonds and how they function in the real estate market, you may be wondering if this type of investment is viable for you. Before any financial investment, it’s crucial to look at both the benefits and potential drawbacks – so let’s take a look at the biggest pros and cons of investing in the mortgage bond market.\n- Recurring interest payments from homeowners can provide reliable and safe income for investors\n- Bondholders can sell off a foreclosed property if a borrower defaults on their mortgage\n- Mortgage bonds are safer investments than treasury bonds because they are secured by real property and the U.S. government\n- Yields tend to be lower than corporate bond yields\n- Investors can lose money if a borrower pays off their loan early\n- If a borrower defaults on their mortgage, investors risk losing the collateral\nThe Bottom Line\nBecause they’re secured by real property and GSEs, mortgage bonds are considered one of the most low-risk investment opportunities available. As always, we recommend taking a deep dive into your budget and finances before choosing to invest – but making the right investment can put you one step closer to a stronger financial future.\nWant to continue learning about mortgages and homes? Read more homeowner tips in the Rocket Homes® Homeowner Guide!']	['<urn:uuid:7f6e0a25-f6f8-4041-8370-6e17a3401b35>', '<urn:uuid:3371f93f-15e3-492f-bc40-52aeb553b05b>']	factoid	with-premise	verbose-and-natural	similar-to-document	multi-aspect	expert	2025-05-12T22:49:38.933606	31	74	3621
72	indigenous artwork documentation collection locations midwest	Several significant indigenous artwork collections exist in the Midwest region. The Art Institute of Chicago houses extensive Western and Native American art collections, including works from the late 19th and early 20th centuries. In southern Illinois, the Millstone Bluff Archaeological Area contains petroglyphs from Mississippi and Woodland tribes, featuring thunderbird symbols and other figures. In Missouri, Washington State Park holds the state's largest collection of ancient rock carvings created about 1,000 years ago. Wisconsin's Roche-a-Cri State Park protects Ho-Chunk ancestors' petroglyphs featuring birds, canoes, and geometric designs on a 300-foot outcrop.	"['Chicago Imagine an exhibition of Southwestern art without a single coyote howling beside a saguaro cactus. And now imagine that exhibition in shingle-flat Chicago, where the manmade landscape seems a world removed from the arroyos and mesas of New Mexico.\n""Window on the West: Chicago and the New Frontier, 1890-1940,"" is just that exhibition -- a look at the pivotal role Chicago\'s philanthropists, railroaders and politicians played in encouraging and subsidizing successive waves of Southwestern artists.\nThe show on view at the Art Institute of Chicago presents more than 115 works on the West by 19th- and 20th-century artists with connections to Chicago. Many of the paintings, sculptures and drawings are from the museum\'s own collection but had not been on public display in 40 or 50 years. Some of the works are from the Ayer collection of the Newberry Library in Chicago.\nThe almost-forgotten works fascinated curator Judith Barter, who described one of her greatest pleasures as simply ""rooting around storage."" It was while researching the Art Institute\'s large collection of paintings and bronzes by popular artist Frederic Remington that Barter realized just how much Western art was in those storage rooms.\n""I discovered that Chicago was a crucial center in creating and fostering the country\'s image of the West,"" Barter said.\nActs of preservation\nThat relationship, she said, was cemented in 1893 when historian Frederick Jackson Turner presented his influential paper, ""The Significance of the Frontier in American History."" Jackson\'s paper, which was presented at the building that soon became the Art Institute, announced the closing of the frontier and gave notice that the Old West was coming to an end.\nCoupled with the interest in the ethnographic pictures of Native Americans produced for the World\'s Columbian Exposition of that same year, Jackson\'s paper sent many artists westward in search of something vanishing and irreplaceable.\nMany of those artists had subsidies from Chicago businessmen, particularly from lumber baron and self-taught scholar Edward E. Ayer, who began his career as an illiterate teenage cavalryman in the Southwest during the Civil War. It had been Ayer\'s duty to fight Indians, but when he learned to read, he became a student of their various cultures.\n""We have simply destroyed a great race of human beings, in many virtues our superiors,"" Ayer wrote in the 1890s. To help preserve what was left of the tribes of the Southwest and to propagandize on their behalf, Ayer dispatched artists, including his nephew, Elbridge Ayer Burbank, into the region.\nOther artists to enjoy Ayer\'s patronage included sculptor Hermon Atkins MacNeil and his painter friend, Charles Francis Browne. Along with Burbank, they were among the first white Americans to witness and document the Hopi Snake Dance.\nCowboy was king\nThe next generation of Southwestern artists also had Chicago patrons. Restaurateur Frederick Henry Harvey, who ran the Santa Fe dining cars, as well as restaurants, inns and resort hotels along its route, wanted to decorate his facilities in Southwestern style and was willing to pay artists generously to do so. Even more financial support came from Carter H. Harrison Jr., a progressive Democrat who served five terms as Chicago mayor, from 1897 to 1915.\nHarrison\'s father, also a five-term mayor of Chicago, was assassinated in 1893, a few months after Jackson delivered his paper. The senior Harrison had land holdings in the West, and his son spent much of his youth in New Mexico, becoming an accomplished ethnographic photographer. As mayor, he offered financial support to Chicago artists willing to live and work in Taos, N.M. Those painters, who included Walter Ufer and Victor Higgins, practiced a form of sun-drenched realism and became the core of the Taos Society of Artists.\nIn the early years, the artists sent West from Chicago concentrated on American Indians, but that all changed in 1915, when the erudite Harrison was succeeded by another Western-reared Chicagoan, William Hale ""Big Bill"" Thompson. The bullnecked Thompson was an isolationist Republican who once made a campaign promise to punch the king of England in the nose if His Majesty ever dared visit Chicago. He eventually became an ally of Al Capone.\nTo Thompson, who had ranched in Nebraska and Wyoming, the cowboy was king. And his right-hand man, George F. Harding Jr., was an even bigger cowboy fan. At his South Side ""castle,"" Harding assembled what he called his ""red-blooded"" art collection, which consisted of medieval weapons, plus a great number of Remington\'s Western paintings and cowboy bronzes. Most of them eventually made their way to the Art Institute, and many are now on display.\nLater rooms of the exhibition are devoted to the Santa Fe School of the World War I years and 1920s, where the influence of the French postimpressionists can be seen. Many of those artists, like Gustave Baumann, had been sent West by Harrison.', 'Archeologists study them, and tourists marvel at them. Petroglyphs are some of our world’s most ancient art, etched into caves, canyons, hillsides, and boulders by indigenous people hundreds, and sometimes thousands, of years ago. Some depict animals or people, while the meanings of other symbols are less clear.\nHere are some of the most spectacular spots in America to see these mysterious markings. Many petroglyphs are located in parks designed to protect them. Remember, if you go, be respectful — leave nothing behind, take nothing with you, and don’t touch — to help keep these historic sites beautiful for generations to come.\nNine Mile Canyon, Utah\nThere’s a reason this place is often called “the world’s longest art gallery.” The 46-mile-long canyon is filled with rock art created by the Archaic, Fremont, and Ute peoples.\nThis amazing spot is located about 2 hours from Salt Lake City, and it makes a perfect day trip. It is, however, quite remote. Make sure to gas up and bring plenty of water and snacks with you. While you can easily see the area’s petroglyphs from your car, it’s worthwhile to park and take a closer look during your canyon cruise. There’s no cost to access the site.\nCanyonlands National Park, Utah\nHorseshoe Canyon, a part of Canyonlands National Park, is a marvel that is home to both petroglyphs and pictographs (painted images). The Great Gallery — Horseshoe Canyon’s most impressive sight — features life-size figures and amazing designs in a display that’s more than 200 feet long. Believed to have been created by hunter-gatherer tribes thousands of years ago, it’s a dazzling display of rock art.\nGetting to the canyon, however, is tough: It’s a long drive on a dirt road to reach the trailhead (3 hours and 30 minutes from Moab, Utah, the nearest city), and the road can be impassable during storms. From the trailhead, you must hike 7 miles to the Gallery and back. Do not attempt the hike in the summer, since temperatures can easily reach well over 100 degrees, and there are no services or amenities. Yes, it’s a daunting journey. Yes, you will need to plan ahead to get there. And yes, it’s completely worth it.\nPetroglyph National Monument, New Mexico\nLocated in Albuquerque, New Mexico, Petroglyph National Monument was set up to protect one of the largest ancient art sites in North America. Scientists estimate that there may be more than 25,000 individual etchings in the park; these etchings are thought to be the handiwork of the ancestors of the Pueblo people.\nStart your day at the visitor center to learn more about these people and their art, and then hit the trails. There are four hikes available, ranging in both length and difficulty. Three of them will allow you to get up close and personal with hundreds of petroglyphs. The park is open year-round, and admission is free.\nEl Morro National Monument, New Mexico\nEl Morro National Monument was once a stopover spot of sorts, a place where desert travelers could find shelter, food, and a place to rest. Thousands of years ago, the Zuni people made this spot in the sandstone bluffs their home; some of their pueblos and other structures still remain, and so do the images they carved into the surrounding stones. That art is still vivid and visible, but centuries later, Spaniards also carved their names — and the dates they passed through — into the soft rock. It’s fascinating to see the Zuni markings alongside the younger European ones.\nThis magical spot is located about 2 hours west of Albuquerque. There are camping and picnic facilities, and admission is free.\nTutuveni Petroglyph Site, Arizona\nThe Tutuveni Petroglyph Site is sacred to the Hopi people. The Hopi word Tutuveni means “Newspaper Rock”; the petroglyphs here tell the stories of ceremonial pilgrimages to the Grand Canyon. The site sits along a 100-mile trail from the Hopi mesas to the Canyon, and the faithful recorded information about their journeys on the rocks.\nTutuveni is home to more than 5,000 etchings, and 60 percent of them are on one boulder (Boulder 48). The site has been vandalized over the years, and it is now protected by a fence and surveillance cameras in an effort to preserve the petroglyphs.\nTutuveni is located on a Hopi reservation near Tuba City, Arizona. A visit to the reservation is free.\nValley Of Fire State Park, Nevada\nOnly about an hour northwest of the bright lights of Las Vegas, Valley of Fire State Park is a prime spot to view petroglyphs. Scientists say that the art here is more than 2,000 years old, and its canvas is dramatic red Aztec sandstone. Carved by members of the Basketmaker culture and then the early Pueblo people, the images depict hunting and gathering.\nHiking at Valley of Fire is easy, and the picturesque payoff is well worth the effort. The Mouse’s Tank Trail is especially stunning — and only about a mile long. The park offers camping areas and other amenities; admission costs $10 per vehicle.\nPuako Petroglyph Archaeological Preserve, Hawaii\nIf you’re on Hawaii’s Big Island, take a break from the beach and channel your inner Indiana Jones at the Puako Petroglyph Archaeological Preserve, just north of Kona. Here, ancient islanders carved thousands of images into the lava rocks. The sheer size and scope of the site are apparent as you hike the fields.\nWord to the wise: Bring plenty of water, put on sunscreen before you go, and throw on a hat for good measure. This part of the island is arid, ferociously sunny, and unforgiving to those who don’t take the proper precautions. The area is free to the public.\nMillstone Bluff Archaeological Area, Illinois\nThis little-known location in southern Illinois is rich in ancient history and art. Located in the Shawnee National Forest, the Millstone Bluff Archaeological Area is on the National Register of Historic Places for its archeological significance. Frequented by the Mississippi and Woodland tribes, the bluff was once home to a sizeable village. The village was abandoned at some point; scientists still don’t know why. Today, an ancient burial ground and several striking petroglyph panels still exist. The National Park Service has installed interpretive signs along the mile-long hike, so visitors can easily spot the thunderbirds and other figures etched in the stones.\nWashington State Park, Missouri\nOnly about an hour southwest of Saint Louis sits a treasure trove of ancient petroglyphs. They’re located in Washington State Park and are easy to view from the observation decks designed to protect them. Here, you’ll see the largest number of ancient rock carvings discovered in the state of Missouri; they were created by people who lived in the area 1,000 years ago. Thunderbirds, footprints, and human figures are all discernible, along with other symbols and scenes.\nThe park offers guided tours of the petroglyphs on Saturday afternoons from Memorial Day to Labor Day; private tours can also be arranged. Admission is free, and there are cabins for rent and camping facilities on-site.\nOlympic National Park, Washington\nAlong the rugged Pacific coast, one can spot carved orcas, moons, suns, and even a sailing ship set in stone. The Wedding Rocks petroglyphs, located on the Ozette Trail inside Olympic National Park, are difficult to reach, but they’re worth the trek. Left behind by the Makah people who settled here, these 40 gorgeously rendered images are 300 to 500 years old.\nTo reach them, you’ll need to hike 9 miles along the rocky coastline. It’s important to time your trip correctly so that you reach the area at low tide. All that said, this is a stunning hike with an incredible payoff in terms of natural and man-made beauty. Access to the park is free.\nRoche-A-Cri State Park, Wisconsin\nAbout 30 miles north of the Wisconsin Dells, in the small town of Friendship, Wisconsin, sits an ancient collection of rock art carved into a dramatic 300-foot outcrop. The Roche-a-Cri (taken from the French phrase “crevice in the rock”) petroglyphs are located inside a state park that was established to protect them back in 1948. While you can climb the stairs to the top of the cliff for sweeping views, the petroglyphs are carved into the base and are easy to view. People believed to have been ancestors of the Ho-Chunk tribe etched birds, canoes, and geometric designs deep into the rock. It’s thought that this spot held special meaning — perhaps as a message post for travelers — since the outcrop can be spotted for miles.\nYou do need to purchase a sticker if you’re driving in; vehicles with out-of-state plates can access the park for $11.']"	['<urn:uuid:36258e53-5cc1-49e2-a721-28f99514ddd4>', '<urn:uuid:41ecf09b-bf01-4dfd-b0bb-06b889cefc2c>']	open-ended	direct	short-search-query	distant-from-document	three-doc	expert	2025-05-12T22:49:38.933606	6	91	2250
73	essential oils fda regulation approval before market requirement	The law does not require FDA approval before they go on the market, but they must be safe for consumers when they are used according to labeled directions, or as people customarily use them	['Even some products identified “unscented” may include scent ingredients. This is since the manufacturer might include just enough fragrance to mask the undesirable odor of other ingredients, without giving the product a noticeable fragrance. Some scent items that are used to the body are intended for healing usages, such as treating or avoiding disease, or affecting the structure or function of the body. Here are some examples of identifying declarations that will cause a product including scents to be dealt with as a drug: Alleviating muscle pains Relaxing headaches Assisting people sleep Treating colic Many other items that may contain scent components, however are not used to the body, are controlled by the Consumer Product Security Commission.\nTo get more information about the differences, including the different requirements, see “Is it a Cosmetic, a Drug, or Both? (or Is It a Soap).” There is no regulative definition for “necessary oils,” although people commonly utilize the term to describe particular oils extracted from plants. The law deals with Active ingredients from plants the like those from any other source. If an “aromatherapy” product is meant to deal with or avoid illness, or to affect the structure or function of the body, it’s a drug. To get more information, see “Aromatherapy.” Likewise, a massage oil planned to lubricate the skin is a cosmetic. However if claims are made that a massage oil alleviates aches or unwinds muscles, apart from the action of the massage itself, it’s a drug, or possibly both a cosmetic and a drug.\nFragrance Stores for Dummies\nThe law does not need FDA approval prior to they go on the marketplace, but they need to be safe for consumers when they are utilized according to labeled directions, or as individuals usually use them. Business and individuals who produce women’s cologne lists or market cosmetics have a legal responsibility for making sure that their items are safe and appropriately labeled. In many cases, each component must be listed individually. But under U.S. policies, fragrance and flavor ingredients can be listed just as “Fragrance” or “Taste.” Here’s why: FDA needs the list of active ingredients under the Fair Product Packaging and Identifying Act (FPLA). This law is not permitted to be utilized to require a business to inform “trade tricks.” Scent and flavor formulas are complex mixes of lots of various natural and artificial chemical components, and they are the sort of cosmetic elements that are more than likely to be “trade tricks.” To find out more, see the guideline on cosmetic ingredient labeling and the Federal Register notification for this policy, which attends to “trade tricks” and the FPLA.\nHow Perfume Distributors can Save You Time, Stress, and Money.\nSome components of scent formulas may have a potential to cause allergies or sensitivities for some people. FDA does not have the exact same legal authority to require allergen labeling for cosmetics as for food. So, if you are worried about fragrance level of sensitivities, you might want to pick items that are fragrance free, and check the active ingredient list carefully.\nPhthalates are a group of chemicals utilized in numerous items. The phthalate commonly utilized in scent products is diethyl phthalate, or DEP. DEP does not pose recognized dangers for human health as it is currently utilized in cosmetics and scents. To find out more, see “Phthalates and Cosmetic Products.”.\nThe Single Strategy To Use For Perfume Distributors\nFor many Brazilian ladies, their hair is their crowning glory. According to Euromonitor, 20% of Brazil’s cosmetics and toiletries spend goes on hair care and 20% of international hair care growth in 2013 originated from Brazil. Brazilian women commit much attention to their hair, treating it carefully with conditioner and leave-in items targeting particular hair conditions.']	['<urn:uuid:fef5b741-9d0e-4c02-ab07-23ed3894f87f>']	factoid	direct	long-search-query	similar-to-document	single-doc	expert	2025-05-12T22:49:38.933606	8	34	624
74	ndvi readings benefits applications field real world farming	NDVI (normalized difference vegetation index) has multiple benefits and real-world applications in farming. According to field verification studies, NDVI can effectively indicate aboveground herbal phytomass. It works by measuring crop reflectance in the visible and near infrared region of the spectrum, with near infrared light being reflected by leaf mesophyll cells. This technology allows agronomists and farmers to identify problem areas in crops requiring remedial action, rather than walking large areas of healthy crops. NDVI is widely used in variable rate nitrogen mapping offered by many providers like Yara's AtFarm, Hummingbird, SOYL, DroneAg, Rhiza, Precision Decisions and Omnia. The technology helps match nitrogen amounts to biomass and crop growth, enabling more precise and efficient farming practices.	"[""|Issue № 3||\nConference proceedings May 22, 2020\n|D.Sc., Docent, Lomonosov Moscow State University, email@example.com|\nSummary: The dependence of the variability of landscape functioning on its spatial structure was studied on the example of the steppes of the southern Urals. The values of NDVI and its intra-seasonal variability were considered as functions of landscape, neighborhoods, and the configuration of stows. Field verification showed that NDVI can be used as an indicator of aboveground herbal phytomass. NDVI increments between time pairs were ranked by deviations from modal values. The stability of NDVI dynamics was characterized by the Shannon index through the ratio of repeatability of deviations from background increments. Statistical methods revealed a variation in the contributions of landscape organization factors to the dynamics of NDVI during the warm period. On the southern slopes and in the bottoms of gullies, the phytomass significantly deviates from the background due to the landscape. The degree of stability of NDVI dynamics depends on the position relative to boundaries of stows and their shape. In the central sectors of plateaus and deluvial plumes, the dependence on the background landscape dynamics weakens, and the contribution of positive reverse soil-phytocenotic relationships to the formation of phytomass increases.\n© Petrozavodsk State University\nReceived on: 27 June 2020\nPublished on: 29 September 2020\nAraya S., Ostendorf B., Lyle G., Lewis M. Remote Sensing Derived Phenological Metrics to Assess the Spatio-Temporal Growth Variability in Cropping Fields , Advances in Remote Sensing. 2017. Vol. 6. P. 212–228. DOI: 10.4236/ars.2017.63016.\nBasso B., Ritchie J. T., Pierce F. J., Braga R. P. and Jones J. W. Spatial validation of crop models for precision agriculture, Agricultural Systems. 2001. Vol. 68. P. 97–112. DOI: 10.1016/S0308-521X(00)00063-9.\nCorwin D. Site-speciﬁc management and delineating management zones, Oliver M. (Ed.) Precision Agriculture for Food Security and Environmental Protection. Ear5thscan. London, UK, 2013. P. 135–157.\nCurrent landscape-ecological state and problems of optimization of the natural environment of the regions: Proceedings of the XIII International landscape conference, is dedicated to the 100th anniversary of the birth of F. N. Milkov. Voronezh: ISTOKI, 2018. T. 1. 489 p. T. 2. 426 p.\nDoraiswamy P. C., Sinclair T. R., Hollinger S., Akhmedov B., Stern A. and Prueger J. Application of MODIS Derived Parameters for Regional Crop Yield Assessment, Remote Sensing of Environment. 2005. Vol. 97. P. 192–202. DOI: 10.1016/j.rse.2005.03.015.\nGrodzins'kiy M. D. Landscape ecology. K.: Znannya, 2015. 550 p.\nHoroshev A. V. Leonova G. M. Response to increasing humidification in the aituar steppe landscape (the Southern Urals), Vestnik Moskovskogo universiteta. Seriya 5: Geografiya. 2015. No. 4. P. 95–103.\nHoroshev A. V. Landscape pattern of the Aituar steppe (“Orenburgsky” nature reserve) and ecological series of urochishches, Problemy geografii Urala i sopredel'nyh territoriy: Materialy IV Vserossiyskoy nauchno-prakticheskoy konferencii s mezhdunarodnym uchastiem. Chelyabinsk: Kray Ra, 2016. P. 210–216.\nKaspar T. C., Colvin T. S., Jaynes D. B., Karlen D. L., James D. E., Meek D. W., Pulido D., Butler H. Relationship between six years of corn yields and terrain attributes, Precision Agriculture. 2003. Vol. 4. P. 87–101. DOI: 10.1023/A:1021867123125.\nNagy A., Fehér J., Tamás J. Wheat and maize yield forecasting for the Tisza river catchment using MODIS NDVI time series and reported crop statistics, Computers and Electronics in Agriculture. 2018. Vol. 151. P. 41–49. DOI: 10.1016/j.compag.2018.05.035.\nOlaya V. A gentle introduction to SAGA GIS. Edition 1.2. 2004. 202 p.\nPahuchiy V. V. Pahuchaya L. M. Experience of using vegetation indices for complex researches on the objects of hydro and forest amelioration, Vestnik Povolzhskogo gosudarstvennogo tehnologicheskogo universiteta. Seriya: Lep. Ekologiya. Prirodopol'zovanie. 2014. No. 1 (21). P. 33–41.\nPuzachenko Yu. G. Biogeocoenosis as a complex dynamic system, Biogeocenologiya v XXI veke: idei i tehnologii. M.: Tovarischestvo nauchnyh izdaniy KMK, 2017a. P. 11–114.\nPuzachenko Yu. G. Landscape organization, Voprosy geografii. Sb. 138. Gorizonty landshaftovedeniya. M.: Kodeks, 2014. P. 35–64.\nPuzachenko Yu. G. Mathematical methods in ecological and geographical studies. M.: Akademiya, 2004. 416 p.\nPuzachenko Yu. G. Theoretical and methodological basis of long-term ecological and geographical investigation at natural reserves, Voprosy geografii. Sb. 143. Ekologo-geograficheskie issledovaniya na zapovednyh territoriyah. M.: RGO, 2017b. P. 192–233.\nRaynolds M. K., Walker D. A., Maier H. A. NDVI patterns and phytomass distribution in the circumpolar Arctic, Remote Sensing of Environment. 2006. Vol. 102. P. 271–281. DOI: 10.1016/j.rse.2006.02.016.\nSolncev V. N. Structural landscape science: base of a concept. Some arguments. M., 1997. 12 p.\nTurner M. G. & Gardner R. H. Landscape ecology in theory and practice. Pattern and process. N. Y.: Springer, 2015. 482 p.\nVerhulst N., Govaerts B. The normalized difference vegetation index (NDVI) GreenSeekerTM handheld sensor: Toward the integrated evaluation of crop management. Part A: Concepts and case studies. Mexico, D. F.: CIMMYT, 2010. P. 1–16."", 'Five years ago, when people started talking about Digital Farming and Big Data, most were not sure what this was or how it related to field base crop production. Since then, writes Keith Norman, the speed of technical innovation, its benefits and uptake by industry has accelerated beyond the hobbyists, which goes to show the financial benefits are being increasingly recognised and exploited by farmers and growers.\nHowever, there is still a long way to overcome some of the barriers to uptake, such as standardisation of connectivity, conformity of data for cross platform usage, rural connectivity and speed of data transmission, cost and resistance to change.\nSoil sampling for P&K and pH has been routinely carried out for many years using the traditional approach of walking a “W” shape in each field. The introduction of grid sampling, using one sample point per hectare, combined with Kriging allowed contour maps to be generated for each nutrient, which can be used for variable rate applications using precision equipment. Electromagnetic conductance maps have also been developed illustrating soil type variation within a field, from which more targeted sampling can take place.\nNutrient mapping technology has moved further with scanning equipment using Gamma Radiometrics. The level of four naturally occurring isotopes (Caesium, Uranium, Potassium, Thorium) are detected in the subsoil/topsoil, providing an overview (more than 800 reference points per hectare) of all nutrient levels, plus pH, soil texture, organic matter and cation exchange capacity (CEC): in total 21 different metrics. This technology is not affected by soil moisture, compaction, crop or cultivation, which offers a much wider sampling window. Terramap from Hutchinsons has recently been independently endorsed in an independent evaluation by NIAB whereby it was compared to grid sampling and EC Scanning. A similar endorsement for gamma radiometrics compared to conventional approaches has been published by Wageningen University.\nIn situ soil nutritional sensors have also started making an appearance on the market, providing real-time measurements of soil moisture, salinity, NPK, aeration, respiration, air temperature, light, and humidity. These are useful to monitor real time nutrient uptake by the surrounding crop to ensure there are no phases of crop development where nutrients fall below thresholds. Some probes, such as FungiAlert’s SporSenZ go further, allowing farmers to understand the soil’s microbial community. Such soil health indicators could also be used to understand the “inner workings” of the soil microbiome and how management practices impact on the delicate balance of its components. One such sensor is being developed in an Innovate UK project led by PES Technologies that hopes to give an instant, in-field measurement of the activity of the soil microbiome through sensing VOCs (Volatile Organic Compounds). The Small Robot Company, which is also part of the consortium is looking to automate the sampling process.\nRemote Tillage Detection (RTD) could also become important should carbon sequestration and a trading market develop in the UK. Such a market exists in the US with sequestrated carbon selling for about $15-20 per tonne. There are many management practices a farmer can use to sequester carbon, all of which need to be verified, for example, rotation and cropping, previous crop residue removal, and more importantly cultivation type used. Hummingbird Technologies is developing the capability of remotely detecting tillage method (plough, min-till or direct drilling). Crop type recognition is also being developed so that field specific rotations can be identified using archive satellite data. In North America, Dagan Inc, and Radicle are also developing such capabilities.\nSubsoil compaction is known to affect soil function and root development, but conventional sampling methods do not facilitate the acquisition of high-resolution spatial compaction data on a field wide basis. A team at Wageningen University is using ground penetrating radar to map subsoil compaction, with the aim of creating a compaction map for each field, which can then be interpreted for a differential approach to subsoil management, only subsoiling areas that need it, and at the correct depth. The benefits of a spatial approach to subsoiling are significant in terms of labour cost, fuel usage and time.\nVariable seed rate technology is available from several suppliers, and has seen a good uptake by industry. There are clear benefits to having a uniform plant population throughout a field across different soil types, mostly from targeted nitrogen application, tiller management and growth regulation.\nOnce crops are established, plant counting and sizing are now possible for some horticultural crops such as lettuce, cauliflower broccoli and pumpkins with companies such as Hummingbird Technologies, Solvi and Earth Rover. Not only can individual plants in a field be counted, but sizing information can also be presented, which is really important when it comes to matching size to supermarket contractual obligations.\nThere are now many types of optical sensor for looking at crop health, biomass and chlorophyll in cereals. Crop reflectance works in the visible and near infrared region (NIR) of the spectrum, and at least two wavelengths are combined to calculate vegetation indices. The near infrared light, not visible by the human eye, is reflected by the leaf mesophyll cells, resulting in a much higher reflectance than visible light. Using both wavelengths it is possible to evaluate the colour and biomass of a crop using a measurement called NDVI (normalised difference vegetation index). NDVI is very useful for agronomists and farmers to inspect areas of crops where problems are highlighted and where remedial action is necessary, rather than walking lots of “good” hectares. Similarly, remote sensing / imaging technologies are now widely available from many manufacturers and may be tractor-mounted, hand-held or use satellite technology through a computer or phone app.\nVariable rate nitrogen mapping, offered by many, exploits this natural soil/crop variation and matches nitrogen amount to biomass and growth of the crop. Examples of this include; Yara’s AtFarm and VRN products from Hummingbird, SOYL, DroneAg, Rhiza, Precision Decisions and Omnia\nGrowth stage prediction is a feature that some providers offer, such as Omnia from Hutchinsons, which uses climatic information combined with physiological crop modelling to predict when key growth stages are reached. For root crop growers, ground penetrating radar is being developed to provide a non-invasive way of looking at crop development in terms of size and shape. An Innovate UK funded project led by B-Hive Innovations is developing capability to identify tuber size and shape and quantity.\nMost yield prediction systems are based on the original WOFOST model, originally developed by Wageningen University but now maintained by the Joint Research Centre of the European Commission. The more recent introduction of AI makes modelling very large datasets of weather and crop metrics a much easier task, meaning it is now possible to get yield estimates down to individual field level.\nAccuracy increases as harvest date approaches. Most yield prediction is reasonably accurate at 30-days pre-harvest, but the challenge is to extend that to 60- and 90-days pre-harvest so there is still the potential to change input choice within and between fields to maxmise gross margin.\nCrop inventory and field benchmarking not only benefits farmers but it is also key information for many commodity trading organisations, government and supply industries, with an accurate hectarage, on a crop-by-crop basis, in regions or at national level.\nThere are many new innovations being developed for the detection of diseases, all of which work in a slightly different way but aim to give an early warning a specific disease of interest is in the early stages of infection. This “intelligence” at field level enables growers to use the optimum selection fungicides and timings, rather than using a prophylactic spraying approach. For example, Burkard and Rothamsted are developing a LAMP assay bio sensor, where air is sucked into the sensor and the spores are disrupted to release DNA for identification and quantification by a series of ‘in-trap’ laboratory tests. Results are then sent wirelessly to a server, using an internal 4G router. The Earlham institute (EI) has developed a similar system called AirSeq using nanopore technology, a new generation of DNA sequencers which read longer pieces of DNA than previously possible called the MinION platform This was discussed at a recent EI event attended by CHAP.\nThe University of Manchester and Sony have developed a totally different type of biosensor with Gates Foundation backing that uses a simulated leaf surface, impregnated with specific biochemicals known to stimulate the germination of the target disease. A micro camera in the sensor detects the hyphal growth and, through AI, recognises the target pathogen and sends an alert.\nFERA offer a qPCR service for farmers to send in leaf samples and the DNA of any latent target disease is extracted and measured in picogrammes. This gives a grower an indication of the amount of disease present, but as yet there is no real calibration between the resulting pico grammes of a disease and what level of fungicide is needed to control it. However, it is a very useful tool during dry springs when deciding fungicide mixtures and rates.\nPre-symptomatic disease detection is only one part of the story: the resulting spatial application of fungicides, in different combinations and dose rates is also an important consideration. Various digital technologies are being developed to deliver the science into practice in field. Often variable rate fungicide application assumes that thicker, higher biomass areas of crops have a microclimate more conducive to disease development. NDVI maps of a field can help identify such areas to create a targeted spatial application map.\nHowever, there are problems varying the rate of one tank mix component, such as a fungicide, while delivering a constant rate for other components such as insecticides or trace elements. A similar scenario exists with variable rate growth regulator and other tank mix partners.\n“On the move” rate variability can be overcome using direct injection spraying systems, where undiluted pesticide is placed into canisters on the sprayer, and plain water is in the sprayer tank. The pesticide is then metered and introduced into the water on the pressure side upstream from the boom sections, with the rate being varied by the speed of the direct injection pump. One example of this is Raven’s Sidekick Pro available as factory option on Case and John Deere sprayers, or as a retrofit to any sprayer. In addition to these technologies, small scale precision application is also being explored by the industry, such as CHAP’s Innovate UK project Slugbot, which precisely applies biopesticides where they are needed.\nNorth Carolina State University is developing a Volatile Organic Compound detector for late blight in potatoes. A small electronic nose “sniffs” the crop and gives an instant readout if the very early stages of blight are detected. The device is still handheld at the moment, but there are plans to make it drone mounted so crops can be flown and random points of inspection can be made to check a crop’s disease status.\nVolatile Organic compound detection is being used in Florida’s Orchards to detect a disease called “citrus greening” which affects orange, lemon and grapefruit trees. Sniffer dogs can detect diseased trees up to two years before symptoms appear. Similar work is happening in Canada with dogs sniffing Clubroot. The aim is to develop and automate a similar detection methodology on a drone.\nDisease modelling has an integral part to play in spore detection technologies. Knowing that there are spores in the air is one thing, but knowing how they will develop is another. The University of Reading and Rothamsted have developed a Septoria prediction model based on accumulated rain and accumulated minimum temperature pre GS31. The known varietal resistance is also used in the model output.\nCHAP and Fera have partnered to create the disease prediction tool CropMonitor Pro, which provides information sourced from monitoring sites located across the country and reports up to date measurements of crop pest and disease activity in arable crops throughout the UK.\nIntelligent insect traps are being developed whereby insects are lured into a trap, and are quantified and identified because of their size and shape. One example is DTN’s SmartTrap, which can identify up to 16 different crop pests through an onboard camera that counts and reports on them in near real time. It can even distinguish between target and non-target pests.\nAnother bio-sensor based technology that records and analyses electrical signals emitted by plants is being developed by Vivent. The system called PhytlSigns, provides early warnings of a wide range of crop stresses, including nutrient deficiencies, environmental stresses, pathogens and insect infestations well before visual symptoms, enabling farmers to action early interventions.\nYield mapping is a well-established technology in cereal combine harvesters, but the technology is now being developed for forage harvesters and root crop harvesters too. This digital technology gives farmers and growers realtime evidence to look back at their different approaches to crop production and management. It also allows field zones to be identified that are consistently high or low yielding, therefore allowing a differential approach of crop inputs to be deployed.\nMany manufacturers including New Holland, CASE, Claas, AGCO and John Deere all provide a yield-mapping function and most incorporate moisture analysis for cereal harvesting. Some also provide additional elements, Claas has a very useful Telematics option called Fleet View, which informs the field team about the position of the machines and their grain tank fill levels. Everyone will know which machine needs to be unloaded next. This avoids idle time and unnecessary vehicle travel, save fuel and make full use of the harvesting machines’ capacity.\nSensors installed in John Deere’s ActiveYield system combines, not only weigh the amount of grain coming into the tank, but NIR sensors can also measure protein content. The weight sensors avoid the need for weighbridge calibration. This is useful in gauging the success of late nitrogen applications for protein in wheat. Other such as Bayer’s FieldView enables remote real-time harvesting information, yield mapping while the combing operation is happening, and also gives access to in-season satellite imagery allowing evaluation of crop health.\nYield mapping can also be used to examine other factors such as PCN affected areas in potato. Allowing differential strategies for nematicide usage / varietal choice to be implemented in specific situations. Soil Essentials’ EssentialsRootYield weighs potatoes coming over the harvester’s web, with the data then integrated with Trimble FmX® and TMX-2050 guidance to display yield while on the move and as overall yield maps. Similarly, knowing the yield and quality of forage as it is being cut is a very useful management tool for livestock farmers to know what is coming in for storage and to assess feed potential. An example of this is the recent John Deere, HarvestLab, which can measure yield and dry matter of forage on the move, but also analyse dry matter, crude protein, starch, crude fibre, NDF, ADF, sugar and crude ash.\nIs digital farming only for developed countries? The widespread use and availability of mobile phones, 3G, 4G and internet in the third world means that some of the small-scale technologies could be used with minimal costs. Seventy per cent of the poorest population and 20 per cent of the low and middle-income countries have access to a mobile phone, and one in three people have internet access.\nThe priorities will be different in developing countries, for example pest control practices and the prediction of unforeseen extreme weather events will give a much greater payback than disease control. There will be an associated need for digital literacy which will be essential to make these systems work.\nAs technological uptake increases, so will the need for agricultural advisory services in smallholder farming communities. This could be done as distance learning from anywhere in the world.\nSeveral technologies such as drone-mounted sensors, laser weeding and insect trapping are all really suited to small scale agriculture if properly coordinated at a local scale.\nThere is a huge potential for local and regional coordination of crowd-sourced information and feedback, together with reporting on the success of the various technical solutions that have been used and their efficacy.\nFrom a mechanisation point of view, digital tools are being developed that aim to connect tractor owners and farmers for example Hello Tractor in Nigeria; EM3, Trringo and farMart in India; Trotro Tractor in Ghana; and Rent to Own in Zambia.\nThere is no doubt that we are in the midst of a Digital Farming revolution. As this article illustrates, there are a lot of technologies being developed, covering a wide range of crops, that will ultimately increase crop output and profitability.\nThe skill will be how all these individual components are bought together in a workable “systems-based approach”.\nFarmers very much favour the one-stop-shop or grower-portal approach, where one log in provides visibility of all the technologies active within a farming business. This concept is very much behind the development of the technologies themselves but needs to gain momentum to keep up with the pace of technical development.\nThe rapid technical development within the industry is also beneficial in attracting new entrants who may have previously viewed farming as rather traditional and low-tech.\nCropMonitor Pro is a state of the art sophisticated decision support platform which has been developed by Fera with Crop Health and Protection funded by Innovate UK\nCropMonitor Pro is a state of the art sophisticated decision support platform which has been developed by Fera with Crop Health and Protection funded by Innovate UK.\nCHAP’s Fine Phenotyping Lab is based at Rothamsted Research in Hertfordshire.\nCHAP’s precision machinery is housed at Stockbridge Technology Centre (STC), near Selby.\nCHAP has four mobile laboratories.\nCHAP plays a key role in developing new control strategies, which are going to be essential for the farmers and growers who are having to deal with the loss of actives in the market.- Dr Tom Ashfield , Rothamsted Research\nFor more information on our capabilities or to discuss a collaboration and/or grant for a commercially funded project, complete the form below.']"	['<urn:uuid:d2266df6-d55d-4054-9176-63b78e0aecb1>', '<urn:uuid:163fa02d-e3f2-4968-8079-433beabbfadf>']	open-ended	with-premise	long-search-query	distant-from-document	multi-aspect	novice	2025-05-12T22:49:38.933606	8	116	3756
75	I'm doing research about banking secrecy and wondering when Switzerland first started offering secret banking services - what's the history behind this?	Banking secrecy in Switzerland began in 1713 when the Great Council of Geneva passed the first regulations limiting bankers' ability to share client information. It really expanded in the 1920s when European nations increased taxes after World War One, leading wealthy Europeans to hide their money there. In 1934, Switzerland made it a criminal offense for bankers to disclose financial information.	['How much of the world’s wealth is hidden offshore?\nWould you like to pay less tax? Make a sandwich: specifically, a “double Irish, Dutch sandwich”.\nSuppose you’re American. You set up a company in Bermuda and sell it your intellectual property. It then sets up a subsidiary in Ireland.\nNow, set up another company in Ireland: it bills your European operations for amounts resembling their profits. Now, start a company in the Netherlands.\nHave your second Irish company send money to your Dutch company, which immediately sends it back to your first Irish company. You know, the one headquartered in Bermuda.\nAre you bored and confused yet? If so, that’s part of the point.\nTax havens depend on making it, at best, very difficult to get your head around financial flows, and, at worst, impossible to find out any facts.\nAccounting techniques that make your brain hurt enable multinationals such as Google, eBay and Ikea to minimise their tax bills – completely legally.\n50 Things That Made the Modern Economy highlights the inventions, ideas and innovations that have helped create the economic world.\nYou can see why people get upset. Taxes are a bit like membership fees for a club: it feels unfair to dodge the fees but still expect to benefit from the services provided to members – defence, police, roads, sewers, education, and so on.\nBut tax havens haven’t always had such a bad image. Sometimes they’ve functioned like any other safe haven, allowing persecuted minorities to escape the oppressive rules of home.\nJews in Nazi Germany, for example, were able to ask secretive Swiss bankers to hide their money.\nAvoidance v evasion\nUnfortunately, secretive Swiss bankers soon undid the good this did their reputation by proving to be just as happy to help the Nazis hide the gold they managed to steal, and reluctant to give it back to the people it was stolen from.\nNowadays, tax havens are controversial for two reasons: tax avoidance and tax evasion.\nTax avoidance is legal. It’s the stuff of double Irish, Dutch sandwiches.\nThe laws apply to everyone: smaller businesses and even ordinary individuals could set up border-hopping legal structures too. They just don’t earn enough to justify the accountants’ fees.\nIf everyday folk want to reduce their tax bill, their options are limited to various forms of tax evasion, which is illegal: VAT fraud, undeclared cash-in-hand work, or taking too many cigarettes through the “nothing to declare” lane at customs.\nThe British tax authorities reckon that much evaded tax comes from countless such – often modest – infractions, rather than the wealthy entrusting their money to shadowy bankers.\nBut it’s hard to be sure. If we could measure the problem exactly, it wouldn’t exist in the first place.\nPerhaps it’s no surprise that banking secrecy seems to have started in Switzerland: the first known regulations limiting bankers’ ability to share information about their clients were passed in 1713 by the Great Council of Geneva.\nSecretive Swiss banking really took off in the 1920s, as many European nations hiked taxes to repay their debts from World War One – and many rich Europeans looked for ways to hide their money.\nRecognising that this was boosting their economy, in 1934 the Swiss made it a criminal offence for bankers to disclose financial information.\nThe euphemism for a tax haven these days, of course, is “offshore” – despite Switzerland’s lack of coastline. Gradually, tax havens have emerged on islands such as Jersey or Malta, or, most famously, in the Caribbean.\nThere’s a logistical reason for this: a small island isn’t much good for manufacturing or agriculture, so financial services are an obvious alternative.\nBut the real explanation is historical: the dismantling of European empires in the decades after World War Two.\nUnwilling to prop up Bermuda or the British Virgin Islands with explicit subsidies, the UK instead encouraged them to develop financial expertise, plugged into the City of London. The subsidy was implicit, instead – tax revenue steadily leaked away to these islands.\nMind the gap\nThe economist Gabriel Zucman came up with an ingenious way to estimate the wealth hidden in the offshore banking system.\nIn theory, if you add up the assets and liabilities reported by every global financial centre, the books should balance – but they don’t. Each individual centre tends to report more liabilities than assets.\nZucman crunched the numbers and found that, globally, total liabilities were 8% higher than total assets. That suggests at least 8% of the world’s wealth is illegally unreported. Other methods have come up with even higher estimates.\nThe problem is particularly acute in developing countries. For example, Zucman finds 30% of wealth in Africa is hidden offshore. He calculates an annual loss of $14bn (£11bn) in tax revenue. That would build plenty of schools and hospitals.\nZucman’s solution is transparency: creating a global register of who owns what, to end banking secrecy and anonymity-preserving shell corporations and trusts.\nThat might well help with tax evasion. But tax avoidance is a subtler and more complex problem.\nTo see why, imagine I own a bakery in Belgium, a dairy in Denmark, and a sandwich shop in Slovenia.\nI sell a cheese sandwich, making 1 euro of profit. How much of that profit should be taxed in Slovenia, where I sold the sandwich, or Denmark, where I made the cheese, or Belgium, where I baked the bread? There’s no obvious answer.\nAs rising taxes met increasing globalisation in the 1920s, the League of Nations devised protocols for handling such questions. They allow companies some leeway to choose where to book their profits.\nThere’s a case for that, but it opened the door to some dubious accounting tricks.\nOne widely reported example may be apocryphal, but illustrates the logical extreme of these practices.\nA company in Trinidad apparently sold ballpoint pens to a sister company for $8,500 (£6,600) apiece, resulting in more profit booked in low-tax Trinidad and less in higher-tax regimes elsewhere.\nMost such tricks are less obvious, and consequently harder to quantify.\nMore from Tim Harford\nStill, Zucman estimates that 55% of US-based companies’ profits are routed through some unlikely looking jurisdiction such as Luxembourg or Bermuda, costing the US taxpayer $130bn (£100bn) a year. Another estimate puts the losses to developing country governments at many times the amount they get in foreign aid.\nSolutions are conceivable: profits could be taxed globally, with national governments devising ways to apportion which profit is deemed taxable where.\nA similar formula already exists to apportion national profits made by US companies to individual states.\nBut that would need political desire to tackle tax havens. And while recent years have seen some initiatives, notably by the Organisation for Economic Co-operation and Development (OECD), they’ve so far lacked teeth.\nPerhaps this shouldn’t surprise us, given the incentives involved. Clever people can earn more from exploiting loopholes than trying to close them.\nIndividual governments face incentives to compete to lower taxes, because a small percentage of something is better than a large percentage of nothing.\nFor tiny, palm-fringed islands, it can even make sense to set taxes at 0%, as the local economy will be boosted by the resulting boom in law and accounting.\nPerhaps the biggest problem is that tax havens mostly benefit financial elites, including some politicians and many of their donors. Meanwhile, pressure from voters for action is limited by the boring and confusing nature of the problem.\nTim Harford writes the Financial Times’s Undercover Economist column. 50 Things That Made the Modern Economy is broadcast on the BBC World Service. You can find more information about the programme’s sources and listen online or subscribe to the programme podcast.\nLIST OF AGGREGATORS AND STATE FOCAL PERSONS FOR THE FREE 250,000 FG/CAC BUSINESS NAMES REGISTRATION FOR MSMEs']	['<urn:uuid:6e458995-9796-4d66-8745-addc746c74e9>']	factoid	with-premise	verbose-and-natural	similar-to-document	single-doc	novice	2025-05-12T22:49:38.933606	22	61	1299
76	eyeglasses affordability worldwide cost market size	While affordable eyeglasses can cost as low as $1-7 through initiatives like OneDollarGlasses for the poor, the global ophthalmic equipment market is substantial, valued at US$42.471 billion in 2019 and projected to reach US$49.618 billion by 2026.	"['How to Build a Market for Eyeglasses: More than 600 million people have serious vision problems and they — and society — pay a steep price\nMartin Aufmuth, founder of OneDollarGlasses, created a hand-operated milling machine that allows opticians to produce his glasses at a cost of $1 apiece after 14 days of training. To enable the local specialist to turn a profit, the glasses sell for between $2 and $7, according to The Guardian.\nAccording to Vision Aid Overseas, some 10 percent of the world’s population are vision-impaired, and eyeglasses could correct the vision problems of virtually all of them – sometimes making an enormous difference in their lives. For example, for a tailor in a hill village in Nepal who no longer can see to sew, a pair of affordable eyeglasses makes the difference between earning a living and becoming a beggar.\nUsually beginning in their forties, many people become unable to focus their vision on near objects, a condition called presbyopia. Today you can go into a drugstore in Denver or Amsterdam and select an $8 pair of reading glasses that will correct your vision problem. Why not make a robust version of this display stand available to the nearly 700 million poor people in the world who need eyeglasses?\nGive me a market so I can see\nAdaptive Eye Care, a UK-based company, uses the invention of an Oxford physics professor, Joshua Silver, to bring self-adjusting eyeglasses to people who need them. The constraint here is the cost – $15 dollars now, perhaps $10 or less with volume, but still not affordable to people who earn less than $2 a day.\nNew Eyes for the Needy, a U.S.-based organization, shipped 355,000 donated used eyeglasses in good condition during 2005-06 to medical missions and charitable organizations in developing countries. The problem here is that giving away glasses is not a scheme that can be scaled up to reach more than a tiny fraction of the people who need them.\nIn the first five years alone, New York–based VisionSpring (formerly Scojo Foundation) and its partners sold 50,000 reading glasses, at prices from $3 to $5, in India, Bangladesh and El Salvador. And they referred 70,000 people to eyecare professionals through a network of 600 vision entrepreneurs, 26 franchise partners and a number of urban wholesalers distributing to pharmacies and other retail outlets. Now, eight years after its founding, VisionSpring glasses are being worn in 26 developing countries. The organization employs a systematized partnership model that works with microfinance institutions, NGOs, for-profit businesses and social enterprises.\nGraham Macmillan, former executive director of what was then called Scojo Foundation (now VisionSpring), told Paul that a surprising number of small-acreage farmers were enthusiastic customers for affordable eyeglasses, because without these glasses they can’t read the labels on seed packages. Some of them don’t know what crop they are planting until it begins to come up.\n“The combined efforts of VisionSpring, New Eyes for the Needy and Adaptive Eyecare have reached less than one percent of the 670 million poor people who need eyeglasses. The rest live with serious visual problems, paying a significant price in lost income because they can’t see straight – while society pays the price of their lower productivity.”\nA simple solution, and healthy profits\nThis is outrageous, because there is such a simple solution in taking advantage of uncomplicated eyeglass display stands that already sell affordable eyeglasses to millions of wealthier customers. It would take $5 million to $10 million in venture capital to start an international company that would buy a million eyeglasses in mainland China at around 50 cents apiece, design robust, visually appealing mobile display stands pushed by people or pulled by bicycles or motor scooters in poor areas, perhaps forming partnerships with major corporations such as Tata in India, developing an effective global distribution and marketing strategy.\nThe company’s goal would be to reach sales of 50 million $2 eyeglasses within five years, and make a healthy profit doing it.\nOne-acre, $2-a-day farmers and their urban brothers and sisters are already hard-nosed, stubborn survivalist entrepreneurs ready to take advantage of marketplace opportunities if the price is right, the return is high and the risk is low. But they need private-sector supply chains to furnish them with the tools, materials and information required to create high-value products, and private-sector value chains that sell what they produce at an attractive profit. As their incomes increase, they become customers for products like affordable eyeglasses, houses, solar lighting, health care and education.\nNew markets that serve poor customers will provide opportunities for hundreds of millions of dollar-a-day people to move out of poverty. But a revolution in design is needed to create the range of new income-generating tools that will make this move possible.\nPaul Polak and Mal Warwick are the co-authors of the book: “The Business Solution to Poverty: Designing Products and Services for Three Billion New Customers“', ""The ophthalmic equipment market is projected to grow at a CAGR of 2.25% to reach US$49.618 billion by 2026 from US$42.471 billion in 2019.\nOphthalmic equipment is used in the process of ophthalmology. It's the medicines and surgery used in treating and diagnosing eye disorders. Many diseases such as cataracts, proptosis, glaucoma, macular degeneration, and dry eye syndrome are treated by ophthalmologists. Some of the types of equipment used includes:\nA major reason for the growth of this market is the promptly growing aged population.\nAccording to World Health Organisation, “By 2050, the world’s population aged 60 years and older is expected to total 2 billion and there will be almost this many (120 million) living in China alone of the age group 80 years and above, and 434 million people in this age group worldwide.” The number of people aged 60 years and above accounted for 1 billion of the total population in 2019. According to the World Health Organisation, people aged 52 years or above constituted 82 percent of the blind population. Half of the world’s population is constituted in China and India. According to the UN, Economic and Social report, the population of people aged 65 years and above is expected to increase to 587.4 million people by 2030 from 395.3 million in 2019, in Asia. The prevalence of eye-related diseases in them times lesser in children. With the rapidly growing geriatric population, the prevalence of eye diseases is becoming more prominent. Moreover, vision loss is becoming a cause of concern. With an increase in chronic disorders such as diabetes and hypertension among the aged population, eye diseases have become more significant. All this will increase the population of people suffering from eye disease substantially and are expected to contribute to the growth of the market.\nThe technological advances in the developing countries are expected to drive the demand for this market in the forecast period.\nAccording to the World Health Organisation, “More than 1 billion people worldwide are living with vision impairment because they do not get the care they need for conditions like short and farsightedness, glaucoma, and cataract.”\n“Globally, at least 2.2 billion people have a vision impairment or blindness, of whom at least 1 billion have a vision impairment that could have been prevented or has yet to be addressed.” The limitation of eye disorder is not equally borne. It is much more prevalent in people living in rural areas, women, low-income groups, and the indigenous populations. According to the World Health Organisation, distance vision impairment is four times greater in low-income and middle-income countries than the high-income countries. Low and middle-income regions of sub-Saharan Africa and South Asia have an eight times greater rate of blindness when compared to the high-income countries. With the growing digitalization and technological advancement in developing nations, the market for ophthalmic equipment is expected to grow. Also, the increase in the number of people using spectacles and contact lenses is also expected to support the market growth.\nThe impact of COVID-19 on the ophthalmic equipment market and increase in Research and Development and government initiatives.\nThe market is expected to be negatively impacted by the ongoing COVID-19 pandemic. There has been a significant drop out in the number of people visiting clinics due to the government norms. The imposition of lockdown has led to a lesser number of people visiting eye health care centers thereby leading to a decline in the number of surgeries. Also, ophthalmologists have rescheduled many surgeries. With the prevalence of pandemics, there has been a significant re-organization in the number of surgeries performed. Thus, COVID-19 is expected to curtail the growth of the market.\nCompanies are deploying huge amounts of funds for the research and development of new equipment. Also, the government is taking a lot of initiative across the globe in order to control visual impairment. This, in turn, is expected to push the growth of the ophthalmic equipment market in the coming years.\nProminent key market players include Johnson and Johnson Services, HOYA Group, NIDEK Co, HAAG-STRIT Group, etc. The players in the Ophthalmic equipment market are implementing various growth strategies to gain a competitive advantage over their competitors in this market. They are constantly working upon technological innovation.\n|Market size value in 2019||US$42.471 billion|\n|Market size value in 2026||US$49.618 billion|\n|Growth Rate||CAGR of 2.25% from 2019 to 2026|\n|Forecast Unit (Value)||USD Billion|\n|Segments covered||Product, End-User, And Geography|\n|Regions covered||North America, South America, Europe, Middle East and Africa, Asia Pacific|\n|Companies covered||Carl Zeiss Meditec AG, Ziemer Ophthalmic Systems AG, Johnson and Johnson Services Inc., Baush and Lomb, Alcon, HOYA Group, NIDEK Co, Ltd., Coburn Technologies Inc., Haag-STRIT Group, Veatch Ophthalmic Instruments|\n|Customization scope||Free report customization with purchase|\nFrequently Asked Questions (FAQs)\nQ1. What will be the ophthalmic equipment market size by 2026?\nA1. The ophthalmic equipment market is projected to reach a total market size of US$49.618 billion in 2026.\nQ2. What is the size of global ophthalmic equipment market?\nA2. Ophthalmic Equipment Market was valued at US$42.471 billion in 2019.\nQ3. What are the growth prospects for ophthalmic equipment market?\nA3. The global ophthalmic equipment market is projected to grow at a CAGR of 2.25% during the forecast period.\nQ4. Who are the major players in the ophthalmic equipment market?\nA4. Prominent key market players in the ophthalmic equipment market report include Johnson and Johnson Services, HOYA Group, NIDEK Co, HAAG-STRIT Group, etc.\nQ5. What factors are anticipated to drive the ophthalmic equipment market growth?\nA5. A major reason for the ophthalmic equipment market growth is the promptly growing aged population.\nCarl Zeiss Meditec AG\nZiemer Ophthalmic Systems AG\nJohnson and Johnson Services Inc.\nBaush and Lomb\nNIDEK Co, Ltd.\nCoburn Technologies Inc.\nVeatch Ophthalmic Instruments\nAll our studies come with 2 months of analyst support.\nWe are in compliance with the global privacy laws.""]"	['<urn:uuid:2d03d5a5-e68e-41f5-8975-8f3ec05a5d83>', '<urn:uuid:881240e6-27eb-4e84-91c7-367d69c9aaf9>']	factoid	direct	short-search-query	similar-to-document	multi-aspect	novice	2025-05-12T22:49:38.933606	6	37	1797
77	I've been researching personal connections in Elizabethan drama - did Shakespeare and Ingram Frizer have any documented interaction or mutual associates?	While there's no direct documented interaction between Shakespeare and Frizer, they were connected through the theatrical world of London. Frizer was associated with Thomas Walsingham during the same period (early 1590s) when Shakespeare was becoming well established in London, as confirmed by Robert Greene's 1592 reference. Frizer was involved in the death of Christopher Marlowe, who was a contemporary dramatist during Shakespeare's early career in London.	"[""Shakespeare's Last Will and Testament For all his fame and celebration, William Shakespeare remains a mysterious figure with regards to personal history. There are just two primary sources for information on the Bard:\nThe christenings of their children are recorded, that of his elder daughter Susanna in Maythat of the twins Judith and Hamnet in February The boy Hamnet died aged 11 but Judith married and survived her father; his granddaughter Elizabeth d.\nA familiar, but less likely, legend relates that he left Stratford c. A disparaging reference to Shakespeare in by the dramatist Robert Greene confirms that he was well established in London.\nThere was an extraordinary burst of creativity in drama towards the end of the Elizabethan and in the early Jacobean periods, unparalleled until the literary explosion in Russia in the 19th century.\nFrancis Meres, in Palladis Tania. Most of the sonnets may date from this period. There are only two functional marriages in the 38 plays, Macbeth and Lady Macbeth, Claudius and Gertrude, suggesting that Shakespeare took a bleak view of the institution.\nMacbeth monologue from the play by William Shakespeare Essay The Henry VI plays, popular in their time, are now sometimes cut and bracketed together and performed as a single work.\nThe Comedy of Errors a free adaptation of Plautus and Titus Andronicus from Seneca are also early and despite skill in plot construction and versification, there are crudities which disappeared as the playwright matured.\nSome of his most popular plays were written in the period — The second and third of the Roman plays were Antony and Cleopatra —07 and Coriolanus Antony and Cleopatra, written in 42 scenes, is a complex epic, involving love, betrayal and conflicting loyalties, and critical opinion has long been divided on its ranking.\nShakespeare borrowed from Plutarch and Virgil whose account of Dido and Aeneas was in part a tactful account of Cleopatra and Antony, their contemporary prototypes. Eliot, is the most overtly political work in the canon, with a disconcerting contemporary relevance: Hamlet —01 is the longest, greatest, most performed, most filmed, most quoted of all the plays and the one most resembling a novel, with its seven interior monologues soliloquiesexploring the problem of self-knowledge and emotional paralysis.\nThen came Othellowith its themes of sexuality, race and treachery, King Lear —06the darkest of all, with its paroxysms of grief, a metaphor for reversion from civilization to barbarism, and Macbeth, psychologically one of the most complex — Cymbelineset in Ancient Britain, is an extraordinary mixture of genres, full of anachronisms but with fine poetry.\nKermode points to ranting and pathology in the first part, then calm and acceptance in the last acts His last completed play, The Tempest —11shows his creative powers at their highest and the character of Prospero, the deposed Duke of Milan, a magus-like figure on a remote island, seems to be strongly autobiographical and may have been played by Shakespeare himself.\nThe Tempest, the most musical of the 38 plays, represents a farewell to his creative life in the theatre. The plays are not dated and attempts to arrange them in chronological order have provoked endless controversy. Eighteen plays, including Macbeth, only survive because they appear in the First Folio.\nThe Sonnets were published in book form, possibly without authorisation, in The dedication, by the publisher Thomas Thorpe or T. Seventy-nine alternate candidates have now been proposed.\nThree are royal, 16 are peers or peeresses, one a cardinal, one a saint, and 32 are published authors. None is remotely plausible. There are clocks in Julius Caesar. There are striking examples of anatopism, having something out of place. Characters in Two Gentlemen of Verona sail from Milan to Verona although he might have been referring to travel by canaland from Milan to the Adriatic in The Tempest.\nThe only banks in Venice were mercantile and lovers would not be sitting on them. Shakespeare was a man of genius who trawled and reworked the secondary sources rather than having direct exposure to life outside England.\nHe died there on his birthday, 23 April the same date as Cervantes, but 10 days later under the unreformed Julian calendarand is buried in Holy Trinity Church. New Place was substantially rebuilt infinally demolished in Archaeology continues on the site and the gardens have been imaginatively restored.\nThe theatres closed from —60 during the Civil War and the Commonwealth, and as fashions changed his work suffered some eclipse. His vocabulary was exceptionally large for his time: David Crystal cautiously estimates that Shakespeare used between 17, and 20, words, allowing for divergent spellings, definitions and ambiguities.\nHis works have been translated more than any other author and many characters are household names. No writer has given more continuous delight or shown greater insight into the heart and mind, although we know so little of his own.A Trying Relationship The history of William Shakespeare, poet and playwright, is anything but one free of controversy.\nThere are several arguments challenging his very existence. Over the years, every aspect of his life has been studied and researched comprehensively.\nGet an answer for 'What might be good questions to ask William Shakespeare?For English, a partner and I are supposed to act out an interview with Shakespeare. Biography of William Shakespeare. Get an answer for 'What plays of Shakespeare's were seen as controversial?' and find homework help for other William Shakespeare questions at eNotes.\nJul 15, · Most scholars accept that William Shakespeare was born in Stratford-upon-Avon, and spent time acting in London before returning to Stratford, where he lived until his death in Little do we know about the true history of William Shakespeare; there are many conspiracies that surround his life.\nFor centuries, scholars have debated. William Shakespeare (bapt. 26 April – 23 April ) was an English poet, playwright and actor, widely regarded as both the greatest writer in the English ."", 'Ingram Frizer (// freezer; died August 1627) was an English gentleman and businessman of the late 16th and early 17th centuries who is notable for his reported killing of playwright Christopher Marlowe in the home of Eleanor Bull on 30 May 1593. He has been described as ""a property speculator, a commodity broker, a fixer for gentlemen of good worship"" and a confidence trickster gulling ""young fools"" out of their money.\nThere is no definite information regarding Frizer\'s origins, but he may have been born in or near Kingsclere in Hampshire, and the not always reliable International Genealogical Index does in fact show the baptism there of a female child called Ingram Frysar on 26 September 1561. Parish records for Kingsclere held at Hampshire Record Office show an Ingram Frizer, son of Stephen, christened 26 September 1561 in Kingsclere, Hampshire.\nSurviving legal records show Frizer to have been a fairly well-to-do business man profiting from buying and selling property. At the time of Marlowe\'s death the landowner Thomas Walsingham was Frizer\'s ""master"", but this does not imply that Frizer was a servant. As well as acting on his own behalf, Frizer appears to have been Walsingham\'s business agent. Walsingham was a young relative of Queen Elizabeth\'s Secretary of State, Sir Francis Walsingham; both Walsinghams had been heavily involved with intelligence work a few years earlier but there is no evidence that Frizer ever had any connection with it.\nNot all of Frizer\'s business dealings were honest. In 1593, collaborating with Nicholas Skeres (who was also present at Marlowe\'s killing), he was involved in lending money to one Drew Woodleff. Woodleff signed a bond for £60 in exchange for some guns that Frizer supposedly had in storage. Frizer then claimed to have sold them on Woodleff\'s behalf, but for only £30. The effect of this was that Frizer, who had never offered any guns for sale, had made Woodleff a loan of £30, to be repaid by the redemption of the £60 bond, an interest rate of 100%. Woodleff later signed a bond for £200 in favour of Thomas Walsingham, agreeing the forfeit of land to him in default of payment, to extricate himself from his bond to Frizer.\nA few years later, when King James ascended the throne, Frizer received numerous benefices from the crown, through the action of Audrey Walsingham (Thomas\'s wife and a friend of James\'s Queen, Anne of Denmark). He moved to Eltham, about three miles from the by then Sir Thomas Walsingham\'s estate at Scadbury. He became a churchwarden in 1605 and a parish tax assessor in 1611. There was a daughter named Alice Dixon, who lived in London, and another who married a man called John Banks. A ""Mrs. Ingeram"" who was buried at Eltham on 25 August 1616 may perhaps have been his wife, and he remained there apparently in genteel respectability until his death, being buried in the church there on 14 August 1627.\nFor several years before his death Marlowe had been employed in some intelligence capacity on behalf of the government. In the Spring of 1593 he appears to have been staying at Thomas Walsingham\'s home at Scadbury, near Chislehust in Kent, and had been invited by Frizer to a ""feast"" in Deptford, a township on the river Thames some seven miles to the north, at the house of Eleanor Bull, the widow of a local official. The status of Dame Bull\'s establishment is unclear, but it was probably a private victualling house, rather than a public tavern. Also in attendance were Nicholas Skeres and Robert Poley, both of whom had been associated with Sir Francis Walsingham\'s intelligence operation. In fact Poley still was working for the Privy Council at the time.\nComplete details of Marlowe\'s killing on 30 May 1593, as contained in an inquest run by the Coroner of the Queen\'s Household two days later, were discovered by Leslie Hotson in 1925. According to this report, based upon accounts from the three men present, Poley, Frizer, Skeres and Marlowe were in a private room, having had dinner. Poley, Frizer and Skeres were all seated facing a table with Frizer in the middle. Marlowe was lounging on a bed just behind them when Frizer and he got into an argument over ""the reckyninge"" (the bill). Marlowe suddenly jumped up, seized Frizer\'s dagger, which Frizer was wearing ""at his back"", and with it struck him twice on the head, leaving wounds two inches long and a quarter deep. Frizer, his freedom of movement restricted between Poley and Skeres, struggled to defend himself and in doing so stabbed Marlowe above the right eye, killing him immediately.\nAlthough some contend the ""self defence"" evidence offered at Marlowe\'s inquest was quite in keeping with the victim\'s alleged propensity for sudden violence, this has been brought into question by Charles Nicholl, who notes that Marlowe\'s supposed previous history of violence has been somewhat exaggerated. The tendency, particularly by Park Honan, to portray Marlowe as violent is also challenged by Rosalind Barber in her essay ‘Was Marlowe a Violent Man?’.\nIt has been suggested Frizer could have had other motives. Park Honan proposes that Marlowe\'s presence at Scadbury was a threat to Walsingham\'s reputation and influence, and thus threatened Frizer\'s interests also: The Privy Council certainly suspected Marlowe of atheism and heresy, and yet he was a regular and welcome house-guest of one of Elizabeth\'s former spymasters. At the start of 1593 it was upheld in Parliament that heresy was tantamount to the greatest crime of all—treason. Honan considers it possible that, given the circumstances, it was Thomas Walsingham himself, accustomed ""not to look far into Frizer\'s…trickery"", who initiated the deed by making his agent aware that Marlowe was becoming a liability to them both, and so indirectly securing his former friend\'s death.\nAnother theory suggests that Marlowe, as a supposed member of ""The School of Night"", became aware of Essex\'s plots against Raleigh, and Skeres was sent to warn him to keep silence. It was only when Marlowe refused to heed the warning was the unpremeditated decision taken to silence him in a more certain and final way. In this surmise Frizer is no more than one of Skeres\'s associates, and not the principal player.\nThe Marlovian theory suggests that Frizer took part in the faking of Marlowe\'s death to allow him to escape trial and almost certain execution for his subversively atheistic activities. This theory further suggests that Marlowe went into exile, and wrote the plays attributed to William Shakespeare.\n- Nicholl, Charles (1993). The Reckoning: The Murder of Christopher Marlowe. pp. 327–328. ISBN 0-226-58024-5. ""According to the official story – the story told by Skeres and Poley – it was Marlowe who pulled the knife and Frizer who killed him in self defence. ... I believe that in this, as in so much else in their careers, Skeres and Poley were lying."" ... ""Ingram Frizer may well have struck the fatal blow. It is probable, though not certain, that he did.""\n- Hotson, Leslie (1925). The Death of Christopher Marlowe. London: Nonesuch Press. p. 22. OCLC 459421025.\n- Nicholl (1993: 25)\n- Kuriyama, Constance Brown (2002). Christopher Marlowe: A Renaissance Life. Ithaca: Cornel University Press. p. 103.\n- ""FamilySearch"". Retrieved 13 February 2012.\n- Hampshire Record Office parish registers for Kingsclere\n- Honan, Park (2005). Christopher Marlowe: poet & spy. Oxford, England: Oxford University Press. p. 325. ISBN 0-19-818695-9.\n- Nicholl (1993:91)\n- Nicholl (1993: 22–25)\n- Honan (2005: 328; 350)\n- Boas, Frederick S. (1940). Christopher Marlowe: A Biographical and Critical Study. Oxford University Press. p. 327.\n- Nicholl, Charles (January 2008). ""Marlowe [Marley], Christopher (bap. 1564, d. 1593): Government service, c.1585–1587"". Oxford Dictionary of National Biography. Oxford, England: Oxford University Press. doi:10.1093/ref:odnb/18079.\n- Hutchinson, Robert (2006). Elizabeth\'s Spy Master. London: Weidenfeld and Nicolson. p. 111. ISBN 0-297-84613-2. ""The most famous spy in Walsingham\'s network was the dramatist Christopher Marlowe, who worked for him as a student...""\n- Honan (2005:121)\n- According to William Vaughan in his The Golden Grove, the most reliable of the contemporary accounts before the discovery of the inquest itself.\n- Honan (2005: 346)\n- Nicholl (1993: 35–37)\n- Nicholl (1993: 28–29)\n- Nicholl (1993: 31–32)\n- Hotson (1925)\n- According to William Vaughan they were playing ""tables"" (or backgammon).\n- The original of the pardon is in Chancery Patent Rolls 35 Eliz., 28 June 1593, and was first translated from the Latin by J. L. Hotson and published in his The Death of Christopher Marlowe (1925)\n- Honan (2005: 352)\n- ""…he was no stranger to violence…but [the evidence does not] prove much about him as an aggressor"": Nicholl (1993: 86–87)\n- Barber, Rosalind (2010). ""Was Marlowe a Violent Man?"". In Scott, Sarah K. Christopher Marlowe the Craftsman: Lives, Stage and Page. Ashgate. ISBN 978-0-7546-6983-8.\n- (35 Eliz. cap 1 Against Seditious Sectaries)\n- Honan (2005:348)\n- Nicholl (1993: 327)\n- ""The International Marlowe-Shakespeare Society"". marloweshakespeare.org. Retrieved 19 January 2012.']"	['<urn:uuid:47d61e33-c097-44e5-8bb3-d36586b7a2f9>', '<urn:uuid:4bd5aef5-714f-4c03-aa57-36b824b09a89>']	factoid	with-premise	verbose-and-natural	distant-from-document	comparison	expert	2025-05-12T22:49:38.933606	21	66	2472
78	What role did Venice play in the ancient spice trade and how did it connect to the battle of Acre during the Crusades?	Venice played a major role in the medieval spice trade, having the largest merchant navy in Europe by the early 1500s and using a sophisticated banking system. The city handled about 500 tons of spice yearly, mostly pepper, which generated much of Venice's wealth. This trade position connected to the battle of Acre because Acre's port was essential for Latin Christian transport and trade in the Mediterranean. The conflict over Acre involved competing trade armies from Venice and Genoa against the Mamluk sultanate, ultimately leading to Acre's fall in 1291.	['Roger Crowley. The Accursed Tower: The Fall of Acre and the End of the Crusades. New York: Basic Books, 2019. Maps. 272 pp. $28.00 (cloth), ISBN 978-1-5416-9734-8.\nReviewed by John Behnken (University of New Mexico)\nPublished on H-War (September, 2022)\nCommissioned by Margaret Sankey (Air University)\nThe Accursed Tower: The Fall of Acre and the End of the Crusades by Roger Crowley is a narrative history oriented on the battle of Acre and the sociocultural impact of its destruction in 1291. This work actively follows the train of source materials, crafting a narrative through fourteen chapters with an extended epilogue on the legacy of Acre. This monograph focuses on the final opportunity for Latin Christian influence within the Levant during the Seventh Crusade. The narrative perspective of Acre’s position is from the eyes of both those in the past and modern laypeople. The editing of this monograph is also commendable as Crowley notes in his acknowledgments the assistance of Arabic and German translators who illuminated constructive directions in this research. This assistance is evident in reading the narrative from a multicultural perspective.\nThe beginning of the monograph asserts the dire position of the Latin Christian Europeans as they existed within a multiethnic conflict. This conflict fostered social movement between the hierarchy of classes on all warring sides. The variable social strata of crusading Christians cared about Acre as its port provided essential transport and retained that value throughout its history. The excess of motivations between the combatting nations over Acre is adequately distilled by Crowley in two chapters, “The Second Kingdom of Jerusalem” and “Death on the Nile.” These short chapters increase the accessibility of the work and Crowley smoothly transitions the reader between the shifting historical narrative. For example, the important monastery of St. Sabas is central to the conflict for Acre, which reveals the wider struggle for trade supremacy between merchants of the Mediterranean and Black Sea. The manner in which Crowley portrays such simplicity is belied by the rich examples of social interactions provided.\nThis idea of an extended multiethnic conflict steaming to a head at the battle of Acre is continued throughout the monograph as Crowley establishes the competing trade armies of Genoa and Venice against a surging Mamluk sultanate. This methodology of analysis skillfully blends a fictional narrative approach with the veracity of source material. The auxiliary forces of the Mongols are positioned as overtly supporting the pope’s call for an anti-Mamluk campaign, which was naturally doomed by Christian infighting. The observation that Crowley makes is one that could easily lead to further research into the Mongol-Mamluk relations that existed beforehand. The very role and social status of the Mamluks as slaves who defeated Christians needed reconciliation within the Latin Christian sphere. Space here could have been devoted to the Black Sea slave trade that provided Mamluk leadership their military. Crowley provides illuminative social source material in multiple Latin contexts and this political position is briefly touched on. Alternatively, it is within individual cases of material analysis in the chapter “Bolts of Thunder, Flashes of Lightning” that Crowley’s work shines as he poses succinctly the values of opposing military arms. The coordinated bombardment of these war engines forced defenders to cover and provide heavier armaments like trebuchets to eliminate the battlements. This conclusion is proceeded by the cultural ties to these armaments and Crowley’s research into the necessity of these instruments is interesting.\nThe Accursed Tower provides a narrative window into the multicultural end of the Crusades with grace and effective prose. Crowley is adept at distilling extant primary sources into digestible material. His authorial style makes the Christians’ slow struggle understandable as they fall to defensive siege positions. For example, the Templar source that Crowley makes extensive use of observes the tactical ramifications of weather on the defenders. This narrative takes existing source material and expands on it to encompass the implication of environmental factors. He compares the observations made by the Templar sources to other such examples. He describes in vivid detail the vision of the defenders of the Accursed Tower. This effective method of analyzing and portraying history in narrative is seen best within the final chapters of the monograph. The turn to the Islamic response following the siege leads to the creation of apocryphal stories and fraudulent examples of accounts from similar sources. This development is interesting as it provides evidence of a multicultural impact of the war from alternative sources. This social narrative of the fall of Acre is an example of graceful negotiation of the past and the present as Crowley seeks to illuminate the positions of the crusaders and the people of Acre today.\nIf there is additional discussion of this review, you may access it through the network, at: https://networks.h-net.org/h-war.\nJohn Behnken. Review of Crowley, Roger, The Accursed Tower: The Fall of Acre and the End of the Crusades.\nH-War, H-Net Reviews.\n|This work is licensed under a Creative Commons Attribution-Noncommercial-No Derivative Works 3.0 United States License.|', 'Carried across land and sea from Asia the spices of the Far East arrived in the West via India. India was a half-way house between East and West and, along with the Axum Empire of northern Ethiopia and Eritraea fl. 100– CE which bounded the Red Sea, controlled the sea lanes into the Red Sea at this time although Roman merchants had learned how to take advantage of the seasonal monsoon winds. The Grand Trunk Road running across northern India was especially active in the Hellenistic period but probably dates back several millennia.\nIn the Indian segment of the Silk Road there are the c. 30 rock-cut Buddhist Ajanta Caves dating from the 2nd century BCE to about 480 CE with paintings and rock-cut sculptures that are outstanding examples of ancient Indian art and now a UNESCO World Heritage Site. They are, in effect, ancient monasteries and probably a monsoon retreat for monks, as well as a stopping point for travelling merchants and pilgrims.\nThe Ajanta Caves They are recorded by medieval Chinese Buddhist travellers and the Mugha official of the Akbar era in the early 17th century. Enveloped in jungle they were rediscovered and recorded for the West in 1819 by British colonial officer Captain John Smith when hunting tigers.\nBy 500 CE the Indian centre of trade had moved to Sri Lanka which was on the preferred trade route of merchants from Burma, Java, Sumatra and Malaya. Indian traders working in south-east Asia brought with them the Hindu and Buddhist faiths. Sanskrit inscriptions dating to the 4th century have been found in Indonesia perhaps the most obvious evidence of this Indian influence today being the 8th century Borobodur temple in Java and the 12th century temples around Angkor Wat in Cambodia.\nThe overland route from India to Europe was by camel and packhorse and it passed from India to Pakistan, Afghanistan, Iran, Iraq, Syria, Turkey, the Balkans and, finally, to Venice. The loyalty of the Veneti tribe to Rome had been rewarded with a gift of marshy lands where the tribe had prospered such that, by the 800s, a small township called Venice had emerged. By the early 1500s Venice had the largest merchant navy in Europe an it used a sophisticated banking system with branches in Europe’s main cities. Eastern influence was evident in the architecture, like the Doges palace. In the Middle Ages meat was salted and pepper was regarded as a culinary necessity for the well-to-do. Spices generated much of the wealth on display in Venice, driving the spice race that was launched from the Iberian Peninsula. Pepper served as a currency for the storage and exchange of wealth and it was a useful source of government tax revenue.\nArabic numerals though originating in India, had arrived in Europe with Arabic merchants.\nIndian connections with SE Asia and the Far East were invaluable to Arab and Persian traders of the 7th to 8th centuries.\nIslam, from its beginnings, encouraged trade. There was a natural transition from the star-guided navigation of camel caravans across the waves of the desert to navigation on the seas. From local trade in frankincense and myrrh to international trade in spices. Prophet Muhammad (c. 570-632 CE) was born into a family of spice traders and his revelations comitted to the Qur’an rapidly united the Arab empire from Baghdad to Alexandria under the religion of Islam and Muslim control of the spice trade throughout Arabia, initially under the control of the Umayyad Dynasty in Damascus. With the passing of the caliphate to the Abbasid Dynasty in 750 the centre of the Muslim world passed from Damascus to Baghdad, much closer to the Persian Gulf and trade along the Tigris and Euphrates. (B. p. 29) At the mouth of the Red Sea the port of Aden was used by shipping from India carrying ambergris, camphor, musk, and sandalwood. Captains would pay a tribute to the Sultan of Yemen to use the Red Sea and this led to the fabulous riches that are recounted in the Tales of Sinbad the Sailor. As Islam spread across North Africa c. 650 CE both overland European caravans and Red Sea shipping trade was closed off except via Arab merchants from Arabia and Persia.\nBy the mid 7th century CE there was a take-over of sea routes and this continued into the Middle Ages. Tribes of south and west Arabia also gained control of land trade between South Arabia and the Mediterranean. Nabateans took control of the route crossing the Negev from Petra to Gaza. Petra, the Nabatean city carved out of rock, provided an oasis for caravans on a route that passed by sea from Arabian Jeddah (adjacent to Mecca) on the east coast of Red Sea north to Medina, inland to Jordanian Petra and then on to Gaza on Israel’s southern coast. Trade in the Red Sea passed from Bab-el-Mandeb at the southern mouth of the Red Sea to Berenike, built by Ptolemy II and from the 1st to 2nd century CE the trading hub for Arabia, Egypt, India and the Malabar coast.\nWhen Alexandria was taken by Muslim forces in 641 CE direct trade with the Mediterranean ceased. As early as 671 Arab and Persian traders were operating in China and by the 8th century were trading with Canton (today’s Guangzhou). Here goods from the Moluccas would be loaded on the ships for the return trip – silk, camphor, porcelain, and spices, this trade coming to a halt when Guangzhou was destroyed by rebel forces in 878. At about the same time Buddhist traders had established a strong trading centre at Srivjaya (near Palembang) in South Sumatra where nutmeg and cloves from the Moluccas were passed on to merchants from China, Arabia, and India.\nIn the 13th century Arab vessels sailed from Basra at the head of the Persian Gulf trading their cargo on the way and using the monsoon winds to arrive in Canton (Guangzhou) six months later. Through the 15th century there was increasing European concern about Muslim control of trade to the East, about 80% of this being in Arab hands in 1400. The merchants of Venice were dealing with about 500 tons of spice a year, mostly pepper.\nMuslim control of trade continued in the high and late Medieval period through the Ottaman Turks. In the Middle Ages European trade was largely controlled by Venetian and Genoan merchants who dealt with the merchants of the Byzantine Empire. When the Ottoman Turks took Constantinople in 1453 the overland trade between Venice and the Arabs was finally closed off. There was just one possible way forward for Portugal and Spain, the maritime powers of the day … a sea route to the Indies. Ottoman Muslim rivals, the Mamluks, followed by increasing the duties on spices passing through Alexandria.\nMuslim trade domination was a major incentive for European sea powers to find alternative sea routes for their business and as navigational skills and shipbuilding improved the Age of Discovery opened up sea lanes via the Cape of Good Hope and world trade was steadily taken over by European colonial powers.\nThe first records of cloves in China date to the third century BCE.(B. p. 22)\nBy the 16th and 17th centuries technological advance in Europe – the improved ship building and sophisticated navigation aids so important to the Age of Discovery, the increasingly effective weaponry – presented European powers with the opportunity to loosen the Muslim grip on trade in the East while, at the same time, introducing the orient to the ‘one true religion’.\nEuropean merchants were also able to cash in on the fortunes to be made from spices, serving as middle-men in Silk Road trade that passed through Byzantium. Although trade was delivered to many ports it was, between about 700 and 1500 that the maritime republics of Italy, most notably Venice and Genoa, commandeered the trade passing to the Middle East – not only the lucrative spices and incense but also opium and other goods. Italy thus held a virtual monopoly on this trade until the rise of the Ottoman Empire and the fall of Constantinople that closed to Europeans the land-sea route to the east, the merchants of Venice amassing huge wealth together with considerable resentment.\nAt the Far Eastern nd of the trade route were the Austronesian sailors who were ancestors of Polynesians, Micronesians, Maoris, Malayans and Madagascans. They used outrigger canoes that carried cargoes of rice, taro, sugarcane, yams, breadfruit, and coconuts. Pliny noted how in his day these remarkable sailors traded cinnamon, the journey from their homeland to the coast of Africa and back taking about five years. However, their major trade occurred in India and included cloves and nutmeg as well as cinnamon also venturing along routes to the Mediterranean that included the Red Sea, Persian Gulf, as well as the Nile, Tigris, and Euphrates Rivers, in the classical era c. 50 BCE to 96 CE usually distributed round the Mediterranean following accumulation on the docks of Alexandria. Pepper was a major commodity traded with India at this time.\nWhile Rome was marching east, Chinese of the Han Dynasty (206 BCE-220 CE) were pushing west through the Gansu corridor to today’s northwestern Xinjiang Province from which it was about 1000 km to the crossroad city of Dunhuange on the fringes of the Taklamakan Desert. progress was hampered by the raids from the northern Yuezhi and Xiongnu nomadic tribesmen who, like the Scythians, were skilled horsemen. They were also a source of prize horses. The Kushan Empire was a syncretic Empire formed by the Yuezhi a people occupying the arid grasslands of today’s Chinese provinces of Xinjiang and Gansu. The Yuezhi siezed Greco-Bactrian territories in the early 1st century and at its height King Kanishka the Great (127–163 CE) ruled over an area that included much of Afghanistan and today’s Peshawar and northern India – from Turfan in the Tarim Basin to Pataliputra on the Gangetic plain. Turpan was a trading hub with numerous inns and brothels, a slave trade but mostly supplying vegetables, cotton and grapes, as China’s largest raisin-producing region. For many years China was prepared to pay for peace in goods but eventually lost patience and after about ten years intermittent struggle managed, in 119 BCE, to occupy the Gansu corridor marking what is possibly the time of east-west integration on the Silk Road.\nGeneral Ban Chao with tens of thousands of troops penetrated from the Great Wall as far as the Caspian Sea, even sending an envoy to Rome.\nSilk is a textile made from the extremely fine thread produced by silk-worms, the caterpillers of the insect Bombyx mori as they spin cocoons while feeding off the leaves of Chinese Mulberry, Morus alba. In a China lacking coinage silk was a valuable commodity of exchange and this use expanded into the international markets.\nIn the 7th century especially there was contact between India and China through the medium of Buddhist monks leading to later Buddhist shrines in Bamiyan (Afghanistan), Mount Wutai (China), Angkor Watt (Cambodia) and Borobudur (Indonesia).\nDuring the Tang dynasty (618-907) the capital city of Chang An in about 700 CE under female Wu Zetien had a population of about 1 million citizens and it was linked to the Silk Road as a city of great wealth and luxury based on its trade to the Mediterranean and Japan. Wu was a concubine who rose to become political leader during the brief Zhou dynasty interlude of 684–705 CE. Here there was the largest ever known palace complex (178 acres) that included areas for archery and polo. At this time rice was stored in vast granaries and Buddhism and its temples were established across the land. The famous five-storey Buddhist Giant Wild Goose Pagoda built in 652 CE in Xi’an was destroyed by an earthquake and was rebuilt in 701-704. This was an era in which women gained political power only to be resisted by the subsequent Confucian hierarchy.\nFrom 1206 to about 1360 the Mongol power of Ghengiz Khan and family extended beyond the Central Asian steppes into northern China forcing the Song Dynasty in 1227 to move to the southern trading port of Huangzhou and a new maritime trade and when this also fell in 1276 Kublai Khan ruled a trading route that extended 6000 km from China to the Black Sea. Strung along the route were trading hubs that included, from West to East, Erzurum (Anatolia), Kazan (C Russia), Solkhat (Crimea), Astrakhan (Lower Volta), Tabriz (N Iran, Samarkand (Transoxiana), Karakprum (C Mongolia) Beijing (N China). This ended the Islamic hold on world trade.\nFor the West this period is familiar through the chronicles of Marco Polo who was respectfully entertained by Kublai Khan who was keenly interested in life, the Roman Catholic Church, and other aspects of life in the the West. In 1271 the three Polo brothers Nicolo, Mafeo and the 15-year-old Marco had travelled with the Venetian merchant fleet noting that for the merchants of Venice, Pisa, and Genoa it was Antioch (Ayas) that was the main Mediterranean point of access to inland routes.\nAt the time of the Tang Dynasty China opened its doors, accepting foreigners and their trade while themselves sailing beyond India to become regular merchants along the Red Sea and Persian Gulf. During the Han Dynasty there was a long period of peace, a Pax Sinica, at the same time as the Pax Romana. This was later followed by a second Pax Sinica lasting from 589 to 907, mostly during the Tang Dynasty (618–907).\nMorco Polo describes Chinese smerchnat ships of the late 13th century carrying up to 300 people and cargos of 120 tons. Built with four masts, double hulls, airtight compartments (bulkheads) allowing the ship to remain afloat of the hull was damages – ships of this quality were not built by Europeans for another 500-600 years.By the 14th century Western visitors were also amazed by Chinese skills with porecelain and the use of paper money. By 1402 Emperor Yongle of the Ming Dynasty decided to open a political dialogue with the world’s great nations hoping that in return for gifts and protection they would pay tribute to the Emperor. Nanjing shipyards on the Yangtze River produced hundreds of giant junks – military, trade, and provision. This Treasure Fleet was placed under the command of Admiral Zheng He who, rom 1405-1433 led seven expeditions, the sixth rounding the Cape of Good Hope into the Atlantic. To mobilise such extraordinary campaigns, some with fleets of several hundred ships, required logistical skills and technology far in advance of any other country in the world. Though such forces were capable of subduing other countries these voyages were peaceable and on the death of Emperor Yongle in 1424 was succeeded by his Confucian son Zhu Gaotzi China once again looked inwards, leaving the seas open to the European ships and ambitions that would change the world. This theme is taken up in the next article.']	['<urn:uuid:9447a4c7-b382-42d5-be5c-da3044bbdf7c>', '<urn:uuid:17d1264e-4a2a-46b0-8100-cd7a09ad64e1>']	factoid	direct	verbose-and-natural	similar-to-document	three-doc	novice	2025-05-12T22:49:38.933606	23	90	3330
79	How do parental respect requirements apply in difficult situations, and what is the biblical teaching about paying tribute to authority figures who may be unworthy?	According to Jewish law, children must respect their parents regardless of the parents' moral character or behavior. This obligation stems directly from God's commandment and not from parental merit. Even if a parent exhausts their child's wealth or shames them, the child must still show honor because this is what God directed. The only exception is when a parent commands a child to disobey Jewish law. In parallel, the biblical teaching shows a similar principle regarding tribute to authority through Jesus' response about paying taxes to Caesar. When questioned about paying tribute to Caesar, Jesus responded that one should 'Give back to Caesar what is Caesar's, and to God what is God's,' indicating that respect for authority figures is required regardless of their worthiness, while maintaining ultimate loyalty to divine law.	"[""|OLD TESTAMENT||NEW TESTAMENT|\n|Old Testament |\n|Epistles of |\n|1 Thess. |\n|1 Καὶ ἤρξατο αὐτοῖς ἐν παραβολαῖς λαλεῖν. ἀμπελῶνα ἄνθρωπος ἐφύτευσεν, καὶ περιέθηκεν φραγμὸν καὶ ὤρυξεν ὑπολήνιον καὶ ᾠκοδόμησεν πύργον, καὶ ἐξέδετο αὐτὸν γεωργοῖς, καὶ ἀπεδήμησεν. 2 καὶ ἀπέστειλεν πρὸς τοὺς γεωργοὺς τῷ καιρῷ δοῦλον, ἵνα παρὰ τῶν γεωργῶν λάβῃ ἀπὸ τῶν καρπῶν τοῦ ἀμπελῶνος: 3 καὶ λαβόντες αὐτὸν ἔδειραν καὶ ἀπέστειλαν κενόν. 4 καὶ πάλιν ἀπέστειλεν πρὸς αὐτοὺς ἄλλον δοῦλον: κἀκεῖνον ἐκεφαλίωσαν καὶ ἠτίμασαν. 5 καὶ ἄλλον ἀπέστειλεν: κἀκεῖνον ἀπέκτειναν, καὶ πολλοὺς ἄλλους, οὓς μὲν δέροντες, οὓς δὲ ἀποκτέννοντες. 6 ἔτι ἕνα εἶχεν, υἱὸν ἀγαπητόν: ἀπέστειλεν αὐτὸν ἔσχατον πρὸς αὐτοὺς λέγων ὅτι ἐντραπήσονται τὸν υἱόν μου. 7 ἐκεῖνοι δὲ οἱ γεωργοὶ πρὸς ἑαυτοὺς εἶπαν ὅτι οὗτός ἐστιν ὁ κληρονόμος: δεῦτε ἀποκτείνωμεν αὐτόν, καὶ ἡμῶν ἔσται ἡ κληρονομία. 8 καὶ λαβόντες ἀπέκτειναν αὐτόν, καὶ ἐξέβαλον αὐτὸν ἔξω τοῦ ἀμπελῶνος. 9 τί οὖν ποιήσει ὁ κύριος τοῦ ἀμπελῶνος; ἐλεύσεται καὶ ἀπολέσει τοὺς γεωργούς, καὶ δώσει τὸν ἀμπελῶνα ἄλλοις. 10 οὐδὲ τὴν γραφὴν ταύτην ἀνέγνωτε: λίθον ὃν ἀπεδοκίμασαν οἱ οἰκοδομοῦντες, οὗτος ἐγενήθη εἰς κεφαλὴν γωνίας: 11 παρὰ κυρίου ἐγένετο αὕτη καὶ ἔστιν θαυμαστὴ ἐν ὀφθαλμοῖς ἡμῶν;||1 Then he began to speak to them in parables; There was a man who planted a vineyard, and put a wall round it, and dug a wine-press and built a tower in it, and then let it out to some vine-dressers, while he went on his travels. 2 And when the season came, he sent one of his servants on an errand to the vine-dressers, to claim from the vine-dressers the revenue of his vineyard. 3 Whereupon they took him and beat him, and sent him away empty-handed. 4 Then he sent another servant on a second errand to them, and him too they beat over the head and used him outrageously. 5 He sent another, whom they killed; and many others, whom they beat or killed at their pleasure. 6 He had still one messenger left, his own well-beloved son; him he sent to them last of all; They will have reverence, he said, for my son. 7 But the vine-dressers said among themselves, This is the heir, come, let us kill him, and then his inheritance will be ours. 8 So they took him and killed him, and cast him out of the vineyard. 9 And now, what will the owner of the vineyard do? He will come, and make an end of those vine-dressers, and give his vineyard to others. 10 Why, have you not read this passage in the scriptures, The very stone which the builders rejected has become the chief stone at the corner; 11 this is the Lord’s doing, and it is marvellous in our eyes?||1 Et cœpit illis in parabolis loqui: Vineam pastinavit homo, et circumdedit sepem, et fodit lacum, et ædificavit turrim, et locavit eam agricolis, et peregre profectus est. 2 Et misit ad agricolas in tempore servum ut ab agricolis acciperet de fructu vineæ. 3 Qui apprehensum eum ceciderunt, et dimiserunt vacuum. 4 Et iterum misit ad illos alium servum: et illum in capite vulneraverunt, et contumeliis affecerunt. 5 Et rursum alium misit, et illum occiderunt: et plures alios: quosdam cædentes, alios vero occidentes. 6 Adhuc ergo unum habens filium carissimum, et illum misit ad eos novissimum, dicens: Quia reverebuntur filium meum. 7 Coloni autem dixerunt ad invicem: Hic est hæres: venite, occidamus eum: et nostra erit hæreditas. 8 Et apprehendentes eum, occiderunt: et ejecerunt extra vineam. 9 Quid ergo faciet dominus vineæ? Veniet, et perdet colonos, et dabit vineam aliis. 10 Nec scripturam hanc legistis: Lapidem quem reprobaverunt ædificantes, hic factus est in caput anguli: 11 a Domino factum est istud, et est mirabile in oculis nostris?|\n|12 καὶ ἐζήτουν αὐτὸν κρατῆσαι, καὶ ἐφοβήθησαν τὸν ὄχλον: ἔγνωσαν γὰρ ὅτι πρὸς αὐτοὺς τὴν παραβολὴν εἶπεν. καὶ ἀφέντες αὐτὸν ἀπῆλθον. 13 Καὶ ἀποστέλλουσιν πρὸς αὐτόν τινας τῶν Φαρισαίων καὶ τῶν Ἡρῳδιανῶν ἵνα αὐτὸν ἀγρεύσωσιν λόγῳ. 14 καὶ ἐλθόντες λέγουσιν αὐτῷ: διδάσκαλε, οἴδαμεν ὅτι ἀληθὴς εἶ καὶ οὐ μέλει σοι περὶ οὐδενός: οὐ γὰρ βλέπεις εἰς πρόσωπον ἀνθρώπων, ἀλλ' ἐπ' ἀληθείας τὴν ὁδὸν τοῦ θεοῦ διδάσκεις: ἔξεστιν δοῦναι κῆνσον Καίσαρι ἢ οὔ; δῶμεν ἢ μὴ δῶμεν; 15 ὁ δὲ εἰδὼς αὐτῶν τὴν ὑπόκρισιν εἶπεν αὐτοῖς: τί με πειράζετε; φέρετέ μοι δηνάριον ἵνα ἴδω. 16 οἱ δὲ ἤνεγκαν. καὶ λέγει αὐτοῖς: τίνος ἡ εἰκὼν αὕτη καὶ ἡ ἐπιγραφή; οἱ δὲ εἶπαν αὐτῷ: Καίσαρος. 17 ὁ δὲ Ἰησοῦς εἶπεν αὐτοῖς: τὰ Καίσαρος ἀπόδοτε Καίσαρι καὶ τὰ τοῦ θεοῦ τῷ θεῷ. καὶ ἐξεθαύμαζον ἐπ' αὐτῷ.||12 This parable, they saw, was aimed at themselves, and they would gladly have laid hands on him, but they were afraid of the multitude; so they went away and left him alone. 13 Then they sent some of the Pharisees to him, with those who were of Herod’s party, to make him betray himself in his talk. 14 These came and said to him, Master, we know that thou art sincere; that thou holdest no one in awe, making no distinction between man and man, but teachest in all sincerity the way of God. Is it right that tribute should be paid to Caesar? Or should we refuse to pay it? 15 But he saw their treachery, and said to them, Why do you thus put me to the test? Bring me a silver piece, and let me look at it. 16 When they brought it, he asked them, Whose is this likeness? Whose name is inscribed on it? Caesar’s, they said. 17 Whereupon Jesus answered them, Give back to Caesar what is Caesar’s, and to God what is God’s. And they were lost in admiration of him.||12 Et quærebant eum tenere: et timuerunt turbam: cognoverunt enim quoniam ad eos parabolam hanc dixerit. Et relicto eo abierunt. 13 Et mittunt ad eum quosdam ex pharisæis, et herodianis, ut eum caperent in verbo. 14 Qui venientes dicunt ei: Magister, scimus quia verax es, et non curas quemquam: nec enim vides in faciem hominum, sed in veritate viam Dei doces. Licet dari tributum Cæsari, an non dabimus? 15 Qui sciens versutiam illorum, ait illos: Quid me tentatis? afferte mihi denarium ut videam. 16 At illi attulerunt ei. Et ait illis: Cujus est imago hæc, et inscriptio? Dicunt ei: Cæsaris. 17 Respondens autem Jesus dixit illis: Reddite igitur quæ sunt Cæsaris, Cæsari: et quæ sunt Dei, Deo. Et mirabantur super eo.|\n|18 Καὶ ἔρχονται Σαδδουκαῖοι πρὸς αὐτόν, οἵτινες λέγουσιν ἀνάστασιν μὴ εἶναι, καὶ ἐπηρώτων αὐτὸν λέγοντες: 19 διδάσκαλε, Μωϋσῆς ἔγραψεν ἡμῖν ὅτι ἐάν τινος ἀδελφὸς ἀποθάνῃ καὶ καταλίπῃ γυναῖκα καὶ μὴ ἀφῇ τέκνον, ἵνα λάβῃ ὁ ἀδελφὸς αὐτοῦ τὴν γυναῖκα καὶ ἐξαναστήσῃ σπέρμα τῷ ἀδελφῷ αὐτοῦ. 20 ἑπτὰ ἀδελφοὶ ἦσαν: καὶ ὁ πρῶτος ἔλαβεν γυναῖκα, καὶ ἀποθνῄσκων οὐκ ἀφῆκεν σπέρμα. 21 καὶ ὁ δεύτερος ἔλαβεν αὐτήν, καὶ ἀπέθανεν μὴ καταλιπὼν σπέρμα: καὶ ὁ τρίτος ὡσαύτως: 22 καὶ οἱ ἑπτὰ οὐκ ἀφῆκαν σπέρμα. ἔσχατον πάντων καὶ ἡ γυνὴ ἀπέθανεν. 23 ἐν τῇ ἀναστάσει, ὅταν ἀναστῶσιν, τίνος αὐτῶν ἔσται γυνή; οἱ γὰρ ἑπτὰ ἔσχον αὐτὴν γυναῖκα. 24 ἔφη αὐτοῖς ὁ Ἰησοῦς: οὐ διὰ τοῦτο πλανᾶσθε μὴ εἰδότες τὰς γραφὰς μηδὲ τὴν δύναμιν τοῦ θεοῦ; 25 ὅταν γὰρ ἐκ νεκρῶν ἀναστῶσιν, οὔτε γαμοῦσιν οὔτε γαμίζονται, ἀλλ' εἰσὶν ὡς ἄγγελοι ἐν τοῖς οὐρανοῖς. 26 περὶ δὲ τῶν νεκρῶν, ὅτι ἐγείρονται οὐκ ἀνέγνωτε ἐν τῇ βίβλῳ Μωϋσέως ἐπὶ τοῦ βάτου πῶς εἶπεν αὐτῷ ὁ θεὸς λέγων: ἐγὼ ὁ θεὸς Ἀβραὰμ καὶ ὁ θεὸς Ἰσαὰκ καὶ ὁ θεὸς Ἰακώβ; 27 οὐκ ἔστιν θεὸς νεκρῶν ἀλλὰ ζώντων. πολὺ πλανᾶσθε.||18 Then he was approached with a question by the Sadducees, men who say that there is no resurrection: 19 Master, they said, Moses prescribed for us that if a man’s brother dies, leaving a widow behind him but no children, he, the brother, should marry the widow, and beget children in the dead brother’s name. 20 There were seven brethren; the first married a wife, and died childless; 21 the second married her, and he too left no children, and so with the third; 22 all seven married her, without having children, and the woman died last of all. 23 And now, when the dead rise again, which of these will be her husband, since she was wife to all seven? 24 Jesus answered them, Is not this where you are wrong, that you do not understand the scriptures, or what is the power of God? 25 When the dead rise, there is no marrying or giving in marriage, they are as the angels in heaven are. 26 But as for the dead rising again, have you never read in the book of Moses how God spoke to him at the burning bush, and said, I am the God of Abraham, and the God of Isaac, and the God of Jacob? 27 Yet it is of living men, not of dead men, that he is the God; you are wrong, then, altogether.||18 Et venerunt ad eum sadducæi, qui dicunt resurrectionem non esse: et interrogabant eum, dicentes: 19 Magister, Moyses nobis scripsit, ut si cujus frater mortuus fuerit, et dimiserit uxorem, et filios non reliquerit, accipiat frater ejus uxorem ipsius, et resuscitet semen fratri suo. 20 Septem ergo fratres erant: et primus accepit uxorem, et mortuus est non relicto semine. 21 Et secundus accepit eam, et mortuus est: et nec iste reliquit semen. Et tertius similiter. 22 Et acceperunt eam similiter septem: et non reliquerunt semen. Novissima omnium defuncta est et mulier. 23 In resurrectione ergo cum resurrexerint, cujus de his erit uxor? septem enim habuerunt eam uxorem. 24 Et respondens Jesus, ait illis: Nonne ideo erratis, non scientes Scripturas, neque virtutem Dei? 25 Cum enim a mortuis resurrexerint, neque nubent, neque nubentur, sed sunt sicut angeli in cælis. 26 De mortuis autem quod resurgant, non legistis in libro Moysi, super rubum, quomodo dixerit illi Deus, inquiens: Ego sum Deus Abraham, et Deus Isaac, et Deus Jacob? 27 Non est Deus mortuorum, sed vivorum. Vos ergo multum erratis.|\n|28 Καὶ προσελθὼν εἷς τῶν γραμματέων, ἀκούσας αὐτῶν συζητούντων, ἰδὼν ὅτι καλῶς ἀπεκρίθη αὐτοῖς, ἐπηρώτησεν αὐτόν: ποία ἐστὶν ἐντολὴ πρώτη πάντων; 29 ἀπεκρίθη ὁ Ἰησοῦς ὅτι πρώτη ἐστίν: ἄκουε Ἰσραήλ, κύριος ὁ θεὸς ἡμῶν κύριος εἷς ἐστιν, 30 καὶ ἀγαπήσεις κύριον τὸν θεόν σου ἐξ ὅλης τῆς καρδίας σου καὶ ἐξ ὅλης τῆς ψυχῆς σου καὶ ἐξ ὅλης τῆς διανοίας σου καὶ ἐξ ὅλης τῆς ἰσχύος σου. 31 δευτέρα αὕτη: ἀγαπήσεις τὸν πλησίον σου ὡς σεαυτόν. μείζων τούτων ἄλλη ἐντολὴ οὐκ ἔστιν. 32 καὶ εἶπεν αὐτῷ ὁ γραμματεύς: καλῶς, διδάσκαλε, ἐπ' ἀληθείας εἶπες ὅτι εἷς ἐστιν καὶ οὐκ ἔστιν ἄλλος πλὴν αὐτοῦ: 33 καὶ τὸ ἀγαπᾶν αὐτὸν ἐξ ὅλης τῆς καρδίας καὶ ἐξ ὅλης τῆς συνέσεως καὶ ἐξ ὅλης τῆς ἰσχύος καὶ τὸ ἀγαπᾶν τὸν πλησίον ὡς ἑαυτὸν περισσότερόν ἐστιν πάντων τῶν ὁλοκαυτωμάτων καὶ θυσιῶν. 34 καὶ ὁ Ἰησοῦς ἰδὼν αὐτὸν ὅτι νουνεχῶς ἀπεκρίθη, εἶπεν αὐτῷ: οὐ μακρὰν εἶ ἀπὸ τῆς βασιλείας τοῦ θεοῦ. καὶ οὐδεὶς οὐκέτι ἐτόλμα αὐτὸν ἐπερωτῆσαι.||28 One of the scribes heard their dispute, and, finding that he answered to the purpose, came up and asked him, Which is the first commandment of all? 29 Jesus answered him, The first commandment of all is, Listen, Israel; there is no God but the Lord thy God; 30 and thou shalt love the Lord thy God with the love of thy whole heart, and thy whole soul, and thy whole mind, and thy whole strength. This is the first commandment, 31 and the second, its like, is this, Thou shalt love thy neighbour as thyself. There is no other commandment greater than these. 32 And the scribe said to him, Truly, Master, thou hast answered well; there is but one God, and no other beside him; 33 and if a man loves God with all his heart and all his soul and all his understanding and all his strength, and his neighbour as himself, that is a greater thing than all burnt-offerings and sacrifices. 34 Then Jesus, seeing how wisely he had answered, said to him, Thou art not far from the kingdom of God. And after this, no one dared to try him with further questions.||28 Et accessit unus de scribis, qui audierat illos conquirentes, et videns quoniam bene illis responderit, interrogavit eum quod esset primum omnium mandatum. 29 Jesus autem respondit ei: Quia primum omnium mandatum est: Audi Israël, Dominus Deus tuus, Deus unus est: 30 et diliges Dominum Deum tuum ex tota corde tuo, et ex tota anima tua, et ex tota mente tua, et ex tota virtute tua. Hoc est primum mandatum. 31 Secundum autem simile est illi: Diliges proximum tuum tamquam teipsum. Majus horum aliud mandatum non est. 32 Et ait illi scriba: Bene, Magister, in veritate dixisti, quia unus est Deus, et non est alius præter eum. 33 Et ut diligatur ex toto corde, et ex toto intellectu, et ex tota anima, et ex tota fortitudine, et diligere proximum tamquam seipsum, majus est omnibus holocautomatibus, et sacrificiis. 34 Jesus autem videns quod sapienter respondisset, dixit illi: Non es longe a regno Dei. Et nemo jam audebat eum interrogare.|\n|35 Καὶ ἀποκριθεὶς ὁ Ἰησοῦς ἔλεγεν διδάσκων ἐν τῷ ἱερῷ: πῶς λέγουσιν οἱ γραμματεῖς ὅτι ὁ Χριστὸς υἱὸς Δαυίδ ἐστιν; 36 αὐτὸς Δαυὶδ εἶπεν ἐν τῷ πνεύματι τῷ ἁγίῳ: εἶπεν κύριος τῷ κυρίῳ μου: κάθου ἐκ δεξιῶν μου ἕως ἂν θῶ τοὺς ἐχθρούς σου ὑποκάτω τῶν ποδῶν σου. 37 αὐτὸς Δαυὶδ λέγει αὐτὸν κύριον, καὶ πόθεν αὐτοῦ ἐστιν υἱός; καὶ ὁ πολὺς ὄχλος ἤκουεν αὐτοῦ ἡδέως. 38 Καὶ ἐν τῇ διδαχῇ αὐτοῦ ἔλεγεν: βλέπετε ἀπὸ τῶν γραμματέων τῶν θελόντων ἐν στολαῖς περιπατεῖν καὶ ἀσπασμοὺς ἐν ταῖς ἀγοραῖς 39 καὶ πρωτοκαθεδρίας ἐν ταῖς συναγωγαῖς καὶ πρωτοκλισίας ἐν τοῖς δείπνοις: 40 οἱ κατεσθίοντες τὰς οἰκίας τῶν χηρῶν καὶ προφάσει μακρὰ προσευχόμενοι, οὗτοι λήμψονται περισσότερον κρίμα.||35 Then Jesus said openly, still teaching in the temple, What do the scribes mean by saying that Christ is to be the son of David? 36 David himself was moved by the Holy Spirit to say, The Lord said to my Master, Sit on my right hand while I make thy enemies a footstool under thy feet. 37 Thus David himself calls Christ his Master; how can he be also his son? And the multitude at large listened to him readily. 38 This was part of the teaching he gave them, Beware of the scribes, who enjoy walking in long robes, and having their hands kissed in the market-place, 39 and the first seats in the synagogues, and the chief places at feasts; 40 who swallow up the property of widows, under cover of their long prayers; their sentence will be all the heavier for that.||35 Et respondens Jesus dicebat, docens in templo: Quomodo dicunt scribæ Christum filium esse David? 36 Ipse enim David dicit in Spiritu Sancto: Dixit Dominus Domino meo: Sede a dextris meis, donec ponam inimicos tuos scabellum pedum tuorum. 37 Ipse ergo David dicit eum Dominum, et unde est filius ejus? Et multa turba eum libenter audivit. 38 Et dicebat eis in doctrina sua: Cavete a scribis, qui volunt in stolis ambulare, et salutari in foro, 39 et in primis cathedris sedere in synagogis, et primos discubitus in cœnis: 40 qui devorant domos viduarum sub obtentu prolixæ orationis: hi accipient prolixius judicium.|\n|41 Καὶ καθίσας κατέναντι τοῦ γαζοφυλακίου ἐθεώρει πῶς ὁ ὄχλος βάλλει χαλκὸν εἰς τὸ γαζοφυλάκιον: καὶ πολλοὶ πλούσιοι ἔβαλλον πολλά, 42 καὶ ἐλθοῦσα μία χήρα πτωχὴ ἔβαλεν λεπτὰ δύο, ὅ ἐστιν κοδράντης. 43 καὶ προσκαλεσάμενος τοὺς μαθητὰς αὐτοῦ εἶπεν αὐτοῖς: ἀμὴν λέγω ὑμῖν ὅτι ἡ χήρα αὕτη ἡ πτωχὴ πλεῖον πάντων ἔβαλεν τῶν βαλλόντων εἰς τὸ γαζοφυλάκιον: 44 πάντες γὰρ ἐκ τοῦ περισσεύοντος αὐτοῖς ἔβαλον, αὕτη δὲ ἐκ τῆς ὑστερήσεως αὐτῆς πάντα ὅσα εἶχεν ἔβαλεν, ὅλον τὸν βίον αὐτῆς.||41 As he was sitting opposite the treasury of the temple, Jesus watched the multitude throwing coins into the treasury, the many rich with their many offerings; 42 and there was one poor widow, who came and put in two mites, which make a farthing. 43 Thereupon he called his disciples to him, and said to them, Believe me, this poor widow has put in more than all those others who have put offerings into the treasury. 44 The others all gave out of what they had to spare; she, with so little to give, put in all that she had, her whole livelihood.||41 Et sedens Jesus contra gazophylacium, aspiciebat quomodo turba jactaret æs in gazophylacium, et multi divites jactabant multa. 42 Cum venisset autem vidua una pauper, misit duo minuta, quod est quadrans, 43 et convocans discipulos suos, ait illis: Amen dico vobis, quoniam vidua hæc pauper plus omnibus misit, qui miserunt in gazophylacium. 44 Omnes enim ex eo, quod abundabat illis, miserunt: hæc vero de penuria sua omnia quæ habuit misit totum victum suum.|\n Ps. 117.22; cf. Rom. 9.33; I Pet. 2.7.\n vv. 1-12: Mt. 21.33; Luke 20.9; cf. Is. 5.1.\n Ex. 3.6.\n Deut. 6.4.\n Lev. 19.18\n Ps. 109.1.\n vv. 13-37: Mt. 22.15; Lk. 20.19.\n vv. 38-44: Lk. 20.45; 21.1.\nKnox Translation Copyright © 2013 Westminster Diocese\nNihil Obstat. Father Anton Cowan, Censor.\nImprimatur. +Most Rev. Vincent Nichols, Archbishop of Westminster. 8th January 2012.\nRe-typeset and published in 2012 by Baronius Press Ltd"", ""If a first child (daughter) of a father is born out of wedlock (my father married my mother after I was born, put his name on the birth certificate, but divorced her 6 months later) what laws and rules should I obey and how am I viewed in Jewish law? [Administrator's note: for answers on JVO regarding illegitimacy and the term mamzer vs bastardy, see http://www.jewishvaluesonline.org/question.php?id=27 and http://www.jewishvaluesonline.org/question.php?id=93.]\nTo What Extent is a Child to Honor and Respect a Parent Who is a Scoundrel?\nI. The Question:\na. Case A The question as asked is “If a first child (daughter) of a father is born out of wedlock (my father married my mother after I was born, put his name on the birth certificate, but divorced her 6 months later) what laws and rules should I obey and how am I viewed in Jewish law?”\nb. Case B A modern Orthodox wife and mother becomes more spiritual and observant. Her modern Orthodox husband undergoes a midlife identity crisis, he cannot tolerate his wife’s newfound and to his view, excessive piety, or his children’s religious sincerity. He leaves his home, wife, and children and connects with a Korean woman—young enough to be an oldest daughter-- who subsequently iconverted under non-halakhic auspices. His oldest daughter, a former Hebrew language and literature student of mine at a local Orthodox day school, becomes engaged to be married. Her father the home breaker and formerly observant, well educated Jew, demands that he and his new wife [a social gesture symbolically validating his new wife, his moral choices, and his newly discovered existential identiy] be invited to his daughter’s Orthodox wedding—after all, his daughter is Orthodox, she has to keep all the rules, including honoring him; the bride says, “I hate him, I do not want him in my life and certainly not at the wedding.” What to do?\nII. The statutes\na. The Torah at Exodus 20:12 and Deuteronomy 5:16 commands “Honor your father and your mother.” This apodictic syntax is foundational, constitutional, and seemingly allows no apparent exceptions.\nb. The Oral law teases out of the constitutional\nTorah text several specific norms:\ni. bQiddushin 30b. When married in rabbinic antiquity, the pappa who pays the penny gets the preference in honor which is expressed materially [Genesis 13:2]; if divorced, the parents are totally equal in their claims to respect.\nii. bQiddushin 32a also requires that parental respect be expressed tangibly, by providing financial support for parents.\niii. bKetubbot 103a. The child is obliged to honor his parents’ spouses, even if that spouse is not a parent.\niv. pQiddushin 1:6 requires that the child beg [seek alms from people at their doors] in order to sustain a parent.\nv. Maimonides, Mamrim 6:1 teaches that we respect and hold both parents in regard because God says so, and by implication, not for meta-halakhic fantasies. By respecting our parents, we respect God the lawgiver Who commanded that we respect our parents.\nvi. Supra.¸6:2. Cursing one’s parent is a capital offense.\nvii. Supra.¸6:3. We do not sit in judgment of or contradict our parents’ words, or sit in their seat. We stand in their presence and we do not address them by name during and after their lives.\nviii. Supra.¸6:7. Even if our parents exhausts our wealth and even after they shame us, we honor them because God in the Torah as so directed us to do so.\nix. Supra.¸6:10. If a child is unable to handle a demented paren, the child may provide care through surrogates.\nx. Supra.¸6:11, If a child is legally illegitimate, i.e. s/he was conceived through either incest or adultery, respect for the birth parent remains in force.\nxi. Supra.¸6:12. Only when a parent commands a child to disobey a Jewish law is the child to disobey the parent. It is God’s honor that generates value; parental honor is therefore derivative.\nIII. The value-driven decision\na. Case A refers to a man who is able to be a biological father but is unable—or unwilling-- to fill the moral role of father. The child’s obligation to honor her father derives from Torah law, and not from parental merit. By dint of her carrying her father’s DNA, she owes her father respect, deserved or not, because that is the Torah norm.\nb. Case B also requires respect for the wayward, sinful father. But here the case has a subtle nuance. Since her father gave his daughter his DNA at conception, she owes him respect and she must invite the “gentleman” to the wedding. The bride protested that she hates her father, she “cannot help it.” I responded: your father can say, “I cannot help it [=my feelings]” as well, and the Torah also happens to teach that hating is by law a forbidden moral disposition. [Leviticus 19:17] But since his consort was not Jewish by halakhic standards, his consort is not his wife according to Orthodox Jewish law. Therefore, while the bride owes her father respect in general and a wedding invitation in particular, she owes nothing at all to her father’s consort, who not being Jewish according to Orthodox Jewish law, she need not invite her to the wedding, even over her father’s objections. The father does not have the Jewish legal right to demand of her that she recognize what for Orthodoxy remains an intermarriage. The offended father happily did not attend the wedding.\nc. The Torah is teaching that we obey God without flinching, doing the right thing even if our egos find such obedience distasteful.\nBecause, however ironically, your legal status as a Jew (as you describe it) is so unmistakable, I worry that I may be misinterpreting your question:\nAssuming that your mother is Jewish (and was Jewish at the time of your birth), then you are Jewish, with no caveats or exemptions. Assuming that your mother was not married to anyone else at the time you were born, then there is no issue of the category mamzerut (often crudely – and misleadingly - translated as “illegitimacy” or “bastardy”), either. Mamzerut is ONLY an issue when the mother is married to someone else besides the father of the baby born.\nIf these assumptions are correct, then you should view yourself as a full member of the Jewish community, eligible to participate in any and all ways. You should obey and be included in all laws and observances, without any misgiving.\nI hope that this clarifies your questions about your Jewish status – and that you go on to live life as a Jew to the fullest!\nCopyright 2014 all rights reserved. Jewish Values Online\nN O T I C E\nTHE VIEWS EXPRESSED IN ANSWERS PROVIDED HEREIN ARE THOSE OF THE INDIVIDUAL JVO PANEL MEMBERS, AND DO NOT\nNECESSARILY REFLECT OR REPRESENT THE VIEWS OF THE ORTHODOX, CONSERVATIVE OR REFORM MOVEMENTS, RESPECTIVELY.""]"	['<urn:uuid:53382c8b-9ccd-4585-9ff3-c2fb1a3588b2>', '<urn:uuid:1ecd6e5b-a0b1-42d7-ae7f-eb415d8e9168>']	open-ended	direct	verbose-and-natural	similar-to-document	multi-aspect	novice	2025-05-12T22:49:38.933606	25	131	3978
80	What exactly happens when two surfaces rub against each other, and how does it affect the life of objects in machines?	When two surfaces rub against each other, wear and tear occurs, which depends on two factors: the roughness of the surfaces in contact and the amount of time they rub against each other. This wear and tear is not desirable as it reduces the life of the object. This is particularly important in the case of moving parts in automobiles and machinery, which is why efforts are made to reduce friction between moving parts.	['Ways of Increasing Friction and Reducing Friction\nMethods of Reducing friction\nWear and tear due to friction depends on two factors: the roughness of the two surfaces in contact and the amount of time the two surfaces rub against each other. Wear and tear of an object is not desirable as it reduces its life. This is more so in case of moving parts in automobiles and machinery. Therefore, efforts are made to reduce friction between moving parts.\nFriction between moving parts is usually reduced by introducing a substance between the moving surfaces. This process is called lubrication. The substance introduced is called a lubricant. Common lubricants are oil and grease.\nBall bearings are also used to reduce friction. Ball bearings change sliding friction to rolling friction. This is a very useful thing to do since rolling friction is much smaller than sliding friction. Ball bearings are used in most mechanical structures which have moving parts. Small metal balls made of stainless steel, brass, ceramic, etc., are placed between moving surfaces (the surfaces . can be flat or cylindrical) to reduce friction.\nOther than friction between solid parts, there can also be friction due to fluids (e.g., air and water). The force of friction due to air and water (and other fluids) is called fluid friction. When cars and aeroplanes move at very high speeds, their motion is opposed by friction offered by the air molecules surrounding them. The friction of air produces what is called drag, which opposes the motion of the vehicle. The same applies to ships and boats. To reduce drag, automobiles, ships, and aeroplanes are given a special shape, called a streamlined shape. An automobile with a streamlined body experiences minimum resistance when travelling through air. Even sea creatures like fish and shark have streamlined bodies, which makes it easier for them to move with great speeds in water.\nFrictional force can be reduced in the following ways\n- Use of lubricants: In machines, friction can be reduced by applying lubricants between the contact surfaces to fill the fine pores or depressions in the surfaces and make them smooth thereby reducing friction.\n- Polishing : unevenness of the surfaces can be reduced by polishing, thereby reducing the friction.\n- Use of ball bearings: In rotating machines, shafts are mounted on ball bearings. By doing so, rolling friction occurs lesser than sliding friction, thereby reducing the friction.\n- By streamlining: Air friction is reduced by designing streamlined bodies of cars or aeroplanes. Similarly, if the bodies of boats and ships are streamlined, friction of water can be reduced.\nMethods of Increasing Friction\nThere are two methods of increasing friction: one is by making the surfaces rough and the other by increasing the mass of the object that is moving.\nFor example, the tyres of vehicles have treads (these are the ‘designs’ that you can see on the tyre surface), which increase the friction between the tyre and the road. Similarly, the soles of shoes have grooves, in order to increase friction. Gymnasts often apply a coarse material on their hands to get a better grip by increasing friction.\nAim: To show that greater friction causes increased wear and tear.\nMaterials needed: A new eraser, a piece of paper from your notebook, a piece of cardboard, and sandpaper.\nMethod: Use the eraser to rub on the different surfaces mentioned above. Each time, make a note of the amount of wear and tear on the eraser.\nObservation: You will see that the rougher the surface, the greater the wear and tear.\nConclusion: Greater friction causes increased wear and tear.']	['<urn:uuid:96ad49c5-8cec-4816-8432-8a2ce584c947>']	open-ended	direct	verbose-and-natural	similar-to-document	single-doc	novice	2025-05-12T22:49:38.933606	21	74	600
81	What impact does coastal development have on oyster habitats, and how does their decline affect the growth of harmful algae?	Coastal development can prevent oyster reefs from migrating shoreward as sea levels rise, particularly when hard armoring or development blocks their movement. The loss of oyster populations has severe consequences, as their reduced filtration capacity allows harmful algal blooms (HABs) to intensify. For example, in Shinnecock Bay, this has led to recurring brown tides and red tides, with brown tides appearing since 1985 and red tides emerging in the past decade, causing fish kills and forcing shellfish bed closures.	"['Crassostrea virgnica, oyster, sea level rise, climate change, apalachicola, inundation, intertidal, gulf of mexico, estuary\nSea level rise and changing storm frequency and intensity resulting from climate change create tremendous amounts of uncertainty for coastal species. Intertidal species may be especially affected since they are dependent on daily inundation and exposure. The eastern oyster Crassostrea virginica is an economically and biologically important sessile intertidal species ranging from Canada to the Gulf of Mexico. Declines and changes in distribution of oyster populations has forced commercial harvesting to spread from subtidal to intertidal reefs. We investigated the potential responses of intertidal C. virginica to sea level rise, and the response of larval settlement to sedimentation which is likely to increase with higher water levels and storm frequency. Inundation was used as a proxy for sea level rise. We hypothesized four possible outcomes for intertidal oyster reefs as a result of changes in inundation due to sea level rise: (a) intertidal reefs become subtidal and remain in place, (b) intertidal reefs will be lost, (c) intertidal reefs migrate shoreward upslope and remain intertidal, and (d) intertidal reefs will grow in elevation and remain intertidal. To test the plausibility of these four outcomes, oyster ladders were placed at two sites within Apalachicola Bay, Florida, USA. Ladders supported oyster recruitment mats at five heights within the range of intertidal elevations. The bottom-most mat was placed near mean low tide, and the top mat near mean high tide to investigate the effect of tidal inundation time on C. virginica. Sediment traps were attached to ladders with openings at equal elevation to the oyster mats. Ladders were deployed for one year starting in June 2012, and again in June 2013, during peak oyster recruitment season. Monthly for six months during year one, sediment was collected from traps, dried to constant weight and weighed to obtain a monthly average for total sediment at each elevation. At the end of one year, oyster mats were collected from the field and examined for the following responses: live oyster density, mean oyster shell length of live oysters, mean oyster shell angle of growth relative to the benthos, and mean number of sessile competitors. We used AICc to identify the most plausible models using elevation, site, and year as independent variables. Oyster density peaked at intermediate inundation at both sites (maximum 1740 oysters per m2), it decreased slightly at the mean low tide, and sharply at the mean high tide. This response varied between years and sites. Mean oyster shell length peaked near mean low tide (6.7 cm), and decreased with increasing elevation. It varied between years and sites. Oyster shell angle of growth relative to the benthos showed a quadratic response for elevation; site but not year affected this response. Sessile competitor density also showed a quadratic response for elevation and varied between sites and years. Barnacles were the primary spatial competitor reaching densities of up to 28,328 barnacles per m2. Total monthly sedimentation peaked at the lowest elevations, and varied by site, with an order of magnitude difference between sites. Sediment increased with decreasing elevation. Outcomes a, c, and d were found to be viable results of sea level rise, ruling out complete loss of intertidal reefs. Outcome (a) would be associated with decrease in oyster density and increase in oyster length. Outcome (c) would require the laying of oyster cultch upslope and shoreward of current intertidal reefs, as well as the removal of any hard armoring or development. Outcome (d) remained possible, but is the least likely requiring a balance between sedimentation, oyster angle of growth, and recruitment. This should be further investigated. A laboratory experiment was designed to test relative impact of varying sediment grain sizes on settlement of C. virginica larvae. Previous studies showed that suspended solids resulted in decreased larval settlement when using mixed sediment grain sizes. Predicted storm levels and hurricane levels of total suspended solids were used in flow tanks. Sediment from the field experiment was sieved into seven size classes, the most common five of which were used in the experiment since they represented 98.8% of total mass. Flow tanks were designed and built that held 12 aged oyster shells, instant ocean saltwater, and sediment. Oyster larvae were added to the flow tanks and allowed one hour to settle on shells. Each run utilized one of the five size classes of sediment at either a high or low concentration. Following the one-hour settlement period, oyster shells were removed from the flow tank and settled larvae were counted under a dissecting microscope. Settlement was standardized by settlement area using Image J. AICc model selection was performed and the selected model included only grain size, but not concentration. A Tukey\'s post hoc test differentiated <63 ?m from 500 – 2000 ?m, with the < 63 µm grain size having a negative effect on oyster larval settlement. This indicates that the smaller grain sizes of suspended solids are more detrimental to oyster larval settlement than larger grain sizes. The oyster ladder experiment will help resource managers predict and plan for oyster reef migration by cultch laying, and or associated changes in oyster density and shell length if shoreward reef growth is not allowed to occur. The laboratory experiment will help to predict the impacts of future storms on oyster larval recruitment. Together this information can help managers conserve as much remaining oyster habitat as possible by predicting future impacts of climate change on oysters.\nIf this is your thesis or dissertation, and want to learn how to access it or for more information about readership statistics, contact us at STARS@ucf.edu\nMaster of Science (M.S.)\nCollege of Sciences\nLength of Campus-only Access\nMasters Thesis (Open Access)\nSolomon, Joshua, ""Identifying inundation-driven effects among intertidal Crassostrea virginica in a commercially important Gulf of Mexico estuary"" (2015). Electronic Theses and Dissertations. 1182.', 'Clams and oysters, which are suspension-feeding bivalves, are both a fisheries resource and a provider of key ecosystem services. These shellfish can have a variety of positive effects on estuaries through their feeding activities, such as reducing phytoplankton and other suspended particles. In recent decades, bivalve populations in Shinnecock Bay have declined through overfishing, habitat loss, and disease. Ecosystem services these species provide have been lost, causing reduced water quality and other impacts.\nAs a result of the severe reduction in bivalve filtration capacity, estuaries such as Shinnecock Bay are more vulnerable to environmental impacts associated with coastal human population expansion. For example, groundwater seepage is the primary source of nitrogen in many estuaries along the east coast of the United States. Another serious consequence of the absence of bivalve filtration pressure is harmful algal blooms (HABs), which are a significant threat to fisheries, public health, and economies around the world.\nShinnecock Bay is a prime example of an estuary experiencing the global trend of intensifying HABs. Beginning in 1985, “brown tides” began to appear in Shinnecock Bay during the summer months. These tides are a result of a dense bloom of the algae Aureococcus anophagefferens in the water column, and are stimulated by high levels of organic nitrogen. Because brown tide is better adapted to grow in areas with high levels of organic matter, it is able to bloom very successfully in coastal estuarine environments that are stressed by human activities. Although there is not yet one confirmed cause for these brown tides, research has implicated low rainfall, which reduces flushing, and elevated nutrients such as the nitrogen and phosphorus found in fertilizers and sewage.\nHigh densities of this type of algae give the water a visibly brown color. Unfortunately, brown tide is not the only harmful algal bloom in Shinnecock Bay, as red tides caused by toxic dinoflagellates (marine plankton) have emerged in this estuary during the past decade.\nThe first red tide, caused by the species Cochlodinium polykrikoides, occurred in 2004, causing kills of captive fish in the bay and at the Stony Brook Southampton Marine Science Center. These blooms have recurred annually since then, and are capable of causing rapid mortality in multiple species of finfish and shellfish. In 2008, the toxic dinoflagellate Alexandrium fundyense was first detected in Shinnecock Bay. This dinoflagellate differs from Aureococcus and Cochlodinium in that it produces a toxin (saxitoxin) that can accumulate in shellfish, leading to serious illnesses and even fatalities.\nA condition known as paralytic shellfish poisoning (PSP) can occur if contaminated shellfish are consumed by humans. This fear was nearly realized in the spring of 2011 when Alexandrium cell densities grew to more than 50,000 cells per liter, and shellfish in western Shinnecock Bay accumulated saxitoxins to levels more than four times higher than the USFDA established limit. The entire western half of Shinnecock Bay was closed to shellfishing and remained closed for more than a month. Unfortunately, this red tide event in April and May of 2011 was followed by anAureococcus brown tide in June and July which was followed by a Cochlodinium red tide in August and September. This chronic succession of harmful algal blooms in Shinnecock Bay has occurred annually for the past three years, and are evident this summer in 2012. This is a clear sign of the degraded nature of this system.\n(click image to enlarge)\nLocally, as a consequence of algal blooms, seagrass beds have been lost in much of Shinnecock bay. Eelgrass is a plant that requires light to manufacture food and energy for itself, and algal blooms reduce light penetration. Eelgrass beds are an extremely important component of marine ecosystems because they provide a habitat and food source for many animals that live in Shinnecock Bay. Without this critical habitat, the populations of many other organisms in the bay decline, especially shellfish that rely on the eelgrass beds for protection. Without shellfish to filter feed the dense blooms of phytoplankton out of the water, more eelgrass dies and a negative feedback loop is created.\nEelgrass beds also sustain fish populations by serving as nursery habitat for juvenile finfish. Hence, the loss of this habitat has had a further negative impact on fish populations that rely on seagrass. It is evident that algal blooms and loss of habitat, coupled with overfishing, have led to a dramatic drop in fish populations in Shinnecock Bay. For example, winter flounder is a recreationally important fish species of particular concern in Shinnecock Bay whose population has recently decreased.\nBrown tide in Shinnecock Bay (click image to enlarge)\nDr. Ellen Pikitch holding a juvenile flounder from the bay']"	['<urn:uuid:2108a706-d91b-4090-8b7d-9309e845ac80>', '<urn:uuid:f92239d7-8637-4090-bbd8-533bba62e6d8>']	factoid	direct	verbose-and-natural	distant-from-document	multi-aspect	novice	2025-05-12T22:49:38.933606	20	79	1744
82	What similarities exist between Victor de Sabata's approach to musical detail and the level of instruction found in Mahler's Tenth Symphony manuscript?	"Both demonstrated extreme attention to musical detail - De Sabata would ""rehearse in minute detail"" with orchestras where ""those eyes and ears missed nothing"", while Mahler's Tenth Symphony manuscript contains extensive detailed instructions, including specific opposing dynamics for different instruments (which was revolutionary for that time), along with meticulous notations and emotional instructions throughout the score."	"['Background - The Career of Victor de Sabata\nI hastened to review this disc as soon as I noticed that it was available.\nI had the pleasure of reviewing for Fanfare magazine, the 1998 Testament\nrestoration of Victor De Sabata\'s fabulous recordings of Debussy\'s La\nMer, Jeux and Nuages and Fêtes from the Three\nNocturnes; plus Respighi\'s Fountains of Rome. [Testament\n1108] For those who are unfamiliar with the work of this great conductor\nor those who might care to be reminded, I will quote some background detail\nfrom my review -\n\'Victor de Sabata had a working knowledge of all the instruments in the orchestra\nand his memory for musical scores was prodigious. He began conducting in\n1918 with concerts in Italy before he became conductor of the Monte Carlo\nOpera where, in 1925, he prepared and conducted the premiere of Ravel\'s\nL\'Enfant et les sortilèges. He later went on to conduct in\nLondon, Vienna, Berlin and Bayreuth. De Sabata\'s career came to a halt with\na cardiac crisis in 1953. Appearances were curtailed save for a few notable\nexceptions including a recording of Verdi\'s Requiem with Schwarzkopf, Dominguez,\nDi Stefano and Siepi; plus one more assignment, in Milan to conduct the Funeral\nMarch from Beethoven\'s Eroica. He died on 11th December\n\'De Sabata hated recording, so such recordings as he did make are, as Felix\nAprahamian has said, ""perhaps the more precious musical legacy of a great\nand unique musician."" Aprahamian knew de Sabata well, and he remembered the\nmaestro\'s working relationship with the London Philharmonic Orchestra. De\nSabata would rehearse in minute detail: ""Those eyes and ears missed\nthe players had been made to work harder than ever before and\nthey knew that, without having been asked to play alone, they had been\n\' The Daddy of them all\', said one player, but\nadded that the maestro looked like a cross between Julius Caesar and Satan.""\nTo these quotes, I would add another from this album\'s booklet attributed\nto a former leader of the LPO who remarked: ""With Beecham the orchestra became\nred hot. But above all, with Victor de Sabata the orchestra got white hot!""\nReviews of the Music on the CDs\nBrahms Symphony No. 4 in E minor (recorded April 1939 with the Berlin\nPhilharmonic Orchestra) - one immediately notices how lovingly this work\nis shaped by De Sabata. It flows beautifully and feels fresh and spontaneous.\nIt has power and authority but also great tenderness and intensity - De Sabata\nusing enough judiciously placed portamento and rubato to heighten the effect\nof the music. Some might quibble at some muddy rhythmic configurations, the\nodd rare bit of suspect intonation and, for some, uncomfortably fast tempi\nin the scherzo (but not me I found the effect exhilarating).) The overall\neffect, however, is glorious.\nWagner - Tristan und Isolde Prelude to Act I and Liebestod (recorded\nin April 1939 with the Berlin Philharmonic Orchestra). De Sabata\'s outpouring\nof white-hot emotion in this flaming, thrillingly-paced reading will set\nyou tingling. De Sabata once talked about the Philharmonia Orchestra in these\nterms: ""Your orchestra is the most wonderful English virgin. All she needs\nto achieve ultimate perfection is to be raped by a hot-blooded Italian. I\nwill do that for you!"" In this fervid, voluptuous Lieberstod, he does\nWagner - Tristan und Isolde - excerpts from a La Scala, Milan performance\n(recorded live on 11th December 1930). Despite severe background\nnoise, distortion and audience coughing, one senses an exceptional performance\nunravelling here. The end of the love duet of Scene II, Act II, from what\nwe can distinguish is a deeply-felt experience. The other fragments indicate\nthe remarkable, thrilling performances that De Sabata coaxed from his artists:\nGuiseppina Cobelli (Isolde), Renato Zanelli (Tristan) and Antonio Righetti\n(King Mark). CD2\nRichard Strauss - Tod und Verklärung (with The Berlin Philharmonic\nOrchestra; recorded April 1939). This is another performance to treasure.\nIt is a pity that the quiet early pages are spoilt by excessive surface\ncracklings but as the music picks up tempi and dramatic intensity, one soon\nforgets this distraction. The violence and emotional turbulence Strauss\'s\nhero encounters through his life\'s journey are fierily portrayed. The music\nrages and De Sabata whips up white heat excitement. His romantic interludes\nare tender and, in their climaxes, sensuous and hotly passionate. The soft\nstrokes of the gong, signifying the death of the hero, banishes all worldly\npreoccupations and Strauss takes us, in his imagination, into the hereafter.\nDe Sabata treads with appropriate awe and trepidation onto this higher plane.\nHis transfiguration develops into a most glorious heavenly vision.\nOttorino Respighi - Feste Romane (with The Berlin Philharmonic Orchestra;\nrecorded April 1939). The Testament recording of Sabata\'s reading of Respighi\'s\nFountains of Rome was revelatory and his view of Respighi\'s Roman Festivals\nis equally imaginative and thoughtful. The opening fanfares of \'Circenses\'\nare taken at surprisingly fast speeds (some may feel they are disconcertingly\nso) but De Sabata is cleverly creating an atmosphere of mounting excitement\nand hysteria. The Ancient Romans are eager for blood and gore as the Christians\nare thrown to the beasts. The ensuing savagery and carnage is vividly realised.\nThe second movement Il giubileo demonstrates De Sabata\'s excellent sense\nof control and pacing. This is a remarkable study in crescendo. The pilgrims\nare nearing Rome, their anticipation rising with their every step. De Sabata\nis right there with them, understanding their eagerness, recognising their\npiety and rejoicing with them as they see the Eternal City spread out before\nthem - bells tolling out in greeting. De Sabata\'s L\'Ottobrata is a joyful\ncelebration indeed, crisp yet magically romantic with its echoing hunting\ncalls and appealing mandolin melody. Unlike so many interpreters De Sabata\nknows that the festival of \'La Befana\' is primarily for the children (in\nItalian children\'s lore, a witch rewards good children and punishes the bad;\nand children receive presents during La Befana in the Piazza Navonna in Rome\non Twelfth Night). And so De Sabata\'s opening suggests a frightening witch\nand children\'s games and frolics, before the music opens out to embrace all\nthe excitements of the fairground and the riotous jubilation of Roman citizens\nat leisure - including that drunk. This has to be one of tne best ever\ninterpretations of this often recorded work.\nZoltan KODÁLY - Dances from Galanta (The Berlin Philharmonic\nOrchestra; recorded in April 1939). This is another tremendously exciting\nand invigorating reading. De Sabata catches all the Slavic nuances and turns\nof phrase. He elicits virtuoso performances from all sections of the Berlin\norchestra. A magnificent conclusion to a wonderful concert.\nAn album to treasure', 'Gustav Mahler: 10. Symphonie (Arranger: Michelle Castelletti)\nGustav Mahler: 10. Symphonie (Arranger: Michelle Castelletti)\n- Year of composition:\n- Scored for:\n- for chamber orchestera\n- Gustav Mahler\n- Michelle Castelletti (2012)\n- 1 1 1 1 - 1 1 0 0 - perc, hp, pno, vln, vln, vla, vc, cb\n- Instrumentation details:\nclarinet in Bb\nhorn in F\ntrumpet in Bb\n- for Angèle\nThe re-creation of Mahler’s Tenth Symphony through a new performing edition made in the contemporaneous tradition of the Verein für Musikalische Privataufführungen as established at the beginning of the 20th century.\n‘It should be one‘s sole endeavour to see everything afresh and create it anew.’1 Gustav Mahler\nPossibly one of Mahler’s most passionate emotional outbursts and autobiographical creations, Mahler’s Symphony No. 10 is a fascinating journey, not only for performance aspects, but also for musicological and analytical ones, providing a deep psychological pathway into the genius that was Mahler – a mesmerising voyage for the composer, performer and conductor.\nThe issue of re-orchestration has been a long-discussed debate amongst music scholars and performing musicians. My work relates to, and complements, existing musicological studies, as well as several reconstructions for full orchestra that have been made of Mahler’s last symphony.\nAlthough there are many versions, I focussed my investigation on the following: Derek Cooke (in collaboration with Berthold Goldschmidt, Colin Matthews and David Matthews); Rudolf Barshai; Alexander von Zemlinsky’s completion of movements 1 [&] 3 (with Alban Berg, Ernst Krenek and Franz Schalk); Clinton Carpenter; Remo Mazzetti and Joseph Wheeler.\nWhile the basic material remains intact, there are very significant differences in each of these orchestrations. Deryck Cooke’s version is arguably the most ‘faithful’ one, primarily representing Mahler’s own notes, to make the symphony performable. The edited score also contains a copy of most of Mahler’s annotations and sketches, together with the corresponding short-score in smaller print on every page, where it exists; and thus, I found this version particularly helpful, especially with regard to thematic continuity.\nMy intention was to re-create this symphony for chamber orchestra, retaining the authenticity found in the Mahler manuscripts, combining it with the fuller orchestral palette achieved by Rudolph Barshai, rather than the thinner textures realised in the Cooke version. This approach allowed for the various contrapuntal and timbral lines and colours to form one coherent structure, imbued within Mahler’s voice. Whether fully orchestrated in specific passages, or a sole melody in others, there is one continuous line throughout the surviving manuscript pages.\nThe original manuscripts were published in two separate facsimiles (Paul Zsolnay Verlag, 1924: 116 pages) and a more complete version in 1967 (160 pages) published by Walter Ricke under the aegis of the International Mahler Society, edited by Erwin Ratz.2 This edition included the Adagio and the Scherzo in full draft score, short score and sketch (with completion of varying degrees), 30 bars of full score of the Purgatorio, together with a short score and sketch; and short scores and sketches for the final two movements. Other pages were published in the 1976 score of the performing version by Deryck Cooke.\nThrough the collection of various facsimiles and scores of previous symphonies, I became very familiar with Mahler’s calligraphy, modus operandi, level of detail, instruction and intention. I also acquired the extant sketches of his ‘unfinished’ symphony, including the orchestral draft, the preliminary short score, Ricke’s and Zsolnay’s facsimiles of Mahler’s manuscript, a separate, solitary sketch-page, the surviving short score by Mahler, and, thanks to the National Library of Austria in Vienna, all existing Mahler’s sketches (including previously ‘lost’ pages) found at the Österreichische Nationalbibliothek.\nThis new performing edition for chamber forces is scored for single woodwind (with flute doubling piccolo), horn, trumpet, percussion, harp, piano/harmonium and single strings. The score gives ossia lines for double-bass, for the option of the C-string extension. It also gives the option of ossia lines for the timpani, just in case the 32’ one is not available.\nThe harmonium of choice is the Mustel 1902 Harmonium, with two manuals and with 4’, 8’ 16’ and 32’ stops. This is contemporaneous with the period, as used in Erwin Stein’s chamber orchestra version of Mahler‘s Symphony No. 4 and Schoenberg’s chamber orchestra version of Mahler’s Das Lied von der Erde. Specifically, this instrument is a double manual, with the full complement of expressive devices on a harmonium with 20 stops, and a 5-octave range.\nThe percussion instruments called for are the following: Timpani (a set of 5 would allow the solo at the end of Movement IV to be played with ease), 2 Cymbals (suspended: large, small*), 2 Triangles (large, small*), Glockenspiel, Xylophone, Tam-Tam, Bass Drum, Snare Drum, Tambourine, Whip/Slapstick, Finger cymbals*, Military Drum and Ratchet. The instruments marked with an asterisk are those played by the pianist, in part.\nColour and instrumentation, including Mahler’s use of unusual percussion instruments in symphonic literature to date; his use of con legno, mutes, gestopft and portamento; the culture of vibrato around the fin-de-siècle period; weight, balance, register, texture, and dynamic proportions3, had to be meticulously analysed.\nThe architecture and over-arching form and shape of the symphony, as well as the complexity of emotion this work carries, helped inform my interpretation. These fundamental factors also influenced the reconstruction and orchestration, and, perhaps above all, what I believe Mahler was attempting to say through this music, which is, in my opinion, overwhelmingly autobiographical, excitingly bipolar and plainly futuristic.\nI have taken the decision that this edition will be treated as a performing score. There are no dotted lines, square brackets, small notes – in fact, no editorial markings whatsoever. The doctoral thesis upon which this score is based4 contains all the explanations, footnotes, annotations etc. The fact that this score is already not what Mahler intended instrumentation-wise, would make the exercise of distinguishing between what was in the score and what not, almost futile, and impossible to read. This work is being published to be performed as a version for chamber orchestra.\nIn her forward to the 1924 facsimile edition of the Symphony No. 10, Alma Mahler wrote:\n‘While I initially considered it my absolute right to keep the treasure of the Tenth Symphony hidden, I now know it is my duty to reveal to the world the last thoughts of the master. […] It proclaims not only the last music of the master, but it shows in the impassioned strokes of his handwriting, the enigmatic self-image of the person with perpetuating effect. Some will read in these pages as if in a book of magic, while others will find themselves faced with magic symbols to which they lack the key; none will escape the power which continues to emanate from this handwritten music and scribbled verbal ecstasies.’5 There is endless debate about the ‘ethical’ issues which surround this.\nDo we have the right to do this? However, when one knows that this was being done at the time through the Verein itself, and adds to that, the admiration Schoenberg himself had for Mahler, as well as how Mahler encouraged the ‘creating anew’, I think that while such discussion is legitimate, there is enough evidence to support this endeavor. One need only turn to works like Mozart’s Requiem, Elgar’s Symphony No. 3, Bruckner’s Symphony No. 9, Puccini’s Turandot or even Mahler’s own completion of Carl Maria von Weber’s Die drei Pintos; as well as the very many works arranged for chamber version by the society itself, which gave 353 performances of 154 works in a total of 117 concerts, during its existence.\nEven Sir Georg Solti, who never claimed to be a composer, wanted to attempt reconstructing Mahler’s Symphony No. 10. Sadly, this was never to be, as Solti passed away in the summer of 1997.\n‘My performances of the opening movement of the Tenth Symphony made me want to attempt to conduct a reconstructed version of the whole work. [...] The melodic invention [...] is heartbreakingly beautiful. [...] The English musicologist Deryck Cooke made the first reconstruction of the symphony, but I have not used it as I think it lacks the contrapuntal element in Mahler’s writing. Three further versions of the Tenth Symphony exist or are in preparation and in the summer of 1999 I would like to work on a solution to the symphony, putting together the different reconstructions that are available and adding points of my own.’6 For my reconstruction there were many compositional decisions that had to be made based on colour and timbre to capture the essence of what was intended by Mahler within the chamber instrumentation I chose to work with.\nThere are ‘mistakes’ or ‘oversights’ in the orchestral draft – pitch, rhythm, omission of change of clef, two different (wrong) key signatures at the same time, no indication of time signature etc., as well as unclear instructions, and opposing or contradictory passages in different sketches. There are also instances of contrapuntal vacuums, in which case, the study of the different performing editions proved essential.\nIn places, some performing versions have made decisions to change what Mahler wrote in the orchestral draft, assuming that these were mistakes. My version tries to remain as faithful as possible to the orchestral draft, short score and extra sketches, especially harmonically, even when the language used is not conventional. Like Michael Kennedy, I believe that Mahler was stretching the harmonic palette as far as he possibly could.7\nI believe the stark contrast of an idyllic Toblach in South Tyrol, shattered by the discovery of Alma Mahler’s affair with the architect Walter Gropius8 is fully represented in Mahler’s language, colour, texture and form in this symphony. Desperate Mahler scribbles are found throughout the manuscript: Der Teufel tanzt es mit mir Wahnsinn, fass mich an, Verfluchten! vernichte mich dass ich vergesse, dass ich bin! dass ich aufhöre, zu sein dass ich ver [. . .]9 ending with ‘für dich leben! für dich sterben! — Almschi!’10 on its final pages.\nIt is, in my opinion, the epitome of the pain/beauty paradox, as described by Immanuel Kant.11 This is a work of excruciating beauty; a constant search for the sublime, which is found in the final movement.\nMahler is evidently distraught, as seen and heard through the pages of his manuscript. It feels like reading Mahler’s personal diary, invading his privacy and witnessing his innermost emotions being exposed to the world. It almost feels wrong. The autobiographical content of this most passionate cry in Mahler’s last symphony haunted me as much as the work itself. Yet, is there hope?\nWhat I have attempted to give is a faithful and stylistic re-creation of Mahler’s Symphony No. 10 – a correct representation of a large-scale work, retaining its profoundness, impact and magnificence; creating clarity of lines, but revealing the intimacy of the work.\nFor a conductor, to delve as deep as this, not only re-orchestrating, but rebuilding an unfinished, yet completely structured work, gives an extraordinary insight into the process of how to interpret a composer’s work – even one as complex as Mahler. One explores the symphony’s inner workings, practically and physically, but, more than that – especially in this particular work – psychologically.\nEven in his most impassioned symbolic tenth symphony, Mahler, the man of contrasts, remains unfaltering … the cruelty of the situation, the hurt, the anger, the tenderness, the anguish and torment … and the clinging on to hope and the longing for the beauty to re-emerge, and the acceptance of what is.\nMahler’s ‘scribbled verbal ecstasies’ are almost as powerful as his music – maybe to be read by the one who has caused him so much pain – his ‘immortal beloved’? – The Beethoven of the 20th century.\n‘It is absurd for any conductor in the twenty-first century to proclaim the Tenth unperformable [...] The Tenth exists as Mahler’s last word. It reveals Mahler, in his favoured metaphor, wrestling with his angel, refusing to let go without a blessing. If the symphony reveals nothing else, it is that Mahler did not surrender to fate, nor to depression at his wife’s betrayal, nor to health fears, nor to any other force except his mission to compose. In these final pages he surmounted the fickleness of love and life in a way that only Mahler could, with a never-say-die symphony that offers in its last unfinished page a glimmer of hope. No knowledge of Mahler is complete without the live experience of his Tenth Symphony.’12\n23 September, 2015\n1 H-L. La Grange, Mahler, Volume I, Garden City, NY, Doubleday [&] Co, 1973.\n2 T-L. Chew, Performing Versions of the Tenth Symphony, Naturlaut, Vol. 1 (2), 2002.\n3 This includes individual [opposing] dynamics for different instruments which was revolutionary for the time.\n4 I conducted the premiere of this editorial score as part of my PhD on November 23, 2012.\n5 D. Cooke, Gustav Mahler – a Performing Version of the Draft for the Tenth Symphony, London Faber Music, 1989.\n6 Sir Georg Solti, [with the assistance of Harvey Sachs], Solti on Solti – A Memoir. Vintage, 1998. It is the analyst/musicologist inside the conductor who takes over. Solti is well-known for discovering the right tempo marking of the second movement of Bartók’s Concerto for Orchestra. This has forever changed conductors’ interpretations of this work.\n7 Michael Kennedy, The Master Musicians – MAHLER, [from the series edited by Stanley Sadie] Oxford University Press, 2000.\n8 J. Bruck, MAHLER, G.: Symphony No. 10, Wheeler, 1966 version. Polish National Radio Symphony, Olson, 1999. [NAXOS CD].\n9 ‘The devil dances it with me / Insanity grasp me, the cursed one! / destroy me / so that I may forget that I exist / that I cease to be / that I ver [. . .]’\n10 ‘To live for you! To die for you! – Almschi!’\n11 Kant, I., Critique of Pure Reason, Guyer P. [&] Wood, A.W. (trans.) Cambridge University Press, 1999.\n12 N. Lebrecht, Why Mahler – How one man and Ten Symphonies Changed the World, Faber and Faber, London, 2001.\nGustav Mahler: 10. Symphonie\nfor chamber orchestera , 75’\nInstr.: 1 1 1 1 - 1 1 0 0 - perc, hp, pno, vln, vln, vla, vc, cb\n- Canterbury Chamber Orchestra\n- Michelle Castelletti']"	['<urn:uuid:43bf3b55-e125-447f-8fc6-05bf846484ff>', '<urn:uuid:66649320-b5e4-4127-aad7-9beca0b1bcc9>']	factoid	direct	verbose-and-natural	distant-from-document	comparison	expert	2025-05-12T22:49:38.933606	22	56	3474
83	I work at a vintage clothing store and often handle both modern and antique sweaters - what are the specific cleaning methods for sweaters made of delicate materials, and how do these methods differ between contemporary and antique pieces?	For modern delicate sweaters, follow the care label instructions carefully - many require hand-washing and should be dried naturally by laying flat. Avoid using alkaline-based detergents on wool and animal fibers. For antique sweaters, use a cold-water soap solution and handle them very gently during washing - do not rub as this causes pilling. After washing, soak in a vinegar bath. For both types, water removal is critical - either squeeze gently (don't wring), lay on a screen to drain, or wrap in a clean towel and use body weight to press out water. Modern sweaters can be tumble dried at low temperatures if the care label permits, while antique sweaters should be gently pressed with an iron on medium heat.	"[""The Wonderful World of Sweaters\nAs the styles of sweaters change, so do the fibers of this wardrobe staple. Sweaters are made from a variety of fibers, ranging from cotton and wool to silk, rayon, acrylic and more. Natural fibers, such as angora, mohair, cashmere, and Shetland are especially popular. To add to the variety many sweaters contain special decorative trims. Trims such as suede, leather, snakeskin, fur, sequins, and beads add to a sweater's special look. The following tips should make the care and maintenance of sweaters easier:\nA good tip for long lasting sweaters is to check to see if it will withstand your lifestyle. If you're an active person or plan on wearing it to dance parties, go for a harder, tighter yarn. Soft, loose yarns tend to stretch easily and often begin to show signs of wear much faster.\n• Although not a common occurrence, check to see if the seams on the sweater pull or fray easily. This is also a good indicator of whether or not it will withstand active lifestyles and can tell you of the quality of the overall product.\n• If the sweater you wish to buy has trim on it, ask the retailer about their return policy. This is recommended because most times the fabric will hold up to the rigors of life in general, but the trim is most often the weakest part. If the there is a problem with the trim, the store may allow you to exchange it depending how long ago it was purchased and the store's return policy.\nFollow your sweater's care label instructions closely to prevent shrinkage and stretching. Many sweaters are hand-wash only. In these cases, it is recommended to allow them to dry naturally by laying them flat. Some sweaters are gentle-cycle washable and others may require drycleaning. In any case, avoid using alkaline-based detergents (usually hard-surface only detergents) on woolens and other animal fibers.\n• If you have any doubts about the best way to approach an item, you may bring it to us to examine and offer a suitable cleaning method.\n• Tumble dry only at low temperatures, if recommended on the care label.\n• Treat stains right away. When spills are blotted immediately and professionally removed, stains won't develop later.\n• Sweaters with pile may be brushed to lift the fabric and remove any surface soils.\n• If wool sweaters get wet, let them dry at room temperature away from any direct heat source.\n• Check knitted sweaters for unraveling and fraying, and secure any loose yarns so the sweater can withstand normal use and care procedures without further unraveling.\n• Place folded sweaters over padded hangers in a well-ventilated closet or place in drawers. Do not hang sweaters from the shoulders; the weight of the sweater can cause it to stretch. Be sure to empty pockets, remove belts, and close zippers.\n• When storing sweaters, be sure to use breathable cloth garment storage bags to prevent yellowing and the development of stains.\n• Be sure to put sweaters away only when they are clean as any stains on the item may develop into worse stains or even attract moths (leading to moths eating through the fabric and creating holes).\n• Remember that delicate items may require special handling.\nPossible Issues When Cleaning\nWhile we are well versed in cleaning many different types of fabrics and treating multitudes of stains, some items may prove more problematic than others to clean. When the sweater is not cared for as directed or the stains on the sweater go untreated for too long then the likelihood of possible irreversible damage goes up.\nStretching, shrinkage, pulls, and pilling, both from use and cleaning may occur even when following the care labels of the items. Some stretching on knit items should be expected as a normal circumstance of wear and care to a given extent. Generally, the softer the knit, the more likely it is to show some change in texture or feel with normal wear, and this may be aggravated with washing or cleaning procedures.\nIf you have any questions about caring for your sweaters simply come to us and we can give you potential solutions to your needs."", 'Washing and caring for antique clothes can be simple if the right steps are taken. This can come in handy in many industries from dry cleaning to wedding alterations to costume design. Here are some commonly found antique garment types and how to care for them.\nSeparate any dyed silk garment and soak them separately in cool salt water. Following a thorough rinse, soak the garment in cool water and soap for 15 minutes. Rinse several times with clean water. Do not put the garment in the dryer – air-dry only as the heat may set wrinkles.\nHere’s the special trick to removing wrinkles and storing sink garments – sprinkle the clean garment with warm water, fold it neatly, and put in a plastic bag. Place the bag in the fridge for an hour. Upon removal, turn the garment inside out and iron. Spritz with water while ironing. A clean spray bottle is typically safer to use than the iron’s steam when working with antique fabrics.\nLinen is often silky to the touch after years of washing. Old linen, especially handkerchief quality, can be mistaken for cotton. To help tell the difference between linen and cotton, lay a piece of fabric on the back of your hand – if it’s linen, it will feel cool to the touch. Cotton, placed in the same location feels warm and dry.\nWhen cleaning white linen, wash with cold water, soap and a few drops of household ammonia. Follow this wash with a good soaking in hot water, liquid soap, and a small amount of chlorine bleach to brighten.\nRust stains on your linen? These can be the result of iron in your water. To correct the issue, you simply need lemon juice and salt. Sprinkle the salt and lemon juice over the dampened rust stain. Suspend the fabric over a bowl and pour boiling water through the stain from about 12″ away. Repeat until the stain is removed.\nWhen cleaning colored linen, soak the fabric in warm water and a cup of salt to set the dye. Rinse out the salt solution, and wash out the garment in warm water and a small amount of liquid laundry soap. Rinse the garment several times, and then soak in a white vinegar bath.\nMost people have experienced the new life a good washing can give to a fine sweater. To wash an antique sweater, soak and wash it in cold-water soap solution. Rinse it several times to gently remove the soap. DO not rub – this will cause pilling.\nSoak the sweater in a vinegar bath. Squeeze – don’t wring – the water, or lay it out on a screen over a sink to let the water drain out. Another option is to wrap the sweater in a clean towel, place it on the floor, and stand on it. Your body weight will push out the water. Gently press the sweater with an iron on medium heat.\nTailored suits of the 30’s and 40’s are well liked for their distinct shape and cut. Tip: look under the collar to determine the original color of the suit – years of washing and sun will fade. The many layers of interfacing and structured pleats means the garment needs to be cleaned with extra care.\nRepair any loose seams before washing. Soak the garment in a bathtub of lukewarm water and soap. Press down on the suit to remove dirt. Repeat with clean water until the water runs clear. Use the same drying process as used on sweaters above. A suit is best steam-press professionally.']"	['<urn:uuid:55852df0-0c6f-4552-bbe1-393ffb22de96>', '<urn:uuid:57e9d005-6684-4717-9256-108138bc389c>']	open-ended	with-premise	verbose-and-natural	similar-to-document	multi-aspect	expert	2025-05-12T22:49:38.933606	39	121	1303
84	light detection sensitivity pmt photoresistor compare	PMTs and photoresistors (LDRs) have different light detection mechanisms and sensitivities. PMTs use the photoelectric effect to convert light into electrical signals, achieving high amplification factors of 10^4-10^7 through multiple dynode stages. In contrast, photoresistors work by changing their resistance based on incident light, with resistance varying from several megohms in darkness to a few hundred ohms in bright light. PMTs are more sophisticated devices with precise quantum efficiency measurements, while LDRs are simpler, low-cost components commonly used for basic light level detection.	"['Photomultiplier tubes (PMTs) are photon detection device that uses the photoelectric effect combined with secondary emission to convert light into an electrical signal. A photomultiplier absorbs light emitted by the scintillator and re-emits it in the form of electrons via the photoelectric effect. The PMT has been the main choice for photon detection ever since because they have high quantum efficiency and high amplification.\nThe Photomultiplier tube is a key part of a scintillation detector. In general, a scintillation detector consists of:\n- Scintillator. A scintillator generates photons in response to incident radiation.\n- Photodetector. A sensitive photodetector (usually a photomultiplier tube (PMT), a charge-coupled device (CCD) camera, or a photodiode) converts the light to an electrical signal, and electronics process this signal.\nComponents of Photomultiplier Tube\nThe device consists of several components, and these components are shown in the figure.\n- Photocathode. Right after a thin entry window is a photocathode made of material in which the valence electrons are weakly bound and have a high cross-section for converting photons to electrons via the photoelectric effect. For example, Cs3Sb (cesium-antimony) may be used. As a result, the light created in the scintillator strikes the photocathode of a photomultiplier tube, releasing at most one photoelectron per photon.\n- Dynodes. Using a voltage potential, this group of primary electrons is electrostatically accelerated and focused so that they strike the first dynode with enough energy to release additional electrons. There is a series (“stages”) of dynodes made of relatively low work function material. These electrodes are operated at increasing potential (e.g., ~100-200 V between dynodes). At the dynode, the electrons are multiplied by secondary emission. The next dynode has a higher voltage which makes the electrons released from the first accelerate towards it. At each dynode, 3-4 electrons are released for every incident electron, and with 6 to 14 dynodes, the total gain, or electron amplification factor, will be in the range of ~104-107 when they reach the anode. Typical operating voltages are in the range of 500 to 3000 V. At the final dynode, and sufficient electrons are available to produce a pulse of sufficient magnitude for further amplification. This pulse carries information about the energy of the original incident radiation, and the number of such pulses per unit of time also gives information about the intensity of the radiation.\nPhotomultiplier Tube – Principle of Operation\nThe operation of scintillation counters and photomultiplier tubes is summarized in the following points:\n- The excited atoms of the scintillator material de-excite and rapidly emit a photon in the visible (or near-visible) light range. The quantity is proportional to the energy deposited by the ionizing particle, and the material is said to fluoresce.\n- Three classes of phosphors are used:\n- inorganic crystals,\n- organic crystals,\n- plastic phosphors.\n- The light created in the scintillator strikes the photocathode of a photomultiplier tube, releasing at most one photoelectron per photon.\n- Using a voltage potential, this group of primary electrons is electrostatically accelerated and focused so that they strike the first dynode with enough energy to release additional electrons.\n- These secondary electrons are attracted and strike a second dynode releasing more electrons. This process occurs in the photomultiplier tube.\n- Each subsequent dynode impact releases further electrons, so there is a current amplifying effect at each dynode stage. Each stage is at a higher potential than the previous to provide the accelerating field.\n- The primary signal is multiplied, and this amplification continues through 10 to 12 stages.\n- At the final dynode, sufficient electrons are available to produce a pulse of sufficient magnitude for further amplification. This pulse carries information about the energy of the original incident radiation, and the number of such pulses per unit of time also gives information about the intensity of the radiation.\nThe sensitivity of a photocathode is usually quoted in terms of quantum efficiency. In general, the term quantum efficiency (QE) may apply to the incident photon to converted electron (IPCE) ratio of a photosensitive device. The quantum efficiency of the photocathode is defined as the probability for the conversion of incident photons to an electrical signal and is defined as:\nThe quantum efficiency of any photosensitive device is a strong function of the wavelength of the incident light, and an effort is made to match the spectral response of the photocathode to the emission spectrum of the scintillator in use. In the photomultiplier tube, the quantum efficiency is limited to 20-30%, but an average quantum efficiency over the emission spectrum of a typical scintillator is about 15-20%.\nThe standard for quotation is the number of photoelectrons per keV energy loss by fast electrons in a NaI(Tl) scintillator. About 8 ~ 10 photoelectrons are produced per keV energy loss for the peak quantum efficiency. Therefore, the average energy loss required to create a single photoelectron is ~ 100 eV, much bigger than the values in gas-filled or semiconductor detectors.\nThe PMT has been the main choice for photon detection ever since because they have high quantum efficiency and high amplification. Lately, however, semiconductors have begun to compete with the PMT. The photodiode, for example, has higher quantum efficiency in the visible range and above, lower power consumption, and smaller size. The quantum efficiency for the photodiode is high (60-80%) compared to the PMT (20-30%), which gives a higher energy resolution.', ""Resistor Tutorial Includes:\nResistors overview Carbon composition Carbon film Metal oxide film Metal film Wirewound SMD resistor Variable resistors Light dependent resistor Varistor Resistor colour codes Resistor specifications Standard resistor values & E series\nLight dependent resistors, LDRs or photoresistors are often used in circuits where it is necessary to detect the presence or the level of light.\nThey can be described by a variety of names from light dependent resistor, LDR, photoresistor, or even photo cell, photocell or photoconductor.\nAlthough other devices such as photodiodes or photo-transistor can also be used, LDRs or photoresistors are a particularly convenient electronics component to use. They provide large change in resistance for changes in light level.\nIn view of their low cost, ease of manufacture, and ease of use LDRs have been used in a variety of different applications. At one time LDRs were used in photographic light meters, and even now they are still used in a variety of applications where it is necessary to detect light levels.\nWhat is light dependent resistor, LDR or photoresistor\nA photoresistor or light dependent resistor is a component that is sensitive to light. When light falls upon it then the resistance changes. Values of the resistance of the LDR may change over many orders of magnitude the value of the resistance falling as the level of light increases.\nIt is not uncommon for the values of resistance of an LDR or photoresistor to be several megohms in darkness and then to fall to a few hundred ohms in bright light. With such a wide variation in resistance, LDRs are easy to use and there are many LDR circuits available. The sensitivity of light dependent resistors or photoresistors also varies with the wavelength of the incident light.\nLDRs are made from semiconductor materials to enable them to have their light sensitive properties. Many materials can be used, but one popular material for these photoresistors is cadmium sulphide, CdS.\nHow an LDR works\nIt is relatively easy to understand the basics of how an LDR works without delving into complicated explanations. It is first necessary to understand that an electrical current consists of the movement of electrons within a material. Good conductors have a large number of free electrons that can drift in a given direction under the action of a potential difference. Insulators with a high resistance have very few free electrons, and therefore it is hard to make the them move and hence a current to flow.\nAn LDR or photoresistor is made any semiconductor material with a high resistance. It has a high resistance because there are very few electrons that are free and able to move - the vast majority of the electrons are locked into the crystal lattice and unable to move. Therefore in this state there is a high LDR resistance.\nAs light falls on the semiconductor, the light photons are absorbed by the semiconductor lattice and some of their energy is transferred to the electrons. This gives some of them sufficient energy to break free from the crystal lattice so that they can then conduct electricity. This results in a lowering of the resistance of the semiconductor and hence the overall LDR resistance.\nThe process is progressive, and as more light shines on the LDR semiconductor, so more electrons are released to conduct electricity and the resistance falls further.\nTypes of photoresistor\nLight dependent resistors, LDRs or photoresistors fall into one of two types or categories:\n- Intrinsic photoresistors: Intrinsic photoresistors use un-doped semiconductor materials including silicon or germanium. Photons fall on the LDR excite electrons moving them from the valence band to the conduction band. As a result, these electrons are free to conduct electricity. The more light that falls on the device, the more electrons are liberated and the greater the level of conductivity, and this results in a lower level of resistance.\n- Extrinsic photoresistors: Extrinsic photoresistors are manufactured from semiconductor of materials doped with impurities. These impurities or dopants create a new energy band above the existing valence band. As a result, electrons need less energy to transfer to the conduction band because of the smaller energy gap.\nRegardless of the type of light dependent resistor or photoresistor, both types exhibit an increase in conductivity or fall in resistance with increasing levels of incident light.\nLight dependent resistor specifications\nThere are several specifications that are important for light dependent resistors, LDRs / photoresistors.\nThese photoresistor specifications include:\n|Key LDR / Photoresistor Specifications|\n|Max power dissipation||This is the maximum power the device is able to dissipate within a given temperature range. Derating may be applicable above a certain temperature.|\n|Maximum operating voltage||Particularly as the device is semiconductor based, the maximum operating voltage must be observed. This is typically specified at 0 lux, i.e. darkness.|\n|Peak wavelength||This photoresistor specification details the wavelength of maximum sensitivity. Curves may be provided for the overall response in some instances. The wavelength is specified in nm|\n|Resistance when illuminated||The resistance under illumination is a key specification is a key parameter for any photoresistor. Often a minimum and maximum resistance is given under certain light conditions, often 10 lux. A minimum and maximum vale may be given because of the spreads that are likely to be encountered. A 'fully on' condition may also be given under extreme lighting, e.g. 100lux.|\n|Dark resistance||Dark resistance values will be given for the photoresistor. These may be specified after a given time because it takes a while for the resistance to fall as the charge carrier recombine - photoresistors are noted for their slow response times.|\nA typical light dependent resistor, LDR / photoresistor specification may be:\n|Example Photoresistor Specifications|\n|Max power dissipation||200mW|\n|Max voltage @ 0 lux||200V|\n|Min. resistance @ 10lux||1.8kΩ|\n|Max. resistance @ 10lux||4.5kΩ|\n|Typ. resistance @ 100lux||0.7kΩ|\n|Dark resistance after 1 sec||0.03MΩ|\n|Dark resistance after 5 sec||0.25MΩ|\nLDRs are very useful components that can be used for a variety of light sensing applications. As the LDR resistance varies over such a wide range, they are particularly useful, and there are many LDR circuits available beyond any shown here. In order to utilise these components, it is necessary to know something of how an LDR works, which has been explained above.""]"	['<urn:uuid:4f3a4abc-bbc7-4935-aca4-cad7bb213c19>', '<urn:uuid:3c314639-773d-4eb8-ae73-394cfcf125d6>']	open-ended	direct	short-search-query	similar-to-document	comparison	expert	2025-05-12T22:49:38.933606	6	83	1931
85	How long did it take to build the USS Ward?	The USS Ward was built at the Mare Island Navy Yard in California in a record of 17½ days, from May 15, 1918 to launching on June 1.	"['SEATTLE, WA – Microsoft co-founder and philanthropist Paul G. Allen’s expedition crew of Research Vessel (R/V) Petrel has documented the USS Ward (Destroyer No. 139) in its final resting place near Ponson Island in the Philippines. The expedition team released video images just prior to the anniversary of the attack on Pearl Harbor.\nThe USS Ward was a Wickes-class destroyer that famously fired the first American shot in World War II at 6:45 a.m. on Sunday, Dec. 7, 1941 just outside of Pearl Harbor, Hawaii. The ship and its crew sighted and sank a Japanese midget submarine. The submarine they sank was one of five top secret Japanese vessels, each armed with two torpedoes that intended to penetrate the harbor under cover of darkness before the attack began. The enemy air attack on Pearl Harbor, and throughout Oahu, started about an hour after the USS Ward sank the midget submarine.\nOn December 7, 1944, three years to the day, the USS Ward was lost after coming under attack by several kamikazes. She had been patrolling Ormoc Bay off the island of Leyte, serving as a high-speed transport for troops. She was hit at the waterline amidships by one of the attacking kamikaze. Unable to extinguish the resulting fire that was now consuming the ship, the crew was ordered to abandon ship. She was soon scuttled by an accompanying ship, the USS O’Brien. Poetically, O’Brien’s commanding officer was Lt. Cmdr. William Outerbridge, who had been in command of the USS Ward during the attack on Pearl Harbor three years earlier. Amazingly, only one USS Ward crew member was injured throughout the day’s events.\nWhile her remains rest at the bottom of Ormoc Bay, the Ward’s historical significance is not forgotten.\n""The USS Ward found herself in the crucible of American history – at the intersection of a peacetime Navy and war footing. She took decisive, effective and unflinching action despite the uncertain waters. Now 76 years on, her example informs our naval posture,"" said Adm. Scott Swift, commander of the U.S. Pacific Fleet.\nUSS WARD EXPEDITION A PAUL G. ALLEN PROJECT\nR/V Petrel is a 250-foot research and exploration vessel purchased in 2016 by Mr. Allen. Petrel\'s advanced underwater equipment and technology makes it one of the few ships on the planet capable of exploring to 6,000 meters deep (more than 3.5 miles). Following a 2017 retrofit, Petrel and its crew use state-of-the-art underwater technology for deep-sea search and exploration expeditions.\n“The Petrel and its capabilities, the technology it has and the research we’ve done, are the culmination of years of dedication and hard work,” said Robert Kraft, director of subsea operations for Mr. Allen. “We’ve assembled and integrated this technology, assets and unique capability into an operating platform which is now one among very few on the planet.”\nTo ensure the location of the ship was accurate, the USS Ward’s wreckage was identified and cross- referenced with historic drawings and schematics of the ship. The survey of the USS Ward was part of a combined mission to document the Imperial Japanese Warships that were lost during the Battle of Surigao Strait in the Philippines. During the November expedition, the R/V Petrel was able to capture video of IJN Yamashiro (FUSO class dreadnought battleship), IJN Fuso (FUSO class dreadnought battleship), Yamagumo (Asashio class destroyer), Asagumo (Asashio class destroyer) and Michishio (Asashio class destroyer). These ships and more than 4,000 men were lost during a decisive battle on October 25, 1944, considered the largest naval battle in history.\nAllen-led expeditions have also resulted in the discovery of the USS Indianapolis (August 2017), Japanese battleship Musashi (March 2015) and the Italian World War II destroyer Artigliere (March 2017). His team was also responsible for retrieving and restoring the ship’s bell from the HMS Hood for presentation to the British Navy in honor of its heroic service. Mr. Allen’s expedition team and R/V Petrel are dedicated to continuing exploration, marine archaeology and oceanographic research.\nABOUT THE USS WARD\n• History of USS Ward:\nThe Ward was launched on June 1, 1918 at Mare Island Navy Yard. Miss Dorothy Ward was the sponsor of the Ward. Ward was named in honor of Commander James Harmon Ward, US Navy, (1806–1861), the first U.S. Navy officer to be killed in action during the American Civil War.\nWard was built at the Mare Island Navy Yard in California in a record of 171⁄2 days. Under the pressure of urgent World War I needs for destroyers, her construction was pushed rapidly from May 15, 1918 to launching on June 1, and commissioning on July 24, 1918.\nIn July 1919, Ward was among the first ""nest"" of destroyers which passed through the Panama Canal locks as the Fleet took passage from the Atlantic to the Pacific. From there, Ward served ports along the west coast, from Seattle down to San Diego.\nWard was assigned a Navy identification number in July 1920, DD-139. Shortly after, she was placed in reserve and decommissioned on July 21, 1921.\nThe outbreak of WWII in Europe brought Ward back into service. She was recommissioned on January 15, 1941 to join the Fourteenth Naval District local defense forces in Pearl Harbor.\n• Action in Pearl Harbor:\nThe USS Ward was a Wickes-class destroyer that fired the first American shot in WWII at 6:40 a.m. on Sunday, Dec. 7, 1941.\nShe engaged a Japanese submarine before the attack on Pearl Harbor, successfully sinking her opponent.']"	['<urn:uuid:a5ab7c16-2a3f-4f68-aaea-d28e9e802152>']	factoid	direct	concise-and-natural	similar-to-document	single-doc	expert	2025-05-12T22:49:38.933606	10	28	908
86	As an environmental scientist studying soil conservation, I'm curious what specific role do native plants' root systems play in flood mitigation and storm water management?	Native plants' root systems play several important roles in flood and storm water management. Their deep roots facilitate rain and surface water returning to sub soils and aquifers. During heavy rains, these root systems allow rainwater to be absorbed into soils rather than overflowing storm drainage systems, providing flood mitigation services. Additionally, as native plants hold soils in place during rains, they help filter out pollution from storm water runoff.	"['When is a plant “invasive”?\nThe U.S. federal government defines an “invasive species” as “a species that is non-native or alien to the ecosystem” AND “causes or is likely to cause economic or environmental harm or harm to human health.”\nFolks often confuse the term ""invasive"" with the term ""aggressive"" and use the two interchangably, but they are NOT the same. Many plants can be aggressive, even native ones, that will readily spread and takeover an area where they may not be wanted. Nature abhors a vacuum, so where there is a ""blank"" in the land, nature will try to fill it in. Too often, though, invasive species, win that battle and take over not just the empty spots in lands, forests, prairies, waters, etc, but will out compete and take over natural spaces since the invasive species have no or few natural enemies to keep the invader\'s population in check / balance with the total environment.\nNorth Central Member, Cherie King explains it like this:\n""Please remember that invasive and aggressive are two very different things.\nThe best way I can explain the difference is this:\nA plant is aggressive when it is difficult to keep it in bounds in your own yard. Both native and non-native plants can be aggressive.\nInvasive means a plant escapes cultivation and displaces native plants in the natural environment. Invasiveness is something that homeowners are generally completely unaware of, because it doesn\'t occur on their own property. Plants escape cultivation when birds eat berries, and poop the seeds out elsewhere, when seeds blow on the wind, or are carried by water, or carried on the fur of animals. Invasiveness is determined when non-native species are discovered growing in wild areas, where no one would have planted them. These instances are usually discovered & reported by Forest Rangers, Park Rangers, environmental scientists and the like.\nOnly non-native species can be invasive. Think of it like this: you can\'t invade your own country.""\nHere are the top DIRTY DOZEN TERRESTRIAL INVASIVE SPECIES for the North Central Texas region as identified by TexasInvasives.org, a partnership of multiple agencies, industries and stakeholders who share the common goal of protecting Texas from the threats of invasive species.\nThese plants have been identified as particularly worrisome terrestrial invasive species in the Cross Timbers and Prairies ecoregion. Click on their scientific names to go to the Invasive Plant Database and learn more. Note this is just the top 12 on the list, so be sure to check out the TexasInvasives.org website for additional information.\nJapanese honeysuckle - Lonicera japonica\nGlossy privet - Ligustrum lucidum\nChinese privet - Ligustrum sinense\nGiant reed - Arundo donax\nChinese wisteria - Wisteria sinensis\nLilac chastetree - Vitex agnus-castus\nBrazilian vervain - Verbena brasiliensis\nGuineagrass - Urochloa maxima\nCommon periwinkle - Vinca minor\nChinaberry tree - Melia azedarach\nChinese tallow tree - Triadica sebifera\nJohnson grass - Sorghum halepense\nWhy are NATIVE Plants better than other plants I can buy at the nursery?\nNative plants are better because they perform functions that create and complete a healthy ecosystem that non-native plants cannot. Some of the benefits of Native Plants are:\n- Native Plants protect the biodiversity of life upon which we all depend.\n- Native Plants provide habitat for wildlife.\n- Habitat = homes, a place to rest, build a nest, lay low or high to ride out the severe weather\n- Habitat = places to find a mate, have a family and raise the next generation of their species\n- Habitat = food, directly through leaves, seeds, berries, bark and indirectly through other organisms (aka mostly insects), that thrive on native plants\n- Native Plants provide food for wildlife.\n- ""Wildlife"" includes many of the native pollinators that, by the way, provide food for you and me through their pollination services. Native plants and native pollinators co-evolved together over the eons and serve each others needs.\n- Of course, native plants also provide food for the wildlife we all really enjoy seeing everyday: birds, butterflies, etc.\n- Native plants support many of the insects that we may not pay as much attention to, but those insects are critically important to support the food web for those birds, butterflies, etc.\n- Native Plants provide food for you and me.\n- Pecan pie anyone? Or how about a dewberry cobbler? How about some pasture raised eggs for breakfast...those eggs came from free range, pasture roaming chickens that ate...you guessed it, native plants, and probably some insects too. Oh, those insects ate native plants too.\n- Think about it, everything you eat either is a plant, is something that came from a plant, or is something that ate a plant when you trace it to the origins of the interrelated food chain. Through the developments of modern agriculture, we may not recognize the native plant origins of many of the foods we eat today. Nevertheless, native plants are critical to support all forms of life, including you and me.\n- Native plants filter the air from pollution.\n- Carbon dioxide in, oxygen out.\n- Ok, all plants do this, but think about it, if a native plant is thriving in its tough local environment / growing conditions, whereas a non-native plant is struggling to survive in those same conditions, then it makes sense that a healthy native plant is going to perform these services better.\n- Native Plants are suited to their local community, which includes the local native soils. We may curse the difficult (clay, sand, caliche) soil we garden in, but for each soil type, there are native plants that are suited exactly for that spot. Why is this important?\n- Native plants\' roots are adapted to their local environment conditions including the challenging native soils and help retain the soil from run off. As native plants hold the soils in place during rains, they also help filter out pollution from the storm water runoff.\n- Native plants roots systems facilitate rain / surface water returning to the sub soils and, where present, to aquifers that store water underground.\n- Deep native plants\' root systems allow heavy rainwater to be absorbed into soils rather than overflowing storm drainage systems, thereby providing flood mitigation services.\n- Native plants store carbon in their structures and roots and can increase carbon stored in soil.\n- Did you know that a native prairie\'s deep roots can grow down to 15 feet deep and sequester more carbon that some forests?\n- Carbon sequestration can be increased in soils to help reduce increased atmospheric carbon that contributes to climate change. How do you take carbon out of the air and store it in the soil? Native plants\' leaves take in carbon dioxide through photosynthesis and carry it through the plant to its deep roots which emit excess carbon the plant did not use to the soil, where it feeds soil organisms that in turn help give soil its structure, water retention capabilities and fertility.\n- More Info\n- Native plants reduce the heat sink effects of the major metropolitan areas where we live: cities’ buildings and suburban sprawl of more buildings, roads & parking lots.\n- Native plants = cleaner drinking water.\n- When native plants are correctly placed in their desired growing conditions that mimic their ""native place"", they require less supplemental water and no fertilizers, pesticides or herbicides, which means less surface runoff pollution for those people living downstream from us. If we can convince the communities that are upstream from us to use more native plants, that means less runoff pollution in the drinking water you and I rely on.\n- You\'ve heard the catch phrase ""We need to drain the swamp!"", right? Well, in reality, that swamp is probably a wetland, a low spot meant to hold water (seasonally or year round) and includes native plants that want to grow in wet or damp soils. These critically endangered native plants provide necessary services of literally cleaning the pollution that drains into wetland waterways.\n- Learn how humans are mimicking Mother Nature\'s natural wetlands that include native plants to provide clean drinking water for North Texas citizens.\nHow do I plant wildflower seeds I received from your booth at a H&G show or other event?\nThe North Central Chapter purchases native plant seeds from Turner Seeds. Below are links to their info about the species of native plants in the seed mix we purchase and their instructions for planting wildflower seeds.\nClick here to see: Wildflower Seed Mix from Turner Seeds\nClick here to see: Planting Information\nWhich products should I AVOID using because they have neonicotinoids that harm pollinators and other wildlife?\nMany have us have heard the news that many off the shelf products containing neonicotinoids, are causing great harm to the pollinators, especially bees and butterflies, and other wildlife that rely on insects for food. As members of the Native Plant Society of Texas and with our understanding that Native Plants = Healthy Habitats, we encourage everyone to discontinue use of chemical pesticides since we are trying to provide safe habitat for wildlife and the ecosystem that supports us all. But exactly which products contain these harmful chemicals? Unfortunately, at the time of this writing, there is not a national policy for clearly labeling products as containing neonicotinoids, so be wary of all chemical pesticides and avoid their use completely if you can. If you have a real invasion that you feel you must treat for, please consider researching and applying an organic solution, like integrated pest management or others that can be found through internet searches. There are many good ones out there that are much more cost effective and less harmful to you, your pets, and the wildlife that lives in our urban habitats. If you absolutely must use a chemical pesticide, consult the lists that you can click on below (and other more up to date versions may be available on the internet) BEFORE you go to the store, to search for one that does NOT contain neonicotinoids. When you look at a product\'s label, you want to find the information on the packaging that lists the active ingredients. If you see one of the following names listed, the insecticide includes a neonicotinoid:\nThese lists show products that contain neonicotinoids, which should be avoided.\nDo you have to be a member to attend meetings?\nNo, membership meetings where we have a guest speaker or activities are open to EVERYONE! Members, guests, friends, or anyone from the public interested in native plants or the topic / activity of the month is welcome to attend! Meetings are on the first Thursday of the month, except January and July.\nI have a photo or article I would like to share. Where do I send it?\nWe welcome your contributions to add photos, announcements, news articles, ""How to Grow"" info, etc. to both the monthly chapter newsletter and this website. The newsletter editor and website team have a shared email address so that they don\'t have to pass items back & forth to each other. Please send your submissions to email@example.com\nPlease note that due to the layout of the template we purchased when creating this website, photos that are featured on the opening Home page of the website, need to be a high resolution, so technically speaking their ideal size is at least 2000 pixels wide. We can edit photos that are too large to trim them to size, but photos that are lower resolution are not suitable for the Home page since they start to look too out of focus. We can still use smaller resolution photos in many other places throughout the website. Please send us some new ""eye candy"" for this website.\nDemo Gardens, Parks, Nature Centers\nIs photography one of the ways you enjoy native plants? If so, please consider visiting one of our demo gardens or a park with native plants or nature center. We would love to receive your photo contributions of native plant places featuring:\n- attractive plant combinations\n- individual plants\n- close ups of plant features\n- wildlife on native plants\n- people enjoying the native plants\nWhich native plants are hosts for caterpillars of Monarch butterflies?\nThere are several species of Asclepias, commonly known as milkweeds, that are native to the eco-regions which cover the North Central chapter. A few of the most common ones are:\n- Asclepias asperula, Antelope horns milkweed\n- Asclepias tuberosa, Butterfly milkweed or pluerisy root\n- Asclepias viridis, Green milkweed\n- Funastrum cynanchoides, Milkweed vine\nHow can I get involved?\nAs an all volunteer organization, the North Central Chapter can only do what its members do. There are no paid staff to carry out our mission. So pick and choose from the following:\n- Attend membership meetings and invite a friend to join us\n- Bring an item to membership meetings to donate to the raffle\n- Attend Board meetings to be in the know of what is going on\n- Participate in gardening days for the demonstration gardens\n- Share a photo or write an article for the monthly newsletter\n- Talk to any of the Chapter Leaders re: how you can help them\n- Let the Vice President know of any topics or speakers you would like to hear at our meetings.\n- Talk with the NC President about becoming a chairperson of a committee\n- Participate in the City of Fort Worth, Mayor\'s Monarch Pledge Committee\n- Donate native plants to the plant sale\n- Volunteer to work at the plant sale\n- Assist in set up and hosting of NLCP classes or lead a plant walk for the class\n- Become a NICE! representative to a local retail nursery\n- Volunteer to engage the public at our information booth at community events.\n- Bring a snack to share at meetings\n- Post our chapter\'s activities on public community calendars\n- Share our chapter\'s meetings, events & activities on your social media and with your friends\n- Help weave together a network of those concerned about the environment: Share your knowledge about other like minded organizations\' events and activities through the newsletter, make an announcement at meetings or tell a Chapter Leader.\n- Go on a field trip or native plant / prairie walk and learn at least one new native plant\n- If you volunteer at a school garden, promote the inclusion of native plants\n- Speak up for native plants to be used in your homeowners association landscape spaces\n- Post on the Chapter\'s Facebook private discussion group\n- Share photos that can be posted on the new chapter website.\nIf we all take a turn to share the load, we can do a lot! Many hands make light work! Start by taking just one item above and do it in the next month.\nWhere can I buy Native seeds?\nNative American Seed is a wonderful source to buy native seeds.\nWhy do you have a raffle at meetings?\nThe raffle is used to collect a small amount of money to help cover the costs of the meeting room at the Botanic Gardens and other chapter expenses. A ticket only cost $1 or you can get 6 tickets for $5. The raffle also provides a way for members / attendees to share extra native plants, or gardening items they have. For example, a friend wanted to get rid of a bunch of decorative pots, so I took them to donate for the raffle. You can help support the North Central chapter by bringing an item to donate to the raffle or by buying a raffle ticket.\nWhere & when do you meet?\nMembership meetings are held at the Fort Worth Botanic Gardens, 3220 Botanic Garden Blvd. Fort Worth. Meetings are on the 1st Thursday of each month, excluding January and July.\n6:15 socializing & snacks\n6:30 membership meeting, announcements\n7:00 guest speaker\nHow much sun is full sun vs. part sun vs. shade?\nWith a very hot climate in North Central Texas, many plants that are considered ""full sun"" by the horticulture industry can tolerate some shade. Here are the general rules of thumb:\n- Full Sun is at least 6 hours of full direct sunlight per day\n- Part Sun is between 2 and 6 hours of full direct sunlight per day\n- Shade is less than 2 hours of full direct sunlight per day.\nDappled shade of mixed sunlight and shade from tree canopies can alter these rules somewhat and it also depends on the particular plant.\nRemember to think about the fact that the sun is lower in the horizon in winter and higher in the horizon in summer, so as seasons change during the year, the shadows created by buildings, trees, etc. also change and effect the amount of sun or shade a particular planting area may get.']"	['<urn:uuid:2980b198-55b1-4ea2-9e09-508cecb46f03>']	factoid	with-premise	verbose-and-natural	similar-to-document	single-doc	expert	2025-05-12T22:49:38.933606	25	70	2817
87	Do flounder and skipjack herring both migrate seasonally?	Yes, both species migrate seasonally. Flounder make migrations offshore in fall and back inshore in spring, with larger flounder participating in these migrations while smaller ones remain inshore. Skipjack herring migrate upstream in the spring to spawn, sometimes traveling very long distances, though they are not required to be anadromous like other members of their family.	"[""Hot Lure Working Magic On Georgia Flounder\nTactics for jetties and creeks, and a new jig that'll catch more flatfish.\nFlounder are on the move this month, migrating back from nearshore reefs and wrecks. Every year they make a migration offshore in the fall and then back inshore in the spring. It’s the larger flounder that make the migrations. The smaller ones, the ones from the current and previous years’ hatches, remain inshore in the creeks and estuaries for the winter. They won’t migrate until they are a year or two old.\nKnowing that the bigger flounder are on the move and knowing where they will be makes them easy targets this month. It’s time to break out the flounder rigs and find a doormat-sized flounder!\nAll along the Georgia coast, the inlets from the St. Marys River to the Savannah River will be holding flounder. I made several trips to locate some flounder for you, and we concentrated on the St. Marys area, and more specifically we looked to see if we could find a few definite locations where you can find flounder.\nIt’s been a warm winter, and the water is warming faster this year than in past years, which means the flounder will be here when you read this. If you have read any of my saltwater articles in GON, you know I write a lot about the St. Marys area. There are two reasons for that. First, it’s close to me. I’ll travel for fish, but if I can find them close to me, I fish at home. The second and main reason I fish this area so much is because there are so many fish here.\nThe first place we fished on each trip was the jetties at the entrance to the inlet. After a short ride from the public boat ramp in downtown St. Marys, we made our way around the end of the north set of jetties. Simple logic tells us the flounder have to come by here to make their way inshore, so we looked for them to be staging here on their way in.\nWe rounded the end of the north jetty and made our way back west toward the beach. The tide was about half down and outgoing, so the water coming out of the inlet was filtering through the rocks coming north toward us. It’s a perfect situation, because you don’t have to worry so much about being pushed too close to the rocks. Rather we had to use the trolling motor to keep us up close enough to cast to the rocks.\nThe flounder will lie in the sandy bottom along the edge of the rocks all along the jetties. We began fishing in water that is close to the shore, but not too close to the breaking surf. We worked from there out toward the end of the jetty and then cranked up and ran back and worked it again.\nWhile a trolling motor is not an absolute necessity, it does allow us to fish more area with less effort. Anchoring is a definite possibility, but you will find yourself moving often and pulling and resetting your anchor. Use a rebar jetty anchor and move close to the rocks. Drop the anchor, and back off with your engine. Once the anchor hangs, the slight current coming through the rock on the outgoing tide will hold you off the rocks. You can then cast to the rocks fanning left and right and work the entire area close to the rocks. The flounder will seldom be far off the rocks, and working the bottom away from the rocks is usually not very productive.\nOn the inside of the jetty, the outgoing tidal current is swift and difficult to fish. You can work the inside of the jetty when the tide slows, stops and begins to move back in. Work the inside of the jetty the same way, making casts up to the rocks. Also cast close to and parallel to the rocks and work your bait back to you slowly along the bottom.\nOn our trips, the wind was out of the west, which is an ideal situation. The water was calm with almost no surf and no sea swell. An east wind will stir the water, and a strong east wind will make fishing the jetties a challenge, so look at the weather and choose the day the wind is either very calm or is out of the west. Those are the days when you have the best chance of finding flounder on the rocks.\nI concentrate on artificial baits when I fish, simply because I prefer them. But natural live bait like a live mud minnow or finger mullet are actually the best baits for flounder. Live shrimp will work as well if you can’t find other bait. But, a 4-inch-long finger mullet is a killer for flounder.\nWhen I fish with live bait, I use a flounder rig consisting of a sinker above a swivel. A 12- to 14-inch fluorocarbon leader is tied to the other end of the swivel, and a 2/0 or 3/0 kahle hook completes the rig.\nThis month, baitfish like mullet are on the move. It is easy to find small schools of mullet and catch them with a cast net. Hook them through both lips with the kahle hook, and work them along the bottom. I drag the sinker along the bottom close to the rocks as the mullet swims above it. A flounder simply cannot resist it.\nWhen a flounder bites, it’s not going to be a hard-running strike. Often it’s more like a resistance on the line as the flounder grabs the passing bait. If you set the hook at that point, you’re going to end up with a half a bait because he does not have the whole bait in his mouth. You are going to have to be patient and allow the flounder to eat the whole bait before setting the hook. Let him move with it for a few seconds before you jerk. Mud minnows or live shrimp are less apt to be bitten in half, but the same rule applies. Let the fish eat the whole bait.\nAs for artificial lures, I like the Saltwater Assassin Sea Shad in the electric-chicken color on a 1/4- to 1/2-oz. jig head. The tail has a nice swimming action, and the color is one that works well for me. The root-beer color also catches a lot of flounder. I cast to the rocks or parallel to the rocks and slowly work it back to the boat.\nOn one trip we used a new jig head that is coming to the market. Bett’s Tackle is producing a new jig head designed specifically for flounder. The lead head is flat, and the hook is bent upward and turned sideways. The flounder’s mouth is actually sideways, and the new sideways hook is designed to more easily get into the mouth on the first bite. The Flounder Fanatic will work with live bait as well as the artificial baits we used, and it seems to be just the thing for flounder. It works really well with a live mullet or mud minnow.\nIn freshwater, when you go bass fishing, you are generally going to catch bass. If you are crappie fishing, you catch crappie. But in saltwater it’s a different world. The baits and methods we use for one fish more often than not also catch other fish. On our trips, we caught a number of seatrout and red drum while looking for flounder. On the jetties, we were cut off numerous times by a passing school of bluefish. The blues were so thick at one point that we put a small wire leader on the jig heads to prevent cutoffs.\nWhen the tide changed and was incoming, we could no longer stay positioned on the rocks. The now incoming current would push us into the rocks, so we moved and concentrated on fishing a creek. On this trip, we moved into the inlet to Beach Creek at the southern tip of Cumberland Island. This is a deep creek that meanders a mile or so back into the island marsh. It has numerous sloughs, feeder creeks and runoffs that provide feeding places for flounder. Flounder will position themselves at the mouths of these locations or along the edges of oyster bars and await meals coming to them on the outgoing tide. Lots of flounder are caught by working these mouths and oysters with the same baits and tactics we used on the rocks; live or artificial baits worked slowly on the bottom.\nBut what most people don’t realize is that you can catch the flounder in those same locations on the incoming tide. The same baitfish that came out of those sloughs and runoffs on the outgoing tide make their way back into the same areas on the incoming tide. And, the flounder will be there waiting for them to return.\nThe only requirement is that the water needs to be moving. The current has to be running to move the baitfish in.\nSince we had fished the outgoing tide out on the jetties, we were now faced with a low and incoming tide at Beach Creek. We had to tilt the engine and slowly make our way across the bar at the entrance to the creek, but once in the creek, the water was plenty deep to navigate. However, we were not going far. Our plan was to start at the mouth of the creek and let the tide move us in with help from the trolling motor.\nWhenever we came to a feeder branch or runoff location, we used the trolling motor to slow us and allow us to make several casts. As the tide came in, the current increased and we tended to speed along with the current. But, it was perfect. We could fish quietly and cover a lot of territory.\nOn the first and third trips we found zero flounder in Beach Creek. On the second trip, we caught a number of flounder, although most of them were small. The point is that flounder are on the move. They can be in a given location one day and be gone the next. So the key to being successful is finding similar territory to fish. There are numerous, literally hundreds of small creeks like Beach Creek along the Georgia coast. And, at some point all of them will hold flounder.\nGet your chart out, and make a fishing plan so you can hit a number of these creeks during the day. Remember, as long as the water is moving, incoming or outgoing, you are subject to finding a flounder sitting in the mouths of the smaller feeder creeks.\nThe third opportunity we fished was hitting the docks at St. Marys. Any dock or piling in the water can hold a flounder. The tidal current moving past the piling forms a small eddy behind the piling, an ideal location from which a flounder can strike at a passing meal. Every dock in the Intracoastal Waterway (ICW) can hold a flounder or two. But, just like the creeks, they may be there one day and be gone the next. It’s a matter of finding them by fishing multiple locations.\nFlounder fishing, that is fishing specifically for flounder, means a lot of moving. Flounder are not normally schooling fish, so anchoring and fishing in one location might get you one or two flounder all day, but not a limit of fish. You are going to have to hunt for them one or two at a time. You may get a limit of fish out of one creek, but they will be scattered in the creek. You have to move to catch them.\nIn spring and fall, the biggest flounder of the year are caught as they make their migrations. Now is the time to hit the inlets, the creeks and the docks on the Georgia coast and put some flatfish fillets in your freezer.\nOther Articles You Might Enjoy"", 'Skipjack herring are large river fish that prefer to reside in clear, deep, and swift waters over gravel or sand. These fish most often travel in large schools, partly for protection from larger predatory species. Skipjack herring are not generally found on the bottom of the river, and they avoid muddy or cloudy waters whenever possible. They frequently ""skip"" along the surface of the water when migrating in early spring. Skipjack herring are known to congregate in swift currents below dams. Unlike many members of family Clupeidae, skipjack herring are not required to be an anadromous species. These fish spend most of their life cycle in rivers and occasionally in coastal marine estuaries. Skipjack herring migrate upstream in the spring to spawn, sometimes traveling very long distances. The addition of dams in many areas has impeded their ability to migrate further upstream. This has resulted in their disappearance in many areas where they were once present such as in Minnesota. (MN DNR, 2013; Morrison, 2009)\nSkipjack herring have a slender, compressed body and can reach a maximum length of 21 inches. These fish have a large mouth and pointed snout with a protruding lower jaw, which is distinctive from other similar species. Skipjack herring have teeth in both jaws as well as two to four rows on their tongue. They are gray dorsally and silver or white laterally and ventrally. At times, skipjack herring can appear to have a blue reflection coming from their sides. These fish also have yellow eyes with protective eye lid covers. Skipjack herring have modified scales on their slender body. These scales are referred to as ""scutes"" and form a saw-tooth margin around the belly, which distinguishes skipjack herring from other similar species. (""Skipjack Herring"", 2012; MN DNR, 2013)\nSkipjack herring complete their entire life cycle in fresh water. Information regarding their spawning patterns is very limited; however, skipjack herring are thought to spawn in the deepest channels over coarse gravel or underwater sandbars. Juveniles feed on zooplankton, insect larvae, and small fishes, fish consumption increases proportionately with size. Juvenile skipjack herring reach lengths of 75 to 150 mm during their first year of life. Sexual maturity occurs at about 300 mm. Immediately after hatching, skipjack herring are on their own and many are eaten by predatory fish. Juveniles that survive the first few months of life have greatly increased chances of survival. Skipjack herring typically stop growing after reaching 21 inches in length, which means they do not have indeterminate growth. (""Herring Family: Clupeidae"", 2008; Hassan, 2013)\nVery little information is available regarding the spawning patterns of skipjack herring. These fish are unique in family Clupeidae, as not all skipjack herring make an anadromous journey. In general, members of family Clupeidae spawn in the spring, once water temperatures have warmed to between 11 and 27° Celsius. Before spawning, skipjack herring typically travel a long distance. Due to the water temperature requirements, spawning typically occurs earlier at lower latitudes and later at higher latitudes. Female clupeids typically reach the spawning grounds before males, where the oldest females spawn first. Since clupeids travel in schools, they do not have a problem finding or attracting mates. These fish typically form mating pairs, or groups of three. Females drop their eggs in moderately deep, to very deep areas over gravel, while males simultaneously fertilize them with sperm. (""Herring Family: Clupeidae"", 2008)\nFemale skipjack herring reach sexual maturity in approximately three years, while males are thought to mature in two years. Females are thought to lay between 100,000 and 300,000 eggs every spring after their migration. Mature skipjack herring immediately leave the spawning site once the spawn is complete. Larvae hatch in 58 hours at 17.2° Celsius. The average larval length after hatching is roughly 3.4 to 3.6 mm. After the spawn concludes, larval skipjack herring are immediately on their own. (Ross, 2001)\nSkipjack herring give no parental care after the young hatch; they immediately leave the spawning grounds and begin the journey back to their original habitat location. Larval skipjack herring spend the summer in the shallows and in the fall, they move to large groups in the main channel for protection. (""Skipjack Herring"", 2012)\nNot much is known about the lifespan of skipjack herring. However, many species in family Clupeidae commonly live to 10 years of age. Most skipjack herring do not live past the first few months of life, around 90% die within the first year of life. Once skipjack herring make it past the first year of life, their chances of survival begin to increase with their increasing size. The biggest threat to the longevity of skipjack herring is predation. Many species prey upon skipjack herring as their primary diet. (""Herring Family: Clupeidae"", 2008; Coad, 1997)\nSchools of skipjack herring drive minnows to the surface for easy capture and often leap out of the water when feeding. These fish often congregate in large numbers below dams in the spring, presumably attempting to migrate upstream to spawn. Skipjack herring vertically migrate daily, this means they move up and down the water column at certain times of the day in search of food. (""Assessment of Migratory Stocks"", 2011; MN DNR, 2013)\nThe home range of skipjack herring includes the Mississippi River. Skipjack herring often migrate up tributaries to spawn, but they typically retreat to the Mississippi River after the spawn due to the relatively steady water levels, large main channel, and swift moving water. There is currently no information available regarding the territory size maintained by these fish. (MN DNR, 2013)\nLittle to no information is known about the communication of skipjack herring besides their feeding and mating behavior. Their yellow eyes are thought to help them find other skipjack herring for mating. Likewise, their yellow eyes also help them locate their prey in low light conditions. (""Herring Family: Clupeidae"", 2008)\nThe diet of skipjack herring includes: plankton and small fishes, primarily minnows, goldeneyes, and gizzard shads. Skipjack herring also feed on insects such as mayflies and caddisflies. Feeding typically occurs in schools, this species commonly crowds minnows to the surface before preying upon them. (MN DNR, 2013; Ross, 2001)\nSkipjack herring are considered forage fishes and have many predators. Their biggest advantage over larger fish is that they travel in schools, making it harder for the predator to locate them. However, this also means when they are found, the predator species may go into a feeding frenzy, eating many at once. (""Alosa chrysochloris"", 2009)\nSkipjack herring are an important host for the parasitic larvae of native ebony shell mussels. The loss of skipjack herring in the upper Mississippi River resulted in the loss of ebony shell mussels. Skipjack herring are also one of the main food sources for all predatory fish in the Mississippi River system. (Ross, 2001)\nSkipjack herring can be eaten by people, but they are generally considered a \'rough fish\' because they are difficult to debone. These fish are caught by commercial fisherman to sell and use for bait to catch preferred game fish. Although skipjack herring do not have a very large economic purpose, they provide a quality food source for many desired game fish. Game fishing is a very large industry and attracts people from all over the country. (Morrison, 2009)\nSkipjack herring are not known to create any negative effects for humans.\nAccording to the IUCN Red List, CITIES appendices, and the United States Endangered Species Act, there is no immediate concern for skipjack herring. Their population size remains very stable except in areas where dams have cutoff migration, near Minnesota and Wisconsin. (NatureServe, 2005)\nSkipjack herring are the sole host for the larval stages of two endangered mussel species in Minnesota, ebony shells and elephant-ears. These fish permit these two mussel species to complete their life cycle. The reestablishment of skipjack herring would allow ebony shell and elephant ear mussels to return to Minnesota. Lock and dam structures limit the spring migration of skipjack herring. To reestablish these fish in Minnesota, fish passage features such as ladders or lifts will be needed at several lock and dam sites between Iowa and central Minnesota. (MN DNR, 2013)\nDylan Chandler (author), Minnesota State University, Mankato, Robert Sorensen (editor), Minnesota State University, Mankato, Leila Siciliano Martina (editor), Animal Diversity Web Staff.\nthe body of water between Africa, Europe, the southern ocean (above 60 degrees south latitude), and the western hemisphere. It is the second largest ocean in the world after the Pacific Ocean.\nliving in the Nearctic biogeographic province, the northern part of the New World. This includes Greenland, the Canadian Arctic islands, and all of the North American as far south as the highlands of central Mexico.\nhaving body symmetry such that the animal can be divided in one plane into two mirror-image halves. Animals with bilateral symmetry have dorsal and ventral sides, as well as anterior and posterior ends. Synapomorphy of the Bilateria.\nareas with salty water, usually in coastal marshes and estuaries.\nan animal that mainly eats meat\nuses smells or other chemicals to communicate\nthe nearshore aquatic habitats near a coast, or shoreline.\nhumans benefit economically by promoting tourism that focuses on the appreciation of natural areas or animals. Ecotourism implies that there are existing programs that profit from the appreciation of natural areas or animals.\nanimals which must use heat acquired from the environment and behavioral adaptations to regulate body temperature\nan area where a freshwater river meets the ocean and tidal influences result in fluctuations in salinity.\nfertilization takes place outside the female\'s body\nunion of egg and spermatozoan\nA substance that provides both nutrients and energy to a living thing.\nmainly lives in water that is not salty.\nAn animal that eats mainly insects or spiders.\nmakes seasonal movements between breeding and wintering grounds\nHaving one mate at a time.\nhaving the capacity to move from one place to another.\nspecialized for swimming\nthe area in which the animal is naturally found, the region in which it is endemic.\nactive during the night\nan animal that mainly eats fish\nan animal that mainly eats plankton\nReferring to a mating system in which a female mates with several males during one breeding season (compare polygynous).\nhaving more than one female as a mate at one time\nmainly lives in oceans, seas, or other bodies of salt water.\nbreeding is confined to a particular season\nassociates with others of its species; forms social groups.\nuses touch to communicate\nuses sight to communicate\nU.S. Geological Survey.. 489. Gainesville, Florida: U.S. Department of the Interior. 2009.\n2011. ""Assessment of Migratory Stocks"" (On-line). Accessed March 26, 2013 at http://www.fao.org/docrep/W5449E/w5449e0d.htm.\n2008. ""Herring Family: Clupeidae"" (On-line). Accessed March 25, 2013 at http://images.library.wisc.edu/EcoNatRes/EFacs/FishesWI/reference/econatres.fisheswi.i0022.pdf.\n2012. ""Skipjack Herring"" (On-line). Accessed March 25, 2013 at http://www.seagrant.wisc.edu/home/Default.aspx?tabid=605&FishID=135.\nCoad, B. 1997. ""Shad Journal"" (On-line). Accessed March 26, 2012 at http://www.cbr.washington.edu/shadfoundation/shad/JOURNAL2/vol2n4.pdf.\nHassan, C. 2013. ""Skipjack herring"" (On-line). Accessed March 25, 2013 at http://txstate.fishesoftexas.org/alosa%20chrysochloris.htm.\nMN DNR, 2013. ""Species profile: Minnesota DNR"" (On-line). Accessed March 25, 2013 at http://www.dnr.state.mn.us/rsg/profile.html?action=elementDetail&selectedElement=AFCFA01030.\nMorrison, S. 2009. Skipjack Herring. Wildlife Diversity Notebook, Spring 2009: 9.\nNatureServe, 2005. ""Comprehensive Report Species"" (On-line). Accessed March 25, 2013 at http://www.tnfish.org/SpeciesFishInformation_TWRA/Research/SkipjackHerring_AlosaChrysochlorisInformation_NS.pdf.\nRoss, S. 2001. The Inland Fishes of Mississippi. Mississippi: Sport Fish Restoration.']"	['<urn:uuid:343ce3c0-b6ab-4ea6-92d9-8a8b1d55e197>', '<urn:uuid:60c2c8b6-5b04-409d-b747-e634fc594431>']	factoid	direct	concise-and-natural	distant-from-document	comparison	expert	2025-05-12T22:49:38.933606	8	56	3891
88	dubai tennis championship entertainment activities	The Dubai Tennis Championships feature various entertainment activities including the Tennis Academy Youth Day on opening day, ball catching competitions with prizes at the Dubai Duty-Free stand, radio competitions for tickets on Dubai Eye, and live entertainers performing in the Tennis Village throughout the tournament. The Tennis Village has big screens showing live action and is open to the public.	"[""Get all the latest WTA Dubai Duty Free Tennis Championships live Tennis scores, results, and more! Defending champion Roger Federer has withdrawn from the Dubai Duty Free Tennis Championships after undergoing knee surgery in. Die Dubai Tennis Championships oder Dubai Open sind ein professionelles Tennisturnier, das Dubai Duty Free gehört und organisiert und jährlich in Dubai, Vereinigte Arabische Emirate, auf Hartplätzen im Freien stattfindet. Das Turnier findet Ende.\nDubai Duty Free Tennis ChampionshipsGet all the latest WTA Dubai Duty Free Tennis Championships live Tennis scores, results, and more! Defending champion Roger Federer has withdrawn from the Dubai Duty Free Tennis Championships after undergoing knee surgery in. Dubai Duty Free Tennis Championships - Dubai ATP live Ergebnisse sowie ältere Tennis Ergebnisse.\nDubai Atp Dubai Tennis Centre VideoHighlights: Roger Federer Wins 100th Title In Dubai, 2019\nEs ist aber durchaus so, die Dubai Atp Top Online Casino und Dubai Atp. - Tennis Live TurniereThese cookies do not store any personal information.\nHome Articles Dubai Tennis Championships Dubai Tennis Championships, also known as Dubai Open, is a professional tennis tournament held annually in Dubai, owned and organised by Dubai Duty Free.\nPrime A seats in the North stand facing the Royal Box are the only pre-allocated seats, i. Prime A seats in the East and West stands to offer free seating within these designated areas except the branded Sponsor Seating.\nPrime B: Prime B seats are located in the North stand. Prime B seats provide free seating on a first-come, first-served basis at the North Stand.\nSource The Dubai Tennis Centre, formerly the Aviation Club, has been the home to the championship since its inauguration in Activities at the Dubai Tennis Championships 1.\nThe Tennis Academy Youth Day The Tennis Academy Youth Day will be held on the opening day of the championships, giving Tennis Emirates affiliated academies the opportunity to participate in tennis skills and drills clinic and interact with WTA superstars.\nSource 4. Each ball caught can be redeemed at the Dubai Duty-Free stand for an exciting prize from the sponsors. Radio competitions and promotions - ARN radio is running several competitions and promotions across Dubai Eye Winners will receive tickets to the tennis.\nEntertainment Entertainers will perform for the spectators and fans in the Tennis village throughout the tournament. The Tennis Village has big screens featuring the live-action and is open to the general public.\nSource This two-week-long championship, which has seen victories by the likes of tennis pros Rafael Nadal, Novak Djokovic and Venus Williams, is a spectacle of fierce competition on the court and energising entertainment for spectators off the court.\nDubai Packages Compare quotes from upto 3 travel agents for free. From Wikipedia, the free encyclopedia. Redirected from ATP Dubai.\nThe National. Retrieved Le Temps in French. BBC Sport. BBC News. February 20, Retrieved May 1, Dubai Tennis Championships.\nATP Tour since WTA Premier tournaments — Indian Wells — Miami — Madrid — Beijing — Previous tournament categories — ATP International Series — Hidden categories: CS1 French-language sources fr Webarchive template wayback links All articles with dead external links Articles with dead external links from September Articles with permanently dead external links Commons category link is on Wikidata Coordinates not on Wikidata.\nNamespaces Article Talk. Views Read Edit View history. Help Learn to edit Community portal Recent changes Upload file.\nDownload as PDF Printable version. Wikimedia Commons. Aviation Club Tennis Centre. Official website. Novak Djokovic. Simona Halep. Fabrice Santoro.\nMagnus Gustafsson. Sergi Bruguera. Wayne Ferreira. Andrea Gaudenzi. Albert Costa. Thomas Muster. Nicolas Kiefer. Juan Carlos Ferrero.\nMarat Safin. Younes El Aynaoui. Roger Federer. Roger Federer 2. Roger Federer 3. Rafael Nadal. Roger Federer 4. Mikhail Youzhny.\nAndy Roddick. David Ferrer. Novak Djokovic 2. Novak Djokovic 3. Roger Federer 5. Andy Murray. Novak Djokovic 4. Roger Federer 6.\nRoger Federer 7. Stan Wawrinka. Marcos Baghdatis. Fernando Verdasco. Roberto Bautista Agut. Lucas Pouille. Roger Federer 8. Stefanos Tsitsipas.\nNovak Djokovic 5. Martina Hingis. Nathalie Tauziat. Sandrine Testud. Justine Henin-Hardenne. Monica Seles. Justine Henin-Hardenne 2.\nSvetlana Kuznetsova. Lindsay Davenport. Justine Henin-Hardenne 3. Maria Sharapova. Justine Henin 4. Elena Dementieva.\nVenus Williams. Virginie Razzano. Venus Williams 2. Victoria Azarenka. Caroline Wozniacki. Julia Görges.\nSara Errani. Venus Williams 3.Roger Federer has won his th ATP Tour title at the Dubai Tennis Championships - 6, days after winning his first in Milan. The year-old Swiss - a time Grand Slam champion - beat Greece. Dubai Tennis Championship Results: Men's Singles. Dubai, United Arab Emirates Hard Courts Feb 22 - Feb Men Women Finals Sat Feb 29, Final. Daniel Evans battles back after a late comeback from Andrey Rublev into his first ATP level semi-final on Thursday in Dubai. Dubai Duty Free Tennis Championships World No. 1 Novak Djokovic is now in after beating Philipp Kohlschreiber on Wednesday in Dubai. kawpermaculture.com offers ATP Dubai livescore, final and partial results, ATP Dubai draws and ATP - Singles rankings. Besides ATP Dubai scores you can follow + tennis competitions from 70+ countries around the world on kawpermaculture.com Just click on the category name in the left menu and select your tournament. ATP Dubai scores service is real-time, updating live. Bringing The Best To Dubai The Dubai Duty Free Tennis Championships has a long history of welcoming some of the top players in the game. Among its champions, the tournament counts Spanish great Alex Corretja, Swiss star Stan Wawrinka and former World No. 1s Juan Carlos Ferrero, Andy Roddick, Roger Federer, Andy Murray, Novak Djokovic and Rafael Nadal. Prime A seats in the East and West stands to offer free seating Esc Favoriten these designated areas except the branded Sponsor Seating. For five years, Swiss Roger Federeron the men's Dubai Atp, and Belgian Justine Heninon the women's side, dominated the singles' tournaments. Venus Williams 2. Justine Henin-Hardenne 2. Elina Svitolina 2. John Fitzgerald Anders Järryd. Svetlana Kuznetsova Alicia Molik. February 20, The tournament takes place at the end of February and organizes a men's and women's event. We value your privacy. Caroline Garcia Joseph Benavidez Mladenovic. Cara Black Elena Likhovtseva.""]"	['<urn:uuid:77aa0971-4f20-4659-a923-a39c3f261600>']	open-ended	direct	short-search-query	distant-from-document	single-doc	novice	2025-05-12T22:49:38.933606	5	60	1003
89	professional sommelier dual purpose cabinet options aging bottles ready serve	For dual-purpose wine storage, a Dual-Zone wine cabinet can be utilized with the lower compartment set at around 15°C for cellaring wines, while the upper compartment can be used for serving wines at their optimal temperatures. However, it's important to note that red wines like Beaujolais, Valpolicella, Chianti, and Pinot Noir should be chilled for about thirty minutes before serving, as these younger wines have less texture. For white wines, serving temperatures of 6-8°C are generally recommended, while reds are best served at 16-18°C. Single-Zone cabinets, while excellent for cellaring at 12-14°C with proper humidity levels, don't offer the flexibility of maintaining different serving temperatures simultaneously.	"['Red Wine- نبيد احمر\nA wine made from red grapes and is often dryer than white wines.\nA couple varieties of well known red wine include Cabernet, Syrah, Merlot, Sangiovese and bordeaux. Red wine is often paired with red meat, blue cheese,red pasta sauces and other rich foods.\nSelecting and Buying\nFind bottles of red wine with vintages at least three years old. Red wines improve with age in the bottle and begin to reach maturity after three years. The major exception is beaujolais-nouveau and fruitier red table wines that are made to be consumed as soon as bottled. Exceptional vintages of red wine will mature earlier than average vintages, and can be very drinkable within two years of bottling. Try a younger bottle of your favorite variety occasionally, to scout for outstanding vintages.\nExplore all the wine vendors in your area, including supermarkets and discount stores. Look for your favorite varieties in the oldest vintages. Try red wines in your favorite varieties from different regions, like Australia, Chile, South Africa and Argentina.\nPreparation and Use\nMany red wine benefit from letting them breathe a bit before drink. Older vintages and some newer one benefit from decanting or using an aerator prior to drinking.\nConserving and Storing\nWine enthusiasts know that proper storage is crucial to the preservation of a fine red wine. The same principals that go for expensive wines usually suit frugal wines as well.\nLearning how to store red wine takes a little effort. It helps to become familiar with different types of red wine in order to make decisions on how to store red wine properly.\nGet to know red wines. Different varieties of reds require different preparation before serving. Some wines are best at room temperature while others should be served with a slight chill.\nTake note of wines that should be chilled. Among those that should be chilled for about thirty minutes are: Beaujolais, valpolicella, chianti and pinot noir. These wines are typically young and have less texture.\nRemember that it is better to keep red wine over-chilled rather than over heated. Store red wine in higher temperatures and the result is a soupy mess. The wine can always sit out for awhile to get closer to room temperature.\nStoring Red Wines:\nStore red wine in a cool, dark place. An underground basement is the ideal environment, hence wine cellars. Those who do not have basements do have other options to consider\nKeep tabs on the temperature. Store red wine in an area that consistently stays between 55 and 65 degrees F. Overheating will make the wine age too quickly, ruining its composition.\nStore red wine bottles on their sides. Ideally, the wine should touch the cork. This prevents the cork from drying out. This also prevents air from sneaking into the bottle. A moist cork is an indicator of a properly stored wine.\nConsider preparing a closet to store red wines. This is ideal for homes that have no basements. The area should have some air circulation to prevent mold from growing. Special wine closets can be built for a nominal fee.\nConsider renting storage for large collections of red wines. While this can be quite costly, it is often the safest approach to keeping very collectible wines in excellent condition.\nSniffing wine corks is unnecessary.\nA properly stored wine will have a cork that is moist to the touch.\nOld wood can cause wine corks to rot.\nAvoid putting red wine bottles in direct light.', 'Which Cabinet is right for me?\nTo store my wines in the ideal cellaring conditions so they can mature?\nChoose any Single-Zone Vintec or Transtherm wine cabinet, and make sure you set it at 12-14 deg C as this is the proper temperature for cellaring and medium/long term storage for all wines: reds, whites, roses and champagne.\nTo keep my wines ready to serve at the perfect drinking temperatures?\nChoose any Dual-Zone or Multi-Zone Vintec or Transtherm wine cabinet, and keep in mind that most whites are generally best served at 6-8 deg C, and most reds at 16-18 deg C. With a Multi-Zone cabinet, you can fine-tune the serving temperatures of different styles of wine: there is a temperature gradient throughout the cabinet which allows you to place different styles of whites and/or reds at exactly the right serving temperatures.\nTo cellar only white wines or only red wines?\nAll wines — Whites, Reds, Champagnes — cellar at the same temperature (12-14 deg C), so any Single-Zone cabinet set between 12-14 deg C is ideal for white wine and/or red wine storage. Set within this temperature range, Single-Zone cabinets will also keep humidity levels above 55% (which is important to maintain cork integrity).\nMy wine is purely for investment: which wine cabinet will suit me best?\nFor (investment) wine to appreciate in value, proof of cellaring conditions may be requested by astute buyers. All Transtherm & Vintec Single-Zone wine cabinets set between 12-14 deg C would meet the criteria such proof would require.\nUsage - Cellaring & Serving\nAt what temperature should I be cellaring my wines?\nThe recommended cellaring temperature is between 12 and 14 degrees Celsius. Whichever temperature you choose, the key is to remember that the temperature must be constant.\nWhat should the humidity levels be in my wine cabinet?\nThe humidity in a wine cabinet should be over 55% so that corks don\'t dry out and shrink: humidity levels below 55% can lead to your wines spoiling because of oxidation. All Vintec or Transtherm Single-Zone cabinets are designed to maintain humidity levels above 55% (when set at 12-14 deg C).\nCan I cellar my wines in the middle section of a Multi-Zone wine cabinet and use the bottom and the top for keeping my reds and whites at serving temperatures?\nYES — if you’re only cellaring wines under screw cap closures. NO — if some of your wines are under natural cork: the reason for this is that Multi-Zone wine cabinets cannot maintain humidity levels high enough for corks to remain intact over long periods of time.\nDo I need humidity control when cellaring my wines?\nYES, humidity is important to ensure that corks do not dry out and shrink. If air can get into the wine it will cause oxidation, generating off-odours. Another symptom of low humidity is corks breaking/crumbling when being removed.\nHow long can I keep my wines in a Multi-Zone wine cabinet?\nThe recommended time to turn-over your wines in a Multi-Zone wine cabinet is 6 months. There are two reasons for this: 1) if your wine cabinet is set at serving temperatures (6-8 deg C for whites, and 16-18 deg C for reds), your wines are of course not being stored at the proper cellaring temperature, which is 12-15 deg C; 2) Multi-Zone cabinets do not provide the adequate humidity levels for corks to remain intact over long periods of time: they may dry out and let damaging air into the bottle.\nTechnical & Installation\nWhat is a Multi-Zone cabinet best suited for?\nGenerally the larger models are best suited for restaurants and bars (e.g. Vintec V190, Transtherm Reserve), as there is a good turn-over of wines. Regular turn-over is important for wines stored in Multi-Zone cabinets (see previous FAQ). Smaller units such as the Vintec V150 can be well suited for individuals who enjoy entertaining regularly and like to have many wines kept simultaneously at the perfect serving temperatures.\nBy opening and closing the door of my single-zone wine cabinet am I affecting my wines?\nNo, the thermal mass of the wine and glass bottles maintains the temperature of the wine while the slow-cycle compressor brings the ambient temperature (the small amount of air between the bottles) back to the desired level. The ambient temperature quickly returns to the correct temperature as the thermostats senses minor temperature changes and activates the compressor immediately.\nCan my bottles touch the back panel of my wine cabinet?\nNo: ensure your wine bottles do not touch the back panel of your wine cabinet. If the bottles touch the back panel the labels will be affected by the condensation running from the back wall on to the bottle. This would also allow less condensation pooling in the tray to be reheated and redistributed through the cabinet as warm vapour, and would thus affect the humidity in your wine cabinet.\nI have a Dual-Zone wine cabinet. Can I use one compartment for the serving of my white wines and the bottom compartment for cellaring my wines?\nYes- Although the design of such cabinets was originally essentially for serving White and Red Wines, the lower compartment, set at around 15 degrees can be used for cellaring.\nCan I use my wine cabinet for beer and food?\nNo, wine cabinets are not fridges. The temperature does not go low enough to keep food fresh and are not cold enough for the serving of beer. The Vintec BVCs (beer & wine cabinets) are designed for beers (or white wines at drinking temperature), as they can cool beverages down to 2 deg C, and have metallic racks on which to stand beer bottles up. However, they are not suitable for food storage.\nShould I rotate my bottles regularly?\nNo, it is not necessary to rotate your bottles at all. Wines need resting without any disturbance.\nIf I don\'t have enough bottles to fill the cabinet, what guideline should I keep in mind?\nMake sure the bottles are evenly distributed throughout the wine cabinet, and avoid clumping together. The units work better when full.\nWhat is the difference between Dual/Multi-Zone cabinets and Single-Zone wine cabinets?\nDual/Multi-Zone wine cabinets are designed for serving red and white wines at the perfect drinking temperatures. With Multi-Zone wine cabinets, the temperature graduates from the bottom (set at 6 deg C) to the top (set at 18 deg C), so you can place different styles/varietals at exactly the right temperature for service (e.g. Sauvignon Blanc should be served at 6-8 deg C so place right at the bottom of the cabinet; Chardonnay should be served at 10-12 deg C so place on a higher shelf). Single-Zone wine cabinets are designed for cellaring all wines — reds, whites or sparkling — at the proper temperature (12-14 deg C).\nHow does the humidity control work?\nWine cabinets create condensation. This condensation forms on the back panel of the unit then flows down to the bottom where it is collected in a tray. In some wine cabinets there is a heater in this tray which heats the water and redistributes it as vapour through the wine cabinet; in others the same effect happens but the heat is generated by the compressor when it engages. Hygrometry cannot be set precisely but it is maintained by the ""thermal pump"". In some of the Vintec units there are also small plastic trays which can be inserted inside the wine cabinets to assist in maintaining humidity. The trays are to be filled with water and placed in front of the fans inside the units and refilled when necessary.\nHow does the vibration control work?\nThese units have slow cycling compressors which are independently housed outside the main body of the unit and on rubber shock absorbers. Our wine cabinets also use wooden shelves as they do not transmit vibrations.\nDoes my cabinet require ventilation and can it be built-in under bench?\nIf it is a Vintec V30 series, it must be freestanding. All other units can be built-in to joinery but there is specific ventilation requirement.\nCan I stack a unit on top of another one?\nThe only way this can be done is if there is a reinforced platform is placed between them, BUT not resting on or being supported by the lower wine cabinet. There must also be a “Chimney” at the back of this platform so that hot air can escape from both lower & upper units.\nMy unit is making a lot of noise\nAll Vintec and Transtherm wine cabinets should produce less than 36 dB of noise. If the noise seems above this level, it may be:\n1) because the unit is not properly levelled or the bottles stacked incorrectly, so please empty the unit, check the levelling and then reload,\n2) because ventilation requirements have not been respected, and so the unit is over-heating.\nIf the noise persists, please call Vintec After-Sales Service (0800 436 245) for further advice\nMy door gasket seems flattened and won\'t seal properly\nThis can happen in transit. Use a hair drier to heat up the gasket and when it\'s hot, plump up the seal. When it has reshaped, shut the door and tape it tightly shut for 48 hours so the seal holds the reformed shape.\nThere is water coming out of the back of my cabinet.\nIt means the door has been left slightly ajar. Wipe out the cabinet and empty the tray then make sure you shut the door properly.\nThere is water on the inside back wall of my cabinet\nThis is normal and is necessary for maintaining humidity levels in your wine cabinet. Just keep your bottles away from the wall so you do not block the water flow, an essential part of the cellaring climate.\nMy bottles are wet\nIf they are in contact with the back wall of the cabinet, please make sure you keep a finger\'s distance between the bottom of the bottle and the wall when you load. If not, please keep in mind that it is normal that condensation appears on the bottles after you open the door, and that high humidity is an essential part of cellaring your wine properly.\nI can\'t open my door\nIf your cabinet is lockable, please check that it is not locked first. Otherwise, the vacuum effect of the seal may have become too strong after being shut for too long. Prise the gasket open gently from the top corner and ease your fingers down and then the door will open easily.\nThere is a +/- 2 deg temperature swing on the digital readout\nYes. It is the variance in the air temperature which triggers the thermostat and the compressor. Please note that the small temperature fluctuations only occur in the air around the bottles, not in the wine: if you place a probe inside the wine bottle, the temperature is actually constant.\nThere is condensation on the outer surface of the glass door of my wine cabinet\nWhen water vapour from the air comes into contact with the cold surface of the glass door, the vapour condenses on the surface of the glass, causing a foggy effect or in extreme situations, water can even flow off. It indicates excessive humidity in the environment.\nWhat happens if there is a power outage?\nThe units are very well insulated and the thermal mass of the wine can maintain the temperature for hours before there is any change in the wine temperature itself. It is advisable not to open the doors during the outage. Once the power is restored, electronically-controlled cabinets may revert to the factory setting, generally 12 deg C which is an appropriate temperature for cellaring. Please reset if necessary.']"	['<urn:uuid:648d8483-e4fa-4f5e-b716-c4b3bf7ad243>', '<urn:uuid:803431c8-4501-4143-96cb-ee13829ce4d3>']	open-ended	with-premise	long-search-query	distant-from-document	multi-aspect	expert	2025-05-12T22:49:38.933606	10	106	2538
90	We're concerned about disk space in our stretched cluster setup - what happens if the disks on one of our sites get almost full?	If disks on one site reach 96 percent full or 5 GB free capacity (whichever is less), components on that site are marked absent, and vSAN continues to perform I/O to healthy object copies on the other site. When the affected site's disks reach 94 percent capacity or 10 GB (whichever is less), the absent components become available again and vSAN resyncs them.	['Stretched clusters extend the vSAN cluster from a single data site to two sites for a faster level of availability and intersite load balancing. Stretched clusters are typically deployed in environments where the distance between data centers is limited, such as metropolitan or campus environments.\nYou can use stretched clusters to manage planned maintenance and avoid disaster scenarios, because maintenance or loss of one site does not affect the overall operation of the cluster. In a stretched cluster configuration, both data sites are active sites. If either site fails, vSAN uses the storage on the other site. vSphere HA restarts any VM that must be restarted on the remaining active site.\nYou must designate one site as the preferred site. The other site becomes a secondary or nonpreferred site. If the network connection between the two active sites is lost, vSAN continues operation with the preferred site. The site designated as preferred typically is the one that remains in operation, unless it is resyncing or has another issue. The site that leads to maximum data availability is the one that remains in operation.\nA vSAN stretched cluster can tolerate one link failure at a time without data becoming unavailable. A link failure is a loss of network connection between the two sites or between one site and the witness host. During a site failure or loss of network connection, vSAN automatically switches to fully functional sites.\nvSAN 7.0 Update 3 and later stretched clusters can tolerate a witness host failure when one site is unavailable. Configure the storage policy Site disaster tolerance rule to Site mirroring - stretched cluster. If one site is down due to maintenance or failure and the witness host fails, objects become non-compliant but remain accessible.\nFor more information about working with stretched clusters, see the vSAN Stretched Cluster Guide.\nEach stretched cluster consists of two data sites and one witness host. The witness host resides at a third site and contains the witness components of virtual machine objects. The witness host does not store customer data, only metadata, such as the size and UUID of vSAN object and components.\nThe witness host serves as a tiebreaker when a decision must be made regarding availability of datastore components when the network connection between the two sites is lost. In this case, the witness host typically forms a vSAN cluster with the preferred site. But if the preferred site becomes isolated from the secondary site and the witness, the witness host forms a cluster using the secondary site. When the preferred site is online again, data is resynchronized to ensure that both sites have the latest copies of all data.\nIf the witness host fails, all corresponding objects become noncompliant but are fully accessible.\nThe witness host has the following characteristics:\n- The witness host can use low bandwidth/high latency links.\n- The witness host cannot run VMs.\n- A single witness host can support only one vSAN stretched cluster. Two-node vSAN clusters can share a single witness host.\n- The witness host must have one VMkernel adapter with vSAN traffic enabled, with connections to all hosts in the cluster. The witness host uses one VMkernel adapter for management and one VMkernel adapter for vSAN data traffic. The witness host can have only one VMkernel adapter dedicated to vSAN.\n- The witness host must be a standalone host dedicated to the stretched cluster. It cannot be added to any other cluster or moved in inventory through vCenter Server.\nThe witness host can be a physical host or an ESXi host running inside a VM. The VM witness host does not provide other types of functionality, such as storing or running VMs. Multiple witness hosts can run as VMs on a single physical server. For patching and basic networking and monitoring configuration, the VM witness host works in the same way as a typical ESXi host. You can manage it with vCenter Server, patch it and update it by using esxcli or vSphere Lifecycle Manager, and monitor it with standard tools that interact with ESXi hosts.\nYou can use a witness virtual appliance as the witness host in a stretched cluster. The witness virtual appliance is an ESXi host in a VM, packaged as an OVF or OVA. The appliance is available in different options, based on the size of the deployment.\nStretched Clusters and Fault Domains\nStretched clusters use fault domains to provide redundancy and failure protection across sites. Each site in a stretched cluster resides in a separate fault domain.\nA stretched cluster requires three fault domains: the preferred site, the secondary site, and a witness host. Each fault domain represents a separate site. When the witness host fails or enters maintenance mode, vSAN considers it a site failure.\n- Site disaster tolerance. For stretched clusters, this rule defines the failure tolerance method. Select Site mirroring - stretched cluster.\n- Failures to tolerate (FTT). For stretched clusters, FTT defines the number of additional host failures that a virtual machine object can tolerate.\n- None. You can set this data locality rule to None, Preferred, or Secondary. This rule enables you to restrict virtual machine objects to a selected site in the stretched cluster.d\nIn a stretched cluster with local fault protection, even when one site is unavailable, the cluster can perform repairs on missing or broken components in the available site.\nvSAN 7.0 and later continue to serve I/O if any disks or disks on one site reach 96 percent full or 5 GB free capacity (whichever is less) while disks on the other site have free space available. Components on the affected site are marked absent, and vSAN continues to perform I/O to healthy object copies on the other site. When disks on the affected site disk reach 94 percent capacity or 10 GB (whichever is less), the absent components become available. vSAN resyncs the available components and all objects become policy compliant.']	['<urn:uuid:5f29467f-fa2f-4386-a50e-9f0b34dd9034>']	factoid	with-premise	verbose-and-natural	similar-to-document	single-doc	novice	2025-05-12T22:49:38.933606	24	63	988
91	How do meteorological systems and PCR tests help in healthcare?	Both technologies serve important healthcare functions. Degreane Horizon's meteorological systems provide crucial weather data through their Automatic Weather Stations and sensors installed at over 2500 sites worldwide, which helps monitor environmental conditions affecting public health. Meanwhile, PCR (polymerase chain reaction) technology is extensively used in clinical diagnostics, particularly for detecting infectious diseases like COVID-19 and genetic disorders. PCR-based molecular diagnostic tests guide patient management due to their high specificity, sensitivity and low sample requirements, becoming especially critical during disease outbreaks.	"['DEGREANE HORIZON is a meteorological systems specialist based in Cuers, France and is recognized as one of the world’s leading manufacturers for measurement and engineering in the field of meteorology.\nEstablished in 1984 as a Division of DEGREANE SA, DEGREANE HORIZON SAS became an individual incorporated wholly-owned subsidiary of the Vinci Group in 2002.\nWe focus on providing Civil Aviation Authorities, National Meteorological Services, Meteorological Research Institutions and Marine Agencies with the sensing technologies and integrated systems solutions they need to carry out their missions.\nWe have more than 30 years experience in the engineering and the manufacture of advanced meteorological products and systems for aeronautical meteorology and professional observing networks.\nOur oldest customer is Meteo France, for whom we designed, built and installed the MIRA and XARIA AWS networks, covering the whole of France. Our range of Automatic Surface Observation Systems is now installed at over 2500 sites worldwide.\nIn 1991 Degreane introduced the SIOMA systems (Integrated Runway Meteorological Observation System) with more than 400 SIOMA now installed in over 90 countries.\nIn 1993 Degreane developed a new family of Wind Profiling Radar Systems known as PCL1300. Our boundary layer profiler is extensively used in aviation for wind shear detection.\nFIELD OF EXPERTISE\nDegreane Horizon has a worldwide experience in systems integration. Degreane Horizon specializes in aeronautical systems, providing integrated solutions for AWOS, ATIS/VOLMET, Wind Profilers, message switching systems. Synoptic and climatologic AWS networks include latest state-of-the-art automatic and semi-automatic Automatic Weather Stations, Buoys, Data Collection Platform and associated softwares for data storage, display and end-user applications.\nDegreane Horizon covers a complete range of visibility sensors. Synoptic visibility is measured by the Degreane DF20+ Forward Scatter Sensor up to 70km. Aeronautical visibility and Runway Visual Range are provided by Degreane TR30 transmissometers and DF320 Forward Scatter sensors. All French airports are equipped with our visibility sensors.\nThe TL320 Ceilometer provides the latest state-of-the-art technical development in the field of laser source and signal processing. The second generation of our Ceilometer range, the TL320 is designed to measure cloud base height and vertical visibility, with unmatched performances and reliability up to 25 000 feet and provides sky cover and vertical visibility.\nDegreane Horizon has a long experience in Automatic Weather Stations and associated solutions. The company is specialized in design, manufacturing, and installation of Automatic Weather Station Network dedicated to synoptic meteorology, climatology, Agrometeorology, and aeronautical meteorology. Our range of AWS MIRIA, AURIA and XARIA have equipped numerous National Met Services including MeteoFrance with more than 500 Xaria in their Radome Network. Having installed equipment in more than 90 countries, our AWS and sensors are fully adapted to most extreme climatic conditions.\nDegreane Horizon is among few suppliers of wind profilers which manufacture major system elements in-house. This has resulted in radar systems of unmatched power, reliability and flexibility, and ensures that support for our many clients around the world is fully optimized.\nOur PCL-1300 wind profiler incorporates a broad spectrum of hardware and software refinements which are the result of an ongoing Research and Development collaboration with major French and European atmospheric research entities. This collaboration is ongoing and ensures that the system benefits from a continuing process of refinement, especially in the areas of advanced signal process and data processing.\nPCL1300 has been adopted by numerous prestigious Met Services such as UK, MeteoSwiss, MeteoFrance, Korean Met services and many other.\nSatisfied customers in more than 90 countries', ""The polymerase chain reaction market is projected to register a CAGR of 8.30% during the forecast period, with a revenue of approximately USD 5,970 million in 2020 and expected to reach USD 10,310 million by 2026. The major factors driving the growth of the polymerase chain reaction market include the increasing application in clinical diagnostics, rising demand for personalized and precision medicine, and technological advancements and application in drug development.\nThere is a positive impact on the PCR market due to the increasing demand for the clinical diagnostic segment of the market. As the authorities have not recommended the viral culture tests, almost all the diagnostic tests use RT-PCR to test the population who have symptoms of COVID-19 and are advised by healthcare professionals to undergo a diagnostic test.\nFurthermore, the polymerase chain reaction is also gaining higher importance in the molecular diagnosis of infectious and genetic diseases with the advent of COVID-19. To facilitate personalized medicine, it is crucial to develop precise and reproducible means of gaining molecular information about the underlying disease, which can be used to guide clinical decision making, with PCR techniques being increasingly utilized in such methods. Therefore, increasing the focus on personalized medicine and patient-centered approach is driving the growth of the market studied.\nPersonalized medicine, which aims to provide tailor-made therapies to individual patients, depending on the molecular basis of disease, became popular over recent years. The aging global population and the rising prevalence of chronic disease are putting unrelenting pressure on the healthcare system's capacity and financial viability across the world.\nAccording to the World Population Prospects: the 2019 Revision, one in every six people will be over 65 years of age by 2050. The rising demand for personalized medicine has thus created tremendous opportunities in the field of genetic medicine. To gain a competitive advantage in the emerging field of personalized medicine, biotechnology and pharmaceutical firms are exploring the grounds of genomic medicine and direct-to-consumer genetic testing. To develop these products, the industry is ramping up the R&D process in the areas of biotechnology, where the polymerase chain reaction finds its major applications.\nPersonalized medicine thus holds the promise of providing better patient care and a high safety margin while also lowering the total healthcare costs. Therefore, the increasing geriatric population, demand for personalized medicine, and the role PCR play in developing them boost the market growth.\nKey Market Trends\nClinical Diagnostics Segment is Expected to Witness a Good Growth over the Forecast Period\nPCR-based molecular diagnostic tests are increasingly being used to guide patient management, particularly in the fields of infectious disease, cancer, and congenital abnormalities. Globally, the prevalence of genetic, infectious, and chronic diseases, coupled with the increased availability of genetic and genomic information, is on the rise and it has led to the rapid incorporation of PCR techniques in clinical laboratories.\nAs the COVID-19 cases are on the rise and spread of the disease in major countries has increased the demand for the diagnostic test of the virus in the suspected population. This trend is primarily due to the low or non-availability of rapid or specific diagnostic tests for such diseases. Therefore pertaining to broad applications of PCR in clinical diagnostics, the segment is likely to register a high growth during the forecast period.\nThe high specificity, sensitivity, and low sample requirement make PCR-based molecular assay a go-to technique for the purpose of clinical diagnosis. PCR-based molecular assays are becoming the primary mode of diagnosis for the detection of pathogens in case of a rapid disease outbreak, such as the recent Zika and Coronavirus outbreaks.\nNorth America is Expected to Dominate the Polymerase Chain Reaction Market over the Forecast Period\nThe increasing prevalence of genetic and chronic disorders, such as cancer, the aging population, the rising demand for precision and personalized medicine, and favorable government initiatives, are the primary factors driving the growth of the market.\nAs the COVID-19 cases are increasing rapidly and the spread of the virus is very rapid, speeding up the transmission. The increasing count of suspects increases the number of diagnostic tests, boosting the market growth in the country.\nPixel by LabCorp COVID-19 is a test home collection kit where the patient can self-collect nasal swab specimens at home when approved by a healthcare provider to be appropriate based on the results of a COVID-19 questionnaire. The specimen is collected carefully and sent back to the lab for RT-PCR, where the results are produced and sent back. Due to such advancements in the country, it has a cutting edge over the others in the market.\nIn February 2020, the Department of Health and Human Services has also announced the authorization of the emergency use of diagnostics for the detection of COVID-19. This authorization has increased the number of diagnostics product launches in the region.\nThere is also a growing trend of genetic engineering and genomic research in academia and biotechnology industries of the United States. Increasing genomic research is primarily fueled by the high demand for targeted and precision medicine, for the management of chronic disorders, as well as due to the need for understanding the genetic and molecular basis of disease. In recent years, several government initiatives were launched, which are supplementing the growth of the PCR market.\nThe market studied is moderately consolidated in nature, owing to the presence of a few major players. Some of the market players are Abbott Laboratories, Agilent Technologies Inc., Becton, Dickinson and Company, bioMerieux SA, Bio-Rad Laboratories Inc., GE Healthcare, Merck KGaA, PerkinElmer Inc., Promega Corporation, Siemens Healthcare, and Thermo Fisher Scientific Inc. These major companies are found focussing on R&D to develop advanced technology products to gain a competitive edge. Companies are also found engaging in partnerships, mergers, and acquisitions, aiming to strengthen their product portfolio, manufacturing capacities, and provide competitive differentiation.\nReasons to Purchase this report:\n- The market estimate (ME) sheet in Excel format\n- 3 months of analyst support\nTABLE OF CONTENTS\n- 1.1 Study Deliverables\n- 1.2 Study Assumptions\n- 1.3 Scope of the Study\n2 RESEARCH METHODOLOGY\n3 EXECUTIVE SUMMARY\n4 MARKET DYNAMICS\n- 4.1 Market Overview\n- 4.2 Market Drivers\n- 4.2.1 Increasing Application in Clinical Diagnostics\n- 4.2.2 Rising Demand for Personalized and Precision Medicine\n- 4.2.3 Technological Advancements and Application in Drug Development\n- 4.3 Market Restraints\n- 4.3.1 High Cost of Instruments\n- 4.3.2 Emergence of Alternative Technologies\n- 4.4 Porter's Five Forces Analysis\n- 4.4.1 Threat of New Entrants\n- 4.4.2 Bargaining Power of Buyers/Consumers\n- 4.4.3 Bargaining Power of Suppliers\n- 4.4.4 Threat of Substitute Products\n- 4.4.5 Intensity of Competitive Rivalry\n5 MARKET SEGMENTATION\n- 5.1 By Product\n- 5.1.1 Instruments\n- 220.127.116.11 Standard PCR Systems\n- 18.104.22.168 Digital PCR Systems\n- 22.214.171.124 Real-time PCR Systems\n- 5.1.2 Reagents and Consumables\n- 5.1.3 Software\n- 5.2 By Application\n- 5.2.1 Clinical Diagnostics\n- 5.2.2 Life Science Research and Industrial Applications\n- 5.2.3 Other Applications\n- 5.3 By End User\n- 5.3.1 Academic Institutes\n- 5.3.2 Clinical Diagnostics Labs and Hospitals\n- 5.3.3 Pharmaceutical and Biotechnology Industries\n- 5.3.4 Other End Users\n- 5.4 Geography\n- 5.4.1 North America\n- 126.96.36.199 United States (By Product, By Application, and By End User)\n- 188.8.131.52 Canada (By Product, By Application, and By End User)\n- 184.108.40.206 Mexico (By Product, By Application, and By End User)\n- 5.4.2 Europe\n- 220.127.116.11 Germany (By Product, By Application, and By End User)\n- 18.104.22.168 United Kingdom (By Product, By Application, and By End User)\n- 22.214.171.124 France (By Product, By Application, and By End User)\n- 126.96.36.199 Italy (By Product, By Application, and By End User)\n- 188.8.131.52 Spain (By Product, By Application, and By End User)\n- 184.108.40.206 Rest of Europe (By Product, By Application, and By End User)\n- 5.4.3 Asia-Pacific\n- 220.127.116.11 China (By Product, By Application, and By End User)\n- 18.104.22.168 Japan (By Product, By Application, and By End User)\n- 22.214.171.124 India (By Product, By Application, and By End User)\n- 126.96.36.199 Australia (By Product, By Application, and By End User)\n- 188.8.131.52 South Korea (By Product, By Application, and By End User)\n- 184.108.40.206 Rest of Asia-Pacific (By Product, By Application, and By End User)\n- 5.4.4 Middle East and Africa\n- 220.127.116.11 GCC (By Product, By Application, and By End User)\n- 18.104.22.168 South Africa (By Product, By Application, and By End User)\n- 22.214.171.124 Rest of Middle East and Africa (By Product, By Application, and By End User)\n- 5.4.5 South America\n- 126.96.36.199 Brazil (By Product, By Application, and By End User)\n- 188.8.131.52 Argentina (By Product, By Application, and By End User)\n- 184.108.40.206 Rest of South America (By Product, By Application, and By End User)\n6 COMPETITIVE LANDSCAPE\n- 6.1 Company Profiles\n- 6.1.1 Abbott Laboratories\n- 6.1.2 Agilent Technologies Inc.\n- 6.1.3 Becton, Dickinson and Company\n- 6.1.4 bioMerieux SA\n- 6.1.5 Bio-Rad Laboratories Inc.\n- 6.1.6 GE Healthcare\n- 6.1.7 Merck KGaA\n- 6.1.8 PerkinElmer Inc.\n- 6.1.9 Promega Corporation\n- 6.1.10 Siemens Healthcare\n- 6.1.11 Thermo Fisher Scientific Inc.\n- 6.1.12 QIAGEN\n- 6.1.13 F. Hoffmann-La Roche Ltd.\n- 6.1.14 Fluidigm Corporation\n- 6.1.15 Takara Bio Inc.\n- 6.1.16 Danaher Corporation\n7 MARKET OPPORTUNITIES AND FUTURE TRENDS""]"	['<urn:uuid:9525cb5b-c683-4fb0-8790-20ce3e8af157>', '<urn:uuid:a7dae56f-5aaf-42e4-9641-ba717a0e108a>']	open-ended	direct	concise-and-natural	distant-from-document	comparison	novice	2025-05-12T22:49:38.933606	10	80	2103
92	How do real-time team meetings like daily scrums compare to asynchronous communication methods in terms of their impact on team productivity and collaboration?	Daily scrums are 15-minute time-boxed events where team members meet synchronously to answer three questions about their work progress and impediments. These meetings enhance team communication and transparency, enabling teams to be self-organized and make faster decisions. In contrast, asynchronous communication reduces the need for lengthy meetings and allows for focused, uninterrupted work, leading to more thorough problem-solving and decision-making processes. While daily scrums provide immediate feedback and collaboration, asynchronous communication allows team members to work independently and contribute at their own pace, providing flexibility and better work-life balance. Asynchronous communication also enables team members to carefully consider their responses and contribute thoughtful, well-considered input, ultimately benefiting overall productivity.	"[""What is Scrum?\nScrum is a simple empirical process that enables teams to build products incrementally in iterations, to keep abreast of the changing market needs and align themselves to the organization's business goals.\nScrum advocates self-organizing teams working towards a common goal through continuous inspection and adaptation. A minimum viable product at the end of each iteration provides an option for the teams to quickly get feedback from end users and respond accordingly much faster.\n3 Scrum Roles\nThe scrum team is made up of just three roles: a Product Owner, the Development team, and a Scrum Master\n1. Product Owner:\nA Product Owner in a scrum team decides what needs to be built. This person has complete knowledge on the market and business needs, has a vision, and owns the return on investment (ROI) or value delivered by the product.\nUnlike traditional delivery, this person is a part of the team that delivers the product. Following are the key tasks of the Product Owner:\n- Creates the vision\n- Represents business, and is responsible for the ROI\n- Cascades the vision to the teams\n- Owns the backlog of features\n- Prioritizes features by market value\n- Is empowered to take decisions\n- Negotiates with the team and business to deliver the right product at the right time\n2. The Development team:\nThe Development team in scrum is the team that has all the skills necessary to implement the backlog items. This team is not any normal team and is committed, dedicated, and motivated to perform the best.\nIt is a self-organizing team that collaborates, shares their special skills and knowledge and are committed completely to fulfill the objective. The team members are empowered to take crucial decisions that can make or break a situation.\nThe following are the special characteristics of 'The Development team':\n- Self-organizing - the Development team will be a self-managing group, who will decide on the tasks that they will work on incrementally. There is no 'Manager', who will be controlling their work\n- Empowered - the team can commit to work, determine HOW to deliver and decide HOW MUCH to deliver in one iteration\n- Cross-functional - the team does not segregate members as developers, testers or analysts and each have the necessary skills to deliver the product increment\n- Small-sized - the Development teams should ideally have 5 to 9 team members with skills sufficient to deliver the committed work. Smaller teams will not have the bandwidth to complete a considerable work and bigger teams will increase complexity\n- Co-located - the agile team is co-located, to ensure effective collaboration\n- Committed - since the team is empowered to take decisions on the scope of work in a sprint, they are committed to delivery, should be transparent on the progress, and highlight the impediments early on\n- Dedicated - this team is focused and is 100% dedicated to product delivery\nUnlike traditional methodologies, where the commitment to deliver is made to business by the team that is not involved in the execution, in Agile, the team that does the work commits to how much work can be executed in a sprint.\nThe Development team decides how much work is to be done in a sprint, and commits to delivering a 'potentially shippable product increment (PSPI)', without sacrificing quality and speed. The team also makes continuous self-improvements.\n3. Scrum Master:\nThe Scrum Master is not a management title and cannot make decisions on behalf of the team. The Scrum Master's major responsibility is to ensure that scrum is understood and practiced by every team member in the true spirit.\nThe Scrum Master should understand the different skill sets of his team and group them by having the right sheep in the right flock. A Scrum Master should guide the team such that the team does not go astray and fall prey to excess time and energy. A shepherd must draw out quiet people during stand-up meetings or when planning poker sessions. And, when the team loses focus or a team member goes astray, the shepherd should bring the lost one back to the flock and guide appropriately.\nThe Scrum Master should not enforce agile practices on the team, but should don a 'Servant leadership' role. Scrum Master should lead by example and be a living demonstration of team assets and scrum values.\nHe should create an environment of safety for the team, and guide and facilitate team collaboration. He should refrain from solving problems or making decisions by guiding teams to do so.\nTo summarize, a Scrum Master:\n- Is a servant leader - mentors and coaches the teams on scrum theory and practices, guides them on how they need to adapt to the same, thereby realizing the benefits of scrum both at team level and organization level\n- Helps remove obstacles/impediments - supports the Development teams in removing the impediments by reaching out to the right people, thereby ensuring a smooth development progress without disrupting the team\n- Facilitates collaboration - enables interactions within the team as well as between the team and the Product Owner\n- Teaches scrum - to the team\n- Protects the teams - from external disruptions like changes to stories in the current sprint\n- Is a change agent - in growing the organization to deliver early and often, and removing waste\nScrum focuses more on a working software at the end of every sprint rather than comprehensive documentation. This does not imply that there is no documentation. The documentation is provided to facilitate collaboration and interactions, rather than tracking. The progress is measured always through a working software. Documentation in scrum is only through four main artefacts namely: Product backlog, Sprint backlog, Increment and Definition of Done.\n1. Product backlog:\nA product backlog is a dynamic list of functionalities the product might include, such that it provides value to users.\nThe Product Owner maintains this list and is responsible for creating, managing, and prioritizing the backlog by focusing on WHAT brings the highest value to the users. These are few unique characteristics of a product backlog:\n- Is dynamic in nature as it evolves based on changing market needs\n- Lists all the features and capabilities that will be taken up in iteration and delivered as a product increment\n- Is refined on a continuous basis. The Product Owner and Development team collaborate and update the details, estimate, and prioritize based on business value and size\n2. Sprint backlog:\nSprint backlog is a subset of the entire product backlog that the scrum team plans to implement in one iteration or sprint.\nDuring the sprint planning, the team selects items from the product backlog that they commit to complete in one sprint and thus, creates the sprint backlog. The Product Owner and Scrum Master should not provide inputs that may impact the team's decision. Sprint backlog has:\n- Subset of product backlog items that the teams commit to implement in one sprint\n- Items broken into smaller pieces of work as tasks\n- A focus on HOW the team does the work and delivers the value in one sprint\n- A story or task board that is used by the teams to view backlog and individuals sign up for work after prioritization\n- Provision for the Development teams to track the sprint progress and check their alignment to sprint goals\nAn increment is the work delivered at the end of every sprint. Typically, after every iteration there will be a Product Increment (PI) that delivers value and the final product will be a working software. This increment is a sum of all the capabilities that were delivered in the previous sprints as part of the PI. A Product Owner decides whether to release the working product increment post the sprint or the release.\n4. Definition of Done:\nScrum clearly states a 'definition of done' that enables teams to understand the meaning of marking a story as done. Based on this, teams measure the progress of completion of their stories. This not only helps identify 'done' items, but also helps decide on the total items to be worked in that sprint or iteration. The 'definition of done' is defined at various levels, which are release level, sprint level and even at the story level. The story level 'definition of done' is handled through acceptance criteria. In a multi-team scenario, teams mutually align to the sprint's 'definition of done'.\nAll scrum activities are time-boxed and allow teams to inspect their current work and implement those learnings in future time-boxes.\nHeart of Scrum - The Sprint\nAt the heart of scrum, is the 'Sprint'. The sprint is a time-boxed iteration, typically ranging from 1 to 4 weeks, at the end of which, a potentially shippable product increment is delivered by the Development team. The sprint has the following characteristics:\n- Does not exceed a maximum of one calendar month, as this will increase the risk due to changes in requirements and thus, may not provide the perceived business value at the end of the sprint\n- Has a goal or 'definition of done' associated with every sprint that actually measures the success of the sprint\n- Can be cancelled by the Product Owner, if the goal or the need for the sprint becomes obsolete due to changing market\nScrum advocates specific types of activities, events, or meetings within a sprint to avoid the traditional formal meetings. These events and meetings are conducted at regular intervals and happen at specific periods of the sprint.\nTypical scrum activities are:\n- Product backlog refinement\n- Sprint planning\n- Daily scrum\n- Sprint review\n- Sprint retrospective\n1. Product backlog refinement (continuous activity throughout the sprint)\nProduct backlog refinement is a continuous activity throughout the sprint, where the Product Owner ensures that the product backlog is in order. The Product Owner performs the following tasks to ensure that the product backlog is relevant:\n- Removes or demotes product backlog items that no longer seem important\n- Adds or promotes product backlog items that become more important\n- Splits product backlog items into smaller items or merges smaller ones into larger items and estimates those\n2. Sprint planning (2 hours per week sprint time-box)\nSprint planning meeting happens at the start of every sprint. This helps the Product Owner and Development teams to plan the product backlog items that will be taken up for implementation during the sprint. The Development team performs the following activities during this meeting:\n- Considers and discusses product backlog items with the Product Owner\n- Ensures a shared understanding on those items\n- Selects a number of items that they estimate to complete\n- Creates a sufficiently detailed plan to complete the selected items\nTo ensure that the above is achieved, two activities need to be done:\nPart I: Define 'WHAT' work will be done\n- Product Owner renders prioritized product backlog to the Development team\n- The whole scrum team collaborates to understand the work\n- The Development team alone decides how much work is to be taken without any pressure for more work to be done\n- The sprint is given a goal called the sprint goal as the essential focus of that sprint\nPart II: Explain 'HOW' the work will get done\n- Development team decides how to produce the next product increment that meets 'definition of done'\n- Sufficient design and planning is conducted to complete the committed work\n- Work to be done in initial days is split into small units of one day or even less\n- Work to be done later are split whenever needed\n3. Daily scrum (15 minutes)\nDaily scrum is a 15 minute time-boxed event in which the team manages its daily activities. This is also called the daily stand-up meeting.\nThe scrum team meets every day, preferably at the same time and same place, so that it becomes a habit and here each member answers three critical questions:\n- What did I get done yesterday?\n- What will I get done today?\n- Are there any impediments blocking me?\nIt is essential that all the members of the scrum team are available for the daily stand-up meeting. The daily stand-up meeting is for the Development team, and they should participate enthusiastically to collaborate with each other.\nThe daily scrum also ensures that the impediments blocking the progress of the sprint are identified and resolved without further delay. Detailed problem solving does not happen during this meeting. Unnecessary meetings should be avoided by broadcasting individual updates to everyone.\nThis event enhances team communication and transparency, thereby enabling teams to be self-organized and make faster decisions.\n4. Sprint review (1 hour/week time-box)\nA sprint review is an event that happens at the end of every sprint, where the teams and stakeholders discuss what was done in the sprint. The following happens during this meeting:\n- A demo of the product increment showcasing the new features and underlying technology\n- Feedback from the review provides input to the team to further discuss on refining the existing backlogs and plan for future sprints\n- The Scrum Master facilitates this review meeting that is typically attended by all the stakeholders invited by the Product Owner\n- Sprint review is essentially a way in which the team inspects and adapts to the next sprint and overall product release\n5. Sprint retrospective (1 hour/week time-box):\nDuring a sprint retrospective meeting, the Development team inspects the previously completed sprint and identifies areas of improvement to be enacted for the upcoming sprints. This happens after every sprint and right after sprint review in which the whole team participates. During this meeting:\n- The team introspects on what went well in terms of collaboration, planning, process, and tools\n- They try to identify potential improvements that can be taken up in the next sprint to make the scrum processes more efficient by learning from previous shortfalls\n- They decide on what would be done in the next sprint by taking into consideration the major improvements\n- Scrum Master ensures that the teams improve their skills and knowledge during the scrum process so that they become more effective in the next sprint\n- The team focuses on improving their entire delivery cycle\nThe three typical questions the team answers are:\n- What shall we start doing?\n- What shall we stop doing?\n- What shall we keep doing?\nAll the above activities in the scrum process framework enable teams to deliver a potentially shippable working software in short iterations. This also enables teams capture feedback, inspect, and adapt for the next iteration.\nScrum also states five core values to which teams have to adhere. The core values are: Commitment, Courage, Focus, Openness, and Respect. These values need to be imbibed and lived by the scrum team to ensure the fulfillment of scrum pillars of transparency, inspection, and adaptation. It builds trust among everyone.\nSuccessful use of scrum depends on people becoming more proficient in these 5 values\n- People personally commit to achieving the goals of the scrum team\n- The scrum team members have the courage to do the right thing and work on tough problems\n- Everyone focuses on the work of the sprint and the goals of the scrum team\n- The scrum team and its stakeholders agree to be open to all the work and the challenges that they encounter while performing the work\n- Scrum team members respect each other and consider each to be capable and independent"", ""In the rapidly evolving landscape of remote work, the adoption of asynchronous communication has become increasingly prevalent. As organizations navigate the complexities of distributed teams, embracing asynchronous communication has emerged as a pivotal strategy for fostering productivity and collaboration.\nThe shift towards asynchronous communication presents unique challenges and opportunities that demand a nuanced approach. Understanding the impact, advantages, and effective implementation of asynchronous communication is not only crucial for remote teams but also holds the key to unlocking new levels of efficiency and cohesion within organizations.\n- Asynchronous communication allows team members to work independently and contribute at their own pace.\n- It provides flexibility, efficiency, and better work-life balance, leading to increased job satisfaction.\n- Asynchronous communication reduces the need for lengthy meetings and allows for focused, uninterrupted work, leading to more thorough problem-solving and decision-making processes.\n- To overcome time zone challenges, teams can identify core working hours, utilize shared calendars or scheduling tools, establish clear communication guidelines, encourage flexibility in task prioritization, and ensure project timelines are met while accommodating diverse working hours.\nThe Impact of Asynchronous Communication\nThe impact of asynchronous communication on remote teams' productivity and collaboration has been significant. It allows team members to work independently and contribute at their own pace, resulting in greater flexibility and efficiency. The flexibility offered by asynchronous communication enables team members to manage their work around personal or family commitments, leading to a better work-life balance. This, in turn, can enhance job satisfaction and reduce stress, ultimately contributing to higher productivity levels.\nMoreover, asynchronous communication, by its nature, allows team members to carefully consider their responses and contribute thoughtful, well-considered input. This can lead to more thorough problem-solving and decision-making processes, ultimately benefiting the overall productivity of the team.\nAdditionally, asynchronous communication can reduce the need for lengthy meetings, freeing up time for focused, uninterrupted work. This not only enhances individual productivity but also allows team members to allocate time to deep, concentrated work, leading to higher quality outputs.\nAdvantages for Remote Teams\nIn the context of remote teams, asynchronous communication offers a myriad of benefits, including increased autonomy and enhanced productivity.\nOne of the significant advantages of asynchronous communication for remote teams is the flexibility it provides. Team members can manage their work schedules more independently, allowing for a better work-life balance. This autonomy leads to increased job satisfaction and can positively impact employee retention.\nAdditionally, asynchronous communication minimizes the need for immediate responses, reducing the interruptions that commonly occur in synchronous communication. This, in turn, enables team members to focus on deep, uninterrupted work, ultimately enhancing productivity.\nMoreover, asynchronous communication allows for the documentation of discussions, decisions, and feedback, creating a valuable knowledge repository for remote teams. This accessibility to information fosters transparency and ensures that all team members are consistently informed, regardless of time zone differences.\nOvercoming Time Zone Challenges\nAsynchronous communication's facilitation of independent work schedules and its reduction of immediate response demands exemplify its potential to address the challenges posed by time zone differences in remote teams. Managing time zones and coordinating remote teams can be complex, but with the right strategies, it is possible to overcome these challenges effectively.\nHere are four key strategies to overcome time zone challenges:\n- Overlap Hours: Identify core working hours that overlap across different time zones to ensure that team members have the opportunity for real-time collaboration and communication.\n- Transparent Scheduling: Utilize shared calendars or scheduling tools to transparently display each team member's working hours and availability, making it easier to coordinate meetings and tasks.\n- Clear Communication Guidelines: Establish clear guidelines for communication expectations, including response times for asynchronous communication, to ensure that team members understand how and when to communicate across time zones.\n- Task Prioritization and Flexibility: Encourage flexibility in task prioritization and deadlines to accommodate the diverse working hours of remote team members while ensuring that project timelines are met.\nStrategies for Effective Collaboration\nEffective collaboration in remote teams hinges on understanding the benefits of real-time versus asynchronous communication and choosing the right tools for the job. By exploring the dynamics of real-time interactions and asynchronous exchanges, teams can optimize their communication strategies to suit their specific needs.\nAdditionally, selecting the most suitable collaboration tools can significantly enhance productivity and cohesiveness within remote teams.\nReal-Time Vs. Async\nWhen considering strategies for effective collaboration, it is essential to carefully evaluate the benefits and drawbacks of real-time and asynchronous communication in remote teams. Both real-time collaboration and asynchronous productivity have their own advantages and limitations, and understanding how to leverage each method can significantly impact team productivity and satisfaction.\nHere are some key considerations for real-time versus asynchronous communication:\n- Synchronous Communication: Real-time collaboration enables immediate feedback and decision-making, fostering rapid problem-solving and team alignment.\n- Asynchronous Communication: Allows for flexibility, deep focus work, and provides time for thoughtful responses, reducing interruptions and multitasking.\n- Balancing Act: Finding the right balance between real-time and asynchronous communication is crucial for maintaining productivity and team morale.\n- Tools and Training: Providing adequate tools and training for both real-time and asynchronous communication is essential for remote teams to thrive.\nCareful consideration of these factors can help remote teams achieve effective collaboration while embracing both real-time and asynchronous communication methods.\nTools for Collaboration\nFinding the right tools for collaboration is essential for facilitating seamless communication and efficient teamwork within remote teams. In the context of remote collaboration and virtual teamwork, it's crucial to leverage tools that enable effective communication, project management, and file sharing.\nPlatforms like Slack, Microsoft Teams, and Zoom are popular choices for real-time messaging, video conferencing, and virtual meetings. Project management tools such as Trello, Asana, and Jira help in organizing tasks, tracking progress, and managing deadlines. Additionally, cloud storage solutions like Google Drive and Dropbox are invaluable for seamless file sharing and version control.\nThese tools not only support effective communication but also foster a sense of connectedness and productivity within remote teams. Selecting the right mix of collaboration tools tailored to the team's specific needs can significantly enhance virtual teamwork and overall productivity.\nTools for Asynchronous Communication\nSeveral digital tools are available to facilitate asynchronous communication within remote teams, allowing for efficient and organized collaboration across different time zones and work schedules. To enhance remote productivity and effective communication, consider utilizing the following tools:\n- Slack: This popular messaging app allows teams to organize conversations into channels, making it easy to categorize discussions by project, team, or topic. With features like threads, file sharing, and integrations with other tools, Slack is an excellent platform for asynchronous communication.\n- Trello: For task management and collaboration, Trello provides a visual way to organize work with boards, lists, and cards. Team members can add comments, attachments, and checklists to keep everyone informed about the progress of tasks, making it a valuable tool for asynchronous project management.\n- Google Workspace: Formerly G Suite, Google Workspace offers a suite of productivity tools including Google Docs, Sheets, and Slides. These cloud-based applications enable real-time collaboration and asynchronous editing, allowing team members to work on documents at their convenience.\n- Zoom: While primarily known for video conferencing, Zoom also offers features for asynchronous communication such as chat, file sharing, and the ability to schedule and record meetings. This makes it a versatile tool for both real-time and delayed interactions within remote teams.\nSetting Clear Expectations\nTo ensure effective asynchronous communication in remote teams, setting clear expectations is paramount for fostering understanding and accountability among team members. Setting boundaries and communication guidelines helps establish a framework within which remote teams can operate smoothly. Here's a table illustrating the importance of setting clear expectations:\n|Benefits of Clear Expectations\n|How It Helps Remote Teams\n|Ensures everyone is on the same page and understands their roles and responsibilities\n|Encourages team members to take ownership of their tasks and deadlines\n|Provides a clear framework for communication, leading to fewer errors and conflicts\n|Allows team members to work autonomously with a clear understanding of what is expected\nManaging Workload and Deadlines\nBuilding on the foundation of clear expectations that fosters understanding and accountability within remote teams, effectively managing workload and deadlines is essential for maintaining productivity and ensuring timely project completion.\nTo achieve this, remote team leaders should focus on the following key strategies:\n- Prioritizing Tasks: Encourage team members to prioritize their tasks based on urgency and importance, ensuring that critical deadlines are met without compromising the quality of work.\n- Setting Clear Deadlines: Establish clear and realistic deadlines for deliverables, taking into account the availability and capacity of team members. This helps in aligning everyone's efforts towards a common goal.\n- Regular Check-ins: Schedule regular check-in meetings to review progress, discuss any challenges, and provide support to team members in managing their workload effectively.\n- Flexibility and Adaptability: Foster a culture that allows for flexibility in managing priorities and deadlines, acknowledging that remote work environments may require adjustments based on individual circumstances.\nNurturing a Healthy Work Culture\nNurturing a healthy work culture requires fostering open communication, prioritizing well-being, and cultivating a sense of belonging among remote team members. Building trust is fundamental in creating a positive work environment. It is essential to encourage transparency, honesty, and reliability within the team. This can be achieved by setting clear expectations, delivering on promises, and being open to feedback. Moreover, fostering autonomy among team members promotes a sense of ownership and accountability. Empowering individuals to make decisions and take ownership of their work not only boosts morale but also enhances productivity.\n|Key Elements of Nurturing a Healthy Work Culture\nCreating a culture of open communication involves actively listening to team members, providing avenues for sharing ideas, and ensuring that everyone's voice is heard. Additionally, prioritizing well-being involves promoting work-life balance, providing resources for mental and physical health, and acknowledging the individual needs of team members. Cultivating a sense of belonging can be achieved through team-building activities, recognizing achievements, and creating a supportive and inclusive environment.\nMitigating Communication Misunderstandings\nFostering a culture of open communication and trust within a remote team is essential for mitigating communication misunderstandings and ensuring effective collaboration. Preventing miscommunication is crucial in remote teams, where interactions primarily occur through written messages. To mitigate communication misunderstandings, remote teams should consider the following:\n- Clear Communication Guidelines: Establishing clear guidelines for communication helps team members understand the expectations around response times, preferred communication channels, and language etiquette.\n- Cultural Sensitivity Training: Providing cultural sensitivity training can help team members understand and navigate cultural differences in communication. This training can include awareness of non-verbal cues, language nuances, and differing communication styles.\n- Active Listening Practices: Encouraging active listening within the team can help prevent misunderstandings by ensuring that team members are fully engaged in understanding each other's perspectives before responding.\n- Utilize Communication Tools: Leveraging communication tools that support asynchronous communication, such as project management platforms and collaborative documents, can provide a clear record of discussions and decisions, reducing the likelihood of misinterpretation.\nAdapting to Asynchronous Workflows\nWhen adapting to asynchronous workflows, remote teams must carefully consider time zone variations to ensure effective communication and collaboration.\nClear communication expectations are essential in mitigating misunderstandings and ensuring that everyone is on the same page when working asynchronously.\nTime Zone Considerations\nAdapting to asynchronous workflows in remote teams requires thoughtful consideration of time zone differences to ensure effective communication and collaboration. Managing time zone variances and accommodating flexible schedules are crucial for maintaining productivity and fostering a cohesive team environment.\nHere are key considerations for navigating time zone variances:\n- Overlap Hours: Identify core hours when all team members are expected to be available for real-time communication.\n- Transparent Scheduling: Encourage team members to share their working hours and availability, promoting visibility and understanding across time zones.\n- Flexibility: Emphasize flexibility in meeting times and deadlines, allowing individuals to work during their most productive hours.\n- Communication Tools: Leverage asynchronous communication tools for sharing updates, insights, and decisions to bridge time zone gaps effectively.\nClear Communication Expectations\nTo ensure effective adaptation to asynchronous workflows, establishing clear communication expectations is paramount for remote teams.\nSetting boundaries and managing accountability are essential components of this process. Clear communication expectations involve defining response times for messages, outlining the preferred communication channels for different types of communication, and setting guidelines for sharing updates and progress reports.\nBy setting boundaries, team members can understand when they are expected to be available and responsive, helping to create a more structured and organized work environment.\nAdditionally, managing accountability through clear communication expectations ensures that team members understand their responsibilities, deadlines, and the consequences of not meeting expectations. This creates a sense of ownership and responsibility within the team, leading to improved productivity and overall success in asynchronous workflows.\nIn conclusion, embracing asynchronous communication in remote teams offers numerous advantages, such as increased flexibility and productivity.\nHowever, it also presents challenges, such as managing workload and nurturing a healthy work culture.\nBy utilizing effective strategies and communication tools, remote teams can successfully adapt to asynchronous workflows and mitigate misunderstandings.\nIt is through these efforts that remote teams can foster a sense of connectedness and collaboration, despite the physical distance, ultimately leading to greater success and satisfaction.""]"	['<urn:uuid:def28e7c-80b7-4c49-bf36-406831180f23>', '<urn:uuid:f2f591e5-2339-4119-9e52-44523d6c7e68>']	open-ended	direct	verbose-and-natural	distant-from-document	comparison	expert	2025-05-12T22:49:38.933606	23	109	4794
93	Which cheese needs more special care in production, Mozzarella or Parmigiano?	Parmigiano requires more special care, as it must follow strict PDO requirements. While Mozzarella is made by simply stretching fresh curd in boiling water, Parmigiano-Reggiano production is heavily regulated - it can only be made in specific regions (Parma, Reggio Emilia, Modena, Mantua and Bologna), using milk from specific cow breeds (like Alpine Brown or Rossa di Parma) that are exclusively grass-fed, and must be aged for at least 12 months under controlled conditions.	['Tips for Exploring Cheeses\nBuying cheese is hard. Start with your average grocery store. Sure, there is cheese. It’s just limited: to quasi-shelf-stable, plastic-wrapped versions of national favorites: Cheddar, Mozzarella, and Parmesan, which is not the real Italian Parmigiano-Reggiano, whose name and style is legally protected by the European Union.\nTiptoe into a fancy food store, and there’s a different kind of cheese: aromas of funk and cream hit your nose as you open the door. Hard-to-pronounce names like Ossau-Iraty, Hittisau or Époisses are enough of a barrier to stomp right out.\nAnd then, there’s the internet. A cheese may look beautiful, the description may sound beautiful, but will it taste like what you want?\nI’ve been there: hungry and frustrated. Cheese Stalemate. Go with the tried-and-true Brie or take a risk with Brillat-Savarin? All this boils down to one answer: you need your own Cheese Rolodex. But no, I don’t mean a physical Rolling Index.\nWhat I’m describing is developing a basic idea of the separate characteristics you like, and hate, in cheese. Then you can walk into a store or restaurant, “flip through” traits you know you like, and say, “I love the hard bite and silky, almost sweet taste of Gruyere, show me something similar.” And you’ll also know, when you’re surfing the internet for a late night cheese purchase, that “hard mountain cheese with a nutty finish” is probably close enough to Gruyere that you’ll polish it off in one sitting.\nStart small. Pick a cheese you like, say Mozzarella. The next time you’re on a cheese safari, preferably at a store with at least 30 types of cheese, ask for one similar to Mozzarella. If the cheesemonger has it, he or she will point to Burrata. Burrata is made with the same technique, by stretching fresh curd in boiling water to make its shiny white ball and stuffing it with pieces of curd and cream. Heaven, right? Or, he might suggest a sharper, salty version of Mozzarella, in which case he’d let you sample at least two stretched-curd cheeses from other regions in Italy. Ragusano and Caciocavallo are both made with the same basic technique, but are salted, stretched into different forms, and aged. And if you like the Ragusano, he might jump styles, to the sharper, creamier (and more familiar) Cheddar or to the sweeter, firmer Comté. Tasting through these connections will give you a more tangible idea of your taste, and add cards to that Rolodex.\nIt’s similar to wine. If you know you like Napa Cabernet, why not try one from Sonoma? And if you like the slightly drier wine, why not try a Cabernet blend, maybe with a touch of Merlot? It’s not a huge leap over to Bordeaux, for the same blend in an Old World style. Once you’re in France, you might be intrigued by the complicated region of Burgundy, and heck, from an Old World Pinot, it’s not a stretch to jump back to Oregon for some New World Pinot Noir.\nAs Lot18’s gourmet food specialist, I recognize that this isn’t a small task. After all, I’ve probably tasted over 350 types of cheeses, and I can still be indecisive. You may not have a good local cheese store, or you may not stop by more than twice a year. But every trek is time well-spent; there are delicious returns on even the most basic Cheese Rolodex.', 'There are really stringent laws governing what kind of cheese can be called Parmigiano Reggiano, so in fact the answer to the question should be: Only one kind – Parmesan cheeses produced in the regions which are covered by the Parmigiano Reggiano PDO (protected designation of origin). In reality, however, it is a little more complicated! Let me try to explain about the variations that can be found amongst cheeses that all proudly bear the PDO stamp which proclaims to the world that they are genuine Parmesan cheeses from the PDO region, which includes Parma, Reggio Emilia, Modena, Mantua and Bologna.\nIt may surprise you to know that there are about 420 creameries within this designated region, and these “parmesan factories” receive their milk from over four thousand farms every day. Inevitably, there will be a large variation in the end product from all these dairies, due to the season, altitude, breed of cattle and expertise of the cheese-maker. Another factor that hugely influences the final cheese is the period of maturation; the minimum time required for a cheese to fulfil the stringent appellation requirements is 12months, but some cheese wheels spend up to 36 months in the maturation cellars, during which time there is a very noticeable change in the taste and character of the cheese.\nFactors which influence the final product are:\nMaturation: at 12 months this medium-fat semi-hard cheese will have a pale cream colour, taste slightly salty, slightly acid and slightly sweet, and have a wonderful nutty fragrance – Parmigiano is never a smelly cheese! There is a slight grainy texture, one of the distinctive characteristics of this King of Cheeses. At 18 months, the texture has changed as more crystals develop and the straw colour of the cheese is a shade darker; the flavour is becoming more savoury and the fragrance has become a little fruity. The flavours and aroma of the cheese continue to deepen and mature, and the colour gets progressively darker. By 30+ months the cheese is fully mature, a golden straw colour with many crystals and can have woody, spicy, and dried-fruit flavours on your palate. The rind will be really hard at this stage.\nAltitude: At higher altitudes, the dairy herd has access to sweeter, greener grass (Parmigiano herds are never fed anything other than grass!) and purer water, resulting in the cheese from the mountains (Parmigiano di Montagna) having a subtly deeper flavour. Many cheese connoisseurs also believe that cheeses made in Spring and Autumn are also superior due to the improved feed at these times of the year. Since each wheel is date-stamped, it is easy for cheese buyers to select cheeses made at these time of the year.\nThe Herd: if you are faming cattle for the meat market you choose good beef producing breeds, and likewise milk producers for the famous Parmigiano cheese production rely on superior milk-producing cows. In this region the most favoured breed is the Alpine Brown, bred exclusively in the mountainous areas. Recently “red cows” as they are locally known are making a coming back. The Rossa di Parma is native cow of the area and it produces a superior milk. These animals produce the very best balance of quality and quantity of milk – a really superior product just perfect for the production of a really superior cheese.\nSo, to get back to the original question – there is only one type of cheese that may be called Parmigiano Reggiano, produced in the areas covered by the PDO, but within the parameters set there can be fairly wide variations in the appearance, aroma and taste (and price!) of your slice of Parmigiano.\nSubmit your review']	['<urn:uuid:ba9a0c48-62ec-4d72-9d8a-969583f2e67e>', '<urn:uuid:17133bf9-f8e6-43f1-bff4-835bb407e0a5>']	open-ended	direct	concise-and-natural	distant-from-document	comparison	novice	2025-05-12T22:49:38.933606	11	74	1183
94	green revolution india difference conventional organic farming methods impact	The Green Revolution in India, initiated in the 1960s, transformed agriculture into an industrial system by adopting modern methods including high-yielding variety seeds, pesticides, and chemical fertilizers. While this increased production, particularly in wheat, it differed significantly from organic farming methods. Organic agriculture focuses on maintaining ecological balance without synthetic pesticides or fertilizers, instead using organic inputs for cultivation. Organic farming has shown better drought resistance according to FAO research and produces food free of pesticide residues, which is why it's preferred for baby food production. While the Green Revolution prioritized maximizing yields through chemical inputs, organic farming emphasizes sustainable practices that improve long-term soil health and ecosystem quality.	"['You have already completed the quiz before. Hence you can not start it again.\nTest is loading...\nYou must sign in or sign up to start the quiz.\nYou have to finish following quiz, to start this quiz:\n0 of 61 questions answered correctly\nTime has elapsed\nYou have reached 0 of 0 points, (0)\nQuestion 1 of 61\nThe branch of agriculture which deals with the feeding, shelter, health and breeding of domestic animals is called:\nAnimal husbandry is the branch of agriculture concerned with animals that are raised for meat, fibre, milk, eggs, or other products. It includes day-to-day care, selective breeding and the raising of livestock.\nQuestion 2 of 61\nCultivation of wheat requires:\nWheat is primarily a crop of mid-latitude grasslands and requires a cool climate with moderate rainfall. The ideal wheat climate has winter temperature 10° to 15°C and summer temperature varying from 21°C to 26°C. Loam soil is the best for wheat cultivation.\nQuestion 3 of 61\nWorld’s maximum newsprint comes from:\nTraditionally, newsprint was made from fibers extracted from various softwood species of trees (most commonly, spruce, fir, balsam fir or pine). However, an increasing percentage of the world’s newsprint is made with recycled fibers. Temperate deciduous or temperate broad-leaf forests are a variety of temperate forest ‘dominated’ by trees that lose their leaves each year.\nQuestion 4 of 61\nIn which of the following countries long-staple type of cotton is mainly grown?\nLong- and extra-long staple cottons include pima cotton and Egyptian cotton. These cottons are renowned for their superior quality.\nQuestion 5 of 61\nLaterite soils are found in areas where:\nThe laterite soil is formed under conditions of high temperature and heavy rainfall with alternate wet and dry periods, which leads to leaching of soil, leaving only oxides of iron and aluminum.\nQuestion 6 of 61\nKharif crops are sown:\nKharif crops are domesticated plants that are cultivated and harvested in India, Pakistan and Bangladesh during the Indian subcontinent’s monsoon season, which lasts from June to November depending on the area. The southwest monsoon is generally expected to begin around the beginning of June and fade away by the end of September.\nQuestion 7 of 61\nWhere is India’s most prized tea grown?\nDarjeeling tea is a well-known tea variety that is exported around the world. It grows in the Darjeeling district of West Bengal, India. Darjeeling tea is unique because the leaves can be processed in different ways, resulting in black, green, white, or oolong tea.\nQuestion 8 of 61\nThe crops grown after the summer monsoon are called:\nThe crops grown after the summer monsoon are called Rabi. Rabi crops are sown in winter and harvested in the summer season.\nQuestion 9 of 61\nFor the cultivation of Tobacco, the soil should be rich in:\nThe major nutrients essential for growth the development of tobacco plants are nitrogen, phosphorus, potassium, calcium, magnesium and sulphur. Nitrogen has a greater effect on tobacco yield and quality than any other nutrient.\nQuestion 10 of 61\nThe part of the Equatorial region which has well-developed rubber plantations is:\nRubber can grow anywhere in Malaysia, because of the suitability of climate and soil; but most of the rubber estates are concentrated in the western coastal plains of Malaysia. Malaysia is one of the world’s leading producers of rubber and rubber products.\nQuestion 11 of 61\nThe soil conservation method in which mountain slope is cut into steps is:\nContour ploughing is the farming practice of plowing and/or planting across a slope following its elevation contour lines.\nQuestion 12 of 61\nIn which part of India, canal irrigation system is the most common?\nMost of the canal irrigation is in the canal network of the Ganges-Yamuna basin mainly in the states of Punjab, Haryana, and Uttar Pradesh. The maximum part of the total irrigated area of the country by canals is in Uttar Pradesh.\nQuestion 13 of 61\nWhich of the following is the main spice producer?\nMalabar coast is the main spice producer comprising Kerala and Tamil Nadu. As it lies in tropical conditions with ample rainfall, it is best suited for spice production.\nQuestion 14 of 61\nWhich of the following statements is not correct?\nJammu and Kashmir is the only state in India where saffron is produced.\nQuestion 15 of 61\nWhich of the following types of soil is best suited for cotton cultivation?\nBlack soils are most suitable for the cotton crop hence it is also known as black cotton soil.\nQuestion 16 of 61\nThe largest irrigation canal in India is called the:\nThe Indira Gandhi Canal is the longest canal in India and the largest irrigation project in the world.\nQuestion 17 of 61\nPlants are dried up in winter due to frost because:\nIn frost covered plants, ice crystals form inside plant cells. These crystals cause expansion of cells. Cells can expand up to a certain limit, after which they got ruptured and plants ultimately are killed due to mechanical damage.\nQuestion 18 of 61\nThe soil which originates under tall-grass prairie vegetation is called:\nChernozems are humus-rich grassland soils used extensively for growing cereals or for raising livestock. They are found in the middle latitudes of both hemispheres, in zones commonly termed prairie in North America, pampa in Argentina, and steppe in Asia or in eastern Europe.\nQuestion 19 of 61\nGreen Revolution in India has so far been most successful in case of:\nThe Green Revolution was a period when agriculture in India was converted into an industrial system due to the adoption of modern methods and technology, such as the use of high yielding variety (HYV) seeds, tractors, irrigation facilities, pesticides, and fertilizers. The production of wheat has produced the best results in fueling self-sufficiency of India.\nQuestion 20 of 61\nThe largest irrigated area in India is occupied by:\nThe largest irrigated area in India is occupied by rice. The total area under irrigated rice is about 22.00 million hectares, which accounts about 49.5 percent of the total area under rice crop in the country.\nQuestion 21 of 61\nWhich of the following methods does not help in conserving soil fertility and moisture?\nTechniques for improved soil conservation include crop rotation, Contour ploughing, Strip cropping, Shifting agriculture, etc. Dry farming encompasses specific agricultural techniques for the non-irrigated cultivation of crops.\nQuestion 22 of 61\nIn a slanting hilly Indian terrain experiencing more than 200 cm of annual rainfall, which one of the following crops can be cultivated best?\nTea grows best in regions which enjoy a warm, humid climate with a rainfall measuring at least 200 centimetres a year. Ideally, it likes deep, light, acidic and well-drained soil. Given these conditions, tea will grow in areas from sea level up to altitudes as high as 2,100 metres above sea level.\nQuestion 23 of 61\nWhich of the following are not grown in the Kharif season?\nThe Kharif crops are usually sown at the beginning of the monsoon season around June and harvested by September or October. Rice, maize, bajra, ragi, soybean, groundnut, cotton are all types of Kharif crops. The crops that are sown in the winter season (November to April) are called Rabi crops. Some of the important rabi crops are wheat, barley, peas, gram and mustard.\nQuestion 24 of 61\n“Slash and Burn agriculture” is the name given to:\nShifting cultivation is a mode of farming long followed in the humid tropics of Sub-Saharan Africa, Southeast Asia, and South America. In the practice of “slash and burn”, farmers would cut the native vegetation and burn it, then plant crops in the exposed, ash-fertilized soil for two or three seasons in succession.\nQuestion 25 of 61\nRotation of crops means:\nCrop rotation is the practice of growing a series of different types of crops in the same area across a sequence of growing seasons. It reduces reliance on one set of nutrients, pest and weed pressure, and the probability of developing resistant pest and weeds.\nQuestion 26 of 61\nWhich one of the following is not a plantation crop?\nA plantation is a large-scale farm that specializes in cash crops. The crops grown include cotton, coffee, tea, cocoa, sisal, oil seeds, oil palms, rubber trees, and fruits.\nQuestion 27 of 61\nWhich one of the following animals is called farmers friend?\nEarthworms are called the friends of the farmer because of the multitude of services they provide that improve soil health and consequently plant health.\nQuestion 28 of 61\nWhich one of the following is related to Silviculture?\nSilviculture is the art and science of controlling the establishment, growth, composition, health, and quality of forests and woodlands to meet the diverse needs and values of landowners and society such as wildlife habitat, timber, water resources, restoration, and recreation on a sustainable basis.\nQuestion 29 of 61\nJhum Cultivation is a method of cultivation which used to be practiced in:\nJhum cultivation also called slash and burn agriculture is a form of crop-growing farming activity. Crops are grown in this cultivation by clearing the trees and other vegetation and then burning the fields. This agriculture is practiced by the tribal groups in the northeastern states of India like Arunachal Pradesh, Meghalaya, Mizoram and Nagaland.\nQuestion 30 of 61\nWith which crop has Green Revolution been associated?\nQuestion 31 of 61\nOf the gross cropped area in India, the foodgrains occupy:\nGrain crops contributed about 127 million Hectare (59%) of the gross cropped area of the country. Rice and wheat occupied 22% and 15% of the total net cultivable area in India.\nQuestion 32 of 61\nThe gradation and standardisation of agricultural products in India are conducted through:\nAGMARK is a certification mark employed on agricultural products in India, assuring that they conform to a set of standards approved by the Directorate of Marketing and Inspection, an agency of the Government of India.\nQuestion 33 of 61\nIndian agriculture is typically characterised as:\nIndian agriculture is typically characterised as land scarce, labour surplus economy.\nQuestion 34 of 61\nIn India, the irrigation of agricultural land is carried out maximum by:\nAbout 80 percent of the current water use is drawn by agriculture. Irrigated area accounts for nearly 49 percent of agricultural land in India. India’s irrigation is mostly groundwater well based. At 39 million hectares (67% of its total irrigation), India has the world’s largest groundwater well-equipped irrigation system.\nQuestion 35 of 61\nWhich of the following countries has the highest percentage of land under cultivation?\nIndia has the highest percentage (57%) of land under cultivation.\nQuestion 36 of 61\n‘IR-20’ and ‘Ratna’ are two important varieties of:\n‘IR-20’ and ‘Ratna’ are two important varieties of paddy. ‘IR-20’ (International Rice-20) is a high-yielding variety of rice developed by the International Rice Research Institute. ‘Ratna’ Rice is as long as Basmati rice grains.\nQuestion 37 of 61\nPick the odd one out based on crop season:\nRice, maize, and cotton are some of the major Kharif crops in India. The opposite of the Kharif crop is the Rabi crop, which is grown in the winter. Wheat is a Rabi crop.\nQuestion 38 of 61\nThe residue left after extracting juice from sugar-beet and sugarcane is called:\nBagasse is the dry pulpy fibrous material that remains after crushing sugarcane or sorghum stalks to extract their juice. It is used as a biofuel for the production of heat, energy, and electricity, and in the manufacture of pulp and building materials.\nQuestion 39 of 61\nHYV refers to:\nHYV full form is High Yielding Variety. HYV seeds are resistant and have a high yielding potential against insects and diseases.\nQuestion 40 of 61\nWhich one of the following is not an HYV of wheat?\n‘Ratna’ is an HYV of rice.\nQuestion 41 of 61\nIn Indian agriculture, the period from July to October November is called:\nIn India, the Kharif season is popularly considered to start in June and end in October.\nQuestion 42 of 61\nWatermelons grow best in:\nSandy loam rich in organic matter with good drainage is ideal for cultivation of watermelon. This crop requires a moderate warm temperature.\nQuestion 43 of 61\nThe term “Green Revolution” has been used to indicate higher production through:\nThe Green Revolution in India was initiated in the 1960s by introducing high-yielding varieties of rice and wheat to increase per hectare productivity.\nQuestion 44 of 61\nNature of unemployment in agriculture in India is:\ndisguised unemployment is also known as hidden unemployment. This refers to a situation where labour that is employed in a job is not actually utilised for the production of goods and services. Seasonal unemployment is when people who work in seasonal jobs become unemployed when demand for labor decreases.\nQuestion 45 of 61\nSoil erosion on hill slopes can be checked by:\nSoil erosion on hill slopes can be checked by Terrace cultivation. Terrace farming is a method of farming whereby “steps” known as terraces are built onto the slopes of hills and mountains.\nQuestion 46 of 61\nWhich breed of the following buffalo breeds is found in the Southwestern part of Gujarat?\nThe Surti is a breed of water buffalo found in the Charottar tract of Gujarat between the Mahi and Sabarmati rivers. The best animals of this breed are found in Anand, Kaira and Baroda districts of Gujarat.\nQuestion 47 of 61\nWhich one of the following categories of workers is termed as cultivators?\nCultivators are agricultural Labourers. A person who worked in another person’s land for wages in cash, kind or share was regarded as an agricultural labourer.\nQuestion 48 of 61\nBT seed is associated with:\nBt cotton was created through the addition of genes encoding toxin crystals in the Cry group of endotoxin.\nQuestion 49 of 61\nBark of this tree is used as a condiment:\nCinnamon is a spice obtained from the inner bark of several tree species from the genus Cinnamomum.\nQuestion 50 of 61\nMatch the following:\n1. Himachal Pradesh\n3. Uttar Pradesh\nThe correct match is as follows:\n3. Uttar Pradesh\n1. Himachal Pradesh\nQuestion 51 of 61\nThe adoption of High Yielding Variety Programme in Indian Agriculture started in:\nThe High Yielding Variety Programme (HYVP) was launched in the Kharif of 1966-67 with an objective to attain self-sufficiency in food by 1970-71.\nQuestion 52 of 61\n‘Brown Revolution’ is:\nThe Brown Revolution focuses on building soil ecology, thus enabling local farmers to feed communities. Brown Revolution: This revolution focuses on meeting the demand for coffee from the developed nations by growing socially responsible and environment-friendly coffee. The Brown Revolution is related to Visakhapatnam’s tribal areas.\nQuestion 53 of 61\nMechanization of Indian agriculture on a considerable scale is not possible due to:\nAmong problems encountered regarding use of agricultural machinery, high cost of equipment ranked first followed by high fuel cost small size of farm holdings and high repair and maintenance cost. Most of the farmers are poor and cannot afford to buy or own farm machines.\nQuestion 54 of 61\n‘Cod’ is a variety of:\nCod, (genus Gadus), large and economically important marine fish of the family Gadidae. The species Gadus morhua is found on both sides of the North Atlantic.\nQuestion 55 of 61\nGolden Revolution refers to:\nThe period between 1991 and 2003 is referred to as the Golden Revolution in India. IT is related to the increased production of honey and horticulture which was the main objective of this agricultural revolution. Nirpakh Tutej is the father of the Golden Revolution.\nQuestion 56 of 61\nDesertification can be checked by:\nDesertification can be checked by artificial bunds or covering the area with the proper type of vegetation and stop over-grazing.\nQuestion 57 of 61\nGreen Revolution was started in:\nThe Green Revolution in India was initiated in the 1960s by introducing high-yielding varieties of rice and wheat to increase food production in order to alleviate hunger and poverty.\nQuestion 58 of 61\nWhich of the following is not a cause of low productivity in Indian agriculture?\nCooperative farming is not a cause of low productivity in Indian agriculture. Cooperative farming refers to an organisation in which each member-farmer remains the owner of his land individually. But farming is done jointly. Profit is distributed among the member-farmers in the ratio of land owned by them.\nQuestion 59 of 61\nWhich of the following is called “brown paper”?\nJute is also called “brown paper” as the colour of the jute fibres is brown. Jute is used chiefly to make cloth for wrapping bales of raw cotton, make sacks and coarse cloth and making fine printing paper.\nQuestion 60 of 61\nThe crop mainly grown in hills is:\nSweet corn is the staple food in hilly and sub-mountain tracts of northern India, although consumed all over the country. It is extensively grown in Karnataka, Andhra Pradesh, Maharashtra, Rajasthan and Madhya Pradesh.\nQuestion 61 of 61\nThere was a substantial increase in food grains production specially wheat production, during the period after:\nAfter the Green Revolution, the productivity of wheat has been significantly increased. From 1966 onwards, the Green Revolution aimed at bringing about a Grain Revolution.', ""In essence, organic agriculture is an agricultural technique that sustains, maintains and improves the quality of the ecosystem. Therefore, it is intimately related to sustainable development.\nOrganic agriculturerefers to an agriculture system that maintains and improves ecological balance. In other words, this cultivation system is based on the use of organic inputs for cultivation.\nTraditional agriculture involves the use of chemical fertilizers, toxic pesticides, etc. That drastically damages the ecosystem. Therefore, this type of agriculture is practiced to produce toxic-free food for consumers and, at the same time, maintain soil fertility and contribute to ecological balance. This type of agriculture allows for sustainable and environmentally friendly economic development.\nSustainable agriculture describes agricultural methods and techniques aimed at minimizing the depletion of natural soil resources. Sustainable agricultural practices aim to preserve higher levels of organic matter, reduce erosion and keep more carbon in the soil. These practices improve soil resilience and long-term health and ultimately lead to higher yields. Because organic agriculture prohibits the use of synthetic pesticides, there is little or no risk of contamination of groundwater and surface water with synthetic pesticides.\nHowever, it is important to mention that when organic farmers use manure fertilizers, manure can also reach bodies of water and contribute to dead zones. In addition, since organic farmers do not use artificial fertilizers, they feed their crops indirectly through the soil, for example by applying fertilizer. FAO research shows that organic agriculture is showing that it can produce better yields during periods of drought. Baby food producers use organic products almost exclusively because organic vegetables and fruits don't normally contain pesticide residues.\nSince organic farmers around the world refrain from using harmful agrochemicals and work as far as possible in harmony with nature, it is clear that these heroes can be considered part of the solution. We have recently created flexible sustainable and cultivable leasing, which allows landlords to sign a lease agreement with their current farmer that includes provisions on sustainable agricultural practices. To determine the role of organic agriculture, a research project was launched with the University of Twente. Since organic farmers do not use chemical fertilizers, they feed their plants indirectly through the soil, for example by applying fertilizer.\nTherefore, it really doesn't matter if an organic product is sold at the farmer's market or in a discount store, if it is sold as “organic”, it must be applied to the strict rules set out in the legislation. So, when it comes to protecting our freshwater supplies, organic agriculture is largely part of the solution. In the U.S. In the US, a farm must be managed through organic practices for 3 years before the first “certified organic” harvest.\nSustainable agricultural practices, such as planting cover crops, help to sequester carbon, and reducing tillage helps prevent the release of additional carbon into the atmosphere. Organic agriculture can contribute to significant socio-economic and ecologically sustainable development, especially in the poorest countries. In organic agriculture, producers must learn to maintain nutrient levels in the soil without synthetic fertilizers and to tackle weeds and insects without herbicides or insecticides. .""]"	['<urn:uuid:1ea130dd-3b32-48a2-9c82-fc7b024ca4b8>', '<urn:uuid:55d8fb1c-226f-486a-a31b-12ee3b7e8b22>']	open-ended	direct	long-search-query	distant-from-document	multi-aspect	novice	2025-05-12T22:49:38.933606	9	109	3375
95	How many people have split sciatic nerves?	In 12-14% of people, the sciatic nerve splits into the fibular nerve and tibial nerve at or near the piriformis muscle.	"['Pre-lab Exercise: Surface Anatomy of the Gluteal Region\nLab 14 Primary Lab Objectives:\nRemove the skin on the buttocks. Identify the gluteus medius muscle and the iliotibial tract. Reflect the gluteus maximus muscle.\n- Locate the piriformis muscle deep to the gluteus maximus. Examine the relationships of the superior and inferior gluteal nerves and vessels and the sciatic nerve to the piriformis muscle as they exit the greater sciatic foramen.\n- Identify the gluteus medius muscle and transect the muscle to expose the underlying gluteus minimus muscle.\n- Locate the deep muscles of the gluteal region: obturator internus, gemellus superior, gemellus inferior, quadratus femoris, and obturator externus. Trace the path of the pudendal nerve and the internal pudendal artery.\n1. GLUTEAL REGION\n- Remove the skin from the buttocks.\n- Notice the cutaneous nerves you are cutting through as you skin the gluteal region.\n- Remove the fat overlying the gluteus maximus muscle and note the muscle\'s lower edge crossing the fold under the buttock obliquely.\n- Locate the specialized band of fascia of the thigh called the iliotibial tract. Its attachments are implied by its name.\nThe gluteus maximus muscle originates from 1) the back of the iliac crest, 2) the lower sacrum, and 3) all the dorsal ligaments binding the pelvis and sacrum together. It inserts into the iliotibial tract and the gluteal tuberosity of the femur. The gluteus maximus muscle lies directly behind the hip and acts primarily as an extensor of the hip joint. Notice that based on its attachments, it can also laterally rotate the thigh and tighten the iliotibial band. It is not active in walking since little active extension of the hip is involved but it comes into play in activities such as climbing stairs, rising from a squatting position, and running.\n- Verify that the superior and superficial fibers of the gluteus maximus muscle insert into the iliotibial tract.\n- The smaller tensor fasciae latae, like the gluteus maximus muscle, also attaches to the iliotibial tract.\n- Reflect the gluteus maximus muscle laterally by cutting along the border of the sacrum and the sacrotuberous ligament.\nNOTE: Cut the gluteus maximus carefully so that you don’t inadvertently take any fibers from the gluteus medius muscle below it. Also be careful for the blood vessels and nerves beneath the gluteus maximus. Attempt to keep all of these structures intact.\nThe head of the femur lies medial to the axis of the shaft. This produces bending stresses in the femur and tends to bow it outward laterally. This tendency is resisted by the functional importance of the iliotibial tract and the muscles pulling on it. The tract also improves the leverage of the gluteus maximus and tensor fasciae latae muscles in rotating the thigh medially and laterally.\n2. PIRIFORMIS MUSCLE\na. With the gluteus maximus reflected, examine the sciatic nerve and the inferior and superior gluteal nerves.\nb. Find the piriformis muscle emerging from the greater sciatic foramen to insert on the upper border of the greater trochanter of the femur. This is a major landmark in the gluteal region.\nc. Below the piriformis muscle, find the inferior gluteal nerve and artery exiting through the foramen to supply the gluteus maximus muscle. The sciatic nerve also exits the greater sciatic foramen below the piriformis muscle.\nNOTE: In 12-14 % o people, the sciatic nerve splits into the fibular nerve and tibial nerve at or near the piriformis muscle. When this happens, the fibular branch can run through the middle of the piriformis or exit the greater sciatic foramen above the piriformis muscle (see images about showing variation). See if your cadaver has one of these variations.\nd. Above the piriformis muscle, the superior gluteal nerve and artery exit through the foramen to supply the gluteus medius & minimus and tensor fasciae latae muscles.\nNOTE: Identification of the piriformis muscle will help to orient you in the gluteal region and find and identify the other rotators of the hip.\n3. GLUTEUS MEDIUS AND MINIMUS\n- Outline the gluteus medius muscle, noting its origin and insertion.\n- Transect the gluteus medius muscle along its origin near the iliac crest. Reflect the gluteus medius inferiorly to expose the gluteus minimus muscle immediately deep to it.\nNOTE: It is often difficult to separate the fibers of the gluteus medius from the gluteus minimus. Dissect carefully in this area.\n- Trace the superior gluteal vessels and nerves running between the two muscles, supplying them and ending in the tensor fasciae latae muscle.\n4. LATERAL ROTATORS\nA group of small muscles including both elevators and depressors cross the hip joint dorsally to act as lateral rotators of the femur:\n- Quadratus femoris\n- Obturator internus\n- Gemelli (L. =""little twins,"" diminutive of gemini)\n- Obturator externus\n- Separate the lateral rotators, beginning with the piriformis muscle.\n- The piriformis muscle, which you located earlier, is just below the gluteus minimus muscle and exits the greater sciatic foramen.\n- The next three muscles (in order from superior to inferior) are: the superior gemellus, obturator internus, and inferior gemellus muscles.\nHint: You will not see obturator externus yet. That will be visible from this aspect shortly when you transect quadratus femoris in a few steps.\n- The quadratus femoris muscle is a square muscle that can be found inferior to the last three.\nHINT: It is sometimes hard to see these small deep muscles. Here we provide a description of where these small muscles originate and insert to help orient you to this complex region. The piriformis muscle originates from the anterior surface of the sacrum and exits through the greater sciatic foramen to the greater trochanter. The quadratus femoris muscle runs from the ischial tuberosity to the back of the femur. The obturator internus muscle originates from the deep surface of the obturator membrane covering the obturator foramen and forms part of the lateral wall of the ischioanal fossa. Its tendon exits dorsally through the lesser sciatic foramen, which is the ""door"" to the ischioanal fossa. The gemelli muscles originate from the margins of the lesser sciatic foramen. These four muscles have separate little motor nerves from the lumbar plexus.\n- Carefully transect the quadratus femoris muscle as shown by the dotted line in the diagram below to see the tendon of the obturator externus muscle wrapping around the hip joint posteriorly.\n- Follow the pudendal nerve and accompanying vessels around the dorsal edge of the sacrospinous ligament into the ischioanal fossa.\nThe five lateral rotators can be assisted in their task by the much larger gluteus maximus muscle.\nAn intramuscular injection is used to deliver medication deep into the muscles. At this level, the medication can be absorbed quickly into the bloodstream (depending on the chemical properties of the drug). One way to determine where to give an intragluteal injection is to use surface anatomy. The sciatic nerve is approximately midway between the greater trochanter and the ischial tuberosity. Hence, it is best to give intragluteal injections in the upper lateral quadrant of the gluteal region to avoid any injuries by intramuscular injection. Typically, the common fibular nerve is more superficial and lateral as it branches off the sciatic, so it is commonly affected by these injections if they are positioned too far inferiorly.']"	['<urn:uuid:81d535e4-7e00-417d-b42c-2ed09165d1a1>']	factoid	direct	concise-and-natural	distant-from-document	single-doc	novice	2025-05-12T22:49:38.933606	7	21	1213
96	How does the permanence of hardware IDs compare to IP addresses?	Unlike IP addresses which can vary based on location and are assigned by network administrators or ISPs, MAC addresses are static and permanent, assigned by hardware manufacturers at the time of manufacture for each network adapter.	['When a device is linked to a local network, its MAC (Media Access Control) address, a distinctive identifier allocated to each network card, makes it simple to recognize the device. Even with Firestick, the MAC address is frequently written on the device’s bottom. The network card on your device has a special address called a media access control address (MAC address). It functions somewhat similarly to a postal address, except that a network distributes internet traffic to your device instead of your mailbox receiving mail. If you cannot physically locate the MAC address on your Firestick, you can use the settings to do so. Reading this post, you may learn how to locate the MAC Address on a Firestick. Consequently, let’s begin:\nRead Also: How to Install SoundCloud on Firestick\nHow to Find MAC Address on Firestick\n1. Join a WiFi network using your Firestick.\n2. Press the Home button on your Firestick controller to access the home screen.\n3. Navigate to the Settings button.\n4. From the Settings menu, choose My Fire TV.\n5. Click the About link next to that.\n6. Select the Network option by moving the cursor down.\n7. Along with the IP Address, Gateway, Subnet Mask, and DNS Address, the MAC Address is displayed on the right side of the screen.\nUsing Router Admin Panel:\n1. Open a browser or connect your PC to the router using WiFi or LAN. The address of the router’s administrative panel.\n2. Enter your Username and Password in the corresponding boxes to log in.\n3. Select the Connected Devices option after logging in.\n4. The list of linked devices will be given to you. Select a name for your Firestick.\n5. You may find your MAC address underneath your Fire TV.\nWhat is a MAC address?\nThe network card on your device has a special address called a media access control address (MAC address). It functions somewhat similarly to a postal address, except that a network distributes internet traffic to your device as opposed to your mailbox receiving mail.\nIs Wi-Fi address the same as MAC address?\nSelect Network. Toggle to Wi-Fi. Select “Advanced” from the menu. Your wireless MAC address is known as the Wi-Fi address.\nWhat is MAC address and IP address?\nA device is identified by its physical address, also known as its media access control, or MAC, address, to other devices connected to the same local network. The gadget is uniquely identified internationally by its internet address or IP address. Both addresses are required for a network packet to reach its destination.\nDoes MAC address change with WIFI?\nFirst, unlike IPs, which might vary based on location and are used to identify network devices globally, MAC addresses are static and only used in local networks. Additionally, unlike IP addresses provided by the network administrator or ISP (internet service provider), MAC addresses are assigned by the hardware manufacturer.\nIs MAC address permanent?\nThe MAC address is indeed permanent. All network adapters are given MAC addresses at the time of manufacture, and each networking device’s MAC address is distinct.\nCan I delete my MAC address?\nChoose MAC ACL under Configuration > Security > Basic. The screen for MAC authentication basics appears. Select the check boxes next to the MAC addresses that you want to delete in the Selected Wireless Clients list. Press the Delete key.']	['<urn:uuid:60d796e7-5c3d-4688-9438-39adc60df134>']	open-ended	direct	concise-and-natural	distant-from-document	single-doc	expert	2025-05-12T22:49:38.933606	11	36	558
97	particle free air maintenance physics department clean room versus nanofabrication facility clean room	Both facilities maintain class 1000 clean room environments but use different systems. The physics department clean room uses a basic clean room setup for processing semiconductors and photolithographic mask alignment. The nanofabrication facility has a more sophisticated system with three-stage air purification, including HEPA and ULPA filters, 14 recirculating air handling units, and maintains specific conditions of 68°F (±1°F), 50% humidity (±5%), and laminar air flow at 21 feet per minute. The nanofabrication facility's system completely replaces the air 35 times per hour.	"['The physics department is well equipped for both research and instruction. Two superconducting magnets, the smaller one operating at a field up to 6 tesla and the other reaching 13.5 tesla, are used in research on the quantum Hall effect, superconductivity, and resonant tunneling studies. A helium leak detector and a computer-based data acquisition system are available for cryogenic work. A mobile pumping station capable of achieving vacuum in the range of 10 -8 torr can be used for gas transfer and sample preparation work. The department has a class 1000 clean room for processing semiconductors and for other applications requiring a controlled environment. The clean room contains a Karl Suss photolithographic mask aligner that is able to pattern microscale circuits and devices. Two intrinsic-germanium detectors and a multiparameter analyzer are used in studies of coincident gamma rays. Apparatus is available for studies of the Mossbauer effect. Other supporting equipment includes a high-vacuum evaporator, and a rapid thermal annealer. Additionally, the department has recently setup a phonon imaging laboratory which allows the study of heat propagation in solids. This is a low temperature imaging system utilizing a cavity dumped argon-ion laser to excite thermal waves in semiconductors and insulators.f\nThe Gedankenlab (Searles 322) contains several PCs running Linux for student and faculty use. The physics department also maintains a Beowulf cluster in its computational physics research lab.\nThe department supervises the college facility machine shop, which has one full-time mechanician and one part-time machinist for the construction of specialized apparatus and the repair and maintenance of existing equipment in the natural science departments. The shop\'s major equipment includes three lathes, two milling machines and a recently acquired computer-controlled mill. Its resources are available for student instruction.\nMachining Center for Support of Teaching and Research\nMechanician: Bob Stevens\nRoom 20, Searles Science Building\nPhone: (207) 725-3610\nMachinist: Ben King\nRoom 20, Searles Science Building\nPhone: (207) 721-5244\nThe shop supports Academic Teaching and Research across the college by constructing special apparatus for\n- Demonstrations in the Classroom\n- Student use in the Teaching Laboratories\n- The research activities of the faculty and students\nA great range of requests can be accomplished by this college-wide facility - as explained on the Shop Work Request page.\nThe shop has two computer controlled machine tools, various conventional machine tools, along with welding, sheet metal and wood working machinery.\nThe computer controlled Machines:\n- Southwestern DPM 3 axis bed mill\n- Okuma Captain L-370M Multifunction Turning Center\nThe CNC lathe from Okuma America and the Robert E. Morris Company has a ""C axis"" spindle and motorized tools on the turret. Shapes not normally done on a lathe can be produced on this machine. Information used in our shop classes and links to outside sources are provided at the Shop Information page.\nThe Mechanician shares knowledge about design of apparatus and shop processes by :\n- Encouraging people to visit the shop\n- Demonstrating machine shop equipment\n- Engaging people in hands on activities when time, interest, and safety allows\n- Providing classes on machine shop processes, shop safety, and use of materials\nSchedules of classes or demonstrations and safety requirements are posted on the Shop Classes and Demonstrations page.\nArticle: Bob the Bowdoin Builder', 'A cleanroom is a facility designed to maintain extremely low levels of particulates in the air. The level of cleanliness is quantified by the number of particles per cubic meter. The ambient outdoor air in a typical urban area contains approximately 35,000,000 particles that are 0.0005 mm or larger for each cubic meter. UHNF cleanroom maintain a cleanliness level of 35,000 particles for each cubic meter or better, equivalent to class 1,000 or ISO 6.\nCleanroom Environment Overview\nThe UH Nanofabrication Facility includes a 3,300 square foot cleanroom space. The cleanroom environment is needed to reliably fabricate microscopic devices for research and manufacturing. This is achieved by taking ambient air and moving it through three stages of conditioning and purification. The cleanroom provides and maintains the following specifications:\n- Class 1,000 or cleaner air\n- Temperature of 68°F within 1°F\n- Humidity of 50% within 5%\n- Laminar Flow of 21 feet per minute (FPM) within 3 FPM\nAir Purification System\nAmbient air is purified through a number of filters before entering the cleanroom. First, ambient air is drawn into the building’s heating, ventilation and air conditioning (HVAC) system, providing acceptable indoor air quality and comfortable working conditions. Next, the building air is processed by the cleanroom’s main HVAC system which further conditions the air (temperature and humidity) and reduces particulates by up 1000x with HEPA filters. Finally, the HEPA filtered air gets conditioned again and purified with ULPA filters by 14 recirculating air handling unit (RAHU). These 14 RAHU is distributed across the roof of the cleanroom to provide and maintain a class 1000 or cleaner air in every region of the cleanroom. Some of the used air gets exhausted, but most of it gets recycled by mixing with the incoming HEPA filtered air followed by reconditioning and purification through the 14 RAHU. This system completely replaces the air in the cleanroom at a rate of approximately 35 times per hour.\nLaminar Flow Air\nSamples remain particle-free as long as it is exposed only to particle-free air (first air). First air flows continuously from the ceiling in a straight downward path (laminar flow) towards the floor at a velocity of 21 feet per minute (FPM). The air then gets drawn towards sideways towards the exhaust grills on the wall by the floor. Most of the exhausted air gets conditioned and cleaned before returning to the cleanroom as first air again.\nWhen the first air encounters an obstruction such as equipment, furniture, people, etc, the air flow becomes turbulent and can pick up particulates. People are responsible for most of the particles generated inside the cleanroom. This is why cleanroom users must wear cleanroom suits to contain the particulates from their clothes and body and refrain from making sudden movements. The average walking speed of 276 FPM, much faster than the first air velocity of 21 FPM, creates a long trail of turbulent air that can take up to a minute to recover.\nAir flow patterns in the cleanroom is visualized using a theatre fog machine. The fog show that the air flows straight downwards from the ceiling without any sideway motion. The air becomes turbulent when it encounters a surface and produces a 1 inch thick layer of dead air that doesn’t move. Dead air is also visible below blank ceiling tiles at the perimeter of the cleanroom.']"	['<urn:uuid:53017f1f-1395-49e6-b512-17a34c1097ff>', '<urn:uuid:19e00369-06e4-4ace-aae4-1b5994df441e>']	open-ended	direct	long-search-query	similar-to-document	comparison	novice	2025-05-12T22:49:38.933606	13	83	1098
98	heavy metals bioaccumulation lead exposure comparison modern medieval	Both today and in medieval times, heavy metal exposure varied by social status and location, but through different mechanisms. In modern times, heavy metals like lead enter the food chain through industrial processes, weathering, and human activities, affecting all population levels through bioaccumulation. In medieval times, lead exposure primarily affected wealthy urban dwellers due to their use of lead-glazed pottery and proximity to lead in coins, stained glass, and roof tiles, while rural populations were less exposed. In both eras, lead accumulation in the body can cause severe health impacts, particularly affecting children's neural development and intelligence.	"['All living things are part of the food chain… no exceptions. Although we experience this principle of dependency daily, it usually gets ignored unless something disrupts the chain and results to detrimental consequences such as food poisoning that may lead to human fatalities or illnesses. Heavy metals are a part of nature and some are even beneficial to the human body but as with most things, too much concentration can have its adverse effects. What Are Heavy Metals? Heavy metals are found in rocks and soils but these may also accumulate in water forms\nwhen these solid objects get broken down in time. The term heavy metal means any “metallic chemical element that has a relatively high density and is toxic or poisonous at low concentrations. (ILPI, 2007, par. 1) Some of the heavy metals that are being considered as threatening are arsenic, cadmium, chromium, copper, lead and mercury. These heavy metals which can also be called minerals have been present in the environment in safe amounts until industrialization has initiated mining activities and technological advances that altered their presence in the food chain.\nSome of the products that elevated these heavy metals to possible intolerable levels are leaded gasoline and silver-mercury tooth amalgam. (Haas, n. d. , par. 5) Unfortunately, heavy metals cannot be destroyed except through radiation. It is therefore necessary to control its content and the way it is distributed in man’s environment especially when the food chain is concerned. How Do Heavy Metals Seep Into The Food Chain? There are many natural ways by which heavy metals enter the food chain.\nNature can release heavy metals from boulders and other rock formations by weathering and eventual breakage or erosion. Volcanic eruptions can also release these heavy metals into the air which will eventually accumulate around the surrounding habitat of many living organisms. Acidic rains can also break down soils and release heavy metals into streams, lakes, rivers and ground water. (Lenntech, 2006, par. 4) Man also has had a hand in the spillage of heavy metals in his environment. Lead paint and water pipes have been a source of many health problems and intoxications.\nCopper, for example, can contaminate drinking water because of the copper-based pipes it passes and also from purifying agents that are intended to control the presence of microorganisms. Sewage sludge disposal unto farms is also a means that was originally a good way of garbage disposal but it can also be a path for certain nutrients to seep through the soil in larger quantities that may not be so beneficial after all. In Ohio, for example, sludges are considered rich in nitrogen and phosphorus which are significant sources of nutrients to farms in the vicinity of the sewage treatment plants.\n(The Ohio State University, n. d. , par. 1) However, it has been found that it also contains unnecessary amounts of cadmium, copper, nickel, zinc and lead that can deter the healthy growth of botanical organisms and contaminate the food chain. Cadmium is the one that is easily absorbed by plants and copper is toxic to livestock. These heavy metals can also contaminate the soil when these are applied as fertilizers and pesticides. Automobile exhausts, although not directly affecting the food chain, can also cause illnesses because of its lead content.\nBurning fossil fuel like coal, garbage and even tobacco can also release heavy metals like cadmium into the environment. (Contaminants Division, n. d. , par. 5) Man and nature can go hand in hand in releasing heavy metals in the environment. A factory in China, for example, can emit these toxic minerals in the air and the wind can carry it over to bodies of land and water in Russia. Because of this fact, it is harder to study the sources of heavy metal contamination in different locations. Bioaccumulation and Biomagnifications\nThere are two terms that are being used to show the problems that we undergo due to heavy metal contamination. These are biomagnifications and bioaccumulation. Biomagnification is the addition of intoxicating quantities of minerals when animals eat prey that could have been contaminated by heavy metals. Bioaccumulation, on the other hand, is an increase in the concentration of a chemical in a biological organism over time, compare to the chemical’s concentration in the environment. (Wageningen University, 2007, par.\n2) This means that the bodies of the contaminated organisms accumulate more of these toxins than what they are able to secrete or eliminate and the build up can cause many negative consequences. Biomagnification, as implied, is a step in the food chain while bioaccumulation pertains to the heavy metal content within a living organism in relation to its habitat. Methyl mercury, for example, is a heavy metal that can contaminate rivers. Marine organisms may make the mistake of taking the heavy metal. These organisms are usually eaten by fish.\nWhen a fish eats a contaminated marine organism, it cannot excrete the methyl mercury from its body anymore. The more contaminated organisms it eats, the more the methyl mercury accumulates within its body. Little fishes that have eaten these organisms can also be eaten by bigger marine creatures. The animals that are on top of the food chain stands to receive the consequences. Should a human, catch a contaminated fish, mercury poisoning will be inevitable and probably be even fatal. It was once assumed that heavy metals on the ground can bind tightly with soil particles and thus avoid being taken in by organisms eating on the soil.\nHowever, a study of snails on cadmium-contaminated soil was made by Renaud Scheifler and his team of soil biologists at the University of Franche-Comte which showed that after two weeks, the snail’s tissues were found to have absorbed 16 percent of cadmium. (Coghlan, 2002, par. 4) In other words, it is not true that heavy metals cannot be accessed by organisms when it is bound to soil particles. Thus, heavy metals can also enter the food chain through the soil. The human body can easily eliminate toxic substances taken in low doses but it can also sometimes confuse heavy metals for other helpful minerals.\nCadmium, for example, can be mistaken for zinc and lead for calcium. Although some of these minerals’ properties are the same, cadmium and lead cannot replace the functions or benefits that zinc and calcium provide. Thus, some essential body functions may not be carried out and heavy metals may also accumulate within. Humans are equipped with a good maintenance system but if our natural means of eliminating these heavy metals from our system is hampered because of overdose and continued exposure, there is a possibility of abnormalities or even fatalities if not treated properly.\nEffects of Heavy Metals to Humans Different heavy metals have unique effects on the living organisms that intake it. In the 1950s, many people in Japan began to experience a painful disorder called “itai-itai” which they discovered was a result of cadmium exposure due to industrial wastes. Cadmium can also have other effects such as the following: damage to the kidney, susceptibility to anemia, renal dysfunction, lung diseases that can lead to lung cancer, osteoporosis and osteomalacia.\nAnimals have been studied and showed that cadmium also increases their blood pressure but it has not been proven enough to affect humans the same way. Mercury and lead can both accumulate in the kidney, liver and spleen which can affect these organs’ functions. Low-level exposure can irritate the skin and cause ulceration. (Lenntech, par. 19) In 1932, people from Minimata Japan experienced what is now known as the Minimata Syndrome which was a direct effect of mercury contamination of marine life which the Japanese loved to eat.\nOver 500 people died because of this disruption in the food chain. Copper is needed by the body but unusual doses can result to anemia, damages to the liver and kidney, plus stomach pain. Chromium can also accumulate in marine creatures and can cause considerable damages to the human kidney, liver and nerve tissues. Selenium is needed for some human body processes but overdose can damage the nerves, result to over fatigue and increased moodiness. Harder to correct health problems that may arise include loss of fingernails, damages to organ tissues and the nervous system.\nOne of the most important links in the general food chain is the plant species. However, heavy metal contamination can cause very sensitive kinds of plants to die. (Velky, n. d. par. 1) When this happens, organisms that rely on these botanical creatures will have a food shortage. Plants who may survive contamination get the chance to be eaten by other living creatures that can start the problems of biomagnifications and bioaccumulation. Humans are susceptible to higher levels of pollutants through ingestion because we are at the top of the food chain.\nWhen plants and the soil from which many living things get food from becomes contaminated with toxic chemicals, these pollutants can be carried and accumulated in each animal that enters the food chain before man finally eats the one with the most quantity at the end of the chain. Heavy metals, as previously mentioned, can affect internal organs, the brain and even the development of young children. Pregnant women can bear ill or handicapped children as a result of heavy metal contamination of their food. For these innocent babies, the effect of these pollutants will remain with them for the rest of their lives.\nPrevention or Solution Since these heavy metals are important for other natural reasons and can only be broken down through radiation, we cannot easily just find technology that will eradicate them. We can only try to control them by studying more about how these affect the human population and how they become a dangerous part of the food chain. We can develop more studies as to which plants are more resistant to heavy metal contamination so that we can adapt our choices of agricultural products in industrial territories. (Velky, par. 3)\nGovernments concerned with the environment can also form agreements such as the “Heavy Metal Protocol” initiated by Canada which seeks to necessitate the use of environmental-friendly technology to lessen heavy metal pollution from industrialized factories. To avoid direct poisoning from toxic materials, it would be wiser to eat younger fish or smaller marine animals that could not have accumulated many chemicals yet from the food chain. It might also be smarter for people to eat animals that are not predators to avoid being the last link in a contaminated food chain.\nIt would also be better to listen and follow health advisories regarding food toxicity rather than risk food poisoning. Conclusion Technology and nature can cook up a dangerous recipe when heavy metals are concerned. Man has to learn to control wastes and learn more about pollution to be able to make wiser decisions regarding many things that affect the food chain. If the food chain is not properly secured, it can be assumed that the human population will experience short-term, long-term and fatal consequences that could have been otherwise avoided with good principles and information. Rough Draft\nIntroduction: All living things are essential in the food chain. Heavy metals are natural necessities but can be poisonous if taken in overdosed amounts. What are Heavy Metals: Nature provided man with heavy metals in natural land forms like rocks and soil. These minerals can be released as the land forms are broken down by weather and time. Man also has increased heavy metal contamination through technology, mining and industrialization. Heavy metals are not easily destroyed unless by radiation. Therefore, man has to learn how to control the quantity of these heavy metals in his environment.\nHow Do Heavy Metals Seep Into the Food Chain? Nature can release these when rock formations are broken, through erosion, volcanic eruptions and acidic rain. Man can contaminate his environment by improper disposal of wastes such as sewage sludges, irresponsible use of technology which emits poisonous gas like lead. Nature and man can also assist each other in contaminating the earth too. Bioaccumulation and Biomagnifications: Biomagnification happens when a contaminated prey is eaten by another living creature.\nEach of the biomagnifications in the food chain allows the accumulation of the heavy metal to increase until the end eater of the chain suffers the most quantity of toxic material ingested. This is bioaccumulation. Scientists are also proving that organisms can get these toxic wastes from the soil even when it was believed that heavy metals can bind themselves well to soil particles so that they become non-bio-accessible. This was refuted by a study in France. The human body also accepts heavy metals like cadmium and lead because these are mistaken for zinc and calcium which have similar properties.\nHowever, due to its differences, the functions aided by zinc and calcium are not met by cadmium and lead which results to devastating consequences. Effects of Heavy Metals to Humans: Different minerals have different effects. Plants, which are a very important part of the food chain, may also die because of contamination and this can affect those who eat it. Humans can die because of contamination. Should a victim live, serious consequences like birth defects for babies and handicaps may form.\nPrevention or Solution: Research must be done to find which plants can adapt to contamination and not before crops are planted near industrialized areas. Prevention and finding ways to control waste disposal are also recommendable. Learning to choose which food to eat can also save one from food poisoning. Conclusion: Man needs to learn how to control or manage waste disposal to protect and survive in the food chain.\nCoghlan, A. (23 December 2002). Danger of toxic metals in soils underestimated. Retrieved 15 October 2007 from http://www. newscientist. com/article/dn3196. html.Contaminants Division. (n. d. ). Northwest Territories contaminants fact sheets. Retrieved 15 October 2007 from http://64. 233. 183. 104/search? q=cache:3JoD8cM9h6cJ:nwt-tno. inac- ainc. gc. ca/pdf/contaminants/HeavyMetals_e. pdf+heavy+metals+in+food+chain&hl=tl&c t=clnk&cd=17&gl=ph. Haas, E. M. (n. d. ). Heavy Metals and Minerals. Retrieved 15 October 2007 from http://www. healthy. net/scr/article. asp? Id=1660. ILPI. (30 June 2007). Heavy Metals. Retrieved 15 October 2007 from http://www. ilpi. com/ msds/ref/heavymetal. html. Lenntech Water Treatment and Air Purification Holding.\n(2006). Heavy Metals. Retrieved 15 October 2007 from http://www. lenntech. com/heavy-metals. htm. The Ohio State University (n. d. ). Background Levels of Heavy Metals in Ohio Farm Soils Retrieved 15 October 2007 from http://ohioline. osu. edu/rc275/rc275_1. html. Velky, P. (n. d. ). The heavy metals in human food chain. Retrieved 15 October 2007 from http://bionet. informatik. uni-oldenburg. de/schulen/novaky/heavy_metals/en/hm08. htm. Wageningen University. (24 September 2007). Heavy Metals. Retrieved 15 October 2007 from http://www. food-info. net/uk/metal/intro. htm.', 'Being wealthy in the Middle Ages was not all benefits: Wealthy people were more exposed to the toxic heavy metal lead than the poor.\n""Lead poisoning can be the consequence when ingesting lead, which is a heavy metal. In the Middle Ages you could almost not avoid ingesting lead, if you were wealthy or living in an urban environment. But what is perhaps more severe, is the fact that exposure to lead leads to lower intelligence of children"", says Associate Professor Kaare Lund Rasmussen, Department of Physics and Chemistry, University of Southern Denmark (SDU).\nTogether with colleagues Rasmussen has published a series of chemical and anthropological analyzes of 207 skeletons from six cemeteries in northern Germany and Denmark. The paper is published in the Journal of Archaeological Science: Reports. The work was performed in collaboration with other SDU scientists: Professor Jesper Lie Boldsen from the Institute of Forensic Medicine and postdoc Lilian Skytte and Ph.D. student Anne Juul Jensen from the research group CHART at Department of Physics, Chemistry and Pharmacy.\nPractical, beautiful -- and poisonous\n""There really is a big difference in how much lead, the individuals from the cemeteries had in their bodies. This depended on whether they lived in the country or in a town. We see almost no lead in the bones from rural individuals, while the levels of this toxic metal were high in urban individuals"", says Rasmussen.\nIn the Middle Ages wealthy Danes and Germans mainly lived in towns, while the rural population was generally poorer and more isolated. The wealthy could afford to eat and drink of glazed pottery, and this was the main source of lead poisoning.\n""In those days lead oxide was used to glaze pottery. It was practical to clean the plates and looked beautiful, so it was understandably in high demand. But when they kept salty and acidic foods in glazed pots, the surface of the glaze would dissolve and the lead would leak into the food"", says Rasmussen.\nIn the country, glazed pottery was seemingly used more rarely. And even if you had the money, it would have been more difficult to get by. Instead, the country people used unglazed pottery and thus unknowingly saved themselves from exposure to the toxic lead.\nGlazed pottery was not the only source of lead in the towns. Lead was also present in coins, stained glass windows and lead tiles on the roofs of important buildings. Drinkingwater was often collected from the roof, and this may also have been an important source of lead.\nRasmussen studied skeletons from six cemeteries.\nThe cemeteries in Rathaus Markt in Schleswig (Germany) and Ole Worms Gade in Horsens (Denmark) are both situated on the coast and people buried here were from medieval towns that were more wealthy and more in contact with the outside world than most rural population.\nThe rural population was represented by cemeteries in St. Clements outside of Schleswig (Germany), Tirup outside of Horsens (Denmark), Nybøl in Jutland (Denmark) and St. Alberts Chapel on the island of Ærø (Denmark).\n""The exposure was higher and more dangerous in the urban communities, but lead was not completely unknown in the country. We saw that 30 pct. of the rural individuals had been in contact with lead -- although much less than the townspeople.""\nThere were different levels of exposure in the towns. 19 pct. (10 individuals) from the cemetery in Rathaus Markt had lead levels above normal. In Horsens all 25 individuals had levels above normal.\nMercury was given as medicine\nThe research team also tested the skeletons for their content of mercury. Mercury was used to prepare the color cinnabar, for gilding and as medicine against leprosy and syphilis.\nThe results of the measurements show that the urban population was more exposed to mercury than the rural population. Mercury was administered to treat especially leprosy, which almost half of the individuals in the study suffered from.\nHowever the study reveals a difference in how effective the treatment was in the towns.\n""Maybe they had more expertise in mercury treatments in Schleswig than in Horsens"", says Rasmussen.\nRef Journal of Archaeological Science: Reports,Vol 3, Sept. 2015, Pages 358-370: Comparison of mercury and lead levels in the bones of rural and urban populations in Southern Denmark and Northern Germany during the Middle Ages. Kaare Lund Rasmussena,Lilian Skyttea, Anne Juul Jensena,Jesper Lier Boldsenb. a Department of Physics, Chemistry and Pharmacy, Institute of Forensic Medicine SDU. University of Southern Denmark.\nAbout lead poisoning Lead is a toxic heavy metal that accumulates in the human body, affecting the nervous system. Since children\'s nervous system is still developing, children are particularly sensitive, and their learning ability and intelligence may be affected. Lead was also a commonly used material in the Roman Empire, and several historians believe that widespread lead poisoning among the rulers may have played a role in the fall of the Roman Empire.']"	['<urn:uuid:46e58331-5b8d-483f-9fa9-8186629815a2>', '<urn:uuid:a60d1cf1-6aaa-4f5b-88d9-237716e1471c>']	open-ended	with-premise	short-search-query	similar-to-document	comparison	expert	2025-05-12T22:49:38.933606	8	97	3251
99	What causes separation anxiety in dogs?	Separation anxiety in dogs can be triggered by abrupt changes in schedule, family dynamic, or residence. It occurs when highly social animals experience intense anxiety from being entirely alone, not necessarily from being separated from a specific person. Dogs may engage in destructive behavior to escape these bad feelings, or sometimes retreat into themselves and refuse to eat.	"['For every book or article on dogs’ physical well-being, there are only a few that address mental health. Perhaps that’s because dogs seem to have, well, a few adorable quirks, but they’re generally so sane — happy and energetic, cooperative, resilient. They live in the moment, they adjust to changes, they soldier through pain. They forgive us our trespasses.\nBut sometimes a dog seems to have serious emotional problems. For author Laurel Braitman and her husband Jude, trouble came in a large package, her Bernese Mountain Dog, Oliver. He experienced truly terrible separation anxiety, first by destroying things inside their apartment, later by desperate attempts to escape. Most frighteningly, he once propelled himself out the window of their fourth-floor apartment, landing on the concrete stairs leading to the basement. Amazingly, he survived, but during his long recovery, his owners began a determined quest to figure out how to understand and abate Oliver’s symptoms.\nOne result of their struggle eventually was divorce, caused in part by the tensions created by their differing perspectives on Oliver’s problems and how to handle them. Another result is her recent book, Animal Madness (Simon & Schuster, 2015), an exploration of mental illness in a variety of species, mainly elephants, cetaceans, primates and dogs, but others as well. Braitman studied the literature on the topic, both scientific and anecdotal, and traveled to a number of exotic locations to interview keepers, owners and veterinarians on the methods they have used to restore disturbed animals to sanity.\nBraitmann has good credentials for undertaking the task she set herself. She is an author, historian, and anthropologist of science with a PhD from M.I.T. She is currently a Writer-in-Residence at the Center for Biomedical Ethics at the Stanford University School of Medicine and her latest TED talk has been watched by over a million people. She has been involved with animals all her life, and for this book traveled extensively to meet and learn from mahouts in Thailand, primatologists in Africa, and many other experts as well.\nBraitman begins from the position that:\n…[H]umans and other animals are more similar than many of us would think when it comes to mental states and behaviors gone awry. …Abnormal behaviors…tip into the territory of mental illness when they keep creatures — human or not — from engaging in what is normal FOR THEM.\nIdentifying “abnormal” behaviors is difficult, of course. Since animals can’t talk to us, diagnosis has to involve, first, making careful and extensive direct observations (if possible) and getting a history of the animal and descriptions of its behavior from individuals who have lived with it. Sometimes technology can be used to measure brain activity, though of course this is expensive and therefore uncommon.\nIn addition, as with some human diseases, we infer the nature of a disease from observing the effect of medicines used to treat it. For example, in humans, Parkinson’s Disease can be differentiated from similar “Parkinsonisms” by whether it responds to levodopa. Many medications developed for human use (Haldol, Prozac, Zoloft and many others) have been used to treat mental problems in animals. In fact, not a few pharmaceuticals have been developed for human use through testing their effects on animals, and then “come full circle” to be used medically on the animals themselves.\nThe core of the book is an exploration of a variety of forms that animal mental illness may take. Among them are separation anxiety, depression, obsessive behaviors (such as licking, rocking, pacing), aggression and other antisocial behaviors. Interwoven with this exploration is discussion of the likely causes of abnormal behavior — maltreatment (neglect, captivity, impoverished environments, cruelty, extreme stress, isolation from others of the animal’s own kind or from inter species “friends,” etc.).\nZoos come in for Braitman’s most serious indictment of human actions that imperil animals’ sanity.Too often they exemplify many of the conditions least conducive to normal existence for animals–captivity, close containment (even chains), improper diet, squalid conditions, and isolation.Braitman believes that zoos, even those offering enriched environments for the creatures held captive in them, are really just a way of making us forget that the animals we’re watching don’t have normal lives or relationships nor do they have any control of their conditions. She would prefer they be abolished in favor of creating places where creatures that “thrive in our presence” can be observed, or replaced with “teaching farms urban dairies, and wildlife rehabilitation centers.”(She doesn’t mention it, but perhaps someday we can observe wild animals in virtual reality.)\nZoos aren’t the only target of her concern: inhumane farming practices are also called to account. In the United States and Europe, there are estimated to be about 16 billion animals in farms and labs.Among them, abnormal behavior is actually normal:91.5 percent of pigs, 82.6 percent of poultry, 50 percent of lab mice and 80 percent of minds exhibit abnormal behaviors.\nEven our much-loved pets may suffer, as Braitman’s Oliver exemplified.What she believes she learned about his symptoms is interesting.She argues that the fear that overcomes some dogs when left alone is not so much a matter of being separated from a particular person.Rather, it’s the sheer terror that grips a highly social animal when it is entirely alone. She says that a dog like her Oliver, when finding itself alone, experiences a wave of intense anxiety, and it is to escape these bad feelings that it engages in destructive behavior. In this situation, the presence of any human (or other non-threatening creature) may be calming.(Destructive behavior like Oliver’s is not the only manifestation of the extreme anxiety created by loneliness, however. A few creatures will retreat into themselves, becoming depressed and despondent. Often, they refuse to eat. As one expert, Dr. L’Elise Christensen (DVM) said, “Emotional eating in dogs is not eating.”)\nAlthough much of the discussion in the book is uncomfortable to read, not all human effects on animals are harmful.Braitman offers many touching stories of the loneliness of wild animals held captive in zoos and of domesticated animals taken or sent away from their human families. But she alsoshe also shares many heart-warming examples of the restoration of lonely animals to health and happiness when they find new homes or congenial companions, of animals’ resourcefulness and resilience, of their intelligence and generosity to other creatures.\nThese tales indicate a distinction that Braitman mentions infrequently but does not discuss as fully as this reviewer would wish — the distinction between wild and domesticated animals, particularly our pets. As obviously as she believes that animals in general need social interaction with companions of their own kind, she also clearly thinks pets can be happy with humans, even in the absence of others like themselves. And she points out cases where wild animals in captivity have had tight bonds of friendship (for want of a better, less anthropomorphic term) with a wild or domesticated animal as a companion. What are the boundaries being drawn here? Which species can live as friends and which can’t? What creates the conditions for inter-species friendships, including human-animal ones?\nAfter her intellectual and physical odyssey in writing this book, Braitman offers a conclusion that is compelling and appealing.We have to live with wildlife, she points out, because we have spread so widely over the earth that there are few spaces left where they are not close to us.As for domestic animals, we want to live with them, having learned over time that we ourselves experience health benefits (including better mental health) from their presence and our interaction with them.Predictably she deplores those who are cruel to animals, and she encourages us to act to as to change corporate farming and other practices that result in unnecessarily and excessively tortured lives for the animals that sustain us.\nFinally, she counsels contemporary pet owners to be aware that our lives do not always allow our companions to live their own best lives.She believes we should do what we can but forgive ourselves for the shortcomings that the modern world imposes.Instead of guilt, though, she proposes we take action – to “stop leading the sorts of lives that cause large numbers of our pets to end up on psycho-pharmaceuticals.”It’s a good point.When you think of it, in fact, who among us doesn’t wish we could “spend more time walking and playing with them and less time on our phones, checking email and watching television.”Improving our lives in ways that would also improve their lives will, she promises, be entirely worth it.', ""Vancouver vet advice on how to prepare for your dog's potential separation anxiety post-lockdown\nAs more of us return to the office, Dr Karley Seagrist from Yaletown Pet Hospital tells us how to help reduce your dog's separation anxiety.\nOne of the unexpected positives that came out of the recent months of lockdown was that dog owners got to spend more time at home than ever with their pups.\nInstead of leaving them behind all day while heading off to the office, owners got to be around their furbabies 24/7, and were probably more excited about walk-time every day than their pups were.\nBut with all this added time together, a lot of dogs have become more co-dependant and as life slowly returns to normal, with more socializing outside the house again and a return to the office for many, there is a real risk of potential separation anxiety developing.\nAs there has also been a huge spike in dog adoptions in Vancouver during the pandemic, many pups have only ever known the 'new normal' of 24/7 at home with their owners, which is leaving many dog owners worried about how their furbabies will react to being alone.\nAs this is a huge concern among Vancouver dog owners right now, we put your questions to Dr Karley Seagrist from Yaletown Pet Hospital who will help you take steps to prevent your dog's separation anxiety, as well as help you recognize, and ease it if you're pup is struggling.\nMany dog owners are worried about how their dog will cope when they return to work in an office. Is potential separation anxiety a valid concern?\nDogs are creatures of habit and routine, so any changes in their day to day activity can cause them stress or anxiety. Our pets have now become accustom to having us home more often, and we are seeing a rise in separation anxiety and destructive behaviours as our schedules have started to return to their pre-pandemic states. What causes separation anxiety and what are the signs that a dog is experiencing it? Separation anxiety is one of the most common behavioural concerns experienced by pet parents and can be triggered from an abrupt change in schedule, family dynamic or residence. Dogs with separation anxiety are often described as being their owner’s shadow, following them around from room to room. They will often begin to show anxiety as their family prepares to leave, which will progress to distress behaviours, such as excessive vocalization, inappropriate chewing or destruction, pacing or shaking, house soiling and heavy panting or salivation.\nIs there anything dog owners can do now to prepare for potential separation anxiety, or reduce the risk of it developing?\nWe can reduce the risk of separation anxiety by developing a routine to help build predictability and stability for your dog. We should ensure that their schedule includes plenty of physical exercise, mental stimulation and enrichment, social interactions and alone time.It is important that we create a safe and positive space for our dogs to relax and have downtime in, which may be in a room of the house or a crate. One of my favourite tricks is to fill a Kong or food puzzle with some high value treats and seal it with peanut butter or apple sauce before popping it in the freezer overnight. We can reward them with the food puzzle when they are having some alone time, which will provide some mental stimulation, help relieve boredom and positively reinforce their independence.\nRELATED: Vancouver Vet Answers Your Questions About Pets and COVID-19 RELATED: 12 Signs That Your Dog Is Genuinely Happy RELATED: Dog Eye Gunk - Should I be worried? Vancouver Vet answers your questions\nThere's been a spike in dog adoptions in Vancouver in recent months, meaning a lot of dogs have only ever known 24/7 company from their owners. What advice do you have for those owners to help it be a smoother transition when normality returns?\nIt is important to rule out other medical concerns with your veterinarian before we try managing separation anxiety. Try to mimic your pre-pandemic routine and schedule as much as possible and practice leaving them alone in a safe room or crate. We can also desensitize them to our pre-departure routine by putting on our shoes or grabbing our keys, without actually leaving. We can then progress to graduated absence exercises, where we slowly increase the time away from our pets, while we monitor them for signs of distress (panting, drooling, trembling, pacing or vocalization). You can also consider other options for pet care while you’re at work, such as doggy daycare, a dog walker or arranging for a friend or dog sitter to spend time with them.\nHow do you treat minor separation anxiety and how can you recognize if it is a more severe problem?\nIt is important that your dog is tired before you leave them – 30 minutes of off leash playing or swimming before you leave them will increase the likelihood they will relax while you’re away. Providing lots of mental stimulation, through food and treat puzzles and toys, will also help decrease stress and provide a safe outlet for normal dog behaviours (like chewing!). Using a camera or home monitoring device when you’re away is a great tool to investigate how comfortable your dog is while you are away and alert you if further support is required. It is always important to consult with your veterinarian in these situations, as severe cases may benefit from medication to assist with behaviour modification and help dogs become accustomed to being gradually left alone.\nIs there anything you recommend that dog owners avoid doing that could make the situation worse?\nIt is important that we focus on keeping the interactions with our pets positive and reward the behaviours we want, rather than punish the ones we don’t, as this may actually exacerbate an issue. We are all excited to greet our pets when we come home from a long day at work but try your best to minimize the ‘celebration’ when you get home and wait until your dog is calm and relaxed before greeting them. Don’t wait to chat with your veterinarian if you have concerns, it is often most rewarding to consult with us at the first sign of anxiety. You are not in this alone and we are here to help you and your furry family!\nALSO READ: 9 dog-friendly patios to visit this August in Vancouver ALSO READ: 9 Facebook Groups all Vancouver dog owners need to join ALSO READ: This Vancouver store allows you to put your dog’s face on YOUR mask""]"	['<urn:uuid:f471e36d-3c5a-4686-b362-fab60fd18b76>', '<urn:uuid:5006213d-9126-410b-9d07-a6770c3a72f1>']	factoid	direct	concise-and-natural	similar-to-document	three-doc	novice	2025-05-12T22:49:38.933606	6	58	2525
100	i want retro style flip clock screensaver how large can i make it display on screen	The Fliqlo screensaver displays an old-fashioned flip-clock with white numerals against a black background. You can customize the size of the clock from 25% to 125% of the original size. The bigger your computer screen, the bigger the clock will appear.	"['Fliqlo Flip Clock\nA flip clock screensaver for Windows and Mac OS X that tells the time against a black background in either a 12-hour or 24-hour format. Along with the format, the size of the old-fashioned flip clock can also be customized, from 25% to 125% of the original size.\nIs your question not listed? Post it on our message board »\n|Flip Clock - there is a small clock on top of the big clock||1||8 months ago|\n|Newer Version Required for Mac OS X 10.12.6||3||1 year ago|\n|Fliqlo Flip Clock does not work on MacOS Sierra||2||1 year ago|\n|Adjusting Flip Clock screensaver||1||1 year ago|\n|Fliqlo not working on Mac||4||1 year ago|\nAnti-virus report for Fliqlo Flip Clock\nOur editors have reviewed all files and found them to be safe, but they are also checked automatically using many different virus scanners. We are happy to share the results.\n|Virus scanner||314-Fliqlo Setup.exe||fliqlo_171.dmg|\n|Last scanned||1 month ago||1 month ago|\nWe have 2 files for ""Fliqlo Flip Clock""\n- 314-Fliqlo Setup.exe (Windows)\n- fliqlo_171.dmg (Mac)\n|File report #1|\n|File name||314-Fliqlo Setup.exe|\n|Target system||Microsoft Windows|\n|File size||4.52 MB (4,741,323 bytes)|\n|File type||Portable Executable (EXE)|\n|Detection ratio||0/15 (0%) View report|\n|Last downloaded||9 minutes ago|\n|File report #2|\n|Target system||Apple Mac|\n|File size||124.44 kB (127,422 bytes)|\n|File type||Apple Disk Image (DMG)|\n|Detection ratio||0/15 (0%) View report|\n|Last downloaded||15 minutes ago|\nA useful and fashionable retro clock screensaver\nThis flip-clock screensaver comes courtesy of Yuji Adachi, a Japanese developer who also creates and publishes other free goodies besides screensavers, such as fonts, apps, icon sets and desktop wallpapers. The Fliqlo screensaver, however, appears to be one of his most popular projects, and it\'s still actively developed. An iOS app version of the screensaver for iPhone and iPad was recently released, and is now available in the App Store for $0.99.\nThe premise of this screensaver is simple: it turns your screen into an old-fashioned flip-clock that looks much like the electromechanical alarm clocks invented in the mid-twentieth century. These clocks quickly grew in popularity due to their simple but elegant design, displaying the time in large white numerals against a black background. The fun and beauty of this screensaver is that it can effectively turn any Windows or Mac OS X computer into such an elegant and useful clock. The bigger the screen, the bigger the clock.\nSome options available to this screensaver, that the original flip clocks did not possess, include the ability to switch between a 12 and a 24-hour format. Furthermore, the size of the clock can be adjusted on a scale of 25% to 125%. These settings can be reset at any time.\nThe only disadvantage we could find is that it requires the Adobe Flash Player plug-in. However, since this is a safe and free download, and most people will already have it installed on their computer, it shouldn\'t really be an obstacle.\nAll things considered, the Fliqlo Flip Clock screensaver is a well-designed and functional screensaver that can be both useful and fashionable in your home or office.\nHappily, it\'s available both for Windows and Mac OS X.\nUser reviews (73)\nAwesome throwback look! I have noticed that in my Windows 10 Surface the screensaver goes black and it locks my system. I\'ve had to restart manually a few times. Finally I stopped using it. Any word on why?\nAlso, can we have an option to disable to ""Check for updates"" feature?\nterrible gave my computer big time issues and drains the battery fast, would not recommend\nMac High Sierra: slight issues with the settings they don\'t seem to work properly, the zoom function doesn\'t work neither does the 24 hour :/\nOtherwise like the idea :)\nI love this screen saver as it is cool and used in apple which makes it look more cool\nBest screen saver I have ever got on the internet.\nBe very careful using this screensaver for extended periods of time without change. Because it\'s very high contrast and the clock face is completely static, you can suffer a burn in (which I did). I\'m in the process of fixing it with a wallpaper created in pure white. I have a small sliver left in the repair. I\'ve had this white wallpaper displayed now for 7 days in the repair mode. Be smart, LCD\'s can suffer burn in.\nThe flip-clock is a terrible screensaver, when I downloaded it blocked my Mac, the mouse stop working and when it went to sleep mode –it didn\'t wake up– I had to force it to start again. I had to delete the screensaver app.\nit was excellent but the time was two mins behind what i read the from the sun\nBest clock screensaver - not battery draining :)\nBeware, this screensaver nught look innocent, but it remotely tries to connect with some ip unknown to me. Always remember to block this screensaver from accessing internet ^^ while the screensaver is fine & dandy, i dont understand the motive behind \'requiring internet connection\', be very careful what you choose to let in your pc.\nScreensavers Planet: It connects to the internet to check for available updates.\nReally great screensaver, but after a few minutes the clock disappears. Is there any fix to this on windows 10?\nLove the big clock.... but after a few minutes the clock disappears and all there is ..is a black screen. How to keep the clock on all the time?\nits super cool !!1\nthis is the best screensaver i\'ve seen in a long time. it redefines brilliance in simplicity.\nits so good\na simple but very good retro clock\nWhen I downloaded the screensaver, it was a different font than the pictures displayed. I checked with my sister, because she has the clock I wanted and it was the exact same download (same numbers and year), but mine is not block letters.\nLove the Screen Saver!!! But wheres the sound of the numbers flipping? i want the flip sounds to make it seem as real as possible!!! Thanks!!!\nSimple and nice looking screen saver. Running on a few Windows 10 computers.\nA concern that I have is ... I copied the 314-Fliqlo Setup.exe (Windows) file to my Google Drive for safe keeping. When I try to download that file from my Google drive to any other computer, Google blocks the download and states that a virus was detected.\nScreensavers Planet: Thanks for reporting that! I suspect they use ClamAV, among other programs, to scan files for viruses, and ClamAV raises a flag for the file. I have submitted a false positive report to ClamAV and expect the file to be cleared soon.\nInstalled the screensaver on my Win-Vista system today, love the retro look. Works well as is but when I enter ""settings"" for screensaver it brings up a flash window which allows me to make changes (24hr, 125%) but does not save them when I exit. It shows a ""reset"" button but no ""save"" button, so I\'m assuming it is supposed to be automatic upon closing. Any suggestions?\nScreensavers Planet: It appears to be an issue with Vista and the latest version of Fliqlo. See this thread on our message board: Adjusting Flip Clock screensaver\nOur school uses this as a clock in the ITV studio, and broadcasts it all day long in all the classrooms on their TVs. Teachers will panic if someone bumps the computer and the clock goes out.\nI love this screen saver, it\'s great but I can\'t get it to stay on 24 clock mode, even though I chose that setting on preferences - any ideas ?\nGreat screensaver. But after an update i was unable to show 24h time. Too bad!\nthe screensaver is dope but now i have weird pop ups / notifications that appear asking me to download more stuff and i don\'t know how to get rid of them. probably will have to delete just based on that.\nScreensavers Planet: That is unlikely to be a direct result of installing this screensaver. Feel free to post any questions or concerns to the message board.\nI really like it. It\'s not bright or over complicated. I use it on my laptop that sits on my night stand. It\'s nice for me, because I wear glasses.. So when I am sleeping. I can just look over, without fumbling for my glasses or trying to find my phone, and know what time it is.\nMy BIGGEST petpeeve with this. I use 24 hour time. I am always waking up at different times, so it\'s MUCH easier for me to glance over, look at the clock. Cool. 900.. It\'s 9am... 2100.. cool. It\'s 9pm.. This thing has a habit of RANDOMLY switching BACK to 12 hour time COMPLETELY ON IT\'S OWN. This has almost made me late to things MORE THAN ONCE! VERY frustrating!\nI like this screensaver, I installed it and immediately three of my coworkers installed it also. Looks great!\nNot working with the latest version of MacOS at the beginning-- But later it is working amazing!!! Thanks and sorry for previous message.\nScreensavers Planet: We recently tested it on macOS Sierra 10.12.1, and it worked just fine. Please post to the message board with details of your problem.\nI saw it on a shabby to sheek decor site offon the designers computer in a small space renovation...LOVED @ first sight.... Good to be a kid in simplier times and even better to be a big kid and combine the two! Thanks for this great functional screen saver!\nI have the new MacBook Pro with Retina running on macOS Sierra 10.12.1 and this isn\'t working. Any suggestions I tried the right clicking method and opening it through there and saving it onto my desktop.\nScreensavers Planet: First open the .dmg file you downloaded to bring up a window where three files will be shown. Right-click the ""Fliqlo.saver"" file, choose ""Open"", then click ""OK"". Failing that, please post to the message board for support.\nHad it for about 6 months on my Mac that was running OS X Yosemite and it worked wonderfully. Recently updated to OS X EI Captain and it said it doesn\'t run on this software.. Had to reinstall and it works perfectly again. Never had a problem with this screensaver and looks lovely. 10/10\nBe aware, this screensaver tries to connect to the internet.\nScreensavers Planet: It connects to the internet to notify you of available updates.\nMine only works when my laptop is charging or plugged in... Is this normal?\nI do love this screen saver, and have been using it for ages, however I recently got another monitor, so that I can have two screens when working. When I use just my monitor with the laptop closed, then this screen saver works fine, however when I use both screens, it is off centre and too large on my extra monitor. Some sort of settings that could be changed for multiple monitors would make this screensaver even more awesome :)\nThis screensaver uses my i5 processor at 50 % !!!\nI can\'t make it apear on my screen saver because it says I can only use them if they are downloaded in app store\nScreensavers Planet: Right-click the Fliqlo.saver file and choose ""Open"". You should then be able to click ""Open"" again to install the screensaver.\nThis is the best screensaver that ever saved my screen. Seriously, I love it. Works perfectly in my Windows 10\nThis unfortunately doesn\'t work with my current operating system. Is it possible to make an older version?\nScreensavers Planet: An older version of Fliqlo for Mac can be downloaded here.\ni went into display settings and found fliqlo there. it was extremely easy to adjust the timeout period as with any other screensaver. so 5 stars. dig it. a LOT.\nCan i use it on iPhone locked screen or i must run app everytime?\nScreensavers Planet: This screensaver is not compatible with iOS devices such as the iPhone and iPad, only with computers running Apple OS X or Microsoft Windows. However, a similar app for your iPhone may be available in the App Store.\ni love this screensaver!!\nBut sinds about a week there is only a white screen :-(\nhope bug (windows 10) will be fixed soon!\nScreensavers Planet: An update should now be available to fix this problem for Windows 10. The update is numbered 3133431. It should automatically install, but if you want to speed it up you can open Windows Update and search for new updates.\nI\'ve been using this screensaver and I loved it, untill, like others have said, it randomly stopped working and only shows a white screen...\nThere was a security update to Internet Explorer Flash Player today. I uninstalled the update and now Fliqlo is working again.\nScreensavers Planet: We have dedicated a help page to this issue. For more information, please see: I get a white screen when my screensaver runs?\nI\'ve been using this screensaver for year (on Windows), and like others have said, today it randomly stopped working and only shows a white screen. Tried restart and uninstall/reinstall with no luck. I loved it until it stopped working today.\nWe\'ve used this screen saver for years...it stopped today. Does anyone have a fix?\nCheck your installed programs. It looks like Adobe downloaded a flash player update today. That must be what killed any screensaver using flash.\nMy Screensaver also randomly started showing a white screen, has been fine for at least 2-3 years!\nmy screen went white also today. whats up with that!\nI\'m also getting the white screen today. Stopped working out of the blue. Anyone figure out why?\nI\'ve had this screen saver for years and absolutely loved it. I wake up this morning to find that the screen saver doesn\'t show a clock anymore...just a white blank screen. I restarted the computer and it didn\'t help. Uninstalled fliqlo and reinstalled and no luck. Even downloaded the newest version and it still just shows a white screen. Not happy right now.\nthe best one\nit didn\'t work for me i tried it so many times and it downloaded but when i select it to use it as a wallpaper it doesn\'t\nScreensavers Planet: That won\'t work because this is a screensaver, not a wallpaper. See our help article Screensavers and wallpaper: what\'s the difference?\nSeems OK so far. Installed easy enough.\nIs this only good for ipad and iphone? I wanted to use for my MacBook Pro.\nScreensavers Planet: This screensaver will not work on mobile devices such as the iPhone or iPad, only on computers running Mac OS X or Windows.\nI tried downloading this screensaver but it says my mac doesn\'t support this version and to contact the supplier.. does anyone know how to fix this?\nScreensavers Planet: This download should support Mac OS X 10.8 and newer. If you have an older version of the operating system, please try searching for an older version of the screensaver, e.g. Fliqlo 1.4, 1.3, and so on until you find one that works.\nYAY love it!\nVery simple and useful. I love it.\nOne thing... It is a bit too bright at night for me. It would be nice if it had brightness control. I adjust the size to small to make it less bright.\nI love it. Few more options would be amazing. (Multiple Monitors can each have own clock size etc).']"	['<urn:uuid:12ee7b30-b059-46cf-9399-d9ebca3028b7>']	open-ended	with-premise	long-search-query	similar-to-document	single-doc	novice	2025-05-12T22:49:38.933606	16	41	2583
