qid	question	answer	context	document_ids	question_factuality	question_premise	question_phrasing	question_linguistic_variation	question_multi-doc	user_expertise-categorization	generation_timestamp	question_length	answer_length	context_length
1	spine specialist curious about relationship between age patient risk facet joint deterioration statistics	Research data shows that individuals over the age of 50 are more prone to facet syndrome than others. This condition is a form of arthritis that can begin due to aging, leading to cartilage deterioration. When age-related deterioration occurs, it often results in exposed nerves and the growth of bone spurs that affect nearby nerves, causing symptoms like pain, tingling, numbness and weakness.	['Facet Syndrome Frequently Asked Questions\nFacet syndrome is a condition that causes pain within the facet joints. In simple terms, facet joints are the hinges that connect the vertebrae of the spine together. Facet joints are located on both sides of the vertebrae and are lubricated by a liquid known as synovial fluid. Facet joint surfaces are lined with cartilage allowing the joints to move fluidly without friction.\nWhat Causes Facet Syndrome?\nFacet syndrome has a variety of causes. It is a form of arthritis that can begin due to aging or injury leading to the cartilage deteriorating. Either way, the result is the bones rubbing together causing painful symptoms. Research data shows that individuals over the age of 50 are more prone to facet syndrome than others.\nDeterioration related to aging often leads to nerves being exposed as well as the growth of bone spurs that end up affecting nearby nerves. Common symptoms include pain, tingling, numbness and weakness.\nWhat are the Symptoms of Facet Syndrome?\nSymptoms related to facet syndrome can be difficult to pinpoint given the fact they are similar to many other back pain related symptoms. Facet syndrome symptoms vary according to which facet joints are affected.\nCervical facet syndrome affects the neck and upper back while lumbar facet syndrome involves the facet joints in the lower back. The neck and upper back are particularly prone to facet syndrome because they are the most flexible making them prone to wear and tear. Symptoms associated with facet syndrome include:\n- Pain that increases in the morning and evenings\n- Increasing pain during climate changes\n- Dull aching in the lower back\n- Headache at the base of the skull along with pain behind the eyes\n- Tenderness around affected facet joint\n- Difficulty twisting or bending backwards\n- Stiffness in the morning\nLumbar Facet Syndrome Symptoms – Lumbar facet syndrome is specific to the lower back. Symptoms are typically felt in the lower back, thighs and buttocks, but occasionally manifest in the lower legs and feet.\nCervical Facet Symptoms – Cervical facet syndrome affects the facet joints in the upper back and neck. The neck is particularly vulnerable because of its flexibility and constant use. One of the main causes of cervical facet syndrome is whiplash and harmful repetitive movements leading to cartilage wear and tear. Painful symptoms are commonly experienced in the neck, shoulders, and head.\nHow is Facet Syndrome Treated?\nThere are several treatment options for facet syndrome. San Diego pain management doctors and other healthcare providers will typically start with conservative treatments to alleviate symptoms. Facet syndrome ranges from moderate to severe depending on the level of degeneration. Below are treatment options categorized by type and invasiveness.\nConservative Treatment Options\nFor moderate cases of facet syndrome, conservative methods are commonly recommended. Treatment options include:\n- Rest – Stopping activities involving the back and neck can help reduce inflammation in the muscle and tissues leading to a relief in pressure.\n- Physical Therapy – physical therapists can help individuals strengthen core muscles, perform pain-relieving stretches and teach proper body mechanics to alleviate pressure on the facet joints.\n- Cold and Heat Therapy – ice packs can reduce inflammation while applying heat can increase blood flow to the affected area.\n- Pain Medication – prescription and non-prescription medications are commonly used to treat painful symptoms. San Diego pain doctors typically start with over-the-counter pain and inflammation medications such as aspirin, ibuprofen and acetaminophen.\n- Alternative Treatments – acupuncture, massage and Pilates are treatments that have been successful for some individuals.\nFacet Syndrome Exercises\nWhile it may seem counterintuitive to perform exercises to improve a back injury, facet exercises including low impact swimming, yoga, water aerobics and stretching can significantly improve overall health and mitigate painful symptoms. Exercises are typically assigned by a physical therapist.\nFacet Syndrome Medications\nMedications are often used along with other treatment options. The following are commonly used medications prescribed to treat facet joint syndrome:\n- NSAIDs – non-steroidal anti-inflammatory drugs include ibuprofen, naproxen and aspirin. These medicines work to mitigate inflammation that causes pain. They are particularly effective at treating more mild cases of facet syndrome.\n- Opioids – opioids are classified as narcotics so there is a risk of abuse. Because they are a stronger classification of medication than NSAIDs, they are more effective at relieving pain. Common opioids include hydrocodone, morphine and codeine.\n- Facet Joint Blocks – facet joint blocks are quite effective at relieving painful symptoms. Numbing and anti-inflammatory medications are injected directly into the affected area often providing instant relief.\n- Medial Branch Blocks – These injections serve 2 purposes, diagnostic and therapeutic. The injections may provide a few weeks to a few months of pain relief, and if they work they provide excellent information to the San Diego pain doctor.\n- Radiofrequency Ablation – if a medial branch block works and then wears off, a radiofrequency procedure may provide long term relief. Studies have shown that an RFA may provide 12 to 18 months of relief from facet syndrome, and can then be repeated if necessary.\nFacet Syndrome Surgery\nSurgery is the last resort in treating facet syndrome. Most people find non-surgical methods of treatment adequate. Research shows that facet joint blocks are the most effective. In fact, a study published in the 2012 Journal of Pain Research indicated 82% of patients at the 2-year follow-up point had at least 50% relief from pain and improvement in functional use after undergoing facet joint injections (Manchikanti 2012). If scoliosis or instability exists, surgery may help if all else fails.\nIf you or a loved one is suffering from low back pain, facet arthritis may be to blame. Pain clinics in San Diego offer relief for the problem. Let the California Pain Network connect those in pain with pain management doctors San Diego trusts.\nSimply call (619) 500-1573 for more information and scheduling today!']	['<urn:uuid:f90a324c-58d8-4b71-b6d2-2dadd77355a3>']	open-ended	with-premise	long-search-query	distant-from-document	single-doc	expert	2025-05-13T04:02:16.770989	13	63	986
2	network traffic clustering customer segmentation differences	Network traffic clustering and customer segmentation through clustering serve different purposes and analyze different types of data. Network traffic clustering, as implemented in environments like AzScienceNet, focuses on grouping network activities into categories like social networks, video resources, and scientific resources to identify anomalous traffic and optimize network performance. In contrast, customer segmentation in GST e-invoicing data analysis groups customers based on purchasing behavior, transaction frequency, and product preferences to develop targeted marketing strategies and improve business decisions. While both use clustering techniques, they differ in their objectives - network security and optimization versus business strategy and customer understanding.	"[""|Article title||ABOUT THE METHOD OF CREATING A PROFILE FOR WEB USERS|\n|Authors||R. M. Аlguliev, Y. N. Imamverdiyev, B. R. Nabiyev|\n|Section||SECTION V. INFORMATION TECHNOLOGIES AND PROTECTION OF INFORMATION|\n|Month, Year||07, 2017 @en|\n|Abstract||There are some tools for securing computer networks and optimizing processes. It is known that one of the main causes of the danger in network traffic is the generation of anomalous and non-core traffic. All this, creates an unnecessary load on the computer network, which in turn, reduces the availability of payload on the communication channels. This event is one of those events, which sooner or later may face corporate networks that are not adapted to the rule of behavior. Considering this, to determine the behavior profile of traffic on the network, a special tool has been developed. To determine the behavior profile, the K-means clustering method was applied. The reason for choosing the K-means algorithm is that this method is very fast and simple for solving the clustering problem. Data for analysis is collected in AzScienceNet network environment consisting of more than 5000 IP addresses (individual computers) and this network is also divided into several small subnets. In order to ensure that users privacy is not violated, AzScienceNet is based on user policy and additionally limited data on the identity of users. As a result of the application of the clustering model, certain clusters were formed. Clusters, in the main, form social networks, video resources and scientific and practical resources. The result is obtained for 20 clusters using the bigml.com resource. Most of all, the cluster under consideration consists of scientific and practical resources. The 2nd cluster in turn, these are social networks. The third cluster consists of calls to video resources. Appeal to other clusters is much less.|\n|Keywords||Network traffic; clustering; behavioral profile; anomalous traffic.|\n|References||1. Sokolov A.S. Modelirovanie segmenta vychislitel'noy seti i vyyavlenie problemnykh uchastkov v protsesse monitoringa [The modeling segment of the computer network and identification of problem areas in the monitoring process], Prikladnaya informatika [Applied Informatics], 2011, No. 3, pp. 116-120.\n2. Available at: http://www.itu.int/en/ITUD/Cybersecurity/Documents/Symantec_annual_internet_ threat_report_ITU2014.pdf.\n3. Callado A., Kamienski C., Szabo G., Gero B., Kelner J., Fernandes S., Sadok D. A Survey on Internet Traffic Identification, IEEE Communications Surveys & Tutorials, 2009, Vol. 11, Issue 3, pp. 37-52.\n4. Mingbo L., Wenjie S., Qianhong Z., Zhaoping T. Design and implementation of IP network traffic monitoring system, 15th International Conference on Optical Communications and Networks (ICOCN), 2016, pp. 23-35.\n5. Howlett T. Open Source Security Tools: Practical Guide to Security Applications, 2004, ed. 1. Prentice Hall, 608 p.\n6. Kumpulainen P., Hätönen K., Knuuti O., Alapaholuoma T. Internet traffic clustering using packet header information, Joint International IMEKO TC1+ TC7+ TC13 Symposium, Jena, Germany, 2011, pp. 13-20.\n7. Gerhard M., Sa L., Georg C. Traffic Anomaly Detection Using K-Means Clustering, In Pro-ceedings of performance, reliability and dependability evaluation of communication networks and distributed systems, 4GI/ITG-Workshop MMBnet, Hamburg, Germany, 2007, pp. 25-33.\n8. Ekola T., Laurikkala M., Lehto T., Koivisto H. Network traffic analysis using clustering ants, Proceedings. World Automation Congress. Seville, Spain, 2004, Vol. 17, pp. 275-280.\n9. Duo Liu, Chung-Horng Lung, LambadanÏs I., Seddigh N. Network traffic anomaly detection using clustering techniques and performance comparison, Proceedings the 26th Annual IEEE Ca-nadian Conference on Electrical and Computer Engineering (CCECE), Canada, 2013, pp. 1-4.\n10. Shokri, R., Oroumchian F., Yazdani N. CluSID: a clustering scheme for intrusion detection improved by information theory, Proceedings of the 7th IEEE Malaysia International Conference on Communications and IEEE International Conference in Networks, Kuala Lumpur, Malasia, 2005, pp. 553-558.\n11. Available at: http://wiki.squid-cache.org/SquidFaq/SquidLogs.\n12. Available at: https://ru.wikipedia.org/wiki/UNIX-время.\n13. Available at: https://en.wikipedia.org/wiki/Network_packet.\n14. Available at: https://ru.wikipedia.org/wiki/Список_кодов_состояния_HTTP.\n15. Available at: https://ru.wikipedia.org/wiki/HTTP#Методы.\n16. Available at: http://squid-handbuch.de/hb/node106_mn.html.\n17. Available at: https://ru.wikipedia.org/wiki/Список_MIME-типов.\n18. Available at: http://www.squid-cache.org/Intro/why.html.\n19. Han J., Kambe M., Pei J. Data Mining: Concepts and Techniques, ed. 3. Morgan Kaufmann Publishers is an imprint of Elsevier, 2012, 740 p.\n20. Yang G., Zhou G., Yin Y., Yang X. K-Means Based Fingerprint Segmentation with Sensor In-teroperability, Journal on Advances in Signal Processing (EURASIP), 2010, Vol. 10, No. 54, pp. 1-12.\n21. Kodinariya M., Makwana R. Review on determining number of Cluster in K-Means Clustering, International Journal of Advance Research in Computer Science and Management Studies, 2013, Vol. 1, Issue 6, pp. 90-95.\n22. Available at: http://www.bigml.com."", 'In recent years, the implementation of Goods and Services Tax (GST) has significantly transformed the way businesses operate. With the advent of GST e-invoicing, a massive amount of data is generated, containing valuable information about transactions, products, and customer behavior. Analyzing this data is crucial for businesses to uncover meaningful insights that can drive informed decision-making. One powerful technique for exploring and understanding such data is cluster analysis, which enables the segmentation of GST data into distinct groups based on similarity. In this blog, we will delve into the concept of cluster analysis and discuss its applications in the realm of GST e-invoicing data analysis.\nUnderstanding Cluster Analysis\nCluster analysis is a data exploration technique that aims to group similar data points while maximizing the dissimilarity between different groups. It helps identify patterns, similarities, and differences within the data that might not be readily apparent through traditional data analysis methods.\nThe process of cluster analysis involves the following steps:\n1. Data Preparation: The first step is to gather, clean, and preprocess the GST e-invoicing data. This includes removing outliers, handling missing values, and transforming variables if required.\n2. Feature Selection: Selecting the relevant features from the dataset plays a crucial role in obtaining meaningful clusters. Features such as transaction value, product category, customer type, or geographic location can be considered for clustering analysis, depending on the specific objectives.\n3. Similarity Measures: To determine the similarity between data points, suitable distance or similarity measures need to be employed. Common measures include Euclidean distance, cosine similarity, or correlation coefficients. The choice of measure depends on the nature of the data and the desired outcomes.\n4. Choosing a Clustering Algorithm: There are various clustering algorithms available, such as k-means, hierarchical clustering, or density-based clustering (e.g., DBSCAN). Each algorithm has its strengths and limitations, and the selection should be based on the characteristics of the GST data and the objectives of the analysis.\n5. Determining the Number of Clusters: Before applying the clustering algorithm, it is essential to determine the optimal number of clusters. This can be done through techniques like the elbow method, silhouette analysis, or domain knowledge.\n6. Cluster Formation: Once the number of clusters is determined, the clustering algorithm is applied to group the data points into distinct clusters based on their similarity. The algorithm iteratively assigns data points to clusters and updates the cluster centroids or density regions until convergence.\n7. Cluster Interpretation: After obtaining the clusters, the next step is to interpret and analyze the results. This involves examining the characteristics and patterns within each cluster and extracting insights that can inform business decisions or strategies.\nApplications of Cluster Analysis in GST e-Invoicing Data\n1. Customer Segmentation: Cluster analysis can help segment customers based on their purchasing behavior, transaction frequency, or product preferences. This information enables businesses to target specific customer groups with tailored marketing strategies, product offerings, or loyalty programs.\n2. Fraud Detection: By clustering GST data, it becomes possible to identify abnormal transaction patterns or anomalies that may indicate fraudulent activities. Clusters containing suspicious transactions can be further investigated for potential irregularities or tax evasion.\n3. Inventory Management: Clustering can assist in identifying similar products or product categories based on transaction data. This information can guide businesses in optimizing their inventory management, demand forecasting, and supply chain decisions.\n4. Compliance Analysis: Analyzing GST e-invoicing data through clustering can help identify non-compliant or potentially fraudulent taxpayers. By grouping taxpayers into clusters based on their tax payment patterns or invoice characteristics, authorities can efficiently allocate resources for audits or compliance monitoring.\nComparative Analysis of Clustering Algorithms for GST E-Invoicing Data Segmentation\nClustering algorithms are powerful tools used to group similar data points into clusters, where each cluster represents a distinct category or segment. These algorithms identify patterns and similarities within the data, allowing for efficient data segmentation without the need for labeled training data. Several clustering algorithms can be applied to GST e-invoicing data, including k-means, hierarchical clustering, DBSCAN (Density-Based Spatial Clustering of Applications with Noise), and Gaussian Mixture Models (GMM).\n- K-means Clustering: K-means is a popular centroid-based clustering algorithm. It partitions the data into k clusters, where each cluster is represented by its centroid (mean). The algorithm iteratively updates the centroids to minimize the sum of squared distances between data points and their assigned centroid. K-means is computationally efficient and performs well when clusters have a spherical shape and similar sizes. However, its effectiveness may degrade when dealing with non-linear and irregularly shaped clusters.\n- Hierarchical Clustering: Hierarchical clustering creates a tree-like structure (dendrogram) of nested clusters by either a bottom-up (agglomerative) or top-down (divisive) approach. It does not require the user to specify the number of clusters beforehand. Agglomerative hierarchical clustering starts with each data point as a separate cluster and then successively merges the closest clusters until all points belong to one cluster. Hierarchical clustering is useful for capturing nested and irregular-shaped clusters. However, it can be computationally expensive for large datasets.\n- DBSCAN: DBSCAN is a density-based clustering algorithm that groups data points based on their density and identifies outliers as noise. It defines clusters as areas of high density separated by areas of low density. DBSCAN can efficiently discover clusters of arbitrary shapes and is robust to outliers. However, it requires setting two parameters, the minimum number of points in a cluster (minPts) and a distance threshold (epsilon), which can influence the results significantly.\n- Gaussian Mixture Models (GMM): GMM assumes that the data points are generated from a mixture of several Gaussian distributions. It models each cluster as a Gaussian distribution and iteratively assigns data points to the cluster that maximizes the probability of generating the data point from that distribution. GMM is capable of handling overlapping clusters and is more flexible compared to k-means. However, GMM may struggle with high-dimensional data and requires estimating the number of clusters.\nSelecting the appropriate clustering algorithm for GST e-invoicing data segmentation depends on the specific characteristics of the dataset and the objectives of the analysis. K-means is suitable for well-separated spherical clusters, while hierarchical clustering can capture nested and irregular shapes. DBSCAN is ideal for handling noise and discovering clusters of varying shapes and sizes, while GMM is more flexible and accommodating of overlapping clusters.']"	['<urn:uuid:954c9c56-b4bb-49f0-8563-71bb2bdb92f9>', '<urn:uuid:f6344d4d-03cf-4c34-85ed-bd8f565afac7>']	open-ended	with-premise	short-search-query	similar-to-document	comparison	novice	2025-05-13T04:02:16.770989	6	99	1753
3	grassroots food assistance programs volunteers funding	These food assistance programs rely heavily on community support and donations. The Community Justice Initiative operates through community-based donations, with volunteers bringing supplies and food, while people make spontaneous contributions like cooked rice and water. Similarly, the Drop-In & Food Access Program depends on volunteers and in-kind and monetary donations to provide their programming, including community meals and holiday banquets.	"['Community Justice Initiative\'s Feed the People event brings 19th Ward neighbors together\nFor Craig Diallo Carson and Niya Shabazz, who hail from the 19th Ward, giving back to their community is a lifelong mission.\nOn May 17 last year, Rochester Police handcuffed a 10-year-old girl during a traffic stop. That same day, Carson, Shabazz, Aqueelah Sovereign El Bey — the girl’s mother— and others formed the Community Justice Initiative (CJI).\nThe organization, Carson said, is “an instrument of justice, a vehicle of justice for Black people, original aboriginal people of color, in this city of Rochester.”\nCJI is focused on ""dismantling, destroying, attacking white supremacy, but then separately empowering our people culturally, empowering our people economically,” Carson said.\nOn June 18, shortly after founding CJI, the group launched ""Feed the People,"" a biweekly effort where they pop up in the neighborhood and distribute food. The first grassroots event was held at Hudson Avenue and Norton Street.\nThe next Feed the People event is scheduled for Wednesday, March 24.\nTeam members, along with people from other coalitions and community groups showed up and donated their time, labor and supplies. Devon Reynolds, a local barber who also has a pantry, brought clothes and shoes so that there were added offerings for people who stopped by. A DJ plays music, adding to the casual, community feel.\nEverything is community-based and donated, CJI said. Prior to an action, the organization makes a post on Facebook that asks for donations and lets its social media followers learn details of the upcoming event.\nPeople who want to help supply the event will drive to the location and leave goods with volunteers. Shabazz remembers one instance where someone stopped by, left and came back with cooked rice to serve people. Other times, people have donated cases of water.\nShabazz said the donations are from people\'s hearts.\n“People will just come out and do genuine acts of kindness,” Shabazz said. “It doesn’t pay you literally, but to see people’s gratitude after the service we provided them — that’s a like a form of payment. The people, the community, really appreciates it.”\nIn addition to providing food for physical sustenance, CJI endeavors to ensure that people are fed mentally.\nThey provide literature to those who stop by and build a rapport with community members, so that people in the 19th Ward know that they have advocates who they can turn to if and when there\'s a need.\n“My motto is, ‘for the people, by the people,’” Shabazz said. “It’s our people, and it’s by us. We want to provide … we want to bridge these gaps, and feeding the people is just a minuscule part of it.”\nCJI also hosts “Do the Knowledge,” a forum during which anyone — from educators, to politicians, to lawyers, to business owners — can have discussions with community members. During Do the Knowledge events, Shabazz said, CJI pulls up in the neighborhood with a tent and chairs to encourage people to join the discussion.\n“We’re not just talking about 1-2-3 and ABC. We believe in having knowledge of self. You have to know who you are to go anywhere in this world, so we teach that, individualism. … We want our children, our men and our women to have knowledge of self, to know who you are so you can make a difference on this realm, on this planet right now. … A lot of people don’t know who they are. They don’t know where they come from. So we want to provide that missing piece,” Shabazz said.\nCarson said the group’s activism seeks to bridge the gap between resources and awareness that exists in Rochester, and help people who could benefit from access to public services the most.\n“Our job as Community Justice Initiative is to engage everyone, but largely people in the communities we’re from, on such a powerful level that we’re messengers of where those resources are,"" Carson said. ""We’re messengers to get those resources directly back to the people.""\nAdria R. Walker covers public education for the Democrat and Chronicle in partnership with Report for America. Follow her on Twitter at @adriawalkr or send her an email at firstname.lastname@example.org. You can support her work with a tax-deductible donation to Report for America.', 'meals provided annually\naverage community members per day\nThe Drop-in and\nFood Access Program\nWorking in close collaboration with CONC’s Shelter and Housing Programs, The Drop-In & Food Access Program provides targeted supports that assist program participants and shelter residents to take steps toward better health, security and sustainability. The Drop-In operates 6 days a week and is open to everyone. We provide support particularly to individuals who are homeless, under-housed, or precariously housed and at risk of becoming homeless. Drop-In participants are often living on low-to-no income, are on ODSP or OW, are unemployed or underemployed, and face barriers to engagement in community life.\nOur program participants are challenged by significant barriers to stability and autonomy, including recent immigration, physical & mental health issues, substance abuse, isolation, trauma, and involvement in the justice system. Many Drop-In participants are seeking to develop the skills and supports they need to take steps out of poverty, including literacy, financial literacy, healthy coping strategies and positive relationships with peers and family. Drop-In participants have often experienced loss, abuse, neglect and mistreatment. They stand to benefit from the practical, tangible components of the program while being treated with respect, dignity and valued as a unique person as well as a valuable part of our diverse communities.\nThe Drop-In provides free access to healthy meals and snacks daily, prepared by volunteers and served with dignity. The Drop-In provides access to phone, fax and internet, showers and laundry facilities, volunteer opportunities, informative and skill-based workshops, and personal support for community members.\nThe Drop-In comprehensively addresses multiple aspects of poverty by providing support for housing and employment seekers. Program staff assist participants with tasks like resume writing, and completing social assistance applications or government forms. There are also activities for community health and wellness, such as fitness classes and health education workshops.\nThe Breaking Barriers Program\nThe Drop-In is also an effective access point to enhanced, targeted individual engagement with Life Management, Health & Wellness, Employment and Housing staff teams. These four teams work collaboratively to support participants in building more stable lives. For needs that go beyond program activities, and to contribute to building a supportive, expansive network for each community member, program staff teams draw on relevant connections and partnerships to provide tailored resources and referrals.\nClinics & Recreation Programs\nThe Drop-In regularly offers recreation programs ranging from Zumba (Latin-inspired cardio-dance workout) and Yoga, Conversation Circles, Neighbourhood Walking Groups and self-defense, to art therapy and cooking classes. We also go on outings to the Toronto Islands and other fun local destinations. Other structured Drop-In activities include Blood Pressure Clinics, TB Testing, Flu Shots, Dental and Hearing tests, Vision Care, Heart Health and Sexual Health information sessions with the support of Toronto Public Health.\nRecent reports from the Ontario Association of Food Banks state that low income adult and senior individuals are most in need of programs that reduce food insecurity. That evidence supports the increase we’ve seen in participants visiting the program primarily for food on a regular basis. Our sole-support parents food bank (currently under construction), that runs in tandem with the Drop-In, supports over 200 community members each month. Individuals who are leaving a shelter for more stable housing also gain access to the food bank for 9 months to a year, to support this important transition.\nEvents & Activities\nOur Drop-in hosts a number of events throughout the year to foster community engagement and inclusiveness. We strive to provide a place of celebration and organize unique experiences that encourage new friendships and a place of belonging during the times of the year where our participants may feel an increased sense of social isolation. Through these activities we are able to strengthen bonds within our social groups, such as our seniors group and men’s and women’s sharing circles.\nWe host daily community engagement activities, such as trips to Toronto landmarks like Centre Island and daily walking club, in addition to providing community meals during holidays, like our Canada Day BBQ, Thanksgiving meal or year-end holiday banquets. Volunteers and in-kind and monetary donations are the driving force that allow CONC to provide this kind of programming to our community. We are deeply grateful for the outside support we have received over the years and the lasting bonds we have been able to make because of this work.\nOn Tuesday mornings, our Drop-In gets creative! Participants are offered the chance to express their artistic side from 10am to 11:30am through art therapy. The group is run by our talented placement students where each week presents a new opportunity for community members to create art based on a common theme or a personal idea.\nThe art is displayed in various ways around our agency, or participants are invited to take their work home. The works have also become an integral part of community celebrations that the Drop-in organizes throughout the year; celebrations such as our Canada Day BBQ, where the participants’ art work was proudly and prominently displayed for the enjoyment of the larger surrounding community.\nThe Drop-In & Food Access program is operated out of our newly opened shelter building on 850/854 Bloor Street W.\n- The Salvation Army\n- Second Harvest\n- Daily Bread Food Bank\n- Unison Health Community Centre\n- Shoppers Drug Mart\n- Hakim Optical\n- Toronto Public Health\n- Toronto Meditation Centre\n- DAT Hair Salon\n- West Toronto Legal Services\n- 211 Community Services\n- Local Immigration Partnership (LIP)\n- Toronto Employment and Social Services\n- Eden Trattoria Restaurant\n- Houselink Community Homes\n- Oasis Dufferin Community Centre\n- Sistering Drop-In Centre\n- Skills for Change, Ontario Employment Services\n- WEST Neighbourhood House\n- Working Women Community Centre\n- Abrigo Centre\n- Adam House\n- Christie Refugee Welcome Centre\n- Church of St Stephen-in-the-Fields\n- 14 Division, Toronto Police Department\n- George Brown College\n- Centennial College\n- CDI College\n- Medix College\n- Ryerson University\n- York University\n- Bickford Adult Learning Centre\n- Marcca College']"	['<urn:uuid:74b56975-3780-4881-a05e-8df87538a915>', '<urn:uuid:7cf18870-be1a-4343-9887-356dd3e38c7f>']	factoid	direct	short-search-query	distant-from-document	three-doc	expert	2025-05-13T04:02:16.770989	6	60	1711
4	How do black holes and optical fibers help transmit signals?	Black holes and optical fibers transmit signals in very different ways. According to the documents, binary black holes emit gravitational waves that can be detected by facilities like LIGO and Virgo as signals traveling through space-time. In contrast, optical fibers physically transmit data signals using laser beams, with modern networks using two fiber strands - one to send data to consumers and another for back-transmission, achieving speeds up to 10 gigabits per second.	"[""Computational Relativistic Astrophysics\nResearch in this division covers mergers of binary neutron stars and mixed binaries – a black hole and a neutron star – as well as stellar core collapse that form black holes. The division also focuses on studying more fundamental aspects of General Relativity using numerical tools.\nTo understand the formation process of black holes and neutron stars, and what happens when black holes and neutron stars merge, we have to fully solve Einstein's equation as well as the equations of motion for matter in the presence of matter fields. It is generally not feasible to solve these nonlinear, partial differential equations analytically so we instead use numerical simulations on high-performance computers, for which we have been developing new methods in numerical relativity, since the 1990s. It is also feasible to accurately solve hydrodynamics/magnetohydrodynamics equations and to approximately solve radiation hydrodynamics equations for neutrino transport, using computational numerical methods.\nFor the numerical-relativistic calculations we use our supercomputer Sakura in Garching. With Sakura we have 11,600 CPU cores with a peak performance of 0,92 petaFLOP/s at our disposal.\nWe are now exploring a variety of dynamic and general relativistic phenomena such as:\n- mergers of binary neutron stars and black hole-neutron star binaries\n- stellar core collapse to a black hole and a surrounding torus\n- formation of a supermassive black hole through the collapse of a supermassive star\n- evolution of black holes and neutron stars by accretion of matter\n- outflow and jet from black holes and neutron stars\nThese numerical relativity simulations play an important role in predicting gravitational waveforms, that are used for gravitational wave detection, and in exploring high-energy phenomena such as gamma-ray bursts an kilonovae. Numerical relativity is also robust for exploring nucleosynthesis of heavy elements and the nonlinear nature of gravity theories.\nPredicting gravitational waveforms\nGravitational waves are emitted by general-relativistic and dynamical phenomena, if the system is not spherically symmetric. When powerful gravitational waves are emitted, they can be detected by gravitational-wave detectors such as advanced LIGO, advanced Virgo, and – in the future – also KAGRA, and Space gravitational wave detector, LISA. The advanced LIGO and Virgo detectors have already detected gravitational waves from binary black holes and binary neutron stars.\nWe expect that a large number of gravitational-wave sources will be observed by the gravitational-wave detectors in the near future. Upon detection, we have to identify the gravitational wave source and extract information such as mass, spin and distance from us from the data. To do this we have to prepare templates of gravitational waves emitted from the expected sources. We are now performing a large number of numerical-relativity simulations for the merger of binary neutron stars, black hole-neutron star binaries, stellar core collapse to a stellar-size and supermassive black hole, and so on, aiming at accurately predicting the corresponding gravitational waveforms.\nMerger of binary neutron stars\nBinary neutron star mergers are one of the most promising sources for gravitational-wave detectors like advanced LIGO, advanced Virgo, KAGRA and of short-hard gamma-ray bursts. To predict gravitational waveforms emitted by binary neutron star mergers and to theoretically explore the merger hypothesis of short-hard gamma-ray bursts, numerical relativity is the appropriate approach. In addition, the merger of binary neutron stars and associated mass ejection process is proposed as the primary environment for r-process nucleosynthesis. To explore this hypothesis, numerical relativity is again the appropriate theoretical approach. We have been working on this problem for the last two decades and discovered much about the merger process and resulting gravitational-waveforms.\nMerger of black hole-neutron star binaries\nThe merger of black hole-neutron star binaries is also among the most promising sources of gravitational waves and a promising candidate for the central engine of short-hard gamma-ray bursts. For this system, broadly speaking, there are two possible fates. In one scenario the neutron star is simply swallowed by the companion black hole, in the other the neutron star is tidally disrupted during the merger process. In the latter case, a wide variety of high-energy phenomena including gamma-ray bursts and mass ejection leading to transient electromagnetic emission are expected. We are exploring these phenomena using numerical relativity.\nGravitational collapse to a black hole\nMassive stars evolve through a series of nuclear burning and eventually, in their centre, an iron core is formed. If the mass of the iron core (and surrounding layers) is sufficiently large, a black hole will be formed after the stellar core collapse. Massive stellar-size black holes recently discovered in binaries observed by advanced LIGO and advanced Virgo are likely to have been formed from such a process. However, the formation process of these black holes is not, yet, well understood.\nRecent observations have shown that large galaxies usually have a supermassive black hole (SMBH) of a million to 10 billion solar masses in their centre. However, the formation process of an SMBH is still unknown: clarifying the formation process of an SMBH has been a long-standing problem in astrophysics.\nWe are investigating these problems in the framework of numerical relativity. Specifically, we perform a variety of numerical relativity simulations with different plausible progenitor stars aiming at clarifying the black-hole formation process. We then explore the possible signals from black hole formation such as gravitational waves, neutrinos, and electromagnetic waves, which may be detected in future observations leading to clarifying the formation process of black holes.\nMagnetohydrodynamics simulation in General Relativity\nMagnetic fields play a crucial role in the processes of a wide variety of phenomena. It is quite likely that magnetic-field instabilities play an important role in the merger of binary neutron stars and in the evolution of accretion disks surrounding compact objects. For example, during the collision of two neutron stars, a shear layer is inevitably formed at the contact surface of the neutron stars. At such a shear surface, it is known that the Kelvin-Helmholtz instability occurs and a number of small vortices are generated. The vortex motion subsequently amplifies the magnetic-field strength through winding of the magnetic fields. After significant amplification of the magnetic field, turbulence is likely to occur, and the resulting turbulent viscosity could determine the evolution of the merger remnant because it contributes to angular momentum transfer and viscous heating. To understand these processes, we perform a magnetohydrodynamics simulation in general relativity. For accurate study, we need to correctly take into account the Kelvin-Helmholtz instability in the simulation. However, this is not a computationally easy task because the fast-growing mode of Kelvin-Helmholtz instability has very small scales and we have to resolve such a small-scale mode in numerical relativity. To date, no simulation has resolved this, and thus, no physical simulation has been done. In the future, we’ll aim to perform an extremely high-resolution simulation to fully clarify the merger process of binary neutron stars. Magnetic-field instabilities could also play a crucial role in the evolution of the merger remnant and accretion disks surrounding compact stars. There are many issues that should be attacked using magnetohydrodynamics simulations in general relativity.\nOne phenomenological way to take into account angular momentum transport and turbulent viscosity is to employ viscous hydrodynamics, with which we explore the merger remnant of binary neutron stars and the accretion disks surrounding the central compact objects.\nBinary neutron stars in scalar-tensor theory\nTo date, we don’t have any evidence that general relativity is violated. However, the tests of general relativity have been performed in relatively weak gravitational environments such as in the solar system and with binary neutron stars of large orbital separation. Now that gravitational waves from a neutron star merger have been detected, we have the great opportunity of testing general relativity in a strong gravitational environment. For this test, it is important to predict what happens to the strong self-gravitating systems in an alternative theory of gravity. For one study, we performed simulations for the merger of binary neutron stars in a scalar-tensor theory of gravity."", 'The household demand for increased internet bandwidth has grown tremendously because of the popularity of data-intensive internet activities such as movie streaming. Conventional copper telephone lines struggle to meet this demand, and modern optical fiber networks connecting the homes of consumers to the network backbone are becoming necessary.\nJing Zhang and co-workers at the A*STAR Institute of Microelectronics have now demonstrated a network scheme that considerably reduces the cost of fiber-optic installations and could make them more attractive for consumer use.\nA key component of any optical fiber network is the laser that transmits information down the fiber. Unlike the silicon-based electronic circuits that control the data flow through the network, these lasers are made from semiconductor materials other than silicon, which is a poor light-emitter. This makes integrating lasers with silicon electronic circuits cumbersome and expensive, and so reducing the number of lasers in the network could substantially lower the cost of connecting users to the internet.\nOne widely adopted scheme for reducing the number of expensive lasers in the network is to transmit data to multiple homes at once using a single laser, with a transmission protocol ensuring that the correct data packet is sent to the correct user. Yet although this configuration reduces the number of lasers considerably, each connected household still needs a laser to send data back the other way.\nThe network architecture proposed by Zhang and his co-workers eliminates the laser at the consumer end. Instead, they propose using two strands of optical fiber: one to transmit data to the consumer as usual and another to send a continuous laser beam to all linked consumers. An integrated silicon chip at the consumer end picks up the incoming continuous laser beam, encodes it with the signal intended for back transmission, and then redirects this laser beam back to the internet provider. “Fiber is cheaper than lasers, particularly as it can be used for more than 20 years once it is installed,” says Zhang.\nIn their experiment, the researchers also demonstrated the practical viability of this scheme for the operation of commercial fiber-optic networks. They fabricated an integrated silicon circuit for this task and have already achieved successful operation at speeds of up to 10 gigabits per second. “Given the cost benefits, these transceiver devices may significantly accelerate the deployment of optical fiber networks,” says Zhang. “Our work has attracted serious commercial interest for collaboration on the development of silicon photonic transceivers.”\nThe A*STAR-affiliated researchers contributing to this research are from the Institute of Microelectronics\n Zhang, J., Liow, T.-Y., Lo, G.-Q. & Kwong, D.-L. 10Gbps monolithic silicon FTTH transceiver without laser diode for a new PON configuration. Optics Express 18, 5135–5141 (2010).\nNew NASA study improves search for habitable worlds\n20.10.2017 | NASA/Goddard Space Flight Center\nPhysics boosts artificial intelligence methods\n19.10.2017 | California Institute of Technology\nUniversity of Maryland researchers contribute to historic detection of gravitational waves and light created by event\nOn August 17, 2017, at 12:41:04 UTC, scientists made the first direct observation of a merger between two neutron stars--the dense, collapsed cores that remain...\nSeven new papers describe the first-ever detection of light from a gravitational wave source. The event, caused by two neutron stars colliding and merging together, was dubbed GW170817 because it sent ripples through space-time that reached Earth on 2017 August 17. Around the world, hundreds of excited astronomers mobilized quickly and were able to observe the event using numerous telescopes, providing a wealth of new data.\nPrevious detections of gravitational waves have all involved the merger of two black holes, a feat that won the 2017 Nobel Prize in Physics earlier this month....\nMaterial defects in end products can quickly result in failures in many areas of industry, and have a massive impact on the safe use of their products. This is why, in the field of quality assurance, intelligent, nondestructive sensor systems play a key role. They allow testing components and parts in a rapid and cost-efficient manner without destroying the actual product or changing its surface. Experts from the Fraunhofer IZFP in Saarbrücken will be presenting two exhibits at the Blechexpo in Stuttgart from 7–10 November 2017 that allow fast, reliable, and automated characterization of materials and detection of defects (Hall 5, Booth 5306).\nWhen quality testing uses time-consuming destructive test methods, it can result in enormous costs due to damaging or destroying the products. And given that...\nUsing a new cooling technique MPQ scientists succeed at observing collisions in a dense beam of cold and slow dipolar molecules.\nHow do chemical reactions proceed at extremely low temperatures? The answer requires the investigation of molecular samples that are cold, dense, and slow at...\nScientists from the Max Planck Institute of Quantum Optics, using high precision laser spectroscopy of atomic hydrogen, confirm the surprisingly small value of the proton radius determined from muonic hydrogen.\nIt was one of the breakthroughs of the year 2010: Laser spectroscopy of muonic hydrogen resulted in a value for the proton charge radius that was significantly...\n17.10.2017 | Event News\n10.10.2017 | Event News\n10.10.2017 | Event News\n20.10.2017 | Information Technology\n20.10.2017 | Materials Sciences\n20.10.2017 | Interdisciplinary Research']"	['<urn:uuid:a9d6c428-aaad-499d-ac34-c8892dc5e46a>', '<urn:uuid:ad8b378a-61ad-4da6-b18e-8d0cd7f3374c>']	open-ended	direct	concise-and-natural	similar-to-document	comparison	novice	2025-05-13T04:02:16.770989	10	73	2172
5	languages cultural identity medical outcomes	Languages play a dual role in cultural identity and health outcomes. From a cultural perspective, language is crucial for connecting with one's heritage and family history, particularly for children of immigrants who may otherwise be unable to communicate with their grandparents or understand their ancestral culture. Language skills also facilitate meaningful connections with other cultures, as people tend to be more open and welcoming when addressed in their native tongue. From a medical standpoint, research demonstrates significant health benefits of bilingualism, particularly in brain health. Studies have shown that bilingual individuals maintain better cognitive functioning despite Alzheimer's disease progression, displaying superior performance in memory tests and better functional connectivity in frontal brain regions. This occurs because the constant use of multiple languages creates structural changes in the brain that provide greater resilience against aging-related decline.	"['- Discover Oneself\nThere is often a language that plays a special role in a family’s history. This language is that of the local land, forefathers and roots, culture or religion, or even in-laws. You may have come across this little child whose family immigrated one generation ago. For lack of a common language, she cannot communicate with her grand-parents who stayed back in their country. As she grows older, more and more questions come to her mind. By learning her parents’ language, she will also discover the culture and the country of her ancestors, and better understand where she comes from.\n- … and discover the Other\nYou may be in a large city or a small village, in the desert or the jungle, in an office or on the beach, abroad or in your own country. When the Other sees how you make the effort to address them in their own language, they will turn their head towards you, stare at you and start smiling. Whether your accent is barely detectable or clearly audible, whether your grammar is already perfect or still perfectible, the Other is moved by your respectful behaviour. They relax, open up, ready to share more personal thoughts now that a psychological filter has been removed. Language knowledge is an invaluable gate-opener towards the Other.\n- Go on a trip\nBe it for holidays, a stopover or a business trip, knowing the local language can change drastically your experience. Not knowing the language, have you ever been hostage to the exclusive grip of a guide monopolizing all exchanges with the outside world? Have you ever seen foreigners fall prey to a complete misperception of the host country because they could not communicate? Conversely, has the local language never made contact with locals, planned or not, much easier? It will sometimes enable you to find your way, have dinner at night, even get your passport back or go through customs.\n- … or go for good\nBetween 1990 and 2010, about 160 million migrants changed countries. Do you happen to be one of them? Whatever the reason to migrate, it is life-changing. Having a good command of the host language is a pre-requisite to social and economic integration. In some countries being granted a visa –let alone citizenship- is subject to a minimum level in the host country’s language. Parents sometimes struggle and prior knowledge of the language is a decisive advantage; children usually adjust much quicker and soon surpass their parents.\n- Be successful at one’s career\nAs globalization increases, there are few jobs and positions left that do not require at least one, maybe two or even three foreign languages. English has become the unchallenged lingua franca of science. In business, one of the job interviews could take place in a foreign language. Language skills will enable the applicant to stand out from multiple candidates with similar résumés, if she manages to put forward her knowledge of Japanese, Spanish or Bahasa at the right moment. As for incumbent employees, some see their career development hampered by their weaknesses in international communication.\n- … and start by succeeding in one’s studies\nThe role of languages at school increases as that in life. In Singapore for instance, pupils take one of the two most important exams of their lives at the end of Primary School; half of the subjects are languages –English and their mother tongue. Elsewhere in the world, language level might decide which high school students will attend, impact significantly the matriculation results or give a huge edge in a University application file.\n- Live better, live longer\nLanguage practice shares cerebral mechanisms with those involved in old-age neurological diseases. Thus it has been noted that Alzheimer’s disease sets off on average five years later for bilinguals than for monolinguals. Do your linguistic gym and live better!\n- … and increase your cognitive capabilities\nKnowing several languages is the ability to switch from one to another by focusing on the language used while ‘inhibiting’ the others. Multi-linguals resort to this capability even in non-linguistic fields. They demonstrate a bigger intellectual flexibility, a better ability to deal with ambiguity or apparent contradiction, and can cope with information while ignoring unnecessary or spurious signals.\n- Marvel at other languages\nYou may be amongst those passionate people for whom discovering any new language triggers jubilant amazement. What sounds has this new language produced? What ingenuity will it come up with to convey such or such concept? Will it be isolating, flectional, agglutinative? How will it address, for instance, the possessive, given that some languages will alter the possessor and others the possessed, or both, or neither, some resorting to an affix, others to a particle, and others still elegantly doing without any grammatical appendix? Isn’t it extraordinary that the French version of this post should have 5368 characters in 1006 words, the English one 4978 characters in 980 words, and the Chinese one only 2174 Chinese characters?\n- …and understand better one’s own language\nOne’s mother tongue remains for very long the obvious response, the one found without having to look for it, the only possible option that no one even thinks of challenging. But opening up to a second language puts things in perspective. Without a doubt an additional language enables to further one’s native language knowledge. The language structure that such and such language has adopted becomes more palatable when compared to others: the origin of words is unveiled, roles in the sentence take shape and the meaning of words is refined. If shadow and shade have the same translation in French, does it not prove blatantly that ombre has two distinct meanings? Even the infamous agreement of the French past participle when used with the avoir auxiliary can be better understood if one is introduced to the Hindi ergative.\nAnd what are YOUR reasons?', 'MONDAY, Jan. 30, 2017 (HealthDay News) -- People who speak two or more languages appear to weather the ravages of Alzheimer\'s disease better than people who have only mastered one language, a new Italian study suggests.\nBilingual people with Alzheimer\'s outperformed single-language speakers in short- and long-term memory tasks, even though scans showed more severe deterioration in brain metabolism among the bilingual participants, the scientists said.\nThe ability to speak two languages appears to provide the brain with more resilience to withstand damage from Alzheimer\'s, said lead researcher Dr. Daniela Perani, a professor of psychology at Vita-Salute San Raffaele University in Milan.\nThe more often a person swapped between two languages during their lifetime, the more capable their brains became of switching to alternate pathways that maintained thinking skills even as Alzheimer\'s damage accumulated, the researchers found.\nPrevious studies have shown that lifelong bilingualism can delay the onset of dementia by as much as five years, Perani said. However, no one has yet examined what causes that effect in the brain.\nTo examine this more closely, Perani and her colleagues performed brain scans and memory tests on 85 seniors with Alzheimer\'s. Among the participants, 45 spoke both German and Italian, while 40 only spoke one language.\nThe bilingual people dramatically outscored monolingual speakers on memory tests, scoring three to eight times higher, on average.\nBilingual people achieved these scores even though scans of their brains revealed more signs of cerebral hypometabolism -- a characteristic of Alzheimer\'s in which the brain becomes less efficient at converting glucose into energy.\nThe brain scans also provided a clue why this might be. People who were bilingual appeared to have better functional connectivity in frontal brain regions, which allowed them to maintain better thinking despite their Alzheimer\'s, Perani said.\nConstantly using two languages appears to make the brain work harder. During a lifetime this causes structural changes to the brain, creating a ""neural reserve"" that renders the bilingual brain more resistant against aging, Perani said.\nBilingualism also sets up a person for better ""neural compensation,"" in which the brain copes with its own degeneration and loss of neurons by finding alternative pathways through which to function, she said.\n""Our finding suggests that in bilingual patients with Alzheimer\'s dementia both mechanisms are at play, since neuronal loss is accompanied by compensatory increase of connectivity, allowing bilingual patients to maintain high neuropsychological performance and cognitive functioning longer than monolingual [patients],"" Perani said.\nHeather Snyder, senior director of medical and scientific operations for the Alzheimer\'s Association, said these results make sense given what is known about the aging brain.\n""It\'s that idea of cognitive engagement -- continuing to use it or you lose it,"" Snyder said. ""People who are bilingual and are going back and forth with two different languages throughout their day are activating a specific way of thinking that\'s making those brain connections.""\n""It\'s a small study, so you can\'t draw too many conclusions from it, but it is the kind of research we do want to see more of,"" Snyder added.\nThe study also suggests that kids who learn a second language and use it often will benefit in their old age, Perani said.\n""Considering that delaying the onset of dementia is a top priority of modern societies, governments and health systems should be stimulated to activate social programs and interventions to support bilingual or multilingual education, and to maintain the use of more languages in aging,"" she said.\nUnderstanding these Alzheimer\'s-resistant brain mechanisms could also lead to future therapies where medications and lifestyle changes are combined to protect seniors\' minds, Snyder said.\nThe new study was published Jan. 30 in the Proceedings of the National Academy of Sciences.\nFor more about protecting your brain as you age, visit the Alzheimer\'s Association.']"	['<urn:uuid:5727d743-d793-4990-8f6e-395c19579e27>', '<urn:uuid:26eeeb9e-3550-4028-93e2-47ae2391c35b>']	open-ended	direct	short-search-query	distant-from-document	multi-aspect	expert	2025-05-13T04:02:16.770989	5	135	1608
6	heating professional need how often inspect furnace	A yearly checkup and inspection is highly recommended to prevent the furnace from wearing out quickly, pumping deadly carbon monoxide into living spaces, or shutting down in winter.	"[""Don't wait for the chilly winter nights to set in. Set a date for your furnace’s annual cleaning and upkeep.\nA yearly checkup and inspection is highly recommended to prevent it from wearing out quickly when used for long periods of time, from pumping deadly carbon monoxide into your living spaces without you knowing it, or from completely shutting down in the dead of the winter.\nBefore Cleaning & Upkeep\nBefore you start working on your furnace, remember the following:\n- Make sure the unit is receiving power. If your furnace is not tapped to the main entrance panel, it might be located at a different panel near it.\n- Make sure the switch is turned on. Look for tripped circuit breakers or blown fuses.\n- Make sure the thermostat is properly set. If necessary, raise or lower the setting by 5 degrees.\n- If your furnace has a reset button, let the motor cool for half an hour before pressing it. If it won’t start, wait another half an hour before pressing the reset button again.\n- If your furnace is gas propelled, make sure the gas supply is turned on and the pilot light is lit.\n- If your furnace is oil-based, make sure there is adequate oil supply.\nSafety Factors to Consider\n- Before working on your furnace, make sure all power leading to it is turned off.\n- Remove the fuse or trip the circuit breaker at the main electrical entrance panel.\n- If you’re not sure which circuit your furnace is connected to, trip the main circuit breaker to cut off all power to the house.\n- If the fuse blows when the furnace turns on, there is a problem in the electrical system. Call a professional service person. Do not attempt to fix it yourself.\n- If your furnace is gas-propelled and there is a gassy odor inside the house, report the leak immediately to the fire department or call the gas company for help. Get out of the house right away and do not reenter until help comes.\nHow to Clean\n- Remove the combustion chamber door by unscrewing it, lifting it up and pulling it out.\n- Inspect the burner flames by turning up your thermostat. Yellow flames mean dirty burners. Clean flames are fairly even and bluish in color. If you have dirty burners, make sure you don’t inhale them. Call in a pro to adjust the burners.\n- Vacuum the burners and the furnace base. Use a flashlight to clearly see dust and soot.\n- Clean the blower (or squirrel cage) and its blades using a vacuum and a small brush. If you have a control panel in front of it, unscrew it and let it hand while you do the cleanup. Make sure you don’t disturb the wirings and counterweights.\n- Change the furnace filter on a quarterly basis to provide adequate protection to the blower and blower motor. A cheap fiberglass filter is better than a high-efficiency one which can strain the blower motor and make your furnace less efficient.\n- Clean the pilot by blowing through a drinking straw to the exact spot. A dirty pilot can trigger the flame sensor that the pilot isn’t lit.\n- Remove any residue from the flame sensor by using a fine emery cloth. This will help ensure your furnace will always light up properly.\n- Clean the hot surface igniters by blowing air through a straw. Do not touch it because it breaks very easily.\nWhen it comes to your furnace, regular cleaning and upkeep goes a long way. The entire procedure takes just a few hours and costs a few dollars – a worthy expenditure to avert the hassle of your furnace from simply not putting out enough heat or from stopping without any warning at all.""]"	['<urn:uuid:36a71ea8-e612-4ca0-bcb7-7922ac0d8157>']	factoid	with-premise	short-search-query	distant-from-document	single-doc	expert	2025-05-13T04:02:16.770989	7	28	638
7	ways physical activity prevents cardiac problems	Physical activity helps reduce the risk of heart disease in multiple ways: it helps people reach and maintain a healthy weight, lowers blood pressure, reduces bad cholesterol, and increases good cholesterol.	['Blood Pressure Questions\nWhat is blood pressure?\nLike it sounds, “blood pressure” refers to the pressure of\nthe circulatory system’s blood. Blood pressure directly corresponds\nwith things like a person’s heartbeat and arteries. Blood pressure\nis at its highest level when the heart beats and lowest in the resting\nperiod between beats.\nWhat are some steps to take to lower blood pressure?\nPeople with high blood pressure should consult their doctor before changing\ntheir diet or implementing an exercise routine. Some doctors may also\nrecommend medication that can help lower blood pressure. Simple steps\neveryone can take to lower their blood pressure include eating a healthier,\nlower-sodium diet, exercising, avoiding stressful activities, and limiting\nsmoking and alcohol consumption.\nHow does high blood pressure contribute to heart disease?\nBlood pressure is essential to moving oxygen through the body. When blood\npressure becomes too high, it puts extra pressure on the body’s\nHeart Disease Questions\nWhat is heart disease?\nHeart disease is a term that encompasses a range of different heart-related\nconditions. Usually this is distinguished from cardiovascular conditions\nsuch as congenital heart disease, which is a result of a birth defect.\nWhat causes heart disease?\nA variety of things can cause heart disease. Some of the common factors\ninclude tobacco smoking or secondhand smoke, high-fat diets, high blood\npressure, high blood sugar (common in diabetics), plaque buildup in the\narteries, and more.\nDoes smoking increase risk of heart disease?\nSmoking increases the risk of heart disease because the chemicals found\nin tobacco smoke damage blood cells. This type of damage causes plaque\nto build up in the arteries. When plaque builds in the arteries, the arteries\nbecome smaller and less flexible, putting a serious strain on the flow\nof oxygen. Smoking alone can put an individual at risk for heart disease,\nand is extremely dangerous in conjunction with other risk factors like\nhigh cholesterol and being overweight.\nDoes heart disease run in families?\nIf you know that heart disease or stroke runs in your family, there is\na chance that you may be at a greater risk for developing heart disease\nat some point in your life.\nHeart Attack Questions\nWhat causes heart attack?\nHeart attacks are caused by blocked arteries. Arteries become blocked when\nplaque builds up and strains the flow of blood and oxygen. Other potential\ncauses of heart attack include coronary spasms and heart artery tears.\nWhat are the symptoms of heart attack in men and women?\nThe most common indicator of a heart attack is severe chest pain or pressure\nin that region. Some men also experience pain in various parts of their\nhead like the jaw or teeth. Some men find it difficult to breath during\na heart attack or experience pain in their left arm (sometimes the right arm).\nThe symptoms are similar for women, but often much less severe. Many women\nwho experience heart attack never notice any symptoms. Although men can\nexperience arm, back, neck, and jaw pain during a heart attack, these\nsymptoms are more common on women. Women can also experience abdominal\npressure, nausea, fatigue, and light-headedness.\nWhat can be done to reduce risk of heart attack?\nIf your doctor tells you that you are at a high risk for heart attack,\nthey will likely recommend that you take steps like improving your cholesterol,\nexercising, losing weight at a healthy pace, and managing your stress levels.\nWhat is a stress test?\nMost stress tests involve monitoring a patient’s heart while the\npatient performs rigorous exercise.\nDoes obesity cause heart disease?\nOverweight and obese individuals are certainly at an increased risk of\nheart disease, but it isn’t necessarily the weight that causes heart\ndisease. Usually, overweight people are characterized by a high-cholesterol,\nhigh-fat diet and minimal exercise. It is these factors that can lead\nto heart disease.\nWhat is a “heart healthy” diet?\nHeart healthy foods are things like fruits and vegetables, whole grains,\nfish, chicken, nuts, and foods that are low in sugar - especially refined sugars.\nHow does regular exercise help reduce the risk of heart disease?\nPhysical activity can help people reach and maintain a healthy weight,\nlower blood pressure, reduce bad cholesterol, and increase good cholesterol.\nWhat are some good resources to learn more about heart disease and prevention?\nThe American Heart Association\nis a great resource for finding out more about heart disease and prevention.\nWe also strongly recommend consulting your physician for more tailored\nadvice, recommendations, and treatment regarding your specific health needs.']	['<urn:uuid:1495c49e-6202-4a13-afdd-a9d965f50d18>']	open-ended	with-premise	short-search-query	distant-from-document	single-doc	expert	2025-05-13T04:02:16.770989	6	31	747
8	what difference between military intelligence warnings and cybersecurity warnings collecting information about enemies	Military and digital security intelligence warnings differ in their fundamental approach. Military intelligence uses indications and warnings (I&W) to predict future events and understand enemy intentions, working with imperfect information about their targets' capabilities. In contrast, cybersecurity practitioners use I&W to detect and validate intrusions that have already occurred or are in progress, working with imperfect perception of network traffic. While military I&W becomes irrelevant once an enemy attack is confirmed, cybersecurity I&W remains relevant even after initial indicators of compromise are detected, as additional collection and investigation is often needed to validate potential breaches.	"[""Russian Spies and Strategic Intelligence\nBy George Friedman\nThe United States has captured a group of Russian spies and exchanged them for four individuals held by the Russians on espionage charges. The ways the media have reported on the issue fall into three groups:\n- That the Cold War is back,\n- That, given that the Cold War is over, the point of such outmoded intelligence operations is questionable,\n- And that the Russian spy ring was spending its time aimlessly nosing around in think tanks and open meetings in an archaic and incompetent effort.\nIt is said that the world is global and interdependent. This makes it vital for a given nation to know three things about all of the nations with which it interacts.\nFirst, it needs to know what other nations are capable of doing. Whether militarily, economically or politically, knowing what other nations are capable of narrows down those nations' possible actions, eliminating fantasies and rhetoric from the spectrum of possible moves. Second, the nation needs to know what other nations intend to do. This is important in the short run, especially when intentions and capabilities match up. And third, the nation needs to know what will happen in other nations that those nations' governments didn't anticipate.\nThe more powerful a nation is, the more important it is to understand what it is doing. The United States is the most powerful country in the world. It therefore follows that it is one of the prime focuses of every country in the world. Knowing what the United States will do, and shifting policy based on that, can save countries from difficulties and even disaster. This need is not confined, of course, to the United States. Each country in the world has a list of nations that it is interdependent with, and it keeps an eye on those nations. These can be enemies, friends or just acquaintances. It is impossible for nations not to keep their eyes on other nations, corporations not to keep their eyes on other corporations and individuals not to keep their eyes on other people. How they do so varies; that they do so is a permanent part of the human condition. The shock at learning that the Russians really do want to know what is going on in the United States is, to say the least, overdone.\nRussian Tradecraft Examined\nLet's consider whether the Russian spies were amateurish. During the 1920s and 1930s, the Soviets developed a unique model of espionage. They would certainly recruit government officials or steal documents. What they excelled at, however, was placing undetectable operatives in key positions. Soviet talent scouts would range around left-wing meetings to discover potential recruits. These would be young people with impeccable backgrounds and only limited contact with the left. They would be recruited based on ideology, and less often via money, sex or blackmail. They would never again be in contact with communists or fellow travelers. They would apply for jobs in their countries' intelligence services, foreign or defense ministries, and so on. Given their family and academic backgrounds, they would be hired. They would then be left in place for 20 or 30 years while they rose in the ranks — and, on occasion, aided with bits of information from the Soviet side to move their careers ahead.\nThe Soviets understood that a recruited employee might be a double agent. But stealing information on an ad hoc basis was also risky, as the provenance of such material was always murky. Recruiting people who were not yet agents, creating psychological and material bonds over long years of management and allowing them to mature into senior intelligence or ministry officials allowed ample time for testing loyalty and positioning. The Soviets not only got more reliable information this way but also the ability to influence the other country's decision-making. Recruiting a young man in the 1930s, having him work with the OSS and later the CIA, and having him rise to the top levels of the CIA — had that ever happened — would thus give the Soviets information and control.\nThese operations took decades, and Soviet handlers would spend their entire careers managing one career. There were four phases:\n- Identifying likely candidates,\n- Evaluating and recruiting them,\n- Placing them and managing their rise in the organization,\n- And exploiting them.\nThe longer the third phase took, the more effective the fourth phase would be.\nIt is difficult to know what the Russian team was up to in the United States from news reports, but there are two things we know about the Russians: They are not stupid, and they are extremely patient. If we were to guess — and we are guessing — this was a team of talent scouts. They were not going to meetings at the think tanks because they were interested in listening to the papers; rather, they were searching for recruits. These were people between the ages of 22 and 30, doing internships or entry-level jobs, with family and academic backgrounds that would make employment in classified areas of the U.S. government easy — and who in 20 to 30 years would provide intelligence and control to Moscow.\nIn our view, the media may have conflated two of Moscow's missions.\nTwin Goals and the Espionage Challenge\nOne of the Russian operatives, Don Heathfield, once approached a STRATFOR employee in a series of five meetings. There appeared to be no goal of recruitment; rather, the Russian operative tried to get the STRATFOR employee to try out software he said his company had developed. We suspect that had this been done, our servers would be outputting to Moscow. We did not know at the time who he was. (We have since reported the incident to the FBI, but these folks were everywhere, and we were one among many.)\nThus, the group apparently included a man using software sales as cover — or as we suspect, as a way to intrude on computers. As discussed, the group also included talent scouts. We would guess that Anna Chapman was brought in as part of the recruitment phase of talent scouting. No one at STRATFOR ever had a chance to meet her, having apparently failed the first screening.\nEach of the phases of the operatives' tasks required a tremendous amount of time, patience and, above all, cover. The operatives had to blend in (in this case, they didn't do so well enough). Russians have always had a tremendous advantage over Americans in this regard. A Russian long-term deployment took you to the United States, for example. Were the Americans to try the same thing, they would have to convince people to spend years learning Russian to near-native perfection and then to spend 20-30 years of their lives in Russia. Some would be willing to do so, but not nearly as many as there are Russians prepared to spend that amount of time in the United States or Western Europe.\nThe United States can thus recruit sources (and sometimes it gets genuine ones). It can buy documents. But the extremely patient, long-term deployments are very difficult for it. It doesn't fit with U.S. career patterns or family expectations.\nThe United States has substituted technical intelligence for this process. Thus, the most important U.S. intelligence-collection agency is not the CIA; it is the National Security Agency (NSA). The NSA focuses on intercepting communications, penetrating computer networks, encryption and the like. (We will assume that they are successful at this.) So whereas the Russians seek to control the career of a recruit through retirement, the NSA seeks access to everything that is recorded electronically. The goal here is understanding capabilities and intentions. To the extent that the target is unaware of the NSA's capabilities, the NSA does well. In many ways, this provides better and faster intelligence than the placement of agents, except that this does not provide influence.\nThe Intelligence Assumption\nIn the end, both the U.S. and Russian models — indeed most intelligence models — are built on the core assumption that the more senior the individual, the more knowledge he and his staff have. To put it more starkly, it assumes that what senior (and other) individuals say, write or even think reveals the most important things about the country in question. Thus, controlling a senior government official or listening to his phone conversations or e-mails makes one privy to the actions that country will take — thus allowing one to tell the future.\nLet's consider two cases: Iran in 1979 and the Soviet Union from 1989 to 1991. The fall of the shah of Iran and the collapse of the Soviet empire were events of towering importance for the United States. Assume that the United States knew everything the shah's senior officials and their staffs knew, wrote, or said in the period leading up to the Iranian Revolution. Or assume that the shah's prime minister or a member of the Soviet Union's Politburo was a long-term mole.\nEither of those scenarios would not have made any difference to how events played out. This is because, in the end, the respective senior leadership didn't know how events were going to play out. Partly this is because they were in denial, but mostly this is because they didn't have the facts and they didn't interpret the facts they did have properly. At these critical turning points in history, the most thorough penetration using either American or Russian techniques would have failed to provide warning of the change ahead. This is because the basic premise of the intelligence operation was wrong. The people being spied on and penetrated simply didn't understand their own capabilities — i.e., the reality on the ground in their respective countries — and therefore their intentions about what to do were irrelevant and actually misleading.\nIn saying this, we must be very cautious, since obviously there are many instances in which targets of intelligence agencies do have valuable information and their decisions do actually represent what will happen. But if we regard anticipating systemic changes as one of the most important categories of intelligence, then these are cases where the targets of intelligence may well know the least and know it last. The Japanese knew they were going to hit Pearl Harbor, and having intelligence on that fact was enormously important. But that the British would collapse at Singapore was a fact not known to the British, so there would have been no way to obtain that information in advance from the British.\nWe started with three classes of intelligence: capabilities, intentions and what will actually happen. The first is an objective measure that can sometimes be seen directly but more frequently is obtained through data held by someone in the target country. The most important issue is not what this data says but how accurate it is. Intentions, by contrast, represent the subjective plans of decision-makers. History is filled with intentions that were never implemented, or that, when implemented, had wildly different outcomes than the decision-maker expected. From our point of view, the most important aspect of this category is the potential for unintended consequences. For example, George W. Bush did not intend to get bogged down in a guerrilla war in Iraq. What he intended and what happened were two different things because his view of American and Iraqi capabilities were not tied to reality.\nAmerican and Russian intelligence is source-based. There is value in sources, but they need to be taken with many grains of salt, not because they necessarily lie but because the highest-placed source may simply be wrong — and at times, an entire government can be wrong. If the purpose of intelligence is to predict what will happen, and it is source-based, then that assumes that the sources know what is going on and how it will play out. But often they don't.\nRussian and American intelligence agencies are both source-obsessed. On the surface, this is reasonable and essential. But it assumes something about sources that is frequently true, but not always — and in fact is true only with great infrequency on the most important issues. From our point of view, the purpose of intelligence is obvious: It is to collect as much information as possible, and surely from the most highly placed sources. But in the end, the most important question to ask is whether the most highly placed source has any clue as to what is going to happen.\nKnowledge of what is being thought is essential. But gaming out how the objective and impersonal forces will interact and play out it is the most important thing of all. The focus on sources allows the universe of intelligence to be populated by the thoughts of the target. Sometimes that is of enormous value. But sometimes the most highly placed source has no idea what is about to happen. Sometimes it is necessary to listen to the tape of Gorbachev or Bush planning the future and recognize that what they think will happen and what is about to happen are very different things.\nThe events of the past few weeks show intelligence doing the necessary work of recruiting and rescuing agents. The measure of all of this activity is not whether one has penetrated the other side, but in the end, whether your intelligence organization knew what was going to happen and told you regardless of what well-placed sources believed. Sometimes sources are indispensable. Sometimes they are misleading. And sometimes they are the way an intelligence organization justifies being wrong."", 'What Is Network Security Monitoring?\nNow that we\'ve forged a common understanding of security and risk and examined principles held by those tasked with identifying and responding to intrusions, we can fully explore the concept of NSM. In Chapter 1, we defined NSM as the collection, analysis, and escalation of indications and warnings to detect and respond to intrusions. Examining the components of the definition, which we do in the following sections, will establish the course this book will follow.\nIndications and Warnings\nIt makes sense to understand what we plan to collect, analyze, and escalate before explaining the specific meanings of those three terms in the NSM definition. Therefore, we first investigate the terms indications and warnings. Appreciation of these ideas helps put the entire concept of NSM in perspective.\nThe U.S. Department of Defense Dictionary of Military Terms defines an indicator as ""an item of information which reflects the intention or capability of a potential enemy to adopt or reject a course of action.""  I prefer the definition in a U.S. Army intelligence training document titled ""Indicators in Operations Other Than War.""  The Army manual describes an indicator as ""observable or discernible actions that confirm or deny enemy capabilities and intentions."" The document then defines indications and warning (I&W) as ""the strategic monitoring of world military, economic and political events to ensure that they are not the precursor to hostile or other activities which are contrary to U.S. interests.""\nI&W is a process of strategic monitoring that analyzes indicators and produces warnings.  We could easily leave the definition of indicator as stated by the Army manual and define digital I&W as the strategic monitoring of network traffic to assist in the detection and validation of intrusions.\nObserve that the I&W process is focused against threats. It is not concerned with vulnerabilities, although the capability of a party to harm an asset is tied to weaknesses in an asset. Therefore, NSM, and IDS products, focus on threats. In contrast, vulnerability assessment products are concerned with vulnerabilities. While some authors consider vulnerability assessment ""a special case of intrusion detection,""  logic shows vulnerabilities have nothing to do with threats. Some vulnerability-oriented products and security information management suites incorporate ""threat correlation"" modules that simply apply known vulnerabilities to assets. There are plenty of references to threats but no mention of parties with capabilities and intentions to exploit those vulnerabilities.\nBuilding on the Army intelligence manual, we define indications (or indicators) as observable or discernible actions that confirm or deny enemy capabilities and intentions. In the world of NSM, indicators are outputs from products. They are the conclusions formed by the product, as programmed by its developer. Indicators generated by IDSs are typically called alerts.\nThe Holy Grail for IDS vendors is 100% accurate intrusion detection. In other words, every alert corresponds to an actual intrusion by a malicious party. Unfortunately, this will never happen. IDS products lack context. Context is the ability to understand the nature of an event with respect to all other aspects of an organization\'s environment. As a simple example, imagine a no-notice penetration test performed by a consulting firm against a client. If the assessment company successfully compromises a server, an IDS might report the event as an intrusion. For all intents and purposes, it is an intrusion. However, from the perspective of the manager who hired the consulting firm, the event is not an intrusion.\nConsider a second example. The IDS could be configured to detect the use of the PsExec tool and report it as a ""hacking incident.""  PsExec allows remote command execution on Windows systems, provided the user has appropriate credentials and access. The use of such a tool by an unauthorized party could indicate an attack. Simultaneously, authorized system administrators could use PsExec to gain remote access to their servers. The granularity of policy required to differentiate between illegitimate and legitimate use of such a tool is beyond the capabilities of most institutions and probably not worth the effort! As a result, humans must make the call.\nAll indicators have value, but some have greater value. An alert stating a mail server has initiated an outbound FTP session to a host in Russia is an indicator. A spike in the amount of Internet Control Message Protocol (ICMP) traffic at 2 A.M. is another indicator. Generally speaking, the first indicator has more value than the second, unless the organization has never used ICMP before.\nWarnings are the results of an analyst\'s interpretation of indicators. Warnings represent human judgments. Analysts scrutinize the indicators generated by their products and forward warnings to decision makers. If indicators are similar to information, warnings are analogous to finished intelligence. Evidence of reconnaissance, exploitation, reinforcement, consolidation, and pillage are indicators. A report to management that states ""Our mail server is probably compromised"" is a warning.\nIt\'s important to understand that the I&W process focuses on threats and actions that precede compromise, or in the case of military action, conflict. As a young officer assigned to the Air Intelligence Agency, I attended an I&W course presented by the Defense Intelligence Agency (DIA). The DIA staff taught us how to conduct threat assessment by reviewing indicators, such as troop movements, signals intelligence (SIGINT) transcripts, and human intelligence (HUMINT) reports. One of my fellow students asked how to create a formal warning report once the enemy attacks a U.S. interest. The instructor laughed and replied that at that point, I&W goes out the window. Once you\'ve validated enemy action, there\'s no need to assess the intentions or capabilities.\nSimilarly, the concept of I&W within NSM revolves around warnings. It\'s rare these days, in a world of encryption and high-speed networks, to be 100% sure that observed indicators reflect a true compromise. It\'s more likely the analysts will collect clues that can be understood only after additional collection is performed against a potential victim. Additional collection could be network-based, such as recording all traffic to and from a possible compromised machine. Alternatively, investigators could follow a host-based approach by performing a live forensic response on a suspect victim server. \nThis contrast between the military and digital security I&W models is important. The military and intelligence agencies use I&W to divine future events. They form conclusions based on I&W because they have imperfect information on the capabilities and intentions of their targets. NSM practitioners use I&W to detect and validate intrusions. They form conclusions based on digital I&W because they have imperfect perception of the traffic passing through their networks. Both communities make educated assessments because perfect knowledge of their target domain is nearly impossible.']"	['<urn:uuid:024058de-9c4e-46f2-bbcf-2c7bddff63ba>', '<urn:uuid:00c9e430-90fe-4153-b2e6-0ed193d44e99>']	open-ended	direct	long-search-query	distant-from-document	comparison	novice	2025-05-13T04:02:16.770989	13	95	3366
9	how often should clean repair seal asphalt driveway protect it	To keep your driveway in good shape, it's important to clean, repair, and seal it every few years.	"['How to Repair Asphalt Driveway Cracks | HowStuffWorks\nThe most frequent cause of cracks in your asphalt driveway is water that has seeped below the surface and expanded or contracted with freezing and thawing temperatures. After patching and filling any cracks or dips in your asphalt driveway, you may also wish to seal .\nDo It! How to Repair and Seal an Asphalt Driveway | Today .\nAsphalt driveways can develop cracks and deteriorate over time. To keep your driveway in good shape, it\'s important to clean, repair, and seal it every few years. It\'s best to work on an asphalt driveway during warm weather so the repair material and sealer will set faster. Be sure to fill all .\nAsphalt Maintenance and Repair - Asphalt Preservation\nAsphalt maintenance and repair is essential to the life of existing asphalt. Asphalt sealing, such as slurry seal, seal coat, and crack seal, provide a protective coating for asphalt-based pavements which protect it from breaking down from water, oils, U.V. damage, and normal wear and tear.\nAsphalt Seal Your Own Driveway! - YouTube\nAug 26, 2016 · This is a simple step by step instructional video to help guide you through the steps of sealing your driveway. CHECK OUT OUR LATEST VIDEOS 🎥Cleaning Large.\nAsphalt Sealcoating Equipment and Asphalt Sealing .\nAt Asphalt Sealcoating Direct, you will find an assortment of high quality, budget priced Asphalt Sealcoating Equipment for sale including Heat Lances, 10 Gallon Melter / Applicators, Asphalt Sealcoating Spray Equipment for sale and asphalt crack filler, along with many other asphalt sealing equipment products we offer for sale.\nAsphalt Crack Repair Treatments: Crack Sealing Vs. Crack .\nSealing Asphalt Cracks Crack sealing is a localized treatment that prevents water and other debris from getting inside of asphalt abrasions and causing further damage to roadways. In order to properly seal a crack, all debris must be blown out and cleaned away.\nAsphalt Crack Filling and Sealing - Local Sealcoating\nCrack Sealing is an Integral Component of an Effective Pavement Preservation Program. A scheduled program of pavement maintenance that includes sealcoating and crack filling will more than double the life cycle of your asphalt pavement and provide maximum curb appeal.\nUtah Crack Sealing Services | Extend the Life of Your Asphalt\nMore cracks will form allowing more water to enter the base. Without maintenance, this cycle will destroy your asphalt. Crack seal seals cracks from water. Crack seal is made of rubberzed asphalt which expands and contracts with the crack. Crack sealing is one of the most important things you can do to extend the life of your asphalt.\nProperly sealing asphalt cracks as they appear can more\nProperly sealing asphalt cracks as they appear can more than double the effective service life of the pavement. Pavement is a costly investment. Just as you would seal leaks in the roof of your building, you should seal cracks in your pavement. Water infiltration through cracks causes deterioration of the pavement and substructure.\nCrack Sealing - Fix Asphalt\nApplication of a hot rubberized asphalt crack sealer will prevent water penetration into the sub-base thereby prolonging the life of your pavement and elimination of potential liabilities. Hot rubberized crack sealing, if installed properly, is the foundation of a successful maintenance program for any type of .\nSeal Coating - Extraordinaire Asphalt & Grounds .\nExtraordinaire is a new asphalt and grounds maintenance company located in Baltimore Maryland, but with years of experience behind us. We specialize in asphalt seal coating, asphalt crack sealing, line striping, pot hole repair, and crack sealing, among other services in Baltimore.\nShould You Seal Or Fill Asphalt Cracks . - Kleenco .\nSealing or filling asphalt cracks is directly dependent upon the extent of asphalt cracks measured in width. Generally, asphalt sealant is used for cracks that measure less than ¾ of an inch in width and crack filling is used for cracks that measure wider than ¾ of an inch.\nThe Basics of Crack Filling / Crack Sealing | Paveman Pro\nThe Basics of Crack Filling by Greg Walters, Sealmaster It\'s no secret that cracks in asphalt surfaces allow water to penetrate the surface, softening the stone base and leading to alligator cracking/spider webbing, pot holes and other forms of degradation.\nConcrete Crack Filler, Best Asphalt Crack Sealant for .\nKOLD-FLO ® Pourable Crack Filler is a modified asphalt emulsion concrete and asphalt crack filler & sealer that is ideal for asphalt crack repairs in roads, pavements, driveways, concrete foundations, parking lots and other asphalt or concrete surfaces. It is a cost-effective and fast-curing asphalt concrete crack repair solution for filling and sealing cracks from weather\'s destructive .\nAsphalt Sealcoating Contractor - Crack Repair | Portland OR\nAsphalt Crack Repair. Cracks usually form from expansion and contractions in the ground. Paying close attention to these cracks is always a good idea; this is because the sooner you seal or fill these cracks, the less likely they will continue to grow.\nAsphalt Patching and Crack Repair | The Family Handyman\nFix driveway cracks. In cold climates, water seeps in and destroys the asphalt when it expands during freezing. If you plan to topcoat your driveway, you\'ll need to fix the cracks first and do asphalt repair later. You can buy squeeze bottle and caulk tube–style crack filler products from any home center.\nCrack Sealing | Asphalt Repair Solutions\nAsphalt cracks are normal and occur over time. Your maintenance program should include professionally sealing cracks that are 1/8"" wide or greater with a proper crack sealant, to mitigate damage to your asphalt caused by water intrusion.\nHow to Seal an Asphalt or Concrete Driveway | Apply .\nHomeAdvisor\'s Driveway Sealing Guide instructs on how to use asphalt blacktop or concrete sealer to sealcoat, reseal, tar, or repair cracks. Discover the best process for DIY driveway sealing, or how to clean and prepare your pavement when working with a professional. Questions anwered including whether it needs to be done for new driveways, and what supplies and materials are needed.\nRepair Asphalt Driveway Cracks - Lowe\'s Home Improvement\nThe forces of nature do their best to break down asphalt, creating cracks and potholes. Repairing driveway cracks is a lot simpler than you may think. Cracks up to 3/4 of an inch wide can be repaired with a pourable or tubed asphalt patch product. A tubed product requires a caulk gun for application .\nThe Difference between Crack Filling and Crack Sealing .\nWhile the terms crack filling and crack sealing are often used interchangeably, there are differences between these methods of pavement crack repair. Understanding these differences will help you make the most cost-effective choice and long-lasting solution for crack treatment of your asphalt surfaces. Crack sealing\nAsphalt Crack Sealing Near Me | Randazzo Paving | New Hope PA\nSealing cracks prevents water and moisture penetration below your asphalt and eliminates the most common cause of premature asphalt pavement failure and deterioration. We use a hot applied crack and joint sealant that is engineered to stay flexible in hot and cold temperature extremes to ensure the crack stays sealed. Please note- Crack sealing .\nHow To Fill Cracks In Asphalt Using Asphalt Crack Filler .\nHow to Fill Asphalt Cracks In Driveways and Parking Lots. . Sealcoating is not designed to be an asphalt crack filler, it is made for sealing the surface and protecting it from the elements such as UV light, salts and oils. It is not flexible enough to fill a crack without re-cracking and it does not have adhesion quality\'s that Asphalt Crack .\nCrack Sealing Company Pavement Crack Filling Crack Repair\nCrack Filling & Sealing Overview. Pavement cracks need to be filled and/or sealed to prevent water from entering sub-grade layers. Special rubberized materials are applied to the cracks, which seals the pavement and helps to prolong its life.\nHow Much Does it Cost to Seal an Asphalt Driveway? | Angie .\nHow Much Does it Cost to Seal an Asphalt Driveway? . Sealing the cracks and the pavement properly is absolutely essential to prevent the damage from occurring. While a poor sealant job has no affect and only looks good, a good sealant job can add years to your driveway in .\nAsphalt Crack Repair - asphaltkingdom\nPreparing for Crack Filling Asphalt This is the most time-consuming and most important part of the job, but it\'s also easy for any DIY\'er. To get the longest-lasting repair, the crack seal needs a clean and solid area to stick to. Any debris or weeds that are left in the crack will degrade your crack repair job.\n7 Different Types of Pavement Failure | Types of Cracks in .\nCracks need to be repaired right away or else they can expand and become costlier in the long run. Perhaps the hardest part of repairing cracks in your pavement is identifying the exact cause and type of crack in your asphalt pavement. 7 Types of Cracks in Asphalt Pavement\nCrack Sealing | A-Line Asphalt Maintenance, Inc.\nCrack sealing is the process of pouring a hot rubberized tar into isolated cracks in the asphalt pavement to prevent water from penetrating the asphalt base. Benefits of Crack Sealing Protects the Base – Effective crack sealing keeps water from entering and weakening the base of the asphalt.\nDifference Between Crack Filling and Crack Sealing .\nCrack sealing is an important procedure that must be addressed yearly. Crack sealing is one of the most cost-effective ways to prolong the pavement life, as much as 3- 8 years. The terms crack filling and crack sealing are often confused as being one and the same. Not true, they are different.\nProfessional Tips for your Next Asphalt Crack Sealing Project.\nCrack sealing is one of the most cost effective methods for repairing damaged pavement before it progresses too extensively. Depending upon the climate conditions, traffic volume and load, type of sealant used, and the application method – asphalt crack sealing can extend the life of damaged pavement by between six months and four years.']"	['<urn:uuid:2b894d97-6371-468e-8e52-b8fe6e167898>']	factoid	with-premise	long-search-query	similar-to-document	single-doc	novice	2025-05-13T04:02:16.770989	10	18	1675
10	dentist curious what zirconia ceramic characteristics safety clinical studies nanomaterials	While zirconium oxide is biocompatible, doesn't cause allergic reactions, and has excellent aesthetic and functional characteristics in dental prosthetics, the safety of new dental nanomaterials still requires more clinical studies. Many toxicity studies have been limited to in vitro testing, and more research is needed to understand their long-term effects in the oral cavity, considering factors like pH, saliva buffer capacity, mucosal contact, and dental tissue spreading.	"['Prosthetics is a branch of dentistry that deals with designing and making prostheses while respecting functionality and aesthetics. Of great importance is a quality dental laboratory, which works closely with the dentist.\nFixed prosthetic works are permanently cemented works that the patient can not remove and replace lost or functionally and/or aesthetically inadequate teeth. The most common works are crowns and bridges, veneers and inlays, onlays, overlays.\nThe metal-ceramics crowns and bridges, where metal bases are completely covered with ceramics, are the most commonly used dental work and satisfy both functionality and aesthetics.\nMetal-free ceramics is produced, just as the name suggests, without a metal base, giving you greater ability to obtain a natural tooth appearance and extremely high aesthetics. Today, modern aesthetic dentistry can not be imagined without metal-free ceramics.\nZirconium oxide is a relatively newer material that, due to its excellent aesthetic and functional characteristics, becomes increasingly common choice material.\nCeramic oxide ceramics\nZircon is a relatively new material in dental medicine and is certainly the greatest discovery of ceramic metal crowns. As a material, Zircon is biocompatible and doesn’t cause an allergic reaction to the surrounding tissue, it is a weak heat and electricity promoter, therefore, the tooth sensitivity is reduced to a minimum. It is an unfavorable base for plaque accumulation, which greatly facilitates the oral hygiene and slows the recession of the gingiva.\nAlong with all the above-mentioned advantages, zircon is a sufficiently solid material to withstand the molar forces of the lateral region without fracturing. Its aesthetic characteristics are exceptional and give the technician the ability to create a crown that is difficult to distinguish from the natural tooth.\nMetal-free ceramic (Press)\nIt is used exclusively in the frontal region to achieve high aesthetics of the crown or for a minimally invasive veneer technique. Since there is no basis that gives firmness and resilience, it is not suitable for lateral regions due to strong chewing forces.\nWith the development of dental medicine and dental materials, a complete corrugated crown is eliminated from the use and a metal ceramic crown is introduced. It consists of a metal base (cobalt – chrome – molybdenum, nickel – titanium, gold) upon which ceramic is applied under special laboratory conditions. In this way, the crown takes the appearance of the tooth and satisfies the aesthetic conditions. The strength of metal bases and aesthetics of ceramics allow the use of metal ceramic crowns and bridges in the lateral and frontal regions.\nWhen fixed prosthetic replacement can not be performed, the situation can be solved by means of a mobile or combined prosthetic replacement. The prostheses are made as mobile dental supplements that can and should be removed from the mouth for proper oral hygiene maintenance.\nMobile prostheses can be complete (total) or partial (partial). Total dentures are made exclusively of acrylates, while partial ones can be made of acrylate (without metal base) or iron (with metal base).\nCombined work is partially fixed in the mouth, while the wironit prosthesis is a mobile part and it is necessary to remove it from oral hygiene. This combination of fixed and mobile prosthetics is a solid solution when the situation can not be resolved by implantology.\nAditional notes: How to avoid alergic reactions\nThe continuous increase in the number of chemicals, food additives, and air pollution is a burden for people. Increased use of wireless communications (using mobile phones) creates more powerful high-frequency fields that pose a threat to vulnerable people. So more and more people are looking for compatible and unethical dentures for their personal dental restoration.\nThe high number of medical materials used in the manufacture of dental prostheses often cause allergy in sensitive persons.\nMaterials used by Thermopress 400 by injection of plastic resin allow dental technicians to produce prostheses for sensitive persons without the use of chemicals, additives, and catalysts. In this way, dental laboratories are given an option that places them in a very strong position in solving allergies in sensitive subjects.', 'New nanomaterials for dental treatments boast impressive antibacterial, decay-resistant and biomimetic properties. In combination with stem cells, they are even capable of regenerating dental tissues. A researcher at CEU Cardenal Herrera University in Valencia collaborates on a compendium of the latest nanomaterials for use in fillers, mouthwashes, medicines and other treatments to improve oral and dental health.\nIn the past decade, some 151 patents for applications of nanotechnology within dentistry have been filed, indicative of the level of development of research in this field. Specifically, advances are being made in the diagnosis, prevention and treatment of oral and dental diseases through the use of potent nanomaterials that bring resistance, antibacterial and other biomimetic properties to oral care. In combination with stem cells, some are even capable of regenerating dental tissues.\nSalvatore Sauro, professor of Dentistry at the Universidad CEU Cardenal Herrera (CEU Cardenal Herrera University, CEU) in Valencia, has collaborated with experts from the College of Dental Medicine at Georgia Regents University in Augusta, US, and the Brazilian Universidade Federal do Ceará and Universidade Estadual de Campinas, on an exhaustive study of these nanomaterials and their clinical applications within ""nanodentistry."" A detailed overview was published in Trends in Biotechnology, analyzing the cutting-edge properties of polymeric, metallic and inorganic nano-based materials and their potential use in therapeutic and restorative dental care.\nBiomimetic, decay-resistant and regenerative\nAs Sauro underlines, ""one of the most promising features of these nanomaterials is their capacity to imitate the natural physicochemical, mechanic and aesthetic properties of dentine and dental enamel."" This is what is meant by biomimetic: human-made materials that imitate nature and natural processes. ""For instance, nanoceramic materials have yielded good results in dental restoration, imitating the aesthetic properties of dental enamel.""\nSome dental resins and composites used today to treat tooth loss have already been given the ""nano treatment,"" incorporating ceramic or silica-rich nanoparticles which, aside from imitating the natural aesthetics of teeth, they are stronger, harder and more resistant to decay. Stronger still are new nanomaterials based on sapphires and diamonds, which have proven twenty times as strong as their ceramic-based counterparts. ""The field of dental materials is one that will feel the benefit of advances in nanotechnology on the short-term,"" adds Sauro, meaning the door is wide open to restorative dental materials that are even more natural-looking, long-lasting and easier to work with in the clinic setting.\nAnother area of development is that of remineralising and regenerating dental tissue, whose natural capacity for regeneration in adults is very limited. Nanomaterials are being used in conjunction with stem cells to regenerate dentin, dental cement and even enamel, the tissue least able to regenerate naturally. Incorporated into composites and injectable biomaterials, this is a promising approach to dental tissue repair which harnesses biological responses. However, Sauro warns that further testing is required to ascertain the toxicity of these materials, which may also affect the healthy cells in the treated tissue.\nIn fact, given the rapid development of these new dental nanomaterials, it is still necessary to evaluate their effects on the oral cavity in general, taking into account factors like pH, buffer capacity of saliva, contact with the mucosa, and spreading of the dental tissues. ""Many of the existing studies into the toxicity of these materials have been restricted to in vitro testing. More clinical studies are necessary to understand their effects on the long term.""\nCite This Page:']"	['<urn:uuid:6ea214b6-e350-4bef-b48b-02fc5710a915>', '<urn:uuid:3397c81d-de7f-4de1-afc7-e9c81a006866>']	factoid	with-premise	long-search-query	distant-from-document	multi-aspect	expert	2025-05-13T04:02:16.770989	10	67	1228
11	What happens when they check if someone has leukemia?	To diagnose chronic myeloid leukemia, doctors perform several tests including sternum puncture, bone marrow morphological evaluation, and cytogenetic investigation. They also check blood cell counts and may conduct ultrasound investigation to measure spleen size. Additionally, they perform molecular genetic assays and analyze chromosomes through various specialized techniques.	['Chronic myeloid leukemia in patient with the Klinefelter syndrome\nSummary. Aim: Genetic inborn along with acquired diseases arise due to the lesions in genome of multipotent hematopoietic stem cells. The aim was to study an influence of constitutional anomaly, Klinefelter syndrome, and additional structural rearrangements on the BCR-ABL tyrosine kinase inhibitor targeted therapy efficacy. Material and Methods: We describe a 32-year-old male patient with chronic myeloid leukemia (CML) who was detected to have sex chromosomal abnormality during evaluation for Philadelphia chromosome. Results: At diagnosis of CML, two clones were detected by standard cytogenetic investigation of bone marrow cells: 1) clone with translocation t(9;22)(q34;q11), with two sex X chromosomes and absence sex chromosome Y; 2) clone with t(9;22) and unbalanced t(Y;20)(q11;q13). Analysis of blast transformed lymphocytes from peripheral blood showed karyotype 47,XXY. Monitoring of targeted therapy with second generation inhibitor of BCR-ABL tyrosine kinase indicated a cytogenetic remission and absence of BCR-ABL1 fusion signals after 11 months. Conclusions: Absence of translocation t(9;22)(q34;q11) in blast transformed T-lymphocytes at diagnosis of CML evidences that this translocation may appear not only at the level of multipotent haemopoietic cell progenitors but also may have oligo lineage myeloid origin. Presence of additional structural chromosomal abnormality in the clone with t(9;22)(q34;q11) does not affect the efficacy of therapy with the use of second generation BCR-ABL tyrosine kinase inhibitor.\nSubmitted: July 14, 2016.\n*Correspondence: Fax: +38 (044) 4402722\nAbbreviations used: BM — bone marrow; CML — chronic myeloid leukemia; KS — Klinefelter syndrome; PB — peripheral blood; PHA — phytohemagglutinin.\nChronic myeloid leukemia (CML) is an acquired disease that arises due to the lesions in genome of multipotent hematopoietic stem cell, and makes up approximately 14% of all types of leukemias. CML is a disease of middle age with manifestation peak in 40–50 years old. The cause of the disease is not currently established, but in the history of some patients the chemotherapy and radiation have been registered [1, 2]. CML cytogenetic feature is the translocation t(9;22)(q34;q11) with the breakpoints in chromosome 9 in the band q34 (ABL gene) and chromosome 22 in the band q11 (BCR gene). The latter was designated the Philadelphia chromosome (Ph՛-chromosome) . As a result of this translocation, two chimeric genes are formed: ABL1-BCR on chromosome 9 and BCR-ABL1 on chromosome 22. Considering that the anomaly occurs at an early precursor of hematopoietic and lymphoid tissues, it is believed that this rearrangement might be registered in all bone marrow (BM) cells, including the peripheral blood (PB) T-lymphocytes stimulated by phytohemagglutinin (PHA) . Other authors indicate lack of translocation t(9;22)(q34;q11) in T-lymphocytes .\nThe use of inhibitors of BCR-ABL tyrosine kinase allows achieving both the clinical and hematologic, and also long-term cytogenetic and molecular genetic remission. This also concerns to the cases of variant translocations t(9;22) and additional abnormalities in the clone with t(9;22) in BM cells at diagnosis of CML [2, 6].\nTo confirm the genetic remission following the therapy with inhibitors of BCR-ABL tyrosine kinase, cytogenetic and molecular genetic control is always required. Achievement of the cytogenetic remission in 3 months of treatment with first generation BCR-ABL tyrosine kinase inhibitors as well as molecular genetic remission (one abnormal cell in 105 of BM cells) during the twelve months therapy, are considered as the gold standard of effective CML therapy .\nKlinefelter syndrome (KS) is the most abundant anomaly of sex chromosomes in men occuring in 1:500 cases . The classic form of KS is described as 47,XXY. However, sometimes the increase in sex chromosome X number up to four copies and sex chromosome Y up to two copies, or mosaic form 47,XXY/46,XY appearance are reported . The cases of CML registered in patients with KS are quite rare [10–14]. Among these cases, two patients are described in whom the effectiveness of BCR-ABL tyrosine kinase inhibitors-based therapy was assessed. In one of these cases, the patient remained in complete hematological and major molecular remission after 2 years of the therapy with first generation tyrosine kinase inhibitor , while in the other case no response to the same inhibitor was achieved and persistent molecular genetic alterations were documented during the therapy with the II generation inhibitor .\nWe, therefore, aimed to study an influence of the constitutional anomaly, KS, and additional structural rearrangements on the BCR-ABL tyrosine kinase inhibitor targeted therapy efficacy.\nMATERIALS AND METHODS\nThe patient D., 32-year-old male, was referred to hematologist for the first time in October 2013 complaining of the expressed weakness, skin pallor and weight loss during the year (height 175 cm, weight 104 kg). The patient gave written informed consent for the publication of his data analyses. Primary observation showed that the patient had narrow shoulders and wide hip. The PB contained 126.5•109/l leukocytes and 39.0 g/l hemoglobin. Spleen size measured by ultrasound investigation of peritoneum was 60×120 mm. To diagnose the patient, the sternum puncture has been done along with the BM morphological evaluation and further cytogenetic investigation for confirmation of the probable CML diagnosis. BM and PB cell counts are presented in the Table.\nTable. BM and PB cells indexes\nFor cytogenetic study of BM cells, the slides of metaphase chromosomes were prepared according to the conventional method followed by GTG staining. Considering that besides classic translocation t(9;22)(q34;q11) typical for CML, mosaics of sex chromosomes was detected in patient, both the molecular genetic assay (FISH) on BM cells and karyotyping of PB blast transformed cells were performed. To define the nature of additional sex chromosome X, the conventional cytogenetics of blast transformed lymphocytes was carried out after 72 h cultivation of PB and addition of PHA in the medium. Slides were stained by GTG-method. Presence of clonal chromosomal abnormalities was described according to ISCN 2013, when two or more metaphase plates had identical structural or additional (trisomy) chromosome abnormalities and also in appearance of three or more metaphase plates with identical chromosomes monosomies . The presence of translocation t(9;22)(q34;q11) during the targeted therapy was revealed by conventional cytogenetics and after fluorescence staining per se (on slide) in interphase nuclei (i-FISH). i-FISH assay was carried out on interphase cell nuclei after 24 h cultivation. The probe set Vysis LSI BCR/ABL Dual Color, Dual Fusion Translocation Probe (Abbott, USA) was used.\nRESULTS AND DISCUSSION\nStandard cytogenetic study on BM suspension cells revealed mosaic karyotype consisting of three clones: 46,XX,-Y,t(9;22)(q34;q11) / 46,XX,t(Y;20)(q11;q13),t(9;22)(q34;q11),-der(Y)t(Y;20)(q11;q13)/4n± . The first clone with two sex X chromosomes, absence of sex Y chromosome and translocation t(9;22)(q34;q11) was detected in 15 metaphase plates (Fig. 1). The second clone with two sex X chromosomes, unbalanced structural rearrangement, namely translocation between chromosomes Y and 20 and loss of derivative chromosome due to translocation between chromosomes Y and 20 was detected in three metaphase plates (Fig. 2), and the third clone (near tetraploid) was detected in two metaphase plates. The results allowed us to suspect that the patient might have innate genetic disease, the KS. Moreover, it is known that during formation of abnormal karyotypes the losses of sex chromosomes could occur. Therefore, cytogenetic study on blast transformed PB lymphocytes was carried out to confirm the constitutional nature of additional sex chromosome X. The study showed karyotype 47,XXY in 20 analyzed metaphase plates (Fig. 3). That was confirmed by cytogenetics as KS. The results suggest the involvement of sex chromosome Y in the formation of two abnormal clones with translocation t(9;22). In the first clone with a translocation t(9;22), a loss of sex chromosome Y was observed; in the second clone with a translocation t(9;22), the unbalanced translocation was registered involving sex chromosome Y and chromosome 20 with the loss of derivative chromosome Y, which was formed as a result of this translocation. The episode of the formation of different clones in BM cells karyotype at CML diagnosis in patient with the KS is reported for the first time. The absence of t(9;22) in PHA blast transformed PB T-lymphocytes at diagnosis of CML has questioned the previous statement that this translocation can be detected in lymphocytes. Perhaps in some cases the translocation could occur not only at the level of multipotent hematopoietic progenitor cell but also may have oligo lineage myeloid origin.\nFig. 1. Cytogenetic analysis of BM cells shows a clone with two sex chromosomes X and balanced translocation t(9;22)(q34;q11)\nFig. 2. Cytogenetic analysis of BM cells shows a clone with one sex chromosome X, balanced translocation t(9;22)(q34;q11) and unbalanced translocation t(Y;20)(q11;q13)\nSince November 2013, the patient was scheduled to hydroxyurea chemotherapy at a dose of 4000 mg/day; there was a reduction in the leucocyte count to normal value while anemia remained.\nFig. 3. Conventional cytogenetics shows karyotype 47,XXY in blast transformed T-lymphocytes of PB\nSince December 2014, the therapy with the II generation inhibitor of BCR-ABL tyrosine kinase at a dose of 600 mg/day has been prescribed, which is still continued. As a result of the treatment, the patient recovered to normal PB and myelogram parameters, spleen size reduced to 100/60 mm on ultrasound examination, and significant increase in weight (125 kg) was observed. Cytogenetic and molecular cytogenetic monitoring of the therapy effectiveness was conducted in 11 months. Analysis of metaphase chromosomes in BM cells has revealed the karyotype containing additional sex chromosome X: 47,XXY (in 20 metaphase plates). Simultaneously, iFISH assay was carried out on 200 interphase BM nuclei, and registered an absence of fusion signals of BCR-ABL1 and ABL1-BCR formed due to t(9;22) (Fig. 4).\nFig. 4. Molecular cytogenetic study shows normal distribution of BCR and ABL1 signals\nThus, in patient with CML in the presence of constitutional chromosomal abnormality, KS, two independent clones were recorded in BM cells at diagnosis: translocation t(9;22) in clone with two sex chromosomes X and without sex chromosome Y, and translocation t(9;22) and unbalanced structural rearrangement involving sex chromosome Y. The molecular cytogenetic remission was achieved following 11 months of the treatment with second generation inhibitor of BCR-ABL tyrosine kinase. Absence of translocation t(9;22)(q34;q11) in blast transformed T-lymphocytes may indicate that not all hematopoietic cells carry this abnormality. The data would be important to assess the effectiveness of targeted therapy for patients with the KS in the presence of additional structural abnormalities in clone with translocation t(9;22).\nWe thank Prof. Danylo Gluzman, RE Kavetsky IEPOR of the NAS of Ukraine, for the confirmation of the diagnosis and disease stage. We are grateful to Dr. Olena Alkhimova for the valuable advice and assistance.\nNo Comments » Add comments']	['<urn:uuid:0f8652d3-9678-4f82-94ae-800f64cdad62>']	open-ended	with-premise	concise-and-natural	distant-from-document	single-doc	novice	2025-05-13T04:02:16.770989	9	47	1727
12	How can China help fight climate change globally?	China can play a key global leadership role by increasing the efficiency of innovative responses to carbon capture, creating low-cost renewable energy, and mainstreaming recovery processes. China's ability to coordinate and rapidly transform societies can be applied to building community resilience and creating sustainable civilizations across China, throughout the Belt and Road, and in the many countries where China is investing.	['By Bertie Ahern\nPresently, the human race is standing at a critical juncture in history, as we risk creating a world that is no longer compatible with human civilization. Evidence is mounting that we need to significantly scale down carbon emissions before climate change reaches the point of no return.\nIf we carry on with our current trajectory, we are projected to reach a three- to four-degree Celsius rise by 2100, and a three- to 10-degree Celsius rise by 2200. To put it plainly, our planet is sick, and we all need to work together to ensure the well-being of future generations.\nThe InterAction Council, an organization of former heads of state and government that promotes global security as part of its mandate, recently launched the “Manifesto to Secure a Healthy Planet for All – A Call for Emergency Action.” This initiative builds upon collaborative action to advance the Dublin Charter for One Health, a product of the InterAction Council’s plenary session in 2017, with an overall aim to secure a healthy planet.\nThe manifesto has been developed in response to increasing evidence and a general understanding of the severity of our global climate and environmental crisis. Now more than ever, we need courageous leadership who will make crucial decisions and take action to secure a healthy planet for all, including the very existence of human civilization.\nMuch can be learned and applied from the philosophy and perspectives of traditional Chinese medicine (TCM) with regards to re-framing how the health of humans is intimately connected to the health of our planet, and ultimately, how to create a healthy planet as a basis for healthy humans. The manifesto summarizes key international evidence and also has been inspired by the parallels of human and planetary health as presented in high-level presentations from TCM practitioners at our plenary sessions.\nFrom a TCM perspective, in many respects human systems can be seen as a microcosm of the Earth’s living biosphere. Although there are significant differences in the scale and functions of some of these systems, in terms of appreciating the seriousness of the Earth’s failing ecosystem, it is helpful to consider the analogies of the planet’s health with that of human systems. If we were to consider our planet as a patient, we would be seriously concerned about its health and would quickly diagnose the “Patient Planet” as critically ill. A rapid assessment of the planet’s health would reveal that it has an escalating fever, difficulty in breathing, a faltering circulation with metabolic acidosis and a toxic status, failing liver and kidney functions, pale and blotchy skin indicating signs of shock, and a rapidly declining mental state.\nFrom the perspective of the planet’s doctor, we would immediately send the ‘‘Patient Planet’’ straight to critical care for emergency resuscitation and stabilization. This should involve a rapid reduction of carbon emissions over the next decade, including actively sequestering carbon to lower key drivers of increasing temperatures. Stabilization of ocean temperatures and acidity may also be required.\nThe UN recently declared that we have to reduce global carbon emissions by 45 percent by 2030 over the level of 2010, in order to keep within the limits of global warming of 1.5 degrees Celsius, with a target of zero emissions by 2050. This will require urgent and large-scale action with an estimated annual investment of 2.5 percent of global GDP to rapidly reduce carbon emissions, including carbon capture.\nWe can draw upon the successes of China’s ability to improve human health and education, advance development outcomes, and rapidly transform the economic well-being of nearly 20 percent of the world’s population. Building upon China’s ambitious goals in its climate change policies and work plans, we can set an example to the world of how to coordinate responses and harness the necessary capacity to address the climate crisis at scale and speed. Ultimately, China is and will be pivotal to our global response in being able to address the climate crisis and successfully secure a healthy planet for all.\nIn order to be successful, climate and environmental emergency response committees will be required to: stabilize risks from tipping points, rapidly reduce carbon emissions, protect ourselves and our planet from the increasing impacts of the climate and environmental crisis, and strengthen recovery processes and community resilience. We can all learn from the successes of China in advancing the development of scaling up green and smart cities within the framework of building ecological civilizations.\nIn addition to this, we can also build upon past experiences of successfully managing emergency situations and draw upon existing tools like the Sendai Framework for Disaster Risk Reduction. Collaborative efforts are required to scale up emergency action that include strengthening coherence and coordination to harness resources and capacity across the global community, while mainstreaming responses to the climate and environmental crisis through established delivery mechanisms.\nWe need to express our commitment and demonstrate our responsibility by becoming “guardians to secure a healthy planet for all” – a concept that reflects the Chinese concepts of the inter-relationship between the health of humans and their environment.\nChina can play a key global leadership role as a guardian for the planet’s health, for example, by increasing the efficiency of innovative responses to carbon capture, creating low-cost renewable energy, and mainstreaming recovery processes. Moreover, China’s ability to coordinate and rapidly transform societies can be applied to building community resilience and creating sustainable flourishing civilizations across China, throughout the Belt and Road, and in the many other countries that China is investing in.\nTogether, by rapidly responding to our climate emergency, we can take the decisive actions that are essential at this critical time. I am especially encouraged by the boldness and energy of our younger generations, as well as the commitment expressed by the many supportive and professional organizations endorsing the manifesto. In particular, I welcome the important role that China has in matching ambition with the size of this existential challenge, in order to transform and create a flourishing future in this world that we all share together.']	['<urn:uuid:3c761bec-da04-4318-87db-d9f09081d381>']	open-ended	direct	concise-and-natural	similar-to-document	single-doc	novice	2025-05-13T04:02:16.770989	8	61	1008
13	What is the recommended approach for treating chronic back pain, and how do different healthcare professionals work together to address it?	Chronic back pain treatment requires a multidisciplinary team approach rather than relying on a single discipline. At USC, physical and occupational therapists team up with physicians to provide coordinated care. While physicians typically spend 15-20 minutes with patients, therapists can devote more time to work on specific issues. The treatment approach varies based on severity: less severe cases (Grade 1) receive simple therapies, while severe cases (Grade 4) require bio-psychosocial therapy. Treatment options include explanation about the disease, exercise, drugs, traction, spinal manipulation, acupuncture, infrared therapy, ultrasonic sound therapy, heat and cold therapy, and rehabilitative measures like Work Hardening and Vocational Conditioning. Physical therapists focus on movement and can analyze posture to understand optimal positioning, while occupational therapists consider daily life activities and help patients modify their routines.	['They stop back pain. Treat headaches. Help people quit smoking and lose weight. They even get cancer patients back on their feet.\nBut they’re not medical doctors. They’re physical and occupational therapists.\nWith specialties that go way beyond rehab for knee surgery or stroke, USC’s physical therapists and occupational therapists are teaming up with physicians to provide a whole-health approach to prevent disease and injury. Across the nation, these professionals are increasingly contributing to patients’ everyday health care.\nAt USC, some of these therapists work closely with health care providers at primary care clinics, where people go for regular checkups. Others are located in specialist centers, such as USC’s headache clinic, where they form a critical part of the health care team. While physicians typically spend 15 to 20 minutes with each patient to provide medical care, therapists can complement doctors’ work by devoting more time to a patient’s unique issues and working intensely with the patient to resolve them.\nPrimary care topics like health management, wellness and prevention have been cornerstones of occupational therapy for decades, says Ashley Halle MA ’11, OTD ’12, assistant professor of clinical occupational therapy and coordinator of primary care residency and services in the USC Mrs. T.H. Chan Division of Occupational Science and Occupational Therapy. “I think there are some practitioners who are doing primary care — they just don’t know it.”\nIt’s a national movement, part of efforts to make health care more coordinated and efficient. “But USC is a place that has been doing it for a long time,” says Chantelle Rice Collins ’07, MA ’08, OTD ’09, director of the USC Occupational Therapy Faculty Practice. And students in the university’s physical and occupational therapy graduate programs — both rated in the top three in the nation by U.S. News & World Report — get exposure to that integrated care during their training.\nUsing Occupational Therapy to Kick Bad Habits\nQuit smoking and lose weight. They’re doctors’ orders because they reduce risk of disease. Yet they require changing habits that are hard to break.\nUSC occupational therapists developed an approach called Lifestyle Redesign to help patients revamp their daily habits and routines. The program was pioneered in the 1990s for aging adults by Florence Clark PhD ’82, USC professor emerita of occupational science and occupational therapy. It has since been shown to improve quality of life and reduce health care costs for patients of all ages and backgrounds.\nThe process takes a holistic look at the body and works in small steps. Let’s say a patient mostly eats fast food, but she wants to adopt a better diet. An occupational therapist might help the woman set an achievable goal of swapping fast food for a healthful meal one night a week. Even little successes can have a big impact, says Halle.\nAt USC Chan, Lifestyle Redesign is just one of the many approaches used by occupational therapists to help patients lower their disease risk by countering obesity, chronic pain, diabetes, fatigue and stress. Programs are individualized, and the occupational therapists meet often with patients to keep them on track.\nSometimes these professionals join with a physician on rounds, or doctors may finish a consultation and hand their patient off to an occupational therapist to work with them more closely. At one USC-affiliated clinic in Orange County, therapists offer group sessions around lifestyle topics like healthy cooking or learning tai chi.\nHalle, who even makes house calls, visits older adults to help ensure they can stay safe in their residences and avoid injury. Occupational therapists can make sure a patient can get in and out of the shower without risk of slipping, for example. It’s part of a growing trend to address patients’ needs at home.\nReorganizing Life After Diabetes\nBeth Pyatak ’02, MA ’04, PhD ’10, MS ’15, an assistant professor at USC Chan, studies how Lifestyle Redesign can help people manage their diabetes.\nIn her research, she has found that young adults with diabetes may struggle to keep their blood sugar at the right level, putting them at risk for complications like blindness or kidney failure. Occupational therapists in her program, called Resilient, Empowered, Active Living with Diabetes (REAL Diabetes), recognized that life can get in the way of managing diabetes. Some people might work long hours without breaks for checking blood sugar. Others might avoid taking their insulin because they dislike needles. Or patients might live in an area where it’s unsafe to go for a jog.\nOnce they understand patients’ challenges, the therapists create an individualized care plan. Over 12 sessions, occupational therapists suggest changes that make it easier to deal with diabetes. For example, they might recommend that someone who fears needles apply ice before the injection or learn relaxation strategies. Occupational therapists also send text messages and electronic reminders.\nIn a recent study, patients in the REAL Diabetes program significantly improved their A1C scores, a measure of consistent blood sugar control. Participants also improved their quality of life and blood sugar-checking habits, Pyatak says. “They felt better about how their diabetes was affecting the rest of their life.”\nNow, Pyatak is teaming up with Jesús Díaz ’05, MA ’08, OTD ’09, associate professor of research, to test her program in a Los Angeles County+USC Medical Center clinic. Manuel Campa, medical director of the center’s Adult Primary Care West, has been impressed with the results so far.\n“Jesús’ work has been a gamechanger for a lot of our patients,” Campa says.\nFor now, Díaz is focusing on the REAL Diabetes trial, but once that wraps up, Campa is excited to see how occupational therapy might help the clinic’s patients with other ongoing issues such as obesity, chronic pain and high blood pressure.\nPhysical Therapy Tackles Pain, Fatigue and Movement\nFatigue is one of the major struggles for people living with multiple sclerosis, a chronic neurological condition. Occupational therapist Ashley Uyeshiro Simon ’08, MA ’10, OTD ’11, associate professor at USC Chan, trains USC students to use Lifestyle Redesign to help these patients.\nOccupational therapists can work with patients on ways to avoid exhaustion. An action plan could include simple steps like buying pre-chopped vegetables, for example. It could also guide patients to prioritize their most important activities, so they know where to focus their energy.\nThese professionals also can help patients struggling with chronic pain from conditions like fibromyalgia or arthritis. Physical therapy may be an option, too. While occupational therapists consider the activities patients perform as part of everyday life, physical therapists focus on movement. “We can analyze a person’s posture, look at the way someone moves, and understand what is ideal or optimal,” says Kenneth Kim DPT ’11, an instructor of clinical physical therapy at the USC Division of Biokinesiology and Physical Therapy.\nOnce physical therapists understand where movement is going awry, they can design a plan to fix it. For those with back pain — one of the most common complaints that primary care doctors hear — Kim might focus on flexibility around the hip and look at the trunk muscles for stability issues. He also teaches his patients about pain management and self-care techniques. The long-term solution, Kim says, is exercise. Muscle pain often occurs when one muscle is overloaded, taking the burden that ought to be shared with other muscles. Physical therapists may treat back pain by strengthening the hips, which usually takes some of the pressure off the spine.\nRx for Cancer Survivors\nThe exercise prescription has value well beyond sports injuries or orthopedic pain. Physical therapy and exercise are also under study at USC for people with Alzheimer’s disease, Parkinson’s, prostate cancer or wounds. Christina Dieli-Conwright PhD ’09, MPH ’17 studies how it can help breast cancer survivors.\n“The main cause of death in breast cancer survivors is heart disease,” says Dieli-Conwright, assistant professor of research in biokinesiology and physical therapy. Some believe that the chemotherapy and radiation that are part of treatment may damage the cardiovascular system. In addition, patients in treatment might become less active or develop poor eating habits that persist longer than their cancer therapy.\nShe recently tested a four-month exercise program for breast cancer survivors. At the study’s start, more than three out of four participants had high blood pressure, high cholesterol or excess body fat, all of which raise heart disease risk. Half of the participants worked out three times a week, while the other half didn’t.\nAt the end of the published study, only 15 percent of the women who exercised still had a combination of heart disease risk actors, and their weight dropped. The benefits persisted three months after the study ended, as many of the women stayed active. The physical activity helps protect the women from heart disease, and maybe cancer, too: Women who are obese have a 60 percent higher chance of cancer recurrence than those who are not.\nTherapists Team Up to Aid Recovery\nWith many studies showing the benefit of physical and occupational therapy for recovery, USC’s physicians and therapists are seeing the benefit of working together. Physical therapists like Kim regularly communicate with their patients’ doctors.\n“I believe that the physicians now trust us quite a bit,” says Kim, since physical therapists are experts at identifying the root of a person’s mobility problems. It’s not uncommon for an orthopedic surgeon to send a patient to a physical therapist for evaluation. And if Kim needs to consult another health care expert to help a patient, he is quick to get on the phone. “We have to incorporate people who are more knowledgeable in other areas, and really get the best treatment possible,” he says.\nSimilarly, the team at USC’s Headache and Neuralgia Center includes both occupational therapists and physical therapists. “It’s very helpful,” says physician Lauren Green, professor of neurology.\nFor a patient with migraines, a variety of triggers could be at fault — a weakened or tight muscle in the neck or back, certain foods, stress or light. During appointments with her patients, Green can address some of those triggers, but she’s thrilled that occupational therapists can work with patients for much longer to identify triggers and develop plans to avoid them. An occupational therapist might help with stress management techniques, or suggest modifications to their workspace to improve lighting or ergonomics. Meanwhile, physical therapists can teach patients how to strengthen or relax those neck and back muscles.\n“That’s why our patients tend to get better … because of our unique team approach,” Green says.\nThat kind of teamwork helps health care providers connect patients with the best care. But, Halle says, not all doctors know about everything occupational and physical therapy can do, so they might not offer a referral on their own.\nSince the passage of the Direct Access Law in 2014, California permits people to schedule appointments with a physical therapist directly. It’s also possible to do so with occupational therapists, but insurers may be more likely to pay if a physician provides a referral. If asked, doctors will often provide such a note, Uyeshiro Simon says.\n“Occupational therapy is one of those secret wonderful underutilized resources that I wish more people knew about,” she says. After all, nobody’s health and habits are perfect: “Everybody needs a little bit of lifestyle change in their life.”', 'Back pain definition\nBack pain may be defined as the pain affecting between the rib margins and the lower folds of buttocks. The amount of physical activities and bad postures influence back pain. Back pain limits movement of the spine. Back pain is frequently found to be a referred pain from other source of pain. Non-specific back pain is not related to fractures, ankylosis, direct trauma or systemic conditions. Specific back pains have specific pathological conditions and have some warning signs. Back pain is a condition that affect so many groups of people. Affected groups of back pain include healthcare professionals, like doctors, nurses, therapists, osteopaths, chiropractors, healthcare administrators, politicians and many more. Among them, 80% of chronic back pain sufferers have one or more elusive etiology. 70–80% of adults of almost all locations of world experience back pain at some point in their lives. The fifth decade is peak point for having back pain. There is drastic increase in incidence of back pain in the past two to three decades. This increase caused an increase in work loss, compensation or sick leave issues, and disability allowances with huge economic cost as its aftermath.\nMyths we know about acute back pain\n- We have a common notion to back pain that prolonged bed rest is needed for this condition.\n- Many also think that patients with acute back pain do not need close follow-up. That is because many say 80–90% of acute back pain completely resolves without treatment within 2–3 months.\nMyths are not true\n- Prolonged bed rest should be discouraged in most cases of acute back pain, as it causes stiffness, osteoporosis, bedsores and other dangerous conditions.\n- Regarding acute pain, it is a responsibility for all to prevent chronic pain. So, patients suffering from acute pain should be followed more closely to ensure that his/her pain does not convert to chronic pain.\n- It is found that only 40% of acute back pain, which are due to non-specific cause completely resolves without treatment within around 2–3 months. So, pathological conditions must be excluded first.\nMyths about Chronic back pain\n- There are myths about chronic back pain. Many of the people think that the people, who show chronic back pain, are faking and doing so for any gains. They give explanation that they have any one sign of Waddell signs. In Waddell sign, there are some tests. In tenderness test, we see superficial and diffuse tenderness rather than deep tenderness, in case of fake ones. Non-anatomic tenderness also shows fake pain. Those have fake pain will feel pain during simulation test. Here, the person feels pain without any movement of said joint. When the person is distracted, the person can score more in tests like straight leg raising test. Those who do not have real pain will have regional weakness or sensory changes, which cannot be explained by anatomical knowledge. Those with false pain, have more exaggerated reaction to any acts. For example they show overreaction of pain while walking.\n- There is myth all around that what doctors can offer only symptomatic treatment in such case, as no organic cause is there.\nMyths can be clarified\n- When Waddell signs are present, we cannot say definitely that this person have non-organic back pain. Back pain may lead a person of organic pain to such behavior. In his book Gordon Waddell said that, presence of more than three of the signs are clinically significant. But, this never exclude organic pain. This is indicative of only magnified clinical expression or magnified pain behavior.\n- Again, Chronic back pain is a problem which cannot be addressed by a single discipline. A multidisciplinary team approach is needed for assessment and proper management of back pain. Therefore, only specific medicine is not the only thing that the disease need. There are many things beyond medication for the back pain patients. However, the patients usually do not think those important.\nClassification of back pain\n- Acute: those back pains having less than 6 weeks\n- Chronic: back pains lasting more than 6 weeks\n(an acute on chronic or sub-acute variety is still in debate)\nThere are sub categories of chronic back pain. They are graded depending on severity.\nGrade 1 is less severe condition where intensity of pain is low and chance of disability is low.\nGrade 2 is mild severe condition where intensity of pain is high but chance of disability is low.\nGrade 3 is moderately severe condition where pain limits daily activity moderately and chance of disability is high.\nGrade 4 is a severe condition where intensity of pain limits daily work severely and chance of disability high.\nAlthough, we cannot say for definite which acute pain goes to chronic, we can try to manage acute pain to prevent chronic pain. There are some factors, which if present back pain may turn chronic. These are\n- Characteristics or working conditions which involve mechanical insult\n- Issues related to pain\n- Medical considerations\n- Bad strategies of response to pain\n- Fear of beliefs about the disease\n- Absence of social or emotional support\nHistory and physical examination in back pain\nBecause of availability of modern imaging systems, many of the centers are not willing to do routine clinical examination in patients with back pain. In many recent researches also concluded that history\nalone correlated well with MRI results could be better approach for back pain. Clinical examination is\nonly considered in those patients who need surgery and we need document of neurological status. However, still many things are there that can only be seen by keen physician during clinical examination and not revealed by MRI.\nHere are some points in favor of clinical examinations\n- MRI is too often picks pathology where there is none. This may be a procedure error.\n- You cannot order MRI in every patient.\n- Sometimes the real diagnosis can only be found on physical examination, e.g. detailed physical examination can point more pin point diagnosis like early cauda equina syndrome (example: the patient may not have noticed asymmetrical saddle sensory loss and reduced anal tone may be the only sign to diagnose it.)\n- From medico-legal point of view, a proper document of the physical examination findings of the patient while visiting you is important. Patient condition may deteriorate suddenly but your findings will defend you in court.\n- If you perform a proper and gentle physical examination, patient will trust you.\n- Finally, routine MRI with the patient in supine position may still miss\nsome pathology that can be picked up only by standing or upright\nThis new open MRI technology is also good because it can be used in patients with claustrophobia.\nManagement of back pain\nThe objective of our management is not to relieve pain only. It should be a holistic approach. We should treat the patient, not the back pain. There are many treatment options. They are explanation about the disease, rest, drugs, traction, spinal manipulation, exercises, acupuncture, infra red therapy, ultrasonic sound therapy, heat and cold therapy and some rehabilitating measures like Work Hardening and Vocational Conditioning, behavioral therapy etc. So, it is a multidisciplinary approach. However, are outlining some basic rules about back pain management.\nAcute back pain:\n- Rule out red flags\n- Stay active\n- Muscle relaxants\nSub-acute or acute on chronic\n- Expectations of patient\n- Regular Re-assessment\n- Active treatments\n- Cognitive behavioral therapy\n- Multidisciplinary approach\n- Occupational program for workers\nChronic back pain\n- Low disability: simple therapies\n- Severe disability: bio-psychosocial therapy']	['<urn:uuid:1985b847-30d9-433f-96b1-0ddd116df2b1>', '<urn:uuid:080557fb-1a32-43d0-b4f2-bcb3b45e1b4d>']	open-ended	direct	verbose-and-natural	similar-to-document	multi-aspect	novice	2025-05-13T04:02:16.770989	21	128	3142
14	summer heat tips protect kids indoors outdoors humidex safety sunlight shade	To protect kids from summer heat, keep them out of direct sunlight during peak hours and use shade solutions like umbrellas, canopies, or indoor solar shades. Monitor the humidex (humidity index) - when it's 35-39, modify outdoor activities, and above 40, limit all unnecessary activity. Keep them hydrated with water (8 ounces per 15 minutes of activity) or sports drinks, and dress them in light-colored, loose, natural fabrics. For indoor protection, stay in lower levels of houses, use air conditioning, and close blinds and curtains. Remember that young children can't perspire as effectively as adults and are more susceptible to heat stress.	['The arrival of summer often means that you have to deal with unbearable heat. While you would be able to handle it, you need to look out for your kids, too. Most parents want to protect their children from dehydration and heatstroke, so they want to keep them cool when the mercury rises. Here are some things that should help ensure that your child will feel much more comfortable.\nKeep Them Out Of Direct Sunlight\nWhile it is nice to see your kids playing outdoors, there is such a thing as too much of a good thing. During the middle of the day, when the sun is at its highest, you should keep them inside or under the shade. A window with interior solar shades can keep out the harsher rays of light while still allowing for a perfect view outside. You could also put up curtains so that no direct light enters your house. This can be very helpful in keeping room temperatures low throughout the day.\nIf you are out on vacation, there are other ways to help keep them in the shade. When walking around, a large umbrella should provide a walking shelter of sorts. If you are at the beach, you should bring along a canopy that you can deploy so that the kids can have a place to chill. It also provides you with a nice place to relax and read that romance paperback.\nWater Cools Everything Down\nIf there is anything that can help your kids cool down, it is water. There are various ways in which you can use it to your advantage. For one, if your child is still an infant, they likely will have a hard time dealing with the heat. A great way to help them is to give them a cooling sponge bath. You can also use these to train and educate them. While applying the bath, mention the name of each part you are bathing. The combination of the soothing sensation and where it is will link itself to the sounds you make.\nIf your child is a bit older, taking them to the local pool can be a great way to cool them down. This is even better if you have your own in your backyard. But there are other creative ways to bring in water into your activities. For example, if your car is dirty, why not have the kids participate in washing the car? Do it in a shaded area while allowing for some spraying and horseplay when it comes to the water. This should teach your children something about chores and responsibility.\nMore playful experiences with water include having a squirt gun battle or hanging a water piñata up for some whacks. These activities are a bit messier, but they will be fun. Just be ready to throw the clothes in the laundry after.\nThe Right Drinks\nThere is nothing more refreshing than a cold drink on a hot day. Plain water is good enough, especially when it is ice-cold. If you want your kids to be cool, giving them eight ounces of water for every 15 minutes of activity can be a good rule. That should be a simple cup of water.\nBesides water, you might also consider other cold drinks that you can use. The best choices available are sports drinks. They have the right mix of salt, sugar, and electrolytes to get the energy back into people. Fruit juices are also a good idea. Sodas and other sugary drinks may not be the best choice since they might make you lose more bodily fluids.\nAnother option for hydration is tasty treats. Freeze up some fruit slices and offer them as snacks. The freezing cools them down, so they provide cooling while the natural water in fruits helps with hydration. Watermelons, mangoes, and strawberries are delicious while being rich in moisture. You can also make popsicle treats for your children to suck on for continuous cooling.\nDress Them Right\nAnother way to keep your children cool during a hot summer is by providing them with the right clothes. Several elements make some clothes bad choices for summer wear. For one, avoid dressing your child in dark colors. Choose light colors and natural fabrics so that your body can breathe better. Loose clothes are also a good choice since they let air flow freely.\nKeeping your kids cool this summer should be very doable. Be observant and don’t always depend on air conditioning to do everything. Take the right steps and your children, no matter what the age, should be more comfortable.', 'Heat Exposure Injury and Its Prevention\nHow does heat affect the body?\nGenerally humans can control their internal temperature in the heat by sweating. However, under extreme heat and humidity conditions the body cannot keep up and will suffer from heat stress. The elderly and young children, as well as those with chronic respiratory and heart conditions, are more susceptible to heat-induced injury. Babies under one year of age are extremely sensitive to the ambient temperature, Their body temperature control is not yet mature and their temperature tends to reflect the ambient level. So special care needs to be taken with babies during hot spells.\nThe effect of heat on the body is a result of three factors: the humidity level, which causes 70 percent of heat stress; sun radiation, which causes 20 percent of heat stress; and the temperature itself, which causes 10 percent of heat stress. It is, therefore, important to understand that the humidity level plays the most important role in heat-induced stress and illness. During heat waves, the temperature is measured, but the humidity is also recorded and tends to bring up the temperature. This measurement is referred to as the “humidex,” a term that is short for humidity index.\nThe humidex chart(Adapted from Health Canada) below determines when people might wish to take precautions to prevent heat-related illnesses.\nHumidex Degree of Comfort\n20—29 No discomfort\n30—39 Some discomfort\n40—45 Great discomfort; avoid exertion\n46 and over Dangerous; high risk of heat stroke\nGeneral recommendations for high Humidex ratings\nHumidex of 35 to 39: Certain types of outdoor exercise should be toned down or modified, depending on the age and health of the individual, their physical shape, the type of clothes they are wearing, and other weather conditions.\nHumidex of 40 and over, which is extremely high: All unnecessary activity should be limited.\nWhat are the consequences of heat exposure?\nHeat exhaustion usually occurs after prolonged exposure to heat and/or heavy exercise in the heat resulting in increased loss of body fluids through heavy sweating. The signs of heat exhaustion include\n- Clammy, pale skin;\n- Dry mouth;\n- Tiredness and fatigue;\n- Headache; and\nHow is heat exhaustion treated?\nChildren suffering from heat exhaustion need to be removed from the heat immediately, given water to drink, and have cool compresses applied to their skin. Fortunately, heat exhaustion is not life-threatening, and will resolve with rest, fluids, and cooling down.\nHeat stroke is a very dangerous and potentially life-threatening form of heat stress or injury. The body is so overwhelmed by the heat and humidity that it loses the capacity to sweat. This results in a very high body temperature, which in severe cases can actually cause brain damage and, tragically, even lead to death. Heat stroke can occur suddenly and is an emergency requiring immediate medical attention.\nThe signs of heat stroke include\n- Very high body temperature—39.5° C (103° F) or higher;\n- Hot, red, and dry skin;\n- Absence of sweating;\n- Deep or shallow breathing;\n- A weak pulse rate;\n- Confusion or hallucinations;\n- Loss of consciousness.\nPrevention of heat injury\nClearly, the best approach to prevent heat injury is to limit activity during high humidex times, as heat injury can potentially result in heat stroke, which is very dangerous. Here are some ways to prevent heat injury during high humidity heat waves:\n- Young children and babies should be dressed very lightly and not bundled in blankets or heavy clothing.\n- Stay out of the heat and humidity by staying indoors during the hottest time of the day (usually mid-morning to mid-afternoon).\n- The use of air conditioners helps … even for young babies and infants. If an air conditioner is unavailable, try to stay at the lowest level of the house, as it tends to be cooler. Also, try to keep the house as shaded as possible by closing window, blinds, and curtains. A fan will help as well.\n- Do not stay or leave children in parked cars during hot weather.\n- Avoid vigorous exercise in the heat (this includes children as well). If you have a young child or a child with a chronic respiratory condition such as asthma, do not allow them to partake in sporting events or exercises during heat waves, especially when there is a heat/humidity advisory in effect.\n- Drink plenty of fluids. Water is best.. It is important to know that children may not feel thirsty, but will still need to drink regularly. Avoid drinking beverages containing caffeine.\n- When in the sun, keep track of how long a child has been outside. Learn to recognize the signs of heat exhaustion right away, so you and your child can get shelter in order to avoid further heat injury. Also, use your common sense and remove your child from the sun and the heat as frequently as you think is necessary. Do not overdo it.\n- If your children are swimming in an outdoor pool, a lake, or the ocean, you have to be aware that the high humidity and sun rays are still potential threats. Proper sunscreen protection as well as frequent rests in the shade are still necessary.\n- Children are unable to perspire as much as adults and, therefore, are more prone to heat stress during exercise than adults are. A sensible approach must be used in determining if children can safely partake in sports activities during heat/humidity waves.\nWhat about smog during heat waves?\nHot, humid air often carries pollutants, pollens, and moulds in higher concentrations than usual. Under these conditions, breathing this air may be harmful to younger children and children with chronic respiratory or cardiac conditions. During smog and heat/humidity alerts, be extra careful by not letting your children outside while the advisory is in effect. In Canada there is a Air Quality Health Index that reports on the air quality, depending on your location. In the United States, air quality data is reported here.']	['<urn:uuid:9814ef24-1554-4022-9b5c-995930d41fd7>', '<urn:uuid:3abb0f12-c45c-41de-8dc9-0c2e9364bf87>']	open-ended	with-premise	long-search-query	similar-to-document	three-doc	novice	2025-05-13T04:02:16.770989	11	102	1767
15	manufacturing engineer seeking highly efficient production methods need to know difference waste levels traditional machining vs powder metallurgy	When machining a gear from a bar of steel, about 40% of the original material becomes waste (known as turnings in the powder metal industry), with only 60% being used in the final product. In contrast, powder metallurgy can produce the same gear with zero waste or at most a few percentage points of waste. This significant reduction in material waste is also evident in modern transmission carrier manufacturing, where even casting requires discarding substantial material to achieve the final result, while powder metal processes like sinter-brazing can minimize waste.	['Many people working with small components have heard the term “near net shape” thrown around. This term refers to when a vendor can, with its primary process, manufacture a result close to the final size and shape your plans called for. That means the part requires minimal machining or other secondary processes afterward.\nBut what if you could drop the “almost” and create a truly net shape component with powdered metal? You can!\nMaybe you’ve already had some of the potential benefits pop in your head. Here are some of the biggest, along with a definition of what powder metal experts consider net shaping capability.\nWhat’s a Net Shape Part?\nWith powder metallurgy, you identify your powder of choice and your vendor pours it into the die, which is shaped as the mirror image of your design. Since you can control where you put the powder and how much, when it’s compacted it turns out exactly how you want the final version to look.\nThe part will still need sintering and, occasionally, some other fine tuning like drilling holes. Nonetheless, you can -- with minimal or no machining -- benefit from a process that goes directly from sintering/pressing to final use!\nOn to those benefits:\nAdvantages of Net Shaping Capability\nThe more raw resources your vendor needs, the more it’s going to affect your bill.\nIf an engineer starts with a bar of steel and machines a gear from it, the gear may only use 60% of the original bar. The rest is on the floor as waste (called turnings in the powder metal industry).\nPowder metallurgy can make you that same gear with zero waste (or at most a few percentage points).\nThe making of modern transmission carriers is a prime example of a wasteful process. Even with casting, your manufacturer has to throw away a lot of material to achieve the final result.\nNot with a precise powder metal process like sinter-brazing!\n2. Turnaround Time\nNot only are you wasting material with machining away all that excess material, you’re also wasting time. Powder metal’s net shaping ability can speed up your supply chain and lead times.\n3. Production & Labor Costs\nThe shorter the processing time, the less you’ll fork over for production and labor costs. Having your components practically market-ready after the first process cuts costly finishing from your manufacturing run. You won’t have to pay for someone to run all those secondary process, plus the machines to help him do it.\n4. Combined Shapes\nThere are certain geometries you can achieve with a single powder metal net-shaped part that would require multiple operations if you used machining instead.\nNeed a big gear on top and a small gear on the bottom. Powder metallurgy can handle that in a single process thanks to its shape-combining ability.\nWith powder metal you can add a hub or other features to your part -- it doesn’t have to be a simple round shape or a gear. Multipiece assemblies can be made as a single part without the need to weld, braze, or stake the additional parts. This same reduction in pieces is very apparent in soft magnetic composite parts, where you can often reduce the number of components from 1,300 pieces to under 10.\nWhile less dramatic, transmission carriers are again a good example of a product that can be streamlined with sinter bonding or brazing net-shaped parts. Your manufacturer can make the top and lower sections separately, then braze them together\nAt Horizon, for the tube assembly pictured above, the stainless tubing and two copper-infiltrated powdered metal parts are all brazed together. When we say infiltration, we mean melting copper into the part to fill the porosity.\nNew Possibilities With PM\nThere’s no need to start your project with that depressing thought of “How much material am I paying for that’s going to get thrown away?” Instead, with the right powder metal process, you can be thinking of the endless design and cost-cutting possibilities you’ve opened up.\nThere’s a reason 65-70% of the powder metal industry’s output is non-machined parts. It’s simply more cost-efficient. It’s also why nearly all of what Horizon produces is non-machined -- more than 90%!\nTo see the additional design benefits of powder metal, check out these resources:\n- What Is Soft Magnetic Composite?\n- Soft Magnetic Composite Vs. Lamination Steel: Uses & Limitations\n- Introducing 1P, 3P & 5P: Powder Metal Materials Optimized at Last']	['<urn:uuid:9519c61e-2182-4569-b4b6-35f129a01887>']	open-ended	with-premise	long-search-query	distant-from-document	single-doc	expert	2025-05-13T04:02:16.770989	18	90	741
16	I want mosquito protection - which works better, DEET or Picaridin?	Both DEET and Picaridin are similarly effective at repelling mosquitoes. Picaridin can be as effective as DEET but without DEET's toxicity and allergenic problems. Additionally, Picaridin has minimal odor and doesn't damage plastics or fabric, while DEET can dissolve some materials like plastics and rayon. Both provide 4-8 hours of protection, but Picaridin is often preferred due to being odorless, non-irritating, and non-damaging to synthetic materials.	"[""What are the different types of insect repellent?\nYou can choose from these forms, depending on your preference:\nSpray in the form of oil or liquid - a very common form of insect repellent, this can be sprayed on clothing or directly onto skin. Most spray repellent preparations contain concentrated amount of DEET. Insect repellents with DEET are considered to be effective even after several hours of walking through places that are heavily infested with mosquitoes.\n- Cream or lotion - are most effective when applied directly to the skin and are rubbed to create a repellent barrier. You can use this in combination with mosquito repellent clothing and are usually made with natural ingredients. These usually have a very minimal scent or sometimes an undetectable scent.\n- Insect or mosquito repellent clothing - specially designed clothing materials with tight fibre weave infused with long lasting insect repellent. It is a great alternative to other insect repellent forms because it can protect you from mosquito or insect bites everyday.\n- Mosquito patch - is the newest kind of insect repellent. It is made of 100% natural and safe vitamin B1. It is small, transdermal skin patch that is very easy to use. Simply slap it onto your skin and it does its work naturally.\n- Mosquito repelling bracelets - are specially designed clip on bracelets or simply clip on devices that are made with either chemical or natural insect repellent pellets inside. These are ideal for babies or those who prefer not to apply anything on their skin. These can be used either as a bracelet or clipped on bags, chairs, prams etc.\n- Mosquito repellent devices - are various types of devices that emit a repellent fragrance usually through the process of burning. These may come in the form of candles, coils or Thermacell products.\n- Electronic repellents - emit ultrasonic sound as a deterrent to bugs and insects.\n- Vitamin B - Thiamin - This product is rumored to put the mosquitos off the smell of your blood.\nWhat are the active ingredients used in insect repellents? DEET\n- (N,N-diethyl-3-methylbenzamide) is a chemical that has been approved for use since 1957. It is considered as reliable and highly effective in repelling insects of many kinds. It is present in most forms of insect repellents. Some products contain a higher percentage of DEET than others. Its concentration content signifies the length of protection time it offers. The higher the concentration, the longer protection time it provides. Picardin\n- also known as KBR 3023 is another active ingredient used in insect repellents and is also an effective alternative to DEET. It offers long lasting protection against mosquito bites. It has been widely used since 1998. It differs from DEET on several accounts: less odour, does not cause skin irritation and no adverse effect on plastics.\nIt also offer long lasting protection. Permethrin\n- is known as an effective pesticide and is also used in insect repellent. Compared to the first two active ingredients, permethrin is not used on the skin but rather used to treat clothes that repel insects of many kinds. It can retain its potency for at least two weeks even through several washings. It can also be used or applied on tent walls and mosquito nets. Clothing treated with permethrin used in combination with products containing DEET applied on skin offers excellent protection even in demanding conditions. Best when camping in forests or mountains. Lemon Eucalyptus Oil\n- is also considered as a natural insect repellent. This has been tested against mosquitoes and found in the US to provide similar protection to repellents containing low concentrations of DEET. PMD is the synthetic form of the chemical derived from oil of lemon eucalyptus. However the use of this product is not advised for those ages 3 years old and below. IR-3535\n- is another active ingredient used in insect repellents and it offers broad spectrum protection from several insects including mosquitoes, deer ticks, and biting flies. It offers reasonably long protection comparable to DEET thus offering a great alternative for those seeking non-DEET products. Plant Based Repellents\n- examples of these are citronella, geranium, basil, garlic and peppermint. Insect repellent plants generally provide quite limited protection against mosquitoes. Usually offering protection for only 2 hours and therefore needing constant reapplying.\nTips for choosing the best repellent\nTo help you choose the insect repellent product that is best suited for you, you can start by identifying the following:\n- Type of insect you want protection from\n- How long do you need protection?\n- What active ingredient do you prefer?\n- Other product specific information that may be useful for you (e.g. allergies to consider with certain ingredients)\n- Consider the kind of activity you will be engaging in and the length of exposure you will have to insects.\nUsing insect repellents with children*\n- Read and follow the directions and precautions on the label\n- Only apply insect repellents on the outside of children's clothing and on exposed skin. NB: Permethrin-containing products should not be applied to the skin.\n- Spray repellents in open, well ventilated areas to avoid breathing them in.\n- Only use enough repellent to cover your child's clothing and exposed skin - using more does not make the repellent more effective. Avoid reapplying unless definitely needed.\n- Help young children to apply their insect repellent and supervise older children when using these products.\n- Wash your children's skin with soap and water to remove any repellent when they return indoors. Wash their clothing before they wear it again.\n- Do not apply insect repellent on children younger than 2 months.\n- Never spray insect repellent directly onto your child's face. Instead, spray a little on your hands first and then rub it on your child's face, avoiding the eyes and mouth.\n- Never spray insect repellent on cuts, wounds, or irritated skin.\n- Avoid using products that combine DEET with sunscreen. The DEET can make the sun protection factor (SPF) less effective, meaning these products can overexpose your child to DEET because the sunscreen needs to be reapplied often.\n*Source: https://www.healthychildren.org/English/safety-prevention/at-play/Pages/Insect-Repellents.aspx Page updated 06/04/18 12:47:36 p.m."", 'Pest Management Fact Sheet #5108\nGriffin M. Dill, IPM Professional.\nEnjoying the Maine outdoors often involves facing a number of arthropod pests including ticks, mosquitoes, black flies, midges, and other biting flies. Moving beyond the simple annoyance posed by these pests, serious mosquito-borne diseases such as West Nile Virus (WNV) and Eastern Equine Encephalitis (EEE), as well as the tick-borne Lyme disease can cause serious illness and even death. Insect repellents are an important tool in preventing these diseases while also allowing us to enjoy everything the Maine outdoors has to offer.\nRepellents can come in a variety of forms including lotions, wipes, pumps, candles, impregnated cartridges, and pressurized sprays. The effectiveness of repellents depends upon active ingredient, concentration, target species, as well as a host of other secondary factors. This fact sheet provides information that will help you make educated decisions regarding the safe and effective use of insect repellents.\nChoosing a Repellent\nWhen heading outdoors, choose a repellent that best fits your needs based on:\n- Length of exposure (How long do you plan on being outside?)\n- When and where you will be (Some pests are more active at specific times and certain places are more likely to have higher pest activity than others.)\n- What you will be doing (Physical activity, temperature, and water exposure can influence the endurance of repellents.)\n- Type of pest present (What types of pests are in the area: mosquitoes, ticks, flies, etc?)\n- Effectiveness of active ingredients (Do you prefer a synthetic repellent or a natural repellent?)\n- Age of user (Caution should be used when selecting repellents for use on children.)\nNot all insect repellents are the same. Specific brands use different active ingredients and different concentrations of these ingredients. The following active ingredients have been determined to have varying degrees of effectiveness in repelling biting arthropod pests. The first four repellents (DEET, Picaridin, IR3535, and Oil of Lemon Eucalyptus) are recommended for use by the Centers for Disease Control and Prevention (CDC) based upon their endurance and effectiveness against biting arthropods.\nDEET: DEET is the commonly used acronym for the chemical N, N-diethyl-meta-toluamide. It has been extensively used as a highly effective mosquito repellent and also works well on ticks, fleas, black flies, and biting midges (no-see-ums). DEET can be found in concentrations ranging from 4-100%. However, studies indicate that concentrations greater than 30% do not provide added protection and have resulted in skin reactions and eye irritation on rare occasions. Exposure to DEET at high doses has also been associated with respiratory and gastrointestinal irritation. Depending on the situation and concentration, DEET provides 2-8 hours of protection. According to the American Academy of Pediatrics (AAP) DEET may be applied to children over the age of two months but should be done so by an adult and in concentrations not exceeding 30%. Care should be taken when applying DEET to clothing or around certain materials including plastics, rayon, spandex, leather, and painted or varnished surfaces. DEET is an effective solvent and may dissolve some of these materials.\nPicaridin: Picaridin (Icaridin, Piperidine, Propidine, INCI, or KBR 3023) is another effective repellent of mosquitoes, ticks, fleas, black flies, and biting midges. It can be as effective as DEET, but without the toxicity and allergenic problems commonly associated with DEET. Picaridin is a relatively new product (introduced to the U.S. market in 2005) and allergenic properties may be discovered once use becomes more widespread. Derived from pepper, this repellent has minimal odor and does not harm plastics or fabric. Picaridin offers 4-8 hours of effectiveness, but, because it is relatively odorless, not irritating or greasy, and doesn’t damage synthetic materials, it is often preferred to DEET.\nIR3535: IR3535 (ethyl butyl acetyl aminoproprionate) is a moderately effective repellent of mosquitoes, ticks, and biting flies. Some tests indicate that the relatively non-toxic IR3535 can provide 4-6 hours of effectiveness, however, USDA laboratories found this repellent to be 10-100 times less effective than DEET.\nOil of Lemon Eucalyptus: Oil of lemon eucalyptus (p-menthane 3,8-diol or PMD) is one of many plant-based insect repellents and is effective against mosquitoes, black flies, biting midges, ticks, and gnats. Generally, plant-based repellents do not have the same level of effectiveness as synthetics such as DEET and Picaridin, however, oil of lemon eucalyptus has been shown to offer protection similar to concentrations of 20-30% DEET, but for much shorter periods of time. According to the product label, oil of lemon eucalyptus should not be used on children under the age of three and care must be taken to keep it out of the eyes because it can cause significant eye irritation.\nCitronella: Citronella is another natural plant-based product with minimal repellence to mosquitoes. Citronella is often used in candles, torches, and in some topical repellents. In general, citronella based products provide much lower protection from mosquitoes than other repellents and are not effective against ticks and other biting pests.\nEssential Oils: In addition to oil of lemon eucalyptus and citronella, commercially available repellents containing active ingredients such as catnip oil, geranium oil, peppermint oil, soybean oil, and a host of other essential oils are purported to have repellent qualities. While these oils may offer some mosquito repellence, they tend to do so for short periods of time and have not been found to be effective against other biting arthropods, ticks in particular.\n2-Undecanone: 2-undecanone (methyl nonyl ketone or IBI-246) is an oily, plant-based repellent that has shown some effectiveness against ticks and mosquitoes. The use of 2-undecanone as an insect repellent is relatively new; it is most commonly used to repel cats, dogs, and even raccoons. Due to the limited use of 2-undecanone as an insect repellent, adverse effects have not been well documented. Studies indicate that the potential exists for some acute toxicity and mild irritation but further testing is needed.\nPermethrin: Permethrin is a pyrethroid that works as a contact insecticide as well as a repellent. The chemical is effective against mosquitoes, flies, ticks, fleas, human lice, and chiggers. It has low mammalian toxicity and is poorly absorbed by the skin. Products containing permethrin are for use on clothing or other fabrics (tents, mosquito netting, etc.) not on skin. The use of permethrin treated clothing in combination with a DEET application provides a formidable barrier against biting insects and can nearly eliminate mosquito bites. Permethrin yard foggers can be an effective short term solution for small outdoor settings, however, some concerns have been raised about potential respiratory and gastrointestinal irritation associated with the prolonged inhalation of permethrin.\nMetofluthrin: Metofluthrin is another relatively new chemical repellent. Although it is a repellent, metofluthrin is similar to permethrin, in that it is a type of pyrethroid and is not to be used directly on the skin. Metofluthrin is found in impregnated repellent strips that are placed near outdoor gathering spots, as well as in the replaceable cartridges of battery operated personal repellent devices. These devices emit a small cloud of metofluthrin that acts as an effective repellent against mosquitoes. Concerns have been raised about the safety of these products, as users are exposed to prolonged inhalation of metofluthrin, which has been found to be a neurotoxin in some studies.\nOnce you have determined the type of repellent you would like to use, it is important to follow these general considerations when applying repellents:\n- Remember insect repellents are registered pesticides. Read and follow all directions and precautions on the product label. It is the law.\n- Only apply repellent to exposed skin as directed, never under clothing.\n- Do not apply over cuts, wounds, or irritated skin.\n- Do not apply products directly onto your face. Spray your hands and carefully apply to your face, avoiding contact with your eyes and mouth.\n- Do not apply repellents near food or drink items.\n- Do not apply repellents to children under the age of two months. Check label for additional restrictions (lemon of eucalyptus should not be used on children under three)\n- Do not apply to hands or near eyes and mouth of children.\n- Do not allow young children to apply this product.\n- Avoid over-application. Use only what you need.\n- Do not spray when you are in an enclosed area.\n- Do not re-apply unless the label allows additional applications.\n- After returning indoors, wash treated skin with soap and water.\n- Wash treated clothing before wearing it again.\n- The AAP cautions against use of a repellent that is combined with sunscreen. The sunscreen will need to be reapplied more often than the repellent so you might end up using too much repellent.\nFor more information regarding the safe use of insect repellents please see:\n- CDC Insect Repellent Use and Safety\n- EPA Guide to Choosing Insect Repellents\n- National Pesticide Information Center Repellent Finder\nWhen Using Pesticides\nALWAYS FOLLOW LABEL DIRECTIONS!\nPest Management Unit\nCooperative Extension Diagnostic and Research Laboratory\n17 Godfrey Drive, Orono, ME 04473-1295\n1.800.287.0279 (in Maine)\nInformation in this publication is provided purely for educational purposes. No responsibility is assumed for any problems associated with the use of products or services mentioned. No endorsement of products or companies is intended, nor is criticism of unnamed products or companies implied.\n© 2011, 2012\nCall 800.287.0274 (in Maine), or 207.581.3188, for information on publications and program offerings from University of Maine Cooperative Extension, or visit extension.umaine.edu.\nThe University of Maine is an EEO/AA employer, and does not discriminate on the grounds of race, color, religion, sex, sexual orientation, transgender status, gender expression, national origin, citizenship status, age, disability, genetic information or veteran’s status in employment, education, and all other programs and activities. The following person has been designated to handle inquiries regarding non-discrimination policies: Sarah E. Harebo, Director of Equal Opportunity, 101 North Stevens Hall, University of Maine, Orono, ME 04469-5754, 207.581.1226, TTY 711 (Maine Relay System).']"	['<urn:uuid:618e86c3-dd34-40fb-93bf-cf94ec8fd633>', '<urn:uuid:ca94f4c9-0270-46ac-beb4-58419d65a417>']	factoid	with-premise	concise-and-natural	distant-from-document	comparison	novice	2025-05-13T04:02:16.770989	11	66	2676
17	recording studio wiring cables equipment noise problem what gear needed and how fix buzz sound	To achieve clean recordings, you need proper gear setup and noise elimination. The gear chain should include a quality microphone, dedicated preamp, compressor (like UA LA-2A), and EQ (like API 550). For eliminating buzz sounds, which are often caused by ground loops, you need to disconnect all cables from your mixer, then reconnect them one by one to identify the problematic connection. Once identified, use a DI box with ground-lift switch or modify the audio cable by disconnecting its shield to break the ground loop.	"['Whether you are aware or not, capturing a great vocal performance sonically has a lot more moving parts than you think. Besides the obvious points of being in front of the microphone and the right distance away, the Microphone, Preamp, Compressor and Eq you have in the chain serve a great purpose as well. In this blog I will shed some light on this topic and show you How to Record Top Tier Vocals.\nThe first topic we are going to discuss is the microphone you should be using when recording. This will all be dependent on the type of vocalist you are going to be recording. Remember to always use your ears, but here are some basic guidelines to go by. If your vocalist is very loud and forceful, almost screaming into the microphone, then a dynamic microphone would probably suit you best in this situation. One of the more famous dynamic microphones to fill this void would be a Shure SM57 or SM7B. If your vocalist is more dynamic and more melodic, than a condenser or tube condenser microphone may be in order. Some of my favorites for these types of vocalist are the Sony C800G (Pictured below) and the AKG C12 for tube condenser mics, and the Neumann U87 and AKG C414 for regular condenser mics. For a warmer sound you can also try ribbon microphones as well, though expensive they can be ideal for certain vocalists. Remember these are just guidelines, use your ears and see what microphone sounds best but remember these principles.\nThe next link in the chain will be the preamplifier you use for your microphone. A lot of people make this mistake, but it is so vital in the process to have a dedicated preamp for your microphone and not just the standard one that comes with your audio interface. This will help ensure you are not losing any of the frequencies you are capturing with your microphone through the conversion process from a mic line signal to a line level signal. It will also add a bit of positive coloration, enhancing the vocal depending on which preamp you use. Remember you can have the world’s best mic, but if your preamp is subpar, you won’t get all the benefits the mic has to offer. However, if you have a mic that isn’t the greatest, having a great preamp will make it sound amazing. Some of my personal favorites are the Neve 1073, Vintech 273, Chandler Limited TG2, and Avalon 737. As always again, experiment to see which sound fits your vocalist best.\nNext in the chain will be your compressor. This isn’t necessarily being used for actual compression as it is for just more coloration and analog warmth. Though you can compress on the way in, you must be mindful not to do too much or you will ruin the dynamics of the actual vocal performance. This also cannot be undone since we are recording on the way in. I personally just have this in the chain not actually doing much compression at all but just giving the vocal added analog warmth. Some of my favorite compressors for this task are the Tube-Tech CL1B, the Universal Audio LA-2A, and the Universal Audio 1176LN. Experiment to find which you like for your vocalist.\nThe last link in the chain will be my Eq. This is following along the same premise as the compressor. I am not necessarily Eqing anything, it is more for the sound and analog warmth. However, if you are going to Eq on the way in, I would maybe low cut up to 60 Hz at the most. Anything more will detract from the vocal performance and remember this cannot be undone. Some of my favorites include the API 550 A and B, the API 560 Graphic, and the SSL 611EQ. Remember you don’t have to use these exact ones, though the ones I have mentioned throughout this blog have been battle tested through the industry, experiment and research your own.\nAll in all, following these ideals as a guideline, you will be set to have industry standard top tier vocals. This methodology is something that your favorite artists employ to give them that vocal sound we know and love from them. I also want to mention although some of the gear I have mentioned above is quite pricey, it doesn’t mean you can’t substitute for cheaper gear and get a great result. What is important though is the following the chain as a whole. I leave you guys with a clip from Pensado’s Place (A Grammy Award Winning Engineer), where he has some A-List recording engineers explaining this whole process a bit more further in detail.\nWritten for SoundOracle.net by Mitchell ""The Innovator"" Tillotson, Producer\nMitchell “The Innovator” Tillotson is a Music Producer, Musician, Songwriter, and Sound Designer hailing from the greater Baltimore area. Growing up as a Military Brat in the early 90’s and 2000’s and listening to producers like Teddy Riley, Rodney Jerkins, The Neptunes, and Timbaland, he fell in love with music at an early age. The recent Fullsail Music Production Grad and Navy Veteran grew up deejaying the local scenes in the Baltimore/DC areas and is now starting to take the music world by storm. Follow @iamtheinnovator on Twitter.\nMORE ARTICLES BY MITCHELL “THE INNOVATOR” TILLOTSON:\n- Top 5 Beat Making Apps for The Mobile Producer\n- Top 10 Best Audio Interfaces For Production And Recording 2018\n- Top 10 Best Computers for Music Production and Recording 2018\n- 7 Delay Tricks Every Producer Should Know\n- 7 Ways To Clean Up Your Muddy Mix\n- Chord Technique: How to Add More Harmonic Color To Your Musical Compositions\n- 7 Tips For Creating Better Musical Arrangements\n- 7 Ways To Dramatically Increase Your Music Production Workflow\n- 7 Ways To Get More Of Your Audio Loops\n- 11 Ways To Improve Your Mixes Instantly\n- Top 10 MIDI Keyboard Controllers 2017\n- Classic Songs Created With The Iconic Roland TR – 909\n- Classic Songs Created With The Iconic Roland TR – 808\n- How To Sample The World Like A Pro\n- World\'s Best Computers For Music Production 2017\n- Discover Been Trappin 3\n- Discover Vocaine Glitched Vocal Loops\n- Discover The Art of Transition\n- Discover Sample Genesis\n- Discover Xo2 R&B Melody Loops\n- Discover No Games Official Kit (Ayo & Keyz x Unquantized)\nAnother dope article with some great info from The Innovator and Soundoracle', 'Have you ever heard that annoying buzz coming out of your speakers? I certainly have been listening to that same old buzz for a while now and I finally decided to do something about it.\nAs your studio expands with more effect processors, synthesizers, compressors, and pre-amps the studio becomes a complex living organism. Thin copper wires connecting completely different types of equipment together. All kinds of noise emerge from seemingly out of nowhere. Today I want to talk about fixing ground loops.\nWhat is a ground loop?\nMost equipment is grounded via their mains cable. Every audio cable has a shield which is also flowing to ground. So, when you connect two pieces of equipment together an unwanted current can run in a loop between the cable shield and the mains cable ground.\nThe more equipment you have wired together the more problems arise. Especially if you use a mixing desk or patch bay. Most mixing desks and patch bays connect all grounds together which makes it hard to figure out what equipment is causing the problem.\nWhere is that troublemaker?\nThe only way to figure out where your ground loop is coming from is to disconnect all cables from your mixer or recording device. Then, by turning up your monitors, you should hear nothing but hiss from the pre-amps. Now, start connecting your cables again, one at a time. At one point you will hear that dreadful 50Hz or 60Hz hum buzzing in your eardrums.\nNow that you found the culprit, it’s time to break the loop. The easiest way to test this out is by grabbing a DI box and flipping the ground-lift switch. If you have a DI with transformers you could also use that to isolate the cable shields. If this solves your problem you know for sure that you have a ground loop problem.\nWhile a simple DI or transformer could fix the problem, if you have multiple ground loops, however, having multiple DI’s would become a bit expensive. Fortunately, there is a cheaper solution! If you were to simply disconnect the audio cable ground from the connector, the loop is broken too! This is exactly the same as the ground lift switch on your DI box.\nJust to be sure\nJust to make sure. I am talking about the shield from the audio cable. You should never disconnect the ground from the mains cable, as this functions as a safety net which prevents you from getting shocked.\nAlso, remember that microphones only have one way of receiving any ground. So, disconnecting the ground from the microphone lead won’t make any sense. There can’t be a ground loop with a microphone and disconnecting the ground would make the microphone unusable. If you hear noise coming from the microphone it is likely from the microphone itself or from the pre-amp.\nThere are various theories about what the best place would be to disconnect the audio cable ground. You can disconnect the ground at the equipment input or at all the equipment outputs. I simply leave all the audio grounds connected at my mixer and disconnect the ground on the other side of the cable. Unfortunately, my previous pile of cables was made up of cheap molded cables so I couldn’t simply disconnect the ground on one side. I had to order new cables and solder them myself, which was a pain in the butt, but hey, I do have great quality cables now as bonus!']"	['<urn:uuid:2cb29eb1-1506-4249-bc62-d41677651506>', '<urn:uuid:5acd7a4c-76ff-4b8f-b7d9-e70099623553>']	factoid	with-premise	long-search-query	similar-to-document	multi-aspect	novice	2025-05-13T04:02:16.770989	15	85	1666
18	I'm doing research about work habits in ancient times - I'm curious about any examples of officials who were known for their dedication and long working hours. Do you know any cases?	Teng Yin demonstrated exceptional dedication in his work as Commander Below the Capital. He would receive guests during the daytime and review written documents at night, sometimes working through the entire night without sleeping. He was notably diligent in receiving scholars and personally handled official documents with great care, refusing to delegate these responsibilities to subordinates.	['Téng Yìn appellation Chéngsì was a Běihǎi Jù man. His father’s elder brother [Téng] Dān, father [Téng] Zhòu, with Liú Yáo were of the same hometown and associated families, and as the world was disturbed in chaos, crossed the Jiāng to rely on [Liú] Yáo. When Sūn Quán became Chariots and Cavalry General, he appointed [Téng] Dān as Right Major, who for his generosity was praised, and died young, no successor. [Téng] Zhòu was good in writing prose, and [Sūn] Quán treated him with courtesy due to guests, and for the military’s and state’s documents and memorials, he was always ordered to revise and polish up, and he also unfortunately was short lived. When [Sūn] Quán became King of Wú, in recollection of their former grace, gave fief on Yìn as a capital precinct Marquis. When young he had integrity, and showed beautiful conduct. (1) He was capped and bestowed with a princess. At thirty years, he began his career as Dānyáng Administrator, transferred to Wú prefecture and Kuàijī, and wherever he was he met with praise. (2)\n- (1) Wúshū states: Yìn at twenty years, but was orphaned and alone established, able to govern himself with strict conduct. As a man he pure and clear, his awe-inspiring manner considerable. Every first moon’s first day at Court congratulations he was industrious, and of the seated great ministers that saw him, none did not sigh and appreciate him.\n- (2) Wúshū states: Yìn sent up memorial explaining the time’s appropriateness, and the good and bad among the people, with many rectifying assistance. [Sūn] Quán because of Yìn, added heavy bestowment of princess, and increasingly consulted him. Yìn at every listening of discussion and litigation, decided guilt and law, investigated words and observed expressions, matters exhaustively with feeling and reasoning. When people had words of grievances and misery, he would face them and shed tears.\nTàiyuán Inaugural Year , [Sūn] Quán was lying ill, he visited the capital, and stayed as Minister of Ceremonies, to with Zhūgě Kè and others receive Legacy Imperial Order to assist the government. Sūn Liàng succeeded the throne, and added him office as General of the Guard.\n[Zhūgě] Kè was about to lead all the armies to attack Wèi, and Yìn remonstrated [Zhūgě] Kè saying: “You at the time of mourning the age [of Sūn Quán], received the trust of Yī [Yǐn] and Huò [Guāng], entered to secure our Court, going out defeated a powerful enemy, your reputation shakes Within the Seas, and Under Heaven none are not shaken and moved, the hearts of ten thousand surnames, hope to receive your grace and rest. Now rashly after toil and conscription, again raising army to go out on campaign, the people are weary and strength bent, and the distant [enemy] ruler has preparations. If attacking cities and being unable to overcome it, the fields will be plundered with nothing obtained, and this is to lose previous works and incur later blames. It is not as good as removing armor and resting the armies, observing for opening and moving. Moreover warfare is a great matter, a matter that needs the armies’ relief, if the armies are not pleased, can you alone secure it?”\n[Zhūgě] Kè said: “Those saying it cannot be, all do not see the calculations, and are harboring wish to stay at ease and peace. But you also believe it is correct, so what do I observe? It is that Cáo Fāng is ignorant and inferior, and government is with private families, and their officials and people, assuredly have departing hearts. Now I because of the state’s resources, wield authority of battle victory, so then where can I go that is not overcome?”\nHe appointed Yìn as Commander Below the Capital, to handle government remaining affairs. Yìn in daytime received guests, at night inspected written documents, sometimes through the night not sleeping. (1)\n- (1) Wúshū states: Yìn had favored appointment very high, received scholars with care and diligence, and memorializing documents, all was personally and carefully by his intentions, not delegated to subordinates.']	['<urn:uuid:c96b4d64-20e7-4f45-8a85-5f4e1165c3cc>']	open-ended	with-premise	verbose-and-natural	distant-from-document	single-doc	novice	2025-05-13T04:02:16.770989	32	56	677
19	What are sickle cell crisis symptoms and blood test values to watch for?	A sickle cell crisis causes mild to severe pain that can last from hours to days, particularly in bones of the spine, arms, and legs. Regarding blood test values, normal adults should have 95-98% hemoglobin A1, 2-3% hemoglobin A2, and less than 2% hemoglobin F. In contrast, people with sickle cell disease show 70-98% of abnormal hemoglobin S, which can be detected through hemoglobin electrophoresis testing.	"['What is a sickle cell crisis?\nA sickle cell crisis is a painful episode that may begin suddenly in a person who has sickle cell disease.\nA sickle cell crisis occurs when sickle-shaped red blood cells clump together and block small blood vessels that carry blood to certain organs, muscles, and bones. This causes mild to severe pain. The pain can last from hours to days. ""Painful event"" and ""painful crisis"" are other terms used to describe these episodes. Some people who have sickle cell disease have many painful events, while others have few or none.\nThe pain can happen in any part of the body. But the most common areas include the:\n- Bones of the spine.\n- Bones in the arms and legs.\nHow is it treated?\nTreatment depends on the level of pain and how long it lasts. Sometimes, nonprescription, or over-the-counter, pain relievers such as ibuprofen can help. Other times, a person needs stronger pain relief medicine that is prescribed or given by a doctor. Some painful episodes may need IV therapy for fluids and powerful pain medicines, such as morphine, to ease the pain.\nYou can prepare for a crisis in advance by creating a pain management plan with your doctor. This plan should include not only the types of medicines you can take at home but also other actions you can take at home to relieve pain. Also, your plan helps you know when to call your doctor or go to a hospital.\nFor more information, see Sickle Cell Disease: Pain Management.\nHow can you prevent a crisis?\nIt isn\'t always possible to know what sets off a crisis, but triggers include dehydration, cold temperatures, infection, stress, and low oxygen intake.\nYou can help prevent a crisis by:\n- Drinking plenty of fluids, especially before, during, and after exercise or strenuous activity and when you have a fever or infection. Drink enough so that your urine is light yellow or clear like water.\n- Dressing warmly in cold weather. Try to avoid situations where you might become cold. Exposure to cold air, wind, and water may cause a crisis by triggering red blood cell sickling in exposed areas of the body.\n- Exercise with care. If you exercise strenuously, rest when you feel tired, and drink plenty of fluids to prevent dehydration. Dehydration and reduced oxygen levels in a person\'s blood resulting from strenuous exercise may cause red blood cells to sickle.\n- Get plenty of sleep.\n- Try to reduce and manage stress in your life.\nFor more information, see Sickle Cell Disease: Staying Healthy.\nOther Works Consulted\n- Meremikwu MM, Okomo U (2011). Sickle cell disease, search date March 2010. BMJ Clinical Evidence. Available online: http://www.clinicalevidence.com.\n- National Heart, Lung, and Blood Institute, National Institutes of Health (2002). The Management of Sickle Cell Disease (NIH Publication No. 02-2117). Available online: http://www.nhlbi.nih.gov/health/prof/blood/sickle/.\nCurrent as of: March 28, 2019\nAuthor: Healthwise Staff\nMedical Review: E. Gregory Thompson MD - Internal Medicine\nAdam Husney MD - Family Medicine\nMartin J. Gabica MD - Family Medicine\nMartin Steinberg MD - Hematology', 'Also found in: Wikipedia.\nHemoglobin electrophoresis (also called Hgb electrophoresis), is a test that measures the different types of hemoglobin in the blood. The method used is called electrophoresis, a process that causes movement of particles in an electric field, resulting in formation of ""bands"" that separate toward one end or the other in the field.\nHgb electrophoresis is performed when a disorder associated with abnormal hemoglobin (hemoglobinopathy) is suspected. The test is used primarily to diagnose diseases involving these abnormal forms of hemoglobin, such as sickle cell anemia and thalassemia.\nBlood transfusions within the previous 12 weeks may alter test results.\nHemoglobin (Hgb) is comprised of many different types, the most common being A1, A2, F, S, and C.\nHgb A1 is the major component of hemoglobin in the normal red blood cell. Hgb A2 is a minor component of normal hemoglobin, comprising approximately 2-3% of the total.\nHgb F is the major hemoglobin component in the fetus, but usually exists only in minimal quantities in the normal adult. Levels of Hgb F greater than 2% in patients over three years of age are considered abnormal.\nHgb S is an abnormal form of hemoglobin associated with the disease of sickle cell anemia, which occurs predominantly in African-Americans. A distinguishing characteristic of sickle cell disease is the crescent-shaped red blood cell. Because the survival rate of this type of cell is limited, patients with sickle cell disease also have anemia.\nHgb C is another hemoglobin variant found in African Americans. Red blood cells containing Hgb C have a decreased life span and are more readily destroyed than normal red blood cells, resulting in mild to severe hemolytic anemia.\nEach of the major hemoglobin types has an electrical charge of a different degree, so the most useful method for separating and measuring normal and abnormal hemoglobins is electrophoresis. This process involves subjecting hemoglobin components from dissolved red blood cells to an electric field. The components then move away from each other at different rates, and when separated form a series of distinctly pigmented bands. The bands are then compared with those of a normal sample. Each band can be further assessed as a percentage of the total hemoglobin, thus indicating the severity of any abnormality.\nThis test requires a blood sample. No special preparation is needed before the test.\nRisks for this test are minimal, but may include slight bleeding from the blood-drawing site, fainting or feeling lightheaded after venipuncture, or hematoma (blood accumulating under the puncture site).\nNormal reference values can vary by laboratory, but are generally within the following ranges.\n- Hgb A1: 95-98%\n- Hgb A2: 2-3%\n- Hgb F: 0.8-2.0%\n- Hgb S: 0%\n- Hgb C: 0%.\nChild (Hgb F):\n- 6 months: 8%\n- greater than 6 months: 1-2%\n- newborn (Hgb F): 50-80%\nAbnormal reference values can vary by laboratory, but when they appear within these ranges, results are usually associated with the conditions that follow in parentheses.\n- 4-5.8% (β-thalassemia minor)\n- under 2% (Hgb H disease)\n- 2-5% (β-thalassemia minor)\n- 10-90% (β-thalassemia major)\n- 5-35% (Heterozygous hereditary persistence of fetal hemoglobin, or HPFH)\n- 100% (Homozygous HPFH)\n- 15% (Homozygous Hgb S)\nHemoglobin C disease — A disease of abnormal hemoglobin, occurring in 2-3% of African-Americans. Only those who have two genes for the disease develop anemia, which varies in severity. Symptoms include episodes of abdominal and joint pain, an enlarged spleen and mild jaundice.\nHemoglobin H disease — A thalassemia-like syndrome causing moderate anemia and red blood cell abnormalities.\nHeterozygous — Two different genes controlling a specified inherited trait.\nHomozygous — Identical genes controlling a specified inherited trait.\nThalassemias — The name for a group of inherited disorders resulting from an imbalance in the production of one of the four chains of amino acids that make up hemoglobin. Thalassemias are categorized according to the amino acid chain affected. The two main types are alpha-thalassemia and betathalassemia. The disorders are further characterized by the presence of one defective gene (thalassemia minor) or two defective genes (thalassemia major). Symptoms vary, but include anemia, jaundice, skin ulcers, gallstones, and an enlarged spleen.\nHomozygous Hgb S:\n- 70-98% (Sickle cell disease).\nHomozygous Hgb C:\n- 90-98% (Hgb C disease)\nPagana, Kathleen Deska. Mosby\'s Manual of Diagnostic and Laboratory Tests. St. Louis: Mosby, Inc., 1998.\na test to identify various abnormal hemoglobins in the blood, including certain genetic disorders, such as sickle cell anemia.\nTo assist in evaluating hemolytic anemias and identifying hemoglobin variants, diagnose thalassemias, and sickle cell anemia.\nSpecimenWhole blood (1 mL) collected in a lavender-top (EDTA) tube.\n|Adult||Greater than 95%|\n|Newborns and infants|\n|1 day–3 wk||70–77%|\n|Adult–older adult||Less than 2%|\nHemoglobin (Hgb) electrophoresis is a separation process used to identify normal and abnormal forms of Hgb. Electrophoresis and high-performance liquid chromatography as well as molecular genetics testing for mutations can also be used to identify abnormal forms of Hgb. Hgb A is the main form of Hgb in the normal adult. Hgb F is the main form of Hgb in the fetus, the remainder being composed of Hgb A1 and A2. Small amounts of Hgb F are normal in the adult. Hgb D, E, H, S, and C result from abnormal amino acid substitutions during the formation of Hgb and are inherited hemoglobinopathies.\nThis procedure is contraindicated for\n- Assist in the diagnosis of Hgb C disease\n- Assist in the diagnosis of thalassemia, especially in patients with a family history positive for the disorder\n- Differentiate among thalassemia types\n- Evaluate hemolytic anemia of unknown cause\n- Evaluate a positive sickle cell screening test to differentiate sickle cell trait from sickle cell disease\n- Megaloblastic anemia\n- Sickle trait\n- Anemia (aplastic, associated with chronic disease or due to blood loss)\n- Erythropoietic porphyria\n- Hereditary elliptocytosis or spherocytosis\n- Hereditary persistence of fetal Hgb\n- Leakage of fetal blood into maternal circulation\n- Leukemia (acute or chronic)\n- Myeloproliferative disorders\n- Paroxysmal nocturnal hemoglobinuria\n- Pernicious anemia\n- Sickle cell disease\n- Unstable hemoglobins\n- Hgb C disease (second most common variant in the United States; has a higher prevalence among African Americans)\n- Hgb D (rare hemoglobinopathy that may also be found in combination with Hgb S or thalassemia)\n- Hgb E disease; thalassemia-like condition (second most common hemoglobinopathy in the world; occurs with the highest frequency in Southeast Asians and African Americans)\n- Sickle cell trait or disease (most common variant in the United States; occurs with a frequency of about 8% among African Americans)\n- Hgb Bart’s hydrops fetalis syndrome\nHgb A2Erythroleukemia Hgb H disease Iron-deficiency anemia (untreated) Sideroblastic anemia\n- High altitude related to a compensatory mechanism whereby red blood cell (RBC) production is increased to increase availability of oxygen binding to Hgb and dehydration related to hemoconcentration may increase values.\n- Iron deficiency may decrease Hgb A2, C, and S related to decreased amounts of Hgb in smaller, iron-deficient RBCs.\n- In patients less than 3 mo of age, false-negative results for Hgb S occur in coincidental polycythemia related to technical limitations of the procedure where increased total Hgb levels reflect a small, possibly undetectable percentage of Hgb S when compared to large amounts of Hgb F.\n- Red blood cell transfusion within 4 mo of test can mask abnormal Hgb levels.\nNursing Implications and Procedure\nPotential nursing problems\n|Problem||Signs & Symptoms||Interventions|\n|Health management (Related to excessive demands; support deficit; conflicted decision making; limited resources; sense of powerlessness)||Inability or failure to recognize or process information toward improving health and preventing illness with associated mental and physical effects||Assess health habits to obtain an interventional baseline; obtain a current health history; identify the patient’s and family’s learning styles; refrain from using medical jargon; observe for altered literacy cues; provide most important information first and reinforce with additional education; ensure the patient understands the ramifications of a lack of healthy behaviors on sickling events; identify number of emergency department visits for sickling crises; instruct the patient and family on situations that can precipitate a crisis; recommend genetic counseling|\n|Pain (Related to hypoxic vaso-occlusive crisis secondary to sickling disease)||Emotional symptoms of distress; crying; agitation; facial grimace; moaning; verbalization of pain; rocking motions; irritability; disturbed sleep; diaphoresis; altered blood pressure and heart rate; nausea; vomiting; self-report of pain; limited mobility||Collaborate with the patient and physician to identify the best pain management modality to provide relief; refrain from activities that may aggravate pain; use the application of heat or cold to the best effect in managing the pain; monitor pain severity; assess sickle pain characteristics, location, type, and duration; monitor pain severity (severe joint pain, abdominal, or back pain may last for days); administer prescribed pain medication (typically IV morphine, hydromorphone, or fentanyl, NSAIDs); monitor HGB/HCT and transfuse with blood as ordered; use splinting of joints, joint support, moist heat to manage pain; consider distraction and rest periods|\n|Coping (Related to sense of powerlessness secondary to sickling event; feeling loss of control; poor support system; chronic nature of the disease process)||Anxiety; demonstrated inability to cope; poor problem solving; inability to meet role expectations; fatigue; frequent illness; poor goal-directed behavior; fear; difficulty asking for help||Assess the ability to convey feelings clearly and appropriately; assess presence and stability of support structure; evaluate number of emergency department visits with sickling events; discuss concerns with the patient at a time that the pain is controlled; provide education related to the treatment of and chronic nature of the disease; consult with social services and case management for home support and community resources|\n|Mobility (Related to pain hypoxic vaso-occlusive crisis secondary to sickling disease)||Difficulty in the performance of purposeful movement (walking, turning, transfers); pain with movement; reluctance or refusal to move; inability to perform directed movement||Assess baseline ability to move; assess need for assistive devices, encourage appropriate use; assess pain level; assess pain medication effectiveness; administer prescribed pain medication; assess emotional response to mobility deficits; ensure a safe environment with side rail up; ensure that room is not cluttered; facilitate ambulation as appropriate; monitor for skin breakdown and deep vein thrombosis (DVT)|\n- Positively identify the patient using at least two unique identifiers before providing care, treatment, or services.\n- Patient Teaching: Inform the patient this test can assist in diagnosing various types of anemias.\n- Obtain a history of the patient’s complaints, including a list of known allergens, especially allergies or sensitivities to latex.\n- Obtain a history of the patient’s hematopoietic system, symptoms, and results of previously performed laboratory tests and diagnostic and surgical procedures.\n- Note any recent procedures that can interfere with test results.\n- Obtain a list of the patient’s current medications, including herbs, nutritional supplements, and nutraceuticals (see Effects of Natural Products on Laboratory Values online at DavisPlus).\n- Review the procedure with the patient. Inform the patient that specimen collection takes approximately 5 to 10 min. Address concerns about pain and explain that there may be some discomfort during the venipuncture.\n- Sensitivity to social and cultural issues, as well as concern for modesty, is important in providing psychological support before, during, and after the procedure.\n- Note that there are no food, fluid, or medication restrictions unless by medical direction.\n- Potential complications: N/A\n- Avoid the use of equipment containing latex if the patient has a history of allergic reaction to latex.\n- Instruct the patient to cooperate fully and to follow directions. Direct the patient to breathe normally and to avoid unnecessary movement.\n- Observe standard precautions, and follow the general guidelines in Patient Preparation and Specimen Collection. Positively identify the patient, and label the appropriate specimen container with the corresponding patient demographics, initials of the person collecting the specimen, date, and time of collection. Perform a venipuncture.\n- Remove the needle and apply direct pressure with dry gauze to stop bleeding. Observe/assess venipuncture site for bleeding or hematoma formation and secure gauze with adhesive bandage.\n- Promptly transport the specimen to the laboratory for processing and analysis.\n- Inform the patient that a report of the results will be made available to the requesting health-care provider (HCP), who will discuss the results with the patient.\n- Depending on the results of this procedure, additional testing may be performed to evaluate or monitor progression of the disease process and determine the need for a change in therapy. Evaluate test results in relation to the patient’s symptoms and other tests performed.\n- Teach the patient that the frequency of sickling crises is reflective of disease control and need for review of therapeutic management.\n- Reinforce information given by the patient’s HCP regarding further testing, treatment, or referral to another HCP.\n- Answer any questions or address any concerns voiced by the patient or family.\n- Teach patient and family the pathophysiology of sickle cell disease in understandable terms.\nExpected Patient Outcomes\n- States understanding that the support of similar patients may assist with coping and disease management\n- States understanding that adherence to disease management recommendations can decrease sickling events\n- Describes lifestyle changes that can be made to decrease hypoxic episodes and the incidence of sickling crises\n- Identifies symptoms of infection that should be reported to the HCP\n- Complies with the request for genetic counseling\n- Complies with recommended therapeutic management for sickle cell disease\n- Related tests include biopsy bone marrow, blood gases, CBC, CBC hematocrit, CBC hemoglobin, CBC RBC morphology, methemoglobin, newborn screening, osmotic fragility, and sickle cell screen.\n- Refer to the Hematopoietic System table at the end of the book for related tests by body system.']"	['<urn:uuid:6288870c-0903-4fc4-b268-8e9bf6a3b421>', '<urn:uuid:38768410-1dce-47b0-8211-e13add6bf791>']	open-ended	with-premise	concise-and-natural	similar-to-document	multi-aspect	novice	2025-05-13T04:02:16.770989	13	66	2770
20	What stuff can you actually store in blockchain?	Blockchain can store various types of data, not just cryptocurrency transactions. It can store physical currency transactions, stock market transactions, purchase/sell transactions of physical assets, and payment transactions for services among many other types of information.	['What is blockchain?\nAs name stands for itself, blockchain is a chain of blocks used for storing and transferring information about transactions taking part in the internet. Each block contains information about specific amount of transactions. Once limit is reached, a new block is formed, making a chain. Depending from the type of blockchain, the new blocks appear regularly each couple of minutes.\nThe information stored in blocks can differ. Although it is commonly presumed that is stores data only on cryptocurrency transactions (like Bitcoin), there can be stored different data, like:\n- physical currency transactions\n- stock market transactions\n- purchase/sell transaction of physical assets\n- payment transactions for services any many more.\nHow does blockchain works?\nThe main idea behind the concept of blockchain is to maintain a common accounting book in a digital form (this is why blocks came into existence), which is a decentralized network and spread globally in precisely same copies. It is a peer-to-peer network without central governing authority/body/server managing and verifying transactions. Each computer connected to the blockchain can participate in these actions and see the transactions taking place (in most blockchains transactions are public). Despite the transactions are public, they user can check only his own transactions (all of them). The rest is encrypted by advanced cryptographic tools (hence the prefix crypto- for the digital currencies).\nHow blockchain can be used?\nCurrently blockchain is most commonly used for all sorts of financial transactions, with most popular transaction way - cryptocurrency transfers. The first blockchains and their cryptocurrencies (like Bitcoin and Litecoin) are very limited as speaking of their functionality. Yet the idea of blockchain makes it a very flexible tool, which is capable to literally change the world. In last couple of years, with such projects as Ethereum or Ripple the scope of application of blockchained has widened to the limits of human imagination. Blockchain so far had found its way to be used in banking system, transaction platform, digital signature, document verification, contracts for services, logistics, insurance, healthcare, real estate, ecology, charity and even protection of endangered species. World Economic Forum estimates, that by 2025 10% of global GDP will be stored on the blockchain.\nIs blockchain technology a safe one?\nAs for now, there is no chance of breaking the blockchain cryptography based security. This would require, at the moment we are writing this, combining most of the global computing power on one task - breaking into a single blockchain.\nAs well blockchain records cannot be altered - if someone would try to alter a blockchain in one copy of it, the safety measures (including checking all other copies of records from whole global blockchain) are going to detect that and refuse to accept the forfeited copy.\nIs blockchain a threat to the banking system?\nSome state that blockchain makes it a vital threat to the banking systems, as it gives to many people a chance to simply bypass the traditional bank networks (eg. in case of international money transfers by banks, which are slow and costly).\nStill, blockchain has the potential to make many banks beneficiaries of it. Spanish Santander bank estimates, that full application of blockchain for payments and transactions can even mean tens of billions of USD savings for banking system.\nRipple blockchain was intentionally created to be a tool for banks for cheap and fast transactions. Alternatively, banks can make their own internal cryptocurrency with specific price, benefit from its blockchain and therefore introduce cheap and fast transactions between themselves.\nIs blockchain important?\nWithout any question, blockchain technology has a potential to change our everyday life. When applied properly, it can make data processing (not only in financial sector) much faster, cheaper and safer. We will discuss the practical application of it in details in the next article.']	['<urn:uuid:af33cd26-4335-437d-9dfa-22b77f43cfee>']	factoid	with-premise	concise-and-natural	distant-from-document	single-doc	novice	2025-05-13T04:02:16.770989	8	36	632
21	I'm a cancer patient and I'm worried about how my medicine needs to be prepared before being given to me. Could you explain why having it as a liquid instead of powder would be safer for the medical staff?	Using a liquid formulation is indeed safer for medical staff because it eliminates the need for reconstitution (mixing with water before use). When drugs like cyclophosphamide need to be reconstituted from powder form, there is hazardous personnel exposure due to aerosolization - small quantities of the potent cytotoxic agent become airborne during mixing. This requires special precautions like rubber gloves and masks. Liquid formulations decrease the amount of manipulation needed, reducing exposure to clinicians and increasing safety. They also decrease the likelihood of dilution errors and provide increased assurance of sterility.	"[""Easy To Use Patents Search & Patent Lawyer Directory\nAt Patents you can conduct a Patent Search, File a Patent Application, find a Patent Attorney, or search available technology through our Patent Exchange. Patents are available using simple keyword or date criteria. If you are looking to hire a patent attorney, you've come to the right place. Protect your idea and hire a patent lawyer.\nA storage-stable liquid oncolytic formulation of cyclophosphamide for\nparenteral administration is presented. Currently utilized lyophilized\nformulations have inherent diseconomies and increased hazard is associated\nwith reconstitution. The liquid formulations of the present invention\ncomprise a solution of cyclophosphamide with an organic polyol as\ncosolvent, which provide enhanced shelf-life and greater ease of\nadministration. The polyol is either propylene glycol, polyethylene glycol\nor glyerol. The solution of cyclophosphamide is either aqueous, or in the\ncase of propylene glycol may constitute 10-30% by weight of an alcohol.\nAlam; Abu S. (Libertyville, IL), Koziol; Kenneth J. (Bensenville, IL), Kapoor; John N. (Lake Forest, IL)\nPrimary Examiner: Goldberg; Jerome D.\nAttorney, Agent or Firm:Leydig, Voit & Mayer, Ltd.\nWhat is claimed is:\n1. A storage-stable, liquid oncolytic formulation for parenteral administration comprising a solution of cyclophosphamide in a substantially anhydrous carrier which comprises\nabout 80 percent propylene glycol and about 20 percent polyethylene glycol, wherein the cyclophosphamide is present in an effective amount up to about one gram per milliliter of solution.\nBACKGROUND OF THE INVENTION\nCyclophosphamide is the generic name for 2-[bis(2-chloroethyl)amino]tetrahydro-2H-1,3,2-oxazaphosphorine-2-oxide monohydrate, a widely used antineoplastic drug chemically related to the nitrogen mustards. The nitrogen mustards are known as\nalkylating agents. These alkylating agents undergo strongly electrophilic reactions with such biologically important molecules as DNA. By alkylating DNA, these agents interfere with replication which ultimately interferes with cell viability. When\nexposed to these alkylating agents at low doses, the cell is capable of remaining viable by relying on its DNA repair enzymes which remove these alkylators prior to replication, thus allowing replication to proceed normally. The efficiency of these\nrepair enzymes will be related to the degree and type of alkylation which must be repaired. For example, alkylation of a single strand of DNA may often be repaired with relative ease allowing normal cell division. However, damage to DNA caused by\ninterstrand cross linkers (bifunctional agents such as cyclophosphamide) are more difficult to repair and involve more complex mechanisms. Thus, with increasing doses there is more extensive cross linking resulting in DNA breakdown with concomitant cell\nThese agents are cell cycle nonspecific being capable of combining with cells at any phase of their cycle. The therapeutic efficacy of these compounds arises from their interference with replication in cells which are dividing faster than their\nDNA repair enzymes can de-alkylate. It is through this destructive interference with replication in these rapidly dividing cells which these alkylating agents exert their cytotoxicity.\nCancer cells are notorious for being just such rapidly proliferating cells. This affords the pharmacologist a target at which chemotherapeutic agents may be aimed. Cancerous tissue growth outpaces the corrective effect of the DNA repair\nenzymes. These tissues then undergo extensive cell death due to breakdowns in replication and tissue growth falls off.\nCyclophosphamide was one example of a group of novel cyclic phosphoric acid ester amides which were disclosed and claimed in U.S. Pat. No. 3,018,302 granted Jan. 23, 1962 to H. Arnold et al.\nA related series of compounds bearing substituents on the oxazaphosphorine ring nitrogen was disclosed and claimed in U.S. Pat. No. 3,732,340 granted May 8, 1973 also to H. Arnold et al.\nEarly in its clinical application cyclophosphamide was available as the monohydrate in parenteral dosage formulations consisting of sterile packaged dry powder blend admixtures of the drug and sodium chloride. The premixes were dissolved in\nwater prior to administration which could be oral as well as parenteral. The aqueous solution, however, necessitated prompt administration in that shelf-life was limited to several hours after preparation. Moreover, during processing and/or storage of\nthe dry powder premix formulation, a glassiness and/or stickiness could be acquired by the premix composition giving an unattractive material with inferior solubility characteristics and decreased potency. This deterioration was more pronounced as\nstorage time was extended or if the upper limit of the storage temperature range was exceeded.\nThis temperature susceptibility was problematic in that a common practice in the constitution of sterile solids involves heating the mixture to expedite the dissolution process. It has been shown, however, that warming vials of cyclophosphamide\nin order to facilitate dissolution, after adding an aqueous vehicle, could decrease the potency of the final injectable product. D. Brooke et al., American Journal of Hospital Pharmacy 32:44-45 (1975). Subsequently, these stability limitations and\ndissolution difficulties were recognized as substantial shortcomings which often resulted in clinical use of subpotent cyclophosphamide solutions.\nAs a result of this thermal and hydrolytic susceptibility, workers in the art turned to lyophilization. The technique known as lyophilization is often employed for injectable pharmaceuticals which exhibit poor stability in aqueous solution.\nThis process involves freeze drying, whereby ice is sublimed from frozen solutions leaving only the solid, dried components of the original liquid. On Aug. 27, 1985 a patent issued to R. L. Alexander et al. which disclosed and claimed process and\npreparations for lyophilized cyclophosphamide.\nLyophilization has several advantages over the previous dry powder formulations. Lyophilization permits pharmaceuticals which are unstable in aqueous solution, yet relatively stable in the solid state to be processed and filled into dosage\ncontainers in solution, taking advantage of the relative ease of processing a liquid; dried without elevated temperatures, thereby eliminating adverse thermal effects; and then stored in the dry state in which there are relatively few stability problems.\nLyophilization has several accompanying disadvantages as well. The lyophilization process is costly, inefficient and dangerous.\nLyophilization requires sophisticated vacuum pumps, sterile, refrigerated chambers with meticulous thermal controls for cooling samples, condensors to trap the water vapor as it sublimes from the frozen solution, and thermocouple probes for\nmonitoring product temperature. The apparatus itself, the energy and the technicians required to run it become quite expensive on an industrial scale and raise the cost of the product accordingly.\nLyophilization is inefficient. Lyophilization involves removing water from a frozen aqueous solution leaving a freeze-dried solid, shipping the freeze-dried solid to the customer, who, when necessary, reconstitutes the drug as an aqueous\nsolution. Clearly, if the lyophilization process could be circumvented, time and cost would be reduced.\nThe lypholized product must be reconstituted. Reconstitution necessitates some degree of personnel exposure. This is particularly undesirable when the drug is a strongly cytotoxic antineoplastic agent. This hazardous personnel exposure is\naggravated by aerosolization of the potent cytotoxic agent. As a lyophilizate the drug must be dissolved prior to removal for injection. This necessitates additional entry to the vial with a syringe to add the solubilizing liquid vehicle. With each\naccession of the vial small quantities of the drug become airborne and this is known as aerosolization. Such added exposure requires particular precautions such as rubber gloves and masks. Furthermore, reconstitution introduces potential for dilution\nerrors. For these and other reasons producers and consumers alike prefer readily injectable liquid formulations of parenterally administered drugs.\nHeretofore, it has been generally recognized that liquid formulations of cyclophosphamide would not be possible due to the inherent instability of cyclophosphamide in water. It was unexpectedly discovered, however, that stable solutions of\ncyclophosphamide for parenteral or oral administration are, in fact, possible. This occurs when cyclophosphamide is dissolved in a solution containing an organic solvent, such as a polyol, preferably propylene glycol, polyethylene glycol or glycerol, or\ncombinations thereof. (See Tables 1 and 2.)\nSUMMARY OF THE INVENTION\nThe present invention provides stable liquid oncolytic formulations for parenteral administration comprising cyclophosphamide in a carrier which comprises from about 50 to about 100% of an organic polyol and from about 0 to about 50% water.\nThus, this invention provides improved liquid pharmaceutical formulations of cyclophosphamide which have improved stability and shelf-life. These desirable stabilized compositions are solutions comprising propylene glycol, polyethylene glycol,\nor glycerol, or combinations thereof, and water. Most notably a solution comprising as the carrier about 80% propylene glycol and about 20% polyethylene glycol 400 gives the greatest stability for the dissolved cyclophosphamide.\nDESCRIPTION OF THE PREFERRED EMBODIMENTS\nThe therapeutically active component of this invention, cyclophosphamide, is a well known and widely used anticancer agent. Cyclophosphamide chemically is [2-[bis-(2-chloroethyl) amino]tetrahydro-2H-1, 3, 2-oxazaphosphorine-2-oxide]monohydrate.\nIt is appreciated by the practitioner that the degree of reactivity desired for efficacy in an agent of this sort necessarily acts as a limit to its inherent stability in aqueous solution. Mainly for this reason cyclophosphamide has historically been\ncompounded as a sterile dry powder mixture of cyclophosphamide monohydrate and sodium chloride for reconstitution with Water for Injection or as the lyophilized solid with mannitol excipient for reconstitution with Water for Injection. Both procedures\nrequire costly, extensive processing in production and time-consuming hazardous handling in preparation or reconstitution. Additionally, both compositions lead to costly waste due to very short shelf-life of the reconstituted solutions. Consequently,\nportions not used immediately must be discarded.\nThe instant invention has resulted from work undertaken to ascertain if the stability of cyclophosphamide in solution can be improved thereby allowing the marketing of such formulations and obviating the aforementioned shortcomings of dry powder\nmixtures and lyophilized compositions.\nAs indicated previously, the liquid oncolytic formulations of the present invention have as the carrier from about 50 to about 100% of an organic polyol and from about 0 to about 50% water. The organic polyols which are useful in the present\ninvention include propylene glycol, polyethylene glycol, glycerol, and mixtures thereof. The polyethylene glycols typically will have molecular weights from about 190 to about 600.\nAs is well known in the art, the presence of water in a carrier vehicle for cyclophosphamide provides a ready means for the degradation through hydrolysis of the cyclophosphamide. However, it has been discovered that through the use of the\npresent invention, water may be present in amounts up to about 50% based on the total weight of the liquid carrier, and one may still obtain formulations with useful stability, in comparison to a purely aqueous solution.\nMost preferably, no water is present in the formulations of the present invention. Also, it is preferable to use as the carrier, mixtures of propylene glycol and polyethylene glycol, particularly mixtures in which the propylene glycol is present\nfrom about 10 to about 90%, and the polyethylene glycol is present in amounts from about 90 to about 10%, based on the total weight of the carrier. An especially useful formulation contains from about 70 to about 90% propylene glycol and from about 10\nto about 30% polyethylene glycol, particularly about 80% propylene glycol and about 20% polyethylene glycol.\nThe amount of cyclophosphamide which may be present in the formulations of the present invention can be quite varied. In an aqueous formulation, the cyclophosphamide is restricted to the solubility limit of the cyclophosphamide in water which is\nabout 33 milligrams per ml of solution. By contrast, the present invention can provide formulations containing up to about 1000 milligrams of cyclophosphamide per ml of solution. Typically, from about 5 to about 1000 mg of cyclophosphamide per ml of\nsolution. Preferably, the formulations of the present invention will take advantage of the discovered solubility of the cyclophosphamide in the carrier and will contain from about 5 up to about 1000 milligrams of cyclophosphamide per ml.\nBy referring to the subsequent examples, it can be seen that several of the formulations of the present invention show surprisingly good stability. Furthermore, the example support the following conclusions: a) the inclusion of water up to about\n50% of the liquid vehicle still results in a solution having useful stability characteristics; b ) a 100% organic vehicle show unexpectedly increased stability; c) that an 80:20 mixture of propylene glycol and polyethylene glycol imparts the most\nimproved stability; and d) there is no significant difference in stability between 20 mg/ml and 100 mg/ml of cyclophosphamide in the formulations. Furthermore, it is likely that the desired stability of cyclophosphamide will also be achieved with the\nformulations of the present invention in combination with alcohols such as ethanol. Wherein ethanol is present in an amount 10-30% based on total weight of the formulation.\nThe formulations of the present invention provide a number of important advantages. The liquid formulations provide a simple method of dosing. No reconstitution is necessary. Cyclophosphamide has greater solubility in the liquid carrier used\nin the present formulations. Thus, the concentration of cyclophosphamide in the formulations of the present invention can be as high or 1000 mg/ml whereas the highest concentration achievable with water is only 33 mg/ml. Consequently, less volume of\nsolution needs to be injected into the patient for administering the same amount of drug. This is particularly beneficial for intramuscular injections.\nAdditional advantages of the formulations of the present invention include increased safety by virtue of the decreased amount of manipulation by, and hence exposure to, clinicians, of the active agent; increased assurance of sterility; and\ndecreased likelihood of errors in dosing.\nThe present invention will be further described by way of the following non-limiting examples.\nPrevious studies have shown that the degradative process for cyclophosphamide follows first order kinetics. The degradation of cyclophosphamide, either in lyophilized form or aqueous solution results from hydrolysis and the loss of a chloride\nion. This chloride ion can be very easily titrated to determine its concentration. In other words, the stability of cyclophosphamide can be easily determined by chloride ion titration.\nAdditionally, temperature variation can be an effective tool in determining drug stability. For a degradative process which follows first order kinetics, an increase in temperature causes a calculatable increase in the decomposition rate. For\nthis reason, temperature effect studies are routinely carried out during storage testing. Tests known as accelerated storage tests have found wide use in determining the effects of given factors on drug stability under conditions of normal storage but\nin which the temperature factor is exaggerated.\nEleven formulations were prepared containing the carrier and amount of cyclophosphamide as set forth in Table I. Examples 4 and 8 are controls in which the cyclophosphamide is dissolved in 100% water as the carrier. Examples 1, 2, 5 and 6 are\ncomparative Examples in which greater than 50% water is present in the carrier vehicle. After preparation the formulations are subjected to accelerated storage tests.\nIn the accelerated storage tests, samples of each formulation (Examples 1-11) were stored in each of four thermal environments (refrigerated, room temperature, 30.degree. C. and 40.degree. C.). The stored samples were generally examined after\n1 week, 2 weeks, 9 weeks and 11 weeks and some after 15 weeks. The amount of cyclophosphamide remaining at each juncture was determined by chloride ion titration and the results of the study are set forth in Tables 2-5.\nFrom the data in Tables 2-5, it is found that the liquid formulations of the present invention have superior storage properties when compared with the formulations comprised of 100% water, or the comparative formulations containing over 50%\nwater. The most preferred formulations of the present invention have a minimum shelf-life of 12 months when stored under refrigeration.""]"	['<urn:uuid:352ace5e-dc4a-4dde-b8a8-be7203c79524>']	open-ended	with-premise	verbose-and-natural	distant-from-document	single-doc	novice	2025-05-13T04:02:16.770989	39	91	2530
22	difference between heat transfer methods conduction convection what happens	Heat transfers from warmer to cooler areas through three methods. Conduction occurs through direct contact between molecules, where heat moves directly from one molecule to another, like when a metal spoon in hot chocolate becomes hot. Convection involves the movement of warmed matter like liquids and gases - as they are heated, they become less dense and rise while cooler fluids sink, creating circulation patterns called convection currents. This is seen in both hot air balloons and boiling water. Radiation is different as it involves heat energy transmitted through empty space via electromagnetic waves, like the heat felt from a fire or candle flame.	"['See what happens when air is heated as you make and fly a huge hot-air balloon.\nSafety note: Use care when using the heat gun.\n- 30 sheets of tissue paper (22"" by 28"" each)\n- File folders or poster board\n- Hot air gun (note: hair dryers don\'t usually get hot enough)\n- Pipe cleaners\n- Glue stick\n- Pen or pencil\n- Template (PDF)\n- Make the template. You can glue file folders or poster boards together to make your template large enough. Cut out the template along the dotted lines.\n- Glue sheets of tissue paper together to make 10 panels that measure 7 feet by 22 inches. You\'ll need three sheets of paper for each panel, glued along the 22-inch edges.\n- Stack all 10 panels on top of each other. Put the template on top and trace around it (a pencil works best because the tissue paper is so thin). Cut out all 10 layers at once.\n- Slide the top panel on the pile about a half inch to the left. A portion of the second panel will be showing. Carefully fold the portion of the second panel that\'s showing over the edge of the top panel. Glue the panels together along this edge.\n- Now slide the attached first and second panels about a half inch to the right, the opposite way you slid the first panel. Fold the portion of the third panel that\'s showing over the edge of the second panel and glue them together. BE CAREFUL NOT TO GLUE PANEL THREE TO THE FREE EDGE OF THE TOP PANEL. The left edge of the top panel must remain free.\n- Continue sliding, folding and gluing each panel. Alternate sliding the panels to the left, then the right, creating an accordian fold as you glue the panels together. Continue until the only free edges are on the first and 10th panels.\n- Glue the edges of the first and 10th panels together.\n- Gather about 6 inches of the top of the balloon (the pointy ends) and tie them securely together with string.\n- Use the pipe cleaner to make a loop that will fit in the base of the balloon. Secure the loop in the base of the balloon by folding about an inch of tissue over the loop and using glue or pieces of tape to hold the loop in place.\n- Use a hot air gun to inflate the balloon. (Hair dryers don\'t usually get hot enough.) As the balloon is inflating, look for and glue any gaps that may appear in the seams. Clear tape can also be used to patch small holes. Safety note: Use care when using the heat gun.\nWhen the air inside the balloon is heated, the molecules in the air begin to move around and spread out, and the air becomes less dense. The surrounding, colder air falls beneath the hot air. This forces the warm air upward, which pushes the balloon up with it. The moving warm air creates a convection current.\nAir or liquid moving from place to place while carrying heat\nThe movement of the molecules that make up an object\nThe more thermal energy an object has, the faster its molecules move. These moving molecules bump into each other more often as the thermal energy increases. Imagine children standing in a sandbox. If they begin bumping into each other, they will spread out and require more space. This is what happens when molecules get more energy and start moving around – they spread out, thus decreasing the density of the substance.\nConvection is one of the ways heat is transferred from place to place. Convection is the transfer of heat by the movement of warmed matter, especially liquids and gasses. As a liquid or gas moves from one location to another, it carries heat along with it in a convection current. Due to their lower density, heated fluids (such as water or air) rise and cooled fluids fall. When air is heated, the molecules in the air begin to spread out and the air becomes less dense than the surrounding air. The more dense air falls beneath the hot air, forcing the warm air upward.', 'You are watching: The movement of energy from a warmer object to a cooler object is called\nan ext Career Education\nmore Prof Development\nbeer-selection.com-TV is operated by the Utah education and learning Network. Our score is come educate, engage, and enrich the stays of Utah occupants through broadcast programs and also services.\nThe Utah education Network (beer-selection.com) uses various systems and tools to deliver distance education classes come Utah students.\nOperations facility 801-585-7440Staff Directory\nbeer-selection.com security Office 801-585-9888\nTechnical services Support center (TSSC) 800-863-3496 staff Directory\nEccles Broadcast center 101 Wasatch drive Salt Lake City, UT 84112 (800) 866-5852 (801) 585-6105 (fax)\nAdministration (801) 585-6013 Org Chart\nInstructional services (800) 866-5852 Org chart\nPublic info (801) 585-7271 Logo and Guidelines\nTechnical services (800) 863-3496 Org graph\nForce, Energy, & activity - Modeling warmth Movement\nHeat is in consistent motion. It operation from warmer locations to colder areas until an all at once equal temperature is established. Heat moves indigenous one location to an additional in 3 ways. The movement of warm from a warmer object to a cooler one is dubbed heat transfer. There space three techniques of heat transfer: conduction, convection, and radiation.Conduction is the activity of heat power through a problem or from one substance to one more by direct contact of atoms and molecules. Warm moves directly from one molecule come another. The warmth energy accelerates the movement of the atoms and also they collide with other molecules setup them into faster motion. This goes on till all the molecules are moving approximately faster and also the entire object becomes hot. What you feel is warm moving follow me the thing from the resource to the end. Have actually you do a cup of hot chocolate? together the hot cacao sits in the mug the mug starts to gain hotter. If you leaving a metal spoon in the cup it will acquire hotter too. Whereby will the spoon acquire hot first? where will it be the coolest? What will happen to the spoon after some time if it is left in the cup? have the right to you think of other examples of conduction? Think about heat transport through another substance.\nHot wait balloons usage this rule to lift turn off the ground. The air in the balloon is less thick than the bordering air and rises come lift the balloon turn off the ground.\nWater is additionally heated through convection. Once water is cook in a pan, the water near the burner is cook first. The heat causes the water come expand, it i do not care lighter, and it rises come the peak of the pan. The heavier, chillier water near the optimal sinks down, pushing up the warm water. This proceeds until every the water is evenly heated. You can see the route of a convection present if you watch spaghetti food preparation in a pot of cook water. The spaghetti will relocate in a one path approximately the edge of the pot as the water boils.\nRadiation is heat energy transmitted with empty room or heating the empty room by electromagnetic waves or infrared rays. This process involves only the molecule of the\nOther familiar forms of warmth transfer by radiation encompass the heat you deserve to feel about an open fire or a candle flame, the warm near a hot stove, and the heat provided off by an electric heater.\nYou deserve to model the movement of molecules as heat energy moves in the adhering to activity.\nMaterials:Inflated sphere Chairs team of friends\nProcedure:One human represents the original heat source and stands in ~ one end of the room. The goal every time is to role the inflated ball (heat energy) to a girlfriend standing at the opposite finish of the room. Trial #1: have actually nothing in the way between the heat source and the person getting the heat energy. Is there too lot of a challenge in getting the inflated round (heat energy) to the person acquiring the heat energy? Trial #2: have actually other world line up in between the heat source and the person getting the warmth energy. Each human in the line passes the round to the person behind him/her. Trial #3: relocate other objects (chairs or desks) in between the heat source and the person getting the warm energy.\nSee more: Mixed Number 48/9 As A Mixed Number ? Convert To A Mixed Number 48/9\nAnalysis:Which an approach of moving the heat energy was the easiest? What kind of warm transfer did that represent? Which technique of moving the heat energy was the many difficult? What type of warmth transfer did the represent?\nHighlight the box listed below to examine your answers.']"	['<urn:uuid:fee8a1ed-eff3-4fee-a63a-366054b859cf>', '<urn:uuid:50c1c9f9-74b0-491d-b397-20539de5ae5c>']	open-ended	direct	long-search-query	distant-from-document	multi-aspect	novice	2025-05-13T04:02:16.770989	9	104	1494
23	How do cyclocross racers and Oxford rowers prepare mentally for races?	Both sports require different mental preparation approaches. For cyclocross, the focus is on minimizing pre-race anxiety through thorough preparation and routines. For Oxford rowers, they stay open with teammates about feelings, keep nerves in check, watch previous races to build knowledge, talk to alumni about their experiences, and focus on controlling what they can control. Both sports emphasize the importance of psychological readiness alongside physical preparation.	['In the just-released Issue 14, our regular contributors all chipped in with advice for a piece on 25 Things to Do on Raceday (and Robbie Carver threw in his own, more lighthearted, race essentials list, which included such things as pre-vomiting). Now Rhonda Morin, Cat 1 ’crosser, Masters Nationals bronze medalist and coach with Wenzel Coaching, adds her own call for preparedness and contributes a couple of valuable lists of her own below–perfect for the newbies and experts alike.\nby Rhonda Morin, EMT\nPreparation prevents poor performance. The more you can convert your race prep into routines, and the more you can take care of in the days before an event, the less stress you’ll have in the final hours before the race and the better you’ll perform. This article provides tips on what you can do to prepare for the race before you get to the venue, thereby freeing your mind so you can concentrate on having an excellent race.\nCleaning your bike after each race cuts down on wear and tear on your bike, provides an opportunity to identify and correct mechanical problems and also eliminates one more thing to do the day before the next race. I’m usually still in race mode when I get home after an event, so after I’ve had my recovery meal and a bit of relaxation time with my legs up to jump-start my recovery, I make it a point to put my bike on the stand and begin cleaning.\nUsing a mild soap – such as dish soap – in a bucket of warm water, I use a soft bristle brush, like one you would wash your car with, for my frame and wheels, and a separate brush for the greasy stuff, like the chain and drive train. Don’t use the same brush on the wheels as you would for the chain, because greasy wheels will break down the rubber on your brake pads and make your rims slippery. As a general rule, it is best to keep brushes and rags separate. Keep a grease rag/brush container, and a non-grease container in your garage or workspace.\nMake sure grit, sand and mud are removed from your chain, drive train, pulleys and cassette. Do this with a rag and/or a stiff brush such as a Park Tool Gear Cleaning Brush. This will ensure that you will start your next race with a smooth sounding chain and not one that’s crunchy. Once the chain is cleaned, apply a lube that is specific for the sorts of conditions in which you race, and wipe off the excess. Also, wipe off the brake pads and rims. Use a toothbrush to reach the grooves in the brake pads. Get into the habit of at least doing these steps after each race and your bike will perform much better.\nThe day before the race is the time to pack your bag. I generally keep a ready-go bag packed all the time, which saves time and keeps me from forgetting important articles of clothing.\n- Socks: tall socks or thermal socks for cool weather\n- Knee warmers\n- Leg warmers\n- Arm warmers\n- Vest, Racing jersey, and shorts or skinsuit\n- Full-length tights\n- Short-sleeve or long-sleeve undershirt\n- Booties or thermal shoe covers\n- Wind shoe covers\n- Rain jacket & pants\n- Team jacket\n- Three kinds of gloves (so you can decide which to use when you get to the venue). These can include: fingerless gloves, thin gloves for mild weather, thermal gloves for cold.\n- Cycling cap that fits under a helmet\n- Wash wipes\n- Energy gels & bars (3 or 4 of each)\n- Electrolyte tablets for bottles (Nuun, Hammer Fizz)\n- Racing license\n- Pre-filled-out rider release form\n- Safety pins\n- Race number (previously pinned to jersey/skinsuit, if available)\n- Plastic trash bags (for muddy, wet clothes)\n- Toilet paper\nDay Before Packing\nThe day before the race, I do a head-to-toe check. Starting with my head, I make sure these items are in my bag: helmet, sun glasses, headband or hat, undershirt, racing jersey and shorts or skinsuit, arm and leg warmers, socks and cycling shoes. Then I also pack post-race casual clothing and podium wear – because I’m always hopeful.\nThe night before the event, I’ll make lunch and prepare the dry ingredients for the bottles and recovery drink. I generally don’t fill the bottles until the morning, because I find the taste of plastic is too strong if they set overnight.\nThe bike usually goes into the car the night before, as well as several other items.\n- Racing glasses with lens options\n- Heart rate monitor\n- Bike pump\n- Extra wheels or pit bike\n- Tool box\n- Foldable chair\n- Square of flat foam or faux grass (to stand on while changing clothes)\n- Bucket with a brush, chain lube and rags\n- Trainer or rollers\n- Cell phone\n- Race flyer and directions\n- Money: cash, or check (most races don’t take credit cards)\nDay of Must Have\nNow that I’m mostly packed, there is only the anxiety of the race to worry about. Get up in plenty of time to eat a regular breakfast anywhere from 30 minutes to three hours before your race. You’re less apt to have stomach distress when your stomach is empty while racing. But you’ll have to experiment with this one to see what works best for you.\nRace day is not the day to try something new. Eat what you normally would, such as eggs, toast, juice; oatmeal and a banana; or cereal. Drink your coffee or tea if that’s your normal routine, but just be aware that coffee and tea are diuretics and may cause you to have to stop at the bathroom once or twice on the way to the race or at the race venue. Drink water during breakfast and pack a gallon of water for the day, as well as a bottle to sip on during the drive. It only makes a small difference, but avoid eating or drinking sweet, high-glycemic stuff during breakfast or before you warm up. In a sport where seconds can matter, small differences can be important.\nFill your race bottles and recovery drink bottle, put your lunch on an ice pack in a lunch pail, and head to your car. Before you drive off do one more head-to-toe check. Helmet, glasses, jersey shorts, shoes … if you have them all, you are ready to go.\nMake it a point to stop and use the restroom at a restaurant or gas station before you get to the venue. The lines will be much shorter, saving valuable time for reconnoitering the course and warming up.\nIt’s best to arrive at the venue at least two hours in advance of your race in order to have time to get your number or register, pin the number on your jersey (which always takes longer than you think), get your pit wheels or bike into the pit, talk with your friends or teammates (which can also consume a lot of time), and wait in line at the Honey Buckets. Plan accordingly, and assume driving will take a bit longer than you expect. Your buddy may need an extra coffee stop, the lights may all be red, and road construction could be out in force.\nIf the course is open for a pre-ride, take an easy lap first so you can see where the tricky parts are and get a sense of what tire pressure is best, then do one or two more laps, with the last one being at race pace or just under, so you can get a sense of how you’ll respond to the course.\nIf you can’t get onto the course, walk some of it and watch how others handle a barrier or tricky corner and decide which lines look best.\nReturn to your bike and do your warm up on the trainer if you didn’t get to ride the course. Try to shoot for at least 40 minutes to 60 minutes of warm up, finishing with some short bursts of race-pace effort – this is another reason why you want to get to the venue two hours before, so you get a proper warm up. If you’re a Wenzel client, you should use the Super Warm Up. Be drinking fluids the whole time, switching from water to exercise drink after about 20 minutes of riding. Try to drink at least a bottle between arrival and racing.\nOnce warmed up, change out of your sweaty clothes and into a race jersey and warm jacket. Eat a GU or something with simple sugars in it to give you a boost, drink one last gulp and head to the start with 10 to 15 minutes to go so you get a good position.\nKeep your jacket on while you wait at the start line. There’s plenty of time during the call-up to get to your start position and then throw your jacket to the side or pass it to a spectator. I sometimes wear an old jacket to the line that I don’t care much about in case I can’t find it later. But generally, people will leave your stuff alone and you can grab it after your race.\nNow that you’re fueled and you’ve kept your morning-of packing preparations to a minimum, you are ready to have the best race of your season. Now go have some fun.\nRhonda Morin, EMT, is a Wenzel coach who specializes in helping people excel at cyclocross and long- distance running. She’s a Cat 1 cyclocross rider and national bronze medalist in the Master’s women’s category who has more than 20 years experience in competitive cycling and running. She can be reached at [email protected]', 'Rowing for Oxford – The Dark Blues’ presidents reflect on the coming race\nThe annual Oxford vs. Cambridge Boat Race, which will take place this Sunday 7th April, is perhaps the most widely watched university sporting event in Britain, drawing around a quarter of a million spectators to the banks of the Thames each year. Competition for one of eight seats and one coxswain position in each of the four boats (Men’s and Women’s Blue boats as well as the second boats, Isis and Osiris) has been incredibly tight and the Boat Race marks the culmination of each team’s training since last September. As preparations for both the 165th Men’s and 74th Women’s Boat Race head into their final few days, The Oxford Student spoke to two rowers as they prepare to take to the water. Eleanor Shearer, the OUWBC President, is returning to cox the Women’s Blue Boat, having coxed for the Women’s Blues in 2017 and Osiris in 2018. Felix Drinkall, the OUBC president and junior world champion, will row for the Men’s Blue Boat at number 6. 2019 is his second year in the Blue boat.\nHow long have you been rowing and how did you get into it?\nEleanor: I started rowing in 6th Form in 2012. I have always liked outdoor sports, and also have always loved being in or around water, whether it’s rivers, lakes or the sea, so rowing seemed like a good pick. I really enjoyed being in boats right away, and knew when I came to Oxford that I wanted to continue. However, because I had accepted I probably wasn’t going to get any bigger (I’m 5’3 and about 50kg) I knew that switching to coxing would be the best way for me to compete at a higher level.\nFelix: I have been rowing since January 2014. I started at school and enjoyed a fun introduction to rowing, the goal of which was to make sure people had fun whilst doing the sport and provide the passion for being in a boat. I made a lot of friends and enjoyed being on the water so it was an easy step to make to start taking it more seriously and to try and win races. It’s that enjoyment of being in a team and pushing yourselves together that makes the whole process very fulfilling.\nWhat sort of preparation and training are you doing for the race?\nEleanor: At the moment, we are staying in London and training on the river twice a day. The rows this week are shorter than they would usually be – around an hour as opposed to more like an hour and a half – because we want to keep people fresh for the race on Sunday.\nFelix: The Boat Race is pretty unique in the rowing world in terms of its distance and unpredictability which makes it an interesting race to prepare for. Ultimately it’s a very long race, so we work on our fitness and technical efficiency daily to give us the best chance of going fast on the day. In the Boat Race you need strength to start the race and endurance to finish it, so we primarily use weights and indoor rowing machines to train both areas of physiology.\nHow about psychologically?\nEleanor: Psychologically, we just try to be really open with each other about how we’re feeling and help each other keep our nerves in check and focus on delivering the best possible performance at the weekend.\nFelix: The unpredictability of the race makes it a very fun event to be part of. You’ve got to be ready for every situation. We’ll watch previous years’ races in order to build up knowledge of racing on the tideway and of what can happen in a race. We’ll speak to alumni about their races in order to build up a bank of experiences. Primarily though we will look to control the controllables, we’ve found that this gets the best response from our crew.\nDoes last year’s race impact on this one or does each year feel separate?\n(Cambridge won all four races in 2018.)\nEleanor: My experience every year has been pretty different, but that’s partly because between 2017 and 2018 we got a new coach. This year, having the same coach as last, I’ve definitely noticed similarities. But it never feels like the result from last year means much – the clubs on both sides usually have a fair amount of turnover year to year so each season feels like a bit of a fresh start.\nFelix: We take experience from the years that have been and gone to make sure that we are better prepared for certain situations and so that we continue to improve as a programme. However, each year is its own project and the results in previous years have very little bearing on any future results. We have a number of people with a great deal of experience within the OUBC, whether that be in the Blue Boat or in our second boat ‘Isis’. However, of the 18 people who competed for both Oxford and Cambridge in last year’s Men’s Boat Race only 3 have returned for this year’s race. That stat alone tells you how different this race is.\nHow does it feel to be part of such a big sporting tradition?\nEleanor: It feels incredibly special to be a part of the Boat Race, especially the Women’s Race. I am always acutely aware of all the incredible women that came before me and paved the way for the women’s race to be able to be on the same platform as the men, and it’s great to feel connected to that history. Every year, before the race, when we stay in London, alumni from as far back as the 1970s will send cards and letters wishing us luck, which is a great reminder of how many people there are behind us.\nFelix: It’s a huge privilege to be entrusted to represent OUBC this year. For most of the season you can forget how big the race truly is and the impact that it has had on people’s lives. Only really through meeting and talking to alumni do you realise the enormity of it all. However, the size and history of the event doesn’t affect our one objective: to win a rowing race.\nThe Women’s Boat Race will start from Putney at 2.13pm this Sunday, followed by the Men’s at 3.10pm. Both races will be covered by BBC1 and BBC5Live Radio.']	['<urn:uuid:86a09b9f-8748-41ef-9520-6e315a717bcb>', '<urn:uuid:ae621140-d0ba-4db8-94fc-279b27e5f97a>']	open-ended	direct	concise-and-natural	similar-to-document	comparison	novice	2025-05-13T04:02:16.770989	11	66	2733
24	difference between exact inexact numeric types postgresql database management	The main difference lies in their precision handling. Numeric and decimal types are exact numeric types that can store numbers with practically unlimited size and precision, making them ideal for monetary amounts where exactness is required, though they are slower. In contrast, real and double precision are inexact, variable-precision numeric types, typically implementing IEEE 754 binary floating point. The real type has a range of at least -1E+37 to +1E+37 with at least 6 decimal digits precision, while double precision ranges from about -1E+308 to +1E+308 with at least 15 digits precision.	"['PostgreSQL has a rich set of native data types available to users. Users may add new types to PostgreSQL using the CREATE TYPE command.\nTable 3-1 shows all general-purpose data types included in the standard distribution. Most of the alternative names listed in the ""Aliases"" column are the names used internally by PostgreSQL for historical reasons. In addition, some internally used or deprecated types are available, but they are not listed here.\nTable 3-1. Data Types\n|bigint||int8||signed eight-byte integer|\n|bigserial||serial8||autoincrementing eight-byte integer|\n|bit||fixed-length bit string|\n|bit varying(n)||varbit(n)||variable-length bit string|\n|boolean||bool||logical Boolean (true/false)|\n|box||rectangular box in 2D plane|\n|character(n)||char(n)||fixed-length character string|\n|character varying(n)||varchar(n)||variable-length character string|\n|cidr||IP network address|\n|circle||circle in 2D plane|\n|date||calendar date (year, month, day)|\n|double precision||float8||double precision floating-point number|\n|inet||IP host address|\n|integer||int, int4||signed four-byte integer|\n|interval(p)||general-use time span|\n|line||infinite line in 2D plane|\n|lseg||line segment in 2D plane|\n|numeric [ (p, s) ]||decimal [ (p, s) ]||exact numeric with selectable precision|\n|path||open and closed geometric path in 2D plane|\n|point||geometric point in 2D plane|\n|polygon||closed geometric path in 2D plane|\n|real||float4||single precision floating-point number|\n|smallint||int2||signed two-byte integer|\n|serial||serial4||autoincrementing four-byte integer|\n|text||variable-length character string|\n|time [ (p) ] [ without time zone ]||time of day|\n|time [ (p) ] with time zone||timetz||time of day, including time zone|\n|timestamp [ (p) ] without time zone||timestamp||date and time|\n|timestamp [ (p) ] [ with time zone ]||timestamptz||date and time, including time zone|\nCompatibility: The following types (or spellings thereof) are specified by SQL: bit, bit varying, boolean, char, character, character varying, varchar, date, double precision, integer, interval, numeric, decimal, real, smallint, time, timestamp (both with or without time zone).\nEach data type has an external representation determined by its input and output functions. Many of the built-in types have obvious external formats. However, several types are either unique to PostgreSQL, such as open and closed paths, or have several possibilities for formats, such as the date and time types. Most of the input and output functions corresponding to the base types (e.g., integers and floating-point numbers) do some error-checking. Some of the input and output functions are not invertible. That is, the result of an output function may lose precision when compared to the original input.\nSome of the operators and functions (e.g., addition and multiplication) do not perform run-time error-checking in the interests of improving execution speed. On some systems, for example, the numeric operators for some data types may silently underflow or overflow.\nNumeric types consist of two-, four-, and eight-byte integers, four- and eight-byte floating-point numbers and fixed-precision decimals.\nTable 3-2. Numeric Types\n|Type name||Storage size||Description||Range|\n|smallint||2 bytes||Fixed-precision||-32768 to +32767|\n|integer||4 bytes||Usual choice for fixed-precision||-2147483648 to +2147483647|\n|bigint||8 bytes||Very large range fixed-precision||-9223372036854775808 to 9223372036854775807|\n|decimal||variable||user-specified precision, exact||no limit|\n|numeric||variable||user-specified precision, exact||no limit|\n|real||4 bytes||variable-precision, inexact||6 decimal digits precision|\n|double precision||8 bytes||variable-precision, inexact||15 decimal digits precision|\n|serial||4 bytes||autoincrementing integer||1 to 2147483647|\n|bigserial||8 bytes||autoincrementing integer||1 to 9223372036854775807|\nThe syntax of constants for the numeric types is described in Section 1.1.2. The numeric types have a full set of corresponding arithmetic operators and functions. Refer to Chapter 4 for more information. The following sections describe the types in detail.\nThe types smallint, integer, bigint store whole numbers, that is, numbers without fractional components, of various ranges. Attempts to store values outside of the allowed range will result in an error.\nThe type integer is the usual choice, as it offers the best balance between range, storage size, and performance. The smallint type is generally only used if disk space is at a premium. The bigint type should only be used if the integer range is not sufficient, because the latter is definitely faster.\nThe bigint type may not function correctly on all platforms, since it relies on compiler support for eight-byte integers. On a machine without such support, bigint acts the same as integer (but still takes up eight bytes of storage). However, we are not aware of any reasonable platform where this is actually the case.\nSQL only specifies the integer types integer (or int) and smallint. The type bigint, and the type names int2, int4, and int8 are extensions, which are shared with various other RDBMS products.\nNote: If you have a column of type smallint or bigint with an index, you may encounter problems getting the system to use that index. For instance, a clause of the form... WHERE smallint_column = 42\nwill not use an index, because the system assigns type integer to the constant 42, and PostgreSQL currently cannot use an index when two different data types are involved. A workaround is to single-quote the constant, thus:... WHERE smallint_column = \'42\'\nThis will cause the system to delay type resolution and will assign the right type to the constant.\nThe type numeric can store numbers of practically unlimited size and precision, while being able to store all numbers and carry out all calculations exactly. It is especially recommended for storing monetary amounts and other quantities where exactness is required. However, the numeric type is very slow compared to the floating-point types described in the next section.\nIn what follows we use these terms: The scale of a numeric is the count of decimal digits in the fractional part, to the right of the decimal point. The precision of a numeric is the total count of significant digits in the whole number, that is, the number of digits to both sides of the decimal point. So the number 23.5141 has a precision of 6 and a scale of 4. Integers can be considered to have a scale of zero.\nBoth the precision and the scale of the numeric type can be configured. To declare a column of type numeric use the syntax\nThe precision must be positive, the scale zero or positive. Alternatively,\nselects a scale of 0. Specifying\nwithout any precision or scale creates a column in which numeric values of any precision and scale can be stored, up to the implementation limit on precision. A column of this kind will not coerce input values to any particular scale, whereas numeric columns with a declared scale will coerce input values to that scale. (The SQL standard requires a default scale of 0, i.e., coercion to integer accuracy. We find this a bit useless. If you\'re concerned about portability, always specify the precision and scale explicitly.)\nIf the precision or scale of a value is greater than the declared precision or scale of a column, the system will attempt to round the value. If the value cannot be rounded so as to satisfy the declared limits, an error is raised.\nThe types decimal and numeric are equivalent. Both types are part of the SQL standard.\nThe data types real and double precision are inexact, variable-precision numeric types. In practice, these types are usually implementations of IEEE 754 binary floating point (single and double precision, respectively), to the extent that the underlying processor, operating system, and compiler support it.\nInexact means that some values cannot be converted exactly to the internal format and are stored as approximations, so that storing and printing back out a value may show slight discrepancies. Managing these errors and how they propagate through calculations is the subject of an entire branch of mathematics and computer science and will not be discussed further here, except for the following points:\nIf you require exact storage and calculations (such as for monetary amounts), use the numeric type instead.\nIf you want to do complicated calculations with these types for anything important, especially if you rely on certain behavior in boundary cases (infinity, underflow), you should evaluate the implementation carefully.\nComparing two floating-point values for equality may or may not work as expected.\nNormally, the real type has a range of at least -1E+37 to +1E+37 with a precision of at least 6 decimal digits. The double precision type normally has a range of around -1E+308 to +1E+308 with a precision of at least 15 digits. Values that are too large or too small will cause an error. Rounding may take place if the precision of an input number is too high. Numbers too close to zero that are not representable as distinct from zero will cause an underflow error.\nThe serial data types are not truly types, but are a notational convenience for setting up unique identifier columns in tables. In the current implementation, specifying\nCREATE TABLE tablename ( colname SERIAL );\nis equivalent to specifying:\nCREATE SEQUENCE tablename_colname_seq; CREATE TABLE tablename ( colname integer DEFAULT nextval(\'tablename_colname_seq\') UNIQUE NOT NULL );\nThus, we have created an integer column and arranged for its default values to be assigned from a sequence generator. UNIQUE and NOT NULL constraints are applied to ensure that explicitly-inserted values will never be duplicates, either.\nThe type names serial and serial4 are equivalent: both create integer columns. The type names bigserial and serial8 work just the same way, except that they create a bigint column. bigserial should be used if you anticipate use of more than 231 identifiers over the lifetime of the table.\nImplicit sequences supporting the serial types are not automatically dropped when a table containing a serial type is dropped. So, the following commands executed in order will likely fail:\nCREATE TABLE tablename (colname SERIAL); DROP TABLE tablename; CREATE TABLE tablename (colname SERIAL);\nThe sequence will remain in the database until explicitly dropped using DROP SEQUENCE. (This annoyance will probably be changed in some future release.)\nWhen you are looking for the ENUM(....) statement in PostgreSQL as the one in MySQL, remember that you must use the ANSI \'CHECK\' command to do the same.\ncreate table order (\nordertype enum ( \'MAIL\',\'SHOP\',\'PHONE\',\'FAX\') default \'SHOP\',\nUse the following instead:\ncreate table order (\nordertype char(8) default \'SHOP\',\ncheck (ordertype in ( \'MAIL\',\'SHOP\',\'PHONE\',\'FAX\')),\n.... (OTHER CONSTRAINTS)\nGood luck, it want easy to find the solution!.\nWolter Smit, France.\nTo Darker, RE can\'t set the starting sequence number:\nSELECT setval(\'functest_seq\', 100);\nThis will set the sequence \'functest_sqe\' to the value 100. Good luck.\nwhen you insert to a table where is a serial type just skip that field:\nCREATE TABLE a (\nINSERT INTO a (...) VALUES (...);\n(I don\'t mentioned the field ""b"")\nOne way to insert a key with serial datatypes as the key is to use the following INSERT INTO syntax.\nHere is the table schema I have used, note that the default value for the promary key points to a SEQUENCE named project_projectnumber_seq:\nColumn | Type | Modifiers\nprojectnumber | integer | not null default nextval(\\\'project_projectnumber_seq\\\'::text)\nstreetaddress | character varying(50) |\ncity | character varying(30) |\nstate | character varying(30) |\ncountry | character varying(30) |\npostalcode | character varying(30) |\nstartdate | date |\nenddate | date |\ndescription | character varying(2000) |\nPrimary key: project_pkey\nI then used the following INSERT INTO:\nINSERT INTO project (streetaddress, city, state, country, postalcode, startdate, enddate, description) VALUES (\\\'21 Newport Ave\\\', \\\'Imbler\\\', \\\'Oregon\\\', \\\'USA\\\', \\\'97841\\\', \\\'2003-09-01\\\', \\\'2003-10-31\\\', \\\'Build a new house at this address\\\');\nThe primary key is not specified, since it will automatically take the value of the next number in the sequence.']"	['<urn:uuid:5a946d7d-4c2f-46ff-bb17-eb1d1964a6d8>']	open-ended	direct	long-search-query	distant-from-document	single-doc	expert	2025-05-13T04:02:16.770989	9	92	1844
25	what department protects us voting rights enforcement	The Department of Justice Civil Rights Division works at the federal level to protect voting rights and enforces federal statutes that protect the right to vote. The Division evaluates its enforcement tools, including litigation, and monitors elections throughout the country to ensure compliance with federal voting rights laws.	['Statement on Ensuring Equal Enjoyment of Rights at HDIM Working Session 4\nAs prepared for delivery by Ambassador Michael Kozak, Head of Delegation\nSeptember 13, 2017\nThe ability of the individual to participate in political life is critical to democratic development, good governance, and stability. Participation encompasses a wide range of activities, from platforms for private citizens to comment on proposed legislation at the local level, to running for high office. Barriers to participation reduce social cohesion and can engender dislocation or even radicalization to violence. It is incumbent upon all participating States to address these barriers.\nIn the United States, most election law is governed by state and local authorities, which provide crucial oversight and protection for elections in their jurisdictions. That protection is supplemented by the Department of Justice Civil Rights Division, which works at the federal level to protect the civil and constitutional rights of all Americans. In particular, the Civil Rights Division enforces federal statutes that protect the right to vote. The Division regularly evaluates its enforcement tools, including litigation, to ensure that the Division is meeting current challenges.\nProtecting the voting rights of all Americans includes protecting against discrimination in voting based on race or need for language assistance, and protecting voting access for service members serving away from home as well as American citizens living abroad. We also have strong legal guarantees to ensure voting rights for persons with disabilities. Polling stations are required to be accessible and include specialized equipment to assist voters.\nVoter enfranchisement and election integrity are subjects of robust debate in the United States. The Civil Rights Division actively monitors elections for compliance with federal law. In the November general election, the Division coordinated the deployment of more than 500 personnel to monitor elections in 67 jurisdictions in 28 states for compliance with the federal voting rights laws. The Division monitors elections throughout the country and throughout each year to ensure compliance with the federal voting rights laws. No voting system is perfect, so it is incumbent upon all of us to constantly reevaluate our policies and procedures to ensure best practices are incorporated.\nFor American citizens who wish to run for office, the various procedures and requirements are generally modest. Although only natural-born U.S. citizens are eligible to be President, naturalized U.S. citizens are eligible for all other elected positions in the federal government. Candidates are often not required to have political party affiliation or support in order to run for office, whether local or national, so barriers to participation are low.\nIn addition, few legal restrictions exist to joining or starting political parties or affiliated organizations, including NGOs, news or opinion outlets, or others. America’s NGOs cover a wide swathe of political and social issues, and provide opportunities to voice political opinions or take part in activism on any issue. Journalists publish opinions on-line and in print, adding to the multi-faceted political discussion that characterizes America.\nThere is no perfect system that guarantees one hundred percent participation in all political processes. We make every effort to ensure that the highest number of citizens can easily and meaningfully participate in our political processes. We also assess our efforts on a regular basis to ensure that Constitutionally-guaranteed protections for political participation are adequate and meet the needs of our dynamic population.']	['<urn:uuid:6c370617-9fc7-41c7-9532-a2f4117c6b11>']	open-ended	direct	short-search-query	similar-to-document	single-doc	expert	2025-05-13T04:02:16.770989	7	48	551
26	I need to replace my old light fixtures but I'm confused about which type to get - are ceramic light sockets better than plastic ones for handling heat?	Yes, ceramic light sockets are better than plastic ones for handling heat. Ceramic sockets are more reliable and their sturdy build allows them to survive high temperatures, typically featuring ratings as high as 300 watts. In contrast, cheaper plastic and paper-insulated sockets have lower ratings because they can't tolerate excess heat, typically only handling 60-75 watts.	['Electricians discourage overlamping. However, that hasn’t stopped consumers from using higher-wattage bulbs in lower-wattage fixtures. The reasons vary. Some people think higher-wattage bulbs are brighter. For others, higher-wattage bulbs are all they have on hand. The results depend on three factors, namely:\n1). Age of the Light Fixture\nOverlamping is dangerous because of the excess heat the practice generates. Light fixtures have wires that transmit the current. The Spruce expects a light fixture’s wires to tolerate roughly 90 degrees C.\nKeeping the temperature below the recommended threshold allows the wires to maintain their integrity and flexibility. Exceeding a wire’s maximum temperature will start a fire. Unfortunately, older light fixtures have weaker wiring with a lower temperature limit (60 degrees C). They are more likely to overheat and melt.\n2). Material of the Light Fixture\nCheaper, older light fixtures have plastic and paper-insulated sockets. They have lower ratings because they can’t tolerate excess heat (60 – 75W). Ceramic light sockets are more reliable. Their sturdy build allows the light fixture to survive high temperatures, which is why they typically feature ratings as high as 300 watts.\n3). Open VS Enclosed Light Fixtures\nIs the light fixture open or closed? Open light fixtures have higher watt ratings because of their superior ventilation. Even if their watt rating is lower, they can still tolerate higher-wattage bulbs because the open design allows the excess heat to dissipate.\nClosed, recessed fixtures are the opposite because the airtight structure allows the heat to accumulate. Therefore, matching these fixtures with a higher-wattage bulb is more likely to start a fire.\nWhat Does This Mean For A 75W Bulb In A 60W Fixture?\nOverall, it’s a bad idea. Overlamping creates three challenges:\n1). Overheating Sockets and Wires\nThis is your biggest problem. Electricity generates heat when it flows through a conductor. A higher-wattage bulb in a lower-wattage fixture (such as a 75W bulb in a 60W fixture) will melt the socket and insulation. If arcing occurs, the sparks could ignite the flammable materials in the vicinity, starting a fire and burning your house to the ground.\n2). Dead Light Fixtures\nThe light fixture won’t survive this catastrophe. You can’t fix a melted socket. The only option is to replace the light fixture, which introduces unnecessary expenses.\n3). Dead Light Bulb\nNaturally, the bulb will also fail, forcing you to replace it.\nThese are the worst-case scenarios. They are not the guaranteed outcome. You can install a 75W bulb in a 60W light fixture without starting a fire. People do this every day. Consider this discussion on the Anandtech forum, in which many members have admitted to using higher-wattage bulbs in lower-wattage fixtures.\nThey expect the bulb to blow earlier than expected. Nonetheless, they disagree with suggestions that a 75W bulb in a 60W light fixture can start a fire. You are better off taking the cautious approach.\nIf a fire starts because you added a higher-wattage bulb to a lower-wattage light fixture, your insurance company may reject your claim.\nThings To Consider Before Using 75 Watt Light Bulb In A 60 Watt Fixture\nMany people use 75W bulbs in 60W fixtures because they think a higher wattage translates into a brighter light. But that is a mistake. According to Larson Electronics, the wattage tells you the amount of power a bulb will consume. It doesn’t say anything about the brightness.\nDon’t assume that a 75W bulb is brighter than its 60W counterparts simply because the 75W bulb uses 15 additional watts. The lumens determine the brightness. A higher lumen rating equates to greater brightness. For instance, an 800-lumen light is brighter than a 450-lumen bulb.\n2). Bulb Type\nThe bulb type and lumen rating are closely related. You shouldn’t install a 75W incandescent bulb in a 60W fixture because they generate too much heat. Incandescent bulbs make light by heating a metal element.\nThis process produces visible light and non-visible radiation. It also wastes a lot of energy as heat. Therefore, a 75W incandescent bulb in a 60W fixture is more likely to melt the insulation and socket.\nLEDs are the opposite. They turn most of their energy into usable light. This allows them to remain cool. It also tells you two things:\n- A higher-wattage LED bulb in a lower-wattage fixture is less likely to overheat.\n- A 75W LED bulb doesn’t actually use 75 watts. The bulb’s rating is 9 to 13 watts, which falls significantly below a 60W light fixture’s rating.\nFrom what Superior Lighting has seen, CFL lights are less efficient than LEDs but far better than incandescent bulbs. A 75W CFL bulb uses 18 to 22 watts. But if that is true, why would a manufacturer place a ‘75W’ label on an 18 to 22W CFL bulb?\nBecause an 18 to 22W CFL light generates 1100 to 1300 lumens. But most people don’t know what lumens mean. Therefore, an 1100 to 1300-lumen rating means nothing to them. The 75-watt label tells a layperson that an 18 – 22W CFL bulb produces as much light as a 75W incandescent bulb.\nManufacturers use incandescent bulbs as a standard of measurement because most people have seen an incandescent bulb.\nIf you must use a 75W bulb in a 60W fixture, find a ‘75W Equivalent’ such as CFL and LED that uses 60 watts or less. 150W LEDs can work in a 60W light fixture without starting a fire.\n3). Bulb Quality\nYou can lower the risk of a 75W bulb by using an open 60W fixture. An open light fixture is less likely to overheat if you pair it with a higher-wattage bulb because an open design dissipates the excess heat.\nHowever, the quality matters. A higher-wattage bulb is more likely to overwhelm a low-quality light fixture. Try to limit your purchases to reputable brands.\n4). Bulb Distance From Light Fixture\nSome consumers gamble with higher-wattage bulbs because they want brighter lights. But you can increase the brightness by simply bringing the light fixture closer to your target. The highest lights are the dimmest.\nLowering a fixture’s height concentrates the light, which, in turn, makes the bulb seem brighter. Lowering a fixture’s height sounds like a lot of work, but it’s safer than using a higher-wattage incandescent bulb in a lower-wattage fixture.\nYou should also select a bright color temperature. For instance, while red and orange can improve a room’s appearance under the right conditions, these colors are not that bright. The same goes for blue.\nLook for color temperatures in the middle of the spectrum. White is your best option because it mimics the sun and enhances visibility regardless of the time of day or night. Interestingly, some LEDs have adjustable brightness and color temperature.\nDepending on your needs, you can increase or lower the brightness and switch back and forth between different colors.']	['<urn:uuid:bc6e0ff9-5adc-4eb5-9d57-7bf157046f67>']	factoid	with-premise	verbose-and-natural	similar-to-document	single-doc	novice	2025-05-13T04:02:16.770989	28	56	1139
27	How does the process of resolving a foul call work in Ultimate Frisbee when two players disagree about whether a violation occurred?	When a player believes they've been fouled, they call 'foul' and play stops immediately. The players involved then discuss the foul. If the opponent disagrees with the foul call, they can call 'contest' and the disc returns to the previous thrower. If they agree there was a foul, they call 'uncontested' and generally the fouled player takes possession of the disc. Play resumes with a 'check' where the marker touches the disc in the thrower's hand and calls 'disc in'.	['Each point starts with a throw-off from the goal line (“pull”). All players must remain in their end zone until the pull is thrown. At the start of the game a toss decides which team throws the first pull.\nAfter a goal is scored, play stops. The team that scored stays in that end zone and throws the pull and becomes the defensive team. So, teams change their direction of attack after each point.\nIn-bounds and out-of-bounds\nA disc is in-bounds when the receiving player is inside the playing field when they catch the disc. If you catch the disc after jumping in the air, your first point of contact must land inside the field. If you catch the disc in-bounds, and then momentum takes you out-of-bounds, you must return to where you left the field before you can throw the disc.\nYou are allowed to throw the disc so that it flies outside the playing field and then comes back in.\nIf the disc goes out-of-bounds, it is a turnover. It does not matter which team last touched the disc. Play continues from the spot where the disc left the field.\nNo running with the disc\nYou are not allowed to run while you have possession of the disc (“travel”). After catching the disc while running, you must stop as quickly as possible. Once you stop, you must keep one foot still, but you are allowed to move the other foot: this is called pivoting.\nThe 10-second rule\nThe thrower has 10 seconds to throw the disc. A defender can stand in front of you (remember: no contact!) and count aloud to ten in one second intervals. If the disc is still in your hand at the “t” of “ten”, the other team gets possession of the disc.\nThe defensive team takes possession of the disc (a “turnover”) if the offence fails to catch a pass, if they catch it out-of-bounds, or if it is intercepted or knocked down by a defensive player.\nTurnovers also occur when:\nthe marker reaches “ten” before the disc was thrown\nthe disc is handed from one player to another without being thrown\nthe thrower catches their own throw without the disc being touched by anyone else\nthe offensive team tries to catch the pull, but drops it\nAfter an in-bounds turnover the other team may immediately resume play at the point where the disc was caught or stopped.\nFouls, Violations and Infractions\nUltimate is a non-contact sport. Physical contact should always be avoided.\nContact that is dangerous or affects the outcome of the play is a Foul.\nThe thrower may not be defended by more than one player at the same time (“double team”).\nThe marker may not come closer than one disc diameter to the thrower (“disc space”).\nThe marker may not hit or grab the disc out of the hand of the thrower. They may however try to block the disc with their hands or feet after it is thrown.\nIf opposing players catch the disc at the same time, the offensive player gets possession of the disc.\nPlayers are not allowed to create shepherds, picks or screens to obstruct the path of defensive players (“pick”).\nMaking a Call\nIf you believe you have been fouled by an opposing player, you can call “foul”, and play stops immediately.\nAfter play stops, you explain what the foul was and discuss this with the other player involved. If the opponent disagrees that there was a foul, they may call “contest” and the disc is returned to the previous thrower. If they agree that there was a foul, they call “uncontested” and, generally, you take possession of the disc. Play is resumed with a “check”: the marker touches the disc in the thrower’s hand and calls “disc in”.\nYou score a goal if you catch the disc in the endzone that you are attacking. If you are in the air, your first point of contact must be in the endzone. The first team to 15 goals wins, with a time cap of 90 minutes, but this can change depending on the level of play.\nSubstitution of players\nAfter each point you may substitute as many players as you want.\nSPIRIT OF THE GAME\nUltimate relies upon a Spirit of the Game that places the responsibility for fair play on every player. There are no referees; the players are solely responsible for following and enforcing the rules, even at World Championship. Competitive play is encouraged, but never at the expense of respect between players, adherence to the rules, and the basic joy of play.']	['<urn:uuid:fef0f239-fb3d-4723-8caf-0548788f77df>']	factoid	direct	verbose-and-natural	similar-to-document	single-doc	expert	2025-05-13T04:02:16.770989	22	80	769
28	I'm curious about how psoriasis affects unborn babies - what are the risks for the baby during pregnancy?	Psoriasis can affect unborn babies through inflammation-related complications. The disease produces excess inflammatory substances (cytokines) that can cause problems with blood vessels in the placenta, potentially leading to low birth weight in infants. Additionally, women with psoriasis are more likely to have other conditions that can affect pregnancy, such as obesity, hypertension, and depression. These associated conditions can increase risks for various pregnancy complications, including premature birth, reduced Apgar scores, and smaller head circumference in babies.	"['Psoriasis and the Pregnant Woman: What are the Key Considerations?\nJennifer M. Landau, BS;1 Megan N. Moody, MD, MPH;1 Natalia Kazakevich, MD;2 Leonard H. Goldberg, MD, FRCP1,2,3\n1DermSurgery Associates, Houston, TX, USA\n2Department of Dermatology, Weill Cornell Medical College, The Methodist Hospital, Houston, TX, USA\n3Department of Dermatology, The University of Texas Medical School at Houston, Houston, TX, USA\nPregnancy is characterized by multiple physiologic changes. During the entire gestational period, both mother and infant are vulnerable to a variety of external and internal factors. Maternal disease, use of certain medications, drugs, alcohol, smoking, and radiation exposure can have devastating effects on the fetus. Pregnancy-related complications in women with psoriasis can be caused by both the disease and the treatment. The response of the maternal placenta to psoriasis-induced inflammation and comorbid conditions, such as obesity, hypertension, and depression, may also influence the pregnancy. Herein, we review the relationship between psoriasis and undesirable pregnancy outcomes.\ncomorbidities, complications, drug therapy, pregnancy, psoriasis, risk factors\nPregnancy is a unique physiologic state characterized by an array of significant changes in the endocrine, vascular, and respiratory systems. These changes facilitate fetal growth and development and prepare the woman\'s body for labor and delivery. During the first trimester of pregnancy (weeks 0-13), the developing embryo undergoes organogenesis and is especially susceptible to injury from systemic maternal diseases, medications, drugs, alcohol, and smoking. During this period many pregnant women are often unaware that they are even pregnant, and therefore do not actively minimize risks to the fetus.1 This may include women with chronic diseases, such as those with moderate to severe psoriasis, who require multiple drugs for treatment.\nPsoriasis is an autoimmune inflammatory skin disease with manifestations resulting from a complex interplay between genetics and the environment. The incidence of psoriasis is bimodal, with one peak between the ages of 15-30 years and a second between 50-60 years.2,3 The average age of diagnosis in women is 28, a prime age for pregnancy.3,4 Annually, there are approximately 65,000-107,000 births to women with psoriasis, of whom 9,000-15,000 have moderate to severe disease.2\nPsoriasis lesions are well-circumscribed, erythematous plaques with a fine silvery scale; they predominate on the scalp and extensor surfaces, yet can occur anywhere on the body; there may also be nail changes. The severity of the condition is determined by two major criteria: 1) the extent of body surface area (BSA) involved and 2) the location of the lesions (for example, if psoriatic plaques are present on the palms and soles, it is considered severe, regardless of percentage of BSA involvement). In general, mild psoriasis occurs when lesions are limited to < 3% BSA, moderate psoriasis with 3-10% BSA, and severe psoriasis with >10% BSA. Quality of life issues for the patient also determine severity. While mild psoriasis can typically be controlled with topical treatments, moderate to severe psoriasis may require systemic therapy.\nThe management of psoriasis in pregnant women is challenging, since the physician and patient must balance teratogenic risks associated with certain drug therapies to potential adverse pregnancy outcomes from uncontrolled skin inflammation and excess cytokines inherent with the disease process. There is very little data detailing the effects of psoriasis on pregnancy outcomes.2,4-6 Herein, we explore potential direct and indirect effects of psoriasis on pregnancy and the effects of pregnancy on psoriasis.\nDirect Effects of Psoriasis on Pregnancy\nIn general, inflammatory/autoimmune diseases such as rheumatoid arthritis, inflammatory bowel disease, systemic lupus erythematosus, and psoriasis have been shown to be associated with low birth weight (LBW), preterm birth, and abortions.5,7 Autoimmune inflammation in psoriasis results from dysfunctional T helper cells with a concomitant amplification of pro-inflammatory cytokines (most notably TNF-alpha, IL1 and IL6). Excess cytokines yield endothelial dysfunction with resulting systemic and placental vasculopathy through induction of platelet aggregation, intermittent vasospasm, and activation of the clotting system.5,8 Placental vasculopathy has been postulated to contribute to LBW infants.5 LBW is also a complication of preeclampsia, which is similarly associated with an activated inflammatory state and increased levels of the same cytokines seen in psoriasis (CRP, TNF-alpha and IL6).8-10 There is conflicting data regarding the correlation between psoriasis during pregnancy and infant birth weight.5-7 Yang et al studied 1,436 mothers with psoriasis compared to 11,704 mothers without psoriasis, and found that LBW was associated only with severe psoriasis (defined as any mother who had received photochemotherapy or systemic therapy within the 2 years prior to delivery).5 In contrast, Cohen-Barak et al analyzed 68 pregnant women, but found that mothers with moderate to severe psoriasis were more likely to give birth to large infants when compared with controls.7 This group found psoriasis to be associated with a higher risk for spontaneous and induced abortions, which is also seen in inflammatory conditions including rheumatoid arthritis and systemic lupus erythematosus.7\nIndirect Effects of Psoriasis on Pregnancy\nComorbidity Induced Adverse Effects\nThe stress associated with chronic, relapsing diseases may affect mental health, increasing the tendency for alcohol misuse, depression, weight gain, and smoking. Psoriasis is also associated with higher rates of comorbid systemic conditions including diabetes mellitus (DM), cardiovascular disease (atherosclerosis, congestive heart failure, and myocardial infarction), obesity, and metabolic syndrome (consisting of obesity, high blood sugars, high triglyceride levels, low high-density lipoprotein, and hypertension). Obesity and hypertension have been shown to be at least twice as common in patients with psoriasis.4,11 Pregnant women with psoriasis are more likely to be overweight/obese, depressed, smoke in their first trimester, and are also less likely to take prenatal vitamins or supplements.4\nBoth the comorbid conditions associated with psoriasis and the drugs used to treat them may be harmful to the developing fetus. Hypertension (HTN) is known to be associated with LBW secondary to placental insufficiency, perinatal mortality, and preterm delivery, in addition to increased risk for acute maternal morbidities.12 The drugs commonly used to treat HTN, such as angiotensin-converting enzyme inhibitors and angiotensin receptor blockers, can be teratogenic.13,14 DM is associated with increased neonatal mortality and multiple morbidities including, fetal macrosomia, post-natal hypoglycemia, and congenital malformations including transposition of the great vessels.15 Furthermore, pregnancy has been shown to hasten the progression of DM; healthy women may even develop diabetes only during pregnancy, which is known as gestational DM.15 Alcohol misuse may result in fetal alcohol syndrome and LBW. Maternal consequences of depression include inadequate weight gain, insufficient utilization of prenatal care, and increased substance abuse, whereas fetal consequences can include premature birth, LBW, decreased Apgar scores, and smaller head circumference.16 Obesity has been associated with macrosomia, low Apgar scores, and premature birth.4 Smoking may increase the risk for oral clefts and reduced birth weight.4\nTreatment Induced Adverse Effects\nLittle evidence exists to delineate the effects of psoriatic medications on human pregnancy due to ethical implications associated with investigating potentially teratogenic medications.1 General guidelines are based on retrospective data and on cases in which a woman may have used a questionable medicine without yet realizing she was pregnant. Mild psoriasis can usually be adequately treated with topical medications, while severe psoriasis may require systemic treatment. Limited amounts of topical preparations including corticosteroids, calcipotriene, coal tar, and anthralin appear to be safe. There is a low likelihood for significant systemic absorption with these topical preparations if used in conservative application patterns.1,5 The risk for potential teratogenicity increases in a dose-dependant manner as systemic absorption increases. The factors that increase systemic absorption include prolonged duration of treatment, large amounts of medication applied, a compromised epidermal barrier, and occlusion.1\nSystemic medications used for psoriasis unresponsive to topical therapies include acitretin, methotrexate, mycophenolate mofetil, and biologics such as adalimumab, alefacept, etanercept, infliximab, and ustekinumab. Most of the systemic antipsoriatic therapies are associated with significant toxic effects to the fetus and should be avoided during pregnancy. Acitretin (an oral retinoid) is strictly prohibited before or during pregnancy since it can cause a classic retinoid syndrome, consisting of well-characterized craniofacial, cardiac, thymic, and CNS malformations.1 Furthermore, acitretin can linger for over 2 months after the last dose, so patients should stop this drug months before attempting to conceive.1 Methotrexate is an antimetabolite that is associated with a specific constellation of prenatal growth deformities, including growth retardation, large fontanelles, craniosynostosis, ocular hypertelorism, micrognathia, limb abnormalities, and developmental delay; these effects are dose-related. Mycophenolate mofetil interferes with DNA and RNA synthesis, and case reports indicate that it can cause microtia or anotia, cleft lip/palate and heart defects. Systemic corticosteroids are not commonly used for psoriasis; however, they remain the best available treatment for a rare condition, known as impetigo herpetiformis, a form of pustular psoriasis seen in pregnancy.17 The side-effects of systemic steroids have mostly been studied in pregnant patients with asthma and they include orofacial clefts, intrauterine growth restriction, and suppression of the hypothalamic-pituitary axis.1 There is very limited data with regard to the biologics, but infliximab has been associated with congenital malformations in two infants and death in a third due to uncontrollable intracranial and pulmonary bleeding.1,18\nPhototherapy with broad-band (290-320 nm) ultraviolet B (UVB) and narrow-band UVB (311-312 nm) appear to be safe during pregnancy.1 The safety of systemic PUVA with psoralens is unknown, although mutagenic potential has been shown in rat studies; however, topical PUVA limited to small areas might be safe. Cyclosporin A in pregnant organ transplant recipients have failed to show an increased risk to the fetus1 and may therefore be an option in pregnant psoriatic patients.\nEffects of Pregnancy on Psoriasis\nPregnancy may influence the severity of psoriasis.6,19 In fact, psoriasis often improves during pregnancy. Boyd et al reported on a study of 90 women with psoriasis, who responded to a questionnaire regarding the condition of their psoriasis during pregnancy.6 Seventy-seven percent of these women noticed a change in their psoriasis, the majority of whom (63%) experienced improvement; within 4 months of giving birth, however, 88% of the women subsequently developed a ""post-partum flare"" of their psoriasis. Similarly, Murase et al found that 55% of women noted improvement in their psoriasis during pregnancy and 65% experienced worsening of their psoriasis post-partum.19 The patients with greater than 10% BSA who reported improvement during pregnancy noted that lesions decreased on average by 84%.19 Furthermore, the authors found that estrogen, but not progesterone, was associated with changes in psoriasis; they attributed the improvement in psoriasis to the high ratio of estrogen to progesterone.19 The authors hypothesized that the alterations in immunity (the immune response shifts from TH1 to TH2 dominance) due to hormonal changes in pregnancy, leads to the improvement in psoriasis, as previously shown in other TH1 mediated autoimmune diseases (i.e., rheumatoid arthritis and multiple sclerosis).19 While the exact mechanism is still not understood, it appears that psoriasis is more likely to improve than worsen during pregnancy with a post-partum flare.\nThe extent of the potential effects that psoriasis can have on pregnancy is variable. When possible, pregnant women should modify their behaviors and treatments to decrease any risk to themselves and their unborn children. Registries such as the International Psoriasis Council - project on pregnancy and psoriasis2 and the OTIS Autoimmune Diseases in Pregnancy Project4 are in the process of compiling more extensive data for this population. As data from these registries becomes more readily available, we will better understand the true implications of pregnancy on psoriasis and of psoriasis on pregnancy. Treatment plans can subsequently be developed that balance the risks from therapy versus the harmful effects of psoriasis and its associated comorbidities.\n- Lam J, Polifka JE, Dohil MA. Safety of dermatologic drugs used in pregnant patients with psoriasis and other inflammatory skin diseases. J Am Acad Dermatol 59(2):295-315 (2008 Aug).\n- Horn EJ, Chambers CD, Menter A, et al. Pregnancy outcomes in psoriasis: why do we know so little? J Am Acad Dermatol 61(2):e5-8 (2009 Aug).\n- Levine D, Gottlieb A. Evaluation and management of psoriasis: an internist\'s guide. Med Clin North Am 93(6):1291-303 (2009 Nov).\n- Bandoli G, Johnson DL, Jones KL, et al. Potentially modifiable risk factors for adverse pregnancy outcomes in women with psoriasis. Br J Dermatol 163(2):334-9 (2010 Aug).\n- Yang YW, Chen CS, Chen YH, et al. Psoriasis and pregnancy outcomes: a nationwide population-based study. J Am Acad Dermatol 64(1):71-7 (2011 Jan).\n- Boyd AS, Morris LF, Phillips CM, et al. Psoriasis and pregnancy: hormone and immune system interaction. Int J Dermatol 35(3):169-72 (1996 Mar).\n- Cohen-Barak E, Nachum Z, Rozenman D, et al. Pregnancy outcomes in women with moderate-to-severe psoriasis. J Eur Acad Dermatol Venereol 25(9):1041-7 (2011 Sep).\n- Guven MA, Coskun A, Ertas IE, et al. Association of maternal serum CRP, IL-6, TNF-alpha, homocysteine, folic acid and vitamin B12 levels with the severity of preeclampsia and fetal birth weight. Hypertens Pregnancy 28(2):190-200 (2009 May).\n- Redman CW, Sacks GP, Sargent IL. Preeclampsia: an excessive maternal inflammatory response to pregnancy. Am J Obstet Gynecol 180(2 Pt 1):499-506 (1999 Feb).\n- Sacks GP, Studena K, Sargent K, et al. Normal pregnancy and preeclampsia both produce inflammatory changes in peripheral blood leukocytes akin to those of sepsis. Am J Obstet Gynecol 179(1):80-6 (1998 Jul).\n- Henseler T, Christophers E. Disease concomitance in psoriasis. J Am Acad Dermatol 32(6):982-6 (1995 Jun).\n- Hutcheon JA, Lisonkova S, Joseph KS. Epidemiology of pre-eclampsia and the other hypertensive disorders of pregnancy. Best Pract Res Clin Obstet Gynaecol 25(4):391-403 (2011 Aug).\n- Podymow T, August P. Antihypertensive drugs in pregnancy. Semin Nephrol 31(1):70-85 (2011 Jan).\n- Rakusan K. Drugs in pregnancy: Implications for a cardiologist. Exp Clin Cardiol 15(4):e100-3 (2010 Winter).\n- Tieu J, Middleton P, Crowther CA. Preconception care for diabetic women for improving maternal and infant health. Cochrane Database Syst Rev (12):CD007776 (2010).\n- Marcus SM. Depression during pregnancy: rates, risks and consequences-- Motherisk Update 2008. Can J Clin Pharmacol 16(1):e15-22 (2009 Winter).\n- Oumeish OY, Parish JL. Impetigo herpetiformis. Clin Dermatol 24(2):101-4 (2006 Mar-Apr).\n- Srinivasan R. Infliximab treatment and pregnancy outcome in active Crohn\'s disease. Am J Gastroenterol 96(7):2274-5 (2001 Jul).\n- Murase JE, Chan KK, Garite TJ, et al. Hormonal effect on psoriasis in pregnancy and post partum. Arch Dermatol 141(5):601-6 (2005 May).\nIn this issue:\n- Psoriasis and the Pregnant Woman: What are the Key Considerations?\n- Newer Approaches in Topical Combination Therapy for Acne\n- Update on Drugs and Drug News - October 2011']"	['<urn:uuid:6c047572-7e81-475b-85e2-aa21e8868b78>']	open-ended	direct	verbose-and-natural	distant-from-document	single-doc	novice	2025-05-13T04:02:16.770989	18	76	2357
29	How many grams of sugar are in some single-portion yogurt containers?	Some single-portion containers of yogurt contain upwards of 18 grams of sugar, which is the same amount as in a miniature Snickers bar.	['Give your breakfast a make-over\nThey say breakfast is the most important meal of the day, but it can sabotage your efforts to eat healthy if you’re eating foods that only appear healthy.\n“It’s always the healthy choice to eat breakfast in the morning,” said Danette McPherson, RD, LDN, of Geisinger Jersey Shore Hospital. “However, many breakfast foods that are marketed as healthy are actually very high in sugar.”\nHere are some of the breakfast foods that aren’t as healthy as you might think, and what you should eat instead.\nFruit is healthy, so fruit juice must be healthy, too, right? Wrong.\n“Just because the bottle or carton of juice says ‘natural’ or ‘100 percent juice’ doesn’t mean it’s healthy,” Danette said. “Many fruit juices typically contain a lot of sugar, some of it even added by manufacturers.”\nAlthough fruit naturally contains sugar, fruit juice lacks the fiber real fruit contains.\n“Since most fruit juice lacks fiber, the fruit’s natural sugar doesn’t have any regulators to slow down the rate at which it enters your bloodstream. Without fiber slowing down sugar’s trip through your bloodstream to the liver, some of it can turn into fat,” Danette said.\nInstead of pouring a tall glass of juice at breakfast, rehydrate with water and slice up whole fruit for its essential fiber and nutrients. Plus, whole fruit’s fiber will make you feel full longer.\nGrab-and-go yogurt seems like a win-win in the hustle and bustle to get ready for work and school – it’s quick and healthy. But it’s actually not as healthy as you may have thought, even the reduced fat variety.\n“Some single-portion containers of yogurt contain upwards of 18 grams of sugar – talk about a sugar rush!” Danette said. “A miniature Snickers bar contains the exact same amount of sugar as some yogurts.”\nYogurt is loaded with sugar. And some yogurts that are low-fat have even more sugar in them. Plus, most yogurts don’t contain much protein. Instead of sugar-laden yogurt, swap it out for Greek yogurt.\n“Greek yogurt has nearly double the amount of protein as regular yogurt, containing an average of 15 to 20 grams of protein. Regular yogurt contains an average of 9 grams of protein,” Danette said. “Greek yogurt is significantly lower in sugar too.”\nIf you thought instant oatmeal was a healthy start to your day, it’s not. While some oatmeal can be a great choice for breakfast, instant flavored oatmeal simply isn’t.\n“Like fruit juice and yogurt, instant flavored oatmeal is bursting with sugar,” Danette said. “On average, flavored instant oatmeal contains 3 to 4 teaspoons of added sweeteners.”\nOne teaspoon of sugar equals 4 grams of sugar – that means your instant flavored oatmeal that contains about 3 to 4 grams of sugar or sweeteners comes out to as much as 16 grams of sugar. Additionally, some brands add sodium to your instant oatmeal as a preservative.\n“Make a healthy oatmeal breakfast by looking for plain instant oatmeal with no added sugar, or steel cut or old fashioned rolled oats. This kind of oatmeal provides you with a hearty dose of vitamins, protein and cholesterol-lowering soluble fiber,” Danette said.\nYour plain or old fashioned oats are still part of a healthy meal plan if you sweeten them yourself with 1 teaspoon of real maple syrup, brown sugar, sugar substitute or fresh fruit, which will increase the fiber content. Oatmeal toppings will add extra calories, so be careful!\nGranola has always been considered a healthy breakfast food, but not all granola is created equal.\n“Grains, dried fruit and nuts mixed together sounds healthy, but that’s not always all that’s in your morning granola,” Danette said. “Sugar is hidden in a lot of granolas as molasses, evaporated cane juice, brown rice syrup, and oat syrup solids.”\nMake sure your granola is healthy by carefully reading the nutritional facts and ingredient list, paying particular attention to fiber and sugar. Make sure that you won’t be consuming more than 8 grams of sugar per serving – otherwise you could wind up eating a sugary carb-heavy meal topping around 400 calories per serving.\nDanette McPherson is a registered and licensed dietitian at Geisinger Jersey Shore Hospital and can be reached by calling 570-398-5142.']	['<urn:uuid:3e58e776-ad02-4bd0-99fc-c264b60399a6>']	factoid	with-premise	concise-and-natural	similar-to-document	single-doc	expert	2025-05-13T04:02:16.770989	11	23	706
30	What efforts support women's rights at school and internationally?	At Hamden Hall, the Multicultural Student Interests committee works to reduce discrimination and increase cultural awareness, while internationally the Parliament of World's Religions published a Declaration for Women's Dignity and Human Rights, and organizations like UN Women promote women's empowerment through the Beijing Platform for Action.	"['1912 is Hamden Hall’s student newspaper that is printed six times per year. While it reports regularly on in-school events and issues, it prides itself on expressing diverse and provocative opinions about the issues of the day, both within the school and in the larger world.\nAmnesty International is a worldwide organization whose mission is to defend liberty and human rights, while fighting to end human rights abuses. Through a variety of advocacy activities, Amnesty International works to end injustices such as torture, censorship of the press, mistreatment of prisoners, and the death penalty. Hamden Hall\'s chapter of Amnesty International, founded in the spring of 2008 by Samuel Genecin and Tobenna Nwangwu, is committed to increasing awareness of human rights issues, to raising funds for Amnesty and other organizations that support its core mission, and to engaging in activism to support prisoners of conscience and other victims of oppression around the world. We have run campaigns on human rights abuses in Tibet, Sudan, and Lybia. This year we plan to turn our attention to the issue of \'human trafficking\' in the developing world and to the death penalty. Amnesty\'s faculty advisors are Mr. Gustafson and Mr.duPont. The group meets every other Monday at 10:40 a.m. in Whitson 39. All are welcome.\nStudent members do not have to be artists or be part of any art class at Hamden Hall, but must have an interest in art. The Art Club will not only be observational but also hands-on as we will work on group projects with other members.\nAs the premiere biology competition for high school students in the United States, the USA Biology Olympiad (USABO) enriches the life sciences education of nearly 10,000 talented students annually. It provides the motivation, curricular resources, and skills training to take them beyond their classroom experience to the level of international competitiveness.\nThe BO exam is administered once a year (usually in February or March), and consists of 50 college-level biology questions. Students prepare independently or in small groups, reading up on various bio topics using a biology textbook. Students are encouraged to try their hand at the Open Exam every year (students are eligible up until they accept college admission). If a student meets the score cutoff on the open exam, they would progress to the semifinal exam given about six weeks later. If they meet the score cutoff on the semifinal, they would progress to the finals.\nRegardless of the outcome on the exam, participation in Biology Olympiad is a great way for students to explore their interest in the life sciences.\nThe Chess Club meets on Thursdays following school. Students and faculty play pick-up games and also compete on a ladder ranking scale. Twice a year the Club holds a student tournament open to the entire school.\nStudents learn about and participate in conservation and recycling efforts at school, in the local community, and in the world. The Conservation Club is responsible for all recycling on campus, while also educating the rest of the student body about this effort.\nThe Debate Club gives students a sense of how to properly organize and present arguments in a lucid, structured fashion. Each week teams of students work on plans to map out optimal lines of defense and attack on the other side’s anticipated views. Debate has many ramifications in regard to gaining the skills needed to form structured, timely, relevant arguments in many areas of the humanities.\nFACES is the literary magazine for grades 9 – 12 and membership is open to all interested students. Meetings are held weekly where the jobs of previewing submitted work and devising ways to promote the magazine among the student body are discussed. Coming out on Prize Day every year, the publication of FACES is an event anticipated by the whole school population.\n(Gay, Straight, Alliance) An important goal of the Hamden Hall GSA is to make our community a safer place for those who are gay, lesbian, bisexual, and transgendered (GLBT), as well as for those who are questioning who they are sexually. GSA also seeks to promote an environment on campus in which different viewpoints can be aired freely and constructively.\nThe Interact Club is the main branch of community service at Hamden Hall and is recognized worldwide. We are very fortunate to be sponsored by the Rotary Clubs of Hamden and Branford. The Interact Club oversees all service projects, making sure that they are organized in a professional manner and completed well. Each month throughout the school year, the entire school community will do its best to support one of our local organizations. In addition to helping out the local community for the majority of the year, the Interact Club also participates in one international community service project.\nHamden Hall\'s Investment Club researches, learns, and discusses an array of investment opportunities as well as relevant current events relating to the field. We run stock market simulations and bring in many guest speakers to further enrich our learning. We look forward to meeting interested students and showing them the dynamic investing world.\nThe North American Computational Linguistics Olympiad is a contest in which high-school students solve linguistic puzzles. In solving these puzzles, students learn about the diversity and consistency of language, while exercising logic skills. No prior knowledge of linguistics or second languages is necessary. Professionals in linguistics, computational linguistics, and language technologies use dozens of languages to create engaging problems that represent cutting edge issues in their fields. The competition has attracted top students to study and work in those same fields. It is truly an opportunity for young people to experience a taste of natural-language processing in the 21st century.\nVarsity: This Upper School team usually has six competitions (meets) per year at various high schools. Following the six math meets, the top schools are invited to the State Competition, usually held in March. The top four schools in the state are invited to the New England Competition, which Hamden Hall has qualified for in the past.\nJunior Varsity: This team competes three times per year as a practice for the varsity level. Subjects for these competitions span from 7th grade math to Pre-Calculus. Participation enhances a student’s ability to be a better problem-solver, while also reinforcing the memory of previous material, thus boosting confidence and encouraging further growth in mathematical ability.\nMiddle School Advocates are seniors who serve as role models for seventh- and eighth-grade students via various programming and activities. Advocates mentor students in different capacities and historically have been involved in proctoring Middle School study hall, tutoring in the student center, participating in assemblies and other special events, and more. There is an application and selection process involved in this endeavor.\nModel United Nations provides students the opportunity to learn about and discuss today\'s most relevant world issues through participation in an authentic simulation of the United Nations and other international organizations. In both pre-conference preparation and in-conference debate, Model UN seeks diplomatic and creative solutions to complex problems. The HH Model UN has received awards from events such as BosMUN at Boston University and NYUMUNC at NYU, with plans to diversify further events. Those interested in internationalism, foreign affairs, or simply want to learn more about the complex issues in the world would find themselves at home.\nMulticultural Student Interests was created to develop and implement a program to reduce prejudices and discrimination on campus, increase cultural, religious, racial and ethnic awareness, and to provide students a safe environment to be able to discuss difficult issues. The committee implements programs to educate faculty, students, and parents. All campus events have included National Mix It Up Day, Cinco de Mayo celebration, Multicultural Monday newsletters, topical speakers, Black History Month, and more. Outside resources are consulted for programs on leadership including participation in a statewide conference.\nThe Production Crew is a club run by the Theater Technical Director. This club meets twice a week and on some weekends to build and paint sets, hang stage lights, and set up sound for all Hamden Hall productions and special events in the Taylor Performing Arts Center. Basic carpentry, safe tool practices, faux painting techniques, and basic stage rigging are just a few of the projects that students are introduced to. Crew members get first hand experience in understanding how the backstage of a theater works, from basic design concepts to special effects.\nHamden Hall Robotics Club participates in the FIRST Tech Challenge. If you are interested in science, engineering, programming, or are just curious about robotics, please join us! No background in these areas needed, just a willingness to participate and learn! We will be participating in a regional competition in addition to building our own robots according to the interests of members.\nThe Science Club originally formed in 2004 evolved into the Science Inquiry Group, which was an umbrella organization under which students carry out many different activities. In 2012 it became the Signature Program called Science, Innovation & Design. The program has two main goals: 1) to encourage students to engage in independent projects and 2) to focus on the development of a culture of inquiry at Hamden Hall.\nThe Student Government is responsible for the organization of student activities including dances, community service projects, and fundraisers. The main board of members is elected by their peers to oversee all student activities in the Hamden Hall community. In addition, each class in grades 9 – 12 will have class officers/representatives who are also members of the Student Government. Each position has particular duties, and the entire Student Government must be responsible, reliable, and able to lead by example.\nThe Students Musicians Union is dedicated to furthering the growth of music and musical talent here at Hamden Hall and is run solely by the students. They incorporate all genres of music and strive to create an active musical environment for the school community.\n""You\'ve been swarmed!"" Swarm was started to help build school spirit among students, faculty, and community members at various school events throughout the year. The main goal of Swarm is to not only raise awareness of the many events, but to increase spectator participation and support of those events. Over the years students have ""Swarmed"" sports games, concerts, theater productions, and art shows. In addition to attending events, members of Swarm help spread the word on campus by hanging posters, making announcements at assembly, and organizing ""Green-outs.""\nThe Thespians are made up of students who have participated in at least three Hamden Hall productions. Members are inducted at the end of every year. The thespians raise money for field trips, dinners, and theater improvements.\nThis is composed of students dedicated to creating a yearbook full of lasting memories. Throughout the year, members take pictures of everyday happenings at Hamden Hall that will provide a foundation for the yearbook. This will include everyday life at HH, sports events, theatre productions, class trips, community service projects, and much, much more. Through the creation of the yearbook, the club is able to represent the community and show the unique qualities of this school.\nHamden Hall Country Day School is a nurturing and inclusive community with a dynamic learning environment that promotes academic excellence by understanding each child and fostering their individual growth.', ""Parliament of the World's Religions\nPrograms include: Interfaith Climate Action, Women's Task Force, Sacred Space, Faiths against Hate.\nClick here - http://parliamentofreligions.org/\nOn 11 October 2016, International Day of the Girl, the Parliament of the World’s Religions published this Declaration.\nClick here - Parliament Declaration for the Dignity and the Human Rights of Women\nUSG-UISG The International Union of Religious Congregations\nUSG-UISG is the international Union of Religious Congregations. Its Commission for Justice Peace and Integrity of Creation has a new website - www.jpicroma.org\nUSG-UISG is the international Union of Religious Congregations. This See-Judge-Act Reflection paper is produced by its Commission for Justice Peace and Integrity of Creation.\nClick here to explore this Reflection Paper - Impact of Mining Industry.pdf\nNewsbrief is a publication of USG-UISG Commission for Justice Peace and Integrity of Creation. Click here to read Ms Navy Pillay's opening speech on the occasion of the United Nations first-ever World Day against Trafficking in Persons on July 30, 2014 in Geneva - http://article.wn.com/view/2014/07/29/statement_by_the_un_high_commissioner_for_human_rights_navi_/.\nGlobal Sisters Report - http://globalsistersreport.org/\nA Project of National Catholic Reporter.\nUN ESCAP - United Nations Economic and Social Council for Asia and the Pacific\nWomen's Rights Asia Pacific\nInternational Women's Rights Action Watch Asia Pacific (IWRAW). This website is particularly useful for information and news related to CEDAW - http://www.iwraw-ap.org/\nEarly and Forced Marriage\nBlog of Sister Winifred Doherty on the issue of early and forced marriage. Winifredd's Blog\nWebsite of Girls not Brides: The Global Partnership to End Child Marriage. http://www.girlsnotbrides.org/about-child-marriage/\nTrafficking of Persons\nThe Anti-trafficking Working Group (ATWG) of UISG posted an interactive information center in 2017, to share the activities of Religious Congregations which combat trafficking.\nClick here - Interactive Survey PPT slides\nUS Secretary of State Report into Global Trafficking. Trafficking in Persons Report\nUN Women - http://www.un.org/womenwatch/daw/csw/56sess.htm\nACRATH (Australian Catholic Religious Against Trafficking of Humans) - http://www.acrath.org.au/\nKiss - Health Report - Health of men, women and children in post trafficking services in Cambodia, Thailand and Vietnam: an observational cross sectional study - Ligia Kiss and colleagues. Click here to read this important and comprehensive research report.\nViolence against Women and Girls\nThe Sisters in India stand in solidarity for support of a freedom movement to end generations of deep violence and suppression faced by millions of Indian woman and girls in this Womanifesto\nOne Billion Rising: One Billion Rising youtube clip\nNo One Should Work This Way – Ending the Abuse of Asian Women Domestic Workers\nThere are more than 52 million domestic workers worldwide but the vast majority are unprotected by labour laws. This leaves them open to – sometimes terrible – abuse and exploitation. The journalist Karen Emmons worked with the photographer Steve McCurry on a documentary project to record and expose some of the treatment experienced by Asian migrant domestic workers.\nVIDEO with Journalist Karen Emmons – 01 December 2014\nThe Beijing Platform for Action\nAs part of UN Women's Beijing+20 campaign, during the month of December 2014 the focus was on Human Rights of Women.\nView these excellent videos on Beijing+20\nHistory of Women’s Empowerment in the Asia Pacific – The Journey for Gender Equality – ESCAP - http://youtu.be/4oCQpzffHW8?list=UUw0H1k76cVytDosvoTULQEQ\nIssues and Challenges in Asia Pacific since Beijing Declaration and Platform for Action – Achieving Gender Equality for the Future We Want - ESCAP - http://youtu.be/EXb3Klv-RME\nGlimpse of Asia-Pacific Beijing +20 Conference – ESCAP and UN Women - https://www.youtube.com/watch?v=cbVSWQeG6QQ\nEmpowering Women - Empowering Humanity: Picture It! - http://www.youtube.com/watch?v=dHliULCiSCA&index=59&list=UUXDenzwzeXM1TNtTuWj8C4A\nCEDAW Quick & Concise: Explaining the Principle of Non Discrimination - http://www.youtube.com/watch?v=OBdDB5PKrmk&list=UUXDenzwzeXM1TNtTuWj8C4A\nCEDAW Quick & Concise: The principle of state obligation - http://www.youtube.com/watch?v=umETapJ4b8o&list=UUXDenzwzeXM1TNtTuWj8C4A\nCEDAW Quick & Concise: The principle of substantive equality - http://www.youtube.com/watch?v=rI8lNB-XMIk&list=UUXDenzwzeXM1TNtTuWj8C4A""]"	['<urn:uuid:91bebdff-16af-4995-94e5-e35e59d5f714>', '<urn:uuid:6c47c7e1-b775-4e81-b538-a512eefd7531>']	factoid	direct	concise-and-natural	similar-to-document	multi-aspect	novice	2025-05-13T04:02:16.770989	9	46	2487
31	how common hurler syndrome compared galactosemia birth rates statistics	According to the statistics, Hurler syndrome (as part of MPS disorders) occurs in approximately 1 in 25,000 births in the United States, with some estimates indicating only 40 babies born with Hurlers per year. In comparison, galactosemia occurs in approximately 1 in 60,000 newborns, making Hurler syndrome more common than galactosemia.	['Hurler, Scheie and Hurler/Scheie syndromes are mucopolysaccharide disorders and are also known respectively as MPS-IH, MPS-IS, and MPS-IH/S. Hurler syndrome takes its name from Gertrud Hurler, the doctor who described a boy and girl with the condition in 1919. In 1962, Dr. Scheie, a consultant ophthalmologist, wrote about some of his patients who were more mildly affected. Patients who seem not to fit clearly in either the severe or the mild end of the disorder are said to have Hurler/Scheie syndrome.\nThere is no magic cure for MPS disorders, but there are ways of managing and treating the problems they cause.\nWhat Causes the Disorder?\nMucopolysaccharides are long chains of sugar molecule used in the building of connective tissues in the body.\n“saccharide” is a general term for a sugar molecule (think of saccharin)\n“poly” means many\n“muco” refers to the thick jelly-like consistency of the molecules\nThere is a continuous process in the body of replacing used materials and breaking them down for disposal. Children with these disorders are missing an enzyme called alpha-L-iduronidase which is essential in cutting up the mucopolysaccharides called dermatan and heparan sulfate. The incompletely broken down mucopolysaccharides remain stored in cells in the body causing progressive damage. Babies may show little sign of the disorder, but as more and more cells become damaged, symptoms start to appear.\nHow Common is the Disorder\nScheie syndrome is 1 in 500,000\nHurler/Scheie syndrome it is 1 in 115,000.\nThere is an estimate in the United States that 1 in 25,000 births will result in some form of MPS. Other estimates state only 40 babies a year are born with Hurlers.\nHow is the Disorder Inherited?\nWe all have genes inherited from our parents which control whether we are tall, short, fair, etc. Some genes we inherit are “recessive,” that is to say we carry the gene, but it does not have any affect on our development. Hurler syndrome is caused by a recessive gene. If an adult carrying the abnormal gene marries another carrier, there will be a one in four chance with every pregnancy that the child will inherit the defective gene from each parent and will be affected with the disorder. There is a two in three chance that unaffected brothers and sisters of MPS I children will be carriers. They can be reassured; however, that, as the disorder is so rare, the chance of marrying another carrier is very slight provided they do not marry a cousin or other close family member. However, you can not find two more different genetic background’s than Joe and I. His family is all from Italy, and I like to say, I am 100% blond!!!!\nThe disorder is based on the bodies inability to produce a specific enzyme that is used to breakdown cellular byproducts into other molecules the body can use. These molecules build up in the body and are stored in the cells where they were originally used. Over time these molecules begin to get in the way and cause a slow down in the normal cellular processes that take place in the body. The most common effects of this build up are mental deficiencies, skeletal and joint problems, vision and hearing impairment, heart, liver and lung disease. The end result is death.\nCurrent Treatment Options\nThere are many treatment options available for Hurler’s.\n- Enzyme Replacement Therapy – Introduction of the missing enzyme back into the body through a central line or peripheral line.\n- Bone Marrow Transplants – Complete obliteration of the Childs malfunctioning bone marrow and replacement with healthy bone marrow that can produce the needed enzyme\n- Stem Cell Transplants – Introduction of stem cells into the body which produce the required cells in the treated organ to create the enzyme\n- Umbilical Cord Transplants:\nIn the 1970s medical researchers discovered that human umbilical cord blood contained the same kind of stem cells found in bone marrow. (Stem cells get their name from their ability to develop into three types of blood cells: red blood cells, while blood cells and platelets). Because stem cells from bone marrow had already been used successfully to treat patients with life-threatening blood diseases, such as leukemia and immune system disorders, researchers believed that they could also use stem cells from cord blood to save patients.\nIn 1988, doctors transplanted human umbilical cord blood into a 5-year old boy suffering from Fanconi’s anemia. Ten years after the transplant, the boy is alive and seems to be cured of his disease. Based on this and other successful transplants, doctors and medical researchers began to collect, freeze and store cord blood units (CBUs) at cord banks throughout the world. As of October 1998, there were approximately 22,000 CBUs collected and frozen for use worldwide, and approximately 700 unrelated donor and 150 related (sibling) donor cord blood transplants had been performed.\nAlthough today marrow transplants and cord blood transplants are often referred to by the same name — stem cell transplants — there are important differences between the two. This section will explain these differences and also discuss the kinds of decisions doctors and their patients must make to determine the best source of stem cells for transplantation. Before considering these issues, however, it is important to understand the challenges patients face in finding a donor.\nFinding a Donor\nUnfortunately, 70% of patients who need a stem cell transplant do not have a suitable donor in their family. The National Marrow Donor Program (NMDP) helps identify stem cell donors for patients who do not have a related donor.\nStem cell transplants require matching certain tissue traits of the donor and patient. Because these traits are inherited, a patient’s most likely match is someone of the same heritage. American Indian and Alaska Native, Asian, Black and African American, Hispanic and Latino, Native Hawaiian and Other Pacific Islander, and multiple-race patients face a greater challenge in finding a match than White patients.\nThe collection and storage of cord blood is one way to give patients of all racial and ethnic backgrounds greater access to stem cell transplantation. For that reason, beginning in the early to mid-1990s, medical institutions around the world began making a serious effort to collect and store cord blood units for use in transplantation.\nSo far, clinical studies by John E. Wagner and others suggest that unrelated cord blood transplantation is a safe and acceptable alternative to bone marrow transplantation for many patients. However, these studies have also found that, as with bone marrow transplants, patients who receive cord blood from sibling (or related) donors generally have higher survival rates than those who receive cord blood from unrelated donors.\nStudies have also found that banked cord blood (from both related and unrelated donors) often contains enough stem cells for transplantation. Physicians need to match the number of stem cells in a cord blood unit with the weight of the patient to be sure the unit is likely to be able to reestablish the patient’s immune system. Because there are fewer stem cells in cord blood than in marrow, until recently most cord blood recipients have been children or small adults. There is, therefore, some concern that the number of cells in an average cord blood unit may not be sufficient for engraftment in larger adults. Engraftment occurs when the transplanted stem cells — the “graft” — regenerate the blood and marrow and begin to function as the recipient’s new immune system.\nOne positive finding is that cord blood transplant patients appear to suffer less from acute graft-versus-host disease (GVHD) than patients who receive bone marrow transplants. GVHD is a very serious, and sometimes fatal, condition that occurs when the patient’s new immune system — which is made up of stem cells from the donor — starts attacking the patient’s body. GVHD affects the skin and internal organs such as the liver and intestines.\nDespite the fact that cord blood recipients appear to suffer less from GVHD, it has not yet been proven that the risk of GVHD is less in all recipients after cord blood transplantation. Because children receive the most cord blood transplants, and because they also experience less GVHD than adults after bone marrow transplants, it may be that the success of cord blood transplants is at least partly attributable to the fact that they are used on more children than adults.\nUnderstanding HLA Matching\nWith stem cell transplants, the better the match between the donor and the recipient, the less likely graft-versus-host disease is to develop. It is important, therefore, to understand how doctors determine the best, or most acceptable, match between the donor and the recipient. To understand how they do this, it helps to have a basic understanding of the human immune system.\nAntigens, a kind of protein located on the outer surface of most cells in the body, help the immune system to identify foreign bacteria and viruses. The antigens that transplant doctors look for when matching patients and donors are located on a cell called a leukocyte, giving these antigens the name Human Leukocyte Antigens, or HLA. Every person has six groups of HLA antigens, but three groups (called A, B, and DR) are considered most important in a stem cell transplant. Each of these groups has two antigens, one inherited from the father and one from the mother, making a total of six antigens that determine a donor/recipient match. A perfect match is called a 6/6 HLA match.\nBone marrow transplants are usually not attempted unless the donor and recipient are a 6/6 or 5/6 HLA match. However, with cord blood transplants, doctors and medical researchers generally believe that a 4/6 match is sufficient. Because immune system cells contained in cord blood are less mature, they have not yet “learned” to attack foreign substances, and so would be less likely to attack the recipient’s immune system, even though the match isn’t perfect. Since matching requirements for cord blood are less strict, patients who are unable to find a 5/6 or 6/6 marrow donor may be able to find a suitably matched cord blood unit.\nWhat is Known About Cord Blood Transplants\nWith its more than 30-year history, bone marrow transplants are a well-established, life-saving treatment for a wide range of blood disorders such as leukemia and aplastic anemia, as well as selected immune system deficiencies and genetic disorders. While the history of cord blood transplants is less extensive, there is evidence to suggest that these transplants can cure diseases, too. But with cord blood there are more unknowns, and doctors and their patients must carefully evaluate the situation before deciding on the best treatment.\nThe following lists explain what is known and not known about cord blood transplants. While these lists are not exhaustive, they do include aspects of cord blood transplants that are critical in the decision-making process:\nWhat We Know About Cord Blood Transplants\n- Cord blood contains sufficient numbers of stem cells for engraftment in most recipients weighing less than 50 kilograms (about 110 pounds).\n- Collection of cord blood poses no health risk to the mother or infant donor.\n- Because it is stored and available for use, cord blood is sometimes more readily available than a potential marrow or blood stem donor, who may be unavailable for donation when it is needed.\n- Cord blood is rarely contaminated by viruses often found in marrow, such as cytomegalovirus (CMV) and Epstein-Barr virus.\n- Cord blood can cause severe GVHD, but possibly less frequently than in bone marrow transplants.\nWhat We Think We Know about Cord Blood Transplants Based on Clinical Data\n- Compared to bone marrow transplants, cord blood transplants may have a lower rate of acute GVHD, at least in cases where a related (sibling) donor is used.\n- It appears that the transplant process using cord blood (from the time a search is started to the time donor cells are ready for transplant) is shorter than that for marrow cell donation because the cord blood units are in storage and ready for use.\nWhat We Don’t Know about Cord Blood Transplants (because of lack of clinical evidence)\n- Whether cord blood is sufficient for engraftment in most adult recipients, although experience suggests that it may be sufficient for a significant proportion of these recipients.\n- Whether cord blood transplants pose a different risk of relapse (recurrence of an illness after a remission) compared to unrelated bone marrow transplants.\n- Whether focused cord blood collection will be successful in meeting the current challenge of finding a match for American Indian and Alaska Native, Asian, Black and African American, Hispanic and Latino, Native Hawaiian and Other Pacific Islander, and multiple-race patients, thus increasing the number of available transplants for these patients.\nClinical studies have demonstrated that stored cord blood is a sufficient source of transplantable stem cells, at least for young patients. Also, in addition to previously known advantages of cord blood (rapid availability and a low rate of virus contamination) studies have found that cord blood transplants may also lead to less GVHD than bone marrow transplants.\nClinical experience also shows that a high stem cell dose (a sufficient number of stem cells based on the patient’s body weight) is an important factor in recipient survival, and that cord blood transplants can be successful with as low as a 4/6 HLA match.\n*Visit “Chemo Counting” to see what a typical hospital day will include*\nGraph Versus Host Disease (GVHD)\nGVHD is a frequent complication of an unrelated bone marrow or umbilical chord transplant. The transplanted cells realize that they are in a new environment and attack the donor’s organs. Approximately 50% of patients that receive an unrelated transplant contract GVHD, the numbers are less in umbilical chord transplants at 25%. There are two types of GVHD, acute and chronic. Acute GVHD occurs soon after the transplant between day 30 and day 60. Chronic GVHD can occur much later after transplant and last much longer. Both types of GVHD can be serious and range from level 1 through level 4 where level 4 is the most severe. Most patients that contract GVHD are treated with steroids and a variety of anti-rejection medications. The disorder has no long term side effects if treated properly.\nT-Cells are the cells in the transplanted marrow that recognize foreign matter. Their sole purpose is to fight off infections, viruses, and other foreign substances. These T-Cells look for genetic markers, HLA markers, that distinguish them from foreign cells. To T-Cells normal body cells can be foreign and are therefore considered bad. The T-Cells will fight these cells trying to rid the body of them. Obviously these small amount of T-Cells are not going to kill the entire human body but the side effects of GVHD can be uncomfortable. Typical side effects are diarrhea, rashes, increased liver functions, stomach and intestinal problems.\n**Information obtained from MPS website, and National Marrow Donor Program', 'Information for Parents\nWhat disorders are included in the newborn screen?\nAll babies born in Illinois should be screened for the disorders listed below. Following is a short description of the disorders included in Illinois newborn screening. If you live in Illinois, but deliver your baby in another state, your baby may not be screened for these same disorders. You may want to discuss with your baby’s doctor, how to obtain additional screening if necessary. This screening is most accurate soon after your baby is born, so it is important to make arrangements before your baby’s birth, or as soon as possible after birth.\nBiotinidase deficiency may occur in one of every 150,000 births. Babies with this problem cannot use a vitamin called biotin. Without treatment, the baby’s growth and development will not be normal. A baby with biotinidase deficiency needs medicine containing biotin and regular medical care.\nCongenital Adrenal Hyperplasia\nCongenital adrenal hyperplasia (CAH) may occur in one of every 15,000 births. Most babies with this problem cannot produce enough of a hormone called cortisol. Sometimes, they also cannot produce enough of a salt-retaining hormone. Babies with CAH may develop medical problems including severe fluid loss (dehydration). Without enough cortisol, a baby’s growth and development will not be normal. A baby with CAH is given medicine to replace these important hormones and needs regular medical care.\nGalactosemia may occur in one of every 60,000 newborns. A baby with galactosemia cannot digest a certain part of milk sugar called galactose. The resulting buildup of galactose in the baby’s body can cause serious medical problems, including liver and brain damage. Babies with galactosemia are treated with a special lactose-free diet and need regular medical care. Early treatment can help prevent physical and mental damage.\nCongenital hypothyroidism may occur in one of every 3,000 newborns. A baby born with this problem does not make enough thyroid hormone, which is needed to help the baby grow normally and stay healthy. Without thyroid hormone, a baby’s growth and mental development will not be normal. A baby with congenital hypothyroidism is treated with medicine to replace the missing thyroid hormone and needs regular medical care.\nPhenylketonuria (PKU) may occur in one of every 12,000 births. Babies with PKU, an amino acid disorder, cannot properly use a substance found in proteins, phenylalanine. If this problem is not found and treated early, PKU can cause developmental delays and mental retardation. A baby with PKU is given a special formula and diet, and needs regular medical care.\nLysosomal Storage Diseases\nBabies with lysosomal storage diseases cannot break down certain waste products. These waste products build up within the body and cause serious medical problems affecting the baby’s health and development. Treatment depends on the specific disorder, and can include medications, enzyme replacement therapy, or may require stem cell or cord blood transplant very early in life. A baby with a lysosomal storage disease needs immediate and on-going medical care. Statewide screening of newborns for lysosomal storage disorders is scheduled to begin in 2014.\nSickle Cell Disease, Trait and Related Conditions\nEach year it is estimated that more than 80 babies in the state will be diagnosed with sickle cell disease, and 40 more babies will be diagnosed with another kind of sickling disorder. Sickling disorders can cause pain, damage vital organs and lead to serious infections. Babies with these disorders are treated with antibiotics, and need immunizations and regular medical care to help prevent some of these medical problems. The newborn screen for sickle cell disease also may find other related conditions that may or may not need treatment.\nOther Metabolic Disorders\nAdditional rare disorders, including some of the amino acid, urea cycle, fatty acid oxidation, organic acid disorders and lysosomal storage diseases, are included in the Illinois newborn screening panel. Babies with these disorders cannot breakdown or remove certain chemicals from their bodies. Without treatment, these chemicals can build up in the baby’s body and cause serious health and developmental problems.\nAmino Acid and Urea Cycle Disorders\nPKU is one of the more familiar of the amino acid disorders. Babies with amino acid and urea cycle disorders cannot properly process amino acids, the building blocks of proteins. Without treatment, the buildup of these chemicals can cause serious medical problems affecting the baby’s health and development, including damage to vital organs, seizures and coma. Treatment depends on the disorder the baby has, but may include special low protein diets, medical treatments and medications. A baby with an amino acid or urea cycle disorder must have regular medical care.\nFatty Acid Oxidation Disorders\nBabies with one of these disorders have trouble burning fat for energy. Without treatment, these disorders can lead to serious medical problems affecting the baby’s health and development, including seizures, liver damage and coma. Treatment depends on the disorder the baby has, but may include special diets, supplements and medications. Babies with fatty acid oxidation disorders must have regular medical care.\nOrganic Acid Disorders\nBabies with organic acid disorders cannot remove certain waste products from their blood. Without treatment, the buildup of these waste products causes serious medical problems affecting the baby’s health and development, including seizures, coma and brain damage. Treatment depends on the disorder the baby has, but may include special diets, supplements and medications. A baby with an organic acid disorder must have regular medical care.\nCystic fibrosis (CF) may occur in one of every 4,000 newborns. A baby with CF produces thick, sticky mucus that causes respiratory and digestive problems. CF affects growth and damages a baby’s lungs and other organs. A baby with CF is treated with special diet supplements and vitamins to improve growth. In addition, breathing treatments, medications and special exercises can help maintain respiratory function. A baby with CF needs regular medical care.\nMore information about each of the diseases or disorders included in the screening panel can be found on the fact sheets.\nIllinois Department of Public Health\nGenetics and Newborn Screening Program\n535 W. Jefferson St., 2nd Floor\nSpringfield, IL 62761\nTTY (hearing impaired use only)\nof Public Health\n535 West Jefferson Street\nSpringfield, Illinois 62761\nQuestions or Comments']	['<urn:uuid:54083459-7d01-49c7-b01c-35a4f41a8d9f>', '<urn:uuid:e9ea9bb0-86a9-4aa5-9afd-3994a71edc30>']	open-ended	direct	long-search-query	similar-to-document	comparison	novice	2025-05-13T04:02:16.770989	9	51	3511
32	What kind of tasks do shoe print experts do?	Forensic footwear examiners document, collect and preserve footwear evidence, compare and analyze footwear impressions, provide expert opinions regarding source conclusions, determine the manufacturer, make, or model of questioned impressions, compare questioned impressions from images or videos, and write reports and provide testimony.	"[""The Footwear and Tire Subcommittee focuses on standards and guidelines related to the detection, documentation, recovery, examination and comparison of footwear and tire evidence.\nForensic footwear and/or tire examiners undertake the following tasks: documenting, collecting and preserving footwear and tire evidence, and comparing and analyzing footwear or tire impressions. Examiners provide expert opinions regarding source conclusions, determine the manufacturer, make, or model of the source of a questioned impression, compare questioned impressions, make, or model of an item of footwear or tire from an image or video, and write reports and provide testimony.\nDavid Kanaris, Subcommittee Chair, Alaska Scientific Crime Detection Laboratory\nRodney Schenck, Subcommittee Vice Chair, U.S. Federal Bureau of Investigation\nVacant, Subcommittee Executive Secretary\nClay Allred, Bureau of Alcohol Tobacco Firearms and Explosives\nKacey Amorello, Louisiana State Police Crime Laboratory\nSarah E. Bohne, Colorado Springs Police Department\nJohn Grassel, Rhode Island State Police\nChristopher Hamburg, ANSI National Accreditation Board\nMartin Herman, Ph.D., U.S. National Institute of Standards and Technology\nBrian Juengst, Maine State Police\nAnthony Koertner, Defense Forensic Science Center\nMathew J. Marvin, Ron Smith and Associates, Inc.\nTroy Mohror, Johnson County Sheriff's Office Criminalistics Laboratory\nHeidi Prough, Michigan State Police\nLisa Ragaza, State of Connecticut\nMatt Redle, Sheridan County Prosecuting Attorney's Office\nNicole Richetelli, West Virginia University\nRodney Schenck, U.S. Federal Bureau of Investigation\nAimee C. Stevens, Illinois State Police Division of Forensic Services\nNatasha Wheatley, ADA County Sheriff's Office\nAlicia Wilcox, Ph.D., Thomas College\nWork Product Sent to SDO:\nEntered OSAC Registry Approval Process:\nThe Forensic Science Standards Board (FSSB) has provided the opportunity for OSAC Subcommittees to identify baseline documents and reference materials that best reflect the current state of the practice within their respective disciplines.\nThese documents contain practical information regarding these disciplines that can help forensic scientists, judges, lawyers, researchers, other interested parties and the general public, to better understand the nature, scope, and foundations of the individual disciplines as they are currently practiced.\nIt is important to note that the identification of these documents in this venue does not represent an endorsement by OSAC or NIST. Only documents that are posted on the OSAC Registries constitute OSAC endorsement. All copyrights for these documents are reserved by their owners. Subcommittee position statements or responses to data collections by the subcommittee represent the consensus opinion of the subcommittee, not necessarily the position of the entire OSAC organization or NIST.\nAbbott, John, “Footwear Evidence”, Charles C. Thomas Publishing, 1964.\nBodziak, William, “Footwear Impression Evidence: Detection, Recovery and Examination” (1st Edition), Elsevier Science Publishing Co., 1990.\nBodziak, William, “Footwear Impression Evidence: Detection, Recovery and Examination” (2nd edition) CRC Press, 2000.\nBodziak, William, “Tire Impression and Tire Track Evidence: Recovery and Examination”, CRC Press, February 2008.\nBodziak, William, “Forensic Footwear Evidence” CRC Press, 2017\nCassidy, Michael, “Footwear Identification”, Canadian Government Publishing, 1980.\nDeforest, Peter; Gaensslen, Robert; Lee, Henry, “Forensic Science - An Introduction to Criminalistics”, McGraw-Hill, 1983.\nFisher, Barry, “Techniques in Crime Scene Investigation” (6th edition), CRC Press, 2002.\nGiven, Bruce W; Nehrich; Richard B. and Shields, James C., “Tire Tracks and Tread Marks”, Gulf Publishing Company, Book Division, Houston, Texas, 1977.\nHilderbrand, Dwane, “Footwear, The Missed Evidence”, Staggs Publishing Co., 1999.\nKiely, Terrence, “Forensic Evidence: Science and the Criminal Law”, CRC Press, 2001.\nMcDonald, Peter, “Tire Imprint Evidence”, CRC Press, Raton, Florida, 1989.\nNause, Lawren, “Forensic Tire Impression Identification”, National Research Council of Canada, Ottawa, Ontario, Canada, 2001.\nIn general, the development of standards and guidelines is transitioning from the Scientific Working Groups (SWGs) to the OSAC. Some SWGs will continue to operate to provide other resources within their discipline. The existing SWG documents will remain in effect until updated documents are disseminated by the OSAC or the SWG. SWGDAM will retain the responsibility for updating the FBI DNA Quality Assurance Standards.\n– Forensic Science Standards Board: March 2015""]"	['<urn:uuid:5a979e9a-81c6-4f0d-a41d-ebca0233a776>']	factoid	with-premise	concise-and-natural	distant-from-document	single-doc	expert	2025-05-13T04:02:16.770989	9	42	633
33	corrosion resistant better x65 or a572	API 5L X65 steel has modest resistance to uniform corrosion but is prone to localized corrosion (pitting), while ASTM A572 Grade 50 steel offers increased resistance to atmospheric corrosion due to its alloy elements.	['Ife Journal of Technology, Vol. 21(2), 43-48, 2012 43 _____ Full Paper ECO-FRIENDLY INHIBITORS FOR EROSION-CORROSION MITIGATION OF API-X65 STEEL IN CO2 ENVIRONMENT _____ O.O. Ige presence in production fluids and the shift towards deeper wells. Figure 1:Optical microscope image of API 5L X65 carbon steel after being polished and etched in API 5L X65 Çeliklerinin MAG Kaynak Yöntemi ile In this study, API 5L X65 steel pipes, used in natural gas and oil pipelines, was welded by the FCAW method using rutile flux-cored wire electrodes. The microstructure and mechanical properties of the samples were investigated.\nWelded (Longitudinal):- Wall Thickness Schedule 5s Schedule XXS (heavier on request), API5L gr.B, API5L gr.X42 to X70 (PSL1 + PSL2), EN10210-1 S355J2H, ISO 3183 L245 L555 NE/ME, API 5L X42 ERW Pipe, API 5L X52 ERW Pipe Austenite Grain Growth Kinetics in API X65 and X70 Line In such context, the application of API 5L grade pipes such as X-65 and X-70, which is considered as high-strength low alloy (HSLA) steels, is presented as a potential solution to enhance the reliability in the operation of these pipes in hostile environments and consequently the attendance of almost strict details posted in the steel procurement specifications. By Authority Of - Public.Resource.OrgAmerican Petroleum Institute. 49 CFR 192.113. API 5L:Specification for Line Pipe. Specification for Line Pipe . Upstream Segment API SPECIFICATION 5L FORTY-THIRD EDITION, MARCH 2004 EFFECTIVE DATE:OCTOBER 2004 ERRATA DECEMBER 2004 . American Petroleum\nOct 01, 2012 · The average mechanical properties of X65 steel are set out in Table 4 together with target values specified by API 5L. As can be seen from this data, the material tensile properties fulfilled the API specifications (yield strength > 448 MPa, tensile strength > 531 MPa) for X65 pipeline steel  . Corrosion Behaviour of Bitumen Coated API 5l X65 Steel API 5L X65 steel sample used for this research was obtained from SCC (Nigeria) Ltd, Ushafa, Abuja, Nigeria. The reagents used for Corrosion test was HCl with pHs of 2, 3, 4, and 7. The chemical composition of the X65 steel is as shown in Table 1. Table 1:Chemical composition of API 5L X65 low carbon steel. IJERT 2. 2 Samples Preparation Fatigue crack growth behaviour of semi-elliptical surface Feb 19, 2018 · Browse more than 70 science journal titles. Subject collections Read the very best research published in IOP journals. IOPcorporate IOP for R&D Science fueling innovation. IOPselect Articles from the past year selected by our editors. Publishing\nFeb 03, 2021 · 1 INTRODUCTION. API-5L Grade X65 steel are commonly used to manufacture pipelines used to convey production fluids extracted by the oil and gas industry. 1, 2 The mechanical properties, cost, and availability are the main factors that determine the selection of steel. However, despite having modest resistance to uniform corrosion, this grade of steel is prone to localized corrosion (pitting GREEN INHIBITOR FOR API 5L X65 STEEL IN HCL 0.5 Msteel (API 5L X65) during the first step causes the formation of Fe 2+. The inhibition effect depends on inhibitor concentration and molecular structure. It is observed that, the inhibition efficiency of CA extract increases with increase in CA extract concentration. CONCLUSIONS Grade X65 and X70 Heavy Wall (up to 37mm in Thick) UOE Nov 26, 2013 · For this purpose, we manufactured API X65 and X70 heavy wall (up to 37mm in thick) UOE linepipe for sour service utilizing an advanced thermo mechanical control process (TMCP) employing the theoretical maximum cooling rate with water (the ultimate cooling rate) and homogeneous temperature distribution in accelerated cooling.\nOct 31, 2011 · On the Relationship of Microstructure, Toughness, and Hardness Properties in a Submerged Arc Welded API-5L Grade X65 Pipeline Steel Section OMAE2014 The Effect of Microstructural Change on Fracture Behavior in Heat-Affected Zone of API 5L X65 Pipeline Steel Investigation of the Effect of pH on Stress Corrosion May 11, 2021 · In this study, impedance spectroscopy, slow strain rate tensile test, and scanning electron microscopy were used to investigate the susceptibility of API 5L X65 steel to stress corrosion cracking (SCC) in a sulfide brine solution with different pHs. According to the analysis of SSRT, steel was susceptible to SCC in a brine solution. Journal of The Electrochemical Society 165 The Journal of The Electrochemical Society, 165 (3) C171-C179 (2018) C173 Table I. Chemical composition of API 5L X65 carbon steel (wt%). Cr Mo S V Si C P Ni Mn Fe 0.14 0.16 0.009 0.047 0.26 0.13 0.009 0.36 1.16 Balance cylindrical UNS K03014 (API 5L X65) carbon steel, its chemical composition is shown in Table I. A Pt-coated Nb cylinder served as\nJan 17, 2011 · The mechanical properties of submerged arc weldment (SAW) in gas transportation pipeline steel of grade API X65 (65 ksi yield strength) were investigated. This steel is produced by thermo mechanical control rolled (TMC), and is largely used in Iran Reduction of hydrogen embrittlement of API 5l X65 steel Jun 14, 2018 · API 5L X65 pipe steel, with a minimum yield strength of 448 MPa (65 Ksi), was used as a substrate in our study. This type of steel is a widely used steel in the European oil and gas pipe network.', 'astm a572 steel grade 50 properties chemical composition\nApr 18,2020 astm a572 steel grade 50 properties chemical composition#0183;As the carbon content increases within the metal,an increasing amount of pearlite is formed in the microstructure of the steel.Grade 50 is a Columbium-Vanadium metal that provides a minimum yield of fifty,000 PSI.In addition,ASTM A572 Grade 50 is famous for its increased resistance to atmospheric corrosion.What is ASTM A572 Gr 50 equivalent material - BBN SteelThere are a lot equivalent standards and materials of ASTM A572 Gr 50 HSLA steel.What is Weathering Steel Plate-ASTM A588 Gr.A/B.C/K-AGICOASTM A588 Weathering Steel Plate.ASTM A588 specifies high strength low alloy weathering steel for structural purposes,it includes 4 grades Grade A,Grade B,Grade C,Grade K.For it has protective oxide film on steel surface,compared with ASTM A36 and ASTM A572-50,it has better cossrosion resistant characteristic,use ASTM A588 steel plate instead of common carbon steel\nMay 11,2012 astm a572 steel grade 50 properties chemical composition#0183;Therefore,this grade of structural steel will have a slightly different chemical composition to the standard S355 grade.Mechanical Properties of Structural Steel - S235,S275,S355 The mechanical properties of structural steel are fundamental to its classification and application.Steel grades according to American standards - A36,Chemical composition A36 - 04b A36 0.26 0.05 0.04 0.40 A572 - 04 Grade 42 0.21 1.35 0.05 0.04 0.40 Grade 50 0.23 1.35 0.05 0.04 0.40Standard Grades C, Mn, Diameter,Thickness,or Distan Standard Grades C, Mn, Structural Shape Flange or Leg ASTM A572/A572M Grade 42  0.21 1.35 6 (150) ASTM A572/A572M Grade 50  0.23 1.35 4 (100) 8 rows on theworldmaterialASTM A572 Grade 50 chemical composition steel plate,ASTM ASTM A572 Grade 50 chemical composition as under Maximum percentage of Carbon (C) is 0.230.Maximum percentage of Manganese (Mn) is 1.35.Maximum percentage of Phosphorous (P) is 0.040.Maximum percentage of Sulphur (S) is 0.050.Maximum percentage of Silicon (Si) is 0.350.Remaining is iron (Fe) percentage and with few negligible impurities.ASTM A572\nA572 Grade 50 Covers structural steel shapes,plates,piling and bars Intended for riveted,bolted or welded construction of bridges,buildings and other structures A992 Covers W shapes (rolled wide flange shapes) intended for use in building framing.Scope A572 Grade 50 A992 Element Composition % Element Composition % Carbon,max 0.23 Carbon,max 0.23SHAPE MATERIAL (ASTM A572 Gr 50 with specialSilicon,max Refer to ASTM A572 VanadiumbRefer to ASTM A572 ColumbiumbRefer to ASTM A572 Phosphorous,max 0.035 Sulfur,max 0.045 Element Composition,% Copper,max 0.60 Nickel,max 0.45 Chromium,max 0.35 Molybdenum,max 0.15 aMinimum manganese for Group 1 shapes is 0.30%.The ratio of manganese to sulfur shall not be less than 20 to 1.Related searches for astm a572 steel grade 50 properties chastm a572 grade 50 sheeta572 gr 50 steel propertiesastm a572 grade 50 vs a36 steelastm a572 grade 50 specificationsastm a572 grade 50 datasheetastm a572 gr 50 platea572 steel equivalenta572 gr50 materialSome results are removed in response to a notice of local law requirement.For more information,please see here.Previous123456Next\nastm a572 grade 50 sheeta572 gr 50 steel propertiesastm a572 grade 50 vs a36 steelastm a572 grade 50 specificationsastm a572 grade 50 datasheetastm a572 gr 50 platea572 steel equivalenta572 gr50 materialSome results are removed in response to a notice of local law requirement.For more information,please see here.12345NextASTM A572 Structural HSLA Grade 50 SteelThe Chemical Composition of HSLA Grade 50 Steels ASTM A572 defines the chemical composition of HSLA Grade 50 steels as under Maximum percentage of Carbon (C) is 0.230.Maximum percentage of Manganese (Mn) is 1.35.Q345 Steel,Q345A Q345B Q345C Q345D Q345E Equivalent Q345 Steel Properties.Q345 steel is a Chinese GB standard Low Alloy High Strength Structural Steel,material density is 7.85 g/cm3,tensile strength is 470-630 Mpa,and yield strength is 345 MPa,it has better properties than Q235.According to GB/T 1591 2008,Q345 material has 5 quality grades Q345A,Q345B,Q345C,Q345D and Q345E.Q345 steel has good weldability,Plate - McneilusASTM A572 Gr50.ASTM A572 is a high strength low alloy steel that offers a higher strength than plain carbon steel plates plus ductility,weldability,formability,toughness and fatigue strength.A572 meets a minimum strength requirement (dependent on grade) and provides good workability and weldability at a moderate price.\nLow alloy steel ASTM A572 Gr 50 is usually produced into steel plates,channel steel and heavy steel beams.Low alloy steel ASTM A572 Gr 50 equivalent material such as EN S355JR,DIN ST52-3,JIS SM490B,GB Q345B has much in common with steel ASTM A572 Gr 50.Chemical composition of Low alloy steel ASTM A572 Gr 50 equivalent material:High Quality Weathering Steel Plate-ASTM A242 Type 1ASTM A242 Type 1 Steel Plate.AGICO-ANSON manufactures high quality weathering steel-ASTM A242 steel plate,ASTM A242 specification is made for low alloy steel with high strength,it has good atmospheric corrosion resistance,some applications has shown that it has better corrosion resistance than ASTM A36 steel plate and ASTM A572 Grade 50.The same as weathering steelHSLA Grade 50 steel,HSLA Grade 50 Steel Mechanical HSLA Grade 50 Steel Chemical Composition ASTM A572 defines the chemical composition of HSLA Grade 50 steels as under Maximum percentage of Carbon (C) is 0.230.Maximum percentage of Manganese (Mn) is 1.35.Maximum percentage of Phosphorous (P) is 0.040.Maximum percentage of Sulphur (S) is 0.050.\nGrade Yield Point (ksi) Tensile Strength (ksi) Min.8 Elongation % 42 42 60 20 50 50 65 18 55 55 70 17 6 rows on leecosteelAstm A572 Grade 50 - azaleacruises\nA572 Structural,Carbon HSLA Steel Plate - Chapel Steel A572 is a high strength low alloy steel plate used in a variety of structural applications.The most common grade Chapel Steel stocks is Grade 50.ASTM A36 Carbon Steel vs.ASTM A572 Grade 50 : Both ASTM A36 carbon steel and ASTM A572 grade 50 are iron alloys.Differences Between ASTM A529 A572 HunkerThe American Society for Testing and Materials standardizes,among other things,the composition and mechanical properties of steel.While many forms of steel possess similar compositions,such as A529 and A572,relatively small differences in the quantities of particular elements are enough to make the steels have different mechanical properties,and therefore,China ASTM A572 Gr.50 Q345b ERW Steel Pipes Suppliers ASTM A572 Gr.50 Q345b ERW Steel Pipes.Product:Fluid steel PipeASTM A572 Fluid Pipe Astm A572 Seamless Pipe Size OD:219mm 3120mm WT 1.25mm to 50mm LENGTH 6mtr ~ 18mtr,SRL,DRL ApplicationGeneral structure,\nASTM A572 Gr.50 Q345b ERW Steel Pipes.Product:Fluid steel PipeASTM A572 Fluid Pipe Astm A572 Seamless Pipe Size OD:219mm 3120mm WT 1.25mm to 50mm LENGTH 6mtr ~ 18mtr,SRL,DRL ApplicationGeneral structure,Carbon Steel A572 Gr 425 Plates,Carbon Steel Gr 50Carbon Steel A572 Gr 45 / 50 Sheets / Plates Specification.Specification ASTM A572 / ASME SA572 Thickness 8 mm to 300 mm Width 1500 mm to 4020 mm Length 3000 mm to 27000 mm Finish Hot rolled plate (HR),Cold rolled sheet (CR),2B,2D,BA NO(8),SATIN (Met with Plastic Coated) Form Coils,Foils,Rolls,Plain Sheet,Shim Sheet,Perforated Sheet,Astm A572 Steel Sheet Plate Grades 42,50,55,60,65 Properties Min.Tensile Strength 65,000 psi Min.Yield Strength 50,000 psi Typical Uses. 4 (Greater than 4 thru 6 would be A572 Grade 42) ASTM A572 Chemical Composition. a572 grade 50 steel round bar a572 hot rolled steel a572 steel shim sheet\nA Carbon 0.19% max Manganese 0.80-1.25% Phosphorus 0.030% max Sulfur 0.030% max Silicon 0.03-0.65% Nickel 0.40% max Chromium 0.40-0.65% Copper 0.25-0.40% Vanadium 0.02-0.10% B Carbon 0.20% max Manganese 0.75-1.35% Phosphorus 0.030% max Sulfur 0.030% max Silicon 0.15-0.50% Nickel 0.50% max Chromium 0.40-0.70% Copper 0.20-0.40%ASTM A573 Steel Plate - Grade 58,65,70 Material Properties The following material properties are ASTM specifications and will be confirmed on the Mill Test Report.Grade Yield Point (ksi) Tensile Strength (ksi) Min.8 Elongation % 58 32 58-71 21 65 35 65-77 20 70 42 70-90 18 Chemical Composition The following composition properties are ASTM specifications for these A573 grades.A573 GRASTM A572/ A572M Grade 50 High-Strength Low - BBNSTEEL SteelASTM A572/ A572M Grade 50 High-Strength Low-Alloy Structural Steel Plates BBNSTEEL Steel can supply A572 Grade 50/ A572 Gr50 High-Strength Low-Alloy Structural Steel Plate,mainly used in construction for bridges and welding fields.\nExporter,Supplier,Stockist Manufacturer Of High-Quality ASTM A572-50W Corten Steel Plates Sheets.We Have Ready Stock Of Corten Steel Astm A588 Corrosion Resistant Plate Sheet / Weathering Steel ASTM A588 Plate Sheet.ASTM 588 GR.A,ASTM 242 TYPE-1,JISG 3125 SPA-H,IRSM 41-97 Corten Steel Plate Sheet.ASTM A572 Structural HSLA Grade 50 SteelDimensional Characteristics of HSLA Grade 50 Steels The applicable thickness for this HSLA Grade 50 material as defined in the ASTM A572 starts from 10 mm to 60 mm.The Chemical Composition of HSLA Grade 50 Steels ASTM A572 defines the chemical composition of HSLA Grade 50 steels as under Maximum percentage of Carbon (C) is 0.230..MaximumASTM A572 Steel Channel - High StrengthASTM A572 steel sections have three grades - Grade 42,50 and 55.You can find the specific chemical content mechanical properties in the tables below.Product description Item ASTM A572-50 steel channel.Dimensions UPN UPE.Web width 80 - 200 mm.Web thickness 6 - 8.5 mm (UPN) 4.5 - 5.2 mm (UPE).\nASTM A572 steel sections have three grades - Grade 42,50 and 55.You can find the ASTM A572 Grade50,55,60 HSLA Structural Steel Plate-AGICOASTM A572 Specification refers to High-Strength Low-Alloy Steel Plate for structural building,among the 5 steel grades of 42,50,55,60 and 65,Grade 50 is one most common steel in applications where need more strength and less weight,use steel plate of this grade other than ordinary carbon steel will make the steel structure with same steel strength but lighter weight.ASTM A572 Grade 65,A572 Gr.65,A572Gr65 steel plate__Steel BBNSTEEL is specialized in supplying ASTM steel plate in A572 Grade 65.For more information of A572 Grade 65 steel plates,please check them in following Chemical composition % of the Product analysis of grade A572 Grade65 .\nIf you want to get the ASTM A572 Grade 55/A572 Gr.55 HSLA structure steel plate steel price,please do not hesitate to contact us.Any need in ASTM A572 Grade 55/A572 Gr.55 HSLA structure steel plate Chemical Composition and Mechanical Properties,please feel free to contact us by email or calling to us.ASTM A572 Grade 55 Steel Sheet/Plate Suppliers,Buy ASTM ASTM A572 is a specifiation covers the standard requirements for Grades 42 ,50 ,55 ,60 ,and 65  of high-strength low-alloy columbium-vanadium structural steel shapes,plates,sheet piling,and bars for applications in bolted,welded,and riveted structures in bridges and buildings.ASTM A572 Grade 50|A572 Gr.50|A572Gr50 steel plate__Steel BBNSTEEL is specialized in supplying ASTM steel plate in A572Gr50.For more information of A572 Grade 50 steel plates,please check them in following Chemical composition % of the Product analysis of grade A572 Grade 50 .\n8 rows astm a572 steel grade 50 properties chemical composition#0183;ASTM A572 Grade 50,60 65 Data Sheet Properties.Chemical properties shall conform to the ASTM A572 Grade 50 Steel Equivalent,Gr 65,60 Properties 8 rows astm a572 steel grade 50 properties chemical composition#0183;Oct 04,2020 astm a572 steel grade 50 properties chemical composition#0183;ASTM A572 GR 50 steel equivalent European standard is EN 10025-2 S355 steel.ASTM ASTM A572 Grade 50 Plate,Corten Steel ASTM A572 42/50 ASTM A572 Gr 50 Carbon Steel Plates Stockists,Corten Steel ASTM A572 50 Plates Suppliers in India.We at Neelcon Steel company is producing ASTM A572 Grade 42/50 Sheets,ASTM A572 Gr 42/50 Plates in Mumbai.we have our ware house in Thane district and factory in Gujarat.We also have our distributor in China and we can supply ASTM A572 Gr 50 Carbon Steel\nOwing to its high strength ASTM A572 Grade 50 Plates requires less material to satisfy strength requirements than plain carbon steel.ASTM A572 Grade 50 Steel Plate have a yield strength 50,000 psi minimum,the tensile strength of 65,000,and elongation of 19% in 2.Due to the alloy elements of these Sheets,its atmospheric corrosion resistance is increased.ASTM A572 Grade 50 Pipe,Carbon Steel ASME SA572 Gr 50 The Astm A572 Grade 50 Pipe detail is the Standard Specification for High-Strength Low-Alloy Columbium-Vanadium Basic Steel for plates utilized inASTM A572 Grade 50 Pipe - HYSP Steel Pipe SupplierASTM A572 Grade 50 Pipe.As you know,ASTM A572 covers five grades of high-strength\nGanpat Industrial Corporation is also one of the well known supplier and trading house for high quality ASME SA 572 Gr.50 Carbon Steel Coils,which are characterized by high chromium (19 % 32 %) and molybdenum (up to 5 %) and lower nickel contents than austenitic stainless steels.ASTM A572 Grade 42,ASTM A572 Grade 42 High TensileASTM A572 Grade 42 cold rolled steel ASTM A572 Grade 50 low alloy steel ASTM A572 Grade 60 high tensile steel.Henan Join-Win Im/Ex Corp.is a professional ASTM A572 steel stockist and supplier.We can supply different product type and good quality ASTM A572 Grade 42,ASTM A572 Grade 50,ASTM A572 Grade 60 steel.If you have any need of ASTM ASTM A572 Grade 345 - Unclassified Carbon Steel -A Unclassified Carbon Steel also known as with Mechanical,thermal and chemical properties..Datasheet Download.\nASTM A572 Gr42 steel plate Chemical composition(%) C0.21 Si0.4 Mn1.35 P0.04 S0.05 Nb:0.005-0.05 V:0.01-0.15.ASTM A572 Gr42 steel plate Mechanical properties.Yield strength Ksi(Mpa):50(345) Tensile strength Ks(Mpa):65(450) Elongation%:21.MOQ 1 PC.Product type Steel plate.Delivery time Promptly ( Stock) or 10-40 days ASTM A572 - SSABThe ASTM A572 specification is the Standard Specification for High-Strength Low-Alloy Columbium-Vanadium Structural Steel for plates used in general construction and structural applications.ASTM A572 includes five grades with specified minimum yield strengths of 42,50,55,60,and 65 ksi,respectively.ASTM A387 Grade 11,22 Alloy Steel Plates Specification Except 21L,22L and 91,each grade is available in two classes of tensile strength levels as defined in the tensile requirements tables.Grades 21L and 22L only has Class 1,and Grade 91 only has Class2.Refered Standards for ASTM A387 Alloy Steel Plate ASTM.A20/A20M General requirements for pressure vessel plates.\nMay 30,2020 astm a572 steel grade 50 properties chemical composition#0183;Both ASTM A36 carbon steel and ASTM A572 grade 50 are iron alloys.Both are furnished in the as-fabricated (no temper or treatment) condition.They have a very high 99% of their average alloy composition in common.For each property being compared,the top bar is ASTM A36 carbon steel and the bottom bar is ASTM A572 grade 50.ASTM A252 Piling Pipe-ASTM A252 Spiral Steel Pipe_ASTM ASTM A252 Piling Pipe.ASTM A252 Piling Pipe STEEL GRADE ASTM A252 GR 1,GR 2,GR 3 STEEL CHEMICAL COMPOSITION The steel shall conform to the following requirements as to chemical composition Phosphorus,maximum (%) 0.050 MECHANICAL PROPERTIESASTM A1011 HSLAS-F Grade 50 ASTM A1011/A1011M - BBN STEEL ASTM A1011 HSLAS-F Grade 50 ASTM A1011/A1011M chemical.ASTM A1011 HSLAS-F Grade 50 ASTM A1011/A1011M In addition to carbon,steel also contains a small amount of manganese (Mn),silicon (Si),sulfur (S),phosphorus (P),oxygen (O),nitrogen (N) and hydrogen (H).These elements are not intentionally added to improve the quality of steel,but\nMaterial Properties The following material properties are ASTM specifications and will be confirmed on the Mill Test Report.Grade Yield Point (ksi) Tensile Strength (ksi) Min.8 Elongation % Grade 42 42 62-82 18 Grade 50 - 2.5 thick 50 70-90 16 Grade 50 - astm a572 steel grade 50 properties chemical compositiongt;2.5 thick 47 70-90 16 Chemical Composition The following composition properties are API specifications for the 2H grade.GradeA690 Mariner Steel The Facts [iSheetPile] - Think ASTM A690 (or,Mariner Steel) was created and promoted by US Steel in the 1960s.At the time there was no grade of steel higher than A328 (39 ksi yield strength),and the US Steel sheet piling literature focuses on the fact that,as a stronger grade of steel,A690 (50 ksi yield strength) will be stronger longer than A328 once corrosion sets in (for any environment).A572 grade 50 round bar,A572 grade 50 steel Chemical A572 grade 50 round bar,A572 grade 50 steel Chemical Composition A572 steel is a high strength,low alloy columbium vanadium structural steel.A572 grade 50 round bar with specification providing for a 50,000 KSI minimum yield strength\nThe ASTM A572 carbon steel specification covers the standard requirements for Grades 42,50,55,60,and 65 for high-strength low-alloy columbium-vanadium structural steel shapes,plates and bars for applications in bolted,riveted and welded structures in bridges and buildings.Consequently,the combined use of columbium,vanadium,titanium meet the requirements ofA572 Grade 65 Chemical Composition,A572 Grade 65 A 572 Gr.65 steel plate are intended for riveted or bolted construction of bridges or for riveted ,bolted,or welded construction in other applications.Compared with A572Gr60 steel,A572 Gr.65 steel plate has a more yield and tensile strength in project.If you want to lower yield,you could choose A572 Gr.50 to use them in your projects.A572 Grade 65 Chemical CompositionA572 Grade 42,50,55,60,65 Steel Plates 6 rows astm a572 steel grade 50 properties chemical composition#0183;Material Properties The following material properties are ASTM specifications and will be\nThis page cover the A572 Gr.50 chemical element,Mechanical Properties,A572 Gr.50 Datasheet,Cross Reference of A572 Gr.50 steel,Mainly used for .A572 ( AISI,ASTM,UNS) - Worldwide equivalent gradesChemical composition and properties of european equivalents (EN) for A572 (USA,AISI,ASTM,UNS) S355JR (1.0045) ,S275J2(+N) (1.0144) ,A572 (USA,AISI,ASTM,UNS ) - European (EU,EN) and wordwide Steel equivalent grades These comparison table is only intended as an indication of the closest khown equivalent grades. TYPE A ELEMENTS HEAT ANALYSIS,% 1 Columbium 0.005-0.05 B 2 Vanadium 0.01-0.15 C 3 Columbium 0.005-0.05 B Vandadium 0.01-0.15 C 8 rows on octalmetalsDatasheet for Steel Grades Carbon Steel A572 GrSteel GradesA572 Gr.50 Chemical information,Mechanical properties Physical properties,Mechanical properties,Heat treatment,and Micro structure A572 Gr.50 Physical Properties Tensile strength 115-234 b/MPa Yield Strength 23 0.2 /MPa Elongation 65 5 (%) - (%) Akv - Akv/J HBS 123-321 - HRC 30 - A572 Gr.50 Mechanical Properties\n- carbon low alloy steel\n- Shipbuilding steel plate\n- Weathering steel plate\n- Boiler pressure vessel steel\n- Gas cylinder steel\n- Alloy Steel\n- Stainless steel\n- Pipeline steel\n- Section steel\n- A283Grade-C steel plate\n- AH36 Steel Plate']	['<urn:uuid:e3461b67-d9a2-4ac6-88ba-30e3bb43cf9e>', '<urn:uuid:ce63702e-1cb9-46e6-942c-92cda1d92885>']	factoid	direct	short-search-query	distant-from-document	comparison	novice	2025-05-13T04:02:16.770989	6	34	3690
34	My friend's child is deaf and attending regular school with an interpreter. Will having a good interpreter be enough to help them succeed in class?	Recent research from the National Technical Institute for the Deaf indicates that having qualified interpreters alone is not sufficient. The research shows that even with qualified interpreters in the mainstreamed classroom, educators need to understand that deaf children learn differently, are more visual, and often process information differently than their hearing peers.	"[""An interesting article has been published about the research that has been carried out at the National Technical Institute for the Deaf in America (NTID), part of the Rochester Institute of Technology (RIT).\nTheir research looks at and challenges the assumptions involved in teaching Deaf children, with thousands of Deaf children being tested across the world. One finding is that children who signed at a young age generally outperformed those who did not.\nExtract (read the full article here).\nResearch at NTID is shifting the way deaf students are being educated. Recent research suggests that even with qualified interpreters in the mainstreamed classroom, educators need to understand deaf children learn differently, are more visual, and often process information differently than their hearing peers.\nResearch Findings at NTID\nA popular assumption in education for many years was that deaf students are the same as hearing students except that they simply don’t hear. But research at RIT’s National Technical Institute for the Deaf is contradicting that belief, and consequently altering the way deaf students are being taught.\n“We’re changing the face of deaf education around the world,” says Dr. Marc Marschark, professor and director of NTID’s Center for Education Research Partnerships (CERP). “You can’t teach deaf kids as though they are hearing kids who can’t hear. It’s not about ears and it’s not about speech versus sign language. It’s about finding their strengths and needs. The historical approach to deaf education simply doesn’t work well enough to get deaf students where they need to be.”\nRead the full article: http://www.rit.edu/showcase/index.php?id=86\nThe Limping Chicken is the world's most popular Deaf blog, and is edited by Deaf journalist and filmmaker Charlie Swinbourne. Find out how to write for us by clicking here, how to follow us by clicking here, and read our disclaimer here.\nThe site exists thanks to our supporters. Check them out below:\n- Ai-Media: Remote captioning. Find out about the Deaf fashion bloggers taking on the world!\n- Bellman & Symfon: home alerting solutions\n- Deaf Umbrella: sign language interpreting and communications support\n- Appa: Communication services for Deaf, Deafblind and hard of hearing people\n- SignLive: Online video interpreting for Deaf people\n- SignVideo: Instant BSL video interpreting online\n- 121 Captions: captioning and speech-to-text services\n- Signature: Leading awarding body for BSL qualifications\n- The National Theatre: Captioned and BSL accessible theatre in London\n- Doncaster School for the Deaf: education for Deaf children\n- Signworld: Learn BSL online!\n- Action Deafness Communications: sign language and Red Dot online video interpreting\n- BSLcourses.co.uk: Provider of online BSL courses\n- Association of Notetaking Professionals: The professional body representing Electronic and Manual Notetakers\n- Sign Solutions: communication support, training and translation\n- InterpretersLive: On demand BSL video interpretation\n- Cast Theatre, Doncaster: The UK's the UK’s first fully BSL integrated pantomime\n- Hamilton Lodge School in Brighton: education for Deaf children\n- Lipspeaker UK: specialist lipspeaking support\n- Ozen: Australian hearing aid specialists\n- Elmfield School, Bristol: Inclusive education for Deaf pupils\n- deafPLUS: BSL advice helpline\n- Exeter Deaf Academy: education for Deaf children\n- Royal Shakespeare Company: Captioned and BSL interpreted performances (see dates here)\n- Royal School for the Deaf, Derby: Residential education for deaf children\n- RAD Tax Advice: Tax and Tax Credit info for Deaf people\n- Deaf Independent: Deaf care and support services\n- Performance Interpreting: BSL interpreting at concerts\n- National Deaf Children's Society: The leading charity for deaf children\n- Signed Culture: Advocating for BSL access to arts and culture\n- SignHealth: healthcare charity for Deaf people\n- CJ Interpreting: communication support in BSL\n- British Society for Mental Health and Deafness: Promoting positive mental health for deaf people""]"	['<urn:uuid:74d06c9a-1bcc-4b17-8e0d-416efc32bc57>']	open-ended	with-premise	verbose-and-natural	distant-from-document	single-doc	novice	2025-05-13T04:02:16.770989	25	52	616
35	why many indian writers move live abroad explain	Many Indian writers move abroad because it gives them better access to the marketplace, publishers, editors and agents in the west. They also get opportunities to teach at universities abroad, access to better jobs, and more scholarships.	"['Kiran Desai\'s Booker-winning novel The Inheritance of Loss has been a bestseller in India for weeks now. It is displayed proudly in upmarket bookshops. Bootleg copies are brandished by boys, weaving in and out of traffic light fumes. These boys can\'t read, but they know what everyone wants: ""Kiran book"".\n""The Booker is huge here - India cares for it in a deep, fierce way. It\'s like Miss Universe. We think it is our own prize because so many Indians have won it and there is a disproportionate amount of interest within the country because of it,"" explains Jeet Thayil, a poet and novelist who lives in Delhi.\nThe Inheritance of Loss is largely based in India, where Desai lived until she was 14. She now lives in America, making her the latest in a line of very successful non-resident Indian (NRI, in the customary acronym) writers. Although India basks in the limelight of such NRIs as Salman Rushdie and Vikram Seth, their ability to portray India from abroad has been questioned. Another NRI, Vikram Chandra writes about being hounded by a Delhi English professor for his use of Hindi words. Now Kiran Desai\'s ""Indianess"" has been scrutinized by the Indian media.\n""There\'s been a fair bit of chatter about why she italicised Hindi words and didn\'t wear a sari to the prize-giving, whether she pandered too much to a western audience,"" admits Tishani Doshi, a writer who is based in the subcontinent. Doshi lives in Madras and her first novel, The Pleasure Seekers will be published by Bloomsbury soon. She feels living in India is essential to her creativity.\n""I have more friends in London than here, but the quality of my work is much clearer, much purer in India than in England. What I felt when I came back home was I can be a writer and I didn\'t know that in London,"" she said.\nAltaf Tyrewalla, whose novella No God in Sight was released last year to critical acclaim, lives in Bombay. He found it impossible to write as an NRI.\n""I don\'t know how, for instance, I could write from the perspective of an imaginary butcher in a chicken shop if I wasn\'t also suffering the humidity like him, suffering the noise of a ghetto like him, and yet trying, like him, to think amidst this discomfort, this cacophony ... Midway through writing No God In Sight, I went to New York to be with my fiancée (now wife), hoping to continue with the novel there. I assumed I could write anywhere, that I could stretch my imagination wide enough to surmount the distance of thousands of kilometres. I was back in Mumbai in two months. It was a very expensive misadventure.""\nNevertheless, many homegrown writers have moved abroad - and Nilanjana Roy, one of India\'s foremost literary critics, can understand why. ""For the Indian writer working in English, going abroad was one way to reach the marketplace, to lessen the very considerable distance between publishers, editors and agents in the west and the writer at \'home\',"" she says. ""Vikram Chandra and Amit Chaudhuri teach at universities abroad; other writers have shifted because they have access to better jobs, more scholarships.""\nDelhi-based reviewer Hirsh Sawhney agrees, believing these opportunities essential for success. ""India continues to produce some of the world\'s most talented English-language writers but many homegrown novelists only make it big after moving abroad - Vikram Seth, Amitav Ghosh ... The exception is Arundhati Roy and she hasn\'t written a novel since bagging the Booker. There aren\'t as many literary institutions in India so writers aren\'t challenged to produce better work - aren\'t nurtured.""\nBut the Booker Prize has affected the future of Indian novelists. Arundhati Roy\'s Booker prize win in 1997 sparked an interest in Indian writing which has led to many new publishing houses being set up. The fact that this year\'s Booker prize winner is yet another NRI does not matter to Jeet Thayil.\n""There is no difference between non-resident and resident writers now. I see it as one body of work,"" he claims. ""If you are a 21-year-old writer living in some little town in India and you read everything you can get your hands on and really learn your craft you have every chance of being published in New York.""\nIn fact, many NRIs such as Thayil are moving back to India to write. He spent years in America as a journalist and poet but returned home to work on his first novel. ""I wouldn\'t have been able to work full time on a book in America because there\'s no question of living there without a job,"" he explains. ""You need the health insurance.""\nNow, working on his book in a wi-fi Delhi cafe, an espresso by his side, Thayil doesn\'t seem to be missing America much. ""Things have changed tremendously in India - when I left in the 1990s there was little possibility of a literary life. There were few publishers and prizes. Now there\'s a thriving literary scene.""\nRana Dasgupta is another writer who signals a reversal of the expatriate template. His father is Indian but he was bought up in Britain and worked for a New York marketing company before moving to Delhi, where he began to write. His novel, Tokyo Cancelled, was published in 2005. ""Something of the Indian spirit informs what I do. There are people coming from abroad to Delhi to work in publishing and journalism - it\'s becoming a cosmopolitan city,"" he says.\nThe social side of literature, too, seems to be thriving. Jaipur, the famously pink city in the middle of the Rajasthan desert, held its second literature festival last month. Despite the remote location, prominent writers such as Salman Rushdie, Sukethu Metha and Kiran Desai all made the journey from America to be there. David Godwin, the agent responsible for both Desai and Arundhati Roy, came from London. But he wasn\'t looking for his next Indian prizewinner and didn\'t sign any authors.\n""Arundhati Roy\'s The God of Small Things was exceptional. All Booker winners are exceptional. You can\'t judge these things. But there have been amazing changes in publishing and India has a more mature literary culture. There is the beginning of branching out into genres and regions,"" he said.\nCritic Nilanjana Roy also attended the Jaipur festival. ""It\'s always difficult to predict literary success, but I\'m greatly interested in the work of Tishani Doshi, Altaf Tyrewala and Siddharth Chowdhury, in Jeet Thayil\'s forthcoming novel and in Ruchir Joshi\'s second novel-in-progress,"" she said. ""I like the way that other literary genres have begun to open up - Anushka Ravishankar does excellent children\'s writing, Kalpana Swaminathan writes detective stories, Samit Basu spins fantasy Indian-style.""\nNo one in India has pinpointed the next homegrown prize-winning writer, but Desai\'s NRI win seems to confirm, rather than undermine, the place of novelists writing in India now. They appear confident that there are new things to say, that people are interested when they say them, and that they can produce books as good as writers living in the west. In fact, they are beginning to write back to the west: perhaps the next big book to come out of India will have nothing to do with the country. Pankaj Mishra\'s new book is about China and Rana Dasgupta\'s second novel, written from Delhi, is set in Bulgaria.\n""I have a lot of pressure from my publishers to write about India,"" he admits, but ""it is a colonial hangover in publishing to think that writers in India, Africa and the Caribbean must write about their home cultures while writers from the West could write about anywhere. Mature literary cultures should feel like they can write about the world.""']"	['<urn:uuid:34cdabce-e2d7-400f-b057-370258462dd8>']	factoid	with-premise	long-search-query	distant-from-document	single-doc	novice	2025-05-13T04:02:16.770989	8	37	1291
36	main reason medical companies check virus safety	Virus safety is checked because animal cell culture involves risks related to virus safety, particularly with Chinese Hamster Ovary (CHO) cell lines which may contain endogenous retroviruses or retrovirus-like particles, and there's also risk of contamination by adventitious viruses. This is critical for patient safety in biopharmaceutical manufacturing.	['Virus Safety in Continuous Processes\nJune 18, 2020\nVirus safety is a key element in biopharmaceutical manufacturing. Inherently, animal cell culture involves risks related to virus safety. Chinese Hamster Ovary (CHO) cell lines are the most common production platform for expressing glycosylated proteins and monoclonal antibodies. Being from rodent origin, CHO cell lines may contain endogenous retroviruses or retrovirus-like particles. Additional virus safety risks come from the possibility of the cell culture being contaminated by adventitious viruses. As a consequence, the regulatory expectation for manufacturing platforms is to demonstrate the ability to remove or inactivate a wide range of viruses to minimize the impact of viruses on patient safety.\nVirus inactivation (VI) is one of the key elements in providing virus safety. It targets enveloped viruses that may be present in the product feed, typically the eluate from the Protein A chromatography step. A widely accepted solution is the exposure to low pH conditions (e.g., pH 3 – 3.6) by acidifying the solution with acetic acid and maintained at that low pH for a specific length of time (typically 60 minutes).\nThere are various approaches for continuous VI. One approach that is being explored by the bioprocessing field relies on a plug flow contactor. In this concept the pH of the eluted monoclonal antibody is lowered in-line as it enters a tubular plug flow contactor. The length of the tubular plug flow contactor is chosen such that it provides the required residence time for the inactivation process. Challenges with the plug flow concept include scale-down validation, managing concentration gradients in the process, and managing process disturbances and upsets. In addition to this, forward processing often requires homogeneous process conditions.\nPall’s approach for continuous VI relies on repetitive batch inactivation instead. The failure mode and effects analysis (FMEA) approach taken when designing and developing Pall’s Cadence® VI system suggested that the product risks and process risks are not significantly different with this approach than in the batch equivalent. Pall’s continuous VI concept relies on the same approach as in the well-known batch VI process and as a result the critical process parameters (CPPs) are also identical. This approach eliminates many uncertainties in scale-down validation, and it provides homogeneous process conditions for forward processing. Pall’s Cadence® VI system has the potential to be used for both, low pH VI as well as solvent/detergent VI.\nVirus retention filtration is the last step in providing virus safety in the downstream processing of monoclonal antibodies. It serves to remove viruses by size and is specifically designed to target small viruses. The virus filtration step is generally assumed to have no impact on any other quality attribute and hence the critical process parameters are exclusively related to the virus removal.\nIn a fully integrated continuous downstream processing platform, the virus retention filtration is performed at constant flow, whereas the common procedure for batch virus filtration is to run the process at constant pressure. Furthermore, unlike batch processing where the output from the previous step is pooled prior to virus filtration, it is possible that the feed to the virus filter in a continuous process has variabilities in protein concentration/pH/conductivity etc. These variabilities are a consequence of the nature of the prior step (eg. chromatography column eluate). If a surge vessel is used between these unit operations, that could be sized to provide a homogenous feed to the virus filtration step. However, if a surge vessel is not employed, the variation in protein concentration/pH/conductivity on virus removal performance needs to be risk assessed. If prior knowledge is not available, these variables may need to be included in a virus clearance study.\nDuring the process, the virus retention filter accumulates viruses and some protein inside the tortuous flow path. Consequently, one would normally see a decay in flux during the batch virus filtration step. This flux decay is a result of a gradual increase in resistance of the filter. In continuous processing, this will translate into an increase in pressure differential across the filter. Provided that the virus validation studies are carried out such that both the minimum and maximum pressures are studied, the data will be representative for the continuous process as well. The critical process parameters for continuous virus filtration therefore would translate into the maximum volume to be processed (similar as in batch virus filtration) and the maximum back pressure that can be accepted (equivalent to the flux decay in the batch virus filtration process). These CPPs can be investigated using constant pressure and – provided that the study design covers the entire operating range of the virus filtration step – the results apply to a constant flow process.\nAn additional factor that needs to be considered in selecting an adequate virus filter and designing the virus filtration step is its capability of handling process interruptions. This is something that may have to be considered for every step in the continuous downstream processing platform, but it may be more critical for virus filtration. The reason for this is that not all virus retention filters tolerate process interruptions equally well. In some filters, release of the transmembrane pressure and/or process interruptions can affect the virus removal capability of the filter as a result of so-called back-diffusion.\nDiscover more in the webinar Quality by Design (QbD) Approach for a Virus Filtration Application.\nThank you for signing up\nThank you for signing up to the Biotech Blog.\nDenis Kole - Principal Scientist, Scientific and Laboratory Services\n- Sort By']	['<urn:uuid:5aacc364-58be-41f3-8eaf-9376f0a824de>']	factoid	direct	short-search-query	distant-from-document	single-doc	novice	2025-05-13T04:02:16.770989	7	48	911
37	What's the difference between single and three-phase generator calculations?	For single-phase generators: Amps X Volts = Watts/1000 = Kilowatts. For three-phase generators: Amps X Volts X 1.73 (Power Factor) = Watts/1000 = Kilowatts.	['Generator Sizing Calculation Overview\nPurchasing a generator requires significant capital and in many cases, is a one-time investment.\nA good purchasing decision must, therefore, involve the choice of a generator that will handle all your power requirements.\nMany factors affect the size of a generator you need making it very difficult to make a straightforward decision on generator size.\nAn oversized generator may cause stress and damage to devices connected to it, while an undersized generator may not power up all your devices as required.\nA generator calculator helps you determine the size of a generator you need by factoring in all your power consumption needs.\nHow to calculate what size generator I need?\nThe size of a generator mainly depends on the total power use of all your equipment in wattage.\nYou should start by making a list of all equipment consuming power in your particular setting.\nAlongside each piece of equipment on the list should be an indication of the power requirement of each piece of equipment in watts.\nFinally, the total of your power requirement should be calculated as this is what determines the size of the generator you need.\nYou should choose a generator that is slightly larger in capacity to cater for under-performance cases of the generator or replacement of equipment with a higher power requirement.\nAlthough home power requirements are relatively lower, proper calculation of generator size is still needed.\nMost of the home generator calculators available online require you to feed information on the power usage of the home equipment that you would want to keep running after a power outage.\nOn feeding all your wattage figures, the total is calculated and the size is determined for you automatically.\nCommercial Generator Sizing Calculator\nSince power outages in business areas such as industries may cause substantial financial liabilities if not addressed on time, an excellent-sized generator must be available.\nThe facility’s square footage and peak usage in real-time are what is needed in a commercial generator calculator.\nOn the calculation of the total kilowatt required, a generator size is selected for your commercial power backup.\nTo ensure that you are not overwhelmed with all these considerations when choosing a generator size, it is essential to use a generator calculator.\nTons of software are available online to assist in generator sizing.\nPurchasing a generator is a huge investment for a home or a business owner. It is also something not a lot of people buy, meaning there is a lot of confusion on calculating the generator load and sizing.\nThe best call is to consult an electrician, but if you decide to do a generator calculation by yourself, you can, by following a few basic rules.\nGenerator calculation (size)\nThe primary method in sizing a generator is as follows. Firstly you must create a list of all the items that will be powered by the generator.\nAfterward, you must determine the starting and running wattage for each piece of equipment.\nThose are the energies needed to turn the equipment on and to operate it. Usually, these are written on the equipment itself.\nFinally, you can calculate the total power needed by adding up those figures and purchasing a generator that has a 10-20% larger capacity.\nGenerator calculation (load)\nWhen calculating the generator load, you must first consider that there are two ways of generators being rated.\nWith kilo-volt-ampere (kvA) and with kilowatts (kW).\nThere is also a difference in the formulas depending on whether you have a single or a three-phase generator.\nThe formulas are:\nSingle-phase: Amps X Volts = Watts / 1000 = Kilowatts\nThree-phase: Amps X Volts X 1.73 (Power Factor) = Watts / 1000 = Kilowatts\nSingle-phase: Volts X Amps / 1000 = kvA\nThree-phase: Volts X Amps X 1.73 (Power Factor) / 1000 = kvA']	['<urn:uuid:bb99f354-48a8-44ee-a385-91fb60280820>']	factoid	with-premise	concise-and-natural	similar-to-document	single-doc	novice	2025-05-13T04:02:16.770989	9	24	634
38	I just got new winter tires installed in my car, but I'm not sure if I need to rotate them since they're only used during winter. Should I still rotate my winter tires?	Yes, you should rotate your winter tires. Rotating winter tires provides several important benefits including better snow cornering, improved steering response, increased balanced handling, greater braking performance, and enhanced traction on roads that are icy, snowy and slippery.	"[""Many car owners are great at taking care of huge maintenance issues with cars. But oftentimes, car owners may forget or neglect tire rotations. Let’s explore the importance of keeping tires rotated during the winter and the importance of rotation when it comes to winter car care.\nWinter Car Care Tips – Reasons That You Need to Rotate Your Tires\nTire rotations are one of the best ways to extend the life of your tires and your car. So, why are tire rotations important in the first place? We have good reasons that you need to keep those tires rotated!\n- More Even Tire Tread– Perhaps the biggest reason as to why you want to get those tires rotated is the fact that doing so will help to keep the tire treads as even as they can possibly be. Over time, that tread can become unbalanced, uneven and can even jeopardize even the quickest car trip. Lots of factors will place strain on the wheels and the tires. If your tires are not rotated, you run the risk of wearing out the tread quickly, resulting in damage to other car components.\n- Safety– As the tread on your tires wears out, you run the risk of damaging other car parts. Should your tire tread get unevenly worn out, the tires will not grip the street surfaces consistently. This of course, presents a danger to anyone riding in the car.\n- You Will Extend the Life Of Your Tires– Thanks to a good tire rotation job, you will extend the life of your tires. The more even you keep those tire treads, the longer your vehicle tires will last. If you put those tire rotations on the back burner, you risk one, two or even all four tires wearing out faster. You may even have two or three tires that will have uneven tread- causing you to have to replace them far more often than normal.\n- Better Performance – Did you know frequent tire rotations can help your vehicle perform better? Similar to safety, the performance of your vehicle will be directly affected by how even the tread on your tires is distributed. Tire rebalancing is also a task that is often overlooked by car owners- but it definitely impacts the performance of your car.\n- Better Working Components– As we stated earlier, tires that are constantly rotated will help other components of your car work better. With tires that are rotated you will have better performance from your brakes, axels, suspension system, wheels and wheel bearings.\nWinter Car Care and Tire Rotations- Three Most Common Tire Tread Patterns\nDriving on roads that are covered in snow, ice, salt and sleet requires tires that are balanced and have even tread. For tires that lack such, you run the risk of the tire not adequately gripping the road and getting into an accident. Various issues can result in tread patters that are unusual as well as unbalanced. Thanks to complete inspection of tires and their tread wear patterns, car owners can learn about the tread patterns and get those tires rotated ASAP.\nSo, what are the most three common tire tread patterns?\n- Edge wear\n- Center wear\n- Outer and inner edge wear.\nCenter wear is typically caused by tires that are overinflated. With that over-inflation, just the center of the tire makes contact with the road. Wear on both the outer and inner edges is a sign of underinflated tires. These parts of the tire come in contact with roads the most. Should you experience severe inner and outer wear then you may have a tire misalignment issue. Other common tire issues also include blistering and cupping of the tire’s sidewall. Often referred to as tire scalloping, tire cupping, results in an uneven tire wear pattern, due to bouncing or up-and-down motions of the wheels- that are irregular.\nGenerally, older vehicles will have suspension systems that have age on them. This means that they need more attention. If you drive an older car, you don’t want to ignore any suspension issues that you may have. Issues with your suspension will cause the tires to wear out quickly and far more unevenly. With that uneven tread, your tires will not make direct contact with the road. If you leave your suspension system untreated, you will also begin to develop issues with vehicle handling, braking and steering. Sidewall tire blistering is another issue. This means that you can see building or bubbling from the tire’s sidewall. Typically, tire bubbles or bulges result in some sort of physical impact – i.e., the tire hitting a pothole. The liner in the tire’s inner frame can become damaged and create a small tear or hole in the tire’s sidewall. Air could also enter into the structure of the tire- helping to form a blister on the tire. If you leave a tire bubble or blister untreated, then you risk a blowout while driving or even a flattened tire.\nImportance of Tire Rotation\nWhether you have rear, front or all wheel drive, each tire will form wear at a different rate and have various levels of usage. For example, a vehicle with front wheel drive will have front tires that may have more wear on them because they work harder than the rear tires. Your tire rotations will allow for all of your tires to have even wear, resulting in extended life, better drivability and safety for you.\nHow Often Should Tires Be Rotated?\nWhile many vehicle experts state that tires should be rotated every 5,000 miles, must auto specialists state that your tires should be rotated each time to go in for an oil change. Many oil change services even offer free tire rotation. Each car expert will offer a different schedule for tire rotations. So, you want to get with your mechanic and get on a tire rotation schedule, depending on your driving habits. For most drivers, a tire rotation should take place every six months. The only way to know how often to rotate your tires, will be to have your tire specialist view your tread and place you on a schedule for tire rotations.\nThe Factors That Impact Your Tire Tread and Wear\nThe kind of driver you are and the kind of roads that you drive on, will impact the condition of our tires. Let’s look at these factors and more– that play a role in you tire rotation schedule and your tires.\nDo you drive on relatively smooth roads or do you drive on roads that are dirt or paved? The condition of the roads that you drive on will definitely affect the condition of your tires. Tires that rotate on smooth roads will definitely last longer compared to tires that drive on rougher terrain. Additionally, tires that travel on highways at consistent speeds with minimal stopping, will also last longer than tires that stop and accelerate due to patterns in traffic.\nThe Kind of Driver You Are\nWhat kind of driver are you? Are you a motorist who likes to speed down the street? Are you a meticulous driver on roads that are uneven? The kind of driver that you are, will have a huge impact on the condition of your tires. If you are speeding down the street where there are potholes and areas of uneven pavement, then your tires are going to have uneven tread and become suspectable to tears and uneven wear. Take into consideration your driving habits and style. Then, remember that you tires will have to absorb the impact of the roads that you travel on.\nStudies show that tires tend to deteriorate quicker in hotter climates. They also break down faster if they are exposed to direct sunlight. If a tire has direct exposure to UV rays, they are more prone to break down quicker, compared to tires that are not exposed to the harmful rays. The UV rays will break down the durability, flexibility and rubber of a tire over time. Additionally, roads that have snow and debris on them can accelerate the wear and tear of a tire. Salt may dissolve ice and snow on a road, but it also causes a tire’s rubber to deteriorate faster too.\nIs Tire Balancing and Rotation the Same Thing?\nWhen you balance a tire, you should also rotate the tire at the same time. Many car owners believe tire rotation and balancing to be the same thing- but it’s not.\nWhen a mechanic rotates a tire, he or she is taking that tire removing it from its present location and then placing that tire in a different position. Whether your tires are moved from front to back or back to front, the movement is that of rotating a tire.\nTire balancing is the act of ensuring that the weight of the combined tire and wheel are evenly distributed. Mechanics use machines to position the tire to balance it correctly and precisely. A tire specialist will used specialized machinery to precisely balance tires. If you have unbalanced tires, then you will certainly feel is as your car will shake and wobble when you drive it.\nHow Long Do Tires Last If You Don't Rotate Them?\nIf you decide that tire rotations are not for you, then you are taking some serious risks in your hands. Tire rotations are very important, relatively inexpensive and can really make the difference in a safe car and an unsafe one. So, what happens if you decide not to get your tires rotated?\n- Wear formations that are irregular– with differences in load pressure and driving habits, your unrotated tires will begin to develop irregular and unbalanced formations. You will begin to experience one-sided wear along your tires too. Soon, you will begin to see visible tread wears. You may even begin to see the white strings or cords of your tires! Those cords are definite sign that your tires need to be replaced, due to no tire rotation taking place.\n- Tires That Are Vibrating – If you’re feeling some lackluster performance from your driving, coupled with some vibrations, this can be due to uneven wear. This is an indicator that you needed to get those tires rotated. Soon, you will begin to bounce in your car and your tires will have decreased contact with the road that is underneath them.\n- Loss of Air Pressure– It’s a fact that due to pressure changes and weather conditions, tires lose pressure all of the time. Just this fact alone should have a motorist in a shop for regular tire rotations. If you have one tire lose pressure faster than the rest of the other tires, then you are in some serious trouble. That one tire may have excessive pressure it. This results in uneven and unbalanced interaction with the road.\nJust like everything in life we value, tires need attention. Regular balancing and rotation help to preserve the life of a tire, while keeping you safe in your car.\nWinter Car Care – Should I Rotate My Winter Tires?\nNot only should you rotate those winter tires, but you also want to check your tire pressure. Cold temperatures can impact tire pressure. Snow and salt on the streets can impact wear and tread.\nThere are some great reasons to rotate winter tires too! They include:\n- Snow cornering\n- Better steering response\n- Increased balanced handling\n- Greater braking performance\n- Enhanced and better traction on roads that are icy, snowy and slippery and more.\nCar Care & Rotating Front Tires with Rear Tires\nMost vehicles have front tires that experience far more stress than their rear counterparts. From weight, to cornering force problems and alignment, the front tires receive the brunt of tire wear. When a tire specialist takes the time to take the front tires and place them in the back—at regular intervals, your tires will have a chance to wear at a similar rate.\nShould You Rotate Winter Tires on AWD & Rear-Wheel Drive Vehicles?\nDrivers should get all-wheel drive tires and rear wheel drive tires rotated at the same time. The front tires on AWD vehicles generally wear out faster compared to the back tires. The sensors that track the AWD vehicles will work in overdrive—especially if the tires have excessive wear. When all four tires are rotated, there is far less stress on the sensors and components of your all-wheel drive system. A vehicle with rear-wheel drive exerts more force from the rear tires. Given such, it is important to rotate tires to the front ensuring an even distribution of wear.\nTAGS: winter car care, winter car care tips, tire rotation, tire rotation how often, tire rotation and balance, tire rotation pattern, tire rotation frequency, tire rotation schedule, tire rotation cost""]"	['<urn:uuid:375e2e61-6808-4223-a41a-ea0e349a0d1d>']	factoid	with-premise	verbose-and-natural	similar-to-document	single-doc	novice	2025-05-13T04:02:16.770989	33	38	2137
39	outdoor lighting installation cost homeowners insurance coverage	Installing outdoor lighting involves different costs and considerations. Solar lamp posts are less expensive to install than standard electric ones and don't require complex wiring. For insurance purposes, any outdoor improvements like lighting should be reported to your insurance agent to ensure proper coverage, as they may increase your home's value. Your homeowner's policy should be reviewed annually to account for such improvements and ensure adequate coverage for replacement costs.	"[""Outdoor lighting enhances curb appeal and home security while providing a cheerful welcome home at the end of a long day. Lamp posts lend a particularly elegant touch of charm to your house and yard. Installing a standard electric lamp post is a fairly involved process, but if you have a concrete drive or walkway in the location you want extra light, using special anchor bolts called wedge anchors is one way to speed the installation. Another way to simplify the process is to go solar. Solar lamp posts not only conserve valuable resources, they are easier and less expensive to install.\nDecide on a place for the lamp post that provides light in the desired location along the concrete drive or walkway at night, yet receives sunlight most of the day to recharge the lamp batteries.\nUtilize either the lamp post base or a template provided by the manufacturer to mark hole positions on the concrete in the chosen location. Insert a pencil through the holes in the base or template and make a heavy black mark on the concrete directly beneath each hole.\nInstall the post base using the wedge anchors supplied or recommended by the lamp manufacturer. Alternatively, select the largest diameter wedge anchor bolts that will fit the holes in the post base, with a length that allows the bolts to embed sufficiently in the concrete while protruding 1 inch above the base. As an example, for a 1-inch thick base with 3/8-inch-diameter holes, choose 3/8-inch wedge anchors with a minimum length of 4 inches. Consult the specifications provided by the wedge anchor bolt manufacturer to determine the appropriate length anchors and embedment depths to use for your lamp post, based on its weight and height.\nSelect a masonry drill bit of the same diameter as the wedge anchors. Wrap a piece of masking tape around the bit to mark the recommended embedment depth plus 1/4 inch. Chuck the bit into a hammer drill.\nPut on eye protection and drill a hole in the concrete at each marked location. Stop drilling when the tape on the bit is even with the hole. Blow the concrete dust out of the holes with an air bulb or piece of tubing, or suck it out with a shop vac.\nPlace the lamp post base over the holes in the concrete. Insert the anchor bolts through the post base and into the holes.\nPlace a washer on each anchor bolt and thread on the nuts, leaving them even with the top of the anchor bolt to protect the threads.\nAssemble the lamp post on top of the base one section at a time, or as instructed by the manufacturer, using the screws provided with the post. Tighten the screws securely. Don't put the lamp on top of the post at this time.\nCheck the lamp post for plumb by placing a level lengthwise along the pole. Have a helper hold the lamp post steady in a plumb position. Slip composite shims underneath the edge of the base if necessary to make the post plumb. Don't use wood shims as they will rot in contact with concrete.\nHold the base steady and strike the end of each anchor bolt with a hammer, driving it into the hole in the concrete until the nut and washer touch the lamp base.\nTighten the bolts with a socket wrench to expand the wedges and set the anchors. Turn the nuts a minimum of 3 full turns past hand tight, or to the torque recommended by the wedge anchor manufacturer. Check the base to ensure it is securely fastened to the concrete.\nInstall the batteries according to the manufacturer's instructions and turn on the lamp. Select the desired brightness level if appropriate for the lamp model. Mount the lamp on top of the post with the provided hardware.\nThings You Will Need\n- Solar-powered lamp post\n- Wedge anchor bolts\n- Masonry drill bit\n- Masking tape\n- Hammer drill\n- Air bulb or piece of tubing\n- Composite shims\n- Socket wrench\n- Torque wrench (optional)\n- Shop vac (optional)\n- For the best results in humid environments or coastal areas, use hot-dipped galvanized wedge anchor bolts.\n- Optimum solar lamp efficiency isn't achieved until the batteries are fully charged.\n- If solar lighting won't work in your location because of too many shadows or too much shade, lamp posts are available that use a plug-in type transformer and low-voltage wiring that's easier to install than regular electrical wiring.\n- Some cities require a building permit to put up a lamp post, especially those connected to the utilities or erected close to a street. Check with your local building department.\n- Jupiterimages/Photos.com/Getty Images"", 'Subscribe to our Emailed Newsletter\nMaintaining adequate homeowner\'s insurance is a vital part of owning a residence and your homeowner\'s policy should be chosen carefully. This Financial Guide discusses the policy provisions to consider when deciding which homeowner\'s insurance policy to buy to be sure that your home is adequately insured and that you are getting the most insurance value for your money.\nTable of Contents\nThis Financial Guide offers guidance about homeowner\'s insurance such as what questions to ask your insurance broker or agent and how to find the best insurer for your needs. It also explains why you need to keep a list of personal possessions and provides a homeowner\'s inventory sheet for you to use to make a list of your belongings, as well as offers useful tips on how to qualify for a discount and helps you purchase the policy that best fits your needs at an affordable price.\nAlthough exact coverage and policy limits vary, homeowner\'s insurance usually covers damage caused by the following events or catastrophes:\nBasic coverage may also include food spoilage, lock replacement, temporary repairs, and removing debris. If these items are not initially included in your basic coverage, it is possible to have them added.\nIf you incur expenses for temporary living quarters because your home is rendered uninhabitable by an insured event/casualty, most policies will reimburse you in part for this so-called ""loss of use.""\nThere is usually a deductible of $100 to $500 for personal property losses. Raising the deductible can lower the premium.\nActual Cash Value Or Replacement Cost\nIf you insure your belongings for their ""actual cash value,"" you will not get their replacement value at the time of a loss. Actual cash value refers to the value of your belongings after taking into account depreciation and wear and tear. this is also known as Fair Market Value (FMV). For instance, the actual cash value of a television you bought ten years ago may be worth only $50. On the other hand, ""replacement cost"" coverage provides you with the costs to replace your belongings. Thus, you would get the $500 you need to replace that ten-year-old television, not the $50 ""actual cash value.""\nLimits on Coverage\nYou choose the limits on the amounts of coverage on your home and personal property. The premium you pay depends on the limits you choose. Regardless of the policy limit, there is a separate limit on the replacement of high-value items, such as jewelry and artwork. If you want increased coverage for certain items, you must purchase an endorsement or floater (also known as a ""rider""). You must generally pay extra for the following:\nIf your home is damaged or your possessions are stolen, will your homeowner\'s policy pay as much as you are expecting? If you are willing to pay the premium for full protection, here are the policy coverages you might consider.\n100 Percent of Rebuilding Costs\nThe amount of insurance that you buy should be based on the cost of rebuilding--not on the price of your home. The cost of rebuilding your house is usually higher than the price you originally paid for it, and often, even the price you could sell it for today. Most insurance companies recommend you insure your home for 100 percent of the cost of rebuilding it.\nThe cost of rebuilding is affected by local construction costs and by the type of house you have; however, the following are some of the factors that enter into the calculation:\nIf you already have homeowner\'s insurance, it\'s very important to make sure that you have enough. If your home is one of the few that are totally destroyed, and it is insured for less than 100 percent of the rebuilding cost, you risk not having enough money to replace it with one of similar size and quality.\nMake sure your insurance agent or broker knows about any improvements or additions to your house that have been made since you last discussed your insurance policy. If you haven\'t increased your policy limits to cover the cost of rebuilding that new deck, a second bathroom, or other improvements that have increased the value of your home, then you risk being under-insured. If you lack sufficient insurance, your insurer may pay only a part of the cost of replacing or repairing damaged items--depending on the kind of policy you have.\nLook at your policy to see what the maximum amount that your insurance company would pay if your house was damaged and had to be rebuilt. The limits of the policy usually appear on the Declarations Page under Section 1, Coverage A Dwelling. Your insurance company will pay no more than this amount to rebuild your home--no exceptions.\nSome banks require that you buy homeowner\'s insurance to cover the amount of your mortgage. However, if the limit of your insurance policy is based only on your mortgage, your policy is unlikely to cover the cost of rebuilding. Make certain that the value of your insurance policy keeps up with increases in local building costs.\nConsider buying replacement cost coverage for structural damage. A replacement cost policy will pay for the repair or replacement of damaged property with materials of similar kind and quality. The insurance company will not deduct for depreciation. Depreciation is the decrease in value due to age, wear and tear, and other factors.\nIf you own an older home, you may not be able to buy a replacement cost policy. Instead, you might buy a modified replacement cost policy that will pay for repairs using standard building materials and construction techniques in use today, rather than repairing or replacing features typical of older homes, like plaster walls and wooden doors, with similar materials.\nInsurance companies differ greatly in the way they insure older homes. Some refuse to insure older homes for 100 percent of replacement cost because of the expense of re-creating special features like wall and ceiling moldings and carvings. Other companies will insure older homes for 100 percent of replacement cost as long as the dwelling is in good condition.\nGuaranteed Replacement Cost Insurance\nA guaranteed replacement cost policy will pay whatever it costs to rebuild your home as it was before the fire or another disaster, even if it exceeds the policy limit. This policy protects you against sudden increases in construction costs due to a shortage of building materials, for example, or other unexpected situations, but generally, does not cover the cost of upgrading the house to comply with building codes.\nIf your home is located in an area prone to flooding, contact your insurance agent or the National Flood Insurance Program (800-427-4661).\nThis list should include everything you and other members of your household own in your home and in other buildings on the property, except your car and certain boats, which must be insured separately. Among the items you should include are indoor and outdoor furniture, appliances, stereos, computers and other electronic equipment, hobby materials and recreational equipment, china, linens, silverware and kitchen equipment, and jewelry, clothing and other personal belongings.\nCheck your homeowner\'s policy to find out how much insurance you have for the contents of your home. The limit of the policy is shown on the Declarations Page under Section 1, Coverage, Personal Property. The contents limit generally is 50 percent of the amount of insurance on the dwelling. For example, on a home insured for $100,000 the contents would be limited to $50,000. Now compare the contents limit with the total value of the items on your list of personal possessions. If you think you are under-insured, give your insurance agent or broker a call.\nAs discussed before, there are two ways of insuring your personal possessions. If you have a homeowner\'s insurance policy, find out whether claim payments for damage to your personal property would be based on replacement cost or actual cash value. Check your policy under Section 1, Conditions, Loss Settlement or ask your agent. As with insurance for the structure, a replacement cost policy pays the dollar amount needed to replace a damaged item with one of similar kind and quality without deductions for depreciation. An actual cash value policy pays the amount needed to replace the item minus depreciation.\nCheck the limits on certain kinds of personal possessions, such as jewelry, art, silverware, and furs. This information is in Section 1, Personal Property, Special Limits of Liability. Some insurance companies also place a limit on what they\'ll pay for computers and other home office equipment. If the limits are too low, consider buying a special personal property endorsement or rider.\nThe price you pay for homeowner\'s insurance can vary by hundreds of dollars, depending on the insurance company. Companies offer several types of discounts, but they do not offer the same discount or the same amount of discount in all states. Here are some things to consider when buying homeowner\'s insurance:\nAlthough it may take a few phone calls to shop around for the best insurance, you could save a few hundred dollars by taking the time to do so. Conduct a preliminary search by compiling a list of possible insurers. Check with your insurance broker or agent, ask your friends, check the Yellow Pages, search online, check consumer guides, and/or call your state insurance department. A thorough investigation of available insurers will give you an idea of price ranges and tell you which companies or agents have the lowest prices.\nWhen talking to insurers, ask them what they would do to lower your costs. Once you\'ve narrowed your search to three companies, get price quotes.\nRaise Your Deductibles\nDeductibles on homeowners\' policies typically start at $250. You might save up to 12 percent of the premium by increasing your deductible to $500, up to 24 percent by increasing it to $1,000, up to 30 percent by going up to $2,500, and 37 percent by raising it to $5,000.\nConsidering Buying Home And Auto Policies From the Same Insurer\nMany companies that sell homeowner\'s, auto and liability coverage will take 5 to 15 percent off your premium if you buy two or more policies from them. This is called a multiple policy discount.\nConsider Insurance Cost Before Buying A Home\nWhen buying a home, don\'t overlook the insurance costs. These may affect the price you are willing to pay for the home. Among the factors to consider:\nDon\'t Insure Land\nWhen deciding how much homeowner\'s insurance to buy, do not include the value of the land under your house. If it is not at risk of theft, windstorm, fire, or other disasters, then why pay for wasted coverage?\nIncrease Home Security\nYou can usually get discounts of at least 5 percent for a smoke detector, burglar alarm, or dead-bolt locks. Some companies offer to cut your premium by as much as 15 or 20 percent if you install a sophisticated sprinkler system and a fire and burglar alarm that rings at the police station or another monitoring facility. Although these discounts are incentives to invest in home security and yard maintenance systems, be aware that these systems are not inexpensive and that not every system qualifies for the discount.\nNo Smoking Discounts\nInsurers may offer lower premiums if all the residents in a house do not smoke.\nIf you are at least 55 years old and retired, you may qualify for a discount of up to 10 percent at some insurers.\nInvestigate Group Coverage\nEmployers, alumni, and business associations can often benefit from an insurance package at competitive rates. Ask your company\'s human resources department or your association\'s director if such a package is available.\nStay With the Same Insurer\nIf you\'ve kept your coverage with one company for several years, you may get a reduction in your premiums of 5 or 10 percent, depending on the insurer.\nCheck Your Policy Once A Year\nCompare the limits in your policy with the value of your possessions at least once a year to make sure your policy covers major purchases and/or additions to your home.\nLook For Private Insurance First\nIf you live in a high-risk area, that is, one that is vulnerable to coastal storms, fires, or crime, and have been buying your homeowner\'s insurance through a government plan, you may find that there are steps you can take to buy insurance at a lower price in the private market. Check with your insurance agent or broker.\n* * * *\nTo be sure you have adequate homeowner\'s insurance, ask your insurance agent questions about the issues discussed in this Financial Guide. A thorough inquiry into specific coverage and costs should result in a policy that offers the best coverage and value. It is also important to ask your agent or broker to explain what factors were used to calculate the policy limits for the dwelling.\nFor your convenience, several common insurance terms are defined below:\nActual Cash Value. The current value of property measured in cash arrived at by taking the replacement cost and deducting for depreciation brought about by physical wear and tear, age and other factors.\nEndorsement. A written form attached to a policy that alters the policy\'s coverage, terms or conditions.\nFloater. A policy or endorsement that applies to moveable property whatever its location. The coverage floats or moves with the property.\nGuaranteed Replacement Cost Insurance. Insurance providing for payment of the cost of replacing the damaged property without deduction for depreciation and without a dollar limit\nInflation Guard Clause Provision. In a policy or endorsement that automatically adjusts the dwelling limit at policy renewal time to reflect current construction costs in your area.\nReplacement Cost Dwelling Insurance. Insurance providing that the policyholder will be paid the cost of replacing the damaged property without deduction for depreciation, but limited by the dollar amount displayed under Section 1, Coverage, A. Dwelling on the Declarations Page of the policy.\nReplacement Cost Contents Insurance. Insurance that pays the dollar amount needed to replace damaged personal property with that of similar kind and quality without deducting for depreciation.\nUse this form to document and determine whether your personal property coverage is adequate. Go through each room and inventory your belongings. Write in the year you bought the item and how much you paid for it. Then write in the approximate cost to replace the item today. Finally, calculate the totals at the end of the form. This list will also help in case you need to submit a claim.']"	['<urn:uuid:14d30e56-49ad-4c0d-8760-774264a37329>', '<urn:uuid:614897da-5f03-41fb-84ea-3f265abe9e5f>']	open-ended	direct	short-search-query	similar-to-document	three-doc	expert	2025-05-13T04:02:16.770989	7	70	3207
40	Could you explain the anatomical structure and functioning mechanism of octopus suckers that allows them to generate such powerful grips?	Octopus suckers consist of two main parts: the infundibulum (outer visible part) with grooves and ridges for creating watertight seals, and the acetabulum (inner chamber) with brush-like hairs that help maintain suction without extra energy. When a sucker contacts a surface, it flattens and conforms to create a seal. Muscles then contract to reduce water pressure within the sucker, creating a watertight seal. The suckers are incredibly strong - in the Giant Pacific Octopus, the larger suckers near the beak can hold up to 35 pounds. They're attached to arms by muscular bases that can rotate in any direction and elongate to twice their normal length.	['What is the shape of a frisbee, can hold up to 35 pounds, pry open a clamshell, AND taste food? An octopus sucker! Powerful and sensitive, octopus suckers are the ultimate all-purpose tool. Read to get suckered into all the cool stuff you never knew you wanted to know about octopus suckers!\nFun Facts About An Octopus’s Sucker\nOctopuses use the many tiny suction cups along their arms to anchor their bodies to:\n- Manipulate objects\n- Investigate their environment\n- Grasp food\nImagine if your fingers could not only hold food but also taste it at the same time.\nWithout even looking at your food, you wouldn’t just know what you’re holding, but you would be able to TASTE it before it gets to your mouth!\nDoes every cephalopod have the same amount of suckers?\nThe total number of suckers an octopus has on each arm is species-dependent. Still, octopuses generally have a double row of suckers (biserial) running down each arm from their mouth.\nThe Giant Pacific Octopus is most impressive, with around 280 suckers PER ARM. Doing some quick math, that means a whopping total of 2,240 suckers PER OCTOPUS.\nAre all suckers the same?\nAs with everything we talk about regarding octopuses, there is considerable variability between species with form, usually getting wackier when we add the other cephalopods to the mix.\nFor example, some species of squid have suckers with tiny hooks or teeth. On the other hand, the Glass Octopus only has one row of suckers (not the usual two), and the Nautilus, despite having 90 tentacles, is completely sucker-less!\n???? Fun Fact ????\nThe sharp “teeth” on the suckers of squid are made out of a protein called suckerin, which gives the teeth strength and flexibility!\nHow do octopus suckers actually work?\nWhen a sucker comes in contact with something, it flattens and conforms to the surface to create a seal. Muscles in the sucker then contract, reducing the water pressure within the sucker, and boom- watertight seal!\nDifferent muscles surrounding the sucker help release the tension and allow the octopus to detach. They even have special mucus covering their suckers, aiding with adhesion.\nThey are mighty, mighty strong!\nOctopus suckers are muscular structures that create low-pressure suction on objects. Each sucker is attached to the arm by a muscular base that can rotate the sucker in any direction and can be elongated to twice its normal length.\nThat’s a lot of independent flexing and stretching happening on each octopus arm!\nA sucker is made up of two main parts, the infundibulum, and acetabulum, all of which are surrounded by different shaped muscles.\n- The outer, visible part of the sucker is the infundibulum. It has many grooves and ridges that help the sucker form a watertight seal on any type of surface.\n- The acetabulum is a chamber inside the sucker, which plays an important role in suction. The roof of this chamber is covered with brush-like hairs that aren’t found anywhere else on the sucker. Scientists suggest that these hairs help an octopus stay suctioned to an object for long periods of time without using any extra energy.\nPretty important when you think about an octopus having to hold a clam for 2 hours while it drills a hole in it! For those interested, let’s look at a more detailed illustration by Gabby Wharton.\nSo, how strong is an octopus sucker?\nLet’s use the GPO.\nThe Giant Pacific Octopus’s larger suckers, near the beak and mouth, can hold up to 35 pounds! They are used to pry open and obliterate clams, crabs, and other sea life that should, and would, be hard to eat under normal circumstances.\nThat’s one powerful grip!\n???? Fun Fact ????\nOctopus arms and suckers are being studied for applications in soft robotics. Bioinspiration from these amazing animals helps design innovative artificial suction cups that can grasp complex-shaped objects and move them in water or oil!\nKeep an eye out for those sticky suckers!\nIf these suckers are so strong and suction to whatever the octopus wants, how does it not get stuck to itself and end up in one giant knotted octopus ball?\nOne study found that an octopus’s skin produces a chemical signal that overrides their suction reflexes, thus preventing them from ending up in a sticky situation.\nThis isn’t all this chemical signal does!\nIt’s unique to each octopus, so they don’t go and accidentally eat one of their own arms.\nSince octopuses have cannibalistic tendencies (see the Maori Octopus’s mating habits), this unique chemical signature prevents them from feasting on the wrong octopus arm.\nSucker sensors→ Brain activity!\nThe first layer on a sucker has sensors called chemotactile sensors. This is how an octopus can figure out what exactly it’s touching.\nNot only that, it lets them taste what they are touching.\nRock or crab? Am I touching, or am I tasting AND touching?\nThese sensors let an octopus know that immediately. That information is sent to their vast neural network, much of which is in their arms.\nBut, the smarts don’t stop there.\nSuggestion: Suckers are tactile, chemical, AND light sensors!\nA recent study (September 2021) identified a light-sensing molecule in the suckers (specifically the sucker rim) of Octopus vulgaris. This light sensing molecule is found in different sucker types in several areas along the arm.\nLight-sensing suckers may aid the octopus in detecting hidden prey. However, different areas of the arm can be used for various functions.\nMore research is needed to explore the light-sensing abilities in octopus arm suckers!\nEver heard of the octopus having 9 brains?\nThat refers to their one main centralized brain and the 8 clusters of neurons they have in each arm.\nAbout 66% of an octopus’s neurons are located in their arms, giving them some serious independence from their main brain.\nImagine trying to keep track of all your fingers that had hundreds of tiny tongues on them? Sensory overload!\nTo overcome this, an octopus’s brain is diversified.\nSo, while different arms are probing rocks and crevices for food, their main brain can be fully concentrated on keeping a lookout for predators.\nAn octopus’s arm has so much control that studies have shown a severed octopus arm will still go on being an arm for about an hour. It will reach for things, move, and even bring food up to where its mouth would be.\n???? Fun Fact ????\nThe Common Octopus have favorite arms! Even though their arms are all the same, they tend to favor their front arms for reaching and exploring.\nMy oh my- are they sensitive!\nHow do they keep their suckers looking fresh, clean, and at maximum tasting capacity? Manicures!!\nIt might sound crazy but hear us out.\nOctopus suckers have a sucker lining, called a chitinous cuticle, which they periodically shed and constantly renew. Kind of like your fingernails, except that for octopuses, it’s a protective lining covering the surface of every-single sucker.\nJust like our fingernails make it easy for us to pick things up, an octopus’s textured sucker lining helps them hold onto objects and not let go.\nBut what happens when your nails get too long? You bite them, trim them, or maybe even paint them! When an octopus’s sucker lining wears out, it will carefully begin to swirl its 8 arms together until all that’s left are hundreds of round translucent sucker discs floating about its den.\nThe outgrown sucker lining sheds off, revealing well-manicured, squeaky-clean suckers.\nA fresh set, if you will.\nAnd that’s not where it ends!\nGrooming improves their grip strength and sharpens their ability to taste and smell with the suckers on their arms.\n???? Fun Fact ????\nEach individual suction cup has more receptors than the human tongue!\nOctopus Suckers: Grab, Smell, Eat, Repeat!\nI think we can all agree that we can add octopus suckers to the long list of what makes these animals so special.\nIf you want to educate yourself some more about all sorts of different cephalopods, take a look at our encyclopedia. Or, what we call it, our Octopedia!\nConnect with other octopus lovers via the OctoNation Facebook group, OctopusFanClub.com! Make sure to follow us on Facebook and Instagram to keep up to date with the conservation, education, and ongoing research of cephalopods.\nMore Posts To Read:\n- 7 Jaw-Dropping Caribbean Reef Octopus Facts\n- Vampire Squid Facts: Ancestors Of The Jurassic Seas!\n- Octopus Lifespan: A Glimpse At An Octopus’s Circle Of Life!\n- Inkcredible News! Meet The Glass Octopus\n- Giant Australian Cuttlefish Facts That Will Make You Go WHOA!\n- Octopus Eyes: Everything You Need To Know About Cephalopod Vision!\nCorinne is a biologist with 10 years of experience in the fields of marine and wildlife biology. She has a Master’s degree in marine science from the University of Auckland and throughout her career has worked on multiple international marine conservation projects as an environmental consultant. She is an avid scuba diver, underwater photographer, and loves to share random facts about sea creatures with anyone who will listen. Based in Japan, Corinne currently works in medical research and scientific freelance writing!']	['<urn:uuid:ea34dbe4-afe0-4257-bff0-0f2d85897475>']	open-ended	direct	verbose-and-natural	distant-from-document	single-doc	expert	2025-05-13T04:02:16.770989	20	106	1529
41	I'm planning a fishing trip - how can I prevent spreading invasive species?	To prevent spreading aquatic invasive species, follow the Clean, Drain, Dry guidelines: 1) Clean mud, weeds and aquatic life from equipment before leaving the area, 2) Drain water from bilges, pumps, coolers and buckets, 3) Dry your boat and equipment for 5 days in the sun before using in another water body. If you can't wait 5 days, you should power wash your boat and trailer, freeze small items overnight, or soak gear in very hot water for 30 minutes. Also, avoid using felt-soled waders as they can trap moisture and spread invaders - studded or soft rubber waders are better choices.	"['- What are aquatic invasive species?\n- Help stop aquatic invasive species\n- Report aquatic invasive species\nWhat are aquatic invasive species?\nAquatic invasive species can harm native species by bringing disease and altering natural ecosystems. This can have a negative effect on fisheries, tourism, health and recreation. The Yukon Invasive Species Council defines an invasive species as:\n""An organism (plant, fungus, or bacterium) that is introduced into an ecosystem and has negative effects on the economy, environment, and/or health. The term “invasive” is reserved for the most aggressive species, which reproduce rapidly and cause major changes to the areas where they become established.""\nHow are aquatic invasive species spread?\nPeople spread aquatic invasive species when they:\n- dump their aquariums illegally; and\n- move from place to place. Aquatic organisms can cling to boats, fishing gear and footwear and unknowingly be transported from one area to another.\nAre there aquatic invasive species in Yukon?\n- Most Yukon lakes and waterways appear to be free of invasive species.\n- Some species of fish have been introduced to Yukon waters but are not considered invasive. These include rainbow trout, stickleback, Arctic char and goldfish.\nWhat aquatic invasive species should I be aware of?\nZebra and quagga mussels\nZebra mussels and quagga mussels attach to boat hulls and underwater infrastructure and can cost millions of dollars in damage. Adult mussels can live several weeks out of the water and be transferred from one body of water to another.\nIdentify zebra and quagga mussels\nZebra and quagga mussels:\n- are small and only up to 3 cm;\n- are shaped like propeller blades;\n- have yellow or brownish shells;\n- can have light-coloured zebra stripes; and\n- form dense clumps and firmly attach themselves to solid objects.\nDidymo algae is found in Yukon. It is considered an invasive species in other parts of Canada, but may be native to Yukon. Further research will provide us with an answer.\nThis algae can form large, slippery mats that cover stream beds. These mats can damage organisms in Yukon waters and degrade fisheries by changing the natural ecosystem and disrupting fish rearing habitat. As stream levels drop, didymo mats resemble and are mistaken for toilet paper.\nThis YouTube video produced by New Zealand Fish and Game explains how didymo can form large algal blooms.\nIdentify didymo algae\n- is brownish-yellow to white and form in clumps or ropes. It isn\'t didymo if it is green or dark brown or black or transparent;\n- has a rough texture like wet cotton wool when pulled apart. It isn\'t didymo if it has a slimy texture or falls apart when handled; and\n- is found in clumps on rocks or plants, or floating in the current. It isn\'t didymo if it is attached to the bottom with roots.\nFind out more about aquatic invasive species in Yukon\n- Yukon Fishing Regulations summary\n- Yukon Invasive Species Council\n- Protect Your Waters and Stop Aquatic Hitchhikers\nReports on Yukon aquatic invasive species\nHelp stop aquatic invasive species\nOne of the most important things you can do to stop aquatic invasive species is to not move water, fish, plants or aquatic life from one water body to another. If you boat, fish or use Yukon waters you should follow the Clean, Drain, Dry guidelines to stop aquatic invasive species.\nNote: It’s illegal to bring live water creatures into Yukon waters or to transfer them among bodies of water without a permit. This includes live fish, uncured fish eggs, crayfish, leeches and water plants.\nClean, Drain, Dry guidelines\nClean mud, weeds and aquatic life from equipment before leaving the area\nMud and weeds can keep invasive species cool and moist, allowing them survive a long time.\nDrain water from bilges, pumps, coolers and buckets before leaving the area\nDraining water makes it harder for aquatic invaders to survive and be transferred to new waters.\nDry boat and gear\nDry your boat and equipment before heading to another body of water. It can take 5 days in the sun to dry. If your equipment won\'t dry before you head onto another body of water, you should:\n- power wash your boat and trailer;\n- freeze small items like footwear, waders and reels in a bag overnight until solid; or\n- soak gear in very hot water for 30 minutes.\nChoose your gear wisely\n- Studded or soft rubber waders are the best choice. Felt and other porous boot soles can trap moisture and spread aquatic invaders.\n- Didymo algae, also known as ""rock snot"" can live several weeks when attached to felt soles.\n- If you have felt-soled waders, it\'s best to freeze them solid overnight.\nReport an aquatic invasive species\nHelp stop the spread of aquatic invasive species by reporting them when you spot them. If you think you\'ve spotted an aquatic invader email email@example.com or phone 1-800-661-0408, ext. 5721.\nSee the next section for more details.\nReport aquatic invasive species\nIf you think you\'ve spotted an aquatic invader:\n- Report the incident to the Fisheries Unit by calling 1-800-661-0408, ext. 5721 or emailing firstname.lastname@example.org.\n- If possible, take a photograph and a small sample for identification in a secure plastic bag, and note the exact location.\n- Prevent its spread with Clean, Drain, Dry.\n- If you find a potential invasive species on equipment after leaving a site, throw it in the garbage and not down the drain.\nIf you have further questions about aquatic invasive species in Yukon, email email@example.com or phone: 867-667-5721, toll free in Yukon: 1-800-661-0408 ext. 5721.']"	['<urn:uuid:15a8dd31-31f3-4f8d-bdd8-a1005d92f0b6>']	open-ended	with-premise	concise-and-natural	similar-to-document	single-doc	novice	2025-05-13T04:02:16.770989	13	102	930
42	independence princeton navy ships battle stars ww2	The USS Independence earned eight battle stars for World War II service. The USS Princeton was commissioned in November 1945, too late to serve in World War II, though it later earned eight battle stars during the Korean War.	"['U.S. Navy - A Brief History of Aircraft Carriers - USS Independence (CV 22)\ndisplacement: 11,000 tons\nlength: 622½ feet\nbeam: 71½ feet; extreme width at flight deck: 109 feet 2 inches\ndraft: 26 feet\nspeed: 31 knots\ncomplement: 1,569 crew\narmament: 26 40mm guns\nFrom: Dictionary of American Fighting Ships published by the Naval Historical Center\nFull-screen images are linked from the images in the text below.\nThe fourth Independence (CV-22), begun as Amsterdam, (CL-59), was launched as CV-22 on 22 August 1942 by New York Shipbuilding Corp., Camden, N.J.; sponsored by Mrs. Rawleigh Warner; and commissioned 14 January 1943, Captain G. R. Fairlamb, Jr., in command.\nThe first of a new class of carriers converted from cruiser hulls, Independence conducted shakedown training in the Caribbean. She then steamed through the Panama Canal to join the Pacific Fleet, arriving San Francisco 3 July 1943. Independence got underway for Pearl Harbor 14 July, and after 2 weeks of vital training exercises sailed with carriers USS Essex (CV 9)and USS Yorktown (CV 10) for a devastating raid on Marcus Island. Planes from the carrier force struck 1 September and destroyed over 70 percent of the installations on the island. The carrier began her next operation, a similar strike against Wake Island 5 to 6 October as CVL-22, redesignated 15 July 1943.\nIndependence sailed from Pearl Harbor for Espiritu Santo 21 October, and, during an ensuing carrier attack on Rabaul 11 November 1943, the ship\'s gunners scored their first success — six Japanese planes shot down. After this operation the carrier refueled at Espiritu Santo and headed for the Gilberts and pre-landing strikes on Tarawa 18 to 20 November 1943. During a Japanese counterattack 20 November, Independence was attacked by a group of planes low on the water. Six were shot down, but the planes managed to launch at least five torpedoes one of which scored a hit on the carrier\'s starboard quarter.\nSeriously damaged, the ship steamed to Funafuti 23 November for repairs. With the Gilberts operation, first step on the mid-Pacific road to Japan underway, Independence returned to San Francisco 2 January 1944 for more permanent repairs.\nThe veteran carrier returned to Pearl Harbor 3 July 1944. During her repair period the ship had been fitted with an additional catapult, and upon her arrival in Hawaiian waters, Independence began training for night carrier operations. She continued this pioneering work 24 to 29 August out of Eniwetok. The ship sailed with a large task group 29 August to take part in the Palaus operation, aimed at securing bases for the final assault on the Philippines in October. Independence provided night reconnaissance and night combat air patrol for Task Force 38 during this operation.\nIn September the fast carrier task force regularly pounded the Philippines in preparation for the invasion. When no Japanese counterattacks developed in this period, Independence shifted to regular daytime operations, striking targets on Luzon. After replenishment at Ulithi in early October, the great force sortied 6 October 1944 for Okinawa. In the days that followed the carriers struck Okinawa, Formosa, and Philippines in a striking demonstration of the mobility and balance of the fleet. Japanese air counterattacks were repulsed, with Independence providing day strike groups in addition to night fighters and reconnaissance aircraft for defensive protection.\nAs the carrier groups steamed east of the Philippines 23 October, it became apparent, as Admiral Carney later recalled, that ""something on a grand scale was underfoot."" And indeed it was, as the Japanese fleet moved on a three-pronged effort to turn back the American beachhead on Leyte Gulf. Planes from Independence\'s Task Group 38.2, under Rear Admiral Bogan, spotted Kurita\'s striking force in the Sibuyan Sea 24 October 1944 and the carriers launched a series of attacks. Planes from Independence and other ships sank giant battleship Musashi and disabled a cruiser.\nThat evening Admiral Halsey made his fateful decision to turn Task Force 38 northward in search of Admiral Ozawa\'s carrier group. Independence\'s night search planes made contact and shadowed the Japanese ships until dawn 26 October, when the carriers launched a massive attack. In this second part of the great Battle for Leyte Gulf, all four Japanese carriers were sunk. Meanwhile American heavy ships had won a great victory in Suriago Strait; and a light carrier force had outfought the remainder of Kurita\'s ships in the Battle of Samar. After the great battle, which virtually spelled the end of the Japanese Navy as a major threat, Independence continued to provide search planes and night fighter protection for Task Force 38 in strikes on the Philippines. In these operations the ship had contributed to a major development in carrier group operations.\nIndependence returned to Ulithi for long-delayed rest and replenishment 9 to 14 November, but soon got underway to operate off the Philippines on night attacks and defensive operations. This phase continued until 30 December 1944, when the great task force sortied from Ulithi once more and moved northward. From 3 to 9 January 1945, the carriers supported the Lingayen landings on Luzon, after which Adm. Halsey took his fleet on a daring foray into the South China Sea. In the days that followed, the aircraft struck at air bases on Formosa and on the coasts of Indo-China and China. These operations in support of the Philippines campaign marked the end of the carrier\'s night operations, and she sailed 30 January 1945 for repairs at Pearl Harbor.\nIndependence returned to Ulithi 13 March 1945 and got underway the next day for operations against Okinawa, last target in the Pacific before Japan itself. She carried out pre-invasion strikes 30 to 31 March, and after the assault 1 April remained off the island supplying Combat Air Patrol and strike aircraft. Her planes shot down numerous enemy planes during the desperate Japanese attacks on the invasion force. Independence remained off Okinawa until 10 June when she sailed for Leyte.\nDuring July and August the carrier took part in the final carrier strikes against Japan itself, attacks which lowered enemy morale and had much to do with the eventual surrender. After the end of the war 15 August, Independence aircraft continued surveillance flights over the mainland locating prisoner of war camps, and covered the landings of Allied occupation troops. The ship departed Tokyo 22 September 1945, arriving San Francisco via Saipan and Guam 31 October.\nIndependence joined the ""Magic Carpet"" fleet beginning 15 November 1945, transporting veterans back to the United States until arriving San Francisco once more 28 January 1946. Assigned as a target vessel for the Bikini atomic bomb tests, she was placed within one-half mile of ground zero for the 1 July explosion. The veteran ship did not sink, however, and after taking part in another explosion 25 July was taken to Kwajalein and decommissioned 28 August 1946. The highly radioactive hulk was later taken to Pearl Harbor and San Francisco for further tests and was finally sunk in weapons tests off the coast of California 29 January 1951.\nIndependence received eight battle stars for World War II service.\nLast Update: 12 June 2009', 'USS Princeton (CV-37)\nUSS Princeton underway\n|Career (United States)|\n|Namesake:||Battle of Princeton, 1777|\n|Operator:||United States Navy|\n|Builder:||Philadelphia Naval Shipyard|\n|Laid down:||14 September 1943|\n|Launched:||8 July 1945|\n|Commissioned:||18 November 1945|\n|Decommissioned:||21 June 1949|\n|Recommissioned:||28 August 1950|\n|Decommissioned:||30 January 1970|\n|Renamed:||PCU Valley Forge to PCU Princeton|\n|Reclassified:||CVA-37, CVS-37 and LPH-5|\n|Fate:||Sold for scrap in 1971|\n|Class and type:||Essex-class aircraft carrier|\n27,100 tons standard\n888 feet (271 m) overall\n93 feet (28 m) waterline\n28 feet 7 inches (8.71 m) light\n8 × boilers\n4 × Westinghouse geared steam turbines\n4 × shafts\n150,000 shp (110 MW)\n|Speed:||33 knots (61 km/h)|\n|Complement:||3448 officers and enlisted|\n4 × twin 5 inch (127 mm)/38 caliber guns\n4 × single 5 inch (127 mm)/38 caliber guns\n8 × quadruple Bofors 40 mm guns\n46 × single Oerlikon 20 mm cannons\n4 inch (100 mm) belt\n2.5 inch (60 mm) hangar deck\n1.5 inch (40 mm) protectice decks\n1.5 inch (40 mm) conning tower\n|Aircraft carried:||As built:\nUSS Princeton (CV/CVA/CVS-37, LPH-5) was one of 24 Essex-class aircraft carriers built during and shortly after World War II for the United States Navy. The ship was the fifth US Navy ship to bear the name, and was named for the Revolutionary War Battle of Princeton. Princeton was commissioned in November 1945, too late to serve in World War II, but saw extensive service in the Korean War, in which she earned eight battle stars, and the Vietnam War. She was reclassified in the early 1950s as an attack carrier (CVA), then as an Antisubmarine Aircraft Carrier (CVS), and finally as an amphibious assault ship (LPH), carrying helicopters and marines. One of her last missions was to serve as the prime recovery ship for the Apollo 10 space mission.\nAlthough she was extensively modified internally as part of her conversion to an LPH, external modifications were minor, so throughout her career Princeton retained the classic appearance of a World War II Essex-class ship. She was decommissioned in 1970, and sold for scrap in 1971.\nConstruction and commissioning\nThe ship was laid down as Valley Forge — one of the ""long-hull"" Essex-class — on 14 September 1943 at the Philadelphia Navy Yard. She was renamed Princeton on 21 November 1944 to commemorate the light carrier USS Princeton (CVL-23), which was lost at the Battle of Leyte Gulf on 24 October 1944. The new Princeton was launched on 8 July 1945, sponsored by Mrs. Harold Dodds, and commissioned on 18 November 1945, Captain John M. Hoskins in command.\nAttack carrier (1945–1954)\nThen transferred to the Pacific Fleet, she arrived at San Diego, departing again on 3 July 1946 to carry the body of Philippine President Manuel L. Quezon back to Manila for burial. From Manila, Princeton joined the 7th Fleet in the Marianas, becoming flagship of Task Force 77 (TF 77). In September and October 1946, she operated in Japanese and Chinese waters, then returned to the Mariana Islands where she remained until February 1947. In 1947 she had Carrier Air Group 13 on board, and in October 1948 evacuated dependents from Tsingtao, returned to San Diego Dec 1948 and unloaded CAG13 Maneuvers in Hawaiian waters preceded her return to San Diego until 15 March. She cruised the West Coast, Hawaiian waters, and the Western Pacific (1 October – 23 December) in 1948. She then prepared for inactivation, and on 20 June decommissioned and joined other capital ships in the Pacific Reserve Fleet.\nReactivated with the outbreak of hostilities in Korea 15 months later, Princeton recommissioned on 28 August 1950. Intensive training refreshed her Reservist crew, and on 5 December she joined TF 77 off the Korean coast, her planes and pilots (Air Group 19) making possible the reinstitution of jet combat air patrols over the battle zone. She launched 248 sorties against targets in the Hagaru area to announce her arrival, and for the next six days continued the pace to support Marines fighting their way down the long, cold road from the Chosin Reservoir to Hungnam. By the 11th, all units had reached the staging area on the coast. Princeton \'s planes, with other Navy, Marine, and Air Force squadrons, then covered the evacuation from Hungnam through its completion on the 24th.\nInterdiction missions followed, and by 4 April Princeton \'s planes had rendered 54 rail and 37 highway bridges inoperable and damaged 44 more. In May, they flew against the railroad bridges connecting Pyongyang with Sunchon, Sinanju, Kachon, and the trans-peninsula line. Next, they combined close air support with raids on power sources in the Hwachon Reservoir area and, with the stabilization of the front there, resumed interdiction. For much of the summer they pounded supply arteries, concentrating on highways, and in August Princeton got underway for the U.S., arriving at San Diego on the 21st.\nOn 30 April 1952, Princeton rejoined TF 77 in the combat zone. For 138 days, her planes flew against the enemy. They sank small craft to prevent the recapture of offshore islands; blasted concentrations of supplies, facilities, and equipment behind enemy lines, participated in air-gun strikes on coastal cities, pounded the enemy\'s hydroelectric complex at Suiho on the Yalu River to turn off power on both sides of that river, destroyed gun positions and supply areas in Pyongyang; and closed mineral processing plants and munitions factories at Sindok, Musan, Aoji, and Najin.\nReclassified CVA-37 (1 October 1952), Princeton returned to California on 3 November for a two-month respite from the western Pacific. In February 1953, she was back off the Korean coast and until the end of the conflict launched planes for close air support, ""Cherokee"" strikes against supply, artillery, and troop concentrations in enemy territory, and against road traffic. She remained in the area after the truce on 27 July, and on 7 September got underway for San Diego.\nAnti-submarine carrier (1954–1959)\nIn January 1954, Princeton was reclassified CVS-37 and, after conversion at Bremerton, Washington, took up antisubmarine/ Hunter-Killer (HUK) training operations in the eastern Pacific. For the next five years she alternated HUK exercises off the West Coast with similar operations in the western Pacific and, in late 1957-early 1958, in the Indian Ocean–Persian Gulf area.\nAmphibious assault carrier (1959–1970)\nReclassified again, 2 March 1959, she emerged from conversion as an amphibious assault carrier, LPH-5. Capable of transporting a battalion landing team and carrying helicopters in place of planes, Princeton \'s mission became that of vertical envelopment—the landing of Marines behind enemy beach fortifications and providing logistics and medical support as they attack from the rear to seize critical points, cut enemy supplies, sever communications, and link up with assault forces landed on the beaches. Since this was a Marine Corps mission, Marines made up a major portion of the ship\'s company in the Air, Operations, and Supply Departments.\nFrom May 1959 – January 1960, Princeton trained with Marine units from Camp Pendleton, then deployed to WestPac to train in Okinawan waters. For the next three years, she followed a similar schedule, gaining experience in her primary mission. Interruptions came in October 1961 when she rescued 74 survivors of two merchantmen Pioneer Muse and Sheik grounded on Kita Daito Shima and in April 1962 when she delivered Marine Corps advisors and helicopters to Sóc Trăng in the Mekong Delta area of the Republic of Vietnam (South Vietnam). From September–November 1962, Princeton served as flagship of Joint Task Force 8 during the nuclear weapons test series, Operation Dominic.\nIn October 1964, Princeton exchanged WestPac training for the real thing as she returned to Vietnam and joined the Pacific Fleet\'s Ready Group in operations against North Vietnamese and Viet Cong forces. Combat operations, interrupted in November for flood relief work, continued into the new year, 1965, and culminated in May off Chu Lai as she carried out her primary mission, vertical envelopment, for the first time in combat.\nReturning to her homeport, Long Beach, California, after that operation, she transported Marine Aircraft Group 36 to Vietnam in August, and in February 1966 got underway for another tour in the combat zone. Relieving Okinawa (LPH-3) as flagship for the Amphibious Ready Group, she engaged the enemy in operations ""Jackstay"", 26 March – 6 April, to clear the Rung Sat Special Zone of Viet Cong guerrillas, and ""Osage"", 27 April – 4 May, to protect Vietnamese in the Phu Loc area from Viet Cong ""harassment.""\nSearch and destroy missions against Viet Cong and North Vietnamese Army units followed as Princeton provided transportation, medical evacuation, logistics and communication support for the amphibious operation ""Deckhouse I"", 18 – 27 June, in the Song Cau district and the Song Cai river valley, then supported 1st Air Cavalry and 101st Airborne units engaged in ""Nathan Hale"" to the south of the ""Deckhouse I"" area. ""Deckhouse II"" and support for ""Hastings"" followed as Navy, Marine, and Army units again combined, this time to impede enemy infiltration from the DMZ.\nAfter ""Hastings"", Princeton sailed for home, arriving on 2 September. She deployed again to Vietnam from 30 January–19 June 1967, and again ranged along that long embattled, highly indented coast. In March, she assisted in countering an enemy threat to the Marine artillery base at Gio Linh and evacuated wounded from Con Thien mountain. In April, she participated in ""Beacon Star"", in the Khe Sanh area, and supported search and destroy operations in conjunction with ""Shawnee"". In May, her helicopters lifted Marines to the DMZ to block enemy forces withdrawing across the Bến Hải River.\nA much-needed overhaul followed Princeton \'s return to the west coast, and in May 1968 she again sailed west to Vietnam. There, as flagship for Amphibious Ready Group Alpha, she provided amphibious assault carrier services for operations ""Fortress Attack"" III and IV, ""Proud Hunter"", ""Swift Pursuit"", and ""Eager Hunter"". In December, she returned to the United States and in April 1969 she was designated the prime recovery ship for Apollo 10, the lunar mission which paved the way for Apollo 11 and the first manned landing on the Moon. Apollo 10 was recovered in the South Pacific on 26 May.\nOn 30 January 1970, Princeton was decommissioned and struck from the Naval Vessel Register, and sold for scrapping in May 1971.\nPrinceton received the Navy Unit Commendation for four periods: 5 December 1950 to 10 August 1951, 15 April to 18 October 1952, 13 March to 15 May 1953, and 11 June to 27 July 1953.\nThe flag of USS Princeton is now in Princeton University in the University Chapel.\nThe USS Princeton was used during the filming of the 1952 Monogram Pictures feature Flat Top\n|Wikimedia Commons has media related to USS Princeton (CV-37).|\n- This article incorporates text from the public domain Dictionary of American Naval Fighting Ships. The entry can be found here.']"	['<urn:uuid:58a4f819-1d3f-48d1-a9c1-99d6cf84b5d2>', '<urn:uuid:ff3f8323-89d1-421c-ac55-34b652d07d4d>']	open-ended	direct	short-search-query	similar-to-document	comparison	novice	2025-05-13T04:02:16.770989	7	39	2972
43	agriculture information technology adoption challenges	Access to information services remains a key constraint to agricultural productivity, affecting various aspects of the value chain. While 96% of large farms (with sales of $1 million or more) report significant technology use, there are still challenges in bringing technology to all farms. Currently, about 40% of employers globally struggle to find skilled workers for technology-related positions, and this demand will increase as greater technical proficiency is required. The situation is particularly challenging in regions like Kakamega County, where inadequate access to information services affects agricultural development and youth participation in farming.	['The Relationship Between Access to Information Services and Youth Involvement in Agribusiness Value Chains in Kakamega County, Kenya.\nKeywords:Youth involvement, Kenya., Agricultural Value chains, information services\nAgribusiness offers huge employment potential considering its wider labour absorptive capacity. However, youth involvement in agribusiness in Kakamega County, Kenya is low. The study aimed at assessing the relationship between access to information services and youth involvement in agribusiness value chains. Stratified and simple random sampling was adopted to select 240 respondents. Data collected was analyzed to generate frequencies, percentages and correlation. It was established that there is a strong correlation between access to information and youth involvement in agricultural value chains. Lack of or inadequate access to information services is a key constrain to agricultural productivity in Kakamega county as it affects all aspects of the value chain except consumption. County governments and the Ministry of Agriculture will use these findings to design appropriate agricultural messaging strategies. Policymakers and Donor agencies using these findings will be able to formulate policies that will enhance youth involvement in the Value Chain by knowing what segments of the value chain to focus on youth intervention strategies.\nAfande, F., Maina, W., & Maina, M. (2015). Youth engagement in agriculture in Kenya: Challenges and prospects. Journal of Culture, Society and Development, 7, 4-19.\nAli, A. e. E. S. (2017). The challenges facing poverty alleviation and financial inclusion in North-East Kenya Province (NEKP). International Journal of Social Economics, 44(12), 2208-2223.\nAry, D., Jacobs, L. C., Irvine, C. K. S., & Walker, D. (2018). Introduction to research in education: Cengage Learning.\nBergman Lodin, J., Tegbaru, A., Bullock, R., Degrande, A., Nkengla, L. W., & Gaya, H. I. (2019). Gendered mobilities and immobilities: Women’s and men’s capacities for agricultural innovation in Kenya and Nigeria. Gender, Place & Culture, 26(12), 1759-1783.\nBoye, S. R., & Kaarhus, R. (2011). Competing claims and contested boundaries: legitimating land rights in Isiolo District, northern Kenya. Africa Spectrum, 99-124.\nBryman, A. (2016). Social research methods: Oxford university press.\nCharoenratana, S., & Shinohara, C. (2018). Rural farmers in an unequal world: Land rights and food security for sustainable well-being. Land Use Policy, 78, 185-194.\nEhebrecht, D., Heinrichs, D., & Lenz, B. (2018). Motorcycle-taxis in sub-Saharan Africa: Current knowledge, implications for the debate on “informal” transport and research needs. Journal of Transport Geography, 69, 242-256.\nFAO. (2013). FAO Statistical Yearbook: World Food and Agriculture: FAO.\nFAO, I., & UNICEF. (2015). WFP. The state of food insecurity in the world.\nFAO, I. (2011). WFP,“The State of Food Insecurity in the World: How does international price volatility affect domestic economies and food security?”. Food and Agriculture Organization of the United Nations, 99.\nFox, L., Senbet, L. W., & Simbanegavi, W. (2016). Youth employment in Sub-Saharan Africa: challenges, constraints and opportunities. Journal of African Economies, 25(suppl_1), i3-i15.\nGichimu, B. M., & Njeru, L. K. (2014). Influence of access to land and finances on Kenyan Youth Participation in Agriculture: A Review.\nIrungu, K., Mbugua, D., & Muia, J. (2015). Information and Communication Technologies (ICTs) attract youth into profitable agriculture in Kenya. East African Agricultural and Forestry Journal, 81(1), 24-33.\nKakamega County. (2017). County Integrated Development Plan 2017-2022. Kakamega: Kakamega County.\nKenya National Bureau of Statistics. (2019). 2019 Kenya Population and Housing Census Volume I: Population by County and Sub County.\nKenya National Bureau of Statistics. (2019). 2019 Kenya population and housing census Vol. IV: Distribution of Population by Socio Economic Characteristics.\nKimani, A. W., Nyang’anga, H. T., & Mburu, J. I. (2019). Assessing the Status of Social Media Familiarity among Smallholder Farmers: A Case Study of Thika, Kiambu Kenya. International Journal of Agricultural Extension, 7(1), 13-20.\nKising’u, J. M. (2016). Factors Influencing Youth Participation In Agricultural Value Chain Projects In Kenya: A Case of Kathiani Sub-County, Machakos County, Kenya. Kenya. Nairobi, Kenya: University of Nairobi.\nKNBS (2020) Kenya Economic Survey Report, 2020. KNBS.\nKumar, M. N., & Philip, H. (2019). Information and Communication Technology Utilization Pattern and Determining Factors of Knowledge and Skill Gain among Rural Youths–An Analysis. Environment and Ecology, 37(3B), 966-970.\nManalo IV, J. A., Pasiona, S. P., Bautista, A. M. F., Villaflor, J. D., Corpuz, D. C. P., & Biag-Manalo, H. H. M. (2019). Exploring youth engagement in agricultural development: the case of farmers’ children in the Philippines as rice crop manager infomediaries. The Journal of Agricultural Education and Extension, 25(4), 361-377.\nMudege, N. N., Mbiri, D., & Mdege, N. (2019). Making the agriculture sector work for youth: A tool to promote young men and women’s engagement in growing root, tuber and banana crops.\nMusa, S. F. P. D. (2020). A Study on Youth Aspiration and Perception of Agriculture and Its Policy Implications. In Handbook of Research on Agricultural Policy, Rural Development, and Entrepreneurship in Contemporary Economies (pp. 441-453). IGI Global.\nNasr-Allah, A., Gasparatos, A., Karanja, A., Dompreh, E. B., Murphy, S., Rossignoli, C. M., ... & Karisa, H. C. (2020). Employment generation in the Egyptian aquaculture value chain: implications for meeting the Sustainable Development Goals (SDGs). Aquaculture, 734940.\nNjenga, P. K., Mugo, F., & Opiyo, R. (2011). Youth and women empowerment through agriculture in Kenya: VSO Jitolee.\nNjeru, L. K., Gichimu, B. M., Lopokoiyit, M. C., & Mwangi, J. G. (2015). Influence of Kenyan Youth’s Perception towards Agriculture and Necessary Interventions; a Review. Asian Journal of Agricultural Extension, Economics & Sociology, 40-45.\nNjeru, L. K., Gichimu, B. M., Lopokoiyit, M. C., & Mwangi, J. G. (2015). Influence of Kenyan Youth’s Perception towards Agriculture and Necessary Interventions; a Review.\nOkello, J. J., Ofwona-Adera, E., Mbatia, O. L., & Okello, R. M. (2010). Using ICT to integrate smallholder farmers into agricultural value Chain: The case of DrumNet project in Kenya. International Journal of ICT Research and Development in Africa (IJICTRDA), 1(1), 23-37.\nOduor, F. O., Boedecker, J., Kennedy, G., & Termote, C. (2019). Exploring agrobiodiversity for nutrition: Household on-farm agrobiodiversity is associated with improved quality of diet of young children in Vihiga, Kenya. PloS one, 14(8).\nParoda, R. S. (2019). Motivating and Attracting Youth in Agriculture. LS: International Journal of Life Sciences, 8(3), 149-156.\nRaza, M. H., Khan, G. A., Shahbaz, B., & Saleem, M. F. (2020). Effectiveness of information and communication technologies as information source among farmers in Pakistan. Pakistan Journal of Agricultural Sciences, 57(1).\nSakketa, T., & Gerber, N. (2017). Rural Shadow Wages and Youth Agricultural Labor Supply in Ethiopia: Evidence from Farm Panel Data.\nSoosay, C., Fearne, A., & Dent, B. (2012). Sustainable value chain analysis–a case study of Oxford Landing from “vine to dine”. Supply Chain Management: An International Journal, 17(1), 68-77.\nWorld Bank. (2011). Engendering Development Through Gender Equality in Rights,Resources and Voice. New York: Oxford Univerity Press.\nYamane, T. (1973). Statistics: An introductory analysis.\nYami, M., Feleke, S., Abdoulaye, T., Alene, A. D., Bamba, Z., & Manyong, V. (2019). African rural youth engagement in agribusiness: achievements, limitations, and lessons. Sustainability, 11(1), 185.\nHow to Cite\nCopyright (c) 2022 Jeremiah Rogito, Everlyne Makhanu\nThis work is licensed under a Creative Commons Attribution 4.0 International License.\nAuthors wishing to include figures, tables, or text passages that have already been published elsewhere are required to obtain permission from the copyright owner(s) for both the print and online format and to include evidence that such permission has been granted when submitting their papers. Any material received without such evidence will be assumed to originate from the authors.', 'In the not too distant future, farms will depend on high-tech workers with titles like tech-gronomist, ag tech integrator and knowledge translators, a recent conference of the Canadian Agriculture Human Resources Council (CAHRC) heard.\nIn a presentation entitled Agriculture Skills for the Future, Stuart Cullum, president of Olds College in Alberta spelled out the kinds of skills that will be needed to ensure farming takes full advantage of new technology to increase food production to meet the needs of the global population.\nWithout trained farmers and workers, agriculture will be left behind, he said. Agriculture is off to a good start with 96 per cent of farms with sales of $1 million or more reporting significant technology use. However, much remains to be done to bring technology to all farms.\nThe 2016 agriculture census found that 70 per cent or more of farmers in the age groups between 25 and 59 reported using technology in their operations. And among older producers, the figure was near 50 per cent, he said.\nThe first two green revolutions in agriculture involved adoption of high-yielding and GM varieties of crops while the third green revolution will be about the greater use of technologies to improve farm decision-making and management and to deal with environmental issues, he said.\nThat’s where the tech-gronomist, who can make recommendations based on the data that is produced through big data and artificial intelligence, the ag tech integrator who can make new applications by using existing applications in other industries and applying them to agriculture and knowledge translators who can create new applications for agriculture about technological innovations come in. These and other skilled workers will be essential throughout the entire agriculture supply and production chain. In addition to big data, Cullum said unmanned vehicles and machines, drones and robotics will be key trends in the coming years.\nThe World Economic Forum has projected the level of use of key technologies by 2022 with big data and analytics leading the way at 85 per cent followed by internet-based marketing, machine learning, cloud computing, digital trade and virtual reality.\nCullum said around the world, 40 per cent of employers have problems finding skilled workers and that demand will only increase as greater technical proficiency is required from those working in the technology fields. While artificial intelligence and robots could take over about 75 million jobs by 2022, their use will create 133 new types of positions for trained workers.\nHis institution is trying to prepare graduates who can close the gap with relevant technology training and education and farming experience. At the same time, he said it will take a significant investment to re-skill the current workforce. In addition to the technical skills, workers also need soft skills such as collaboration, critical thinking, communications, creativity and leadership.\nDebra Hauer, project manager at CAHRC, said her organization has developed agriculture-specific human resource tools designed to support modern farm operations to manage their workforce. They include Agri Skills, online and in-person training programs, and the Agri HR Toolkit — an online resource guide and templates to address the HR needs of any business. For agricultural organizations there are customized labour issues briefings that apply the new research to specific commodities and provinces, to explore the labour implications within their specific area.\nShe said one producer told her that he sees autonomous trucks becoming common in the next two to five years and is looking for a truck mechanic now with the technology skills to be able to install/update the software when it is readily available.']	['<urn:uuid:10a6b172-874c-43a7-87b1-9e72163c8095>', '<urn:uuid:9bf5a9d1-6975-47bc-bec6-d356fdde26e7>']	open-ended	direct	short-search-query	similar-to-document	three-doc	novice	2025-05-13T04:02:16.770989	5	93	1810
44	edward carter community service involvement details board member positions catholic church	Edward Carter served as a board member for numerous organizations including Boy Scouts of America, Wright Tool Inc., Kurtz Brothers Inc., University Services Institute, Ritchie Foundation, The Red Cross, Loyola of the Lakes, Summa Foundation, Summa Health System, and Akron Art Museum. He was also Chairman of Future Farmers of America, President of Portage Country Club, President of St. Hilary's Parish Foundation, Founder/President of the Automotive Informational Council in Detroit Michigan, and earned Fourth Degree in Knights of Columbus.	['Obituary of Edward Carter\nEdward Francis Carter Jr. was never not working.\nEddie was born and raised in St. Louis, Missouri to Ed and Lydia Carter on August 24, 1927. He met his future wife when he crashed a volleyball victory party. June Hope Johnson stated no wedding would occur until a college degree was earned. After serving during WW II and getting help from the GI bill he graduated from the University of St. Louis on June 8, 1950 and married his friend, confidant and soulmate June 10, 1950. The two began their married life in St. Louis not knowing how grand their 67-year partnership would be.\nDad would say he only had one job during his career, Firestone Tire and Rubber Company. He started at the bottom and quickly moved through the ranks. Store manager, district manager, division manager, head of Firestone Canada finally retiring as Executive Vice President of North American sales. The rise to the top included adding 5 children at home (Susan, Ed, Janet, Kit and Tom), 17 moves to several different states (& Canada), and becoming the youngest executive/ board member of any rubber company at age 38!!\nUpon retiring Dad did not slow down. He owned Active Tire Stores from 1978-1982, then began TC Rental with his son Tom, amassing over one hundred rental units.\nDad and Mom’s Catholic upbringing was ingrained in the way they lived. Both were positive examples to all of us in the way they volunteered and served our community. Dad was Chairman of Future Farmers of America, past President of Portage Country Club, past President St. Hilary’s Parish Foundation, Founder/past President of the Automotive Informational Council in Detroit Michigan. Dad served as board member for the following: Boy Scouts of America, Wright Tool Inc., Kurtz Brothers Inc., University Services Institute, Ritchie Foundation, The Red Cross, Loyola of the Lakes, Summa Foundation, Summa Health System, Akron Art Museum and earned Fourth Degree in Knights of Columbus.\nA surprise 90th birthday party was held for both Dad and Mom on August 19th. They received a ton of cards, and the Carter kids learned just how far Dad and Mom’s fan base reached. Many well-wishers also expressed thanks to Dad for his years of mentorship\nDad loved Mom, his family, his home and his friends. He was most proud of his wife, his family, and his career. Losing his son Ed to cancer at age 29 was the hardest thing he ever had to deal with.\nHe was preceded in death by his son Edward Francis III and his sister Nancy Lasater. He is survived by his one-and-only, June, son Tom, daughters Susan, Janet, Kit, son-in-law Ken and daughter-in-law Sue as well as 12 grandchildren and 16 great grandchildren.\nYou can stop working now Dad.\nMass of Christian Burial will be Wednesday, October 18, 2017 at 11 AM at St. Hilary Catholic Church, 2750 W Market St, Fairlawn, OH 44333. The family will greet friends one hour before Mass at the church. Entombment in Rose Hill Cemetery. In lieu of flowers memorials can be made to Summa Foundation or St. Hilary Parish Foundation.']	['<urn:uuid:9cb76c4d-2d80-49cc-93b2-deed95e34bd5>']	factoid	with-premise	long-search-query	similar-to-document	single-doc	expert	2025-05-13T04:02:16.770989	11	79	522
45	interested in helping wildlife on farm what benefits conservation tillage has for animals	Conservation tillage provides significant benefits for wildlife on farms. The crop residues provide food and shelter for small game and many species of songbirds. Research specifically shows that quail chicks in no-till fields can meet their daily food needs in twice as quickly compared to conventionally tilled fields. This approach creates a more diverse farm wildlife environment.	"[""What's in it for me?\nPlenty, if you farm row crops or small grains!\nDo any of these interest you?\n- Saving fuel, time, machinery wear, and labor (money!).\n- Better uniformity of stands.\n- Saving nutrients that you paid for.\n- Less runoff, erosion, and weeds.\n- Better soil tilth and overall soil quality.\n- Crops surviving dry weather better.\n- More diverse farm wildlife.\n- A state income tax credit.\n- Better water quality on your farm and downstream.\nSound good? Here's the best part: You can do it, too. Read on to find out more.\nWhat is it?\nSimply stated, conservation tillage is planting crops in the soil through a previous crop's residue. Herbicides are usually used for weed control because you rarely use actual tillage.\nFarmers are now actually planting more acres to conservation tillage than to conventional tillage.\n- Reduced labor and\n- As little as one trip for planting compared to two or more plus planting for conventional tillage. That saves fuel, time, and machinery wear (money!).\n- Time savings:\n- On a 500-acre farm, the time savings can be as great as 225 hours, or almost four 60-hour workweeks.\n- Easier planting:\n- You can plant in straighter rows on hilly land; rows don't have to exactly follow the contour.\n- More soil moisture:\n- Crop residues lower evaporation from the soil. This can mean up to 2 additional inches of water available to your crop in late summer.\n- Better soil tilth:\n- It builds up a rich layer of organic material on the soil surface. This increases water infiltration and moisture holding capacity. That means more uniform stands that can better survive dry weather.\n- Less erosion:\n- Year-round ground cover can reduce erosion by up to 90% compared to an unprotected, conventionally tilled field.\n- Improved water quality:\n- Crop residues help hold soil particles and the associated nutrients and pesticides in the field, and out of your streams. And the microbes that live in organic-rich soils quickly degrade pesticides, better protecting ground water quality.\n- Improved soil quality:\n- You get more earthworms and other soil critters that work for free. What's the benefit? Reduced soil compaction, improved soil structure, increased organic matter, better soil tilth, and better nutrient holding capacity.\n- More wildlife:\n- Do you enjoy nature? Crop residues provide food and shelter for small game and many species of songbirds. Research shows that quail chicks in no-till fields meet their daily food needs in half the time compared to conventionally tilled fields.\n- Lower your taxes:\n- You may be eligible for a state income tax credit after purchasing a conservation tillage planter or drill, or converting existing equipment.\nWant to be successful?\n- For early crops like corn, well drained soils are better suited to conservation tillage than are poorly drained soils, which warm more slowly in the spring.\n- Test your soil fertility yearly.\n- Develop a nutrient management plan that gives credit for a previous legume crop, manure, or other land applied wastes. Use a starter fertilizer if needed.\n- Know your weeds before you plant, and use a pre-emergence herbicide. After the crop germinates, properly identify weeds that you may need to spray with a post-emergence herbicide.\n- Scout for weed problems to plan next year's weed control.\n- Scout for insect pests, and apply insecticide only when natural predators don't provide economical control.\n- Plan for next year's residue cover at harvest time. Spread the residue evenly; don't allow it to accumulate in windrows behind the combine.\n- Finally, be patient. The benefits of conservation tillage may take a few years to notice, but they last for many years.\nConservation tillage is very effective for corn, wheat, soybeans, and even cotton. Pasture renovation, too.\nAlthough it often needs special equipment, conventional equipment can be adapted to leave more residue on the surface. Overall equipment and labor costs can actually decrease since you don't need a plow, disk, or cultivator, or as powerful a tractor as when you were turn-plowing.\nMany Conservation Districts rent conservation tillage equipment, and have staff available from the USDA Natural Resources Conservation Service and the SC Department of Natural Resources. The Cooperative Extension Service is another great source of help. All of them have knowledge based on research throughout the US, and the experience of local farmers.\nThe Bottom Line:\nIf you're new to conservation tillage, go slowly. There's lots of free help available from local experienced farmers, and through your Conservation District and county Extension Service offices. Call them!\nEven if you're experienced, call these agencies. They keep up with the latest developments that can help boost your profits. And if you have a problem, they'll help you find the answer.\nThe first step, though, is up to you. Call your Conservation District or county Extension Service office. They have free information and technical support that can help you.""]"	['<urn:uuid:d76dbeff-59d3-4651-8269-0aa1a56e43da>']	open-ended	with-premise	long-search-query	similar-to-document	single-doc	novice	2025-05-13T04:02:16.770989	13	57	823
46	What's harder - getting the offshore or ocean certification?	The Ocean certification is more demanding as it requires first holding the Yachtmaster Offshore Certificate, plus completing additional requirements including: a 40-hour theoretical course on astro navigation and worldwide meteorology, a qualifying passage of at least 600 miles with 96 continuous hours at sea, demonstrating navigation by sextant, and passing an oral exam that typically takes 1.5 hours. The Offshore certification, while still challenging with its own theoretical and practical components, has less extensive requirements and allows operation only within 150 miles from safe haven.	"['What is an Ocean Yachtmaster? and How to become an Ocean Yachtmaster\nThe RYA/MCA Ocean Yachtmaster Certificate of Competence (CoC) is the highest level certificate in the RYA scheme. It can be used by blue water leisure sailors and by commercial skippers and crew. Under the MCA Codes of practice the Ocean Yachtmaster Certificate of Competence holder, (with relevant commercial endorsement etc.) can skipper a vessel;\n- Up to 200 tonnes\n- Carrying up to 12 passengers\n- Anywhere globally (i.e. beyond the 150 miles from a safe haven limit imposed upon a Yachtmaster Offshore).\nFurthermore the Yachtmaster Ocean CoC is the minimum requirement for certain officer positions on board larger (over 200 tonne) yachts.\nThere are 5 stepping stones to becoming an Ocean Yachtmaster CoC holder. Steps 1-4 can be taken in any order although the order presented below is the most logical. Step 5 can only be completed once the first 4 steps have been completed.\n- Yachtmaster Offshore Certificate of Competence\n- RYA Ocean Yachtmaster Shorebased Course\n- Qualifying Passage\n- Sights and Compass Check by sextant at sea\n- RYA/MCA Ocean Yachtmaster Certificate of Competence Oral Exam\nIt is technically possible to take the Ocean Yachtmaster CoC Oral exam without having previously completed the RYA Ocean Shorebased Course but not advised as it involves an additional written exam and you would require all of the relevant knowledge taught on the course. Further information is detailed the relevant 5 steps below;\nBecoming a Yachtmaster Offshore Certificate of Competence Holder\nWhile you can proceed towards the RYA Ocean shorebased course and the Ocean practical steps (qualifying passage and sights) you can not proceed to the Oral exam without first holding the Yachtmaster Offshore Certificate of Competence.\nRYA Ocean Yachtmaster Shorebased Course\nThis is a 40-hour theory course. It can be taken;\n- Over 5 consecutive days face to face in the classroom\n- Over 13 evenings face to face night school in the classroom\n- Over 5.5 days face to face using zoom\n- Online in your own time.\nWhichever format you choose the course culminates in a written paper.\nThe course concentrates on astro navigation, i.e using a sextant and the heavenly bodies (sun, moon, stars and planets) to fix your position. The course also devotes time to ocean voyage planning and worldwide meteorology.\nFull details can be found at Ocean Yachtmaster Shorebased Course\nWhile you don’t strictly need to be a Yachtmaster Offshore before taking the Ocean Yachtmaster Shorebased Course, the following knowledge is assumed before the Ocean Shorebased course starts;\n- Use of plotting instruments (plotter, dividers etc.)\n- Latitude and longitude, knots and nautical miles\n- Variation and deviation\n- Application of UT, DST\n- Position Fixing\n- 2/3 Point fixes and angles of cut\n- Dead Reckoning / EP (and ideally the Running Fix)\n- GPS and other electronic nav aids\n- Coastal/offshore voyage planning\n- Coastal and offshore meteorology in particular;\n- Sources of forecast information\n- Synoptic charts\n- Low pressure systems\n- Coastal communications /distress comms. (Navtex, VHF, EPIRBs and SARTs)\nIs the Ocean Yachtmaster Shorebased Course Written Exam Invigilated?\nIf you take a face to face Ocean Yachtmaster Shorebased Course then the written paper is invigilated and marked by your Instructor.\nIf you choose to take the Online or Webinar RYA Ocean Yachtmaster Shorebased Course then face to face invigilation may be required (see table below).\nReason for taking the Ocean Yachtmaster Shorebased Course\n|I am taking the course for fun/ and/or for my own interest||Invigilation not required|\n|I intend to use the knowledge for leisure sailing||Invigilation not required|\n|I intend to use this course as a pre requisite for the RYA/MCA Ocean Yachtmaster Certificate of Competence Exam||Invigilation required by an RYA Instructor, otherwise you will be required to complete a written exam at the time of your Ocean Yachtmaster Certificate of Competence Oral Exam|\n|I intend to use this certificate as a pre requisite for the MCA Master 200 (unlimited) Certificate of Competence||Invigilation required by an RYA Instructor|\n|I intend to become a STCW Chief Mate (and possibly Master 500/3000)||Invigilation required by an RYA Instructor|\nWhat qualifies as a RYA Yachtmaster Ocean Qualifying Passage?\nA qualifying passage must have been taken in the last 10 years. Sea time prior to this date does not qualify. The passage must meet the following requirements\nOcean Yachtmaster Candidate’s Role On Board\nFor your qualifying passage you should be either the skipper or mate in sole charge of a watch. You must have been fully involved in the planning of the passage, including selection of the route, the navigational plan, checking the material condition of the vessel and her equipment, storing with spare gear, water and victuals and organising the watch-keeping routine.\nIf the skipper changes role at any point during the passage, then neither skipper can use the passage as a qualifying passage.\nIt is our opinion that it is impossible for multiple Ocean Yachtmaster candidates to use the same passage as their qualifying passage as you can not all fit the definitions above. More than two candidates would be highly unlikely more than three impossible.\nOcean Yachtmaster Qualifying Passage\nThe passage has several minimum requirements\n- Departure and arrival ports must be more than 600 miles apart by the shortest navigable route\n- Minimum non-stop distance of 600 miles must have been run by the log\n- At least 200 miles of that passage must have been more 50 miles from land (or charted objects capable of being used for navigation/position fixing, such as an offshore oil rig)\n- The vessel must have been at sea continuously for at least 96 hours\nPassages such as recognised races which may not comply exactly with these requirements may be submitted to the RYA for consideration before the voyage.\nExamples of Ocean qualifying passages (non stop passages)\n- Trans-Atlantic ARC Rally (Canary Islands to St. Lucia/Caribbean)\n- Between Azores and anywhere in mainland Europe/UK or the Canary Islands\n- Between Bermuda and any of; Bahamas, Caribbean, Canada or most of USA (parts of North Carolina fall below the requirements)\n- Between Bermuda and the Azores or Europe\n- Solent/UK to Cascais/Portugal,Algarve, Southern Spain or Gibraltar (assuming you follow the rum line or stay offshore when crossing Biscay)\n- Trans Pacific Passage (excluding passages between Alaska and Russia, on or close to the Bering Sea)\n- Atlantic Germany (Elbe) to Scotland, where the 200 mile run is impossible due to oil rigs)\n- Gibraltar to Northern Lanzarote where the mileage falls slightly below 600\n- RORC Fastnet Race which does not follow the shortest navigable route or have the 200 mile run\n- Northern Spain to Majorca, although well over 600 miles, very little of the passage is over 50 miles from land\nVessel used for Ocean Yachtmaster Qualifying Passage\nThe yacht (or vessel) must be;\n- Minimum size 7m, LWL\n- Maximum size 500 tonnes (If the vessel is over 24m LOA then the candidate would need to hold an appropriate Certificate of Competence to act as Officer of the Watch on the passage).\nSights and Compass Check by Sextant at Sea\nYou are required to provide your Ocean Examiner with a minimum of’\n- Sun Run Mer Pass (or sun run sun, sun run planet etc.)\n- Compass check carried out using the bearing of the sun, moon, a star or planet\nSights are usually taken on the qualifying passage however in some circumstances (such as lots of cloud cover) this is not possible. If sights have been taken on another passage then the following requirement apply to this passage.\n- The vessel must of been out of sight of land and charted objects when the sights are taken/used.\n- The vessel must be on a passage by the shortest navigable route. You can not therefore simply head offshore take sights and return to departure port.\nWe always advise candidates to present the examiner with more than the minimum required sights. If you present the examiner with additional sights and your preferred set suffers from errors you still stand a chance of passing the exam.\nRYA/MCA Ocean Yachtmaster Certificate of Competence Oral Exam\nPrior to the exam you will need to provide the examiner with;\n- A narrative account of the planning and execution of the qualifying passage providing all relevant details.\n- Navigational records, completed on board a yacht on passage, out of sight of land showing that the candidate has navigated the yacht without the use of electronic navigational aids. The records must include as a minimum, planning, reduction and plotting of a sun run meridian altitude sight and a compass check carried out using the bearing of the sun, moon, a star or planet.\nDuring the oral exam you will be required to answer questions on all aspects of ocean passage making in a yacht, including passage planning, navigation, worldwide meteorology, crew management and yacht preparation, maintenance and repairs.\nIf you already hold the RYA Ocean Shorebased Course Certificate, the exam typically takes 1.5 hours although examiners can continue questioning considerably longer. If you do not hold the Ocean Shorebased certificate then your exam will take considerably longer as you will also have to take a written test.\nDoes the Ocean Yachtmaster Qualifying Passage have to be on the same type of vessel as I took my Yachtmaster Offshore Exam on (i.e. power or sail)?\nMost candidates will qualify in the same kind of vessel as they passed their Offshore exam, however it is possible to qualify as a Yachtmaster Offshore (power) and then compete the Yachtmaster Ocean requirements on a sail vessel (or vice versa).\nI hold a OOW (Yacht 3000gt) CoC but not a Yachtmaster Offshore CoC\nIf you passed the Yachtmaster Coastal Certificate of Competence Exam instead of the Yachtmaster Offshore Certificate of Competence Exam as your entry requirement into the OOW 3000 CoC then you will not be eligible to hold the Yachtmaster Ocean Certificate of Competence. On passing the oral exam you will receive a pass confirmation certificate.\nHow do I commercially endorse the Yachtmaster Ocean Certificate of Competence?\nThose working under the MCA Codes of practice will require a commercial endorsement. Information can be found at RYA Commercial Endorsements. If you already hold a commercial endorsement on your Yachtmaster Offshore CoC then it is simply transferred across.\nDo I require any other certificates to operate commercially as an Ocean Yachtmaster?\nTo operate a coded sailing yacht in Category 1 or 0 waters (i.e. Over 60 miles from a safe haven) you will additionally require a RYA Diesel Certificate.\nTo operate the mandatory GMDSS radio equipment on a commercial vessel in Sea Area A2 (more than about 35 miles offshore) you will require either a Long Range Certificate (LRC) or STCW General Operator Certificate (GOC).\nTo skipper a coded vessel in Category 1 or 0 waters (i.e. Over 60 miles from a safe haven) you will additionally need to hold STCW Proficiency in Medical First Aid and Proficiency in Medical Care, unless there is a current qualified nurse practitioner (or higher) on board.\nIf working aboard a vessel in Category 1 or 0 waters (i.e. Over 60 miles from a safe haven) you will need a ENG1 Medical certificate. The alternatives which are suitable further inshore such as ML5 Medical Certificate are not valid in category 1 and 0 waters.', ""Yachtmaster offshore certificate of competence\nA RYA Yachtmaster Certificate of Competence is often the ultimate aim of aspiring skippers. It is a well known, highly respected qualification worldwide, proving your experience and competence as a skipper.\nThe Yachtmaster offshore is an important international yachting certificate of competence. We have sucessfully trained client from over 30 nationalities.\nIt signifies that a skipper is competent on a yacht to make passages up to 150nm from harbour.\nThe Yachtmaster qualification is an aspiration for many yachtsmen and a key achievement for those wishing to follow a professional career in yachting.\nMany of the top yachts in the world trust us to train their crews.\nThe RYA/MCA indicate that there is no formal course to apply for a Yachtmaster assessment exam just a lot of knowledge and experience of differing sailing environments, sufficient command experience and seatime.\nIn our experience, your chances of being successful will be greatly enhanced by competing the RYA yachtmaster theory course and undertaking our Practical course of preparation, prior to the exam.\nWhat to expect\nThe yachtmaster assessment will push you to the limits of your practical and theoretical knowledge. It is the most exhausting and exciting experience, regardless of the weather conditions. The RYA pre requirements are the minimum,the exam can cover anything in the entire yachting syllabus. .\nWe work with some of the top examiners and assessors in the RYA system. They have had decades of experience and they will try to put you at ease in order that you demonstrate your full potential.\nThe Yachtmaster offshore is obtained by examination which involves exercises, challenges and tasks from any part of the syllabus is to demonstrate the ability and confidence of the skipper.\nWe help you prepare for the exam look at your strengths and weaknesses.\nWe can then build a on the areas that need developed to put you in the best position for the exam. This is typically 4-5 days depending on the breadth of experience.\nWe will work with you to prepare you for this important challenge and tell you if you are not ready.\nWe make a commitment to work with you until successful if you put the effort in.\nA separate exam fee is payable to the RYA for examinations. These must be arranged well in advance.\nwe will discuss your experience prior to starting the course. If you don’t have enough Tidal miles, we regularly run Tidal Mile-Building trips.\nWe regularly hold 60-mile passages for prospective yachtmaster s to build the skipper and crews day and night command skills.\nThe yachtmaster certificate of competence can be commercially endorsed to enable you to work in a wide range of yachting internationally.\nWorking with a Yachtmaster™ Coastal certificate\nA commercially endorsed Yachtmaster™ Coastal Certificate of Competence will enable you to skipper vessels up to 24 metres in length, operating in category 3,4,5, and 6 waters - up to 20 miles from a safe haven.\nWorking with a Yachtmaster™ Offshore certificate\nA commercially endorsed Yachtmaster Offshore Certificate of Competence will enable you to work as a Master of commercial vessels of up to 200gt in category 1 to 6 waters - that is up to 150 miles from a safe haven.\nThis Certificate of Competence can used commercially in its own right, or as a pre-requisite for the MCA's Officer of the Watch qualification, which enables you to work worldwide on vessels of up to 3000gt.\nWorking with a Yachtmaster™ Ocean certificate\nA commercially endorsed Yachtmaster™ Ocean Certificate of Competence will enable you to work worldwide as a Master of commercial vessels of up to 200gt.\nThis Certificate of Competence can be used commercially in its own right. It is also a pre-requisite for the MCA's Chief Mate, Master 500 and Master 3000 qualifications.""]"	['<urn:uuid:4871067e-5c84-4898-9f50-3a0d37dc3aeb>', '<urn:uuid:1e8ab801-73ac-48fd-b596-12e3f4ecb185>']	open-ended	with-premise	concise-and-natural	distant-from-document	comparison	novice	2025-05-13T04:02:16.770989	9	85	2527
47	I work with endophytic bacteria in forest nurseries and I'm wondering about the advantages of using endophytic bacteria like Burkholderia sp. for controlling pitch canker fungus in Pinus seedlings - what does the research show?	The research shows that endophytic bacteria are particularly advantageous as biocontrol agents because they are already well-adapted to live in host tissues and are symptomless colonizers of Pinus taeda seedlings. Burkholderia sp. has beneficial effects through the production of antifungal compounds that can suppress plant pathogens. The study demonstrated that Burkholderia sp.'s thermostable metabolites reduced F. circinatum growth by over 50%. This makes it a promising alternative to chemical control in nurseries to prevent disease expansion to the field, especially since Burkholderia is not frequently used in forest management.	"['versión On-line ISSN 0718-5839\nChilean J. Agric. Res. vol.72 no.2 Chillán jun. 2012\nChilean Journal of Agricultural Research 72(2) April - June 2012\nEndophytic Bacteria from Pinus taeda L. as Biocontrol Agents of Fusarium circinatum Nirenberg & O\'Donnell\nBacterias Endófitas de Pinus taeda L. como Agentes de Control Biológico de Fusarium circinatum Nirenberg & O\'Donnell\nSilvina Soria1, Raquel Alonso1*, and Lina Bettucci1\n1Universidad de la República, Facultad de Ciencias-Facultad de Ingeniería, Montev\nideo, Uruguay. ""Corresponding author (firstname.lastname@example.org).\nFusarium circinatum Nirenberg & O\'Donnell, the pitch canker fungus, has been recently reported in Uruguay affecting Pinus taeda L. seedlings. The spread of this pathogen to plantations constitute a risk to forestry production. The aim of this work was to evaluate the inhibitory effect of live bacteria and their thermostable metabolites on F. circinatum growth in vitro. Four Bacillus subtilis strains and one of Burkholderia sp. isolated as P. taeda endophytes were evaluated as biological control agents of F. circinatum. Dual cultures between live bacteria and pathogen were performed. Furthermore, bacteria metabolites obtained from liquid cultures were sterilized and added to the culture media where fungus was grown. In this study all bacteria showed an antagonist effect on the pathogen growth arresting the mycelia at one cm of the edge of the bacteria colony. Bacteria thermostable metabolites reduced over 50% fungal growth. These results demonstrates that endophytic bacteria, well adapted to live in host tissues, constitute a good alternative to control F. circinatum affecting Pinus seedlings.\nKey words: Biological control, Bacillus sp., Burkholderia sp., pitch canker.\nLa presencia de Fusarium circinatum Niremberg & O\'Donnell, agente causal del cancro resinoso en pino, ha sido detectada recientemente en plántulas de Pinus taeda L. en Uruguay. La propagación de este patógeno en las plantaciones constituye un riesgo para la producción forestal. El objetivo de este trabajo fue determinar la capacidad inhibitoria de bacterias vivas y de sus metabolitos termoestables sobre el crecimiento de F. circinatum in vitro. Cuatro cepas de Bacillus subtilis y una de Burkholderia sp. aisladas como endófitas de P. taeda, fueron evaluadas como potenciales agentes de control biológico sobre F. circinatum. Para ello, se realizaron enfrentamientos directos entre las bacterias vivas y el micelio del patógeno. Por otra parte, los metabolitos bacterianos obtenidos de cultivos líquidos fueron esterilizados en autoclave y se incorporaron al medio de cultivo donde se hizo crecer el patógeno. En este estudio todas las bacterias mostraron un efecto antagónico sobre el crecimiento del patógeno, deteniéndose el avance del micelio a 1 cm del borde de la colonia bacteriana. Los metabolitos termoestables de las bacterias produjeron una disminución significativa en la tasa de crecimiento del hongo mayor al 50%. Estos resultados muestran que las bacterias que viven dentro de los tejidos sanos del hospedante son una buena alternativa para el control del patógeno F. circinatum en plántulas de Pinus.\nPalabras clave: control biológico, Bacillus sp., Burkholderia sp., cancro resinoso.\nThe pitch canker fungus Fusarium circinatum Nirenberg and O\'Donnell is a destructive pathogen that affects several Pinus species (Barnard and Blakeslee, 1980; Viljoen et al., 1994). The symptom more frequently associated to this pathogen is the presence of large resinous cankers on the main trunk and lateral branches of trees but it can also be associated to roots, shoots, cones, and seedlings. In plant seedlings aerial symptoms do not appear until the pathogen reach the trunk from lesions at soil level resulting in plant discoloration and needles drying. The disease has been detected in south eastern USA (Kuhlman et al., 1982), Mexico, South Africa, Chile, Japan, and Spain (Kobayashi and Muramoto, 1989; Guerra-Santos, 1999; Wingfield et al., 2002; Perez Sierra et al., 2007). Recently, in Uruguay this pathogen was detected on Pinus taeda L. seedlings from nurseries mainly affecting stem collar (Alonso and Bettucci, 2009).\nAccording to Cook and Baker (1983) biological control can be defined as a reduction of the amount of inoculum or disease produced by the activity of a pathogen, based on the use of natural enemies or the use of compounds derived from its metabolism. Then, the biological control offers an alternative to the chemical products, contributing to minimize the negative consequences for human health and environment (Kim et al., 2003). Fungal diseases are very frequent in nurseries and the chemical control of pathogens is the most common practice.\nBacillus subtilis has been identified as a potent antagonist against several fungal pathogens due to the production of antifungal compounds, antibiotics and proteases, hence is extensively used in agricultural systems (Todorova and Kozhuharova, 2009; Chen et al., 2009; Kinsella et al., 2009).\nBurkholderia sp. is known to have beneficial effect on plant growth through the production of antifungal and other compounds that are able to suppress many soil-borne plant pathogens (Holmes et al., 1998). Burkholderia cepacia is an ubiquitous soil organism that can be easily obtained and it has been studied as biocontrol agent of plant disease (Leisinger and Margraff, 1979). Many of its metabolites have been isolated and identified thus verifying its inhibitory effect on different plant pathogens such as fungus, bacteria and yeasts (Sopheareth et al., 2006), particularly on species of Pythium, Botrytis, Fusarium, and Rhizotocnia (Sijam and Dikin, 2005; Quan et al., 2006).\nThe abuse and misuse of chemical products can cause environmental and human health-related risks. On the other hand, little work has been performed on biological control of forest pathogens. Identification and action mode of antifungal compounds produced by an antagonist need to be studied.\nThe aim of this work was to evaluate the antagonist effect of both live bacteria and their thermostable metabolites of four Bacillus subtilis strains and one of Burkholderia sp. on Fusarium circinatum growth.\nMATERIALS AND METHODS\nFungal and bacteria isolates\nFusarium circinatum strains used in this work were all isolated from symptomatic Pinus taeda seedlings from two Pinus nurseries from Rivera and Florida Departments in Uruguay. The fungal isolates were identified by macro and micromorphological characteristics and verified by molecular analysis using CIRC1A and CIRC4A specific primers for F. circinatum (Schweigkofler et al., 2004). The isolates were maintained in potato dextrose agar (PDA). Bacteria were present as endophytes from Pinus seedlings and were isolated from stem healthy tissues. Those showing inhibitory effect on fungal growth were selected. The identification of bacteria strains were performed by molecular analysis of 16S RNA region. The cultures were maintained on triptone soy agar (TSA).\nBacteria antagonist on F. circinatum growth\nTo evaluate the antagonist effect of different live bacteria, mycelia plugs from the edges of actively growing fungal cultures were placed in the center of Petri dish containing PDA. Four bacteria isolates were streaked on the same plates at equal distance from the fungal inocula. Plates with the fungal plug without bacteria were used as control. Plates were incubated at 25 °C for 5 d to evaluate the inhibition activity of bacteria on the fungus. Each treatment was replicated five times. The fungal strains used were Fc 2052, Fc2053, Fc2054, and Fc2057. Bacteria strains of Bacillus subtilis used were B1, B2, B3, B4, and one strain of Burkholderia sp. (B5).\nObservations of mycelia of the interaction zone between fungi and bacteria were performed under microscope.\nThe activity of bacteria thermostable metabolites was also evaluated. Liquid cultures of bacteria were performed transferring colonies of each bacterium to a 250 mL Erlenmeyer flask containing 100 mL of potato dextrose broth (PDB) and then incubated in a rotary shaker at 27 °C and 180 rpm during 7 d. Ten milliliters of each flask were transferred to a new flask with 90 mL of PDA. These new flasks were sterilized during 16 min at 121 °C and 1 atm. The culture medium plus the metabolites were homogenized and 20 mL were placed on Petri dishes of 9 cm of diameter. Once the medium was solidified a plug of each fungal strain was placed in the centre of a dish. A fungal plug placed on PDA was used for control. Each treatment and control was replicated three times. Both treatments and controls were incubated at 25 °C during 9 d. After incubation for 120 h the diameter of the colonies was measured daily during 4 d and compared with controls. The measures were made from the centre of the fungal plug to the edge of the colony. Two measures were taken which were then averaged. Percentage of inhibition growth and the rate of growth were calculated. To determine if there were differences in the rate of growth between the four fungal strains tested a One Way ANOVA test was made using the Sigma Stat 3.5 program.\nRESULTS AND DISCUSSION\nIsolation of bacteria and screening of antifungal effect The screening of bacteria for antifungal activity against the Pinus pathogen F. circinatum showed that all of them exhibited growth inhibition against the pathogen. All the strains arrested the mycelium growth at 1 cm or more of the fungal colony margin (Figure 1). The development of an inhibition halo was observed between the fungal colonies and the bacteria inocula. This may be due to the production of bacterial metabolites that may diffuse in the culture medium and suppress the growth of F. circinatum. These results are consistent with those obtained by Nourozian et al. (2006) who evaluated the antagonist activity of different bacteria (Bacillus, Pseudomonas) against F. graminearum. They observed, in dual culture experiments, the formation of inhibition zones between bacteria and fungus.\nThe micromorphology of mycelia in the interaction zone showed a change in hyphal mode development, exhibiting empty, vacuolated and swollen hypha and a different ramification pattern.\nEffect of thermostable metabolites\nDespite metabolites of all strains showed an inhibitory effect against the fungus strains tested (Figure 2) all of them had a different incidence on the fungal growth (Figure 3).\nFigure 2. Antagonist effect of thermostable metabolites on Fusarium circinatum growth (±SD).\nGrowth of Fusanum circinatum strains Fc2052 Q, Fc2053 S, Fc2054 PS and Fc2O570 after 5 days on culture media containing thermostable metabolites of Bacillus subtilis strains (B1, B2, B3, B4) and Burkholderia sp. (B5). Control: culture media without metabolites.\nFigure 3. Growth of Fusarium circinatum strain Fc2057 on culture media containing thermostable metabolites of Bacillus subtilis strains (A: strain B1; B: strain B2; C: strain B3; D: strain B4; E: control, culture media without metabolites).\nThere were significant differences among the bacterial strains. Growth inhibition on the strain Fc2052 was greater than to the other strains (p < 0.05) (Figure 2). On the other hand, from all strains of B. subtilis the strain B2 showed the lowest effect on the pathogen growth. Although the fungal strain Fc2053 showed a lesser growth than the control, the difference was not significant. The effect of metabolites of B. subtilis B1 on Fc2054 was greater than to other fungal strains. Metabolites from Burkholderia sp. evidenced a lesser effect on the growth of this pathogen. Metabolites of B1, B3, B4, and B5 reduced the growth of F. circinatum Fc2057over 50% (Figure 2).\nThese results showed that the metabolites of Bacillus and Burkholderia tested, reduced the rate of growth of F. circinatum although some differences among fungal strains were observed. These findings suggest the possibility of using B. subtilis as biocontrol agent of Pinus pathogen F. circinatum, consistently with other studies where Bacillus has inhibitory effect against Fusarium spp. and other plant pathogen fungi (Moita et al., 2005; Kinsella et al., 2009). Recently, Burkholderia spp. have been used as biocontrol agents against fungal disease, including Fusarium spp. (Quan et al., 2006).\nThe bacteria that were present as endophytes of Pinus taeda seedlings were symptomless colonizers and apparently adapted to host tissues. This can constitute an advantage for using them as biocontrol agent of the pitch canker fungus on this host. The biological control could be an alternative to reduce the incidence of the pathogen in nurseries in order to avoid the expansion of the disease to the field. The active thermostable metabolites are also a very interesting alternative to chemical control and to avoid the use of living organisms. Both, B. subtilis and Burkholderia are not frequently used in forest management.\nWe thank Estella Reginensi and Ana Clara Bianchi for the identification of the bacteria used in this study.\nAlonso, R., and L. Bettucci. 2009. First report of the Pitch canker fungus Fusarium circinatum affecting Pinus taeda seedlings in Uruguay. Australasian Plant Disease Notes 4:91-92. [ Links ]\nBarnard, E.L., and G.M. Blakeslee. 1980. Pitch canker of slash pine seedlings: a new disease in forest tree nurseries. Plant Disease 64:695-696. [ Links ]\nCook, R.J., and K.F. Baker. 1983. The nature and practice of biological control of plant pathogens. 593 p. APS Press, St. Paul, Minnesota, USA. [ Links ]\nChen, F., M. Wang, Y. Zheng, J. Luo, X. Yang, and X. Wang. 2009. Quantitative changes of plant defense enzymes and phytohormone in biocontrol of cucumber Fusarium wilt by Bacillus subtilis B579. World Journal of Microbiology and Biotechnology 26:675-684. [ Links ]\nGuerra-Santos, J.J. 1999. Pitch canker on Monterrey pine in Mexico. In Devey, M.E., A.C. Matheson, and T.R Gordon (eds.) Forestry and forest products. Current and potential impacts of pitch canker in Radiata pine. Technical Report Vol. 112. p. 58-61. CSIRO, Canberra, Australia. [ Links ]\nHolmes, A., J. Govan, and R. Goldstein. 1998. Agricultural use of Burkholderia (Pseudomonas) cepacia: A threat to human health? Emerging Infectious Diseases 4:221-227. [ Links ]\nKim, H.S., J. Park, S.W. Choi, K.H. Choi, G.P. Lee, S.J. Ban, et al. 2003. Isolation and characterization of Bacillus strains for biological control. Journal of Microbiology 41:196-201. [ Links ]\nKinsella, K., C.P. Schulthess, T.F. Morris, and J.D. Stuart. 2009. Rapid quantification of Bacillus subtilis antibiotics in the rhizosphere. Soil Biology & Biochemistry 41:374-379. [ Links ]\nKobayashi, T., and M. Muramoto. 1989. Pitch canker of Pinus luchuensis, a new disease of Japanese forests. Forests Pests 40:169-173. [ Links ]\nKuhlman, E.G., S.D. Dianis, and T.K. Smith. 1982. Epidemiology of pitch canker disease in a loblolly pine seed orchard in North Carolina. Phytopathology 72:1212-1216. [ Links ]\nLeisinger, T., and R. Margraff. 1979. Secondary metabolites of fluorescent pseudomonads. Microbiological Reviews 43:422-442. [ Links ]\nMoita, C., S.S. Feio, L. Nunes, M.J.M. Curto, and J.C. Roseiro. 2005. Optimization of physical factors on the production of active metabolites by Bacillus subtilis 355 against wood surface contaminant fungi. International Biodeterioration and Biodegradation 55:261-269. [ Links ]\nNourozian, J., H.R. Etebarian, and G. Khodakaramian. 2006. Biological control of Fusarium graminearum on wheat by antagonistic bacteria. Songklanakarin Journal of Science and Technology 28:29-38. [ Links ]\nPerez Sierra, A., E. Landeras, M. Leon, M. Berbegal, J. García-Jiménez, and J. Armengol. 2007. Characterization of Fusarium circinatum from Pinus spp. in northern Spain. Mycological Research 111:832-839. [ Links ]\nQuan, C.S., W. Zheng, Q. Liu, Y. Otha, and S.D. Fan. 2006. Isolation and characterization of a novel Burkholderia cepacia with strong antifungal activity against Rhizoctonia solani. Applied Microbial and Cell Physiology 72:1276-1284. [ Links ]\nSijam, K., and A. Dikin. 2005. Biochemical and physiological characterization of Burkholderia cepacia as biological control agent. International Journal of Agriculture and Biology 7:385-388. [ Links ]\nSchweigkofler, W., K. O\'Donnell, and M. Garbelotto. 2004. Detection and quantification of airborne conidia of Fusarium circinatum, the causal agent of pine pitch canker, from California sites by using a real-time PCR approach combined with a simple spore trapping method. Applied and Environmental Microbiology 70:3512-3520. [ Links ]\nSopheareth. M., L. Seug-Je, H. Hoon, K. Yong-Wong, P. Keun-Hyung, C. Gyu-Suk, et al. 2006. Isolation and characterization of antifungal substances from Burkholderia sp. culture broth. Current Microbiology 53:358-364. [ Links ]\nTodorova, S., and L. Kozhuharova. 2009. Characteristics and antimicrobial activity of Bacillus subtilis strains isolated from soil. World Journal of Microbiology and Biotechnology 26:1207-1216. [ Links ]\nViljoen, A., M.J. Wingfield, and W.F.O. Marasas. 1994. First report of Fusarium subglutinans f. sp. pini on seedlings in South Africa. Plant Disease 78:309-312. [ Links ]\nWingfield, M.J., A. Jacobs, T.A. Coutinho, R. Ahumada, and B.D. Wingfield. 2002. First report of the pitch canker fungus, Fusarium circinatum, on pines in Chile. Plant Pathology 51:397. [ Links ]\nReceived: 15 September 2011.\nAccepted: 25 May 2012.']"	['<urn:uuid:b2ae39c2-542e-4f5e-aa2a-2a9ee94ad27a>']	open-ended	with-premise	verbose-and-natural	similar-to-document	single-doc	expert	2025-05-13T04:02:16.770989	35	89	2670
48	Why does movie rain need to be torrential?	Movie rain has to be torrential because if not, it's invisible on camera.	"[""It's a painful truth that movie rain has to be absolutely torrential. If not, it's invisible. Done right, there is a very literal crossover betweensmoke and mist, which is generally made out of small droplets of fluid, and rain, which is made out of larger droplets of fluid (movie smoke is generally boiled oil, as opposed to burned oil). There exists a transitional zone in real-world weather, where mist is made of big enough drops that it immediately soaks anything that's put out in it. This too can be simulated using high-pressure water jets. They're often seen in theme parks and can be improvised from a pressure washer. The difference between mist and rain is perhaps best defined as how much water ends up lying on the ground and how much evaporates before it even gets there.\nMany professionally supplied rain effects approximate a very large lawn sprinkler on a tall pole (in fact, some of them are a very large lawn sprinkler on a tall pole) and can also be improvised, although the sheer amount of hoses, connectors, and other hardware required for even medium-sized setups will quickly make rental a worthwhile option. Perhaps the biggest problem is the sheer misery: the cast will quickly be drenched, perhaps demanding multiple costume sets, and even the crew, who will generally magic arm an umbrella to the dolly, are unlikely to enjoy the situation. Electrical equipment must be kept dry and there must be somewhere for the water to go.\nThe movie that started it all - Singin' in the Rain\nMost people have seen a street after rain, and while it isn't solely a technique of exteriors the greatest difficulty is often finding a way to achieve the effect over a very large area. Street-sized areas are so familiar that they're easy to underestimate and if there's a trick to be had, it's to at least ask the local water authorities. In some parts of the world, you can rent standpipes to tap into firefighting water services at an affordable price. Often the standpipe will include a meter and sometimes — unless a production uses really huge amounts — it's often seen as not worth charging for. Surprisingly large amounts of water can be required, especially if you're in a place where it evaporates quickly.\nWater on a street does several things: it highlights texture, creates reflections and in a practical sense often increases contrast. The latter is really a characteristic of the first, inasmuch as a wet-down is most typically used at night. At that time, things can be set up so the water reflects either a black night sky or produces specular reflections of lighting, which tends to create contrast. It can be necessary to set up lighting specifically to be reflected. If reflected objects are in focus, that lighting may be seen in some detail. Now we've described one of those '80s movies shot on Panavision C and E-series lenses with the horizontal blue flares and the neon signs reflected in the puddles, blurring the boundaries between production design and cinematography.\nIt looks great, but try not to slip over, and don't spray water on the public motorway.\nThis frame from the 1989 Batman was shot in the same disused power station that Cameron used in Aliens. Steam features behind this railing kill.\nThere's some crossover between water effects and smoke, but we'll put steam here because it is a water effect. Many of the effects are smoke-like, although of course, steam moves.\nThe density and persistence of steam varies wildly with ambient temperature and humidity. On a chilly London evening, with the mercury hovering around freezing, a single quite modest wallpaper stripper can create a column of dense white vapour twenty feet high. An equivalent device deployed in the steamy heat of a Los Angeles summer evening will barely register. As with any vapour or particulate, its visibility can be enhanced with backlighting, and a backlight can also create aerial effects within the cloud itself.\nSaving Private Ryan. World War 2 looks harsher in the rain\nEven full-time visual effects people tend to use wallpaper strippers to create steam. They're very cheap and very available, and they can remove skin like a peeled-off strip of not-very-sticky tape, so there's plenty of reason to be cautious. Filling them up with already hot water reduces the time taken after a refill before they start producing steam again. This does imply more power consumption and big electric heaters full of boiling water to be carried around the location, creating yet more safety issues to assess and control.\nPresumably, the snow in this scene from Max Payne is fake, but the steam billows suggest it was cold anyway. Shot in Toronto\nHaving done that, it's an effective trick and with the big, flat wallpaper-removing plate removed, the steam issues from a convenient hose. They're quite power-hungry, usually 3kW in places with mains at or over 220V, so it isn't a cheap effect unless we have access to wall socket power. Don't plug more than one into a single circuit unless you're very sure what you're doing. More directional, high-pressure jets of steam can be created with smoke machines, which will generally tolerate being loaded with deionised water. It's usually OK to dilute smoke fluid with deionised water, so a hybrid smoke-steam effect with some degree of persistence can be created.\nEven if we're not pretending to be in New York, the dramatic application of smoke and steam effects is familiar almost to the point of cliché. Bad guys looming through the mist, driving through steam clouds to enhance a feeling of speed, or the imminent failure of the faster-than-light drive are... well, they're tropes for a reason. Beyond that, steam can do many of the same tricks with parallax and dimensionality as smoke. Speaking of which, smoke comes next.""]"	['<urn:uuid:1be9094b-dd03-49d8-8e01-841be96ef378>']	factoid	direct	concise-and-natural	similar-to-document	single-doc	novice	2025-05-13T04:02:16.770989	8	13	979
49	side effects chemotherapy vs radiation therapy lung cancer most common	Common side effects differ between these treatments. Chemotherapy's most common side effects include nausea, vomiting, infections from low white blood cell counts, easy bruising, tiredness, and skin problems. For radiation therapy to the lungs, the most common side effects include difficulty breathing, nausea, vomiting, sore throat, difficulty swallowing, loss of appetite, and hoarseness.	"[""Thyroid Cancer: Chemotherapy\nWhat is chemotherapy?\nChemotherapy uses special medicines to kill cancer cells. The medicines attack and kill cells that grow quickly, like cancer cells. Some normal cells also grow quickly. Because of this, chemotherapy can also harm those cells. This can cause side effects.\nChemotherapy is a systemic treatment. This means the medicines travel through the body in the bloodstream.\nWhen might chemotherapy be used for thyroid cancer?\nChemotherapy is not a common treatment for thyroid cancer.\nIt is sometimes given if you are getting radiation therapy. It may help the radiation work better when treating anaplastic thyroid cancer.\nIt may also be used for advanced thyroid cancer that doesn't respond to other treatments.\nHow is chemotherapy given for thyroid cancer?\nYou get chemotherapy in cycles over a period of time. That means you may take the medicine for a set amount of time and then you have a rest period. Each period of treatment and rest is one cycle. You may get several cycles.\nMost people have chemotherapy in an outpatient part of the hospital, at the healthcare provider's office, or at home. In some cases, you may stay in the hospital during treatment.\nThe chemotherapy medicines used to treat thyroid cancer are usually given into the bloodstream through a small, thin flexible tube called an IV or intravenous catheter. Currently, the medicine that works best, doxorubicin, is still much less effective than surgery and radioactive iodine therapy(RAI).\nWhat are common side effects of chemotherapy?\nChemotherapy attacks cells that are dividing quickly. This includes normal cells as well as cancer cells. Normal, quickly dividing cells can be found in the bone marrow, the hair follicles, and lining of the intestines and mouth. Damage to these normal cells is a common cause for side effects. Side effects will depend on the type and amount of medicine being taken.\nSome of the more common short-term side effects from chemotherapy include:\nNausea and vomiting\nConstipation or diarrhea\nInfections from low white blood cell counts\nEasy bruising or bleeding from low blood platelets\nTiredness from low red blood cell counts\nSkin problems, such as dryness, rash, blistering, or darkening skin\nTingling, numbness, or swelling in hands or feet\nMost side effects will go away or get better between treatments and over time after treatment ends. You may also be able to help control some of these side effects. Tell your healthcare providers about any side effects you have. They can help you cope with them.\nA more serious possible side effect of some chemotherapy medicines is organ damage. This can include damage to the kidneys, liver, testicles, ovaries, brain, heart, or lungs. You may have blood tests or other tests done while you’re getting chemotherapy. This is to make sure your organs are working properly and you aren’t having harmful reactions to the medicine.\nWorking with your healthcare provider\nIt's important to know which medicines you're getting. Write down your medicines, and ask your healthcare team how they work and what side effects they might have.\nTalk with your healthcare providers about what signs to watch out for an when you should call your healthcare team. For example, chemotherapy can make you more likely to get infections. Make sure you know what number to call with questions. Is there a different number for evenings and weekends?\nIt may be helpful to keep a diary of your side effects. Write down any physical, thinking, and emotional changes. A written list will make it easier for you to remember your questions when you go to your appointments. It will also make it easier for you to work with your healthcare team to make a plan to manage your side effects."", 'Resources for coping with cancer during the COVID-19 pandemic.\nRadiation therapy for lung cancer\nRadiation therapy uses high-energy rays or particles to destroy cancer cells. Most people with lung cancer have radiation therapy. Your healthcare team will consider your personal needs to plan the type and amount of radiation, and when and how it is given. You may also receive other treatments.\nRadiation therapy is often combined with chemotherapy to treat lung cancer. This is called chemoradiation. The 2 treatments are given during the same time period. You will not be offered chemoradiation if you aren’t healthy enough to have this type of treatment.\nRadiation therapy is given for different reasons. You may have radiation therapy or chemoradiation:\n- as the main treatment for lung cancer that can’t be removed with surgery, or if you don’t want to have surgery\n- after surgery to lower the risk of the cancer coming back (recurring) (called adjuvant therapy)\n- to relieve pain or control the symptoms of advanced lung cancer (called palliative therapy)\n- to treat lung cancer that has spread to the brain (brain metastases)\n- to prevent small cell lung cancer from spreading in the brain\nThe following types of radiation therapy are most commonly used to treat lung cancer.\nExternal radiation therapy\nDuring external radiation therapy, a machine directs radiation through the skin to the tumour and some of the tissue around it.\nBefore radiation therapy is started, your treatment is planned carefully. The radiation healthcare team measures how your lungs move when you breathe and maps the shape of your internal organs. This helps the radiation team to plan the best way of giving you external radiation therapy. The goal is to aim the radiation at the tumour while lowering the amount of radiation to surrounding tissue.\nExternal radiation therapy is usually given 5 days a week, for 5 to 7 weeks. If it is being used as a palliative therapy, it may not be given for as long.\nThere are several different ways to give external radiation therapy for lung cancer.\n3D conformal radiation therapy (3D-CRT)\nThe most common form of external radiation therapy is 3D-CRT. Radiation beams that are all the same strength are aimed from several different directions at the tumour. A CT scan is used to guide the radiation beams to the tumour.\nIntensity-modulated radiation therapy (IMRT)\nIMRT is a much more targeted way of giving radiation therapy than 3D-CRT. The radiation beams are given in small beams that are shaped by a machine called a multi-leaf collimator. The strength of the beams is different across the treatment area so that the tumour gets the most radiation and nearby tissue gets less. IMRT is often used if the treatment area includes important areas of the body such as the spinal cord.\nStereotactic body radiotherapy (SBRT)\nSBRT is a way of giving radiation therapy from several different positions around the body. Using a CT scan for guidance, radiation beams are directed to all meet at a point in the tumour. This is a very accurate way of giving radiation because the tumour gets a high dose of radiation while the surrounding tissue gets lower doses. SBRT is sometimes called stereotactic ablative radiotherapy (SABR).\nSBRT for lung cancer is given over 7 to 10 days, which is much shorter than other ways of giving radiation therapy.\nYou may be offered SBRT if you have lung cancer that hasn’t spread outside of the lung or if you can’t have or don’t want to have surgery.\nHypofractionated radiation therapy\nWith hypofractionated radiation therapy, fewer radiation treatments are given. This is done by giving either a short course of daily treatments or by giving fewer large doses (sometimes just a single treatment).\nYou may be offered hypofractionated radiation therapy if you are not able to have the high doses of radiation given during SBRT.\nProphylactic cranial irradiation (PCI)\nProphylactic cranial irradiation (PCI) is external beam radiation given to the whole brain. It is used to prevent small cell lung cancer from spreading to the brain or to treat cancer cells that may have already spread there but cannot be seen by imaging tests. It may help prevent brain metastases and improve survival.\nPCI is offered to people with limited and extensive stage small cell lung cancer that has responded well to chemotherapy and radiation therapy. It is not offered to people with small cell lung cancer that has not responded to chemotherapy.\nPCI is not used to treat non-small cell lung cancer because research has shown it does not improve survival or quality of life.\nBrachytherapy is a type of internal radiation therapy that places radioactive material in the body. This is done during a bronchoscopy using a small tube called a catheter that goes through the bronchoscope. At the end of the treatment, which usually takes less than 30 minutes, the radioactive material is removed from the lung through the catheter. No radioactive material is left inside the body. As the radiation effect kills the cancer cells over 2 to 4 weeks, the tumour shrinks.\nBrachytherapy may be used to treat a tumour that is blocking an airway of the lung. It may also be used as a primary treatment if you cannot have external radiation therapy because of poor lung function.\nThis can also be called endobronchial brachytherapy or endobronchial radiation therapy.\nSide effects can happen with any type of treatment for lung cancer, but everyone’s experience is different. Some people have many side effects. Other people have only a few side effects.\nDuring radiation therapy, the healthcare team protects healthy cells in the treatment area as much as possible. But damage to healthy cells can happen and may cause side effects. If you develop side effects, they can happen any time during, immediately after or a few days or weeks after radiation therapy. Sometimes late side effects develop months or years after radiation therapy. Most side effects go away on their own or can be treated, but some side effects may last a long time or become permanent.\nSide effects of radiation therapy will depend mainly on the size of the area being treated, the specific area or organs being treated, the total dose of radiation, the treatment schedule and if radiation therapy is being given with chemotherapy. Some common side effects of radiation therapy used for lung cancer are:\n- difficulty breathing, including a cough and shortness of breath\n- nausea and vomiting\n- sore throat\n- difficulty swallowing\n- loss of appetite\n- radiation pneumonitis\n- hoarseness, changes to your voice\n- skin problems\n- heart problems (if the treatment area is near the heart)\n- lung problems\n- bleeding from the tumour\nSome side effects of prophylactic brain irradiation are:\n- somnolence syndrome\n- increased intracranial pressure\n- cognitive problems, such as problems with memory or speech\nTell your healthcare team if you have these side effects or others you think might be from radiation therapy. The sooner you tell them of any problems, the sooner they can suggest ways to help you deal with them.\nQuestions to ask about radiation therapy\nA group of symptoms that include drowsiness, lethargy (abnormal drowsiness or lack of energy), loss of appetite and irritability.\nSomnolence syndrome can occur in children following radiation therapy to the head.']"	['<urn:uuid:5767eecf-79a9-4b2b-8341-a95d13dcaa15>', '<urn:uuid:7a0195b4-1001-4fcc-82c2-d664f51a798f>']	factoid	direct	long-search-query	similar-to-document	comparison	novice	2025-05-13T04:02:16.770989	10	53	1837
50	did mel ott and dave concepcion receive baseball awards for same number consecutive years all star games	No, they received All-Star honors for different numbers of consecutive years. Mel Ott was an All-Star for eleven consecutive seasons, while Dave Concepcion made eight All-Star teams over his career, with his last selection coming in 1982.	"['It’s called the fall classic, and the 1975 World Series was indeed a “classic.” The Series waged between the Cincinnati Reds and the Boston Red Sox was one of the more memorable championship battles, as a single run decided five of the seven games. Cincinnati shortstop Dave Concepcion entered the Series hoping that the old saying “third time is a charm” would prove true. He had been to two other World Series, losing out both times: first to Baltimore in 1970 and then to Oakland in 1972.\nIn 1975 Boston won Game One at Fenway Park, shutting out the Reds by a 6-0 score, and the Reds were looking to balance the ledger before the Series headed to the Queen City. It was a rainy day in Boston on October 12 for Game Two. But the inclement weather did not hinder Boston starter Bill Lee. He held the Reds to one run, and was clinging to a 2-1 lead entering the ninth inning. But after Johnny Bench’s leadoff double chased Lee from the game, Dick Drago and his blazing fastball moved to the hill.\nAfter Drago retired Tony Perez on a groundout to shortstop with Bench taking third and George Foster flied to short left field, Concepcion came to bat with two outs and the tying run 90 feet away. Concepcion hit a 1 and 1 fastball into the dirt and the ball bounced high toward second base. Boston’s Denny Doyle raced to his right and backhanded the ball, but it was too late for the second baseman to make a play. Bench scored the tying run, and Concepcion was on first. Red Sox fans in the Fenway Park crowd fell silent. Concepcion stole second base, sliding past the bag but getting back safely. Ken Griffey then doubled him home, and the Reds won 3-2 to even the Series. “I was just looking to make contact,” Concepcion said later. “That’s all you can do in a situation like that against a fastball pitcher like Drago. I knew it was a hit once I got it past the pitcher.”1\nDavid Ismael (Benitez) Concepcion was born on June 17, 1948, Ocumare de la Costa, Aragua, Venezuela. His father, a truck driver, was against young Dave’s pursuing a career in baseball, instead hoping that he would make a living as perhaps a lawyer, banker, or doctor. After attending Agustin Codazzi High School, Dave worked as a bank teller and played for a local amateur baseball team. His coach, Wilfredo Calvino, was a scout for the Reds, and despite his father’s wishes, young Concepcion signed a contract with Calvino in September 1967 and joined Tampa in the Class A Florida State League in 1968.\nConcepcion’s time in the Reds’ minor-league chain was brief; by the end of the 1969 season he was playing for Triple-A Indianapolis. The 21-year-old hit .341 for the Indians in 167 at-bats, and showed a high aptitude on the basepaths. “Concepcion has the best baserunning instincts I’ve ever seen in a youngster,” said Indians manager Vern Rapp. “He stole 11 bases in 12 attempts and he was only with us about a month.”2\nConcepcion was promoted to the Reds for the 1970 season, but he faced veteran competition at shortstop in Woody Woodward and Darrel Chaney. When Concepcion showed up at camp, standing 6-feet-2 and weighing just 155 pounds, Pete Rose joked that he wouldn’t be in danger of pulling a muscle in his legs, that instead it would have to be a pulled bone. But Rose also acknowledged, “They tell me that the kid can play shortstop with a pair of pliers.”3\nReds rookie manager Sparky Anderson took a liking to the youngster, as did hitting instructor Ted Kluszewski. Anderson made Concepcion the starter, mostly for his defensive ability. Anderson didn’t expect much offense from his young shortstop. But when Concepcion’s batting average rose to .270 in May, Kluszewski commented, “I’ve been saying all along that the kid’s gonna be a pretty good hitter.”4\nConcepcion’s unexpectedly good hitting could not keep him in the starting lineup. He made 14 errors through mid-June, and Anderson replaced him with the dependable Woodward. Woodward was a valuable commodity for the Reds, able to play every infield position and play them well. He solidified the position for a while, but by the time the second half of the season began, Concepcion was back in the lineup. He made only eight more errors and batted a respectable .260 for the season. The Reds steamrolled through the National League West Division and had little trouble sweeping Pittsburgh in the NLCS, holding the Pirates to three runs in the three games. They were not as fortunate in the World Series, losing in five games to the Baltimore Orioles.\nConcepcion missed most of the 1971 exhibition season with a badly sprained right thumb, and when he returned to the team in late April, he was used as a utilityman, playing second base, third base, and the outfield. He got his shortstop job back in early May, but struggled at the plate that season and in 1972 with .205 and .209 batting averages. His career got an indirect boost after the 1971 season when a big trade brought second baseman Joe Morgan from the Astros. Concepcion and Morgan established themselves as one of the better keystone combinations in major-league history. As teammates with the Reds, they appeared in four All-Star Games, starting three, and won two World Series.\nConcepcion was his own worst critic, and at times his being hard on himself caused subpar play to further spiral downward. Sparky Anderson decided that he needed a big-brother influence, and asked veteran Tony Perez to room with the youngster and mentor him. “He cannot stand 0-4 day. It kill him. I tell him very simple thing. ‘Don’t get your head down.’… ‘If you don’t hit now, you will next time.’… Things like this. Always I try to pick him up.”5 Perez also felt that marriage helped Concepcion settle down. (Dave and his bride, Delia, were married in 1972. They had three children, David Alejandro, David Eduardo, and Daneska.)\nWhatever the reason, Concepcion emerged as a top-flight player in 1973. He was named to the All-Star team for the first time. He batted.287 and provided some punch at the bottom of the Reds’ lineup. He posted the first five-hit performance of his career against San Francisco on July 5 – hit number five, in the bottom of the ninth inning, driving in the winning run.\nUnfortunately for Concepcion and the Reds, his season was curtailed by an injury. On July 22 the Reds were breezing to a 6-0 victory over Montreal at home. Concepcion was having a fine afternoon with three hits and two runs scored. On first base in the seventh inning, he took off as Denis Menke hit a smash to Expos shortstop Larry Lintz. As Lintz threw Menke out at first base, Concepcion never stopped and raced to third base. As he slid into the base his left leg folded underneath him. The fibula, a long bone between the knee and ankle, was broken and his ankle was dislocated. His season was over. “It probably cost us the league championship,” said Rose.6 The Reds won the NL West, but lost to the New York Mets in the NLCS without their All-Star shortstop.\nConcepcion rehabbed while playing winter ball in Venezuela. He came back healthy and began a string of four years (1974-77) in which he won a Gold Glove. In 1974 he had his first big offensive season, smacking 14 home runs and driving in 82 runs, while batting mostly sixth or seventh in the lineup. Concepcion brought another dimension to the Reds in addition to his offensive and defensive skills. Beginning in 1973 he stole 20 or more bases in six consecutive seasons, pilfering 41 in 1974.\nThe Reds finally reached the summit in 1975 and 1976, winning back-to-back World Series. In 1975 Concepcion hit .455 in the NLCS against the Pirates but, only .179 in the tense and gripping World Series against the Red Sox. The next year he hit .357 in the Series against the Yankees with a triple and three RBIs. On a team filled with all-stars and future Hall of Famers, Concepcion was playing at a high level at the apex of his career. Former Brooklyn Dodgers great Pee Wee Reese, a Hall of Fame shortstop himself, offered a synthesis of Concepcion as a shortstop: “Mark Belanger may be a little smoother then Concepcion. Larry Bowa is very quick. Rick Burleson is a leader type. Bill Russell has an accurate arm. But no one does everything as well as Concepcion. It’s possible that no one ever has.”7\nReds’ third base coach Alex Grammas agreed with Reese’s assessment. Grammas had worked with Concepcion since Dave was a rookie, helping him to hone his craft. “There are some mighty good shortstops in the league today,” said Grammas. “But Concepcion is a notch ahead of them all in all-around ability because his bat is stronger and his range in the field is greater.” 8 Concepcion and Grammas had such a solid relationship, that Dave’s first son, David Alejandro, takes his middle name from Grammas.\nConcepcion also famously used Riverfront Stadium’s artificial surface to his advantage. He started to develop a pain in his throwing arm, and perfected the art of throwing the ball on a bounce off the artificial turf to the first baseman. It was extremely helpful to him on groundballs hit in the hole between shortstop and third base. “I didn’t invent that throw,” Concepcion said. “I saw another fellow do it. I saw Brooks Robinson do it to Lee May here in 1970. Then when my arm hurt, I decided, ‘Why not try it?’ ”9\nAfter a couple of second-place finishes, in 1979 the Reds won the NL West to cap off the decade of the 1970s, but lost the NLCS in a three game sweep to Pittsburgh. By that time, many of the cogs in the Big Red Machine had moved on. Perez was the first to go, in a deal with Montreal. Rose left via free agency in 1978, the same year Anderson was fired. Soon Morgan and Cesar Geronimo would be gone. But Concepcion could still play. “The other people move away, and all of a sudden you notice the antique work of art in the corner,” Bench said of Concepcion.10 Concepcion posted career highs in home runs (16) and RBIs (84) in 1979. He also claimed his fifth and final Gold Glove Award.\nConcepcion remained the Reds’ regular shortstop through the 1985 season, and made the last of his eight All-Star teams in 1982. In that season’s All-Star Game, in Montreal’s Olympic Stadium, he hit a two-run homer off Boston’s Dennis Eckersley, and was named the game’s Most Valuable Player. Before he hit his second-inning homer, he spoke with All-Star teammate and fellow Venezuelan Manny Trillo of the Philadelphia Phillies, “I told Manny, ‘I got a feeling I’m going to hit one out of the ballpark.’ He kidded me, but I said, ‘I’m gonna do it.’ ”11 And he did.\nConcepcion retired after the 1988 season, having played his entire major-league career with the Reds. His successor at shortstop, Barry Larkin, began his own 19-year career in 1986, and eventually was voted into the Baseball Hall of Fame. Concepcion was inducted into the Cincinnati Reds’ Hall of Fame in 2000, and his number 13 was retired by the Reds on August 25, 2007. Said Joe Morgan, “He’s the greatest shortstop I’ve ever played with or I’ve ever seen.”12\nIn retirement, Concepcion returned to his native Venezuela, and later managed his hometown Aragua Tigers. Later, he became an executive in a trucking business.\nConcepcion continued a fine lineage of shortstops from Venezuela. He grew up idolizing Chico Carrasquel and Luis Aparicio and trying to emulate them in the field. Later, countrymen Ozzie Guillen and Omar Vizquel grew up fantasizing about playing baseball in the major leagues like their hero, Dave Concepcion. Vizquel paid homage to his boyhood icon by wearing the number 13, saying Concepcion was “the one that I liked, the one that I looked up to.”13\nLast revised: May 1, 2014\nThis biography is included in the book “The Great Eight: The 1975 Cincinnati Reds” (University of Nebraska Press, 2014), edited by Mark Armour. For more information, or to purchase the book from University of Nebraska Press, click here.\n1 George Vass, “The Game I’ll Never Forget,” Baseball Digest, December, 1987, 86.\n2 Earl Lawson, “Reds’ Phenom Bears Out Latin Raves,” The Sporting News, March 28, 1970, 11.\n3 Lawson, “Reds’ Phenom.”\n4 Earl Lawson, “McCrae-Carbo Bat Platoon Is Cincy’s Assault Force,” The Sporting News, May 23, 1970, 7.\n5 Si Burick, “The Making of Dave Concepcion,” Baseball Digest, August, 1974, 40-42.\n6 Jim Brosnan, “Dave Concepcion: Best in the Business,” Boys’ Life, September, 1975, 20-23.\n7 Dick Peebles, “Dave Concepcion: Best All-Around Shortstop in the Majors,” Baseball Digest, December 1979, 50-51.\n8 Earl Lawson, “Concepcion Almost Immaculate at Shortstop.” The Sporting News, April 26, 1975, 3.\n9 Feldman, “The 1976 Cincinnati Reds,” 41.\n10 Ivan Maisel, “An All Star Comes To Light,” Sports Illustrated, July 25, 1982, 46.\n11 Maisel, “An All-Star,” 46.\n12 Kevin Kelly, “No Shorting Concepcion on This Night,” Cincinnati Enquirer, August 26, 2007.\n13 Tim Wendel, “The New Face of Baseball,” (New York: Harper/Collins, 2003), 76.', 'March 2, 1909|\n|Died: November 21, 1958\nNew Orleans, Louisiana\n|April 27, 1926 for the New York Giants|\nLast MLB appearance\n|July 11, 1947 for the New York Giants|\n|Runs batted in||1,860|\nCareer highlights and awards\n|Vote||87.2% (third ballot)|\nMelvin Thomas Ott (March 2, 1909 – November 21, 1958), nicknamed ""Master Melvin"", was an American former professional baseball player who played in Major League Baseball (MLB) as a right fielder for the New York Giants, from 1926 through 1947.\nOtt was born in Gretna, the seat of government of Jefferson Parish in suburban New Orleans. He batted left-handed and threw right-handed. He was an All-Star for eleven consecutive seasons[a], and was the first National League player to surpass 500 career home runs. He was unusually slight of stature for a power hitter, at 5 feet 9 inches (1.75 m), 170 pounds (77 kg).\nHe was elected to the National Baseball Hall of Fame in 1951.\nA power hitter\nOtt was a six-time NL home run leader, in 1932, 1934, 1936–38, and 1942. From 1928 to 1945, he led the New York Giants in home runs. This 18-season consecutive dominance is a record; no other player has ever led his team in more consecutive years in a single Triple Crown category. He was both the youngest player to hit 100 home runs and the first National Leaguer to hit 500 home runs. He passed Rogers Hornsby to become the all-time NL home run leader in 1937 and held that title until Willie Mays passed him in 1966.\nBecause of his power hitting, he was noted for reaching base via the base on balls. He drew five walks in a game three times. He set the National League record for most walks in a doubleheader with six, on October 5, 1929 and did it again on April 30, 1944. He tied an MLB record by drawing a walk in seven consecutive plate appearances (June 16 through 18, 1943). He also led the NL in walks six times: in 1929, 1931–33, 1937 and 1942. He twice scored six runs in a game, on August 4, 1934 and on April 30, 1944. He was the youngest major leaguer to ever hit for the cycle, until Mike Trout hit for the cycle in 2013. Ott was the first NL player to post eight consecutive 100-RBI seasons, and only Willie Mays, Sammy Sosa, Chipper Jones, and Albert Pujols have since joined him.\nHe used a batting style that was then considered unorthodox, lifting his forward (right) foot prior to impact. This style helped with his power hitting. More recent players who used a similar style include Harold Baines and Kirby Puckett, as well as the Japanese home run king, Sadaharu Oh.\nIn 1943, all of his 18 home runs came at home; only two others ever had a greater number of all-homefield home runs. Of Ott\'s 511 career home runs, 323 of them, or 63 percent, came at home. (Home Run Handbook, John Tattersall, 1975). Because of this, his home run record historically has been downplayed, suggesting that a 257-foot (78 m) foul line at the Polo Grounds resulted in higher numbers at home. Sportswriters often jokingly referred to him as the master of the ""Chinese home run"" as such short homers were called at the time; Ott would often respond by noting that if it was so easy to inflate his homer totals by hitting over that fence, all other hitters in the league would be doing it.\nAs a balance, the Polo Grounds had the deepest power alleys in baseball. Also, he hit more career home runs in foreign stadiums than any other National League hitter at the time of his retirement. In some of his better seasons, he hit more homers on the road than in the Polo Grounds.\nThough there may be reason to believe that he was a better hitter than his record holds due to differences in National League and American League ball specifications (""All too forgOtten"" Steve Treder, October 2, 2007). Those differences are considered the most outstanding in the history of the game and made it considerably harder for National League hitters to achieve home runs.\nDuring the prime of Ott\'s career, eleven seasons from 1931 through 1941, American League batters averaged 21% more home runs—peaking at 41% more home runs—than their National League counterparts. Babe Ruth and Jimmie Foxx, contemporaries, and both American League players, were the only batters to surpass Ott\'s record during this time.\nHe played in the World Series in 1933, 1936 and 1937, winning in 1933.\nHe hit two home runs during the 1933 series. In game 1, he had four hits, including a two-run home run in the first inning. In game 5, he drove in the series-winning run with two outs in the top of the 10th, driving a pitch into the center-field bleachers.\nIn the 1936 World Series, Ott had 7 hits and 1 home run. In 1937, he had 4 hits and 1 home run.\nOtt managed the Giants from 1942 until being succeeded by Leo Durocher midway through the 1948 season. The Giants\' best finish during that time was third place in 1942. It was in reference to Ott\'s supposedly easy-going managing style that then-Dodgers manager Durocher made the oft-quoted and somewhat out-of-context comment, ""Nice guys finish last!"" Ott was the first manager to be ejected from both games of a doubleheader, when the Giants lost both games to the Pittsburgh Pirates on June 9, 1946.\nIn 1951, Ott succeeded Chuck Dressen as manager of the Oakland Oaks of the Pacific Coast League, leading the club to a 80-88 finish (seventh place). In 1952, the Oaks finished 104-76 under Ott, good for second place in the PCL.\n|Mel Ott\'s number 4 was retired by the New York Giants in 1949.|\nOtt was elected to the Baseball Hall of Fame in 1951 with 87% of the vote. His number ""4"" was also retired by the Giants in 1949, and it is posted on the facade of the upper deck in the left field corner of AT&T Park.\nAfter his playing career ended, Ott broadcast baseball on the Mutual radio network in 1955. From 1956 to 1958, Ott teamed with Van Patrick to broadcast the games of the Detroit Tigers on radio and television.\nDeath and legacy\nOtt was involved in an auto accident in Bay Saint Louis, Mississippi in 1958. He was transferred to a hospital in New Orleans; where he died one week later. He was interred in Metairie Cemetery. Ott died in a similar manner to two other N.Y. Giants Hall of Famers: Frankie Frisch in 1973 and Carl Hubbell in 1988 (the latter 30 years to the day of Ott\'s death). Ott is remembered in his hometown of Gretna, where a park is named in his honor. Since 1959, the National League has honored the league\'s annual home run champion with the Mel Ott Award. In the 1989 film Field of Dreams, Ott was one of several deceased players portrayed in farmer Ray Kinsella\'s Iowa cornfield. In 2006, Ott was featured on a U.S. postage stamp, as one of a block of four honoring ""Baseball Sluggers"" — the others being Mickey Mantle, Hank Greenberg, and Roy Campanella. In announcing the stamps, the U.S. Postal Service stated, ""Remembered as powerful hitters who wowed fans with awesome and often record-breaking home runs, these four men were also versatile players who helped to lead their teams to victory and set impressive standards for subsequent generations"". Ott is also remembered in the name of the Little League of Amherst, New York. The Mel Ott Little League began in 1959, named for the recently deceased superstar.\nBaseball records and accomplishments\n- 6-time NL home run leader (1932, 1934, 1936–38, 1942)\n- Was the youngest player to hit 100 home runs and the first NL player to reach 500 home runs\n- Passed Rogers Hornsby to become the all-time NL home run leader in 1937 and held that title until Willie Mays passed him in 1966.\n- Holds major league record by leading his team 18 consecutive years in home runs (1928–1945)\n- Drew five walks in a game three times, and six walks in a doubleheader twice\n- Shares MLB record by drawing a walk in seven consecutive plate appearances (June 16 through 18, 1943)\n- Led NL in walks six times (1929, 1931–33, 1937, 1942)\n- Twice scored six runs in a game (August 4, 1934 and April 30, 1944)\n- Hit for the cycle (May 16, 1929)\n- First NL player to post eight consecutive 100-RBI seasons (only Willie Mays, Sammy Sosa, Chipper Jones, and Albert Pujols have joined him)\n- Twice led NL outfielders in double plays (1929 and 1935)\n- 11-time All-Star (1934–44) and four time The Sporting News All-Star (1934–36, 1938)\n- In 1999, he ranked number 42 on The Sporting News\' list of the 100 Greatest Baseball Players and was a nominee for the MLB All-Century Team.\n- One of six NL players to play more than 20 years with one team (Cap Anson, Stan Musial, Willie Stargell, Craig Biggio, and Tony Gwynn are the others)\n- He managed the New York Giants in seven seasons (1942–48).\n- List of baseball players who went directly to the major leagues\n- List of Major League Baseball Home Run Records\n- 500 home run club\n- List of MLB individual streaks\n- List of top 300 Major League Baseball home run hitters\n- List of major league players with 2,000 hits\n- List of Major League Baseball players with 400 doubles\n- List of Major League Baseball players with 1000 runs\n- List of Major League Baseball players with 1000 RBI\n- Hitting for the cycle\n- List of Major League Baseball RBI champions\n- List of Major League Baseball home run champions\n- List of Major League Baseball runs scored champions\n- List of Major League Baseball player–managers\n- List of Major League Baseball players who spent their entire career with one franchise\n- Major League Baseball titles leaders\n- MLB cancelled the 1945 All-Star Game and did not name All-Stars that season.\n- Hardy Jr., James D. (2007). Baseball and the Mythic Moment: How We Remember the National Game. Jefferson, NC: McFarland & Company. pp. 32–34. ISBN 9780786426508. Retrieved March 18, 2015.\n- Pellowski, Michael J (2007). The Little Giant Book of Baseball Facts. United States: Sterling Publishing Co. p. 352. ISBN 9781402742736.\n- Baseball Did You Know? - VII, 1945 All Star Game Replacements  Retrieved July 28, 2015\n- ""Baseball Quick Quiz"". Baseball Digest 31 (12): 77. December 1972. Retrieved December 16, 2011.\n- MacMullan, Jackie (October 17, 2002). ""A bronze homage to Babe"". The Boston Globe. p. E3. Retrieved November 8, 2011.\nThe National League honors its sluggers with (here\'s a trivia question for your next cocktail party) the Mel Ott Award, with about the same amount of fanfare as the AL.(subscription required)\n- ""Baseball Sluggers"". The 2006 Commemorative Stamp Program. USPS. 2005-11-30. Retrieved 2008-01-23.\n- ""Baseball Almanac"". Retrieved 2008-01-23.\n- Career statistics and player information from Baseball-Reference, or Fangraphs, or The Baseball Cube\n- Mel Ott managerial career statistics at Baseball-Reference.com\n- Mel Ott at the Baseball Hall of Fame\n- 1933 World Series\n- Mel Ott at Find a Grave']"	['<urn:uuid:e4022f59-65a0-4ee0-8518-606d0c7fe441>', '<urn:uuid:2210be21-6ff3-4578-a084-70e190e14838>']	factoid	direct	long-search-query	distant-from-document	comparison	novice	2025-05-13T04:02:16.770989	17	37	4133
51	wondering purpose post mortem meetings in business what exactly are they used for	Post mortem meetings in business are structured reviews conducted after a project's completion. The term 'post mortem,' meaning 'after death' in Latin, is used metaphorically to signify analysis after a project's end. These meetings serve as an opportunity for project team members to discuss successes and failures, and identify how future projects can be improved. They are crucial for continuous improvement, allowing teams to learn from experiences and apply these lessons to future endeavors.	"['Can\'t remember much about previous work projects? Wish you could analyze the wins and fails for future projects, or articulate the lessons from them in your work portfolio?\nThat\'s why project post mortem meetings exist. They\'re structured reviews conducted after the completion of a project. They\'re an opportunity for project team members to discuss what went well, what didn’t, and how future projects can be improved.\nThe term \'post mortem,\' Latin for \'after death,\' is used metaphorically in business to signify analysis after a project\'s end. These meetings are crucial for continuous improvement, allowing teams to learn from experiences and apply these lessons to future endeavors.\nIn this blog, we’ll delve into a step-by-step guide to conducting effective post mortem meetings:\n- Step 1: Understand the Purpose and Set Objectives\n- Step 2: Schedule the Meeting and Invite Participants\n- Step 3: Assign a Note-Taker\n- Step 4: Create an Agenda (Copyable Template Here)\n- Step 5: Assign a Moderator\n- Step 6: Conduct the Meeting with Best Practices\n- Step 7: Develop Actionable Insights and Follow-Up Plans\nStep 1: Understand the Purpose and Set Objectives\nBeing clear about the point and objectives of the post mortem meeting ensures the discussion is focused and goal-oriented. This clarity guides the team to extract meaningful insights and make concrete plans for improvement, directly impacting the success of future projects.\nDefine the Scope:\nClarify what aspects of the project will be discussed. This could range from project performance, team communication, to specific incidents.\nIdentify Learning Goals:\nDetermine what the team should gain from this meeting. It might be lessons learned, process improvements, or ideas to mitigate future risks.\nFocus on Improvement:\nThe aim is to foster a culture of continuous improvement. The meeting should not be about finger-pointing but about understanding how the entire project unfolded.\nStep 2: Schedule the Meeting and Invite Participants\nTiming and participant selection are key factors in organizing an effective post mortem meeting. Here\'s how to approach this step.\nChoose the Right Time:\nSchedule the meeting soon after project completion, ideally within one to two weeks. This ensures that details are still fresh in everyone’s mind. Post mortem meetings typically last between one to two hours, depending on the project\'s complexity and the points of discussion.\nWhen selecting a meeting time, be mindful of everyone\'s schedules and time zones. The goal is to find a time slot that accommodates all participants, encouraging full attendance and engagement.\nInclusive Participant List:\nInvolve all relevant stakeholders. This includes the project team members, project managers, and possibly other key personnel who contributed to or were affected by the project.\nHelp People Prepare:\nWhen sending out invitations, clearly state the meeting\'s purpose. This helps participants prepare appropriately and sets the right tone for the meeting.\nAsk team members to come prepared with their insights and points for discussion. This could be in the form of a post mortem questionnaire or simply reflective notes on their experience with the project.\nStep 3: Assign a Note-Taker\nDocumentation is a crucial aspect of a post mortem meeting. It ensures that the insights and decisions made during the meeting are recorded for future reference and action. Here\'s how to effectively assign and utilize a note-taker.\nOutsource Notetaking to AI:\nWhy split a team member\'s valuable time between notetaking and participating in the discussion? Utilizing AI to record the conversation allows everyone to fully engage in important discussions without distraction.\nThat\'s what Wudpecker is here to do. It records the discussion and generates post mortem meeting notes that the participants can utilize after the meeting (they\'ll be available max 10 min after the meeting has ended).\nWudpecker is compatible with Google Meet, Zoom, and Microsoft Teams. It generates an accurate and objective transcript, meeting summary and action items. The notes are easily shareable to other people.\nLet\'s see how easy it is to set up Wudpecker\'s meeting recording software:\n1. Sign in to Wudpecker by clicking ""Get started""\n2. Continue either by connecting a Google or Microsoft account to Wudpecker.\nAfter this, accept the permission for Wudpecker to access your calendar (this is for the purpose of automatically joining calls for a more seamless experience).\n3. Make sure the online meeting you want notes for shows up in ""Upcoming calls"" and that there\'s an activated toggle button next to it.\nYou can choose which meetings Wudpecker will try to join with a press of a toggle button. If it can\'t detect a meeting link in an event, no toggle button shows up.\nIf this is not the case...\n- Make sure you signed up with the correct account. The items on the menu are all the events in your calendar connected to the account you signed up with.\n- Check that the online meeting event you have in your calendar has a meeting link. (Psst: The meeting link needs to be in the ""location"" of the event)\n- Try clicking on the toggle button to activate it (it should be activated/colored automatically).\n- If none of this helps, you can always contact us by pressing the chat button on the right bottom corner.\nEasy peasy! For any future meetings, just admit the notetaker in each time, and you\'ll be all set!\n4. Once you\'re in the meeting, allow Wudpecker\'s Notetaker to join by clicking ""Admit"".\nThe Notetaker looks like any of the other meeting participants.\n+ Soon after the online meeting has ended, you\'ll see notes and a transcript for your meeting in ""My Calls"".\nPost-meeting, the notes should be shared with all participants and relevant stakeholders. This promotes transparency and keeps everyone on the same page regarding the outcomes of the meeting.\nOn Wudpecker, just go to the notes of your previous post mortem meeting, press ""Share"", and anyone with the copied link can access the notes, audio recording and transcript from the meeting.\nStep 4: Create an Agenda (Copyable Template Here)\nA well-structured agenda is pivotal for an effective post mortem meeting. It guides the discussion and ensures that all critical aspects of the project are covered.\nStart with Goals:\nBegin by clearly outlining the meeting\'s main purpose at the top of the agenda. This sets the overarching goal for the meeting. Then, under this, list more specific objectives as individual items or key topics on the agenda.\nThese objectives represent the key areas of focus and discussion points for the meeting. This format helps conceptualize the structure and ensures that each segment of the meeting contributes towards the overall purpose.\nAllocate Time Slots:\nAssign a specific time to each topic on the agenda. This approach helps in managing the meeting duration effectively and ensures that all important points are discussed within the allocated timeframe.\nTime management is crucial in keeping the meeting concise and on track, allowing for a thorough discussion of each point without the meeting becoming overly lengthy or unfocused.\nInclude a Roundtable Segment:\nAllow time for an open discussion where team members can bring up points not covered elsewhere in the agenda. This segment encourages open communication and ensures that all voices are heard.\nIt provides flexibility within the structured format, allowing team members to express concerns, ideas, or feedback that might not fit neatly into the predefined topics but are essential for a comprehensive post-mortem analysis.\nSet Aside Time for Action Items:\nDedicate a portion of the meeting to discuss next steps and assign responsibilities for follow-up actions. These action items are crucial for transforming insights and discussions into concrete steps for future improvement.\nExample: If the meeting identifies a need for better project tracking tools, an action item could be to research and propose suitable software options. Assign this task to a specific team member, with a deadline for presenting their findings.\nFeel free to use our agenda template below!\nStep 5: Assign a Moderator\nThe role of a moderator is crucial in steering a post mortem meeting towards productive and constructive outcomes. Here\'s how to approach this step.\nBy assigning a competent moderator, you ensure that the post mortem meeting is efficiently managed, focused on objectives, and beneficial for all participants.\nThe moderator\'s role is pivotal in harnessing the collective insights of the team and translating them into actionable steps for future project success.\nSelecting the Right Moderator:\nChoose someone with good facilitation skills, ideally someone who can remain impartial and objective. This could be a project manager, an experienced team member, or an external facilitator.\nDefine the Moderator\'s Responsibilities:\nThe moderator should guide the discussion, ensure that all agenda items are covered, and that every team member has a chance to speak. They also need to manage time effectively and prevent the discussion from veering off-topic.\nFacilitate Open and Honest Communication:\nThe moderator plays a key role in creating a safe environment for team members to share honest feedback. They should encourage participation from all attendees and manage conflicts or heated discussions diplomatically.\nSummarize Key Points:\nAt the end of the meeting, the moderator should help summarize the main findings, lessons learned, and action items agreed upon. This reinforces the meeting\'s outcomes and sets the stage for follow-up actions.\nStep 6: Conduct the Meeting with Best Practices\nConducting the post mortem review effectively is vital to extract maximum value from this exercise. Here are the best practices to ensure a successful and productive meeting.\nStart and End on a Positive Note:\nBegin the meeting on a positive note by acknowledging the team\'s efforts and successes. This sets a constructive tone for the meeting.\nConclude the meeting by reiterating the team\'s achievements and the value of the insights gained. This helps maintain team morale and motivation.\nEncourage Open and Empathetic Dialogue:\nFoster an environment where team members feel comfortable sharing their thoughts. The moderator should encourage quieter members to contribute while ensuring more vocal participants don\'t dominate the conversation.\nFocus on processes and outcomes rather than personal criticisms. The goal is to learn from mistakes, not to assign blame.\nAddress Key Topics Thoroughly:\nEnsure that each agenda item, such as project performance, team dynamics, and specific incidents, is discussed in-depth. Encourage team members to share their perspectives and experiences.\nEstablish Follow-Up Plans:\nTransforming the discussion into actionable insights ensures that the meeting results in tangible improvements and that the lessons learned are effectively applied.\nAs previously mentioned, allocating time in the agenda for creating follow-up plans and deadlines is beneficial. With Wudpecker\'s notetaking tool, it\'s also easy to document what was agreed upon in an objective way.\nThese notes should be shared to all the stakeholders for better accountability and transparency.\nTo really make sure people will follow up with their promises, set a timeline for when the team will review the progress of these action items. This could take place in a follow-up meeting or as part of regular team meetings.\nA project post mortem meeting is vital for learning from past mistakes and setting the stage for future success. By following the steps outlined in this guide, you can elevate these meetings from routine discussions to catalysts for continuous improvement.\nLet\'s make all projects and their post mortems count!\nWhat does post-mortem mean in business?\nIn a business context, a post-mortem refers to a meeting or process conducted after the completion of a project or significant event. The term, borrowed from medical terminology meaning \'after death,\' is used metaphorically in business to analyze a project after its conclusion. The goal is to understand what went well, what didn\'t, and how similar projects can be improved in the future.\nWhat is the primary purpose of a postmortem meeting?\nThe primary purpose of a postmortem meeting is to reflect on and analyze a completed project. It aims to identify successes, challenges, and areas for improvement. The ultimate goal is to gather insights and lessons that can be applied to future projects, enhancing efficiency, effectiveness, and overall project performance.\nWhat is the post-mortem process?\nThe post-mortem process involves several key steps: defining the meeting\'s purpose and objectives, scheduling the meeting and inviting relevant participants, assigning roles such as a note-taker and moderator, following a structured agenda, conducting the meeting with open and honest communication, and finally, developing actionable insights and follow-up plans based on the discussion.\nWhat questions are asked at a post-mortem meeting?\nQuestions typically asked at a post-mortem meeting include:\n- What were the major successes of the project?\n- What challenges did the team face, and how were they addressed?\n- What were the key lessons learned? How can these insights be applied to future projects?\n- What specific improvements can be made in our project management process?\nDate: [Insert Date]\nTime: [Insert Time]\nLocation: [Insert Location or Virtual Meeting Link]\n- [Clearly state the purpose of the meeting]\n- [Insert any specific reports or updates members should review before the meeting]\n1. Project Recap (10 mins):\n- Brief overview of the project, highlighting key milestones and overall performance.\n2. Key Wins (15 mins):\n- Discussion on what worked well, including successful strategies and effective team communication.\n3. Challenges Faced (15 mins):\n- Identifying and discussing major hurdles and how they were addressed or could have been handled differently.\n4. Lessons Learned (15 mins):\n- Insights gained from the project, including both technical and process-oriented learnings.\n5. Areas for Improvement (15 mins):\n- Identifying processes, team dynamics, and strategies for future enhancement.\n6. Roundtable Discussion (20 mins):\n- Open floor for additional points, concerns, or feedback from team members.\n7. Action Items and Follow-Up (10 mins):\n- Assigning responsibilities for identified improvements and setting deadlines.']"	['<urn:uuid:33260c39-c777-49c8-8687-1d572b9b010d>']	open-ended	with-premise	long-search-query	similar-to-document	single-doc	novice	2025-05-13T04:02:16.770989	13	74	2258
52	small business investment returns timeline profit risks	Small business investments typically take 5-7 years to generate returns, if any. Most small businesses fail in the first few years, making them among the most risky investments. While some successful investments can generate significant returns, many will only generate small returns or result in total loss of capital.	['Condition legal guidelines have been relaxed to make it less difficult for modest company to increase begin-up and expansion funding from the community. Several investors see this as an chance to get in on the ground floor of an emerging organization and to strike it huge as the tiny companies expand into huge types.\nStatistically, most tiny businesses are unsuccessful in the 1st number of several years. Tiny enterprise investments are amid the most risky that investors can make. where to invest 1 million, implies variables to take into account for identifying regardless of whether you need to make a tiny organization expenditure.\nRisks and expense method\nA standard basic principle of investing in a tiny organization is: Never make small enterprise investments that you cannot afford to shed! By no means use funds that could be necessary for other functions, such as college training, retirement, loan repayment, or healthcare expenditures.\nAs an alternative, use funds that would otherwise be utilised for a buyer acquire, such as a vacation or a down payment on a boat or a new vehicle.\nPreviously mentioned all, by no means allow a commissioned securities salesperson or place of work or administrators of a business influence you that the expense is not risky. Small organization investments are usually difficult to transform to funds (illiquid), even even though the securities may technically be freely transferable. Thus, you will typically be not able to offer your securities if the company takes a turn for the worse.\nIn addition, just simply because the state has registered the supplying does not mean that the distinct investment will be successful. The state does not evaluate or endorse any investments. If any individual indicates or else, they are breaking the regulation.\nIf you prepare to make investments a massive sum of funds in a modest organization, you need to think about investing smaller amounts in several little firms. A couple of very effective investments can offset the unsuccessful kinds. Nevertheless, even when utilizing this approach, only spend income you can pay for to shed.\nExamining the investment\nThough there is no magic system for generating productive investment decision decisions, specified elements are regarded critical by skilled venture buyers. Some concerns to consider are:\n– How lengthy has the business been in enterprise? If it is a start off-up or has only a transient functioning background, are you being asked to spend more than the shares are worth?\n– Take into account whether administration is dealing unfairly with buyers by getting salaries or other positive aspects that are way too massive in look at of the firm’s stage of development, or by retaining an inordinate quantity of equity inventory of the company in contrast with the quantity buyers will acquire. For example, is the general public putting up eighty p.c of the income but only getting 10 % of the organization shares?\n– How considerably expertise does management have in the business and in a tiny company? How successful have been the administrators in preceding companies?\n– Do you know ample about the market to be able to assess the company and to make a sensible expenditure?\n– Does the firm have a practical advertising and marketing strategy and do they have the methods to industry the merchandise or services effectively?\n– How or when will you get a return on your expense?\nGenerating money on your investment decision\nThe two classic techniques of making income on an investment in a little enterprise are resale of stock in the community securities marketplaces adhering to a public offering, and acquiring income or marketable securities in a merger or other acquisition of the business.\nIf the firm is not very likely to go public or be marketed out inside a realistic time (i.e., a family members-owned or intently held corporation), it may not be a good investment decision for you in spite of its prospects for achievement since of the absence of chance to funds in on the investment decision. Management of a successful personal company may possibly acquire a very good return indefinitely by means of salaries and bonuses, but it is unlikely that there will be income adequate to shell out dividends in proportion with the danger of the investment decision.\nInvestors have to be offered with a disclosure doc – a prospectus – prior to producing a final decision to commit. You require to study this materials prior to investing.\nEven the greatest tiny enterprise enterprise choices are extremely risky. If you have a nagging sense of question, there is possibly a very good explanation for it. Very good investments are based mostly on seem enterprise standards and not feelings. If you are not totally comfy, the best technique is typically not to commit. There will be numerous other possibilities. Do not enable a securities salesperson pressure you into producing a choice.\nIt is typically a excellent notion to see management of the organization experience-to-confront to dimensions them up. Focus on encounter and document of accomplishment relatively than a easy sales presentation. If possible, get a innovative businessperson with you to support in your evaluation. Beware of any details that differs from, or is not included in the disclosure document. All important information is essential by regulation to be in the disclosure document. Quickly report any troubles to your state Workplace of the Commissioner of Securities.', 'Investing in early stage companies is inherently high risk. You might lose your entire investment. Here we explain some of the risks. Please read these risks and take them seriously.\nThere are risks that you must consider when making an investment in a startup company or early stage company on Manhattan Street Capital. Investing in startups is very risky, speculative, and investments should not be made by anyone who cannot afford to lose their entire investment.\nCarefully consider the risks associated with the type of investment, security, and business before making any investment decision.\nPrincipal risk: Investing in startups will put the entire amount of your investment at risk. There are many situations in which the company may fail completely or you may not be able to sell the stock that you own in the company. In these situations, you may lose the entire amount of your investment. For investments in startups, total loss of capital is a highly likely outcome. Investing in startups involves a high level of risk and you should not invest any funds unless you are able to bear the entire loss of the investment.\nReturns risk: The amount of return on investment, if any, is highly variable and not guaranteed. Some startups may be successful and generate significant returns, but many will not be successful and will only generate small returns, if any at all. Any returns that you may receive will be variable in amount, frequency, and timing. You should not invest any funds in which you require a regular, predictable and/or stable return.\nReturns delay: Any returns may take several years to materialize. Most startups take five to seven years to generate any investment return, if any at all. It may also take many years before you will know if a startup investment will generate any return. You should not invest any funds in which you require a return within a certain timeframe.\nLiquidity risk: It may be difficult to sell your securities. Startup investments are privately held companies and are not traded on a public stock exchange. Also, there is currently no readily available secondary market for private buyers to purchase your securities. Furthermore, there may be restrictions on the resale of the securities you purchase and your ability to transfer. You should not invest any funds in which you require the ability to withdraw, cash-out, or liquidate within a certain period of time.\nInstrument risk: You may be investing in preferred equity, common equity, or convertible notes. These securities instruments all have different inherent risks caused by their structure. You should take the time to understand the nature of the securities instrument that you are investing in.\nDilution: Startup companies may need to raise additional capital in the future. When these new investors make their investment into the company they may receive newly issued securities. These new securities will dilute the percentage ownership that you have in the business.\nMinority stake: As a smaller shareholder in the business you may have less voting rights or ability to influence the direction of the company than larger investors. In some cases, this may mean that your securities are treated less preferentially than larger security holders.\nValuation risk: Unlike publicly traded companies that are valued publicly through market-driven stock prices, the valuation of private companies, especially startups, is difficult to assess. The issuer will set the share price for your investment and you may risk overpaying for your investment. The price you pay for your investment may have a material impact on your eventual return, if any at all.\nFailure risk: Investments in startups are speculative and these companies often fail. Unlike an investment in a mature business where there is a track record of revenue and income, the success of a startup often relies on the development of a new product or service that may or may not find a market. You should be able to afford and be prepared to lose your entire investment.\nRevenue risk: The company is still in an early phase, and may be just beginning to implement its business plan. There can be no assurance that it will ever operate profitably. The likelihood of achieving profitability should be considered in light of the problems, expenses, difficulties, complications, and delays usually encountered by companies in their early stages of development. The company may not be successful in attaining the objectives necessary for it to overcome these risks and uncertainties.\nFunding risk: The company may require funds in excess of its existing cash resources to fund operating expenses, develop new products, expand its marketing capabilities, and finance general and administrative activities. Due to market conditions at the time the company needs additional funding, it is possible that the company will be unable to obtain additional funding when it needs it, or the terms of any available funding may be unfavorable. If the company is unable to obtain additional funding, it may not be able to repay debts when they are due or the new funding may excessively dilute existing investors. If the company is unable to obtain additional funding as and when needed, it could be forced to delay its development, marketing and expansion efforts and, if it continues to experience losses, potentially cease operations.\nDisclosure risks: The company is at an early stage and may only be able to provide limited information about its business plan and operations because it does not have fully developed operations or a long trading history. The company is also only obligated to provide limited information regarding its business and financial affairs to investors.\nPersonnel risks: An investment in a startup is also an investment in the management of the company. Being able to execute on the business plan is often an important factor in whether the business is viable and successful. You should be aware that a portion of your investment may fund the compensation of the company’s employees, including its management. You should carefully review any disclosure regarding the company’s use of proceeds. You should also carefully consider the experience and expertise of the management team.\nFraud risks: It is possible that certain people involved in the company may commit fraud or mislead investors. If fraud or misleading conduct occurs, then your total investment may be lost. You should carefully review any disclosures regarding the company’s management team and make your own assessment of the likelihood of any potential fraud.\nLack of professional guidance: Many successful startups partially attribute their early success to the guidance of professional investors (e.g., angel investors and venture capital firms). These investors often play an important role through their resources, contacts, and experience in assisting startup companies in executing their business plans. A startup company primarily financed by smaller investors may not have the benefit of such professional investors. You should consider the existing professional investors in the company and whether or not they or any other professional investors are participating in the current round.\nGrowth risk: For a startup to succeed, it will need to expand significantly. There can be no assurance that it will achieve this expansion. Expansion may place a significant strain on the company’s management, operational and financial resources. To manage growth, the company will be required to implement operational and financial systems, procedures and controls. It also will be required to expand its finance, administrative and operations staff. There can be no assurance that the company’s current and planned personnel, systems, procedures, and controls will be adequate to support its future operations. The company’s failure to manage growth effectively could have a material adverse effect on its business, results of operations, and financial condition.\nCompetition risk: The startup may face competition from other companies, some of which might have received more funding than the startup has. One or more of the company’s competitors could offer services similar to those offered by the company at significantly lower prices, which would cause downward pressure on the prices the company would be able to charge for its services. If the company is not able to charge the prices it anticipates charging for its services, there may be a material adverse effect on the company’s results of operations and financial condition.\nMarket demand risk: While the company believes that there will be customer demand for its products, there is no assurance that there will be broad market acceptance of the company’s offerings. There also may not be broad market acceptance of the company’s offerings if its competitors offer products which are preferred by prospective customers. In such event, there may be a material adverse effect on the company’s results of operations and financial condition, and the company may not be able to achieve its goals.\nControl risks: Because the company’s founders, directors, and executive officers may be among the company’s largest stockholders, they can exert significant control over the company’s business and affairs and have actual or potential interests that may depart from yours. The company’s founders, directors, and executive officers may own or control a significant percentage of the company. In addition to their board seats, such persons will have significant influence over corporate actions requiring stockholder approval, irrespective of how the company’s other stockholders, including you, may vote. Such persons’ ownership may also discourage a potential acquirer from making an offer to acquire the company, which in turn could reduce the company’s stock price or prevent you from realizing a premium on your investment.']	['<urn:uuid:60e86042-2fa0-45e6-b93e-a174f14ccae6>', '<urn:uuid:3289e71f-ea58-4fd9-a5b8-46a1ff7cc86a>']	factoid	with-premise	short-search-query	similar-to-document	multi-aspect	novice	2025-05-13T04:02:16.770989	7	49	2465
53	how do t cells cause autoimmune disease symptoms treatment	T cells, which mature in the thymus, can cause autoimmune diseases when they fail to recognize the body's own tissues as 'self' and attack them instead. This results in inflammation and tissue damage in various organs. The symptoms depend on which organs are attacked - for example, joint pain in rheumatoid arthritis or neurological problems in multiple sclerosis. Treatment approaches vary by disease but often focus on controlling inflammation and preventing organ damage.	"[""Konstantina Alexandropoulos, PhD\n- ASSOCIATE PROFESSOR | Medicine, Clinical Immunology\n- ASSOCIATE PROFESSOR | Medicine, Liver Diseases\nResearch Topics:Autoimmunity, Cell Adhesion, Cell Motility, Chemokines, Chemotaxis, Epithelial Cells, Immunological Tolerance, Immunology, Inflammation, Integrins, Lipid Signaling, Migration, Protein Kinases, Signal Transduction, T Cells, Tolerance, Trafficking, Transplantation\nKonstantina Alexandropoulos, Ph.D. is an Associate Professor of Medicine at the Department of Medicine/Division of Clinical Immunology at the Icahn School of Medicine at Mount Sinai and Head of the T-cell-mediated Autoimmunity and Inflammation Laboratory. Research in the laboratory focuses on understanding the mechanisms that regulate T cell tolerance and how disturbances in this process result in organ-specific autoimmunity. The laboratory has uncovered mechanisms that regulate T cell tolerance through elimination of autoreactive T cells in the thymus, as well as tolerogenic mechanisms that supress self-reactive T cells in peripheral organs. Ongoing collaborative projects are exploring how the gut microbiota regulates T cell self-reactivity and inflammation in the liver and colon. Studies in preclinical mouse models and human specimens are in progress to identify immune cell profiles that promote development of liver and colon autoimmune diseases, elucidate the mechanisms of disease pathogenesis and develop strategies to combat organ-specific autoimmune inflammation.\nMulti-Disciplinary Training AreaImmunology [IMM]\nPhD, City University of New York (CUNY)\nMassachusetts Institute of Technology\nKonstantina Alexandropoulos, PhD, is the Director of the T-cell Mediated Autoimmunity and Inflammation Laboratory. The laboratory focuses on elucidating several aspects of T cell physiology including T cell development, activation and trafficking under physiologic and disease conditions.\nOne major focus of our research is directed towards understanding the processes that cause aberrant T cell function and T cell-mediated autoimmune diseases exemplified by conditions such as rheumatoid arthritis, inflammatory bowel disease and diabetes. Under normal conditions, developing T cells in the thymus are educated not to attack the body's own tissues in a process known as T cell tolerance. T cell tolerance is exerted through two different mechanisms: a) elimination of mature, self-reactive T cells in the thymus (central tolerance); b) intrathymic generation of regulatory T cells which in peripheral tissues suppress the activity of self-reactive T cells that escape destruction in the thymus (peripheral tolerance). Establishment of both central and peripheral tolerance occurs in the thymus and is highly dependent on reciprocal interactions between developing T cells and the thymic epithelium, specifically medullary thymic epithelial cells (mTECs). Disruption of these interactions leads to aberrant elimination of autoreactive T cell clones, defective peripheral tolerance and autoimmunity, manifested as T cell-containing inflammatory infiltrates in and autoantibody production against peripheral tissues. We are currently using different mouse models with mutations that disrupt the development of mTECs to understand how disruption of thymic cross-talk between the medullary epithelium and T cells affects T cell development and autoimmunity.\nAnother area of research in the laboratory concentrates on elucidating the cellular and molecular mechanisms that regulate T cell activation and migration during the initiation and establishment of an immune response respectively. In these studies we are using knockout mice lacking expression of novel signaling proteins we previously characterized to study how these proteins regulate T cell activation, migration, and T cell-mediated immune responses under normal or inflammatory conditions. Our studies using mouse models coupled with molecular and biochemical approaches serve as a platform towards elucidating basic aspects of T cell physiology and are aimed towards identifying novel therapeutic targets to control the behavior of T cells in inflammation and autoimmunity."", 'Autoimmune Disease: When our immune system goes haywire\nWhile many people are familiar with the term autoimmune disease, many don’t have a clear understanding of what that means. Perhaps much of the mystery and confusion behind diseases such as multiple sclerosis, rheumatoid arthritis and thyroiditis lies in the fact that the biological basis and the symptoms that accompany such debilitating illnesses may not be linked to a specific infection. Rather, autoimmune disorders occur when our very own immune system—a complex system to begin with—begins to attack our body.\nGiven that many different kinds of proteins and molecules comprise our immune system, it is often a challenge to understand how and why a crossed signal or miscommunication can lead to an autoimmune disease. Yet given the complexity of a healthy and properly functioning immune system, it is not so difficult to see why autoimmune diseases are so prevalent in our population.\nThere are many different scientific hypotheses to explain the cause of autoimmunity; among these include viral infection, bacterial infection, stress and genetic susceptibility.\nInfection, whether viral or bacterial, is especially regarded as a culprit as it has been found to precede the onset of an autoimmune disease in many confirmed diagnoses.\nViruses and bacteria gain access into our bodies in the first place by devising methods to avoid detection. Normally our immune system reacts by recognizing antigens (foreign substances that reside on the surface of bacteria and viruses) and then creating antibodies (special proteins designed to destroy the foreign invaders). Yet our immune system is sometimes tricked into triggering an immune response that instead attacks our own organs and tissues, as well as the pathogens that cause infection. (See figure to the right.)\nOur Immune System: The Basics\nTo better understand how these situations in which the “body attacks itself” can lead to an autoimmune disease, it helps to know some of the basics of immunology, such as the various organs, the cells they produce, and the roles these cells play in protecting us from illness.\nImmunology basics include:\n- Bone marrow: The location within our bones where immune cells are derived.\n- Thymus: A flat, pinkish-gray gland, located in the upper chest in front of the heart, where T-cells pass through and mature.\n- Lymphatic system: Made up of lymph fluid, lymphatic vessels, bone marrow, lymph nodes, spleen and tonsils, the lymphatic system is critical in the elimination of toxic waste from tissues.\n- T-cells: Considered the “warriors of the immune system,” these cells mature in the thymus enabling each individual T-cell to recognize only one of millions of antigens. T-cells then migrate into the lymphatic system and circulate in the blood.\n- B-cells: Immune cells that are produced in the bone marrow and then secrete antibodies.\nWhen discussing autoimmune diseases, the role played by T-cells is of great importance. As Lorna Vanderhaeghe and Dr. Patrick Bouic explain in their book The Immune System Cure, T-cells are taught to recognize the difference between invading cells (“nonself”) and our own cells (“self”). Normally, the immune system attacks only substances and infections that are thought of as foreigners, such as invaders from outside the body, or cancer cells made within the body; however, sometimes the immune system may be confused and attack healthy body cells.\nExamples of Autoimmune Diseases\nThyroid disease, lupus, multiple sclerosis, and rheumatoid arthritis are some of the most common autoimmune diseases that affect our population. The table below provides a more comprehensive list.\nThere are two different autoimmune diseases that target the thyroid: Graves’ disease, which causes an overactive thyroid (hyperthyroidism), and Hashimoto’s disease, which causes an underactive thyroid (hypothyroidism). Both forms of thyroid disease are more common in women than men and are often first diagnosed in individuals between the ages of 20 and 30 years.\nBecause the thyroid gland controls the metabolic activity of our body, dysfunction of this gland affects our metabolism. In the case of Graves’ disease, the thyroid gland is attacked by the body’s antibodies, resulting in inflammation and swelling of the thyroid gland. This in turn leads to hyperthyroidism (an overactive metabolic state) whereby the body goes into overdrive, causing an increase in heart rate, blood pressure, and calorie burning rate.\nLike Graves’ disease, Hashimoto’s thyroiditis is an autoimmune disorder whereby antibodies react against proteins on the thyroid; however, this disease is characterized by a gradual destruction of the gland itself and its ability to produce the thyroid hormones needed by the body. People in a hypothyroid state experience a lowered metabolic activity.\nTreatments for Graves’ disease include radioactive iodine (RAI) treatment and surgical removal of the thyroid, which usually result in a disabling of the thyroid and eventual hypothyroidism. Thyroid hormone therapy may therefore be indicated. Similarly, for hypothyroidism caused by Hashimoto’s disease, doctors typically prescribe thyroid hormone therapy.\nSystemic Lupus Erythematosus (SLE)\nSLE (often referred to simply as “lupus”) is a chronic, autoimmune disease that affects various parts of the body, particularly the skin, blood, joints and kidneys, lungs, and heart. It is caused by an overactive immune system that produces antibodies that attack the body’s own organs, joints, and tendons. The result is the formation of immune cell complexes that build up in various tissues causing pain, inflammation and eventual injury or destruction.\nIn her book Living Well with Autoimmune Disease, Mary Shomon writes: “For most, lupus is considered a mild condition, affecting only a few organs. For others however, it may not take such a simple course and may trigger serious, even life-threatening, conditions.” Lupus can occur at any age, and while it is found in both men and women, the disease is 10-15 times more common in women.\nMedical studies have investigated the use of DHEA (dehydroepiandrosterone), a hormone produced by the adrenal gland, and have found it to improve the health of people with lupus. DHEA is a major precursor, or building block, to the sex steroids (androgens and estrogens). Because studies have shown that some lupus patients have low levels of DHEA and that this may contribute to the onset of the disease, it is thought that increasing the level of androgens may help.\nIn a scientific review titled DHEA For Lupus, Dr. Kay Shaver concludes that the use of DHEA may provide lupus patients with several benefits including the potential to provide relief from symptoms, a decrease in the frequency of disease flare-ups, and possibly even sparing of the destructive effect on the bone.\nMultiple Sclerosis (MS)\nMultiple sclerosis is another chronic inflammatory autoimmune disease, but this one targets the central nervous system, affecting the brain and spinal cord.\nIn MS, the body overproduces antibodies that specifically attack myelin (the protective sheath that covers our nerves) and can result in a variety of neurological problems. These problems include cognitive and psychological changes, weakness or paralysis of limbs, numbness, vision problems, speech difficulties, problems with walking and motor skills, and sexual dysfunction.\nMS is the most common acquired neurological disease in young adults and, while it can affect anyone, it is most often diagnosed in individuals between ages 20 and 40. Like all of the autoimmune diseases already discussed, MS is much more prevalent (twice) in women than in men.\nInterestingly, repeated observations that women with MS show a significant improvement in their symptoms and a decrease in their relapses or flare-ups upon becoming pregnant, led to the design of some important studies. The effects of oral hormonal treatment for MS were tested by Dr. Nancy Sicotte and colleagues. They showed that estriol, a pregnancy hormone, when given to nonpregnant women with MS, helped to decrease MS symptoms. More extensive trials in animals with MS confirmed that various doses of estriol work to stabilize and even improve symptoms in this debilitating disease.\nThe role of another hormone— progesterone—has also been implicated in the possible treatment of MS. Dr. Herbert Koenig and colleagues showed in a laboratory study that progesterone may be involved in the process of myelination, or the formation of myelin to protect nerve cells. Their work suggests that the administration of progesterone may be a valuable therapeutic approach for initiating myelin repair in MS patients.\nRheumatoid Arthritis (RA)\nRA is a widespread and disabling autoimmune disease that affects the joints and muscles. Most frequently the free-moving joints—such as the small joints of the hands, knees, ankles, hips, elbows, wrists and shoulders—are targeted.\nIn RA, our body launches an autoimmune attack on the synovial membranes (the tissue that lines and cushions the joints) leading to inflammation, thickening and pain. As this process continues the pain and swelling increase, and ultimately can result in destruction and deformity of the bones.\nThe condition usually starts between the ages 25 and 50, and perhaps because it is so common, the symptoms are often mistaken as a normal part of aging. RA afflicts females two to four more times frequently than males. For most patients, RA is progressive, despite treatment. The objective of treatment is primarily to control inflammation, prevent or slow joint damage, and ultimately ease the condition into remission.\nThe role of the hormone progesterone in RA patients has also been investigated. Dr. Rossella Valentino and colleagues describe decreased levels of progesterone in women with RA, and their studies support the positive outcomes reported by Dr. Miguel Cuchacovich when using progesterone treatment in RA patients. Dr. Valentino also describes decreased levels of testosterone in such patients and has shown the positive effects in laboratory and clinical studies when testosterone is used as therapy.\nThe Endocrine System & Autoimmune Diseases\nThe endocrine system is a target for autoimmune diseases. As the body’s hormonal regulator, the endocrine system releases and then slows and/or stops the production of different hormones in response to various internal and external triggers.\nThe tightly controlled network of endocrine organs and glands (which includes the thyroid, pancreas, pituitary, adrenal, ovaries and testes) may be affected in cases of autoimmune disease. In cases of insulin-dependent diabetes, the pancreas comes under attack, while in Graves’ disease, as discussed earlier, the thyroid gland goes into overdrive in response to overproduction of antibodies.\nAutoimmune disorders involving the endocrine system may also arise when a person produces antibodies to a particular hormone. Antibodies against naturally occurring hormones such as estradiol and progesterone can wreak havoc. When women make antibodies to such hormones, they may experience erratic ovulation or insufficient production of the uterine lining. These conditions can cause abnormal menstrual periods and even prevent successful implantation and pregnancy.\nWhile autoimmune diseases certainly afflict men, it is virtually impossible to ignore the fact that they are much more prevalent in the opposite sex. In his book Women and Autoimmune Disease, Dr. Robert Lahita writes, “Why is there such a seemingly unfair preponderance of women associated with practically every one of the autoimmune diseases? As it turns out, one of the greatest factors that influence the immune system is gender.”\nThe Role of Estrogen in the Immune System\nMany scientists are focusing their research efforts on trying to understand precisely why it is that autoimmune diseases are more common in women than in men. The authors of The Immune System Cure offer the following explanation: “Scientists believe that the female hormone estrogen may be the reason for this. The hormone estrogen may interplay with certain immune factors that enhance the action of the inflammatory response, increasing antibodies that attack certain tissues in the body. An over abundance of estrogen or estrogen-dominance may be a factor in the prevalence of autoimmune conditions in women.”\nOther studies have shown that during their reproductive years, when estrogen levels are higher, females tend to have a more vigorous immune response. It is during menopause, when estrogen levels decrease, that a woman’s immune system becomes more similar to that of a man’s. This lowered immune response is believed to be caused by changes in the function and activity of certain immune cells. And even more interesting evidence for the influence of estrogen on our immune system is provided by the observation that the incidence of many autoimmune diseases in women dramatically decreases following menopause.\nResearch continues to show that the decreased estrogen level associated with menopause can affect our immune system. In a review of various studies designed to better understand the relationship between sex hormones such as estrogens and the immune system, Dr. Sarit Aschkenazi and colleagues explain that sex hormones affect and modify the actions of different types of immune cells. The authors also point out that certain interactions between estrogen and cells of the immune system can also influence other organs of the body that are not directly related to immunity. For example, cardiovascular disease and osteoporosis—health issues that often affect women after menopause—are linked to a decrease in estrogen and a loss in estrogen’s ability to regulate the healthy functioning of other types of immune cells.\nIn their review, Dr. Aschkenazi and colleagues concluded that sex hormones, in particular the estrogens, play a role in the activity of immune cells. Furthermore, a deficiency in estrogen that occurs during menopause may result in a failure of estrogen to properly regulate the immune system. These changes, in turn, may play an important role in the development of menopausal symptoms and disease. The possible role of hormone therapy should be considered in cases of autoimmune disease.\nKeeping Your Immune System Healthy\nHow do you keep the immune system active and healthy? All the books say essentially the same thing— simply by living well. And “living well” involves common sense practices such as eating a healthful diet, getting enough sleep, exercising, drinking alcohol only in moderation, and avoiding stress. A few additional tips for keeping the immune system healthy include:\n- Avoid or prevent exposure to environmental toxins such as mercury, poisons and heavy metals.\n- Avoid taking unnecessary drugs.\n- Understand that diet can influence your immune system, and choose your foods wisely.\n- Have sex. Sexual activity has been found to be good for the immune system because it activates the hormones that are regulated by the act of having sex and helps maintain a healthy hormone balance.\n- The Immune System Cure by Lorna R. Vanderhaeghe and Patrick J.D. Bouic, PhD, Penguin Books; Ontario, Canada; 1999.\n- Living Well with Autoimmune Disease by Mary J. Shomon, Harper Collins; New York, NY; 2002.\n- Women and Autoimmune Disease by Robert G. Lahita, MD, PhD, ReganBooks; New York, NY; 2004.\n- “DHEA for Lupus” by Kay Shaver, PharmD; Pharmacist’s Letter/ Prescriber’s Letter, 2000.\n- “Treatment of Multiple Sclerosis with the Pregnancy Hormone Estriol” by Nancy L. Sicotte, MD, et al; Ann Neurol, 2002.\n- “Progesterone Synthesis and Myelin Formation by Schwann Cells” by Herbert L. Koenig, PhD, et al; Science, 1995.\n- “Hormonal Pattern in Women Affected by Rheumatoid Arthritis” by Rossella Valentino, MD, et al; J Endocrinol Invest, 1993.\n- “Intraarticular Progesterone: Effects of a Local Treatment for Rheumatoid Arthritis” by Miguel Cuchacovich, MD, et al; J Rheumatol, 1988.\n- “Menopause, Sex Hormones and the Immune System” by Sarit Aschkenazi, MD, et al; Menopause Management, March/April 2000.']"	['<urn:uuid:163f8374-71b0-4d7d-b555-c772f15ea605>', '<urn:uuid:c9420bc3-6206-4552-9167-f3a43ef322a8>']	factoid	with-premise	short-search-query	similar-to-document	multi-aspect	novice	2025-05-13T04:02:16.770989	9	73	3067
54	average weight mature hawaiian sea turtle	Hawaiian green sea turtles can grow to have a shell length of 36 inches and weigh about 250 pounds on average.	['Sea Life Park Hawaii is home to the only active breeding colony of green sea turtles in the entire United States. This means that the sea turtles you see here reproduce every season. Every year after mating the females go up on to that sandy beach and lay their eggs, or clutch. They can lay up to 5 clutches per breeding season. Each clutch can have anywhere from 60-120 eggs. After about 60 days and then we collect the hatchlings and release them into the ocean. So far here at Sea Life Park Hawaii, we have released over 16,000 baby sea turtles! Some juvenile turtles from the park can be seen at other educational facilities throughout the islands and part of the educational and outreach programs we have through our partnerships and loan programs. Before being released to the ocean we “PIT” tag the hatchlings where they receive a microchip in their back flipper. These tags provide a permanent method of identifying and tracking the turtles that we release so we can further collect data on where the turtles are heading.\nHow old do you think these sea turtles are? These sea turtles were donated to Sea Life Park Hawaii in the 1970’s, so we estimate that they are at least 60 years old; but may be as old as 70 or 80. Green sea turtles live to be anywhere between 80 to 100 years old.\nHow do green sea turtles (known in the Hawaiian language as honu, scientific name chelonia mydas) get their name? From what they eat, or their diet! Adult green sea turtles are completely herbivorous, or vegetarian. They eat algae, or seaweed, off of the coral reef. They eat so much green stuff that their subdermal layer of fat, inside their body is stained green in color.\nHow do you tell the difference between a male and a female sea turtle? You can identify males vs females by the length of their tail once the sea turtle is a mature adult. Maturity is reached as early as 10 and as late as 50 years old. An adult male has a long dinosaur like tail, while females have short, stubby tails.\nWhat type of animal is a green sea turtle is? It’s a reptile.\nWhat are some characteristics of a reptile?\nThey lay eggs.\nThey have backbones! Their backbone is attached to their shell!\nThey are cold-blooded: What does cold-blooded mean? It means that their body temperature changes to match the temperature of their environment.\nThey breathe air. All reptiles breathe air. They have lungs similar to humans. Honu have a special ability to lower their heart rate. This allows adults to hold their breath for up to 2 hours.\nThey have scaly skin. Even their shell is made up of modified scales called scutes. Hawaiian Green Sea Turtles have 13 scutes!\nGreen sea turtles do not have teeth; however they have a beak with a very sharp jagged edge. This allows them to scrape the algae off of the reef and off of rocks. Moving down their body, they have specially modified front flippers that help them swim, while their hind limbs enable them to steer. The shell of a green sea turtle consists of two parts, the carapace and the plastron. The carapace is the top or back of the shell and is covered with 13 scutes, or scales, on average. The underside of a turtle is known as the plastron. You will notice that the belly of the sea turtle is a lighter color. This is a type of camouflage called countershading, so their dark carapace blends in with the dark ocean floor; and the lighter plastron blends in with the sky and light coming in from above. This countershading helps to protect them from predators.\nThis habitat, like all of our habitats at Sea Life Park Hawaii, contains real ocean water. Sea Life Park Hawaii pumps about 12 million gallons of fresh sea water through our habitats every day. We do not put any kind of chemicals into that water, so algae grows naturally in our habitats. This algae called diatoms actually absorbs harmful sunlight and produces atmospheric oxygen. This algae may also grow on sea turtles. It can be seen on their scales or shell. In the wild, sea turtles visiting something called a cleaning station, which is a place on the reef where fish come and eat the algae off of the sea turtle. The turtle is getting clean, and the fish is getting fed; this is what is called symbiotic relationship in which both animals benefit from the partnership. We do not have those fish in our habitat, so twice a week we drain the habitat and our staff scrub the sea turtles clean!\nAll sea turtles have different patterns and colors on their shells. Our turtles may look different than wild turtles that you see because their shells are kept clean from being scrubbed. However, when sea turtles first hatch from the egg, they are a dark grey almost black color. If you get to see one of the juveniles at our touch pool today you will notice this color difference. When a Hawaiian green sea turtle hatches it is about 2 inches and weighs around 1 oz.; which is about the size of a golf ball! On average, they can grow to have a shell length of 36 inches and weigh about 250lbs.\nOnly about 1 in 1,000 sea turtle hatchlings survive until maturity. What kinds of dangers do you think they face as the make their way from their nest to the ocean? Threats to green sea turtles include crabs, seabirds, heat from the sun, humans, and several other threats; but if they make it to the ocean the threats don’t end there. Sharks, large fish, and human interaction such as nets and marine debris also threaten their pelagic lifestyle. When sea turtles first hatch, they make their way out into the open ocean and spend 4-10years there. This is called their pelagic life style. A pelagic lifestyle is where a turtle will float around at the surface of the water, and will not typically be seen until it returns to the nesting beaches as an adult. During this time, the juvenile sea turtle is an opportunistic feeder, which means that it eats whatever it can find. They may be eating squid, fish, or anything floating on the surface of the ocean. Our juvenile sea turtles are fed krill, squid, and fish like ahi.\nHawaiian green sea turtles were listed as endangered, however due to being protected by Hawaii state and federal law as well as the Endangered Species Act; their status has now been moved to threatened. This is better, but our goal is to get them off of this list completely. Therefore, you should not threaten, hunt, feed, or harass green sea turtles in the wild. Hawaiian green sea turtles have been known to come up on to the beaches; and it is very important to leave them alone when they do this, so that they can get the rest and warmth that they need to survive. Unfortunately, disease, marine debris, and net entanglements also threaten these turtles. What is marine debris? Marine debris is our trash that ends up in the ocean.\nFor all of these threats to green sea turtles, you can help by picking up your trash; and even taking it a step further by picking up someone else’s trash to reduce the amount of marine debris found in our oceans. If you see a turtle in distress you should not attempt to come to the turtle’s aid; instead you can call the appropriate agencies to assist with turtles locally.']	['<urn:uuid:3fa08790-7438-4420-91d9-3e8072f51e3a>']	factoid	with-premise	short-search-query	distant-from-document	single-doc	expert	2025-05-13T04:02:16.770989	6	21	1288
55	How did researchers identify the genetic cause of PKD/IC, and what specific gene mutations did they discover in their investigation?	Researchers identified the genetic cause through a study of 103 families with a history of the disease. Their genetic testing revealed mutations in the PRRT2 gene, which cause the proteins the gene encodes to either shorten or completely disappear in the brain and spinal cord, where they normally reside.	"['A large, international team of researchers led by scientists at the University of California, San Francisco (UCSF) has identified the gene that causes a rare childhood neurological disorder called PKD/IC, or ""paroxysmal kinesigenic dyskinesia with infantile convulsions,"" a cause of epilepsy in babies and movement disorders in older children.\nThe study involved clinics in cities as far flung as Tokyo, New York, London and Istanbul and may improve the ability of doctors to diagnose PKD/IC, and it may shed light on other movement disorders, like Parkinson\'s disease.\nThe culprit behind the disease turns out to be a mysterious gene found in the brain called PRRT2. Nobody knows what this gene does, and it bears little resemblance to anything else in the human genome.\n""This is both exciting and a little bit scary,"" said Louis Ptacek, MD, who led the research. The John C. Coleman Distinguished Professor of Neurology at UCSF and a Howard Hughes Medical Institute Investigator, Ptacek is a professor in the Department of Neurology, which seeks to discover the causes of human nervous system disorders and improve treatment options for patients by applying state-of-the-art translational research methods and engaging in collaborations with colleagues around the globe.\nDiscovering the gene that causes PKD/IC will help researchers understand how the disease works. It gives doctors a potential new way of definitively diagnosing the disease by looking for genetic mutations in the gene. The work may also shed light on other conditions that are characterized by movement disorders, including possibly Parkinson\'s disease.\n""Understanding the underlying biology of this disease is absolutely going to help us understand movement disorders in general,"" said Ptacek.\nDisease Strikes Infants with Epileptic Seizures\nPKD/IC strikes infants with epileptic seizures that generally disappear within a year or two. However, the disease often reemerges later in childhood as a movement disorder in which children suffer sudden, startling, involuntary jerks when they start to move. Even thinking about moving is enough to cause some of these children to jerk involuntarily.\nThe disease is rare, and Ptacek estimates strikes about one out of every 100,000 people in the United States. At the same time, the disease is classified as ""idiopathic"" -- which is just another way of saying we don\'t really understand it, Ptacek said.\nIf you take an image of the brain by MRI, patients with the disease all look completely normal. There are no injuries, tumors or other obvious signs that account for the movements -- as is often the case with movement disorders. Work with patients in the clinic had suggested a genetic cause, however.\n""Sometimes we trace the family tree, and lo and behold, there is a history of it,"" said Ptacek. In the last several years, he and his colleagues have developed a large cohort of patients whose families have a history of the disease.\nThe new research was based on a cohort of 103 such families that included one or more members with the disease. Genetic testing of these families led to the researchers to mutations in the PRRT2 gene, which cause the proteins the gene encodes to shorten or disappear entirely in the brain and spinal cord, where they normally reside.\nOne possible explanation for the resulting neurological symptoms, the researchers found, relates to a loss of neuronal regulation. When the genetic mutations cause the gene products to go missing, the nerve cells where they normally appear may become overly excited, firing too frequently or strongly and leading to the involuntary movements.\nCite This Page:']"	['<urn:uuid:d4b0fd7c-4063-4480-bbe6-e97a8521a40d>']	factoid	direct	verbose-and-natural	similar-to-document	single-doc	expert	2025-05-13T04:02:16.770989	20	49	582
56	What makes spelt different from regular wheat?	Spelt has several unique characteristics compared to regular wheat. Unlike normal wheat, spelt is harvested with its husk still on, which needs to be removed while the bran is still attached, resulting in less bran content than wheat flour. Spelt is actually a hybridized variety of grain with Emmer as one of its ancestors. It has gained popularity due to its similarity to wheat, featuring a higher gluten content and nutty flavor. It's easier to mill than some heritage grains, and interestingly, some people who don't tolerate regular wheat well can enjoy spelt. Most whole wheat bread recipes work with a direct substitution of spelt flour.	['This a free preview of a premium article published in BREAD Magazine. We hope you’ll enjoy it.\nFlour is the most important component in bread. However, as bakers, we often don’t know much about the processes involved in making it. The growing interest in home milling and heritage grains is making milling more visible, but many aspects of a miller’s craft remain a mystery. To get a better picture of what milling consists of, I contacted two millers in South Australia, whose flours I regularly use with great results, Laucke Flour Mills and Four Leaf Milling. Both agreed to meet me, happy to share their knowledge.\nLaucke Flour Mills is a family-run company that has been operating in South Australia for over a century and currently has its third generation at the helm. Ensconced in the mill’s baking test lab, I had a fascinating conversation on baking and milling with Martin McLennan. Four Leaf Milling was founded by Rosemary and Gavin Dunn who have been milling organic flour since the 1960s. They are now grooming the younger generation to step in to uphold the tradition of their milling principles.\nFour Leaf Milling is a certified producer and miller of organic grains. Laucke Flour Mills processes both organic and conventional grain, with an objective to process both as “cleanly as possible” with the minimum amount of pesticides applied to the harvested grain.2\nBoth mills have an extensive offering of flour varieties ranging from wheat to the increasingly popular ancient grain types such as spelt.\nDifferences Between Roller-Milled and Stone-Ground Flours\nMilling is the process of breaking wheat kernels into small particles that are refined to various degrees, that is, flour. The method used for doing this is the most notable difference between the two millers: Laucke Flour Mills primarily roller mills the grain while Four Leaf Milling only produces stone-ground flour.\nRoller milling is the conventional method of milling: the grain is milled using steel rollers and then pushed through consecutive sets of sieves that separate the bran from the endosperm. The process results in a soft, white, refined flour that consists mostly of endosperm—desired by many over the centuries. To make wholemeal flour, millers put a certain percentage of the sifted-out bran back after the initial milling.\nIn stone milling, the different parts of the grain do not get separated but are crushed and distributed together using a pair of millstones. Four Leaf Milling processes the grain through a stone grinder, and all that comes out is used. Compared to roller milling, the temperature of the flour stays cooler, which helps maintain higher protein levels and does not disrupt essential enzyme activity. Many people prefer stone-ground flour because they believe it has a higher nutritional content and a better flavor.\nWhen comparing flours, bakers and millers often talk about extraction rates.\nAccording to Martin McLennan, “The extraction rate is the percentage of the whole grain that remains in the flour.”\nSo, wholemeal flour should have a 100% extraction rate because it contains all of the bran. In roller milling, this is not strictly true because the bran is added back after the sifting process—whether this was the content of bran found in the initial milling is debatable.\nThe extraction rate is also a measure of the mill’s efficiency: when making white flour, a good mill can reach an extraction rate of 78-79%. If the number is lower than that, there was either more bran in the milled grain or the endosperm was poorly sifted and got stuck in the bran.\nSpelt differs in the sense that, unlike normal wheat, it is harvested with its husk still on it. The husk in spelt needs to be removed while it still has the bran on it and, as a consequence, there is less bran to be found in spelt flour than in wheat flour.\nMoisture Content in Milling\nTo get the best out of the grain, millers need to know and control its moisture level. This is done by grinding a wheat sample.\nAt Laucke Flour Mills, where most of the milling is done using roller mills, the aim is to achieve a moisture content of around 13.8%. By going for a reasonable amount of moisture penetration on the bran but not so much on the endosperm, they hope to make the grain like a pea popping out of the pod. Ideally, as soon as the bran goes through the first break rollers, the endosperm would shoot out leaving a big lump of bran behind. It doesn’t usually happen, but it is the aim.\nThe measurement is done by grinding a wheat sample which is then placed in a chamber that will measure how much moisture there is in it (using sophisticated infrared technology). Based on the results, some amount of water is added to the grains by storing them up to 48 hours in large conditioning bins before they go through the mill. Hard wheat usually needs more conditioning than soft wheat.\nAt Four Leaf Milling, moisture content (they aim for 12%) is measured using a moisture meter, and for a different purpose: all grain loads that come to the mill are tested, to make sure that they are safe for storage. If grain were to be stored above a moisture level of 12%, they believe this would invite mold problems.\nProtein Content in Flour\nOne of the things bakers often focus on when considering the flour they use is its protein content, ”Too much so,” Martin McLennan suggested, “unless you want to make a rubber ball. And adding gluten is unnecessary.”\nThe general school of thought is that high protein flour is better suited to bread making. However, Martin disagrees. He believes that the wheat variety is more significant when it comes to making bread. Within one wheat variety, protein content can be anything between 10% and 14%. A protein content of 11% is good enough for general bread such as French baguettes—anything higher than that would only be too tough and chewy. The one instance where a higher protein content is desirable is when making bagels, which are expected to be dense and chewy.\nWeather conditions also affect the protein content and the quality of the flour. Water dilutes the nitrogen in the soil, which in return diminishes the protein content in the grain. In a nutshell: wet weather leads to low protein and dry weather to high protein flour. Because of the wet weather this past season, both millers expect all flours to be softer this year.\nAs wheat needs to be dry to ripen properly, the wet season also delayed harvests. Farmers in South Australia harvest only once a year, usually starting around November. This year, they were still harvesting in January!\nGrain classification in Australia is less complex than in the United States. Its purpose is to determine whether the grain is suitable for human consumption in the first place, and secondarily, to assign a benchmark for the grain’s hardness, color, and protein content to assist in determining whether the flour is suitable for bread making or pastry making.\nThis is an article from a paid BREAD Magazine issue.\nIf you have already bought the issue, sign in to read the article.', 'The wheat most people are familiar with is just one or two varieties of grasses in a family called Triticum. While bread wheat (T. aestivum) will yield consistently good results in sourdough bread baking, home bakers may wish to try out some other varieties for fun, nutrition, and flavor. Here are some grains that can be found in health food stores and large supermarkets.\nTypes of Heirloom Wheat\nEinkorn (Triticum monococcum)\nEinkorn wheat is one of the oldest known cultivated varieties of wheat. It has a more simple genetic structure, and has not been hybridized. Einkorn has experienced a resurgence in popularity, as it is believed to be easier for people with a gluten intolerance to digest.* Einkorn is available as a whole grain or white flour for baking.\nEmmer (Triticum dicoccum)\nEmmer (also known as farro) is another very early variety of wheat. Farmers grew both einkorn and emmer in the Fertile Crescent. Farro in stores is usually sold whole or pearled. Soak the grains before cooking to enjoy their nutty, chewy texture in salads. Emmer flour is not as widely available as some other heritage wheats. Because of the lower gluten level and slightly harder grains, dough will be quite sticky and will not rise as much. Home bakers should experiment with hydration levels.\nSpelt (Triticum spelta)\nSpelt is confusingly also referred to as farro by some mills. It is perhaps one of the most popular of the alternative wheats and is the most similar in genetic structure to T. aestivum. The exact history is unclear, but spelt is a hybridized variety of grain, with Emmer as one of its ancestors. Spelt’s popularity stems in part from its similarity to wheat. It has a higher gluten content, a nutty flavor, and is easier to mill than some heritage grains. However, some people who do not tolerate regular wheat well, can enjoy spelt.\nMost whole wheat bread recipes will work with a direct substitution of spelt flour.\nTriticale (× Triticosecale)\nTriticale is hybrid of wheat and rye, and carries characteristics of each. It is grown for its high rate of germination and tolerance of poor growing conditions. Triticale is high in protein, but lower in gluten than wheat. Use triticale in baking as a whole wheat substitute. Because of the nature of this hybrid, there can be variations between crops.\nKamut (Triticum turanicum)\nThe history of kamut is a little less clear than some other wheat varieties. It was a popular grain in Egypt and the surrounding area. Kamut makes a delicious porridge and can be used in pasta, bread, and other baked goods. Like other old wheat varieties, kamut is lower in gluten and does not make a light, lofty loaf of bread. It is excellent in sweeter foods because of its buttery flavor.\nFind A SOURDOUGH STARTER FOR HEIRLOOM WHEAT VARIETIES\nOur Desem Sourdough Starter can be used with any whole-grain heirloom wheat flour. If your sourdough starter is already active, follow the instructions for switching your sourdough starter to a new type of flour.\nBaking with Heirloom Wheat Flours\nHow to Work with Heirloom Wheat Dough\nHeirloom wheat absorbs water more slowly, so the dough tends to be quite sticky at first.\nRule of Thumb: Reduce the water in the recipe by one-fourth, but be prepared to add more if needed.\nA slightly sticky dough will rise better and have a more pleasant crumb.\nCombine the ingredients and knead the dough until it is springy. Then set it aside to proof for several hours, depending on the temperature. The structure tends to develop better over time, rather than with a lot of vigorous kneading. A second proofing before baking will give the proteins time to develop more fully and the sourdough cultures time to improve the flavor and crumb. Allowing the dough to rest in the refrigerator overnight before baking is a wonderful way to fit these flours into a busy schedule.\nHow to Combine Heirloom Wheat with Modern Wheat\nCombining heirloom wheat with modern wheat is another way to enjoy the flavor and benefits of heirloom wheat, while still making bread with a more familiar texture. Begin by replacing ¼ - ½ of the total amount of white flour in the recipe with a whole grain flour. Reduce the water slightly to compensate for the change. Mix, knead, and proof as directed. Increase the proportion of heirloom wheat flour over time, or continue making loaves of light, chewy bread.']	['<urn:uuid:08ac78f5-10e9-430b-bcc6-1312f38a7c11>', '<urn:uuid:e2fc7021-37ea-475b-8cd2-f3880d1662e9>']	open-ended	direct	concise-and-natural	similar-to-document	three-doc	novice	2025-05-13T04:02:16.770989	7	106	1950
57	mediterranean diet score reduction premature death risk compared lower scores	Those with higher Mediterranean diet scores had a 37 per cent lower risk of premature death compared with those with lower scores.	"[""If you’ve ever have the misfortune of a heart attack or are considered at risk of heart disease or stroke, your doctor will probably prescribe a statin drug, such as atorvastatin (Lipitor), to lower your blood cholesterol levels.\nRecent reports of an Italian study have suggested adhering to a Mediterranean-style diet may actually better protect people from a heart attack or stroke than taking a statin.\nSuch a claim can’t really be made. To do so, we’d need a trial in which a large number of well-matched participants were randomly given either statins or a Mediterranean-style diet, and followed faithfully to see the comparative results.\nSuch a trial is unlikely to occur, as withholding medication from people at risk of heart attack or stroke would be regarded as unethical.\nBut I also suspect ethics committees would be unlikely to recommend anyone avoid following the healthy features of a Mediterranean-style diet, which so many studies have shown to be protective.\nThe Italian study and statins\nThe recent Italian study randomly enrolled more than 25,000 people, about 1,200 of whom reported a prior history of heart attack, stroke or blocked arteries at enrolment. Each person recorded their usual diet over the next seven years. Researchers recorded deaths from any cause.\nParticipants' diets were given a score out of nine, based on how many features of a healthy Mediterranean-style diet they followed. Those with higher scores had a 37 per cent lower risk of premature death compared with those with lower scores.\nThere is no one Mediterranean diet, nor does every Mediterranean country have a diet that ticks every healthy box.\nThese results were controlled for confounding factors, including age, sex, smoking, exercise, energy intake, waist-to-hip ratio, blood pressure, blood cholesterol levels and diabetes.\nThe benefits of statins on various levels of heart health have also been extensively researched. A recent randomised controlled trial compared statins with a placebo in 21 countries in 12,705 people who were at higher-than-average risk of heart disease.\nOver the more than five years of this study, those on statins had a 23 per cent reduction in heart attack, stroke or heart-related death compared with those on placebo. There were no differences in diabetes or cancers, but those on statins were 20 per cent more likely to have muscle symptoms, such as weakness or pain, and 18 per cent more likely to have cataract surgery.\nThe Mediterranean-style diet\nThere is no one Mediterranean diet, nor does every Mediterranean country have a diet that ticks every healthy box. However, dozens of studies have defined the features of what makes a Mediterranean dietary pattern healthy.\nPrimarily, the diet needs to be based on whole or minimally processed foods. Positive points accrue for protective foods such as fruits, vegetables, legumes, nuts, wholegrains, fish, olive oil and modest amounts of alcohol consumed with meals. High intakes of red and processed meats, sugary foods and drinks, refined grain products and fast foods all score negative points.\nThe benefits of certain Mediterranean diets were first publicised in the 1960s. Researchers found that rates of death from heart disease were three times higher in Northern European countries (top score to Finland) compared with four groups studied in Southern Europe.\nHigh intakes of red and processed meats, sugary foods and drinks, refined grain products and fast foods all score negative points.\nDuring the 1990s, the Lyon Heart Study began. This was a long-term study designed for participants who had already had a heart attack. It produced results so favourable for the benefits of Mediterranean eating patterns compared with the standard diet advice usually given that it was stopped early. Results four years later confirmed the original benefits of the Mediterranean eating pattern.\nEven more dramatic results were claimed from the HALE study in Europe. Conducted between 1988 and 2000, the trial involved 2,340 older men and women in 11 European countries.\nThose who followed a Mediterranean-style diet and a generally healthy lifestyle – no smoking, moderate alcohol intake and regular physical activity – had more than a 50 per cent lower rate of death from any cause.\nA more recent trial in Spain of people who had not had a heart attack but were considered at high risk has confirmed the value of a Mediterranean eating pattern.\nThose who followed a Mediterranean-style diet and a generally healthy lifestyle...had more than a 50 per cent lower rate of death from any cause.\nOne-third of its 7,500 participants were asked to follow a Mediterranean eating pattern and add extra olive oil; another third followed the same basic diet but were given extra tree nuts. The remaining third were asked to follow a low-fat diet, although this section of the study failed as the participants barely changed their fat intake.\nThe study found adding extra olive oil or nuts to the basic Mediterranean eating style conferred many benefits for heart health. This study also showed that the higher the intake of saturated fat in each group, the worse the results.\nWhether the Mediterranean diet can outdo statins may be up for debate. However, there’s no doubting the strong evidence for a Mediterranean eating pattern for everyone. Even for those on statins, a healthy Mediterranean eating pattern has been shown to bring extra benefits.\nTry the BBQ Calamari recipe from Greek Safari""]"	['<urn:uuid:b52cb88c-de22-4a34-a51b-1e9937e01a27>']	factoid	direct	long-search-query	similar-to-document	single-doc	expert	2025-05-13T04:02:16.770989	10	22	882
58	What are the core requirements for admission into the School Psychological Examiner program, and what ethical frameworks guide their professional practice?	For admission, candidates need an undergraduate major preferably in psychology or education, a GPA above 3.0, minimum 40th percentile scores on both verbal and quantitative sections of the GRE, two recommendation letters, and a personal statement. Regarding ethical frameworks, school psychologists are guided by several standards including the American Psychological Association's Ethical Principles and Code of Conduct, the National Association of School Psychologists' Principles for Professional Ethics, and the Standards for Educational and Psychological Testing.	"[""Human Exceptionality, School Psychological Examiner\nAssist students to succeed psychosocially and academically by becoming a School Psychological Examiner! Demand for child psychological services in schools is projected to increase over the next decade. The Master of Education of School Psychological Examiner aligns with the National Association of School Psychologists’ professional standards to assess cognitive and academic abilities, or describe behavior, personality, or aptitude of P-12 learners in order to determine eligibility for services. Help students reach their academic potential as a School Psychological Examiner!\nHuman Exceptionality, School Psychological Examiner, M.Ed.\nPreparing professional educators for leadership, health, and performance improvement in sport\n- Public School Psychological Examiner\n- Private Clinic Practice\n- Post-Secondary Practitioners\n- Hospital Practice\n- Private School Psychological Examiner\n- School-Based Mental Health Center\n- Community Day Treatment Center\n- Trainer of Teachers, Health Professionals, Care-Givers\n- Juvenile Justice Program\nAdmission and Program Requirements\nCandidates for the M.Ed. in School Psychology must meet all college and university requirements for admission and retention. Preference is given to applicants with an undergraduate major in psychology or education (including special education), a GPA above 3.0, and minimum score at the 40th percentile on both the verbal and quantitative sections on the Graduate Record Examination (GRE) General Test. Applications must include at least two letters of recommendation and a personal statement of interest and goals. Complete application materials, including transcripts and test scores, must be received by January 1st to be considered for summer semester admission. Our program admits about six to eight students each year.\nOur students usually enter the program with a Bachelors's degree and complete their M.Ed. of School Psychological Examiner before being accepted to continue their study toward an Ed.S. degree. Other master’s degree majors in a closely related field may be approved upon recommendation of the selection committee. However, they may be required to take additional, prerequisite coursework.\nStudents completing a Master of Education in School Psychological Examiner must complete both a written comprehensive examination and an oral examination.\nAll requirements for the M.Ed. must be completed within a period of eight years from the date of completion of the first course to be applied toward the degree.\nSchool Psychology Major Requirements\nEd. School Psychological Examiner (31 credits)\nSummer Semester (9 Graduate Credits)\nSCPY 6660 Seminar in School Psychology (3 cr)\nSCPY 6672 Problem-Solving Intervention in Schools (3 cr)\nEDUC 6602 Theories of Learning (3 cr)\nFall Semester (12 Graduate Credits)\nSCPY 6619 Individual Intelligence Testing (3 cr)\nSCPY 6673 Response to Intervention Methods (3 cr)\nEDUC 6610 Applied Educational Statistics (3 cr)\nEDUC 6601 Research and Writing (3 cr)\nSpring Semester (10 Graduate Credits)\nSCPY 6682 Cognitive Behavioral Intervention in Schools (3 cr)\nSCPY 6668 Practicum: Intro to School Psych, SPED & LD (3 cr)\nSCPY 6657 Legal and Ethical Issues in School Psychology (2 cr)\nSCPY 6659 Multicultural Issues in School Psychology (2 cr)\nWhat does it look like?\n- Data-Based Decision Making:Our students will be able to impact children through the collection, interpretation, and use of data. They will be able to use this data to create appropriate interventions.\n- Consultation & Collaboration:Our students will be able to indirectly impact children through consultation and collaboration with teachers, families, systems, etc.\n- Support of Academic Skills:Our students will be able to impact children through their expertise in learning and developmental theory, and academic intervention strategies.\n- Support of the Mental Health, Social & Life Skills:Our students will be able to impact children through their expertise in mental health.\n- School-Wide Interventions:Our students will be able to indirectly impact children through their knowledge of system theory and their expertise in the creation of system wide change.\n- Preventative & Responsive Services:Our students will be able to impact children through their knowledge of resiliency, protective and risk factors and their experiences in implementing preventative services.\n- Family-School Collaboration:Our students will be able to impact children through their ability in bridging the connection between school and family.\n- Diversity Practice:Our students will be able to impact children through their awareness, knowledge, and skills in the area of diversity. This competency is imbued throughout their practice. They will be seen as a beacon of inclusion and culturally competent practice.\n- Research & Evaluation:Our students will be able to impact children through their knowledge of research, statistics, and program evaluation. They will be able to use this information to make real world positive impact within the schools.\n- Legal & Ethical Practice:Our students will be able to impact children through advocacy and ethical practice. They will standup for the rights of our students and always perform in a legally and ethically exemplary manner.\nDr. Joel Bocanegra\nAssociate Professor of School Psychology\nOffice: College of Education 108A"", ""Abstract. School psychologists routinely engage in ethical decision making, and existing models have served as useful tools for systematically approaching ethical dilemmas. However, few of these models have taken account of the rich and salient body of social psychology research. This article reviews social psychological phenomena that present clear implications for school-based ethical decision making and, in light of such applications, provides recommendations for practicing school psychologists. Case examples are provided to illustrate key concepts.\nSchool psychologists operate in ecosystemic contexts that offer unique challenges (Borgelt & Conoley, 1999; Curtis & Stollar, 2002; Lusterman, 1992). Moreover, the practice of psychology in the schools presents a number of ethical concerns that are specific to the nature of working with teams, systems, and groups. School psychologists must frequently navigate systems' boundaries, conflicting values and beliefs, and multiple roles. As assessors, consultants, counselors, and administrators, school psychologists routinely address complex issues of privacy, confidentiality, informed consent, and multiple relationships when working with students, parents, teachers, administrators, and other school personnel. Therefore, understanding ethical decision making in the context of social, organizational, and family systems necessitates an understanding of social influence. This article addresses the influence of relevant social psychological phenomena on school psychologists' ethical decision making, examines the potential effects of specific constructs in social psychology, and presents case examples to illustrate the constructs' potential emphasis on ethical decision making. The article concludes with recommendations for practice.\nEthical codes and standards such as the American Psychological Association's (2002) Ethical Principles of Psychologists and Code of Conduct, the National Association of School Psychologists' (2000) Principles for Professional Ethics, and the American Educational Research Association, American Psychological Association, and National Council on Measurement in Education's Standards for Educational and Psychological Testing (1999), and legal constraints including federal, state, and statutory regulations provide frameworks for distinguishing ethical conduct from unethical conduct. However, school psychologists, by virtue of the unique contexts of their work, frequently experience vexing ethical dilemmas that are not adequately addressed by existing codes. To address these more difficult decisions, psychologists have developed ethical decision-making models.\nThe purpose of ethical decision-making models is to provide practitioners with a systematic, organized way of addressing ethical concerns. A variety of existing models share common features. Generally, these models involve an initial conceptualization of the problem's parameters, gathering additional data, consultation with peers, cost-benefit analysis, commitment to a decision, and ongoing monitoring (Haas & Malouf, 1989; Koocher & Keith-Spiegel, 1998). The advantage of the decision-making models is that they promote careful study of the dilemma, thoughtful consideration of potential pitfalls, and documentation that the final decision was made using a rational process. However, one disadvantage of ethical decision-making models is that they often fail to address the effects of significant and powerful social psychological phenomena on the contexts in which ethical dilemmas arise. Although social psychology research has been applied broadly to the practice of school psychology (Medway & Cafferty, 1992, 1999), the specific implications for ethics have not yet been addressed. The need to address the ethical decision making of school psychologists through an understanding of social psychological phenomena is significant because such decisions occur in social contexts. …""]"	['<urn:uuid:e67b6dc1-0591-4a34-831e-ce863e641051>', '<urn:uuid:e97c21c6-d185-4f44-b452-04a07227595f>']	factoid	direct	verbose-and-natural	similar-to-document	multi-aspect	expert	2025-05-13T04:02:16.770989	21	75	1309
59	What are the current limitations of the Varian 810 ICP-MS system?	The Varian 810 ICP-MS cannot operate without dedicated ventilation for both the machine itself and its water chiller. It also requires a fume hood for safe sample preparation with acids.	['At the Lab, we have several instruments that require proper laboratory conditions and safety equipment. Lab conditions can mean a number of things depending on the instrument, but here’s a quick idea of some of the things that are often required:\n- Stable temperature\n- Clean air, positive pressure\n- Ventilation of fumes\n- Fire Safety Cabinets\nOur Lab, Today\nWe have a small office space that we work out of today. It is a great space, but ultimately, not a laboratory. We do have several pieces of equipment within the space that are currently available:\n- One of, if not the only, publicly accessible Scanning Electron Microscopes in the US.\n- Optical Microscopy, capable of brightfield, as well as Phase-contrast, and Darkfield.\n- Gamma Spectroscopy Equipment\n- CNC Prototyping equipment, including 3D printing and access to an Abrasive Waterjet Machining Center.\nOur Lab, moving forward\nWe believe providing access to test, measurement, and analysis equipment is vital to advancing science, whether this is in the context of citizen science or academia. Often times, barriers to carrying out important research involve access to equipment and funding. Our mission is to facilitate that access.\nUnfortunately, some of these instruments cannot operate to their full potential, and others not at all, until we meet the requirements necessary to operate the equipment safely and properly. While we have accomplished a tremendous amount by pooling together our knowledge, resources, equipment and tools, the construction of a proper laboratory will require building materials, supplies and consumables for the equipment.\nFirst and foremost, we need to address fume extraction and ventilation.\nScanning Electron Microscopy\nAnalytics Lounge received a donation of a Leica S430 Scanning Electron Microscope, capable of secondary electron and backscatter imaging, as well as Energy Dispersive X-ray (EDX) spectroscopy, from Pumping Station: One, NFP. This enables imaging samples at scales smaller than the wavelength of visible light, as well as determining elemental analysis via EDX.\nWe are currently unable to image wet organic specimens. Generally accepted laboratory procedures to do so require first fixing the specimen using chemicals such as glutaraldehyde, paraformaldehyde, osmium tetroxide, etc., followed by dehydration in ethanol, critical point drying, and sputter coating. Analytics Lounge already owns a Hummer sputter coater and has a Tousimis critical point dryer on loan. However, fixing specimens safely requires use of a fume hood, as the chemistry necessary is toxic and volatile. We will need to acquire a fume hood and adequate ventilation.\nAnalytics Lounge acquired a Varian 810 ICP-MS as a donation from the Field Museum. We were told that this equipment is fully functional. It will enable elemental analysis, including detecting trace elements such as pollutants in drinking water or soil.\nICP-MS creates an extremely hot plasma. The machine itself requires significant ventilation. It also uses a water chiller, which produces heat that must be vented. This equipment cannot operate without dedicated ventilation. This must be addressed before we can operate this instrument. Additionally, samples often must be dissolved in acid. Doing this safely requires a fume hood.\nGraphite Furnace AAS\nAnalytics Lounge acquired two Perkin-Elmer graphite furnace Atomic Absorption Spectrophotometers. While neither are currently in a functional state, we have reason to believe that all critical systems in one of them are operational. Remaining work requires obtaining appropriate tubing, graphite tubes, and repairing the drive mechanism of the autosampler. This instrumentation is similar to ICP-MS in that it can quantify the presence of specific elements, which would be useful for trace elemental analysis. Having both ICP-MS and AAS functional would enable confirming results. However, this requires calibration solutions, often made by dissolving the element being measured in acid, and diluting it. This process requires a fume hood. We would also need an analytical balance to measure the mass of specimens and materials used for calibration solutions.']	['<urn:uuid:0ae413e1-26f9-4e88-93f6-8697b80befcb>']	factoid	with-premise	concise-and-natural	similar-to-document	single-doc	expert	2025-05-13T04:02:16.770989	11	30	634
60	I heard about this thing called 'corporate veil' but I'm not sure what it means - is it the same thing as making a company legally separate from the people who own it?	Yes, the corporate veil is exactly the concept of separating a company's identity from its members/owners. This separation means the company is recognized as its own legal person that can sue and be sued, enter contracts, open bank accounts, and continue operating after its owners die. This separation was a crucial development that made modern business possible - before the corporate veil, business owners risked their personal assets if their company failed, and could even face debtor's prison. However, courts can 'lift' or 'pierce' this veil if owners commit fraud or use the company for illegal activities, making them personally liable for the company's actions.	['LLC Asset Protection Checklist\nMaximize Your LLC Benefits\nLimited liability companies are highly sought after due to their asset protection benefits. Wyoming exceeded other states by intentionally crafting laws meant to further enhance the benefits of forming an LLC.\nIt is important to understand the laws in Wyoming are not loopholes. They were intentionally written to be taken advantage of. Wyoming was the first state to allow LLCs and continues leading the world to this day.\nGenerally, LLCs offer two forms of asset protection. The first is personal protection from business creditors, and the second is protecting business assets from personal creditors. The first form of asset protection is known as the corporate veil.\nThe business entity is considered its own person under the eyes of the law. It may enter contracts, open bank accounts and carry on after its owners die. This degree of separation from the owners is what provides asset protection. The liabilities of the LLC are solely those of the LLC. They do not pass through to the owners.\nThis means your company can go bankrupt without affecting your personal finances. The company’s creditors cannot sue or otherwise pursue the company’s owners. This feature is intentional and, in part, made modern business possible.\nOther states provide judges ample opportunity to pierce the corporate veil. Common reasons for piercing the veil are fraud, criminal acts and using the LLC as an alter ego.\n- If you commit fraud, then the corporate veil will not protect you, e.g. lying on a loan application or embezzling funds.\n- If you drive drunk in a company car and have an accident, then both you and the company will likely be sued. The LLC will afford no protection.\n- If the judge rules you never obeyed corporate formalities, then the LLC may be disregarded. E.g., not properly titling property or comingling funds. This is an increased risk for Single Member LLCs in states other than Wyoming.\nPrior to the corporate veil, individuals were discouraged from starting businesses or otherwise taking risk. If a company failed, not only would the initial equity investment be at risk, but personal assets could be seized as well. This, along with debtor prisons, made doing business before the corporate veil a precarious endeavor.\nProtection from Personal Creditors\nWyoming LLCs also offer superior protection from personal creditors. Other states make it easy for personal creditors to seize your membership interest. They may then vote, force asset sales and make distributions to themselves.\nThis means your LLC will not be protected from personal risks such as car accidents. Other states offer varying degrees of protection for multi-member LLCs, but none have specific protections for Single Member LLCs as Wyoming does.\nWyoming provides charging order protection for all LLCs. This means creditors cannot obtain an order allowing them to seize control of the company. They may only seize distributions IF they occur. If a charging order is secured, then you may keep your funds inside the company. This allows you to continue growing the company.\nIt also provides a powerful bargaining chip. Since a creditor cannot easily access funds inside the LLC they are more likely to settle. It becomes a waiting game with you holding all of the money.\nIf properly structured, you may make payments to other LLCs you own through either debt repayments or service contracts, for example. Through preferential payments you reduce the funds available to creditors.\nThese protections provide a strong deterrent to lawsuits in the beginning. Creditors know they do not have an easy path to securing a judgement and attaching it to assets. This often deters all but the most determined of creditors.\nOne issue not covered above is protecting business assets from business liabilities. It would be nice if insurance operated as a catch all, but it does not. Insurance may be inadequate, lapse or the insurance company may simply refuse to pay.\nSetting up a holding company and subsidiaries enhances the above protections. A holding company and its subsidiaries can be thought of as a “Double LLC”. This means there are two layers of protection from personal and business creditors.\nAn accident with an operating company would have to pierce both the operating LLC’s veil and the holding company’s before reaching you. This is exceedingly unless there has been fraud.\nThe charging order protection is also amplified through a holding company. The operating subsidiaries will be unaffected and may continue to transfer funds between themselves and invest as needed.\nWhile Wyoming LLCs offer excellent asset protection, they do have shortcomings. Insurance also cannot be expected to cover everything. Those with significant assets, or in risky industries, should consider establishing an an asset protection trust or a 401k. These vehicles provide additional asset protection, including from the government, while offering tax benefits', 'By Rhea Sinkar ~ DES Law College\nThe separation of the identity of a company from its members is known as the concept of the corporate veil. What this does is the members of the company are free from liability of any acts committed on behalf of that company. The veil shelters defaulters from violating laws and the members enjoy unreasonable immunity. The concept of corporate veil and recognizing the company as a separate entity/distinct from its members came into existence through: Salomon vs Salomon &Co Ltd (1897) AC 22]. This is currently in practice throughout the globe in different forms.\nThe concept recognizes the company as a separate legal person which means that the company can sue and be sued. However, executives in certain companies started using the veil to cover up their frauds and the courts have recognized this decision that certain members should be held responsible individually for their acts of misconduct. This is known as the lifting of the corporate veil which now has gained statutory recognition through the Companies Act,2013.\nLifting the Corporate Veil:\nThe concept of Corporate veil recognizes the company as a separate entity from its members. However it fails to recognize the fact that although a company is an artificial legal entity, its functioning and day to day affairs is run by its members. However, the disadvantage, in this case, is if a director/shareholder commits fraud or takes part in illegal activities, it is unfair to hold the company responsible as a separate entity which is when the corporate veil needs to be pierced and the director/person responsible should face the charges for committing the offenses.\nIn the case of the United States vs. Milwaukee Refrigerator Transit Company, it was held that ‘an organization shall be looked as a separate entity as a general rule unless there is sufficient reason for the contrary. If it appears that the veil is used to justify a wrong, protect fraud, or defend crime, the law will regard the corporation as an association of persons.’[i]\nIn Santanu Roy vs Union of India, the court held that the corporate veil can be lifted by authorities to determine which director is responsible for evading tax by fraud and wilful suppression of facts or violation of laws. [ii]\nIn Delhi Development authority vs Skipper Construction company, it was held that where individuals claim corporate immunity to commit illegal acts and defraud others, the court would ignore the corporate character and lift the company’s veil.[iii]\nIn Subhra Mukherjee vs Bharat Coking Coal Ltd, on intimation of nationalization, the company moved its immovable assets to the director’s wives accounts. The court held that the transaction was not made in the best interests of the company but slyly by the directors and lifted its corporate veil.[iv]\nWhen can the corporate veil be lifted: Statutory provisions under the Companies Act-\n- Section 7(7):\nIf a Company is incorporated by furnishing false information or by suppressing material facts or information in any documents, the court may choose to lift the corporate veil and hold members liable for their defaults.[v]\n- Section 26(9):\nIt says that if false statements are furnished in the prospectus for the sale of securities, the company shall be fined with Rs 50,000 up to Rs 3,00,000 and the members of the company who knowingly participate in the act shall be imprisoned for a period which may extend to 3 years or a fine of Rs 50,000 up to Rs 3,00,000 or both. This provision lifts the corporate veil and holds persons individually responsible for any contraventions.[vi]\n- Section 34 &Section 35:\nSection 34 imposes criminal liability for making any misleading statement in the prospectus by way of omission or inclusion and Section 35 imposes civil liability for making any misleading statements because of which the company sustains any losses or damages.[vii]\n- Section 39(3):\nIt makes a provision against allotment of securities. If the sum to be paid on the application is not received within 30 days from the date of issuance of the prospectus, the officer in default is fined with a sum of Rs 1000 for each day of continuance of the default or Rs 1,00,000 whichever is less.[viii]\n- Section 216 & Section 219:\nThe Government has the authority to lift the corporate veil and check the legitimacy of the company and find out the members of the company responsible for the day to day working, finances, and the success and failure of the company. Both sections have a similar purpose.[ix]\n- Section 339:\nIn course of winding up of a company, if it is found that it was involved in any fraudulent transactions, unlawful activities, the Court is empowered to lift the corporate veil and hold the person responsible, liable for such acts.[x]\n- Section 447 & Section 448:\nIf in any return, report, certificate, financial statement, prospectus, or any other documents any false statement/concealment of material fact has been done, the guilty person responsible for such a release in the company’s name shall be found by lifting the corporate veil and held liable.[xi]\nThe doctrine of corporate governance creates a check on the activities of a corporation which acts as a dangerous weapon against defaulters who seek protection behind the company’s veil. The statutory provisions make sure that there is no blame game and that illegal activities/transactions come to a complete halt. The punishments and fines provided by the act increase the potency and makes sure that businesses carry out activities with complete transparency. However, courts need to apply the doctrine only in situations where it is of utmost necessity.\n- [i] United States vs Milwaukee,(1905) 142F,edn.244.\n- [ii]SantanuRoyv Union of India, 1989 65 CompCas 196 Delhi.\n- [iii] Delhi Development Authority vs Skipper Construction Company, 1996 AIR 2005, 1996 SCC (4) 622.\n- [iv]Subhra Mukherjee vs Bharat Coking Coal Ltd, AIR 2000 SC 1203\n- [v]Companies Act,2013,Act No.18, Acts of Parliament,2013, Section 7(7).\n- [vi]Companies Act,2013,Act No.18, Acts of Parliament,2013, Section 26 (9).\n- [vii]Companies Act,2013,Act No.18, Acts of Parliament,2013, Section 34, Section 35.\n- [viii]Companies Act,2013,Act No.18, Acts of Parliament,2013, Section 39(3).\n- [ix]Companies Act,2013,Act No.18, Acts of Parliament,2013, Section 216, Section 219.\n- [x]Companies Act,2013,Act No.18, Acts of Parliament,2013, Section 339.\n- [xi]Companies Act,2013,Act No.18, Acts of Parliament,2013, Section 447, Section 448.']	['<urn:uuid:3cf33362-a75b-4e03-b974-a33c0aa8e659>', '<urn:uuid:0a50eaa6-9fff-450a-80b6-858a5b302ab0>']	factoid	with-premise	verbose-and-natural	distant-from-document	comparison	novice	2025-05-13T04:02:16.770989	33	105	1851
61	I need help understanding computers. What's good about digital technology and how is it related to true/false logic?	Digital technology has several advantages: it's more reliable, easier to design, cheaper than analog circuits, and offers high speed and programmability. These digital systems work based on Boolean logic, which deals with true/false values (represented as 1's and 0's). Boolean algebra is the fundamental basis of modern digital computers, where logic gates process these true/false values using electronic switches to perform computations.	"['What do you mean by digital electronics?\nDigital electronics is a field of electronics involving the study of digital signals and the engineering of devices that use or produce them. This is in contrast to analog electronics and analog signals. … Complex devices may have simple electronic representations of Boolean logic functions.\nWhat is the importance of digital electronics?\nDigital electronic circuits are main thing in digital electronics which is usually made from large assemblies of logic gates. The system which process discrete values is known as digital system. The significance of digital electronics is that are inherently more reliable than analog, in terms of information processing.\nWho is the father of digital electronics?\nProfessor Emeritus Claude E. Shannon\nHow does digital electronics work?\nDigital electronics are electric circuits that work on only two fixed values: “1” and “0”. They use a series of 1’s and 0’s to store and communicate information. They can also perform math using just 1’s and 0’s. This is called Boolean math or Boolean logic.\nWhat mean electronics?\nElectronics comprises the physics, engineering, technology and applications that deal with the emission, flow and control of electrons in vacuum and matter.\nWhat is the best example of digital system?\nThe digital computer, more commonly called the computer, is an example of a typical digital system. A computer manipulates information in digital, or more precisely, binary form.\nWhat are the advantages of digital electronics over analog electronics?\nAdvantages of Digital Communication\nDigital circuits are more reliable. Digital circuits are easy to design and cheaper than analog circuits. The hardware implementation in digital circuits, is more flexible than analog.\nWhere are digital circuits used?\nDigital circuits are the most common mechanical representation of Boolean algebra and are the basis of all digital computers. They can also be used to process digital information without being connected up as a computer. Such circuits are referred to as “random logic”.\nWhat are the advantages of digital system?\nAdvantages of Digital Systems\n- Ease of programmability. The digital systems can be used for different applications by simply changing the program without additional changes in hardware.\n- Reduction in cost of hardware. …\n- High speed. …\n- High Reliability. …\n- Design is easy. …\n- Result can be reproduced easily.\nWhat was the first electronics?\nThe first electronic device ever invented is the relay, a remote switch controlled by electricity that was invented in 1835 by Joseph Henry, an American scientist, although it is also claimed that the English inventor Edward Davy “certainly invented the electric relay” in his electric telegraph c. 1835.\nWhat is the history of electronics?\nElectronics’ actual history began with the invention of vacuum diode by J.A. Fleming, in 1897; and, after that, a vacuum triode was implemented by Lee De Forest to amplify electrical signals. This led to the introduction of tetrode and pentode tubes that dominated the world until the World War II.\nWhat are examples of electronics?\nElectronic equipment, systems, etc. Electronics is defined as devices run by electric power or the field of studying such items. An example of electronics are radios, computers, and televisions.\nWhat comes under digital electronics?\n- Number System and Representation :\n- Programs :\n- Boolean Algebra and Logic Gates :\n- Gate Level Minimization :\n- Combinational Logic Circuits :\n- Flip-Flops and Sequential Circuits :\n- Register and Counters :\n- Memory and Programmable Logic :\nWhat is the difference between analogue and digital electronics?\nAnalog Circuits and Digital Circuits is a classic way of differentiating between two types of electronic circuits based on the signals they process. To put it in simple words, Analog Circuits deals with continuous analog signals whereas Digital Circuits deals with discrete digital signals.', 'There are two main reasons mathematics has fascinated humanity for two thousand years. First, math gives us the tools we need to understand the universe and build things. Second, the study of mathematical objects themselves can be beautiful and intriguing, even if they have no apparent practical applications.\nWhat\'s truly amazing is that sometimes a branch of math will start out as something completely abstract, with no immediate scientific or engineering applications, and then much later a practical use can be found.\n""And,"" ""Or,"" ""Not""\nBoolean algebra is the combination of logic and algebra, initially developed by George Boole, for whom the subject is named, in the 1840s and \'50s, and later refined by other logicians through the rest of the nineteenth and early twentieth centuries.\nFormal logic concerns itself with the truth or falseness of statements, or propositions. ""Barack Obama is the President of the United States"" is a proposition that is true. ""Google manufactures the iPhone"" is a proposition that is false.\nThings get more interesting when we start combining simple propositions together. ""Barack Obama is the President of the United States, and Joe Biden is the Vice President"" is true, since the two simple propositions joined by the ""and"" in the middle are both true. ""Either Texas has a population of 300, or television was invented by Issac Newton"" is false, since the two simple propositions joined by the ""or"" in the middle are both false.\nBoolean algebra, and other forms of abstract propositional logic, are based on dealing with compound propositions made up of simple propositions joined by logical connectors like ""and"", ""or"", and ""not"". All that matters for telling whether such a compound statement is true are the abstract truth values of the component propositions and formal rules based on which logical connectors we\'re using.\nFor example, if proposition X is true, and proposition Y is true, then the compound proposition ""X and Y"" is also true. If either X or Y is false, or both are false, then ""X and Y"" is also false.\nBoole recognized that this kind of logic based on combining symbols for propositions using connectors like ""and"", ""or"", and ""not"" had a similar structure to normal algebra and arithmetic. In normal algebra, variables representing numbers get combined together into formulas and equations by using the arithmetic operations of addition, subtraction, multiplication, and division.\nIn Boole\'s logical algebra, variables representing logical propositions get combined into formulas and equations by using the logical operations of and, or, and not. The statement ""X and Y is true"" gets converted into the equation X × Y = 1. The statement ""X or Y is false"" becomes X + Y = 0.\nBoolean algebra makes it possible to use the same kinds of algebraic techniques we use to solve normal equations involving numbers to establish logical relationships. By solving Boolean equations, logicians can more easily see when one combination of propositions logically leads to another.\nA Hundred Years Later\nIf this seems extremely abstract, it is. Logic has always straddled the line between philosophy and mathematics, attempting to reason about the way we can reason, and getting at fundamental ideas about what truth is and how to be sure we know things. While fascinating, propositional logic and Boolean algebra initially belonged strictly to the realm of pure mathematics, with fewer applications than a branch of math like differential equations and calculus, which are at the foundation of our understanding of physics.\nRemarkably, about a century after Boole\'s initial investigations, mathematicians and scientists discovered an extremely powerful set of applications for formal logic, and now this apparently abstract mathematical and logical tool is at the heart of the global economy.\nBoolean algebra — taking true and false values, manipulating them according to logical rules, and coming up with appropriate true and false results — is the fundamental basis of the modern digital computer.\nOne of the first major applications of Boolean algebra came from the 1937 master\'s thesis of Claude Shannon, one of the most important mathematicians and engineers of the 20th century. Shannon realized that switches in relay networks, like in a telephone network, or an early proto-computer, could be easily described by viewing ""on"" switches has having a Boolean value of ""true"", ""off"" switches as having a Boolean value of ""false"", and with the different patterns in which switches are connected to each other corresponding to the Boolean operations of ""and"", ""or"", and ""not"".\nShannon\'s innovation made the design of switch networks vastly easier: rather than needing to actually play around with network connections themselves, the techniques developed by Boole and his successors provided a mathematical framework allowing for more efficient network layouts.\nThe connection between electrical switches and boolean algebra goes in the other direction as well. A computer\'s CPU is largely built out of logic gates: physical manifestations of Boolean operators. Logic gates take in one or more electrical Boolean values: a wire with a high voltage might represent ""true"", and a wire with a low voltage might represent ""false"". The output of the logic gate, calculated using the electronic properties of semiconductors, is the appropriate voltage from the desired Boolean operation.\nAn ""and"" gate, for example, takes in two inputs. If both inputs are high voltage (representing ""true""), the ""and"" gate has a high voltage output of ""true"" as well, while if either or both inputs are low voltage, or false, the gate will have a low voltage output of false.\nPutting these gates together in the right ways allows for the execution of computer programs. Being able to perform Boolean operations on various inputs essentially allows a CPU to decide how to handle those inputs.\nFurther, this Boolean algebra embedded in computers comes back around to normal math. The Boolean dichotomy of true vs. false lends itself nicely to the representation of binary numbers: true corresponds to 1, and false maps to 0. Under this interpretation, it\'s possible to assemble Boolean circuits that, simply by correctly combining two binary input numbers using and, or, and not operations, can add, subtract, multiply, or divide numbers.\nSometimes, developments in pure math can, decades or centuries later, turn out to have amazing applications.']"	['<urn:uuid:2ef0d142-6efc-4541-a88c-a4f4ca868f7d>', '<urn:uuid:5c522917-85ba-4ed1-96b0-b17921c9e78c>']	factoid	with-premise	concise-and-natural	distant-from-document	multi-aspect	novice	2025-05-13T04:02:16.770989	18	62	1653
62	As someone new to art history, I'm trying to understand how Aestheticism and the Arts and Crafts movement differed in their views about the purpose of art - what were their main goals?	Aestheticism believed art should exist purely for beauty and aesthetic satisfaction, emphasizing form over subject matter and often creating poems that weren't really 'about' anything. In contrast, the Arts and Crafts movement had a practical purpose, aiming to revive decorative arts and integrate beauty with everyday life objects. They focused on hand fabrication and creating beautiful objects of utility, driven by both aesthetic and social reform goals.	"['[The following passage comes from the author\'s John Evelyn Barlas, A Critical Biography: Poetry, Anarchism, and Mental Illness in Late-Victorian Britain (2012) — George P. Landow.]\nWith alienation as the point of departure, the Aesthetic and Decadent approaches to life and art branch off, or at least settle at different places along a continuum of attitudes toward the society left behind and the prison of consciousness. At least on a theoretical level, the Aesthete may be blissfully indifferent to the forsaken social world. Through astute and highly selective observation, he can draw pleasing sensations and impressions from it, though for him it has a lower potential yield than art. He need not hate the world. He has retreated to art and inaction in pursuit of beauty. Morality is simply irrelevant.\nAestheticism places greater emphasis on the creation of art and stresses form over subject matter. Poetry in this vein often relies on intricate verse forms, mostly French, which present demanding technical requirements and feature verbal music, including insistent rhyme and repetition. Aesthetic verse also empnasizes visual description and color. The Aesthetic alientaion and retreat from life are recapitulated in the verse itself, often through exotic setting or subject matter from the long-distant past that, in turn, originates more in literature, legend, and myth than in history. As the medium is to certain extent the message, the French verse forms, almost all of which derive from the troubadours, suggestively heighten the separation from the present. The purest Aesthetic poems are not really ""about"" anything. form, sound, image, and mood dominate to the extent that little or no room remains for ideas. In England, the Aesthetic impulse found a voice, even before it had been labeled, in a handful of brilliant seminal poems by Tennyson, including the archetypal ""The Lotos-Eaters"" It also produced the accomplished parlor verse of Austin Dobson, Andrew Lang, and their ilk. Such poems are given over entirely to the evocation of beauty and aesthetic satisfaction, within the constricted, detached, amoral realm of art. The dominant notes of Aestheticism are escape, fantasy, detachment, passivity, reverie, and harmony,\nThe Decadent, in contrast, wages a guerilla war against the dominant culture. He defines himself through conflict and contrast. Having erected, or accepted, the same barriers against life as the Aesthete, he then attacks. Through his efforts epater le bourgeoisie, he expresses his contempt for prevailing values and sensibilities and asserts his sense of superiority and the amorality of art. This aggressive stance toward society conveys the artist\'s alienation. At the same time, however, the attack, often in the form of intimate self-revelation, suggests both engagement in one of its most direct forms, and powerful communication, rather than the silence of separation. If society considers sexual relations, even between husband and wife, a private matter bordering on taboo, the Decadent may devote a poem to a graphic, intimate description of a night with a prostitute. But of course the attack itself serves at very least to underscore the force and dominance of mainstream morality, if not to concede its validity. The paradox, or self-contradiction, plays throughout perhaps the greatest English expression of Decadent thought and art. The Picture of Dorian Gray. In the ""Preface,"" added after initial publication, Wilde boldly asserted; ""There is no such thing as a moral or an immoral book. Books are either well written, or badly written. That is all."" In this statement of art for art\'s sake, he defended his book against moral criticism of its subject matter, arguing that morality is irrelevant to art. Yet the book he sought to rescue from moral judgment is itself a moral condemnation of all aspects of the very tempting, attractive Decadence, including the effort to view and live life as if it were art and therefore beyond good and evil. [214-15]\nCohen, Philip. John Evelyn Barlas, A Critical Biography: Poetry, Anarchism, and Mental Illness in Late-Victorian Britain. Rivendale Press, 2012. [review]\nLast modified 5 December 2012', 'arts and crafts(redirected from Art and craft)\nAlso found in: Dictionary, Thesaurus.\narts and crafts,term for that general field of applied design in which hand fabrication is dominant. The term was coined in England in the late 19th cent. as a label for the then-current movement directed toward the revivifying of the decorative arts. The chief influence behind this movement was William MorrisMorris, William,\n1834–96, English poet, artist, craftsman, designer, social reformer, and printer. He has long been considered one of the great Victorians and has been called the greatest English designer of the 19th cent.\n..... Click the link for more information. . By the mid-19th cent., factory processes had almost entirely driven artisans from their ancient trades and threatened to obliterate the techniques they used to produce beautiful objects of utility. The Gothic revivalGothic revival,\nterm designating a return to the building styles of the Middle Ages. Although the Gothic revival was practiced throughout Europe, it attained its greatest importance in the United States and England.\n..... Click the link for more information. , however, had brought into existence a great body of knowledge concerning the arts of the Middle Ages, and Morris, together with the Pre-RaphaelitePre-Raphaelites\n, brotherhood of English painters and poets formed in 1848 in protest against what they saw as the low standards and decadence of British art. The principal founders were D. G. Rossetti, W.\n..... Click the link for more information. painters and a small group of architects and designers, returned to these arts as a rich source of inspiration.\nThe pupils and followers of Morris multiplied, and proficient artisans developed. Their methods aimed at a practical demonstration not only of Morris\'s aesthetic creed but also of his ideas concerning socialism and the moral need for integrating beauty with the accessories of daily life. The aesthetic and political aspects of the arts and crafts movement influenced the development of modernism, particularly as they were later reflected in the core philosophy of the BauhausBauhaus\n, artists\' collective and school of art and architecture in Germany (1919–33). The Bauhaus revolutionized art training by combining the teaching of classic arts with the study of crafts.\n..... Click the link for more information. . The revival of folk arts has continued to prosper in some quarters, especially in remote communities and among Native Americans of the Southwest and the Eskimos (see North American Native ArtNorth American Native art,\ndiverse traditional arts of Native North Americans. In recent years Native American arts have become commodities collected and marketed by nonindigenous Americans and Europeans.\n..... Click the link for more information. ).\nA less aestheticized version of the arts and crafts movement was important in the United States, where it spread from England and flourished from the late 19th cent. to about 1915. It was prominent in American architecture and design, notably in the buildings and interiors of Greene and GreeneGreene and Greene,\narchitectural firm working in the American arts and crafts style, formed by the brothers Charles Sumner Greene, 1868–1957, and Henry Mather Greene, 1870–1954, both b. Brighton (now part of Cincinnati), Ohio.\n..... Click the link for more information. and in the ""mission-style"" oak furniture of Gustav StickleyStickley, Gustav,\n1858–1942, American furniture designer, b. Osceola, Wis. Probably the best-known American associated with the arts and crafts movement, Stickley ran a Binghamton, N.Y., chair factory in the 1880s.\n..... Click the link for more information. (1858–1942) and his contemporaries. The movement\'s precepts were also applied to ceramics, glassware, utensils, and other objects of American daily life. The arts and crafts movement also spread to continental Europe, where it was quite influential during the late 19th and early 20th cent.']"	['<urn:uuid:4ad692fc-55fe-4c33-a89d-879c61b9fea8>', '<urn:uuid:29596280-4f79-4a5c-9bfe-1002df853a3b>']	factoid	with-premise	verbose-and-natural	similar-to-document	comparison	novice	2025-05-13T04:02:16.770989	33	67	1269
63	how many scholars experts contributed research papers book iran deccan	Iran and the Deccan features 14 essays written by an interdisciplinary group of 18 scholars. These scholars specialized in various fields including history, art and architectural history, literatures and languages, and book arts and conservation.	['Keelan Overton, ed. Iran and the Deccan: Persianate Art, Culture and Talent in Circulation, 1400-1700. Bloomington, IN: Indiana University Press, June 2020.\n468 pages, 8.50 x 10.00 in, 144 color illustrations\nISBN 9780253048912, paperback only\nIran and the Deccan features 14 essays by an interdisciplinary cast of 18 scholars specializing in history, art and architectural history, literatures and languages, and book arts and conservation.\nPublication of the book has been supported by grants from the College Art Association (Millard Meiss Publication Fund) and Persian Heritage Foundation (PHF).\nIn the early 1400s, Iranian elites began migrating to the Deccan plateau of southern India. Lured to the region for many reasons, these poets, traders, statesmen, and artists of all kinds left an indelible mark on the Islamic sultanates that ruled the Deccan until the late seventeenth century. The result was the creation of a robust transregional Persianate network linking such distant cities as Bidar and Shiraz, Bijapur and Isfahan, and Golconda and Mashhad.\nIran and the Deccan explores the circulation of art, culture, and talent between Iran and the Deccan over a three-hundred-year period. Its interdisciplinary contributions consider the factors that prompted migration, the physical and intellectual poles of connectivity between the two regions, and processes of adaptation and response. Placing the Deccan at the center of Indo-Persian and early modern global history, Iran and the Deccan reveals how mobility, liminality, and cultural translation nuance the traditional methods and boundaries of the humanities.\nNote to the Reader\nList of Abbreviations\n- Introduction to Iranian Mobilities and Persianate Mediations in the Deccan / Keelan Overton\n- Iran and the Doors to the Deccan, ca. 1400–1650: Some Aspects / Muzaffar Alam and Sanjay Subrahmanyam\n- Excerpt on Yusuf Beg ‘Adil Khan, from Rafi’ al-Din Shirazi’s Tazkirat al-Muluk / Translated by Wheeler Thackston\n- Ghariban in the Deccan: Migration, Elite Mobility, and the Making and Unmaking of an Early Modern State / Roy S. Fischel\n- Dynastic Self-Fashioning and the Arts of the Pen: Sufi and Calligraphy Networks between Fifteenth-Century Shiraz and Bidar / Peyvand Firouzeh\n- From Iran to the Deccan: Architectural Transmission and the Madrasa of Mahmud Gavan at Bidar / Sheila Blair and Jonathan Bloom\n- Qur’an Manuscript No. 106 Copied by ‘Abd al-Qadir al-Husayni al-Shirazi and Endowed to the Shrine of Imam Riza by Ibrahim Qutb Shah / Maryam Habibi, translated by Arash Khazeni\n- Vaqfnama of Ibrahim Qutb Shah in the ‘Abd al-Qadir Qur’an Manuscript Endowed to the Shrine of Imam Riza / Translated by Jake Benson\n- Faith and Fate: The Khalili Falnama and Shi’i Identity in Golconda / Rachel Parikh\n- Indo-Persian Histories from the Object Out: The St Andrews Qur’an Manuscript between Timurid, Safavid, Mughal, and Deccani Worlds / Keelan Overton and Kristine Rose-Beers (with contributions by Bruce Wannell)\n- The Qit’at-i Khushkhatt Album: Authenticity and Provenance / Jake Benson\n- Khalilullah “Padishah of the Pen”: Royal Scribe and Ambassador of Shah ‘Abbas and Ibrahim ‘Adil Shah II / Hamidreza Ghelichkhani, translated by Kimia Maleki and Jake Benson\n- Forging a Canon of Dakhni Literature: Translations and Retellings from Persian / Sunil Sharma\n- On Heroes and History: Responding to the Shahnama in the Deccan, 1500–1800 / Subah Dayal']	['<urn:uuid:1d5016ad-7edf-496e-969f-179a7c6268e8>']	open-ended	direct	long-search-query	distant-from-document	single-doc	novice	2025-05-13T04:02:16.770989	10	35	532
64	I love old books - how do you protect them from insects?	To protect manuscripts from insects, they should be placed in an airtight container with para-dichlorobenzene covering the base for at least one week. The manuscripts should be supported above the insect repellant using bricks or stones. Additionally, cedarwood oil can be applied to provide extra protection, and insect repellant should be placed in storage boxes.	"['CAMBODIAN PALM-LEAF MANUSCRIPTS:\nPROCEDURES FOR CONSERVATION\nThe manuscripts have been largely stabilized by casing and boxing, with an insect repellant inserted in the box. The manuscripts that have been microfilmed are relatively dust-free. Most of the manuscripts appear to be written by incision, and have a strong image. Some are insect-damaged and broken, particularly at the ends.\nThe following procedures are designed to clean soiled surfaces, strengthen the image, support damaged areas, impart flexibility, and reduce further insect damage.\n1. Fumigation. It is important that, as each group of manuscripts is set aside for conservation treatment, they be removed from their boxes and placed in an airtight container for fumigation. To ensure that each cased manuscript is returned to the correct box, the cases and first leaves of each manuscript should be marked in soft pencil with the box number.\nThe container (a plastic garbage container with lid, for example) should have an appropriate quantity of para-dichlorobenzene covering the base. The manuscripts in their cases may then be stood on end, supported above the level of the para-dichlorobenzene by bricks or stones, but not jammed in too tightly. The lid should be sealed, and the manuscripts left for no less than one week.\nBy employing more than one ""fumigator,"" it should be possible to arrive at a workable schedule, coordinating fumigation exposure to conservation treatment time.\n2. Cleaning. The manuscripts should be removed from the fumigator and the protective cases one at a time. The leaves should be numbered discreetly in the lower right corner with a soft pencil, and the covers and strings carefully removed.\nAll the leaves should be lightly dusted with a soft dry brush to remove dust and insect parts. If manuscript fragments are loose, they should be set aside in a polyester envelope bearing the leaf number for future attachment.\nAfter the bench surface has been cleaned, a sheet of polyester film is laid onto it, and a stable container of warm (preferably distilled) water and a lint-free cloth (preferably cheese cloth) prepared. The manuscript should be checked to ensure that the writing is incised and not surface-written (a magnifying glass and a raking light are helpful).\nThe cloth is dampened, and a small area tested to ascertain the stability of the image. If stable, the leaf is carefully cleaned on both sides, and placed between sheets of blotting paper to dry. The polyester film is wiped, and the next leaf cleaned, until all have been treated.\n3. Repair and Support. If the manuscript is damaged (by insects or splits, etc.) it must be repaired at this point. A stable adhesive that does not readily mold is a mixture of methylcellulose and Elvace 1864 polyvinylacetate. This is made as follows:\nA piece of Tengujo tissue is torn or water-cut to cover the damaged area, and laid onto a small square of polyester film. The tissue is carefully pasted, the tissue laid into place on the palm leaf, and gently rubbed down through the film with a bone folder. The film is removed, and the repair allowed to dry.\nIf a significant portion of the palm leaf is missing, a piece of Kitakata paper is carefully torn or water-cut to match the missing area, and tipped into place. It is then supported on both sides by the tissue in the manner noted above. Loose fragments are similarly secured in place in this fashion.\nAn effective variation of this repair technique is the use of tissue coated with a dry fish gelatin solution. With this technique, the tissue is laid dry over the dampened surface of the damaged palm leaf, and pressed into place with a damp cloth until firmly set. The advantage of this method is that repairs dry quickly, adhesive does not have to be prepared, and adhesion is very strong.\n4. Oiling. The oiling of the palm leaf imparts a smooth surface and slight increase in flexibility. If the oil is insect-repellant, the leaf has added protection.\nThe leaf is laid onto polyester film or glass, and a thin coat of cedarwood oil applied to the entire surface on both sides of the leaf. It will be noted that tissue repairs are not released by the oil, but they blend further into the leaf surface.\nEach leaf should be air-dried in a constant air current to avoid molding. A useful method is to secure the leaves to a line by a peg or spring clip.\nWhen dry, the surface should be lightly polished with a soft dry cloth, the manuscript restrung, recased, and reboxed. It is important that the case and box be clean and the insect repellant in place before reshelving.']"	['<urn:uuid:b17b58ba-d9dd-41fa-b74c-7dd23da1e98e>']	open-ended	with-premise	concise-and-natural	distant-from-document	single-doc	novice	2025-05-13T04:02:16.770989	12	55	778
65	organic based magnets and conducting polymers applications electronic devices field	Organic-based magnets and conducting polymers serve different roles in electronic devices. Organic-based magnets, like TCNE, are studied for potential use in spintronic devices where both magnetic properties and semiconducting behavior are needed for spin-based information carrying. In comparison, conducting polymers are being developed for applications in organic solar cells and biosensors, valued for their low cost and easy production, though scaling up to industrial levels remains challenging.	['Molecular Electronics : A Theoretical Study of Electronic Structure of Bulk and Interfaces\nSammanfattning: This thesis deals with theoretical studies of the electronic structure of molecules used in the context of molecular electronics. Both studies with model Hamiltonians and first principle calculations have been performed. The materials studied include molecular crystals of pentacene and DNA, which are used as active material in field-effect transistors and as tentative molecular wires, respectively. The molecular magnet compound TCNE and surface modification by means of chemisorption of TDAE on gold are also studied.Molecular crystals of pentacene are reported to have the highest field-effect mobility values for organic thin film field-effect transistors. The conduction process in field-effect transistors applications occurs in a single layer of the molecular crystal. Hence, in studies of transport properties molecular crystals of pentacene can be considered as a two dimensional system. An open question of these system is if the charge transport is bandlike or if as a result of disorder is a hopping process. We address this question in two of the included papers, paper I and paper II.The conducting properties of DNA are of interest for a broad scientific community. Biologist for understanding of oxidatively damaged DNA and physicist and the electronics community for use as a molecular wire. Some reports on the subject classifies DNA as a conductor while other report insulating behavior. The outcome of the investigations are heavily dependent on the type of DNA being studied, clearly there is a big difference between the natural and more or less random sequence in, e.g., λ-DNA and the highly ordered syntethic poly(G)-poly(C) DNA. It has been suggested that long-range correlation would yield delocalized states, i.e., bandlike transport, in natural DNA, especially in the human chromosome 22. In paper III we show that this is not the case. In general our results show that DNA containing an approximately equal amount of the four basis is an insulator in a static picture.An emerging research field is spintronics. In spintronic devices the spin of the charge carrier is as important as the charge. One can envision a device where spin alone is the carrier of information. In realizing spintronic devices, materials that are both magnetic and semiconducting are needed. Systems that exhibit both these properties are organic-based magnets. In paper IV the electronic structure of the molecular magnet compound TCNE is studied, both experimentally and theoretically.The injection of carriers from metal contacts to organic semiconductors is central to the performance of organic based devices. The interface between the metal contact and the organic material has been pointed out to be one of the device parameters that most significantly influences the device performance. This relates to the process of injection of charge carriers in to the organic material. In some contact and organic material combinations the energy barrier for charge injection can be very high. The barrier can be reduced by modify the interface dipole, this is achieved by a monolayer of adsorbed molecules at the interface. The molecule TDAE chemisorbed on gold is studied in paper V.\nKLICKA HÄR FÖR ATT SE AVHANDLINGEN I FULLTEXT. (PDF-format)', 'For the 12 Days of “The STEM Chicksmas” we’re highlighting 12 scientists who have contributed something innovative and exciting to their field. It is the season of giving, and these brilliant minds have given incredible gifts to the scientific community! This year we’re looking at 12 Nobel Prize winners from the past 15 years in the fields of Physics, Chemistry, and Physiology or Medicine.\nDay Nine: The 2000 Nobel Prize in Chemistry.\nWhen we think of plastics, we generally think of them as insulators, materials that inhibit the flow of electrical current. A common application of this insulating ability is the plastic that coats wires to protect us from receiving a shock if we touch them. However, what if plastics could conduct electrical charge the way metals can? It turns out that certain plastics can conduct—but only if you make them correctly. This discovery by Alan J. Heeger, Alan G. MacDiarmid and Hideki Shirakawa earned the Nobel Prize in Chemistry in year 2000.\nThe conducting ability of a material is determined by its electronic structure. The energy of electrons is quantized, which means electrons can only be at certain energy levels. However, this also means that electrons cannot exist within a certain energy range. This forbidden energy range is called the band gap, and in solid materials it is the gap between the conduction and the valence band. The valence band is the band where electrons exist in a non-excited material. If a voltage is applied to the material and the band gap is small enough, electrons can jump to the conduction band. However, this is only possible if the valence band is not fully occupied. This movement of electrons is an electrical current! Using band gaps we can define three types of materials: conductors (no band gap, like metals), semi-conductors (a small band gap), and insulators (a very large band gap). In general, the longer a material is, the smaller the band gap gets. This is relevant when talking about plastics, because chain length is a very important factor.\nWhen we talk about plastics we’re actually talking about polymers, very large molecules made up of a chain of repeating units. In organic polymers, this is a carbon chain. The unit can include double bonds, atoms such as oxygen or chloride, or functional groups like alcohols. The groups that are on the carbon chain determine its properties. The type of polymer the Nobel Prize winners looked at were organic polymers with alternating double bonds, specifically polyacetylene. They found that when they “doped” these polymers, they became conductive. When you dope a substance, you introduce a hole (“p-doping) or an electron (“n-doping”) into the chain via a chemical reaction, either reduction or oxidation. This is important because generally, carbon chains have fully occupied valence bands. If you p-dope it, you turn one of the double-bonds into a single electron. Since an electron is missing, it appears that you have a positive charge which we call the hole. The single electron and hole can move along the chain fairly easily. If you n-dope it, a more complicated mechanism causes the transport of charges across the molecule.\nBy discovering conductive plastics, Shirakawa et al revolutionized the future of electronics. Plastics are cheap and easy to produce, and making them conductive also is a fairly simple chemical reaction. They can potentially be used in organic solar cells and biosensors. It is difficult to scale up their processing to industrial scales, but if this can be achieved conductive polymers could be the future of our devices.\nTo read more, check out the Nobel Prize website here.']	['<urn:uuid:3c0c301e-0add-4beb-b6be-bed87fa88e45>', '<urn:uuid:5dfa3b98-d5c3-4a28-98c9-301decd2be72>']	factoid	direct	long-search-query	similar-to-document	comparison	expert	2025-05-13T04:02:16.770989	10	67	1117
66	I'm trying to measure our company's reputation as an industry leader, but I'm not sure how to track something so intangible. What are some ways we can measure our reputation?	There are several ways to track reputation: conducting surveys in your sector to measure awareness, monitoring online mentions through services like Google Alerts, tracking levels of returning users to your site, and monitoring subscription levels for things like newsletters and LinkedIn groups. While these methods aren't 100% accurate, they can provide useful indicators of reputation growth.	['Before you can start work on improving your online presence, you need criteria by which to measure success or failure. You also need a way to judge what work is worth undertaking. You need trackable business objectives.\nHow do you judge whether your website is performing adequately or not? How do you decide what should be done next? How do you justify further investment in your web strategy?\nIf you are anything like the majority of website owners, you will struggle to answer those questions. That is because the majority of websites are run on an ad-hoc basis with decision making being made on the fly. Somebody senior feels the website is looking dated so a redesign project is launched. Somebody else feels that the site needs a new feature and so that is rolled out. It is essentially knee jerk development.\nThis is what I want to tackle in this, my next post, in our web governance series.\nIt is time to bring some focus to our fictional law firm’s online strategy.\nBefore we leap into implementing ideas, we need to know the destination.\nSetting your destination\nAs Bilbo Baggins says to Frodo in the Fellowship of the Rings:\nIt’s a dangerous business, Frodo, going out your door. You step onto the road, and if you don’t keep your feet, there’s no knowing where you might be swept off to.\nThe same is true for your website. If you set off without a clear destination you can easily be swept anywhere. Before we take our first step we need to know where we are headed.\nIn the case of an online strategy, the destination is your business objectives.\nSo far we have not formalised the business objectives for Wolfram and Hart. We would of collected a lot of perceived business objectives from various people within the organisation, while doing stakeholder interviews, but these will not have been formally agreed by the “powers that be.”\nBefore we can develop a roadmap we need a set of objectives for our website that have been signed off across the organisation.\nThis process would begin by Headscape taking the suggestions from the stakeholder interviews and comparing them with our SWOT analysis.\nWhere a suggestion is inline with a strength or opportunity from the SWOT analysis, we will include it. However, if a suggestion seems infeasible because of the weaknesses or threats the company faces, it will be left off. This means when we are questioned about our proposed list, we have some criteria upon which we based our decisions. This is especially important when two suggested objectives directly conflict.\nFortunately it is rare for business objectives to conflict so completely. Most of the time the challenge is in agreeing a priority. This is the case with Wolfram and Hart where objectives clash in two areas.\nFirst, the CEO wants users to be primarily introduced to Wolfram and Hart, while attorney’s want them funnelled as quickly as possible to their own biographies. Luckily these are not so much a difference in objective as implementation. Both objectives are about generating more leads.\nSecond, marketing sees the website as exclusively a lead generation tool, while PR wants to use it for recruitment. Although not a direct clash there is a difference in priority. Fortunately the CEO resolved this priority difference when he stated in his own stakeholder interview that the website is primarily a sales tool.\nAs you can see the prioritisation of your business objectives is crucial. Without that prioritisation it becomes hard to work out what work should be prioritised on your roadmap, or where the emphasis is placed on the site.\nIt is important that the list of objectives does not become too long. If it does then the strategy and roadmap can begin to become unfocused. Half a dozen objectives is normally more than enough. In the case of Wolfram and Hart, we decide on four:\n- The primary objective of the site is to generate quality leads.\n- To increase the reputation of Wolfram and Hart as a ‘thought leader’ in the technology and petrochemical sectors.\n- To build a community of ex-staff, clients and prospects who could potentially turn into leads or recommend Wolfram and Harts services.\n- To portray a positive image of Wolfram and Hart as a place to work, so attracting new attorneys.\nThere are a couple of things to note here.\nFirst, the primary objective is to “generate quality leads.” Wolfram and Hart want the digital strategy to be judged on quality, not quantity. It is also about leads, not sales. Most of the sales work will happen offline and so is beyond the reach of the digital strategy to influence.\nSecond, the second and third objectives support the first and the last. Being seen as a thought leader not only helps generate leads, it also makes Wolfram and Hart an attractive company to work for. Equally a network of people promoting Wolfram and Hart helps lead generation and recruitment.\nWith our business objectives in place, you would be forgiven for jumping into planning tasks. However, we have one last thing to do. We need a way of measuring the success of our roadmap, which means we need a baseline to measure from.\nSetting a baseline\nIn order to know if our roadmap is successful we need to be able to measure it against our business objectives. But, how do we measure our business objectives? We need to turn them into something trackable. Take for example Wolfram and Hart’s primary objective.\n> The primary objective of the site is to generate quality leads.\nThis objective presents us with two problems. First, the existing site does not track leads at all and second tracking the quality of leads is challenging. Fortunately, both are solvable using Wolfram and Hart’s existing systems.\nHow to track\nThe first step is to be able to track any lead coming from an online source. Currently this happens in three ways:\n- Via a contact form.\n- Via the phone number displayed on the site.\n- Via the email address or phone number of an individual attorney.\nTracking the contact form can easily be done with Google Analytics. A phone number is slightly more difficult. The best solution is to have a phone number that is unique to the website. That way any calls coming from it are almost certainly coming from the site (although phone numbers do get passed around).\nThe individual attorneys information is trickier to track. This is because it is just displayed on the biography page. We have no idea whether those visiting the page are using that information or not. Having website unique email addresses and phone numbers for every attorney is impractical. Therefore the best option available is to initially hide contact information on an attorney bio. Only when the user clicks a contact button will the information be revealed.\nThis is not an ideal solution for three reasons.\n- There is no guarantee that just because users clicked the button, they will actually contact anybody.\n- It requires an extra step for the user, which is never desirable.\n- If they do contact somebody we have no way to know that lead has come from the web.\nHowever, I strongly believe that tracking something is better than not tracking at all. At least we can compare the number of clicks on the button before and after improvements have been made to the site, so giving an indication of whether the improvements have helped.\nThat said, it is not just a problem of tracking, its also ensuring we are tracking the right thing.\nThe second problem I identified with tracking Wolfram and Harts business objectives was that they wanted to generate quality leads. In other words the web strategy has not achieved its business objective if they receive a large number of leads that don’t convert or are of too low a value.\nFor many organisations this presents a considerable challenge. It requires having the ability to not only identify a lead as coming from the website, but also being able to track that lead all the way through its lifecycle.\nFortunately for Wolfram and Hart, this isn’t as much of a challenge as for some. They already have a customer relationship management system (CRM) in place for managing prospects. This is something I would recommend for any organisation wanting to track the quality of leads coming via the web.\nMost CRM systems (such as the well known SalesForce) allow you to enter the source of a lead. Even the lower cost solutions (such as Highrise) allow you to enter notes that could include a hash tag citing the source.\nWith the source tracked in the CRM system, it is relatively easy to produce reports that outline the percentage of web conversions and the average value.\nAlthough we can now track Wolfram and Hart’s primary objective relatively accurately, some of the other objectives need creative thinking.\nTracking the impossible\nWhen confronted with an objective such as:\nTo increase the reputation of Wolfram and Hart as a ‘thought leader’ in the technology and petrochemical sectors.\nthings get a little trickier. How do you track reputation and perception?\nObviously, there is no way to track these figures accurately. However, we can get an indication. Remember, we are looking to measure these against a baseline and so as long as the measurement criteria don’t change we can get an indication of whether things are improving.\nIn fact we have several options here. We could:\n- Carry out a survey. By surveying people within the related sector we could judge the level of awareness surrounding Wolfram and Hart and how they are perceived.\n- Monitor online mentions of Wolfram and Hart. Services like Google Alerts allow us to track mentions of names or high profile cases. By analysing the results and looking at where the mentions are made (are they being mentioned in publications relating to our targeted sectors) we can get a sense of how well known Wolfram and Hart are.\n- Look at levels of returning users to the site. If Wolfram and Hart are looking to build a reputation as thought leaders, they need to be producing useful content. If they are, then people will be visiting the site more often. We can track how many people return to the site on a regular basis, so getting an indication of how engaging the content is.\n- Track subscription levels. If Wolfram and Hart produce material in the targeted sectors which users can subscribe to, we can track those subscription levels. This would include things like newsletter subscriptions, membership of linkedIn groups or RSS subscriptions.\nAll of these approaches have obvious weaknesses. However, as I have already said, monitoring something is better than nothing. The important thing is to be able to see an upward curve that can be correlated to the work we are doing as part of our digital strategy.\nIt is amazing what it is possible to gather data about, if you are willing to accept it is only an indication rather than 100% accurate. It just takes some lateral thinking.\nOnce you have a way to track each of your objectives, you are ready to start work. Of course the big question is; what do you do first? To know that you need a roadmap, which is what we will cover in the next post.']	['<urn:uuid:9f787c42-6189-4014-94ff-71454af23b26>']	factoid	with-premise	verbose-and-natural	similar-to-document	single-doc	novice	2025-05-13T04:02:16.770989	30	56	1910
67	greenfield robotics development process timeline	Greenfield Robotics' development began about three years before 2020. They first tested with existing farm tools, then created a prototype with engineer Carol Sutter. In 2019, they tested four robots on 25 acres of soybeans using remote control and live video streaming. During the winter of 2019-2020, they developed machine vision software to control 10 robots simultaneously and partnered with Eck Fabrication to improve hardware. By 2020, they planned to maintain 400-600 acres across 10 farms as part of a paid beta trial.	['By Rhonda McCurry on August 14, 2020\nClint Brauer from Cheney is working to re-shape food. His operation, MG Honor Farms in south-central Kansas, is a mecca of vegetables and herbs. For nearly a decade, MG Honor Farms has grown food for local consumers. Brauer, along with high school students and other part-time help, has completed most of the work himself.\n“We are branded on vegetables and herbs and grass-fed lamb that is rotationally grazed,” Brauer says. “Now we plan to expand this to our broadacre farm operation.”\nThis summer, Brauer launched a new wave of farm labor to help him. On May 22, 10 robots joined his farm. The robots repeatedly cut weeds such as pigweed and mare’s tail near ground level, within an inch of soybeans, milo, cotton, sunflowers and corn.\nThe vision of using robots to carry out no-till and regenerative farming is made possible by Brauer’s professional background in technology. He grew up near Cheney, worked for Sony in California and returned to his Kansas roots in 2010. Now, Brauer says, his worlds have combined to re-shape food for hungry consumers.\n“I have a friend, Steven Gentner, who writes machine vision software,” Brauer says. “He is a brilliant engineer and after I explained to him how farms worked, I asked, ‘Can robots be used to control weeds between rows of crops, without damaging the crops?’ Steven said, ‘Yes.’”\nNext, Greenfield Robotics was born.\nBOTS MEAN BUSINESS\nAfter testing with existing farm tools, Brauer began working on his prototype three years ago with engineer Carol Sutter, another technology guru from California, testing a design to remotely control robots to cut down pigweed.\nIn 2019, the Greenfield team settled on a design and put four robots to work killing weeds on 25 acres of soybeans. Next, the team developed an internet system to stream live video at the edge of the field and control the robots using a PC.\nThe robots were able to maintain these 25 acres, but the team concluded the remote-control robot needed a person to constantly walk behind it or steer using a computer from the edge of the field, which was labor intensive and subject to errors.\nAll last winter, Gentner and Sutter wrote machine vision software to control 10 robots at one time and partnered with Eck Fabrication in Kingman to improve the hardware.\nBrauer, Gentner and Sutter added to the team Nanden Kalle, an accomplished product and business development pro, and Jay Samit, a strategist who has been creating and advising successful companies since the ’80s.\nThe team worked out details in one of the MG Honor Farms greenhouses to test how the software will perform in the actual field this season.\n“This will either work or go down in flames, but we are pretty confident as the season goes on, the bots will get the job done,” Brauer says. “The bots will use machine vision to steer themselves in rows, in a field, where the path was established through drone and satellite imagery.”\nGreenfield Robotics plans to maintain 400 to 600 acres of corn, soybeans, cotton, sunflowers and milo (or grain sorghum) across 10 farms this summer, as part of a paid beta trial.\nBrauer recognizes there may be a need this year to use herbicides for “burndown,” which is a way to kill weeds and grasses in row crops, to complement the robots. But he hopes that robots can control broadleaf weeds better than herbicides because they mow the rows repeatedly. The robots weigh between 100 and 140 pounds, so after a big rainstorm, they can still get the job done without bogging down in the field.\nThe team plans to expand in 2021 and add a new form of weed control that eliminates grasses in addition to broadleaf weeds.\n“When we started developing robots, my vision was just to kill pigweed,” Brauer says. “We think, given the robotics systems we are currently developing, tractors may not be needed on our cropland as soon as this next year. And we believe these systems will lower weather-related risks, give back farmers control over their costs, boost productivity and re-align farmers and consumers.”\nFROM ROADSIDE TO ROBOTS\nMG Honor Farms has evolved from humble beginnings 10 years ago. Brauer began growing vegetables on a few acres just outside his grandmother’s farmhouse. His market was local only, including restaurants in Wichita and roadside stand customers. But the lessons learned were hard ones, Brauer says, as Wichita was not a terrific market for local foods, making income a struggle.\n“I also learned the Kansas climate is not consistent enough to grow some veggies at a local level,” he says. “We couldn’t grow at a price point people could comprehend.”\nEventually MG Honor Farms built multiple greenhouses near Cheney, and Brauer worked with his cousin on a hydroponic business in Topeka, where they grew various greens such as lettuces, arugula and kale for large customers like HyVee Stores in Kansas City. The Topeka business is currently not operating, but Brauer learned a ton about consumer interests while spending more than 30 weekends in Kansas City demonstrating and speaking firsthand with prospective buyers in stores.\nDuring the COVID-19 pandemic, Brauer says he has recognized the demand for food fresh from the farm. Farm traffic picked up at MG Honor Farms as families wanted to pick their own produce.\nHEALTHY FOOD BEFORE AND AFTER\nJust before the pandemic, MG Honor Farms launched a new program. Customers now help grow their own vegetables through a subscription program. Visitors not only get to take vegetables home, but they also learn how to grow them.\nBrauer decided to launch this program so Wichita-area consumers could learn how to grow food, herbs and flowers, share ideas about new products to create with those crops, get some exercise and take time away from their “garden” and let others keep it going.\n“As we sold into grocery stores and to pet food companies, I just wanted to make food less risky,” Brauer says.\nBoth the Greenfield Robotics and MG Honor Farms teams joined Brauer, he says, because they believe in producing food in a safe, special way. It’s not about the money, but rather for people’s health and ecology.\nBrauer says if his grandmother, Margaret, could see her former farmstead now she would get a good laugh at how many segments of the farming and growing industry Brauer has become involved in.\n“The timing couldn’t be better for what we’re doing,” he says. “The whole country is waking up and asking how our food supply becomes resilient and how it gets from the farm to the consumer.”\nTo learn more about MG Honor Farms, visit their Facebook page at www.facebook.com/MGHonorFarms.']	['<urn:uuid:40b6876e-be86-4718-9437-91458b99011b>']	open-ended	with-premise	short-search-query	similar-to-document	single-doc	expert	2025-05-13T04:02:16.770989	5	83	1118
68	What are the main differences between food intolerances and the allergic reactions caused by Oral Allergy Syndrome when it comes to how severe they are and what body systems they affect?	Food intolerance and Oral Allergy Syndrome (OAS) differ significantly in severity and affected systems. Food intolerance is generally confined to the gastrointestinal tract, does not involve the immune system, and is a less serious problem. In contrast, OAS is a true allergy involving the immune system, where IgE antibodies produce a histamine response. OAS can cause symptoms like acid reflux, throat swelling, hives, and in severe cases can lead to anaphylaxis, which can be fatal.	['You still hurt when you eat. Your tongue swells, your throat tightens and the tell-tale churn and burn of the same old acid reflux welcomes you to yet another painful meal. “But all the tests were negative,” you might think. Or you might plead, “But I’m confident I’ve cut gluten from my life, and this meal is 100% gluten-free!”\nIf healthy foods make your lips, tongue or throat itch and swell, you may be suffering from Oral Allergy Syndrome (OAS).\nI suspect oral allergy syndrome remains largely undiagnosed, and some evidence suggests it could be one of the most common food-related allergies in adults. It is different from many allergies in that it is less common in children; it is far more common in late teens and adults.\n- What Is Oral Allergy Syndrome?\n- How Is This Different From Other Food Allergies?\n- OAS Symptoms\n- Related Conditions\n- Oral Allergy Syndrome Food List and Chart\n- Exercise-Induced Food Allergies\n- OAS Treatment and Prevention\n- Final Thoughts\n- Take The Quiz\nWhat Is Oral Allergy Syndrome?\nOAS is a food allergy where people with a pollen allergy also experience allergic reactions to foods containing proteins structurally similar to the proteins in their pollen allergen. For this reason it is sometimes called Pollen-Food Allergy.\nCross-reactivity occurs when you experience an allergic reaction or intolerance to a protein similar to a well-defined allergy or intolerance. For example, some people with celiac disease experience cross-reactivity to a protein in oats (although that is not an allergic cross-reactivity — it is an autoimmune cross-reactivity).\nIn OAS, the cross-reactivity occurs when proteins in specific nuts, fruits and vegetables are structurally similar proteins to specific pollens (see below for a food list and chart).\nIf you experience hay fever or a known allergy to a pollen, such as the pollen from grass, trees or ragweed, you have the potential to experience OAS. Like the allergies to these pollens, OAS is most common during the spring and early summer allergy seasons, but it can occur any time of the year.\nOAS is a true allergy: it is a type 1 hypersensitivity where an immediate or near-immediate reaction occurs. Your immune system produces IgE antibodies against the allergen (in this case pollen or the protein similar to the allergic pollen protein), which results in a histamine response.\nIn most cases this reaction occurs with raw or fresh foods. Cooking, canning, or freezing may denature the problem proteins. This creates confusion as someone might enjoy something like canned peaches without difficulty but then experience an uncomfortable reaction to a nice, fresh peach.\nHow Is This Different From Other Food Allergies?\nThe main difference is that an OAS reaction is a cross-reaction to food with similarities to another protein, where that other protein is the primary allergen.\nFor example, a peanut allergy is not part of OAS: it is a serious allergy directly to peanuts.\nHowever, because a protein in almonds and hazelnuts is similar to a protein in alder trees, someone with a tree allergy to alder may experience OAS when they eat almonds or hazelnuts.\nSo you wouldn’t necessarily say this person is allergic to almonds or hazelnuts; you would say they are allergic to alder and cross-reactive to almonds or hazelnuts.\nI know this is a little confusing, but I hope this helps.\nOral Allergy Syndrome Symptoms\nThese are the most common oral allergy syndrome symptoms:\n- Acid reflux\n- Esophageal swelling and burning\n- Hay fever, including itchy, watery eyes, runny nose, congestion and sneezing.\n- Hives (urticaria) or Eczema\n- Itching or Tingling in the mouth and throat\n- Swelling of the lips, face, tongue or throat (including the uvula)\n- Wheezing, throat tightening or trouble breathing\nIn people with stronger allergies, the proteins may survive stomach acids and create gastrointestinal distress, including gas, cramping and diarrhea.\nWhile most cases involve relatively minor symptoms, please note that anaphylactic reactions are possible. If you have a history of severe allergic reactions or anaphylactic shock and you suspect you may suffer from OAS, I urge you to seek formal diagnosis and treatment from an allergy specialist.\nAnaphylaxis can come fast and be fatal, so proper diagnosis and treatment is critical.\nSome people with allergies to grasses, especially barley and rye grasses, may experience cross reactivity to wheat. Thus, some forms of OAS may appear to be a wheat allergy. Please see my lesson on wheat allergy symptoms for more.\nUrticaria (hives) and asthma sometimes occur when OAS patients prepare food. This may happen when you touch or inhale the cross-reactive proteins.\nSome people with a form of chronic rhinitis, a condition where the mucus membranes of the nose are chronically inflamed, may have experienced OAS for years without diagnosis.\nThe most common related condition is hay fever. If you are an adult who suffers from hay fever each spring and summer, you are at greater risk for experiencing an oral allergy syndrome.\nIf you believe you’ve reacted to eating certain raw or fresh foods and you suspect OAS, I urge you to discuss the matter with an allergy specialist so you can accurately diagnose and treat it.\nOral Allergy Syndrome Food List and Chart\nIn what first appears contradictory, ripe fresh foods often cause more severe reactions than fresh-picked foods, and cooked or canned foods cause less severe reactions than fresh foods.\nSo a fresh-picked apple right off the tree will cause less of a reaction than the apple that’s been sitting in your fruit bowl for a couple of days.\nIn some cases, such as with apples and carrots, peeling the fruit or vegetable appears to minimize or eliminate the reaction.\nHere are the most common pollens in Oral Allergy Syndrome, along with their most common cross-reactive foods:\n- coriander (cilantro)\n- melons (watermelon, cantaloupe, honeydew)\n- coriander (cilantro)\n- sunflower seeds\n- chamomile (including the tea made from chamomile)\n- melons (watermelon, cantaloupe, honeydew)\n- sunflower seeds\nI’ve tried to make this list comprehensive, but it’s unlikely anyone can put a 100% accurate and complete list together. It is possible to react to foods that aren’t on this list. However, I believe this list will cover the most common cases.\nRemember that food restrictions can compromise nutrition unless you really know what you’re doing and you are deliberate in your nutritional choices. For this reason, I encourage you to see an allergy specialist if you suspect OAS. Self-diagnosing and unnecessarily removing healthy foods from your diet may only reduce your long-term health.\nExercise-Induced Food Allergies\nOAS can be associated with exercise-induced allergies. In some cases, it can be related to exercise-induced anaphylaxis (EIA). While the condition isn’t entirely understood yet, understanding how cross-reactivity to something you eat triggers a reaction may help you prevent EIA.\nIf you’ve experienced an exercise-induced allergic reaction and you don’t know why, you might discuss OAS with your allergy specialist.\nDiagnosing oral allergy syndrome can be difficult for several reasons. Cooking, canning, freezing and pasteurizing the allergen can reduce or eliminate reactions, making it difficult to identify or even suspect certain foods.\nIn addition, other food reactions, including the symptoms of gluten intolerance or lactose intolerance may cause patients to inaccurately self-diagnose.\nSometimes other conditions may hide behind OAS. For example, oral allergy syndrome may mask a food intolerance resulting from the inability to metabolize certain proteins or salicylates in food.\nTo obtain an accurate diagnosis, you need to work with an allergy specialist familiar with all these possibilities.\nYour doctor may use the following to diagnose OAS:\n- Elimination diet (often followed by a food challenge)\n- History of symptoms (arguably the most important one here)\n- Oral food challenge (done in the office)\n- Radioallergosorbent test (RAST), or a Fluorescence Enzyme-Labeled Assay – These are food allergy blood tests used to identify antibodies to specific food proteins.\n- Skin prick test\nHowever, doctors often like you to keep a detailed food journal and symptom history so they can narrow down the allergy tests you need and avoid random testing.\nMany may find this process challenging in a world of diet trends and self diagnosis, but it’s important to let the data speak for itself rather than imposing preconceived notions on to that data.\nI’ve come across cases where people who diagnosed themselves with gluten intolerance later learned they actually suffered from oral allergy syndrome unrelated to wheat.\nWhile I don’t mean to dissuade you from diagnosing a wheat allergy or a gluten intolerance, remember that the goal is to find out what’s wrong and get better.\nThe goal is not to fulfill a confirmation bias, something that happens more often than people like to admit, especially during an era when the anti-wheat bandwagon barrels through Internet blogs like a party bus without brakes.\nOAS Treatment and Prevention\nIf you want to learn how to prevent oral allergy syndrome, the most important step is to obtain an accurate diagnosis. Food journals are tedious and unpopular, but maintaining one can save you from a lifetime of frustration resulting from inaccurate diagnoses or missed diagnoses.\nFor someone with a broad range of food allergies (unfortunately, it happens), allergen immunotherapy through allergy shots may be considered. Such therapy doesn’t exist for celiac disease or non-celiac gluten sensitivity, but it can help people with OAS or a wheat allergy.\nLong term, improving your immune system may help minimize symptoms of OAS. To improve your immune system try the following: exercise daily, improve your amount and quality of sleep, drink plenty of water (soda pop and alcoholic beverages don’t count), reduce sugars, take a probiotic supplement and take a gluten-free multivitamin.\nFor immediate treatment, I recommend a rigorous cold water rinse and an oral antihistamine. Benadryl (diphenhydramine) appears to be particularly effective. While the brand name Benadryl is expensive, the same medication is sold as a generic sleep aid in some markets. You may find generic sleep aids where the only ingredient is diphenhydramine a cheaper alternative to Benadryl.\nOther oral antihistamines like Claritin (Loratadine) may work for you as well. Keep in mind that Claritin works better taken well in advance of an allergic reaction, while Benadryl works better if you take it right as a reaction begins.\nPeople with severe allergic reactions may need to keep a couple of epinephrine autoinjectors (EpiPens) on hand at all times. These are often necessary to curb potentially deadly reactions like anaphylaxis.\nI suspect many more people suffer from oral allergy syndrome than we currently understand. It may be the trigger of problems blamed on other conditions or allergens. It may sometimes remain within a tolerable threshold, so many people choose not to do much about it.\nIf your negative reactions to food are often immediate and you’ve tested negative for celiac disease or a wheat allergy, I encourage you to watch your diet closely for reactions to the foods I detailed in the oral allergy syndrome list.\nIf you discover a new pattern relating to those foods, discuss this pattern with an allergy specialist for accurate diagnosis. I sincerely hope this helps someone out there discover a new opportunity for healing.\nTake The Quiz!\nHow Well Do You Understand Oral Allergy Syndrome?\nCongratulations - you have completed How Well Do You Understand Oral Allergy Syndrome?.\nYou scored %%SCORE%% out of %%TOTAL%%.\nYour performance has been rated as %%RATING%%', 'Food allergy is the term used for an allergic reaction triggered by the immune system of the body after consuming certain food items. Eating even a small portion of allergy causing food can lead to development of hives, swelling of airways, and even anaphylactic reaction in some people.\nIt is important to understand that food allergy is an entirely separate entity from food intolerance. The latter is generally confined to the gastrointestinal tract, does not involve the immune system and is a less serious problem.\nPrevalence of food allergy\nIt is believed that 6% to 8% of all children under the age of three and 3% of all adults suffer from some kind of food allergy. Although there is no cure for this condition, the food allergy gets cured spontaneously in some children.\nSymptoms of food allergy\nThe symptoms of food allergy may develop within minutes in a person who is severely allergic to a few hours in individuals who are less allergic.\nThe common symptoms of food allergy include:\n- Itching in and around the mouth\n- Development of hives\n- Swelling of the lips and throat\n- Watering of eyes\n- Difficulty in breathing\n- Pain in abdomen\n- Loose motions\n- Nausea and vomiting\n- Lightheadedness and fainting\nIn certain individuals, the food allergy is so severe that it may trigger an anaphylactic reaction. The symptoms of this reaction are:\n- Constriction of airways\n- Heaviness in chest with difficulty in breathing\n- Sudden drop in blood pressure\n- Cold, clammy skin\n- Rapid pulse rate\nIf not treated urgently, it can prove fatal.\nCauses of food allergy\nIn certain individuals, the immune system mistakes a particular food to be an allergen and produces immunoglobulin E antibodies against it. The next time the person consumes the same food item, the IgE antibodies already present in the blood stream sense it immediately and trigger an allergic reaction. This involves release of a chemical called as histamine which is responsible for producing the symptoms related to food allergy.\nCommon food items that produce food allergy\nFood allergy is usually due to specific proteins present in the food items. Some of the food items that are known to induce allergic reaction are shellfish, walnuts, fish, eggs, peanuts, milk and wheat.\nRisk factors for food allergy\nSome of the common risk factors for food allergy include:\n- Family history: a person is more likely to develop food allergy if he has a family history of or hay fever.\n- Food allergy in the past: in children, food allergies may resolve on their own but often come back in adulthood.\n- Age: Food allergies are more common during childhood. As children grow up, the possibility of absorption of allergens decreases. Allergy to milk, wheat and eggs usually resolves with age. However, allergy to shellfish and nuts usually lasts for a lifetime.\n- Other allergies: Food allergies are common in individuals suffering from other allergies like asthma and hay fever. Similarly, asthma and hay fever are more likely to develop in individuals suffering from food allergies.\nComplications of food allergy\nFood allergy can give rise to complications like:\n- Anaphylactic reaction\n- Migraine due to release of histamine\nTreatment of food allergy\nAntihistamines are usually prescribed to treat cases of mild food allergy. However, in case of severe food allergy, injecting epinephrine is the only way to save the life of the patient. It is advised that people suffering from food allergy carry an epinephrine auto injector with them at all times.']	['<urn:uuid:f939d8d1-6bb9-40eb-a6dd-90a1d801c5e9>', '<urn:uuid:01512023-10be-4566-b2da-6f6e98d028b9>']	open-ended	direct	verbose-and-natural	distant-from-document	comparison	novice	2025-05-13T04:02:16.770989	31	75	2484
69	identify manage osteoporosis risk early signs	Osteoporosis risk factors include family history, low calcium and vitamin D levels, use of corticosteroids, hormone imbalances, low physical activity, and excessive alcohol intake. Women are particularly susceptible after menopause due to decreased estrogen levels. The condition is diagnosed through DEXA scans, which measure bone mineral density in the wrist, hip, and lumbar spine. T-scores determine severity: normal is -1.0 or above, osteopenia is between -1.0 and -2.5, and osteoporosis is -2.5 or below. Early management includes proper nutrition, ensuring adequate calcium intake to prevent bone calcium depletion, and specific exercise programs. Since approximately 99% of body calcium is stored in bones and teeth, maintaining proper calcium levels through diet is crucial for prevention.	['It can be easy to take our bodies for granted and assume we will stay perfectly fit and healthy for years to come. However, unless you’re making a conscious effort to stay healthy, this may not be the case.\nThis includes taking proper care of your bones. While bone health may be one of the last things on your mind, ensuring they stay nourished is extremely important, especially as you age.\nRead here to discover the importance of our bones, and we can best support their health.\nWhat Are Your Bones Made Of And Why Does It Matter?\nBones are made of living, growing tissue. Primarily, bone is made of the protein collagen. Collagen offers a soft framework for your body. Then there are several minerals, like calcium phosphate, for instance, that support your bone mineral density and add strength by helping to harden your bone framework.1\nWhat’s so special about the collagen and calcium duo? These compounds help make your bones flexible and strong. And strong, flexible bones are able to better withstand injury and stress than weaker bones.2\nBelieve it or not, approximately 99 percent of your body’s calcium is actually contained within your bones and teeth. Of course, there are traces of calcium found in your bloodstream as well.3,4\nImportance Of Bones: Risk Factors Associated With Poor Bone Health\nAlthough bones will stop growing in length in early adulthood, they may continue to grow in density. Until you reach about 30 years of age, your bones are at peak bone mass and your body is able to create new bone pretty quickly.5 After you hit age 30 or so, however, your body’s bone-building ability naturally changes and bone loss may begin.6,7\nBone health issues are generally characterized by lower bone mass. Sometimes the structural deterioration of your bone tissue can play a role here too.8\nPorous bones can sometimes lead to fragility in your bones and an even higher risk of certain types of bone fractures — namely fractures of the wrist, spine, and hips. One of the issues with this type of bone health concern is that you’ll really have no warning of weakened bone because there are not usually many symptoms leading up to a bone fracture.9 To help avoid this from happening, you’ll make to make sure you’re getting the proper nutrients your bones need to stay strong and healthy.\nBone Health And Nutrition\nA well-balanced diet can go a long way to keeping your bones as healthy as possible. Of course, this means you should include plenty of lectin-free vegetables in your diet.\nCertain fruits and vegetables can help provide more calcium, vitamin D, and vitamin K. These vitamins and nutrients are essential for bone health.10,11\nOne thing to remember is that if your body isn’t getting enough calcium from a well-balanced diet, it will start to poach calcium from your bones — this can weaken them.12 So then, how might you enrich your diet with calcium?\nHere are some of the best calcium-rich foods to keep in your kitchen – all of which are Dr. Gundry-approved.\n- Casein A2 milk, goat milk, or buffalo milk\n- Leafy greens (kale, bok choy, collard greens)\n- Wild-caught sardines or wild-caught salmon\n- Blanched almonds\nOther Potential Ways To Support Bone Health\nVitamin D — Vitamin D plays a significant role when it comes to calcium absorption and maintaining proper bone health. And the synthesis of vitamin D takes place in your skin when you are exposed to sunlight.16\nSo, if you live in an area of the world that doesn’t get a lot of sun exposure or you spend much of your time indoors, you may want to talk to your doctor about the best way to get more vitamin D. They may recommend taking a vitamin D supplement or increasing your vitamin D intake through foods.\nYou’ll find vitamin D in the following lectin-free food sources:\n- Wild-caught fish\n- Omega-3 egg yolk\n- Grass-fed liver17\nVitamin K is also important as it can activate the osteocalcin protein — this protein is essential when it comes to building bone and helping weakened bone to rebuild strength.18 To find your vitamin K in food, try getting the following ingredients on your plate:\n- Olive oil19\nExercise — Because your bones, like your muscles, are living, growing tissue, exercise may also be a great way to support their health.\nSome National Institutes of Health (NIH government) sites recommend weight-bearing exercise as a particularly great way to support bone strength. Weight-bearing exercise ensures you are working against gravity. Resistance exercises may also be great for supporting bone health.\nTalk to your doctor about incorporating the following types of exercises into your routine:\n- Climbing steps\n- Playing tennis\n- Lifting weights20\nBone Health: Follow These Tips And Tricks\nDiet and exercise can go a long way when it comes to supporting the health of your bones. It’s important to get the proper nutrients your bones need to stay strong and healthy— especially if you’re over 30 years of age.\nLoad up on lectin-free foods that are rich in vitamin D, vitamin K and calcium. Start a workout routine and incorporate some bone-support exercises. Just make sure to get your doctor’s approval first. They may have other suggestions for supporting your bone health as well.', 'What is Osteoporosis?\nOsteoporosis (OP) is a condition of low bone mineral density (BMD). It causes fragile and brittle bones where fractures are more prevalent. The most commonly affected areas are the spine, hip, upper arm, wrist, ribs or forearm.\nEpidemiology data reports 70% of people in NSW & ACT aged 50 years and older have osteoporosis or osteopenia; this is 1.9 million people (Sanders et al. 2017). Year on year prevalence continues to rise with the ageing population. Women are more likely to suffer from OP, specifically after menopause, as bone loss is higher as estrogen levels decrease.\nOther risk factors include:\n- Family history of OP\n- Low calcium and vitamin D levels\n- Medical history: use of corticosteroids, hormone levels and thyroid conditions\n- Low levels of physical activity\n- Excessive alcohol intake\nIf you are over 50 and have suffered a fracture after a minor incident, it is important you are investigated for osteoporosis as it is a “silent disease” and you may not have any other signs or symptoms.\nHow is Osteoporosis Diagnosed?\nIf your care team suspects low bone mineral density, a GP will refer for a DEXA scan. A DEXA scan is the most specific way to determine bone mineral density, a T-Score is then calculated to make a diagnosis. A DEXA scan includes BMD readings in the wrist, hip and lumbar spine. According to the World Health Organisation (WHO) the following scores determine osteoporosis severity.\n- A T-score of -1.0 or above is normal bone density\n- A T-score between -1.0 and -2.5 means low bone density or osteopenia\n- A T-score of -2.5 or below is a diagnosis of osteoporosis\nI Have Been Diagnosed with Osteopenia or Osteoporosis, What Should I Do?\nOsteoporosis severity will determine what happens next (refer to image 1 below). A GP usually manages mild-moderate BMD loss and they may refer you to an Endocrinologist for further medical management if indicated.\nPharmacological interventions may be prescribed to assist in rapid bone rebuilding. Calcium and vitamin D levels should also be checked as adequate levels are crucial to maintain and build bone. Exercise is the only other way to increase or stimulate bone growth. After a diagnosis of OP it is absolutely necessary to either commence or modify exercise to ensure its’ impact is as effective as possible.\nExercise for Osteopenia and Osteoporosis\nExercise is the most effective lifestyle strategy to maintain healthy bones, it can assist in building and maintaining bone density. Specific loading through strength training has also been shown to be an effective way to treat osteoporosis (Liftmor 2019).\nWhat Kind of Exercise is Best to Build Bone?\nExercise at difference ages has different impacts. Adults need a combination of progressive resistance training and moderate impact weight-bearing activities. These specific types of exercise will increase BMD and prevent further bone loss. The key here is exercise TYPE and progressive increases in resistance.\nOptimal exercise guidelines\n- Regular: at least 3 x per week\n- Challenging: heavier weights with fewer repetitions\n- Progressive: exercise difficulty needs to increase over time\n- Varied: routines need to have variety, bone adapts to exercise and stops changing if you continue the same set of exercises\n- Short intensive bursts of weight bearing exercise are more effective than slow movements\nWhat Type of Exercise Should I be Doing?\n- Highly osteogenic (best for building bone):\n- Impact aerobics\n- Progressive resistance training\n- Sports e.g. Basketball or netball\n- Moderately osteogenic (some ability to build BMD)\n- Running or jogging\n- Brisk walking or hill walking\n- Stair climbing\n- Low osteogenic effect (minimal effect on bone mineral growth)\n- Leisurely walking\n- Lawn bowls\n- Yoga or Pilates\n- Tai Chi\n- Non-osteogenic (no effect on bone mineral growth)\nIt is most effective to do three activities per week, aiming for activities that are HIGHLY OSTEOGENIC.\nAre There any Types of Exercise I Cannot do with Osteoporosis? Do I Need to be Careful?\nThere is no specific exercise that is completely off-limits. In fact, recent research has found that high-intensity and impact training, previously thought to be high fracture risk, to be safe in the osteoporotic population (LIFTMOR Trial, 2019). This research also found this type of exercise to enhance bone strength when compared to lower intensity type exercise.\nHowever, for those with either osteoporotic spinal fractures, or a history of such fractures, it is worth considering end of range spinal positions, including: flexion, extension and rotation of the spine. End range spinal positions theoretically increase vertebral body load, thought to increase risk of a wedge or compression fracture. This is definitely not to say you can’t bend forward/backward or rotate to the side, but if loads are excessive or repetitive, the load has the potential to cause injury. This is why exercise programs need to be specific to each individual and exercise programs need to be monitored.\nExercise intensity, selection, variety and the overall program should be matched to capabilities and training history. Muscle strength and endurance in the tissue surrounding your bones will greatly influence your overall exercise capacity, as will current and previous exercise history. Exercise programs should be developed by either a Physiotherapist or exercise physiologist, who are trained in exercise therapy in chronic disease. This will help to ensure optimal outcomes while avoiding potential pain flare-ups or overload.\nFor exercise to have the biggest possible impact you need to participate in regular exercise (at least 3 x per week), choose exercise/activity that has high or moderate osteogenic (bone building) effects and change your schedule regularly.\nExercises to Get You Started\nThe femoral neck and the spine are two high-risk areas to suffer osteoporotic fractures. Targeted strength training in muscles surrounding these joints aims to directly increase BMD and surrounding muscle bulk. The following are examples of exercises that target these areas.\n*As this information is a general guide only, the following exercises do not take into consideration other pathologies or injuries. This does not substitute for a Physiotherapy exercise plan.\nSit to Stand\n- Start sitting on a chair, feet hip width apart\n- Arms out in front\n- Rise from the chair by shifting body weight forward into the heels of the feet\n- Stand with control, completely straighten hips and knees at the top\n- Lower with control to sitting\nTo make easier: start with bottom further forward in the chair or use a higher chair.\nTo make more difficult: hold arm weights, use a very low chair or hold each phase as pictured for 5 seconds.\n- Keeping feet hip distance, place one foot on the step\n- Push up onto the step, and straighten your hip and knee with control\n- Place opposite foot up on the step\n- Descend with control\nTo make easier: use a lower step or hold on to the wall for balance.\nTo make more difficult: use a higher step (picture b), hold hand weights, or add a single leg jump at the top (this requires balance, strength and coordination).\n- Start with feet hip width apart, knees behind toes, in a low squat position\n- Keeping arms straight holding weights\n- Drive up to standing by straightening your back and hips\n- Keep weights close to you\n- Lift and lower with control, descend as far as your hips and back are comfortable\nTo make easier: use light weight, move through a small range of motion.\nTo make more difficult: heavier weights, increase speed and depth of the motion.\nActive Prone Extensions\n- Lie face down on a firm surface, resting the head\n- Lift one arm and alternate leg as high as you can\n- Hold 3-5 seconds\n- Repeat opposite side\nAdd arm or ankle weights and increase length of hold to progress.\n- Lie face down on a firm surface\n- Lift arms, legs and head off the floor as high as you can\n- Hold 5-10 seconds\n- Repeat x 20\nTo make easier: lift either upper or lower body or move through a small range of motion.\nTo make more difficult: Add arm or ankle weights and increase length of hold, flutter arms and legs in a swimming motion.\nExercise to Prevent Osteoporosis\nThe most effective time to build bone is pre-puberty. Research has found that jumping has significant protective effects against bone related decline later in life (McKay et al 2005). This research found that only 10 jumps three times per day is adequate to improve bone mineral density. Weight bearing exercise is incredibly important to build bone, especially if your child tends to spend a lot of time in non-weight bearing sports such as swimming or bike riding. To make sure children are getting the benefits of weight bearing exercise, get them hopping, skipping or jumping every day.\n- McKay H.A., MacLean L., Petit M., Mackelvie K., O’Brien K., Janssen P., Beck T., Khan K.M. (2005) ‘Bounce at the bell’: a novel program of short bouts of exercise improves proximal femur bone mass in early pubertal children. British Journal of Sports Medicine 39, 521-526\n- Sanders KM, Watts JJ, Abimanyi-Ochom J, Murtaza G. Osteoporosis costing NSW & ACT: A burden of diseaseanalysis – 2012 to 2022. Osteoporosis Australia 2017 ISBN 978-0-9923698-2-8\n- Watson, S. L., Weeks, B. K., Weis, L. J., Harding, A. T., Horan, S. A., & Beck, B. R. (2018). High‐intensity resistance and impact training improves bone mineral density and physical function in postmenopausal women with osteopenia and osteoporosis: the LIFTMOR randomized controlled trial. Journal of Bone and Mineral Research, 33(2), 211-220.']	['<urn:uuid:2d69e16d-2134-44a5-9bc4-37f33cdbacce>', '<urn:uuid:8ff23d19-52eb-48f0-887c-a4514882195e>']	open-ended	direct	short-search-query	distant-from-document	three-doc	expert	2025-05-13T04:02:16.770989	6	114	2485
70	How does the khyal performance in North Indian music incorporate time and gesture?	In khyal performance of North Indian classical music, time and gesture are integrated through specific attention patterns and embodied movements. The performers use beat marking and other gestural elements that are crucial to the rhythmic and expressive aspects of the performance.	"['Professor Martin Clayton\nMartin Clayton is Professor in Ethnomusicology in Durham University. He studied at the School of Oriental and African Studies (SOAS) in London, where he obtained degrees in Music and Hindi (BA, 1988) and Ethnomusicology (PhD, 1993). His research interests include Hindustani (North Indian) classical music, rhythmic analysis, musical entrainment and embodiment, comparative musicology and early field recordings, British-Asian music and Western music in India. He previously worked at the Open University, and has taught a wide range of ethnomusicological courses at numerous other UK universities, besides contributing to OU teaching materials, and worked as Visiting Assistant Professor at the University of Chicago. He was a member of the Music sub-panel for the 2008 Research Assessment Exercise, and for the 2014 Research Excellence Framework.he is currently Director of Research in the Music Department.\nProfessor Clayton directs a major research project, \'Interpersonal Entrainment in Music Performance\', funded by the Arts and Humanities Research Council (AHRC, 2016-18), with co-investigators Tuomas Eerola (Durham), Antonio Camurri (Genoa) and Peter Keller (Sydney). he leads the Leverhulme Trust-funded project The Breath of Music: Investigating respiration in Indian music performance, and is also co-investigator on Laura Leante\'s AHRC-funded project \'Khyal: Music and Imagination\' in 2016. He previously directed the \'Experience and meaning in music performance\' research project: the co-authored book of the same name was published by OUP in October 2013.\nMartin served for many years as committee member for the British Forum for Ethnomusicology (BFE) and the European Seminar in Ethnomusicology (ESEM), and serves on several editorial boards including the journals Music Analysis and Music Performance Research.\nTo read more about Indian music at Durham, follow this link.\nFor more information on research publications, go to ResearchGate.\n- Clayton, Martin (2007). Music, time and place: Essays in comparative musicology. Delhi: B.R.Rhythms.\n- Clayton, Martin (2000). Time in Indian Music: rhythm, metre and form in North Indian rag performance. Oxford: Oxford University Press.\n- Clayton, Martin, Dueck, Byron & Leante, Laura (2013). Experience and Meaning in Music Performance. Oxford Oxford University Press.\n- Clayton, Martin, Herbert, Trevor & Middleton, Richard (2012). The Cultural Study of Music: A Critical Introduction (Second Edition). Routledge.\n- Clayton, Martin (2008). Music, Words, and Voice: a reader. Manchester: Manchester University Press.\n- Clayton, Martin & Zon, Bennett (2007). Music and Orientalism in the British Empire, 1780s to 1940s: Portrayal of the East. Music in Nineteenth-Century Britain. Aldershot: Ashgate.\nChapter in book\n- Clayton, Martin (2020). Entrainment and the Social Origins of Musical Rhythm. In The Philosophy of Rhythm. Aesthetics, Music, Poetics. Cheyne, Peter Hamilton, Andy & Paddison, Max Oxford: Oxford University Press.\n- Clayton, Martin (2017). The Ethnography of Embodied Music Interaction. In The Routledge Companion to Embodied Music Interaction. Lesaffre, Micheline, Maes, Pieter-Jan & Leman, Marc Routledge.\n- Clayton, Martin (2017). Time, Gesture, and Attention in a Khyāl Performance. In Ethnomusicology: A Contemporary Reader, Volume II. Post, Jennifer C. Routledge. 249-266.\n- Clayton, Martin & Leante, Laura (2013). Embodiment in Music Performance. In Experience and Meaning in Music Performance. Clayton, Martin, Dueck, Byron & Leante, Laura Oxford University Press. 188-207.\n- Clayton, Martin (2013). Entrainment, ethnography and musical interaction. In Experience and Meaning in Music Performance. Clayton, Martin, Dueck, Byron & Leante, Laura Oxford University Press. 17-39.\n- Clayton, Martin, Dueck, Byron & Leante, Laura (2013). Introduction: Experience and meaning in music performance. In Experience and Meaning in Music Performance. Clayton, Martin, Dueck, Byron & Leante, Laura Oxford University Press. 1-16.\n- Clayton, M. (2013). The Time of Music and the Time of History. In The Cambridge History of World Music. Bohlman, Philip V. Cambridge: Cambridge University Press. 767-785.\n- Fatone, Gina A., Clayton, Martin, Leante, Laura & Rahaim, Matt (2011). \'Imagery, melody and gesture in cross-cultural perspective\'. In New Perspectives on Music and Gesture. Gritten, Anthony & King, Elaine Farnham, Surrey: Ashgate. 203-220.\n- Clayton, Martin (2009). \'Local practice, global network: The guitar in India as a case study\'. In Theorizing the local: Music, practice and experience in South Asia and beyond. Wolf, Richard K. New York: Oxford University Press. 65-78.\n- Clayton, Martin (2009). \'The social and personal functions of music in cross-cultural perspective\'. In The Oxford Handbook of Music Psychology. Hallam, Susan, Cross, Ian & Thaut, Michel Oxford: Oxford University Press. 35-44.\n- Dahl, Sofia, Bevilacqua, Frederic, Bresin, Roberto, Clayton, Martin, Leante, Laura, Poggi, Isabella & Rasamimanana, Nicolas (2009). Gestures in performance. In Musical Gestures: sound, movement, and meaning. Godoy, Rolf Inge & Leman, Marc Routledge. 36-68.\n- Clayton, Martin (2008). Toward an Ethnomusicology of Sound Experience. In The New(Ethno)musicologies. Stobart, Henry Lanham, Maryland: Scarecrow Press. 135-169.\n- Clayton, Martin (2007). \'Musical Renaissance and its Margins in England and India, 1874–1914\'. In Music and Orientalism in the British Empire, 1780s to 1940s: Portrayal of the East. Clayton, Martin & Zon, Bennett Aldershot: Ashgate. 71-93\n- Clayton, Martin (2005). \'Communication in Indian raga performance\'. In Musical Communication. Miell, Dorothy Hargreaves, David & MacDonald, Raymond Oxford: Oxford University Press. 361-381.\n- Clayton, Martin (2003). Comparing music, comparing musicology. In The cultural study of music: a critical introduction. Clayton, Martin, Herbert, Trevor & Middleton, Richard New York: Routledge. 57-68.\n- Clayton, Martin (2001). \'Introduction: towards a theory of musical meaning (in India and elsewhere)\'. In Music and Meaning: Special issue of British Journal of Ethnomusicology. Clayton, Martin Routledge. 10/1: 1-17.\n- Clayton, Martin (2001). Rock to Raga: the many lives of the Indian guitar. In Guitar Cultures. Bennett, Andy & Dawe, Kevin Oxford, UK: Berg. 179-208.\n- Alborno, Paolo, Clayton, Martin, Keller, Peter, Volpe, Gualtiero & Camurri, Antonio (2015), Automated video analysis of interpersonal entrainment in Indian music performance, 15: 7th International Conference on Intelligent Technologies for Interactive Entertainment. Torino, Italy, EAI, e3.\n- Eerola, T., Jakubowski, K., Moran, N., Keller, P. & Clayton, M. (2018). Shared Periodic Performer Movements Coordinate Interactions in Duo Improvisations. Royal Society Open Science 5(2): 171520.\n- Jakubowski, Kelly, Eerola, Tuomas, Alborno, Paolo, Volpe, Gualtiero, Camurri, Antonio & Clayton, Martin (2017). Extracting Coarse Body Movements from Video in Music Performance: A Comparison of Automated Computer Vision Techniques with Motion Capture Data. Frontiers in Digital Humanities, section Digital Musicology 4: 9.\n- Clayton, Martin (2015). Aksak Patterns and Entrained Interaction in Transylvanian Village Music. Empirical Musicology Review 10(4): 292-301.\n- Will, Udo, Clayton, Martin, Wertheim, Ira, Leante, Laura & Berg, Eric (2015). Pulse and Entrainment to Non-Isochronous Auditory Stimuli: The case of North Indian Alap. PLoS One 10(4): e0123247.\n- Clayton, Martin & Leante, Laura (2015). Role, status and hierarchy in the performance of North Indian classical music. Ethnomusicology Forum 24(3): 414-442.\n- Angelis, Vassilis, Holland, Simon, Upton, Paul J & Clayton, Martin (2012). Testing a computational model of rhythm perception using polyrhythmic stimuli. Journal of New Music Research 2012(iFirst article): 1-14.\n- Clayton, Martin (2012). What is entrainment? Definition and applications in musical research. Empirical Musicology Review 7(1-2): 49-56.\n- Lucas, Glaura, Clayton, Martin & Leante, Laura (2011). Inter-group Entrainment in Afro-Brazilian Congado Ritual. Empirical Musicology Review 6(2): 75-102.\n- Clayton, Martin (2009). Crossing Boundaries and Bridging Gaps: thoughts on relationships between ethnomusicology and music psychology. Empirical Musicology Review 4(2): 75-77.\n- Clayton, Martin (2007). \'Observing entrainment in music performance: video-based observational analysis of Indian musicians’ tanpura playing and beat marking\'. Musicae Scientiae 11(1): 27-59.\n- Clayton, Martin (2007). \'Time, gesture and attention in a khyal performance\'. Asian Music 38(2): 71-96.\n- Clayton, Martin, Sager, Rebecca & Will, Udo (2005). \'In time with the music: the concept of entrainment and its significance for ethnomusicology\'. European Meetings in Ethnomusicology 11 (ESEM Counterpoint 1): 1-82.\n- Clayton, Martin (1999). \'A. H. Fox Strangways and the Music of Hindostan: revisiting historical field recordings\'. Journal of the Royal Musical Association 124: 86-118.\n- Clayton, Martin (1998). ""You can\'t fuse yourself"": Contemporary British-Asian music and the musical expression of identity. East European Meetings in Ethnomusicology 5: 73-87.\n- Clayton, Martin (1997). Le metre et le tal dans la musique de l\'Inde du Nord. (translated by Georges Goormaghtigh). Cahiers de Musiques Traditionelles 10: 169-189.\n- Clayton, Martin (1996). Ethnographic Wax Cylinders at the British Library National Sound Archive: A Brief History and Description of the Collection. British Journal of Ethnomusicology 5(1): 67-92.\n- Clayton, Martin (1996). Free Rhythm: Ethnomusicology and the Study of Music Without Metre. Bulletin of the School of Oriental and African Studies 59(2): 323-332.\n- Clayton, Martin (1993). Two gat Forms for the sitār: A Case Study in the Rhythmic Analysis of North Indian Music. British Journal of Ethnomusicology 2(1): 75-98.\nOther (Digital/Visual Media)\n- Polak, Rainer, Tarsitani, Simone & Clayton, Martin (2018). IEMP Malian Jembe.\n- Clayton, Martin, Leante, Laura & Tarsitani, Simone (2018). IEMP North Indian Raga.\n- Clayton, Martin & Sahasrabuddhe, Veena (1999). \'Khyal: Classical singing of North India\' (DVD).\n- Clayton, Martin & Sahasrabuddhe, Veena (1999). \'Khyal: Classical Singing of North India\' Accompanying booklet.\n- Clayton, Martin & Cook, Simon (1999). \'Wayang Golék: Performing arts of Sunda (West Java)\' (DVD).\n- Clayton, Martin & Cook, Simon (1999). \'Wayang Golék: Performing arts of Sunda (West Java)\' Accompanying booklet.']"	['<urn:uuid:898542eb-04bc-45aa-9c9b-c5a01e7420a4>']	open-ended	direct	concise-and-natural	similar-to-document	single-doc	expert	2025-05-13T04:02:16.770989	13	41	1494
71	What are SCR efficiency rates and EGR drawbacks for NOx control?	SCR can achieve over 90% reduction in NOx, while EGR has several drawbacks: it increases particulate emissions due to reduced oxygen availability, reduces peak engine power requiring shutdown at full power demand, has delayed valve response times during transient operation, and faces challenges with uneven gas distribution between cylinders.	"['System to Control Nitrogen Oxides (NOx) in Coal Fired Power Plants\nBy Dr. Prasanna Seshadri\nCommonly referred to as NOx, Nitrogen oxides are one of the primary pollutants emitted by high temperature combustion systems such as pulverized coal (PC) fired boilers. Due to its role in both acid rain and ozone formation, NOx is a regulated pollutant under the EPA’s Clean Air Act. The options to reduce NOx emissions include source reduction and post combustion treatment of the flue gas. To control NOx at source, fuel and air distribution, otherwise referred to as staging, are modified to reduce flame temperatures. This is typically achieved by using low NOx burners.\nPost combustion measures for NOx control include both catalytic (SCR) and non-catalytic (SNCR) where NOx in the flue gas is reduced to molecular Nitrogen by reaction with Ammonia. However, it is quite common for utilities and other industrial combustion systems to employ both source reduction and flue gas treatment to meet required regulations. This paper will particularly focus on the two tail end options, SCR and SNCR, for flue gas NOx control.\nNitrogen oxides (NOx) denote the combined emissions of nitric oxide (NO), nitrogen dioxide (NO2) and other nitrogenous species in combustion derived flue gas. While NOx comprises all oxygenated nitrogen species, NO is the most dominant species in combustion gases accounting for anywhere between 95-99% of the total NOx in the gas stream. Together with SOx and Particulate Matter (PM), NOx is strictly regulated. NOx contributes to the formation of smog and acid rain, as well as increasing the amount of ozone (O3) in the earth’s troposphere. When NOx and volatile organic compounds (VOCs) react in the presence of sunlight, they form photochemical smog, which is a significant form of air pollution. The high concentrations of ozone in the atmosphere typically arise from high NOx emissions together with other reactive hydrocarbons, termed as VOCs. At lower levels, ozone is created by a chemical reaction between nitrogen oxides (NOx) and VOCs in the presence of heat and sunlight. Production of O3 follows the chain reaction mechanism as follows7:\nNOx + VOCs + Sunlight → O3 + other products (1)\nNO2 + hν → NO + O(3P), λ<400 nm (2)\nO(3P) + O2 → O3 (3)\nPeroxy-radicals (HOCO) in the atmosphere, produced as a result of carbon monoxide (CO) oxidation with the hydroxyl radical OH, go on to react with NO to produce NO2, which is then photolysed by UV-A radiation to give a ground-state atomic oxygen. This further reacts with molecular oxygen to form ozone7. While NOx emission limits vary globally, the U.S has one of the strictest limits in the world, especially for existing coal power plants. For new installations, the limits are even more stringent requiring the use of Best Available Control Technology (BACT) in both attainment and non attainment areas. Selective Catalytic Reduction, referred to as SCRs, is the current BACT for NOx control in power plants and also for other industrial applications. NOx is also regulated in combustion engine vehicles, especially vehicles using diesel engines.\n2. Nitrogen Oxides (NOx) From Fuel Combustion\nTypically, NOx formation happens during fuel combustion through two major pathways. In the first case, Nitrogen present in combustion air reacts with oxygen forming Nitrogen Oxide species. This is referred to as Thermal NOx and is a result of high combustion temperatures. The other major source of NOx is fuel NOx which is the result of fuel Nitrogen reacting with the oxygen in combustion air. Unlike thermal NOx, fuel NOx formation can happen at much lower gas temperatures. Fuel NOx is a significant contributor especially in coal power plants and can account for over 50% of the overall amounts of NOx generation. The control of NOx in combustion derived flue gas usually involves a two-phased approach – during fuel combustion and post treatment of flue gas. The primary focus of combustion control is to minimize thermal NOx formation and the latter option is to reduce the overall amount of already formed NOx.\n3. Control Techniques\n3.1. At Source Reduction\nWith the development of advanced burner technologies, NOx control begins with fuel combustion. Low NOx burners are designed to reduce the overall combustion temperature, thereby reducing the total amount of thermal NOx. Low NOx burners control fuel and air mixing to create larger and more branched flames. They accelerate fuel ignition and intensify combustion by achieving fuel rich conditions in the burner zone1. By improving ignitibility in rich fuel flame areas and producing moderate combustion in moderate fuel flame areas, the production of NOx emissions is reduced2.\nFigure 1. Low NOx type NR burner by Mitsubishi Hitachi Power Systems.\nNote. Adapted from https://www.mhps.com/products/boilers/technology/low-nox-burner/index.html\nCombustion reduction and burnout are achieved in three stages within a conventional low NOx burner. In the first stage, combustion occurs in a fuel rich, oxygen deficient zone where NOx formation takes place. In the second stage a reducing atmosphere follows where hydrocarbons react with the already formed NOx and reduce them to molecular Nitrogen. In the third and final stage of combustion an oxygen rich environment finalizes combustion of the fuel. Control of secondary air is important to ascertain full combustion, but not enough oxygen to regenerate NOx2.\nHowever, source control by itself is not enough to meet NOx emission standards. Downstream technologies are also required to further reduce NOx. The two most common downstream measures to control NOx are Selective Catalytic Reduction (SCR) and Selective Non-Catalytic Reduction (SNCR). Both technologies convert NOx in the flue gas to inert molecular Nitrogen by reaction with ammonia. The different reactions for NOx reduction are shown below and is applicable for both SCRs and SNCRs.\n4NO + 4NH3 + O2 → 4N2 + 6H2O (4)\n2NO2 + 4NH3 + O2 → 3N2 + 6H2O (5)\nNO + NO2 + 2NH3 → 2N2 + 3H2O (6)\nThere are process, efficiency and cost differences between the two technologies and due diligence is required to make a proper selection. The selection of NOx control systems needs to be done in coordination with the overseeing environmental agency.\n3.2. Selective Catalytic Reduction (SCR)\nSCRs are state of the art systems used to eliminate or reduce NOx emissions from the flue gas stream. In this process, ammonia (NH3) is injected into the flue gas stream to create a chemical reaction between NOx and NH3 forming inert Nitrogen molecules and water vapor as products. These chemical reactions are shown in equations 4-6. For the chemical reactions to occur, the gas needs to be between the optimum temperatures of 300°C and 400°C; therefore, the system is usually placed before the air preheater, at the exit of the economizer.\nThis technology uses a catalyst which facilitates the breakdown of NOx and increases the overall conversion efficiency. Most catalysts used in coal power plants consist of vanadium making up the active catalyst, and the substrate (or catalyst support) is usually made of titanium3. Active catalyst is finely dispersed across the support media. However, the final composition can consist of many active metals and support materials to meet specific requirements in each SCR installation. Typically, over 90% reduction in NOx can be achieved with the installation of a SCR6. SCRs are also a widely used technology in the off-gas treatment of large gas combustion turbines.\nFigure 2. Schematic of a SCR process.\nNote. Adapted from https://www3.epa.gov/ttn/ecas/docs/SCRCostManualchapter7thEdition_2016.pdf\nSCRs are designed to handle dust loads and do not require dust capture equipment upstream of the process. The system is relatively easy to maintain and capable of stable operation. While the system offers high NOx control, it is capital cost intensive and requires considerable plant outage time for retrofit applications.\nFigure 3. Selective Catalytic Reduction (SCR) System.\nNote. Adapted from https://www.mhps.com/products/aqcs/lineup/flue-gas-denitration/\nSCR capital costs vary by the type of unit controlled, the fuel type, the inlet NOx level, the outlet NOx design level, and reactor arrangement. Data collected on new installations between 2012- 14 indicated SCR costs ranged from $270/kW to $570/kW5. Typical operation and maintenance costs are approximately 0.1 cents per kilowatt-hour (kWh)5. Operating costs for SCR consist mostly of replacement catalyst and ammonia reagent, and while historically the catalyst replacement has been the higher cost, the reagent cost has become the most substantial portion of operating costs for most SCR. Since the gas pressure drops across the SCR system, the plant may also require ID fan modifications to compensate for the increased pressure loss.\n3.3. Selective Non-Catalytic Reduction (SNCR)\nWhile SCR is considered as the BACT, in certain applications, SNCR technology can be deployed at a relatively low capital cost. However, SNCR does not employ a catalyst and NOx reduction is typically a modest 30-50%4 for most systems. This technology utilizes atomizing nozzles to inject ammonia directly into the hot gas to chemically reduce NOx to Nitrogen and water vapor. Unlike the SCR, NH3 injection is at a much higher temperature window between 850-1050 C4. The goal is to maximize NOx control performance while optimizing chemical utilization with low reagent consumption.\nFigure 4. Schematic of SNCR process.Note. Adapted from https://www3.epa.gov/ttnecas1/models/SNCRCostManualchapter_Draftforpubliccomment-6-5- 2015.pdf\nAdditionally, urea can also be used as a reagent for SNCR applications. Urea (NH2CONH2) is easier to handle and store than NH3. Hence, urea-based systems are more common than ammonia based deployments, but operating data reveals higher NOx reductions occur with ammonia reagent. This is mainly due to improper and incomplete gas mixing with urea injection compared to anhydrous ammonia. Urea dissociates into ammonia first and then reacts with NOx as shown in chemical reactions 4-6. The dissociation of urea to ammonia is as follows: NH2CONH2 + H2O -> 2NH3 + CO2 (7)\nFigure 5. Urea based SNCR process schematic.\nNote. Adapted from https://www3.epa.gov/ttnecas1/models/SNCRCostManualchapter_Draftforpubliccomment-6-5- 2015.pdf\nThe effect of temperature is critical for SNCR applications. Not only does temperature affect conversion efficiencies, but it can also have a debilitating effect if ammonia or urea is injected outside the recommended range. At lower temperatures NO and the ammonia do not react. Ammonia that has not reacted is called ammonia slip and can react with other combustion species, such as sulfur trioxide (SO3), to form ammonium salts. These salts can later form hard deposits on downstream equipment thereby reducing operating efficiencies. At higher temperatures ammonia decomposes to form more NOx.\nSNCR is applied in a wide range of industrial processes, including cement and steel production. While not a BACT option for power plants, it is suited for areas under Reasonable Available Control Technology (or RACT) protocol. Retrofits are also much easier and require a small area for installation. Available data for Best Available Retrofit Technology (BART) analyses for 11 cement kilns indicates estimated NOx reductions for SNCR systems between 35 percent and 58 percent with a median reduction of 40 percent6.\nThe mechanical equipment associated with an SNCR system is simple compared to SCR and hence capital costs for SNCR installations are generally low. Based on available data, the installed capital cost of SNCR applications ranged anywhere between $5–20/kWe (kilowatt) for power generation units6. The absence of an expensive catalyst reduces CapEx requirements for both new systems as well as retrofits. Most of the cost of using SNCR is an operating expense. Reagent costs currently account for a large portion of the annual operating expenses associated with this technology. The annual cost of reagent purchase in $/yr is estimated using the reagent volumetric flow rate, the total operating time, and the unit cost of reagent. One of the bigger challenges with SNCRs is the stack emission of ammonia slip and this concentration is typically higher than SCRs due to larger injection rates. The temperature window at which SNCR typically operates plays a role in NH3 slip levels. Distribution of the reagent can be challenging especially in larger coal-fired boilers because of the long injection distance required to cover the relatively large cross-section of the boiler. Multiple layers are required to adjust to constantly changing boiler loads and this makes it challenging to fine-tune. Additionally, when urea is injected, large quantities of water are required, which can result in efficiency losses.\nDepending on the type of process, PEC Consulting can help in the selection of the best control technology to help reduce NOx emissions. We conduct an objective analysis to select the most feasible and efficient option to meet overall process and environmental requirements.\nSTEAM / Its Generation and Use, The Babcock & Wilcox Company, 42nd Edition 2. International Energy Administration, Clean Coal Centre, Clean Coal Technologies, “Low NOX Burners”, https://www.iea-coal.org/low-nox-burners/\nInternational Energy Administration, Clean Coal Centre, Clean Coal Technologies, “Selective Catalytic Reduction (SCR) For NOx Control”, https://www.iea coal.org/selective-catalytic-reduction-scr-for-nox-control/\nInternational Energy Administration, Clean Coal Centre, Clean Coal Technologies, “Selective Non-Catalytic Reduction (SNCR) For NOx Control”, https://www.iea coal.org/selective-non-catalytic-reduction-sncr-for-nox-control/\nChapter 2, Selective Catalytic Reduction,\nhttps://www3.epa.gov/ttn/ecas/docs/SCRCostManualchapter7thEdition_2016.pdf 6. Chapter 1, Selective Noncatalytic Reduction, https://www3.epa.gov/ttnecas1/models/SNCRCostManualchapter_Draftforpubliccomm ent-6-5-2015.pdf\nReeves, Claire E.; Penkett, Stuart A.; Bauguitte, Stephane; Law, Kathy S.; Evans, Mathew J.; Bandy, Brian J.; Monks, Paul S.; Edwards, Gavin D.; Phillips, Gavin (2002-12-11). “Potential for photochemical ozone formation in the troposphere over the North Atlantic as derived from aircraft observations during ACSOE”. Journal of Geophysical Research: Atmospheres. 107 (D23)\nDr. Prasanna Seshadri is an experienced engineer with strong background in process design, project engineering and management, technology and new product development for a wide range of energy conversion and environmental control processes used in power and other heavy manufacturing industries. He is Subject Matter Expert (SME) for solid fuel combustion, acid gas, and heavy metals emission control for thermal conversion systems and wastewater treatment. He has a BS in Chemical Engineering from the University of Madras, India, MS in Environmental Engineering and PhD in Energy Engineering from the University of North Dakota.', ""In many countries around the world, the emissions of NOx from diesel and gasoline vehicles are restricted by legislation. NOx is formed in the combustion chamber of engines, when high temperatures cause oxygen and nitrogen (both found in the air supplied for combustion) to combine.\nExhaust Gas Recirculation\nA widely adopted route to reduce NOx emissions is Exhaust Gas Recirculation (EGR). This involves recirculating a controllable proportion of the engine's exhaust back into the intake air. A valve is usually used to control the flow of gas, and the valve may be closed completely if required.\nThe substitution of burnt gas (which takes no further part in combustion) for oxygen rich air reduces the proportion of the cylinder contents available for combustion. This causes a correspondingly lower heat release and peak cylinder temperature, and reduces the formation of NOx. The presence of an inert gas in the cylinder further limits the peak temperature (more than throttling alone in a spark ignition engine).\nThe gas to be recirculated may also be passed through an EGR cooler, which is usually of the air/water type. This reduces the temperature of the gas, which reduces the cylinder charge temperature when EGR is employed. This has two benefits- the reduction of charge temperature results in lower peak temperature, and the greater density of cooled EGR gas allows a higher proportion of EGR to be used. On a diesel engine the recirculated fraction may be as high as 50% under some operating conditions.\nAdvantages of EGR\n- Reduced NOx\n- Potential reduction of throttling losses on spark ignition engines at part load\n- Improved engine life through reduced cylinder temperatures (particularly exhaust valve life)\nDisadvantages and Difficulties of EGR\nSince EGR reduces the available oxygen in the cylinder, the production of particulates (fuel which has only partially combusted) is increased when EGR is applied. This has traditionally been a problem with diesel engines, where the trade-off between NOx and particulates is a familiar one to calibrators.\nThe deliberate reduction of the oxygen available in the cylinder will reduce the peak power available from the engine. For this reason the EGR is usually shut off when full power is demanded, so the EGR approach to controlling NOx fails in this situation.\nThe EGR valve can not respond instantly to changes in demand, and the exhaust gas takes time to flow around the EGR circuit. This makes the calibration of transient EGR behavior particularly complex- traditionally the EGR valve has been closed during transients and then re-opened once steady state is achieved. However, the spike in NOx / particulate associated with poor EGR control makes transient EGR behavior of interest.\nThe recirculated gas is normally introduced into the intake system before the intakes divide in a multi-cylinder engine. Despite this, perfect mixing of the gas is impossible to achieve at all engine speeds / loads and particularly during transient operation. For example poor EGR distribution cylinder-to-cylinder may result in one cylinder receiving too much EGR, causing high particulate emissions, while another cylinder receives too little, resulting in high NOx emissions from that cylinder.\nAlthough the term EGR usually refers to deliberate, external EGR, there is also a level of internal EGR. This occurs because the residual combustion gas remaining in the cylinder at the end of the exhaust stroke is mixed with the incoming charge. There is therefore a proportion of internal EGR which must be taken into account when planning EGR strategies. The scavenging efficiency will vary with engine load, and in an engine fitted with variable valve timing a further parameter must be considered.\nApplication of Cambustion Analyzers to EGR Development\nCambustion's CLD500 NOx analyzer offers two channels of simultaneous NOx measurement, with a T10-90% of 10ms or less. This allows NOx concentrations in the exhaust to be measured for each firing cycle, allowing cyclic variability to be observed.\nCambustion's NDIR500 CO&CO2 analyzer offers two channels of simultaneous CO & CO2 measurement, with a T10-90% of 8ms. This allows a variety of applications:\nSampling with the NDIR500 in the intake allows measurement of CO2 concentration in the intake charge. Measurement of exhaust CO2 with the other channel of the NDIR allows calculation of the external EGR rate, on a cycle by cycle basis.\nDepending on the location of the intake probe, either the overall EGR rate or the EGR rate specific to one cylinder may be measured. This allows verification and improvement of EGR modeling and EGR distribution, including transients.\nSampling with the NDIR probes at different points through the EGR loop allows characterization of EGR system delays and behavior.\nComparison of the CO2 concentration in the pre-combustion gas with the exhaust gas from the previous cycle allows total EGR (internal + external) to be calculated. This technique can therefore reveal cyclical variation, as well as cylinder to cylinder variation. Such a capability may also be useful when verifying the effects of variable valve timing.\nCambustion's DMS Series particulate analyzers are capable of making exhaust particulate concentration measurements (both particle number and particle mass) and have a T10-90% response time as low as 200ms. While this is not fast enough for cycle by cycle resolutions, the DMS series allows fine tuning of EGR for particulate emissions, and the ability to measure directly in the exhaust allows comparison of different cylinders.""]"	['<urn:uuid:87540a4c-f429-4cc7-9f8c-4a4655c65286>', '<urn:uuid:77bc6828-c2f8-49f1-9280-3f61589aad73>']	factoid	direct	concise-and-natural	similar-to-document	multi-aspect	expert	2025-05-13T04:02:16.770989	11	49	3150
72	navy pt boat jfk taps connection	JFK served as a PT boat commander in World War II, specifically commanding PT-109 in the Solomon Islands, where he heroically rescued a burned crewman after his boat was sliced in half by a Japanese destroyer. Interestingly, Taps, which would later be played at Kennedy's own funeral, became an official part of military funeral services in 1891, long before Kennedy's military service and eventual presidential funeral.	"['The history of Taps is somewhat clouded by myth and legend, but the importance of this iconic bugle call cannot be argued. The twenty-four notes of Taps compose, arguably, the most recognizable and emotionally charged music ever played on a bugle. Although we usually associate Taps with military funerals (right), that was not always the case.\nOriginally, Taps was intended to signal lights out, but it was not long before it was co-opted as an important part of military funerals in America. According to most accounts of the history of Taps, soon after the tune was written in 1862, it was first used in a funeral ceremony:\n""During the Peninsula Campaign in 1862, a soldier of Tidball\'s Battery A of the 2nd Artillery was buried at a time when the battery occupied an advanced position concealed in the woods. It was unsafe to fire the customary three volleys over the grave, on account of the proximity of the enemy, and it occurred to Capt. Tidball that the sounding of Taps would be the most appropriate ceremony that could be substituted.""\nDespite being widely used during military funerals for many years, Taps was not made an official part of the military funeral service until 1891.\nSo, we know what Taps is, and how it came to be used as a part of military funeral honors... ...but where does the tune itself come from? Good question! To find out, read on...\nSuch a moving and iconic piece of music is bound to have a great story attached to it isn\'t it? Yes it is, but that doesn\'t necessarily mean that the story is true...\nThere is a common legend surrounding the history of Taps that has been around for years, and has taken on a new life in the internet age. It goes something like this...\nIn 1862, Union Captain Robert Ellicombe was hunkered down with his men near Harrison\'s Landing, Virginia. The Union army was being pressed by the Confederates after having been routed during the Seven Days Battles.\nOne night, Captain Ellicombe heard a wounded soldier moaning in the no-man\'s-land between the two armies. Risking his own life, the Captain moved out between the lines to carry the wounded man to safety.\nWhen he was finally back behind his own lines, Captain Elliscombe discovered that the young soldier he had carried was actually a Confederate, and had died just as they reached the hospital tent.\nUpon further inspection, the face of the Confederate soldier looked somewhat familiar. Suddenly, the Captain came to the shocking realization that the young man was his own son.\nConsumed by grief, Captain Elliscombe asked to be able to bury his boy with military honors, but he was denied, because, his son was a Confederate. However, he was allowed to have a bugler to play as his son was lowered into his grave.\nWhen asked what he would like the bugler to play, the Captain provided a piece of paper that his son had been carrying. On the paper was written a series of twenty-four notes. It is said that this haunting scene was the first time that Taps was ever played.\nThis story originated with Ripley\'s Believe it or Not, and seems to fall into the Not category. The largest flaw in the story is the fact that there is no record of a Captain Elliscombe having ever served in the Army of the Potomac. Unfortunately, this legend has obscured the true history of Taps and how it was originally written...\nThe true history of Taps is much less romantic, but there was one kernel of truth in the Captain Elliscombe story. Taps was, in fact, written at Harrison\'s Landing, after the Seven Days Battles, in 1862.\n...but as we already know, it did not originate as a piece of funeral music. It originated as a call for lights out...\nAt that time, the call for lights out was a French tune called Extinguish Lights, but Union General Daniel Butterfield (left) felt this was too formal. Instead, he wanted a more soothing call to tell his men that the day was over, so he turned to an old, unused tune called Scott\'s Tattoo.\nThe term tattoo was derived from an old Dutch military word which meant it was time to turn off the beer taps and return to camp. Tattoo was usually played about an hour before lights out, to give soldiers time to prepare to end the day.\nScott\'s Tattoo had been replaced by a newer tattoo in the Union Army, and Butterfield felt it was a good starting place for his new call to lights out. He called for his brigade\'s bugler, Oliver Wilcox Norton, and the two worked together to write Taps. Here is Norton\'s account of how that meeting went:\n""One day, soon after the seven days’ battles on the Peninsular, when the Army of the Potomac was lying in camp at Harrison’s Landing, General Daniel Butterfield sent for me, and showing me some notes on a staff written in pencil on the back of an envelope, asked me to sound them on my bugle. I did this several times, playing the music as written. He changed it somewhat, lengthening some notes and shortening others, but retaining the melody as he first gave it to me. After getting it to his satisfaction, he directed me to sound that call for “Taps” thereafter in place of the regulation call. The music was beautiful on that still summer night and was heard far beyond the limits of our Brigade. The next day I was visited by several buglers from neighboring brigades, asking for copies of the music which I gladly furnished. I think no general order was issued from army headquarters authorizing the substitution of this for the regulation call, but as each brigade commander exercised his own discretion in such minor matters, the call was gradually taken up through the Army of the Potomac.""\nAs Norton suggested, Taps spread quickly within the Army of the Potomac, and soon saw widespread use as the call to lights out. Within a few months, it had become common to use Taps during funeral services (thanks to Captain Tidball).\nThe tune also quickly gained widespread use for lights out in the Confederate Armies, and roughly ten months after Butterfield and Norton put the finishing touches on Taps, it was played at the funeral service of Confederate General Stonewall Jackson.\nHere is an interesting History Channel video about the history of Taps, and it also includes the famous ""broken note"" from President John F. Kennedy\'s funeral...', 'John Fitzgerald Kennedy was one of America\'s most charismatic and popular presidents. His heroism during World War II has been well documented. His leadership and no-blink courage during the Cuban Missile Crisis Â with World War III in the balance Â ensures his place among world leaders of the ages. Kennedy\'s peccadillos outside the Oval Office were met by the American public with a collective blush.\nThe tragic end to the JFK era in Dallas on November 22, 1963, ripped the heart out of American innocence and stunned the world into recognizing the cataclysmic social and political changes that were occurring in every corner of the globe.\nFare thee well, Camelot.\nThe early years\nBorn in May 1917, John was the second child of Joseph and Rose. Known in his Irish-Catholic neighborhood as ""Jack,"" he was a sickly child, having suffered from whooping cough, scarlet fever, and other maladies. After taking a turn for the better, his family could easily joke that if a mosquito were to bite him, it would be the insect\'s life in danger.\nJack was part of a large household with elder brother Joseph Jr., younger sisters Rosemary, Kathleen, Eunice, and Patricia, younger brother Robert, sister Jean, and youngest brother Edward, better known as Teddy.\nDespite his long list of illnesses, Jack was full of life and was well liked. His father had endowed him with a competitive spirit, and Jack enjoyed a number of sports. His main competition was his brother and best friend, Joe Jr.\nKennedy tapped a promising future by attending an exclusive prep school, Choate Rosemary Hall, in Wallingford, Connecticut, and was a member of ""The Muckers,"" a select group of practical jokers. Jack\'s final prank was to ""fix"" an election, naming himself ""Most Likely to Succeed.""\nJack succeeded indeed, by graduating from Harvard just as World War II broke out. His thesis was good enough to be published in book form with the title Why England Slept, iterating England\'s unpreparedness for war with Germany.\nFollowing graduation, Jack joined the Navy. With his credentials and aid from his father, now the U.S. Ambassador to England, he was made an ensign and assigned to naval intelligence in Washington, D.C. He was there when the attack on Pearl Harbor occurred.\nSoon after, Kennedy volunteered for PT boat duty and took his training in Rhode Island. A bad back kept him from combat service and he was known to complain that he was ""getting the shaft."" That bit of grumbling earned him the moniker ""Shafty.""\nNevertheless, Kennedy was named the commander of an 80-foot patrol torpedo boat, the PT-109, whose theater of operations was the Solomon Islands.\nWhile on night patrol in August 1943, a Japanese destroyer came out of nowhere and sliced Kennedy\'s boat in half. Out of a crew of 12, two died instantly. Others had leaped overboard moments before impact and made their way to a piece of flotsam.\nThe collision injured Kennedy\'s back, but he managed to rescue a burned crewman. He hauled him to the wreckage where the other crewmen were clinging for dear life.\nAs dawn broke, they made their way to a small island a few miles distant. Subsisting on coconuts and rainwater, the men were discovered by friendly natives and eventually rescued by the Navy.\nThe event made headlines in the New York Times and was later made into a movie. Altogether, Kennedy spent nine months in the South Pacific. When he returned stateside, he underwent back surgery.\nIn June 1944, Kennedy received the Gallantry in Action medal after earlier being honored with the Purple Heart. In August of that year, brother Joseph was killed when his plane exploded shortly after takeoff while carrying more than 21,000 pounds of explosives meant for a German V-1 rocket launching pad in Normandy, France.\nJack the politician\nBacked by his father and ""Honey Fitz"" Fitzgerald, his maternal grandfather and ex-mayor of Boston, Kennedy campaigned hard for a seat in the U.S. Congress. With his war heroics serving as a plus, he handily defeated his opponents.\nKennedy held that seat until 1952, when he ran for the U.S. Senate against the popular Republican incumbent, Henry Cabot Lodge Jr., who was from a family that could trace its roots to the Mayflower. In a close election, Kennedy pulled off an upset.\nIn 1953, he managed another upset by wooing and eventually marrying the beautiful Jacqueline Lee Bouvier.\nIn 1955, Kennedy underwent more back surgery. During his lengthy hospital stay and rehabilitation, he wrote Profiles in Courage, a book that analyzed the lives of eight notable U.S. Senators. The book earned Kennedy the Pulitzer Prize for biography.\nThe first bump in the road of Kennedy\'s political career arrived as he lay in the hospital. The Senate censured Senator Joseph McCarthy for instigating a nationwide panic over Communists in the U.S. government. Kennedy didn\'t cast a vote, so he was criticized for not jumping on the anti-McCarthy bandwagon. Kennedy was in a bind: McCarthy had been a guest at the Kennedy retreat in Hyannisport and brother Bobby Kennedy had served on McCarthy\'s staff.\nKennedy\'s persona drew more attention when he began to serve on the Senate Select Committee to Investigate Improper Activities in Labor-Management Relations. The committee investigated racketeering among labor union chieftans. The result was a bill that Kennedy sponsored, to rid the unions of criminal activities.\nKennedy now enjoyed the national spotlight. He had narrowly lost the nomination for the vice-presidential spot on the Adlai E. Stevenson ticket for 1956, but was re-elected to the Senate with more than 73 percent of the vote. When told by an old pol that he should easily capture the vice-presidential nomination in 1960, Kenndy replied, ""I\'m not running for the vice-presidency anymore. I\'m running for the presidency.""\nAfter securing the Democratic nomination in a close race with Lyndon B. Johnson from Texas, Kennedy named Johnson as his running mate.\nA crucial factor in the election was the first televised presidential debate. The Republican nominee, Richard M. Nixon, refused makeup and was feeling ill, owing to a knee injury on the way to the studio. He expected to win voters with his foreign-policy expertise, but viewers beheld a pale, profusely sweating man with a five-o\'clock shadow, wearing a gray suit that blended into the scenery while his rival looked tanned and well.\nLater research indicated that those who had listened to the debate on radio thought Nixon had won, but the television audience gave the win to Kennedy.\nThe campaign assumed two main themes: The economic issue was the Soviet Union\'s high economic growth rate compared to that of the United States. According to analysis at the time, the Soviet economy was expected to overtake the American economy by 1984.\nKennedy also claimed that the Republican administration had allowed a ""missile gap"" to open by not matching Soviet defense spending and allowing the U.S. military to weaken. The claim was made more credible by Soviet superiority in the space program, as evidenced by their successful Sputnik orbit, contrasted by numerous U.S. launch failures. In retrospect, there never was a missile gap.\nThe election results were so close that Nixon was urged to call for a recount in such key states as Illinois, Missouri, and New Jersey. He publicly refused, but privately wanted 11 states included in the recount. Legal battles stretched into the summer of 1961, long after Kennedy had been inaugurated.\n""And so, my fellow Americans: ask not what your country can do for you Â ask what you can do for your country. My fellow citizens of the world: Ask not what America will do for you, but what together we can do for the freedom of man.""\nAt the age of 43, Kennedy became the second-youngest president* (minimum age is 35) and first Roman Catholic ever, winning by the slimmest of margins Â 115,000 votes.\n-John F. Kennedy, from his Inaugural Address\nAs Kennedy entered the glare of the Oval Office, he did so amidst tensions in Southeast Asia and nearby Cuba, as well as the continuing space and arms race with the Soviets.\nHe suffered a rude awakening in April 1961 when the Bay of Pigs Invasion to overthrow Cuban dictator Fidel Castro turned sour. The invasion facilitated Castro\'s call for more aid from the Soviet Union.\nIn June, Kennedy met with Nikita Khrushchev in Vienna for two days of meetings. The Soviet leader carried away an impression that the U.S. president lacked resolve. The fearsome Cuban Missile Crisis of October 1962 proved Khrushchev\'s impression wrong, when he acceded to Kennedy\'s demand that Soviet nuclear missiles recently installed in Cuba be taken out.\nIn February 1962, John Glenn became the first American to orbit the earth. That prompted Kennedy to pledge that the U.S. would put a man on the moon ""before the end of this decade.""**\nOn the foreign relations front, Kennedy created the Peace Corps. The program, which still exists, encourages Americans to give of their talents in Third-World countries. Volunteers are trained for the opportunity to educate youth and elders, facilitate community improvement projects and care for the environment.\nKennedy then made good on his promise to get tough on organized crime by signing three bills into law that targeted the prohibition of telephone betting, interstate transportation for the purposes of racketeering,* and commercial transportation of betting equipment.\nFollowing the missile crisis, Kennedy moved on to make civil rights a priority of his administration. In June 1963, he ordered Alabama governor George Wallace to open the doors to the University of Alabama to students regardless of the color of their skin.\nAlso in 1963, Kennedy visited the Berlin Wall, where he delivered his electrifying speech containing the following: ""All free men, wherever they may live, are citizens of Berlin, and therefore, as a free man, I take pride in the words \'Ich bin ein Berliner.\'""\nThat fateful day\nOn November 22, 1963, the president and first lady arrived in Dallas, to board an open-top limousine with Governor John B. Connelly for a 45-minute ride to speak to a meeting of the Citizens Council. As the vehicle approached a triple overpass, shots were heard, and the president slumped forward with a mortal head wound.\nFifteen doctors attempted to save Kennedy\'s life, but to no avail.\nAfter solemn ceremonies, Kennedy\'s body was taken to Arlington National Cemetery. A promising statesman, father, and son was laid to rest.\n* Theodore Roosevelt was the youngest, at 42.\n**See also Robert Goddard .\n---- Selected Quotes ----\nQuotes by John F. Kennedy.\nRegarding Grandma Moses\nThe death of Grandma Moses removed a beloved figure from American life. The directness and vividness of her paintings restored a primitive freshness to our perception of the American scene. Both her work and her life helped our nation renew its pioneer heritage and recall its roots in the countryside and on the frontier. All Americans mourn her loss.\nNew York Times obituary, 1961\nRegarding Jacqueline Kennedy Onassis\nI do not think it altogether inappropriate to introduce myself to this audience. I am the man who accompanied Jacqueline Kennedy to Paris, and I have enjoyed it.\nRemarks in Paris, June 2, 1961\nRegarding New Frontier\nThe New Frontier of which I speak is not a set of promises Â it is a set of challenges. It sums up not what I intend to offer the American people, but what I intend to ask of them.\nAccepting Democratic nomination for president, 1960\nRegarding Man on the Moon\nI believe that this nation should commit itself to achieving the goal, before this decade is out, of landing a man on the moon and returning him safely to the Earth. No single space project in this period will be more impressive to mankind, or more important for the long-range exploration of space; and none will be so difficult or expensive to accomplish.\nSpeech to Congress, May 25, 1961\nThe problems of the world cannot possibly be solved by skeptics or cynics whose horizons are limited by the obvious realities. We need men who can dream of things that never were and ask ""why not?"".\nSpeech in Ireland, June 28, 1963']"	['<urn:uuid:d6366cbf-939d-46d0-8178-d850eacefacb>', '<urn:uuid:a6833bea-7be4-4550-9c4d-4cef9aec77a2>']	factoid	with-premise	long-search-query	distant-from-document	comparison	novice	2025-05-13T04:02:16.770989	6	66	3127
73	What are the pathways and risks in normal vs WPW hearts?	In a normal heart, electrical conduction starts at the SA node in the right atrium, travels to the AV node, and then reaches the ventricles in a controlled manner. In WPW syndrome, there is an additional accessory pathway that allows conduction to occur directly between atrium and ventricles, bypassing the AV node. This leads to preexcitation of the ventricles with uncontrolled higher rates causing tachycardias. The most serious risk occurs with atrial fibrillation in WPW syndrome, which can degenerate into ventricular fibrillation and cause sudden cardiac death, particularly in patients whose accessory pathway has an effective refractory period less than 250ms.	"[""br Conflict of interest br Case presentation A year\nConflict of interest\nCase presentation A 64-year-old female presented to the emergency room with persistent dizziness that began early that morning. She had a 30-year history of palpitations and known electrocardiogram (ECG) abnormalities. Her pulse was irregular at 130–270min−1 and blood pressure was 90/40mmHg. There were no other abnormalities on physical examination. A chest X-ray was normal and without cardiomegaly. Echocardiography revealed normal left ventricular contraction without structural abnormalities. Blood chemistry evaluation, including electrolytes and cardiac enzymes, was within normal limits. Twelve-lead ECG showed irregular wide QRS tachycardia of various configurations (Fig. 1).\nCommentary The patient\\'s ECG shows wide QRS tachycardia with a rate from 150 to 300beats/min. The RR intervals are irregularly irregular and no P wave preceding QRS was confirmed. The QRS complex has beat–beat variations in morphology. At this point, some of the arrhythmias that should be considered are: (1) irregular ventricular tachycardia (such as torsades des pointes or polymorphic ventricular tachycardia); (2) atrial fibrillation (AF) with bundle branch block; (3) AF in Wolff–Parkinson–White (WPW) syndrome (pseudo-ventricular tachycardia). The QRS complex shows right axis deviation during tachycardia with no progressive change in cardiac axis, thus polymorphic ventricular tachycardia and torsades des pointes associated with QT prolongation are excluded. Polymorphic ventricular tachycardia associated electrolyte abnormality and myocardial ischemia could not be totally excluded by this ECG, however laboratory examination did not indicate myocardial ischemia or an electrolyte abnormality. The representative arrhythmia of the patient\\'s irregular Prostaglandin E2 manufacturer rate is AF, which is the most common cardiac arrhythmia. When the ventricular rate is slow, AF can be easily diagnosed. However if the ventricular rate is rapid, AF is difficult to appreciate because QRS complexes are clustered together and fibrillatory waves become more difficult to evaluate. The QRS complexes during AF with bundle branch block usually do not have beat–beat variation, and both an Rr′ pattern in lead V1 and R\natrioventricular (AV) node and accessory pathways.\nTo terminate AF and block the accessory pathway, procainamide was given intravenously at a dose of 400mg over 30min. It is important to note that AV nodal blocking agents are contraindicated in treatment of AF in patients with WPW syndrome. AV nodal blocking agents, for example verapamil and digoxin, decrease the number of impulses conducted through the His–Purkinje system and enhance conduction across accessory pathways, thus increasing the ventricular rate during AF. If the patient is hemodynamically unstable, electrical cardioversion should be performed. After infusion of procainamide, this patient\\'s AF converted to normal sinus rhythm (Fig. 2) that included a short PR interval and a delta wave. A positive delta wave and QRS in V1 indicated a left sided accessory pathway.\nExplanations of the arrhythmia AF is the most serious arrhythmia associated with WPW syndrome. This arrhythmia has the possibility of degenerating into ventricular fibrillation, which can cause sudden cardiac death. Although the occurrence of ventricular fibrillation is rare, even among symptomatic patients with WPW syndrome, AF carries the potential for sudden cardiac death. The risk of sudden cardiac death in patients with WPW syndrome is related to the short effective refractory period of the anterograde accessory pathway. Electrophysiological studies are performed to measure the refractory period of the accessory pathway. Patients with an accessory pathway with an effective refractory period of less than 250ms, as measured by an R–R interval between 2 preexcited complexes of <250ms during AF, are defined as high risk."", 'Wolff-Parkinson-White (WPW) syndrome is a congenital cardiac abnormality that manifests itself as a conduction irregularity found between the sinoatrial (SA) and atrioventricular (AV) nodes. In an otherwise healthy heart, electrical conduction begins at the SA node, which is located in the right atrium. An electrical pulse is then sent downward causing the atrium to contract and subsequently reaching the AV node, which acts as the connecting catalyst to allow the electrical pulse to reach the ventricles causing them to contract.1This pathway is controlled as electrical conduction is regulated by the SA and AV node. However, in a patient with Wolff-Parkinson-White syndrome, there is an extra pathway—also known as the accessory pathway—that allows conduction to occur directly between the atrium and ventricles, bypassing the AV node, thus leading to preexcitation of the ventricles. This preexcitation allows conduction to occur with higher and uncontrolled rates resulting in tachycardias.2 The electrocardiogram (ECG) shows a shortened PR interval and the characteristic “delta wave” which resembles a slurring slow rise of the initial portion of the QRS interval.\nPathophysiology and Treatment:\nIn the long-term preventative setting, WPW is managed surgically through catheter ablation.3 However, in the emergent setting treatment is dictated by specific manifestations of WPW associated arrhythmias. There is WPW with orthodromic tachycardia, WPW with antidromic tachycardia, and WPW with atrial fibrillation.4\n1. WPW with orthodromic tachycardia\nA. Orthodromic tachycardia occurs when the electrical circuit travels normally from the SA node to the AV node and down the Purkinje fibers; however, the circuit reenters the atrium via the accessory pathway causing the tachycardia as represented in Figure 1.\na. This rhythm resembles a supraventricular tachycardia (SVT) even though etiology is slightly different; however, treatment is identical.5\nB. Diagnosis is made through electrocardiogram (ECG).\na. ECG will show a regular narrow QRS complex tachycardia resembling a SVT as seen in Figure 1.6\na. Due to its similar mechanism as SVT, orthodromic tachycardia can be treated the same method as a SVT with an AV node blocker (AVNB).5\n– Adenosine7, 8\n– Verapamil8, 9\n– Beta blockers10\n2. WPW with antidromic tachycardia\nA. Antidromic tachycardia occurs when the electrical circuit travels from the SA node through the accessory pathway first, then up the Purkinje fibers, and through the AV node all through a retrograde or opposite direction than the orthodromic tachycardia as seen in Figure 1.\na. This rhythm resembles a ventricular tachycardia (VT), even though etiology is slightly different; however, treatment is identical.6\nB. Diagnosis is also made through ECG.\na. ECG will show a regular wide QRS complex tachycardia resembling a ventricular tachycardia as seen in Figure 1.6\na. It is necessary to treat with agents that selectively target the accessory pathway.\n– Loading dose: 20 to 50 mg/min IV infusion until arrhythmia suppressed, hypotension ensues, QRS prolonged by 50%, or total cumulative dose of 17 mg/kg12\n– Alternative loading dose: 100 mg every 5 minutes until arrhythmia is controlled or any condition described above is met.12\n– Follow with a continuous infusion of 1 to 4 mg/min (must reduce maintenance dose in patients with renal impairment).12\nc. Amiodarone150 mg IV over 10 minutes, then 1 mg/minute for 6 hours, then 0.5 mg/minute for 18 hours or change to oral dosing.13\nFigure 1. Diagrams of orthodromic and antidromic electrical pathways and associated ECG rhythms. Available at: https://umem.org/files/uploads/content/MattuECG%20Tumblr/OrthoAnti.jpg. Accessed August 4, 2014.\n3. WPW with Atrial Fibrillation\nA. This is the most dangerous etiology of the WPW manifestations due to its high risk of iatrogenic error and deadly ventricular arrhythmias.2\nB. In WPW with atrial fibrillation, electrical conduction in the heart travels down two paths, the normal pathway through the AV node AND from the atrium to the ventricles through the accessory pathway as seen in Figure 2.14\nC. Diagnosis is made through ECG.\na. The two electrical pathways manifest themselves on ECG as irregularly irregular rhythms.\n– While pulses that pass through the AV node have some rate regulation due to the AV node, impulses traveling through the accessory pathway have no rate regulation, leading to measured ventricular rates on ECG above 200 beats per minute (bpm).2\n> This lack of regulation through the accessory pathway causes the irregular wave morphologies with no consistencies in the QRS waves as seen in Figure 3.\n> In contrast, Figure 4 depicts a more typical atrial fibrillation without WPW where the QRS waves are seen to be more regular and ventricular rate does not exceed 150-200 bpm (due to the rate regulation caused by the AV node).\nb. Atrial fibrillation with WPW is often misdiagnosed as a SVT, VT, or atrial fibrillation with a bundle branch block.\n– If misdiagnosed, treatment with an AVNB will preferentially block the AV node and consequently divert all electrical impulses down the accessory pathway.15\n> This shunting of electrical impulses to the accessory pathway causes ventricular fibrillation and high risk of death.\n> Therefore, AVOID ALL AVNBs (i.e. adenosine, non-dihydropyridine calcium channel blockers, beta blockers, digoxin, and amiodarone) in patients with WPW with atrial fibrillation.\na. Immediate cardioversionis the recommended first line treatment for hemodynamically unstable patients when WPW with atrial fibrillation presents.16\nb. In a hemodynamically stable patient, procainamide can be used, as it selectively targets the accessory pathway.12\n– Per 2010 ACLS guidelines, procainamide dosing is as follows:\n> Loading dose: 20 to 50 mg/min IV infusion until arrhythmia suppressed, hypotension ensues, QRS prolonged by 50%, or total cumulative dose of 17 mg/kg12\n> Alternative loading dose: 100 mg every 5 minutes until arrhythmia is controlled or any condition described above is met. 12\n> Follow with a continuous infusion of 1 to 4 mg/min (must reduce maintenance dose for renal impairment).12\nFigure 2. Diagram of WPW with atrial fibrillation with associated ECG. Available at: http://www.rjmatthewsmd.com/Definitions/supraventricular_tachyarrhythmias.htm. Accessed August 9, 2014.\nAvailable at: http://osuemed.wordpress.com/2011/05/26/nightmare-ekg/. Accessed August 4, 2014.\nFigure 4. ECG of atrial fibrillation without WPW.\nAvailable at: http://www.emedu.org/ecg/af.htm. Accessed August 4, 2014.\nA. WPW orthodromic tachycardias are treated as SVT with an AVNB (i.e. adenosine, verapamil, beta blockers).\nB. WPW antidromic tachycardias are treated as VT with procainamide or amiodarone.\nC. WPW with atrial fibrillation is treated with immediate cardioversion if hemodynamically unstable. Procainamide is a reasonable choice in hemodynamically stable patients.\nEdwin Lim, PharmD Class of 2015\nThomas Jefferson University\nJefferson School of Pharmacy, Philadelphia, PA\nRobert Pugliese, PharmD, BCPS (@theEDpharmacist)\nClinical Specialist, Emergency Medicine\nThomas Jefferson University Hospital, Philadelphia, PA\nReviewed by: Craig Cocchio, PharmD, BCPS and Nadia Awad, PharmD, BCPS\n1. Wolff-Parkinson-White Syndrome (WPW). Available at: http://my.clevelandclinic.org/heart/disorders/electric/wpw.aspx. Accessed July 25, 2014.\n2. Sheinman BD, Evans T. Acceleration of ventricular rate by fibrillation associated with the Wolff-Parkinson-White syndrome. Br Med J (Clin Res Ed).1982;285(6347):999-1000.\n3. Jackman WM, Wang XZ, Friday KJ, et al. Catheter ablation of accessory atrioventricular pathways (Wolff-Parkinson-White syndrome) by radiofrequency current. N Engl J Med. 1991;324(23):1605-11.\n4. Josephson ME. Preexcitation syndromes. In: Clinical Cardiac Electrophysiology, 4th, Lippincot Williams & Wilkins, Philadelphia 2008. P.339.\n5. Goy JJ, Fromer M. Antiarrhythmic treatment of atrioventricular tachycardias. J Cardiovasc Pharmacol. 1991;17 Suppl 6:S36-40.\n6. Goldberger AL, Goldberger ZD, Shvilkin A. Clinical Electrocardiography: A Simplified Approach, Expert Consult: Online and Print,8, Clinical Electrocardiography: A Simplified Approach. Elsevier Health Sciences; 2012.\n7. Dimarco JP, Sellers TD, Lerman BB, et al. Diagnostic and therapeutic use of adenosine in patients with supraventricular tachyarrhythmias. J Am Coll Cardiol. 1985;6(2):417-25.\n8. Lim SH, Anantharaman V, Teo WS, et al. Slow infusion of calcium channel blockers compared with intravenous adenosine in the emergency treatment of supraventricular tachycardia. Resuscitation. 2009;80(5):523-8.\n9. Rinkenberger RL, Prystowsky EN, Heger JJ, et al. Effects of intravenous and chronic oral verapamil administration in patients with supraventricular tachyarrhythmias. Circulation. 1980;62(5):996-1010.\n10. Kowey PR, Friehling TD, Marinchak RA. Electrophysiology of beta blockers in supraventricular arrhythmias. Am J Cardiol. 1987;60(6):32D-38D.\n11. Worthley LI, Holt AW. Digoxin in the critically ill patient. Crit Care Resusc. 1999;1(3):252-64.\n12. Neumar RW, Otto CW, Link MS, et al. Part 8: Adult Advanced Cardiovascular Life Support: 2010 American Heart Association Guidelines for Cardiopulmonary Resuscitation and Emergency Cardiovascular Care. Circulation. 2010;122(18 Suppl 3):S729-67.\n13. Amiodarone Package Insert. Available at: http://dailymed.nlm.nih.gov/dailymed/lookup.cfm?setid=cdd50dc7-f712-4248-b0e3-ba247cf08cee#cbb97eba-08e3-4a99-ac87-e4697427b866. Accessed August 22, 2014.\n14. Das MK, Zipes DP. Electrocardiography of Arrhythmias, A Comprehensive Review. Elsevier Health Sciences; 2012.\n15. Schützenberger W, Leisch F, Gmeiner R. Enhanced accessory pathway conduction following intravenous amiodarone in atrial fibrillation. A case report. Int J Cardiol. 1987;16(1):93-5\n16. January CT, Wann LS, Alpert JS, et al. 2014 AHA/ACC/HRS Guideline for the Management of Patients With Atrial Fibrillation: Executive Summary: A Report of the American College of Cardiology/American Heart Association Task Force on Practice Guidelines and the Heart Rhythm Society. Circulation. 2014.']"	['<urn:uuid:2a2ea326-67cc-4d75-9ae0-a81fc2f326a4>', '<urn:uuid:589bf6cd-d0ad-48e3-86db-ad807367a49c>']	open-ended	direct	concise-and-natural	distant-from-document	multi-aspect	expert	2025-05-13T04:02:16.770989	11	101	1998
74	how many horses needed pull artillery gun 1700s	In the 1700s, the number of horses needed to pull artillery pieces varied by gun size. Light 3-pounder 'galloper guns' could be pulled by just one or two horses. However, larger 6-pounder guns typically required at least a four-horse team, and often more horses were needed, especially when roads were rutted or weather conditions were poor.	"[""Artillery at the start of the 18th century was slow, cumbersome and could easily be lost on the battlefield, yet it was also indispensable to any modern army, and at the start of his reign that is what Peter I of Russia wanted above all else. Peter’s reforming zeal, taking a backward state like Russia and forging a major European power, has since become legendary, and in the major reforms of the army the artillery received special attention. It took a long time to train the men and improve the guns, but Peter’s artillery was to play a major role in many of his victories, most notably that at Poltava, where it was decisive.\nThe first thing to say about this set is also the most obvious after looking at our pictures – you get a great deal for your money here. As with previous artillery sets Zvezda have proved themselves to be masters of this type of miniature, taking a lot of trouble to deliver something vastly superior to the usual gun plus a few crew repeated several times that we are familiar with from most manufacturers. To begin with then we will detail exactly what comes in the box.\nOur first few rows show the artillerymen, including an officer figure. Beside him is a draught horse which, since it is not attached to any burden, might seem superfluous, which it is. The usual Zvezda method of providing three sprues of one type plus a fourth of another has cleverly been used to deliver all the parts necessary for this set, but a small number of items (mostly small components) are repeated in excess of the need. This horse is the only major such piece, and the packaging points out that it is unused, but nonetheless it is perfectly good and could be put to use by those skilled and imaginative enough to wish to do so, so we have included it here.\nMoving down the rows we next find the first of the guns. On the left is a 6-pounder gun, and on the right a howitzer of half a pud (which was 20 pounds). Below them there is a 3-pounder gun, followed by the same weapon being drawn by a two-horse team. Further down still we have a limber, and finally an ammunition wagon.\nLooking in more detail at the crew figures, they all wear the relatively simple uniform of the day, which was much the same as the infantry (except of better quality), with the tricorn, coat and stockings being the only major visible parts. The officer has much finer clothes, but is ultimately only dressed as a gentleman of any European nation of the time would be dressed. All the clothing is authentic, as are the belts etc. Several of the figures have a musket slung across their back, which is something of a surprise. Artilleryman were certainly issued with muskets, but when actually serving the guns they would have put such an encumbrance to one side rather than carry it like this.\nThe men carry most of the normal tools of their trade. Clearly visible are the ramrod and ladle, while the two middle figures in the top row are carrying ammunition – roundshot and a pre-prepared charge respectively. The first figure in the second row is holding a powder horn, which would be used to fill the touchhole before firing, while the third looks to be holding one of the powder-filled tin tubes which were also used to prime the guns, although this could also simply be a tool to prick the powder bag inside the barrel and therefore make the piece ready for firing. The last man in this row holds the linstock (which is particularly short in this case), holding the match with which the gun was actually fired.\nThe other figures look to be man-handling the piece or aiming it, and the total set of figures are a really good representation of an artillery crew. All the poses are excellent, and have mostly been achieved in the usual Zvezda fashion of having separate arms. Indeed the first three figures in the top row are all the same basic figure but with different pairs of arms, and the same is true of the first three in the row below. We found some of these arms rather tricky to attach, although in some cases you can also adjust the angle of the arms to provide some variety of pose. The sculpting of these figures is great, with the ornate officer in particular being a miniature work of art all by himself. However on the down side some of the figures do have areas where detail disappears, despite the separate parts. Nevertheless this is still a very high quality finish for the most part, and certainly compare very favourably to the output of most companies.\nThe 6-pounder gun is the largest piece here, and has been brilliantly fashioned out of many parts, allowing a much better level of detail and sophistication than simpler models can offer. Even small details have been considered, like having the muzzle of the barrel separate so as to have a hole. As with all the assembly in this set the various parts go together with absolute firmness and you will barely have to reach for your glue at all. One feature that has been missed, however, is the pair of ‘dolphin’ handles on the gun barrel, which are represented by a slight ridge instead. We felt that this could have been something a bit more substantial, and therefore realistic, much as has been done in other Zvezda artillery sets. However the only real problem with this piece is the elevation of the barrel. This was controlled by placing a wedge under the breech, and for some reason this wedge, or quoin, is pegged into the gun and therefore fixed. This matters because, as it stands, the barrel is quite horizontal, which is perfectly possible but does not allow for any other angle. The solution is to trim the pegs off the wedge and reposition it further back, which is very little work but should surely have been designed like that to begin with.\nThe howitzer is on a smaller but otherwise very similar carriage. Again all the features of barrel and carriage are correctly done, with the exception of the same problem with the fixed wedge. Again the barrel is horizontal, which is ridiculous for a weapon that was meant to fire at a high trajectory. The same solution applies, but clearly the designer went astray on this not insignificant feature of the set.\nMoving down once more we find the budge barrel where the powder was stored, complete with closure to protect it from stray sparks, and next to that the smallest of the artillery pieces, the 3-pounder gun. Each infantry regiment had two of these pieces, often called galloper guns, to provide close support for the troops. They were relatively light and could therefore be moved with the men, and as a result were not concentrated in batteries like the larger calibres. Once more this is a great little model, and once more the positioning of the wedge forces a horizontal barrel. Although they should be able to elevate, such a horizontal position is more appropriate for these guns as they often fired at very short range. There are in fact three of this gun in the set, but as can be seen the third example is hitched up to a horse in the next row (although you can have it as a separate unhitched gun if you prefer). The trails of the gun took the harness for the animal, and you can optionally add a second horse with handler, as we have done in our picture. The horse is correctly harnessed and attaches in a proper manner rather than the all too common peg-in-the-side method sometimes seen. The harness will need gluing into the animal on this and all the models here, which is the main area where glue will be necessary.\nOne or two horses were sufficient to move a galloper gun, but the larger calibres required full teams. Our next picture shows a simple limber, with a three-horse team and driver ready to pull one of the larger guns. This is fine, including the peculiarly Russian method of having three horses abreast, but we were surprised that the team was so small. In general a 6-pounder required at least a four horse team, and often more, particularly if roads were especially rutted or the weather bad. The howitzer was a lighter piece, so we suggest that this limber is really only useful for the howitzer. Nonetheless it is again a very nice model.\nFinally, after so many words, we come to the last item – an ammunition wagon. Actually this is little more than a limber with an ammunition chest attached, and as such would be more appropriate for immediate support of guns in battle as the main ammunition wagons were larger four-wheeled vehicles with much greater carrying capacity. Still this is another great model and a very welcome addition to the set which is very useful. The ammunition chest has an optional insert representing the compartmentalised interior where the ammunition is held, so if desired the chest could have the separate lid hinged back to show the interior, although we chose the closed option as the horses are, after all, on the move! There is even a little bucket suspended from a hook at the rear.\nWe have already said a lot about this set, and most of it has been admiration, but there are some concerns too. First, ordinary artillerymen or ‘cannoniers' served the guns while bombardiers served howitzers. Bombardiers wore a version of the grenadier cap, and there are none in this set (although the Strelets set has some), so in fact the howitzer here has no crew. Also the mounted drivers are a worry. At this period, and for decades thereafter, artillery drivers and wagoners were recruited from civilians – contractors who would, or at least should, move the guns wherever the Board of Ordnance wanted. There is no evidence they were given any uniform, and were not under military discipline, so the smartly uniformed drivers in this set are probably out of place. Having said that military uniform of the day was not so very different from civilian fashion, but still we are uncomfortable with the appearance of these figures, who are armed with swords.\nIn essence then this is a great set but with a couple of issues as we have mentioned, yet undeniably beautifully engineered. It is also a very appealing set and very satisfying to put together, while the guns and men are little different from those of any nation in the Great Northern War, War of the Spanish Succession or other contemporary conflicts. We very much enjoyed putting this altogether, although we are tempted to enquire where the mounted officer shown on the box artwork went? It seems even the best sets could always be better, but overall this one will take some beating.""]"	['<urn:uuid:9e2a2152-34dc-40d6-b619-604b35c2c976>']	open-ended	with-premise	short-search-query	similar-to-document	single-doc	novice	2025-05-13T04:02:16.770989	8	56	1860
75	basketball court position movement scoring shots fundamental differences between solo performance team dynamic coordination tactics	In free throw situations, players perform individually with no variables except knee bend and ball release, shooting from a fixed 15-foot distance. In contrast, team offensive movements require complex coordination, with players needing to cut with purpose, maintain awareness of teammates' positions, communicate through eye contact and hand signals, and fill vacancies along the three-point line. These coordinated movements serve to break defensive positions and create scoring opportunities.	['In the basketball world, free throws are also known as the charity stripe. The free throw line is called the charity stripe because they are free points if you can make them, which means that they are really important to take advantage of. However, there is no more individual aspect of the game of basketball than at the free throw line. Your teammates cannot help you, the coaches cannot help you, and the fans cannot help you. It is just you and the mental games that take place in your head.\nFor many players, the way that they calm themselves down from the rapid pace of the game to the stagnated pace at the free throw line is by going through some type of repetitious motion. Basketball games go 100 miles per hour, while the free throw line comes to a complete halt at 0 miles per hour. That can be a hard adjustment for anyone to make.\nWhat repetition does is help players remain composed, even keeled, and it also triggers muscle memory whenever players step up to the free throw line. There is no discrepancy at the free throw line. The hoop is always fifteen feet away and because players do not elevate to shoot free throws, there really are no variables when shooting free throws. The only exceptions are the way you bend your knees and release the ball.\nThis has led to some of the most interesting and unique approaches at the free throw line. There is no standard way of going through a particular motion prior to taking a free throw. Every player is different and some are even superstitious. The only thing that is important is that the mechanics remain the same without too much variation. And if it is not broke, don’t fix it.\nThis is a list of the top 10 most famous and ugliest free throws of all-time. What sets these free throw shooters apart from everyone else’s free throws are the personalized touch and the uncommon peculiarity that they add to their free throw routines compared to everyone else’s.\n10. Jermaine O’Neal\nJermaine O’Neal has shot anywhere from 50% to 84% from the free throw line. The reason for the discrepancy may be due to his unusual free throw routine. Prior to a series of injuries O’Neal was a 20 and 10 type of player, so he could always score with a high level of consistency. But whenever he got to the free throw line, he abandoned his shooting stroke for something that looked like Charles Barkley’s golf swing. Everything about O’Neal’s free throw form looked good until he was about to release the ball. While most players have a fluid motion, O’Neal has a little stutter in his shot. Instead of releasing the ball in one motion, O’Neal holds it for an extra 2 seconds right before he releases, faking out even his teammates who are trying to box out for the rebound.\n9. Karl Malone\nKarl Malone was not a great free throw shooter when he first entered the league. He actually shot 48.1% his first season and 59.8% his second season. However, by the end of his illustrious career, Malone shot a respectable 74.2% from the free throw line. One of the reasons for his improvement from the charity stripe may have been due to his mysterious routine whenever he got to the free throw line. When the Mailman got to the line, he would spin the ball with both hands and whisper something under his breath as he was about to shoot the ball. No one really knows what Malone was saying, but his free throw routine took so long, opposing crowds from different arenas would start counting “One…Two…Three” to alert the refs how long Malone took to shoot free throws; not to mention throw him off from his fadeaway free throw.\n8. Jerry Stackhouse\nJerry Stackhouse has a smooth stroke, but he also had one of the most interesting free throw routines ever. The fundamentals of basketball say that players are supposed to bend their knees as they shoot the ball, but Jerry Stackhouse takes this to a totally different level. When Stackhouse steps to the free throw line, he not only bends his knees, but he bends his knees so low that he nearly goes into a squatting position. But as exaggerated as his shooting form looked, it must have worked because Stackhouse was a 82.2% free throw shooter for his career.\n7. Nick Van Exel\nNick the Quick had one of the fastest and smoothest releases in the NBA. However, his career free throw shooting percentage was under 80%. One of the reasons why Nick may not have been an elite free throw shooter is because he shot 2 feet behind the basket. The free throw line is fifteen feet from the basket, but Nick at Night shot his free throws seventeen feet from the basket. While most players want to be as close to the basket as possible, for some reason Van Exel shot his free throws the furthest away from the basket.\n6. Gilbert Arenas\nGilbert Arenas had one of the longest free throw shooting routines in the NBA. The former point guard for the Washington Wizards would wrap the ball behind his back three times before he shot the ball. You only get ten seconds to shoot a free throw and Arenas took nearly all of those ten seconds to go through his shooting routine. But it must have worked somewhat for him because Arenas was a career 80% free throw shooter.\n5. Michael Adams\nMichael Adams had one of the ugliest shooting forms the league has ever seen. Adams rarely made use of his guiding hand, which made it look like he was shot putting the basketball. When Adams shot the ball, the ball never even made it up to his forehead. His shot was sort of off of his right shoulder and then heaved forward. The surprising part was that Adams was a career 85% free throw shooter. It just goes to show that even if a shot may look ugly, it does not mean that it is ineffective.\n4. Jason Kidd\nThe Brooklyn Nets head coach had one of the most famous free throw routines when he was playing. Kidd would take a few bounces and then with his left hand blow a kiss to his wife and kids before he shot the ball. Kidd had a rocky relationship with his current ex-wife and was even charged with domestic violence during his playing days, so his free throw kiss was a message to his family every time he shot the ball. By and large, Kidd was not a great free throw shooter when he first entered the league. In fact, he shot below 70% for the first five seasons of his NBA career. However, by the end of his career, Kidd shot a respectable 78% from the free throw line.\n3. Jeff Hornacek\nJeff Hornacek had one of the most personalized free throw motions in the NBA. Before every shot, Hornacek would wipe the right side of his cheek three times. The reason? It was a way of saying hello to his three kids without actually saying it. Hornacek was not only a good father, but also a good free throw shooter. Hornacek shot a career 87% from the free throw line. In fact, in his last season in the NBA, Hornacek shot a ridiculous 95% from the free throw line.\n2. Wilt Chamberlain\nWhile there is no video evidence for this because this was so long ago, Wilt Chamberlain was so poor at shooting free throws that he would attempt to dunk it from the free throw line every time he had to step up to the charity stripe. The rules have changed today, so that the free throw shooter cannot cross the free throw line prior to the ball touching the ball the rim. The reason for this rule today was because of players like Chamberlain who would jump from the free throw line towards the rim on his free throws. Can you imagine that happening today? What a spectacle that would be with today’s athletes.\n1. Rick Barry\nIf you saw Rick Barry shoot free throws today you might laugh. That is until you saw the rate at which Barry was hitting those free throws. Rick Barry had a career average of 89% from the charity stripe. In fact, he shot over 90% in seven different seasons. How did he do it? Barry shot his free throws underhanded like he was playing in a game of horse. The really interesting part about Barry’s underhanded free throws was that he did not put his hands underneath the ball, but on top of the ball. Most people put both hands underneath the ball when they shoot underhanded, but Barry put it on top of the ball for more of a backwards spin.\n- Ad Free Browsing\n- Over 10,000 Videos!\n- All in 1 Access\n- Join For Free!', 'How you ever had that game whereby your team mates are just standing around, waiting for the ball to come to them? It’s between attacking the basket yourself once again (and bear the label of ‘ballhog’), or trying to force a difficult pass that will probably be picked off. Either way, things are not looking good for you…\nOffensive movements in Basketball serve to break the positional advantage of the defense, trying to adjust them such that you have a gap to attack. When you successfully crossover someone, the immediate space in front of you becomes unobstructed and you can advance freely to occupy that space. This applies to all sorts of offensive movement and footwork, including cutting.\n“Cutting”, or off-ball movement, primarily serves two purpose:\n- Improving the point-of-attack\n- Improving the area-for-attack\nImproving the point-of-attack: The closer you are to the basket, the easier it is to score. Catching the ball near the hoop gives defenders less time to recover from any moves, and turning you into a serious threat of scoring. (the reason why good Centers become near unstoppable if they catch it close to the rim)\nImproving the area-for-attack: If you’re getting the ball in a congested area with 2 or 3 help defenders swarming around, it won’t be an easy shot. Cut to draw your defender away from your team mates, and give them more room to work with\nFundamentals of Cutting\nPurpose: Always cut with a purpose; running around mindlessly will not just tire you out, it will also screw with your team mates’ spacing and focus.\nAwareness: If your team mate is driving towards the basket, cutting in front of them isn’t the best idea. Always look out for your team mates and see if they are in a situation whereby they can make a good pass to you.\nSet-up: Disguise your initial cut by slowly walking your defender away from your intended catch, or jabbing hard in the opposite direction, before sealing him (make contact) and cutting away hard.\nCommunication: Have Eye Contact with your passer. Use your hands to communicate your intention for the cut; holding a hand forward or up can let your team mates know you’re open to receive the pass. Conversely, if you don’t want to receive the ball, make a “cross” in front of your chest.\nThere is a huge variety of ‘cut routes’ available in Basketball, but I’ll just condense them into the more common ones. Essentially, those specific ‘cut routes’ play essential roles in organized basketball offense; when run perfectly, they are one of the greatest beauties to behold in the game. However, for our casual street game, it is more simple and ‘general ideas’ that are easier to remember and ingrain.\nAlthough not some hard-and-fast rules, here are some ideas for cutting:\n1) Cut after making a pass. It could be a front cut (towards the basket) or a weave cut (curling behind the ballhandler); the purpose is to give another option to the ball handler. A ‘triple threat’ is more of a ‘dual threat’ unless the pass option can also lead to a score. If the cutter doesn’t get the pass, he’ll continue cutting to the basket, and stop at the weak side corner/wing.\n2) Fill the vacancy. After a cut is made, the player closets to that vacancy should move along the 3-point line to fill it (does not apply to ball handler). Another player will then fill the vacancy of the previous ‘filler’. If the ball handler choose to dribble to a position, other players should cut (front/weave) and fill the vacancies. At the end of the day, the 3 perimeter players should be constantly moving to ensure that both wings and the top of the key is occupied\n3) When a Ball Handler attacks (Sink, Pitch or Dive)\n- ‘Sink’ means to ‘run down alongside’ the ball handler (imagine a line parallel to the baseline, connecting the both of you), allowing for a easy kick out for a catch-and-shoot.\n- ‘Pitch’ means to fill out the vacancy that the ball handler left, and act as a safety net for the ball handler to pass to if he’s in trouble.\n- ‘Dive’ means to do a hard basket cut as the ball handler picks up his dribble, or retreats from his drive.\n4) When the Offense is Stagnant\n- As the Ball Handler: If no one is moving and the pass in unavailable, dribble towards your team mate to initiate a dribble hand off.\n- As the non-Ball Handler: Initiate a Ball Cut, or a Weave Cut to the Ball Handler. Or even set a screen for him.\n- The whole idea is to create movement; a few dribble hand offs, a few pass-and-cuts, just shift the defense around.\nIf no one in your team is moving, be THAT guy who constantly is!. These are the kind of offensive intangibles that will make your team better (whether they know it or not), and those who understand the game will definitely come to appreciate you a lot more.']	['<urn:uuid:3b2e8643-ec7b-45c0-981a-47c6bc72509b>', '<urn:uuid:2d5251ba-8ebf-45ce-8f09-de5a16419e9f>']	factoid	with-premise	long-search-query	distant-from-document	multi-aspect	expert	2025-05-13T04:02:16.770989	15	68	2359
76	As someone studying ancient Buddhist iconography, I'd like to know what specific features should be present in a Buddha's face according to traditional texts. What are the prescribed characteristics?	According to ancient texts, a Buddha's face should have several specific features: eyes like lotus petals, eyebrows like an archer's bow, a parrot beak nose, and a chin like a mango stone. Additionally, it should have a marked depression in the middle of the forehead (called 'urna') and a slight bump on top of the head (called 'ushnisha').	"['""Images of the Divine: South and Southeast Asian Sculpture from the Mr. and Mrs. John D. Rockefeller 3rd Collection,"" July 1, 2005-Jan. 8, 2006, at Asia Society, 725 Park Avenue, New York, N.Y. 10021\nThey stand here as if forever. Fifty sculptures in stone, schist, copper, silver and gold, from South and Southeast Asia. Their features undergo change from region to region, from country to country, even from workshop to workshop, as craftsmen imprint Buddhist and Hindu gods and goddesses with the features of local inhabitants and the idiosyncrasies of local traditions.\nIn the early autumn sun their presence casts a solemn peace on the second floor of the Asia Society building at Park Avenue and 70th Street in New York City. ""Images of the Divine: South and Southeast Asian Sculpture from the Rockefeller Collection"" is a sublime selection from one of the most prestigious assemblages of Asian art ever created.\nHere are the divine images of the Buddha in his various guises, displaying his multiplicity of gestures. They are flanked by the ""bodhisattvas,"" individuals who have not yet attained the ultimate eighth circle of enlightenment and must earn their position by helping believers function in Buddha’s shadow. And there are the Hindu gods and goddesses from the great Valhalla of the Orient. All shine in this selection from the Rockefeller Collection, a gift to the Asia Society that has helped anchor the society’s holdings firmly in all the artistic disciplines of the East.\nThe myths of Asia are among the richest on earth. The story of Prince Gautama -- or ""Buddha"" as he came to be known -- is central to this presentation. The myth bears repeating. A young nobleman, though wealthy and with wife and child, finds great unhappiness through contemplating unresolved questions about the meaning of life and the constantly changing aspects of fortune. He leaves his home and wanders the vastness of India until he realizes that only by casting off all desires and all personal ambition can he attain the peace that comes through meditation and introspection. His philosophy, later termed Buddhism, though not a religion per se, if practiced wisely can lead a person to his own salvation and free him or her from the endless cycle of death and rebirth.\nRepresentations of the Buddha in the Rockefeller collection take several forms. First, there is the historical Buddha, often referred to as ""Shakyamuni."" There are seven representations of this Shakyamuni on display at Asia Society, originating from Kashmir, India, Cambodia, Burma and Tibet. In most of these sculptures, a middle-aged man wears a crown, his earlobes elongated because of the heavy earrings that were the standard for his time, his expression benign.\nThe most impressive of these crowned Buddhas is a copper alloy figure protected by the seven-headed serpent king, Muchilinda, whose imposing head shelters the Buddha, who sits erect on Muchilinda’s coils. The snake represents the waters of Cambodia’s mainland, source of irrigation and healing. The figure is probably of 12th century origin.\nThe Vajrasattva Buddha is easily identified by the thunderbolt or ""vajra"" he holds in his right hand, and the bell he holds in his left. An impression of wisdom and compassion is conveyed in his countenance. Vajrasattva Buddhas are found in the northern regions of Buddhism as well as Indonesia and Cambodia. Two of the sculptures on view are traceable to the 12th century, one is of copper alloy, the other of stone. The copper structure appears luxurious, yet immensely powerful.\nThrough the centuries of evolving Buddhism, the repose and wisdom reflected in the Buddha’s countenance remain a constant. We see this over and over in the life-sized Buddha heads on display. The heads may have been used for temple decoration, or perhaps they are simply missing parts of scattered statues. According to ancient texts, ""A Buddha’s face is to have eyes like lotus petals, eyebrows like an archer’s bow, a parrot beak nose and a chin like a mango stone."" Other characteristics include a marked depression in the middle of the forehead, or ""urna,"" and a slight bump on top of the head, or ""ushnisha.""\nThe Buddha is dressed modestly, in contrast to his disciples who are more likely to sport elaborate garments, crowns and footwear. Orientalists look for each figures’ gestures or ""mudras,"" which establish a Buddha’s attributes. These might be the absence of fear, the turning of the wheel of law, the teaching mudra and more. In fact, scholars have isolated as many as 22 such gestures found in various monuments. Of the Buddhas on exhibition, the earth-touching gesture is seen most frequently -- it indicates enlightened compassion.\nAmong Buddhist goddesses, the White Tara at Asia Society with her inlays of silver and gold stands out. She is the goddess of infinite compassion. Her eyes are placed in the center of her forehead indicating her concern for the welfare of mortals.\nLike Buddha, bodhisattvas are exempt from the rebirth cycle. Their primary task is to provide salvation and guidance to the average person. In contrast to representations of the Buddha, statues of bodhisattvas are often elaborately styled with crowns, armbands, necklaces and jewelry studded with semi-precious stones. Many do not have the Buddha’s characteristic urna or ushnisha, and their earlobes are seldom elongated. They are not usually represented as performing the Buddha’s mudras. When presented with the Buddha, bodhisattvas are shorter than the deity, although as individual statues bodhisattvas can equal the height of a Buddha.\nThe Rockefeller selection includes several statues of Avalokiteshvara, the bodhisattva of compassion. An exquisite example rendered in a gilt copper alloy is from the estate of Blanchette Hooker Rockefeller. He is standing in a relaxed pose with his right hand, appropriately, in a gift-giving gesture. Another exceptionally crafted example is traceable to the early Malla period in Nepal (13th century). Here Avalokiteshvara, richly encrusted with semi-precious stones, displays two gestures: that of reassurance with his right hand and that of teaching with his left.\nMaitreya, a bodhisattva of the future who must still be born in human shape, is presented in an astonishingly fine 8th century figure. Copper alloys with inlays of silver and black stone accentuate the youthful figure. The sculpture was unearthed in 1964 from the ruins of a temple in northeast Thailand.\nManjushri, the boddhisattva of wisdom, frequently accompanies the Buddha. The sacred texts speak of him as ""The light. . . shining on the torch of knowledge that is the lamp of the world, the great brilliance. . . the clear light."" The Rockefeller Collection has several examples of this important figure. A western Tibetan 13th century copper alloy rendering with turquoise inlays holds a book, but lacks the sword usually present. This symbol is meant to show an intolerance for ignorance -- a standard theme in most Manjushri depictions.\nThe dancing gods of the Hindu pantheon have their own pavilion at the Asia Society. Familiarity with Hinduism is not essential to appreciating this portion of the Asia Society exhibition, but a few facts are helpful. Hinduism evolved over more than 4,000 years, so it’s not surprising that innumerable sects have developed, all living side-by-side and practicing their own interpretive take on the Veda, the sacred scripture. However, central tenets of the Veda and beliefs common to all Hindu sects are that all living things have a soul; that there is an essential equality among all creatures; and that there is rebirth. One’s station in life and the nature of one’s rebirth, which is most likely to take place in an entirely different form, are determined by the experience of previous existences and merits earned in these former lives.\nIt may be difficult to separate the characteristics of Hindu art and religion from that of Buddhism. For one thing, the names of the god or goddess represented are not always clear. Hinduism had no human founder and the Hindu gods have no traditional image, leaving the craftsman or artist wider latitude in fashioning their appearance. The prime Hindu deities are Brahma the creator, Vishnu the preserver and Shiva the destroyer.\nThe Asia Society exhibit’s Brahma has four heads. These are variously said to represent the four cosmic cycles, the four great classes, or the four directions. His arms hold a lotus stem, a bundle of grass and a book, all said to represent knowledge and religious ritual. We assume that this particular presentation is part of a much larger monument, now lost.\nVishnu can be recognized by both a conch shell or ""shankha"" and by a discus or ""chakra"" held in his upper arms. These round objects act as reminders of the cyclical nature of Vishnu’s mission. A sacred thread, an element in all Hindu deity sculptures, runs across his chest. The Vishnus in the Rockefeller Collection are from India, Kashmir and Thailand.\nShiva Nataraja is ""Shiva as Lord of the Dance."" Here he celebrates on the one hand the destruction of our universe, and on the other hand, the creation of an entirely new cosmos as it passes through an eternal circle of flames. This statue is Indian from the 10th century, in copper alloy. With his eyes half-closed and his four arms extended, the god dances rhythmically on the fiery wheel of creation.\nSculptural representations of Shiva and his consort Parvati were made to invite worship. The two figures demonstrate the attributes of masculinity and femininity. Five examples are featured in the Rockefeller Collection. The manifestation of Parvati in these groupings is benign. She is here as Uma, daughter of the mountains, or Devi goddess of light. Parvati also has an alarming aspect, that of Durga, the slayer of the Buffalo-demon who held the world in thrall. This fearsome representation is personified in a sandstone sculpture from Cambodia, thought to be from the 7th century.\nWhat of Ganesha, the elephant-headed son of Shiva and Parvati? Legend has it that after Parvati was pregnant with their child against the will of Shiva, he decapitated the child in his rage. Inconsolable, Parvati railed against Shiva until he could no longer tolerate her anger and grief. In desperation he sent his minions to bring back the head of the first animal they encountered, which, as it happens, was an elephant. Ganesha is worshipped as the god of good fortune as well as the god of war. In representations, his tusk is broken, since myth has it that it was lost in battle. Ganesha is usually the lead god presented in any Hindu festival procession.\nFRED STERN writes on art and antiques.']"	['<urn:uuid:6407d8f1-8ee5-4fcd-872a-6f4634053ff7>']	factoid	with-premise	verbose-and-natural	similar-to-document	single-doc	expert	2025-05-13T04:02:16.770989	29	58	1753
77	compare conservation efforts aullwood audubon center florida audubon christmas bird count	The Aullwood Audubon Center and Florida's Christmas Bird Count represent different approaches to bird conservation. Aullwood Audubon Center, as the Midwest's first nature center, focuses on environmental education and engages over 110,000 people annually through on-site programs to stimulate environmental activism. In contrast, Florida's Christmas Bird Count is part of a citizen science initiative where participants directly contribute to research by counting birds between December 14 and January 5th. The data collected helps track changes in bird populations and guides conservation actions. In Florida, the counts have revealed concerning trends, such as native birds being replaced by exotic species in urban areas.	['Dayton Northwest Birding Drive\nOhio Birding Drives are routes for birding trips which can be accomplished in one day, stopping to walk and bird at various eBird hotspots. For each birding drive, a Google map is provided with the route and suggested stops at eBird hotspots. You may save the link to the Google map on your smartphone or tablet, or print a copy on paper to take with you. Links are provided with information about each eBird hotspot. Follow those links for more information about birding each location.\nDayton Northwest Birding Drive\nClick on the hotspot names below to view the page about that hotspot.\nThis Birding Drive explores eBird hotspots in Montgomery County. When you submit checklists here you help to add to the data about birds in this region of Ohio.\n4361 National Road\nVandalia, Ohio 45377\nFrom I-70, take Exit 29 for OH-48. Turn right onto US-48 and drive 1 mile. Turn right onto US-40 and drive .9 mile. Turn right into Englewood MetroPark and drive .8 mile to the Englewood Recreation Reservoir.\nChecklists of birds seen at the reservoir may be submitted to the primary hotspot, Englewood MetroPark. If you have time, explore North Park and South Park. Each of these areas has a separate eBird hotspot.\nEnglewood MetroPark is one of five natural areas created by the construction of earthen flood control dams. Stillwater River, lakes, woods, and wetlands serve as focal points of this 1,900-acre MetroPark.\nEnglewood MetroPark is a large and heavily utilized MetroPark. The natural areas of the park contain floodplain forests, large areas of former farmland in natural succession, second growth upland hardwood forest, significant remnants of mature and old growth forest, a large shallow lake/wetland, several managed grasslands, and the scenic Stillwater River. The park also contains series of rehabilitated gravel quarry along Old Springfield Road (North Park).\nAullwood Audubon Center\n1000 Aullwood Road\nDayton, Ohio 45414\nFrom the Englewood Recreation Reservoir, drive east on Pattys Road for 1 mile. Turn right onto Frederick Pike and go .4 mile. Turn right onto US-40 west and drive .5 mile. Turn left onto Aullwood Road and go .2 mile. Arrive at the Aullwood Audubon Center.\nAullwood Audubon Center and Farm, an Audubon Center for environmental education and organic agriculture, provides activities that increase understanding and preservation of the planet by children and adults through education, research, and recreation.\nFifty-one years ago Marie Aull gave her land to the Miami Valley, creating National Audubon Society’s first nature center in the Midwest. Today as visitors explore the Marie S. Aull Education Center, walk the trails and experience Aullwood’s organic farm, they discover why Aull’s gift is a paragon among nature centers. More than 110,000 people– tots, school children, teens, and adults — are engaged in exciting on-site or outreach programs every year. By nourishing familiarity with nature and sustainable agriculture, Aullwood stimulates many visitors to environmental activism.\nAullwood Garden MetroPark\n955 Aullwood Road\nEnglewood, Ohio 45414\nFrom the Aullwood Audubon Center, drive south for .5 mile. Arrive at the Aullwood Garden MetroPark on the left.\nThis nationally recognized, historic estate garden is rich in plant diversity, habitats, and tranquility. Many bird and butterfly species are observed here. The garden acquired its present configuration in the two decades following John and Marie’s marriage in 1923. From the beginning, Wiles Creek served as a landscape focus and the forest shade determined the selection of plants. Tens of thousands of Virginia bluebells that now cover the hillsides in late April are the progeny of 500 plants they purchased.\nIn 1977, Marie Aull conveyed her cottage home, a 30-acre garden, and a maintenance endowment to Five Rivers MetroParks, with the provision that she be able to reside on the property as long as she lived while keeping her garden open to the public. Marie continued to direct the work of the gardeners after the donation of Aullwood Garden to MetroParks. Despite the help of gardeners, Marie could not resist working in the garden herself, even at age 90. Mrs. Aull was a familiar figure to those who visited her gardens.\nGreat Miami Wetland Mitigation Bank–Former Larch Tree Golf Course\nLittle Richmond Road\nTrotwood, Ohio 45426\nFrom the Aullwood Gardens, drive northwest on Aullwood Road for .7 mile. turn left onto US-40 west and drive .9 mile. Turn right onto South Main Street for .1 mile. Turn left onto Haywood Road and Drive 2.4 miles. Turn right onto East Westbrook Road and drive 1.1 miles. turn left onto North Union Road and go .1 mile, Turn right onto Shiloh Springs Road and drive .5 mile. Turn left onto Sycamore Woods Boulevard and drive 1.3 miles. turn left onto North Snyder Road and drive 1.9 miles. Turn right onto Little Richmond Road and drive .4 mile. Arrive at the Great Miami Wetland Mitigation Bank.\nIf you have time, you may also wish to visit the nearby Former Larch Tree Golf Course which is now part of the mitigation bank.\nNestled at the southeastern end of Sycamore State Park in Trotwood, the Great Miami Wetland Mitigation Bank consists of a wetland area, a forested wetland area, and a prairie. Wetlands are an important ecosystem that provides many key functions, such as biodiversity support, water quality improvement, flood abatement and carbon dioxide management. With the expansion of human populations, less than half of the world’s wetlands remain today. Wetlands are the “kidneys” of our ecosystem, able to hold enormous amounts of water that minimizing floods and filter and cleanse the water that passes through them, improving local water quality. Wetlands are so efficient at removing contaminants and pollutants from water that some wetlands have even been utilized for waste-water treatment.\nSycamore State Park\n4675 North Diamond Mill Road\nTrotwood, Ohio 45426\nFrom the Great Miami Wetland Mitigation Bank, drive west on Little Richmond Road for 1.6 miles. Turn right onto Diamond Mill Road and drive 2.6 miles. Arrive at Sycamore State Park.\nSycamore State Park lies in the vast fertile till plains of western Ohio in the Wolf Creek Valley. The original forest contained magnificent oaks, walnut, maple, ash, wild cherry and many other tree species. The forest abounded with wild turkey, deer, elk, and bison. Long before any permanent settlement was made in the area, its beauty and fertility were well known in the Kentucky settlements and to the people east of the Alleghenies.\nSettlers were attracted to this area because of the fertile soil. When the Miami-Erie Canal was completed in 1829, the area became quite prosperous. Underlying the rich fertile soils were vast beds of gravel and sand providing excellent materials for road making. Hundreds of miles of roads were built in the county with these materials making it one of the most accessible during the state’s infancy.\nAt one time, the land comprising Sycamore State Park was purchased by a development corporation to build a housing project. When the corporation was unable to complete the construction, the lands were offered to the state of Ohio. Sycamore was dedicated as a state park in November 1979.', 'Counting Florida’s Birds this Christmas\nBy: Kyle Grammatica\nBirds play an important, and often overlooked, role in Florida’s ecosystem. Some keep other species of animals and insects in check, others act as pollinators or planters, and some like vultures are important in the decomposing process of animals. If you’re interested in participating in research that will directly benefit these wonderful animals, look no further than the Audubon Christmas Bird Count!\nThe Audubon Christmas Bird count has been a tradition for 120 years. It was first suggested by ornithologist and early officer in Audubon Society, Frank M. Chapman in 1900. He and other conservationists were concerned about the over hunting of native bird species as a result of Christmas time “Side-Hunts.” The Christmas Bird Count, or the Christmas Bird Census at the time, was proposed as a new tradition aimed at counting birds during Christmas instead of hunting them. On the very first Christmas Bird Count, 25 counts were held, ranging from Toronto, Canada to Pacific Grove, California and recorded around 90 species in total.\nThe Christmas Bird Count Today\nToday, Christmas Bird Counts are held annually from December 14 through January 5th. Audubon and other conservation organizations use the data collected through these counts to determine the health of bird populations and help guide conservation action. The long-standing tradition of the Christmas Bird Count has helped biologists and wildlife conservationists study the long-term changes in the health and population size of North America’s native bird species.\nInformation from the Christmas Bird Count has been used by many organizations for climate change and conservation reports, including\n- Audubon’s 2014 Climate Change Report;\n- The Environmental Protection Agency’s 2012 report on climate change;\n- The 2009 State of the Birds report by the North American Bird conservation Initiative and the U.S. Fish & Wildlife Service; and\n- The 2007 Audubon Common Birds in Decline Report.\nIn Florida bird counts are currently underway, but some worrying signs are already appearing. Dennis Olle, who has led the Miami bird count for 38 years, says, “A lot of our native birds are no longer present… You just can’t find them in our urban environment. They’ve been replaced by large exotic birds from somewhere else, and significantly by parrots and parakeets.” Many of the open areas that birds rely on for habitat are being developed into residential or business areas. Also, natural areas may exist but may not be bird friendly. The bird counters in Miami were more likely to come across invasive parrots than native species like the brown thrasher or red-winged blackbird. There is also the issue of attracting new birders to participate.\nFlorida is home to an incredible variety of native birds, including some found nowhere else in the world, like the Florida scrub-jay. These species are treasured by people and essential to maintaining a healthy ecosystem. By participating in bird counts you can directly participate in research that will be used to protect these wonderful animals. If you are interested in participating in the Audubon Christmas Bird Count, check here to find birding group near you. You can also donate here to fund conservation projects across the state of Florida.']	['<urn:uuid:8110ab54-9ca4-4794-8254-940ead02cec4>', '<urn:uuid:850f948b-e95f-4b37-b4b3-b16faa982817>']	open-ended	direct	long-search-query	distant-from-document	comparison	novice	2025-05-13T04:02:16.770989	11	102	1706
78	As an experienced angler focusing on conservation, I'd like to know what's the difference between photographing catch-and-release fish in lakes versus ice fishing for pike through holes?	For lake fish photography, specific handling rules must be followed: hold the fish horizontally at water's surface, use wet hands, support with both hands, and keep it over water to prevent damage if it jumps. For ice fishing pike, the regulations are more focused on equipment, allowing use of 5 lines through the ice and two hooks on a single line if both are attached to one piece of bait, with no specific photo-taking guidelines mentioned.	"['Fish Handling And Conservation Policy (CPR):\nCatch your trophy, photograph it and release it. Have a taxidermist create a fish mount from your photos. Our ""No Trophies Home"" policy has preserved our fishery since 2005 and explains why our fishing is so good and improving each year.\nAll of our lakes have a strict \'No Trophies Home\' policy to insure our fisheries remain the quality that makes our guests return year after year. This also includes the policies of \'Catch and Release, consumption of smaller fish only\'\nThe trophy fish provide their genes to the next generation. Natural selection insures that the next generation of fish is strong.\nHelp us protect our fishery. Ontario Fishing regulations limit fish size and the number of fish that can be kept. We have an edge over most fisheries as when you visit one of our fly-in lakes, you are most likely to be the only fisherman on the waters. Despite this, we have to practice conservation to insure the continuing success of our fishery.\nWe encourage you to return trophies and larger fish to the lake so they can spawn again. The larger the fish, the greater the amount of spawn. The larger the fish, the chance that its genes will produce other trophy fish. Female fish choose strong males to be their spawning partner. Stronger, larger female fish often pair with larger stronger males. While this is not a firm rule, it is often the case. Please handle fish to be released with care to insure their survival.\nHandling fish properly will insure that a released fish will survive to spawn and be caught again. Wet your hands before touching a fish. Lift a fish carefully and lift it horizontally giving support along the length of the fish with two hands.\nWhen a fish is caught, limit the time you play the fish. Exhausting your fish before netting it will mean that it is less likely to survive if released. A released fish needs to have some strength left to survive. It must have enough energy to re-oxygenate its own blood. An exhausted fish my swim away only to die a few minutes later, out of sight and out of mind. The longer you keep a fish out of water, the more strength it needs to re-oxygenate its blood when released. You can\'t go without oxygen for a minute or longer and either can a fish! Limit the time you keep a fish out of water to a minute or less to insure its safety.\nDispatching a fish that is to be kept in a timely manner is the best way and the humane way to deal with your catch. Two or three sharp blows with a weighted, blunt instrument, striking the fish between and slightly behind the eyes is the best way to dispatch a fish. Any twelve to twenty four inch hardwood will work. A length of one inch galvanized pipe will word. The broken handle of a paddle, cut to length will work. After you arrive at your camp, take a walk in the bush and find a dried hardwood branch that is about one inch or more in diameter and cut it to size with a camp saw.\nLeaving a fish out of the water, to expire by suffocation is not humane. Leaving a fish on a stringer will often cause it to die slowly by suffocation as well.\nSome day your photographs are going to tell some other fisherman how conscientious you are or are not! Taking photos of your fish is often the most common way of damaging a fish that is to be returned to the water. In the excitement we forget to take care. We must put fish handling rules first when taking photographs. Hold your fish horizontally at the water\'s surface to remove hooks and to take a photograph.\nA fish lifted for a picture will likely attempt to jump from your grasp! When lifting a fish use both hands, lift horizontally and over the water. Fish that jump from your hands and fall into the bottom of your boat, instead of falling in the water, are unlikely to survive for long if released. The protective slim covering of fish protects them from infection. When slime is removed by rough handling or from a fall, or from using dry hands, the fish is unlikely to survive if released even thought it looks healthy and is able to swim away with vigor.\nThe thoughtful and informed fisherman today uses barbless hooks. A barbless hook protects the fish as they are much easier to remove and only do a small fraction of the damage a barbed hook will do in the mouth of a fish. When a barbless hook is set after a strike, a fish is not likely to shake it out or spit it out if you keep your line tensioned. The barbs on your hooks can often be removed with side cutters. Better still, go to your tackle shop and purchase new barbless hooks and attach them to your lures.\nCatch And Release - Fish Handling Tips:\nDon\'t place your fingers in the gills of your fish. Don\'t lift your fish by its eyes or touch its eyes. Fish placed on a stringer in the water cannot be released as they are unlikely to survive.', ""Area Sport Fishing Reports\nMarch through April Season\nDon't forget: your fishing license expired Dec. 31! Neither the ADF&G Permanent ID license nor the ADF&G Disabled Veteran's license expire.\nThe sport fishing regulation booklets are good through April 15. Look for new booklets around early April.\nIce conditions are usually good through mid-April, but make test holes before going out on the ice. Ice conditions vary greatly from one system to the next. Typically, lake ice melts near the shoreline first. ADF&G does not keep track of ice thickness, and travel on the ice is at your own risk. For ice and snow pack conditions on state lands, call Alaska State Parks in Palmer at (907) 745-3975.\nOnce ice recedes, the open leads are usually full of hungry fish, catching tidbits melting from the ice. Try casting small spinners or dark-colored flies right to the edge of the ice.\nRainbow Trout - Flowing Waters\nMany flowing waters are closed to ALL fishing for rainbow trout beginning April 15, to protect spawning fish. Some waters allow only catch-and-release of rainbow trout starting April 15. A careful review of the regulation booklet is necessary before heading out to fish.\nIn waters that are open to rainbow trout fishing, success should be fair to good. Also keep in mind that most of the flowing waters are single-hook, no bait through the end of May. Remember, Montana Creek, Willow Creek and the North Fork of the Kashwitna River are catch-and-release only for rainbow trout and grayling, except that in Willow Creek upstream of the Parks Highway bridge, 1 rainbow trout less than 16 inches long is allowed daily.\nIn order to help conserve this resource, it is suggested that you use barbless hooks, or pinch down the barbs on regular hooks.\nWarmer weather and longer daylight hours usually spell success on area lakes until break-up, especially on those lakes that were stocked in late October and early November. Remember to chop or drill a test hole to be sure lake ice is still thick enough for travel.\nThe web pages have links to maps of the area's stocked lakes. You can also find a listing of stocked lakes in the regulation booklet. The limit for rainbow trout in stocked lakes is 5 fish per day (of which only one may be over 20 inches).\nJig lures or lower bait (if allowed) near drop off areas and areas of underwater contour for rainbow trout and catchable salmon. The more popular baits include fresh (not frozen) cocktail shrimp, canned clams, single salmon eggs, or preserved egg clusters. For lake trout/char, fish the bottom of the deepest hole you can find. Some lakes have more restrictive tackle and bag limits, please check the regulations before you head out to fish.\nOnly 2 trout may be harvested in lakes having native trout populations. A stocked lake handout is available from Department of Fish and Game offices in Palmer and Anchorage to assist you in finding good angling opportunities.\nNorthern pike usually spawn from late April to early May. Before spawning, pike tend to become very active and begin feeding heavily. This is usually a great time to head to your favorite spots for some excellent pike fishing. Pike respond well to decoys, shiny silver jigs, and lures through the ice. Check the regs before you use bait. Where bait is allowed chunks of herring work well, as do whole sardines and hooligan.\nFor road-accessible pike fishing, try South Rolly, Tanaina, and Memory lakes. For fly-in or snowmachine-in pike fishing, it's hard to beat Alexander and Trapper lakes. Pike are also to be found in Flathorn, Sucker and Eightmile lakes.\nThere are many lakes where using 5 lines through the ice is legal for pike. Check the reg book, or click on the pike pages on our website. Also when pike fishing through the ice anglers may use two hooks on a single line, provided that both hooks are attached to one single piece of bait.\nA handout describing the Pike Fisheries in the Mat-Su area is available at department offices in Anchorage and Palmer.\nAgain, ice thickness is not monitored by ADF&G. Call Alaska State Parks in Palmer at (907) 745-3975 for more info on snow cover and ice thickness on state lands. For other lands, try to find a local source of info, such as lodges and private property owners.""]"	['<urn:uuid:657bb138-c860-4801-8c4c-3fae9d8643de>', '<urn:uuid:3bf0625b-60b6-415c-b646-9a940311e199>']	factoid	with-premise	verbose-and-natural	distant-from-document	comparison	expert	2025-05-13T04:02:16.770989	27	76	1626
79	structural engineer working southeast us what causes most insurance claims after wind events for homes	According to studies by the Insurance Institute for Business Home and Safety (IBHS), roof coverings are the major problem area in wind-related events, accounting for more than 95% of home claims after such events.	['This week, I’d like to introduce Sam Hensen as the first guest blogger for the Structural Engineering Blog. Sam is the engineering manager for Simpson Strong-Tie in the Southeastern United States. Sam will be posting occasionally on topics that are relevant to our work. We will continue to post on a regular weekly schedule (usually Wednesdays) to the blog. In the future, we hope to expand the voices on the blog to include more Simpson Strong-Tie engineers, along with other industry colleagues and associates.\nI tend to think of designers as dealing with either wind or seismic design, yet the Southeast region contains everything that Mother Nature can throw at a building. This includes high seismic areas along the New Madrid and Charleston faults, hurricanes along the Gulf and Eastern coast, and tornado prone areas throughout the South and Midwest. Sam participated in the investigation and was a co-author of the Damage Study and Future Direction for Structural Design Following the Tuscaloosa Tornado of 2011, which gives him some very recent experience with tornado damage. This week, Sam will be discussing a topic not often thought about by structural engineers – the importance of proper roof tile attachments. Here is Sam’s post:\nAccording to recent studies by the Insurance Institute for Business Home and Safety (IBHS), roof coverings are a major problem area in wind-related events and account for 95% plus of home claims after the event.\nPreventing roof tiles from becoming wind-borne debris in high wind regions is essential for several reasons, and may also have an effect on insurance premiums. In this post, I’d like to discuss two reasons that roof tiles can pose a significant threat to life safety:\n- Many designers rely on the weight of roof tiles to reduce the overall wind uplift effects on the structure. If the roof tiles do not remain in place during the wind event, then an under-designed wind uplift restraint system can exist.\n- Roof tiles can essentially become missiles in a wind event, damaging nearby property and creating a significant and direct risk to public safety.\nA Complete Load Path\nSection 1604.4 in the International Building Code (IBC) requires a complete load path from point of origin to the load-resisting elements. For wind conditions, where does the wind uplift load path begin?\nThe roof tiles to roof decking attachment!\nDesigners often rely on the benefit of the weight of the roof tile to reduce uplift loads on the structure, but rarely (if ever) design or specify these connections. The code allows a portion of the roof dead load to be used to reduce uplift loads on the structure (60% of the typical 25 psf of dead load for tile roofs), so keeping it in place during a wind event is critical. Consequently, the attachment of the tile should also be included in the design by the project designer of record, or it should not be used to reduce uplift loads. This consideration is clarified in section 1605.3.2, “…only two-thirds of the dead load likely to be in place during a wind event shall be used…”.\nThe design and construction of roof systems is addressed in section 1609.5 of the 2012 IBC. Section 1609.5.3 provides a method for determining wind loads on rigid tiles, as well as the minimum detailing and design requirements. In this section, equation 16-33 provides a means for calculating the minimum aerodynamic uplift moment, Ma (ft-lbf), acting to raise the tail of the tile.\nMa = qhCLbLLa[1.0 – GCp]\nThe use of this challenging equation should only be performed by a qualified designer and it should not just be left to the installer of a roof system to ensure the roof tiles are properly attached to the roof deck. Fortunately, the Florida Roofing, Sheet Metal and Air Conditioning Contractors Association (FRSA) teamed up with the Tile Roofing Institute to create the Concrete and Clay Roof Tile Installation Manual. The appendix of this document includes simple tables that assist the designer in determining the proper attachment of clay or concrete roof tiles to resist the aerodynamic uplift moment.\nImproper attachment of roof tile can also create powerful missiles in wind events. These missiles can pose a significant risk to life safety as they become wind-borne, either directly to the public, or through damage to nearby occupied structures, thereby reducing the ability of that structure to remain in place during the event. Both of these reasons make it essential for proper design and detailing of the connection of roof tiles to be incorporated into the design of the building by the project designer of record.\nWhat are your thoughts? Let us know in the comments.\nWhat are your thoughts? Visit the blog and leave a comment!']	['<urn:uuid:5501a9a7-059b-4e79-a5bf-fc1ea1b3461d>']	factoid	with-premise	long-search-query	similar-to-document	single-doc	expert	2025-05-13T04:02:16.770989	15	34	789
80	comparing biomass versus air source heat pump suitability off gas grid properties performance efficiency	Biomass heating systems are more suitable for larger rural off-gas properties that have limited options for building fabric improvement, while air source heat pumps (predominantly air source) are broadly viewed as the leading solution for decarbonising heat. ASHPs can operate efficiently in temperatures down to -15 degrees and work best when combined with good insulation and double glazing, maintaining properties at a consistent temperature.	['A lot has changed since the 2008 Climate Change Act; legally binding carbon budgets have been met by rapidly decarbonising our electricity supply, largely due to significant amounts of PV and wind generation coming online alongside the closure of numerous coal fired generators. However, whilst we have made great progress on electricity, decarbonising heat is proving very difficult and as the fourth carbon budget (2032) sits on the horizon, attention is starting to focus on meeting this.\nTo meet the demands of the Climate Change Act, nearly all heat in buildings and industrial processes must be decarbonised by 2050. The Clean Growth Strategy (CGS) made it clear that action on decarbonising heat must take place in the 2020s. Partly thanks to the CGS, domestic energy efficiency is also making its way back onto the national agenda, with the imminent ‘boiler plus’, ‘MEES’ the building regulations review and extended ECO to name a few changes.\nStability and smooth transitions are needed\nAs one of a series of documents following on from the CGS, BEIS yesterday released a call for evidence on ‘A future framework for heat in buildings’.\nThe call indicates a positive, if small, first step towards action after the RHI closes in 2020 / 2021. Importantly for those in the industry, it includes an acknowledgement by government that regulation is needed to provide clear long-term stability to the industry and consumer post RHI. Aligning with existing policies, BEIS recognise that there must be a smooth transition when the RHI closes (2020/2021), with potential regulation to ensure this “through to the 2030s”. This will aim to reduce barriers whilst also reducing reliance on subsidy (“There may be a role for targeted subsidy…highly targeted in terms of technology it supported, technology it replaced, and the recipient of the subsidy”) and keeping the options open.\nThe graph below shows one of the inherent problems with policy to date, an incredibly spiky market, which is sure to compromise quality, ultimately reducing the real carbon reductions made. Avoiding this is key to long term success for all players in this sector.\nThe domestic RHI has to date been dominated by heat pump (54 per cent) and biomass (22 per cent) installations, predominantly in off-gas areas (76 per cent of installations).\nTechnologies considered under this call include biomass, bioliquids, biopropane, heat pumps, hybrid heat pumps, gas driven heat pumps, direct electrical heating (storage heaters) and rural heat networks. This signals a recognition that the ‘best’ solution is not yet clear and that other options need to be considered if significant levels of renewable heat are to be deployed.\nHeat pumps, predominantly air source, are broadly viewed as the leading solution for decarbonising heat. The idea of shared ground loop GSHPs is also raised on several occasions, recognising the need to address the cost barrier to this more efficient form of heat pump. BEIS is keen for information about hybrid heat pump solutions, their cost and effectiveness.\nBiomass will continue to have a role to play in rural off-gas properties that are larger and have limited options for building fabric improvement, but expect it to take a back seat.\nBioliquid and biopropane fuels were previously excluded from the RHI in order not to compete with transport where options for decarbonisation are limited. However, there is a recognition (much championed by OFTEC) that these might have a part to play post-RHI for those difficult to heat buildings that would not be suitable for alternatives such as heat pumps. These are likely to be largely viewed as transition options and there are checks and balances that must be in place to ensure sustainability.\nEven with the right technology, and some financial support as provided by the RHI, significant barriers to owner occupiers taking up renewable heat remain. This is important as ~17 million of the ~ 28 million homes in the UK are owner occupied.\nBEIS identifies the key barriers for this group as: not a priority, adverse to change, lack of knowledge, hassle of installation, perceived complexity, uncertainty over suitability of building, uncertainty over performance, short term occupation of building (not prepared to invest money for long term).\nFive near-term regulatory approaches to overcome these barriers are suggested as options:\n- Require installers to provide an equal level of information about low carbon alternatives when they quote for a boiler replacement\n- A scheme to enable low income and vulnerable households to take up low carbon heating, including building fabric upgrades if required. (Indicated as an arrangement following on from ECO).\n- DNOs and GDNs support take up of low carbon heating, by ensuring suitable grid capacity is available and new market solutions such as DSR and other flexibility can be easily accessed.\n- Companies producing or selling oil systems are also required to deliver low carbon heating, likely with targets set based on volume of sales\n- Oil suppliers are required to sell a certain amount of bioliquid, or renewable heating or pay into a fund that supports low carbon heating installs.\nThese questions hint at a number of interesting ideas much discussed of late. Are we going to see the ‘traditional’ heating installers pushed into renewables rather than being pulled in?\nCould we see the gas and electricity networks playing a more active part in decarbonising heat – perhaps simply by enabling flexibility markets or even installing efficiency or low carbon measures in homes to overcome grid constraints?\nWill we start to see heat being sold as a service, like broadband and TV subscription packages, with a third party owning and maintaining the heating equipment?\nCan whole house, performance guaranteed approaches such as Energiesprong be delivered at volume and into the able to pay market?\nIt will be interesting to see how industry responds to the forty four questions posed by this call for evidence, and how that shapes the next ten years of heat.', 'An Air Source Heat Pump (ASHP) captures heat from the air circulating outside your property and boosts the temperature to provide heat and hot water. It is a very effective, low carbon way of heating your home and can be combined with a number of renewable and energy efficient technologies to deliver a truly sustainable home or commercial premises.\nAn ASHP can be installed in new and existing properties and the Government’s Renewable Heat Incentive provides cash payments for all eligible installations, which makes the investment even more attractive.\nIn warmer months ASHPs can operate as air conditioning units, meaning that you benefit from your heating system all year round, whatever the weather!\nHow air source works\nAn Air Source Heat Pump uses the same technology as your kitchen fridge to move heat from one place to another.\nAn ASHP uses the temperature of the air circulating outside to warm a liquid refrigerant.\nThe heat pump turns the refrigerant into a gas, compresses it and then condenses back into a liquid again which generates heat energy and the cycle starts again.\nWhat makes heat pumps sustainable?\nThe temperature of the air outside is determined by the sun and local weather conditions and is therefore a renewable source of heat.\nUsing this renewable energy to help heat your home is more sustainable than fossil fuel alternatives.\nHeat pumps are electric, but by using heat from the air they use less electricity to produce heat than traditional electric heating systems.\nCombining your ASHP with your own solar energy increases their sustainability and further reduces carbon emissions.\nAre air source heat pumps efficient?\nThe efficiency and performance of an ASHP is measured using Coefficient of Performance (COP) and this varies by model and brand.\nA number of factors including the insulation levels that your property has, your existing heating system and whether you are using under floor heating versus radiators will determine the overall performance of your ASHP.\nGovernment incentive schemes to encourage investment in low carbon technology can currently cover the cost of installation and ongoing maintenance costs are lower than with traditional heating systems.\nGeo Green Power have extensive experience and will ensure you understand the options available.\nLearn more about how ASHPs work\nIf you choose Air to Air your ASHP will provide hot air to heat your property and you will need an alternative system to provide hot water.\nIf you choose Air to Water then your ASHP will provide hot water to heat your property and provide hot water for use within your home.\nIt’s important to consider your requirements and any unique aspects of your property and location to create the best solution.\nWhen designed and configured correctly your ASHP does not require a back-up heating option.\nHeat pumps are designed to maintain properties at a consistent temperature. This is when they run at their optimum efficiency and are most effective.\nASHPs can be combined with over-sized radiators or underfloor heating. Underfloor heating is often more efficient, but great results can be achieved with other forms of heating.\nWe will ensure that we recommend the right option for you and your property\nASHPs work all year round and in temperatures down to -15 degrees.\nThey are more efficient when the outside temperatures are higher, however in the UK the difference between seasons is very minimal.\nAll air that is above the temperature of absolute zero has heat energy!\nIn recent years ASHP technology has improved considerably. The cost of ownership has come down and the units have become quieter and more efficient.\nRequest a call to discuss your project\nWhat is the installation process?\nASHPs are fitted to the outside of your property and are about 1m wide, 1m high and around 30cm deep.\nNo ground works are required.\nDepending on your existing system, your ASHP may easily link to your water tank and heating with limited additional works. You may need to replace your radiators for larger units.\nA domestic installation in a single property is usually completed and commissioned within 5 working days.\nLearn more about installation\nASHPs have very few moving parts and require less ongoing maintenance than traditional heating systems. We recommend an annual service to ensure that your system is running at its optimum efficiently.\nYou do not require planning permission for an ASHP.\nYour ASHP is positioned outside your property and is best in a sheltered location which has good air flow. Most properties can easily accommodate an ASHP in a location that is both effective and convenient.\nASHPs work best when they are combined with other energy saving technology such as insulation and double glazing. Running your heat pump to maintain your property at a consistent temperature is also advisable.\nChanging from Oil Fired Heating to Air Source\nWhen Paul took on a 1970s property he wanted to move away from oil fired heating. He carefully compared the cost of replacing the old oil boiler with an up to date condensing oil boiler or an Air Source Heat Pump system and found that the heat pump option was the right choice for him.\nCosts & Expected Returns\nWhat is the installation cost for air source?\nOur ASHP installations start from around £12,000\nHow much do ASHPs cost to run?\nIt’s very difficult to estimate the running costs of your installation as it will depend on the size of the space you want to heat, the temperature you are running the system at and a number of other factors such as insultation and whether you are using underfloor heating or radiators.\nWe will be happy to provide an estimate of your running costs if you would like to discuss your project.\nWhat will my return on investment be?\nThe return on investment that you receive will be determined by the type of fuel you are looking to replace and the cost of running your system. Higher returns can be achieved when switching from oil or LPG heating systems.\nThe current Renewable Heat Incentive provides payments that, in a number of cases, can cover the cost of the installation.\nHeat pumps require less maintenance and repair than most traditional heating systems, which also makes them an attractive investment.\nGet in touch to discuss your ASHP project\nJames oversees all of our air source heat pump installations. Get in touch today to organise a no-obligation consultation about your next project.\nWhat is the RHI and are Grants available for ASHPs?\nThe current Government scheme is the Renewable Heat Incentive (RHI).\nThe domestic scheme provides payments for 7 years and applies to eligible heating systems that are used for one dwelling\nYour system will have an Energy Performance Certificate (EPC) and a Seasonal Performance Factor and these two values will be used to calculate your payments based on your usage and the current tariff.\nEstimated output: 12,000kWh per annum\nEstimated RHI income: £900.00 per annum (7 year contract)\nEstimated CO2 savings: 4 tonnes per annum\nASHPs in Commercial & Domestic Buildings\nASHPs in commercial buildings\nASHPs can easily be installed in commercial premises to provide heating and air conditioning and are particularly efficient when running to provide a consistent temperature for offices and workspaces.\nASPHs in domestic houses\nASHPs provide a low carbon, energy efficient way of heating homes. The systems are low maintenance and combining them with other energy efficient technology helps to ensure that they perform at their best.\nASHPs in New Builds vs Existing Properties\nASHPs installation in new builds\nThe construction of a new property is the perfect opportunity to consider and implement energy efficient, sustainable technology to ensure that the finished result is as cost effective and environmentally friendly as possible.\nThe UK Government is due to bring in the Future Homes Standard in 2025 which will prohibit any new build property from having a fossil fuel heating system.\nIncorporating low carbon, renewable heating into new build projects will ensure that you remain ahead of legislation.\nASHPs installation in existing and historic buildings\nASHPs can be retrofitted into existing properties to replace oil, LPG and mains gas heating systems. The return on investment will vary depending on the existing heating system and other factors such as the property’s energy ratings.\nAir Source vs Alternative Heating Solutions\nComparing ASHPs to existing gas and oil systems\nAn ASHP provides an energy efficient, low carbon option when compared to gas, oil or LPG heating systems. It delivers a significant reduction in CO2 emissions and has lower ongoing maintenance costs.\nThe costs of installation may be higher than traditional fossil fuel systems, but this is offset considerably by the RHI payments you will receive.\nRunning costs are usually comparable to mains gas systems, and significantly cheaper than oil or LPG.\nAir source heat pump or ground source\nAn ASHP installation is often cheaper and less intrusive than a GSHP installation and is ideal for smaller properties and those with limited outside space.\nIf you have a large property to heat, and enough outside space a GSHP will outperform an ASHP. A GSHP system can collect more renewable heat from the earth and therefore requires less electricity to produce the same heat output.\nAir source heat pump or solar panels\nWhen considering an ASHP or solar panels, the best choice for you will depend on your heating requirements, budget and energy usage and we will be happy to discuss your options with you.\nIt may be most cost effective for you to consider a scheme that incorporates both. Using solar power to run your heat pump could deliver the greatest cost efficiency and deliver the most sustainable scheme.\nFind out more about renewable energy…']	['<urn:uuid:2412d628-e1a3-45f0-b077-fbd911809134>', '<urn:uuid:416a8aee-e3a5-4e75-a89b-505befe84c0e>']	factoid	with-premise	long-search-query	distant-from-document	comparison	expert	2025-05-13T04:02:16.770989	14	64	2590
81	nitrogen cycle effects global warming butterflies	The nitrogen cycle affects both global warming and butterflies through multiple mechanisms. Car emissions deposit nitrogen into serpentine soils, threatening checkerspot butterflies by allowing invasive plants to crowd out their food sources. Additionally, elevated nitrogen deposition onto soils can lead to increased production of nitrous oxide, which contributes to atmospheric warming and ozone depletion.	"['Life is complicated. Soft summer days beckon and seem to hold the promise of simplicity and ease. A trip to the beach or to the mountains, or a day spent in the shade of a four hundred yer old oak or in a canoe paddling down a gentle river lulls the mind into an idyllic tranquility. Nature seems perfect peaceful and serene. But this is an illusion.\nYou could be, for example, a checkerspot butterfly. What a carefree life, fluttering through the paintbrush and tidy tips, the wild parsnips and owl;s clover. But if you were a checkerspot, you would be studied and followed, photographed and mapped more than any other butterfly of Earth. Your life would not be your own. And the reason for this is that there are so few of you. You are almost extinct. As a matter of fact, during dry years or droughts you seem to have vanished completely. But you persist, if only in a few places. Your life is not easy.\nYou live in a few choice spots in the chaotic jumble of rocks that have been twisted and turned, compressed and exploded, thrust up and dropped down to form the Coast Range and Bay Area. For the moment, cosmically speaking, this heap of rubble has come to rest in such a way that here and there along the ridges on either side of a valley now named for one of Earth’s abundant minerals–silicon–there are outcroppings of a rock known as serpentine.\nSerpentine, composed primarily of the namesake mineral of the valley, is a beautiful rock. It comes in greens like jade, shot through with ripples of white. It is soft–if a rock can be– and soapy in texture. It is a rock people notice. It is a rock you would need if you were a checkerspot.\nIn areas where serpentine abounds, it weathers and provides a soil that is a little different from the soil found in surrounding areas. It is nutrient poor. Some flowers and grasses find this serpentine soil a little hard to take. But some plants love it. And those that do grow wildly and bloom in the spring making a scene that looks lik a painting from Paradise. And it is these plants that you would rely on for your bread and butter if you were a checkerspot.\nCheckerspot larva feed on the small plantain and owl’s clover found growing on serpentine soils. The brief blooms in the spring of the serpentine plants coincide exactly with the short nectar-eating life of the checkerspot butterfly. Serpentine plants and checkerspots have a partnership that cannot be easily altered.\nIn spring it is not hard to see where serpentine stops at the bottom of a ridge or the crest of a hill. Abruptly a glorious scene of blooming flowers changes to one that is less lush, one in which grass predominates. Where the serpentine ends it is like leaving Paradise to return to Earth again, albeit a beautiful Earth. Recently, though, something has changed in the serpentine areas surrounding our valley. Earth is creeping into Paradise. The plants and grasses that rarely ventured in to the lean serpentine soils are encroaching, crowding out the plants that once thrived and rose to the serpentine challenge. Your neighborhood would be shrinking if you were a checkerspot.\nWhat’s going on here? And what’s to be done? Unlikely answers have been found to both of these questions. In a word the answers ar “Cars” and “Cows”. But the connections are complex enough that they lay to rest forever the notion of simplicity in nature.\nThe answer to why the serpentine is now able to support plants that never grew there before lies in the emissions of exhaust gases from thousands and thousands of cars. The nitrogen compounds belched out of a hundred thousand tailpipes have created air that we can sometimes see, and these gases are not totally gone even when we cannot see them. This nitrogen has to go somewhere. It drifts with the breeze and blows with the wind that funnels down the valley to work on the mountains where serpentine soils lie benignly beneath. The nitrogen is deposited, little by little. And as surely as gardeners see changes in their plants from the nitrogen fertilizer they carefully apply, the serpentine soils are nourished. Plants and grasses that would not survive in the lean soil before, now gain a foothold and soon thrive. The owl’s clover and plantain, the tidy tips and wild parsnips, small plants used to living frugally in meager soils, are edged out and overwhelmed by more robust vegetation, foodstuffs that would be foreign to you if you were a checkerspot.\nAnd this is where the cows come in. If just enough cattle are allowed to graze on serpentine lands, the intruders are kept in check. The intruding grasses are large and preferred by cattle. But if there are too many cattle, they will eat even the smaller less vigorous native plants, the ones the checkerspots rely on. Just enough cows, the plants and checkerspots that live on these plants continue to flourish. Too many cows, no plants at all and no checkerspots.\nBut checkerspots are survivors, reappearing and hanging on when once they were thought gone. Somehow in some incomprehensible way, they have claimed media attention. They are giving life their best shot. Hanging in the balance against unforeseen and unknown odds, enduring complications and complexities, they may represent for us more than a vanishing species. Life is never simple.', 'Presentation on theme: ""Effects of variable rainfall and increased nitrogen deposition on nitrous oxide production in a semi-arid grassland ecosystem A forethought of global change.""— Presentation transcript:\nEffects of variable rainfall and increased nitrogen deposition on nitrous oxide production in a semi-arid grassland ecosystem A forethought of global change\nGlobal Change … What is global climate change? “Global climate change can be defined as a considerable change from one climatic state to another, such as an increase in the Earth\'s temperature. An increase in the Earth\'s temperature may lead to changes in rainfall patterns, a rise in sea level, and a wide range of impacts on plants, wildlife, and humans.”\nVariable rainfall: Effects on Precipitation in the Southwestern United States El Nino: Wetter years are associated with El Nino (warm cycle) whereas drought is associated with La Nina (cold cycle) Heating of the atmosphere by global warming could increase the frequency and intensity of El Niño events, bringing more precipitation to the Southwest during winter months Summer Monsoon: Effects of climate change on the North American monsoon are poorly understood Likely to become more variable\nThe Importance of Nitrogen Earth’s atmosphere is ~78% N 2 Essential to many living organisms to produce amino acids, proteins and nucleic acids Necessary for photosynthesis and plant growth\nNitrogen Fixation and Cycling Atmospheric N enters ecosystems in 4 main ways: Biological fixation (free-living or symbiotic bacteria) Lightning Industrial fixation (fertilizers) Combustion of fossil fuels\nThe Nitrogen Cycle Process by which atmospheric N 2 is converted to ammonium (NH 4 ) or nitrates (NO 3 ) and ultimately back to N 2 gas and returned to the atmosphere.\nConsequences of Anthropogenic N Addition Ecosystems: N addition to soil can lead to changes that favor weeds over native plants, reducing species diversity Additional N in rivers, lakes and coastal systems stimulate blooms of algae that deplete O 2, killing fish and other organisms resulting in Eutrophication (Gulf of Mexico) “Elevated N deposition onto arid soils could return relatively more nitrogen to the atmosphere in the form of N 2 O- a contributor to atmospheric warming and ozone depletion”\nQuestion How do global change factors such as variable rainfall and increased nitrogen deposition affect ecosystem function in a semi-arid environment?\nHypothesis: Precipitation If rainfall events occur less frequently, there will be an initial rise in microbial activity followed by a rapid decrease because soils are water limited. If rainfall events occur more often, there will be an initial rise in soil microbial activity which will be sustained for a longer period of time due to higher water availability.\nHypothesis: Increased Nitrogen Semi arid ecosystems are also N limited… So if there is an increase in N deposition, there will be an increase in nitrous oxide (N 2 O) production and community respiration (CO 2 ) due to higher nutrient availability.\nExperimental Design Collection of top ~5 cm of soil from interspace (cyanobacterial crust) soil and from under canopy (rhizosphere) soils Removal of organic matter Incubation of 100 g of each soil type in 125 mL serum vials for 14 days\n3 Factoral Design: 12 treatment combinations Soil type: Canopy or Interspace Rainfall Variability: 1 x 180 mm 3 x 60 mm 6 x 30 mm Nitrogen addition: 2 g/m 2 ammonium-nitrate addition\nMethods Gas samples taken weekly with a gas-tight syringe and transferred to a pre- evacuated 5 ml vacutainer Samples were analyzed within one week of sampling to measure N 2 O and CO 2 on gas chromatographs\nResults! N 2 O concentrations highest in N treated Interspace soils Although all soils received the same amount of precipitation, non-N amended soils did not respond as dramatically\nTemporal Fluxes No Nitrogen: No Response\nTreatment 1 with N: 180 mm\nTreatment 2 with N:60 mm\nTreatment 3 with N: 30 mm\nWhat does it mean? Increased N means more N 2 O production Even though ecosystem is H 2 O limited, water alone had no real effect on N 2 O production They are also N limited so they respond well to additional nutrients A rise in anthropogenic N deposition could lead to more N 2 O production from soils, potentially exacerbating global warming and ozone depletion\nMuchos Gracias Chelsea Crenshaw Joe Fargione Sevilleta LTER US Fish and Wildlife Service John Craig Jennifer Johnson NSF The lovely ladies of House 1']"	['<urn:uuid:b468179b-101f-47f7-8b8d-4ef29819f767>', '<urn:uuid:c57ca237-5c6d-4c2a-a7e8-54cfbc17ba2e>']	factoid	with-premise	short-search-query	similar-to-document	three-doc	novice	2025-05-13T04:02:16.770989	6	54	1644
82	What are some effective ways that construction companies can increase job productivity and make sure workers spend more time on actual installation work?	To increase job productivity, companies should focus on ensuring skilled trade workers focus solely on installation work while delegating other activities to unskilled labor. Activities like handling material, receiving goods, returning items, removing garbage, and cleaning up should be handled by lower-skilled workers. Additionally, using prefabrication techniques and having vendors place materials exactly where needed on the job can boost productivity. Planning is also crucial - research shows that every hour spent planning saves 17 hours at the end of the job.	['Practical tips for making money and satisfying the customer during tough economic times\nIt’s no secret that times are tough for everyone involved in the construction industry — and have been for some time. Although it’s hard to find a silver lining amid such economic instability, there are still projects to be won, profits to be made, and businesses to grow for electrical contractors. It’s true, the total construction market dropped by more than 40% in recent years, compared with the good old days of 2005 to 2008. However, the good news is — that still leaves 60% of the market available for the taking. To win jobs during an economic downturn, what many people don’t know is they must adjust their operational theory, shifting priorities in support of the following areas: transferring value to the customer; increasing job productivity; reducing error and rework; segregating fixed cost from variable cost; and taking care of your people. Let’s take a look at each of these propositions more closely.\nTransferring Value to the Customer\nRemember in a tough economy your customers are dealing with cash flow problems and reduced profits just like you are. What they want is to start generating revenue again as fast as they can. The construction process is nothing more than a nuisance for many owners and customers. They simply want you to finish the building on time (or earlier) with no punch-list — at or below budget. The sooner you accept and understand your customer’s perspective, the sooner you can deliver the project. This might seem like a monumental undertaking; however, this same need exists whether the economy is good or bad.\nIncreasing Job Productivity\nYour focus on productivity has to shift from individual productivity to job productivity. The difference between the two is simple. An individual electrician can be very productive, but if he can’t get to the work to do the installation, he is not producing. In other words, everything you do in the company has to focus on making sure that the skilled trade does one thing and one thing only — installation work. Any other activities, such as handling material, receiving goods, returning items, removing garbage, and cleaning up (Photo), have to be identified and passed on to lower, unskilled labor.\nAs you can see in Fig. 1 (click here to see Fig. 1), the majority of an electricians’ time is typically spent on activities other than installation work. If this could be reduced, the electrician’s individual “production rate” could actually slow down, and the job would still be more productive.\nBy using prefabrication techniques and asking vendors to place the material when, where, and how it is needed on the job, productivity levels will increase. Planning the job will help reduce the unexpected issues and clarify crew assignments. Our research has shown that every hour spent on planning will help save 17 hours at the end of the job.\nReducing Errors and Rework\nOne of the most important contributors to improved job productivity is the reduction of errors and rework. You can only achieve this goal by knowing what it is that labor is working on at any given time and how you can avoid the obstacles that might present themselves. The main reason for rework and error are miscommunications between supervisors and electricians as well as between the general contractor and subcontractors. By creating a simple and routine communication channel, you can avoid many of these issues.\nOne of the tools developed over the last 15 years — short interval scheduling® — has been explained in earlier EC&M articles (“The Secret to Short Interval Scheduling,” February 2009, and “The Agile Construction Advantage,” October 2006). Using this tool will help improve the communication of obstacles. Reducing rework is another means of squeezing dollars out of the project during both good times and bad. During the good times, gaining more-than-anticipated installation time is always a plus. During the bad times, it is a “must,” because the extra buffers are now gone.\nSegregating Fixed Cost from Variable Cost\nThis task is much simpler than it sounds. First, you have to realize that during poor economic times, the competitive pressure of the construction market forces contractors to take on projects at lower-than-usual gross margins. This practice has a few disadvantages:\n- Negative impact on cash flow.\n- Reduced net profits.\n- In larger jobs, the more productive labor may be tied up for a longer period of time, making their availability more scarce when the economy comes back on the more profitable jobs.\n- Negative impact on bonding.\nThe historical approach to respond to this pressure is based on a cost-based pricing model, which assumes unchangeable labor units for the project completion. In other words, the low margins are achieved by cutting the profit from the top, assuming the labor units cannot be adjusted. Best-case scenario, labor units are cut across-the-board to have a competitive estimate, without any knowledge of where these cuts would come from for the job to actually perform profitably.\nContinue to Page 2\nThe alternative approach is based on price-based costing (PBC), coined by management guru Peter Drucker, which focuses on the improvement of elements of the cost drivers, such as labor productivity, cost of money, and cash-flow during these times. PBC will ensure a higher net profit under the tough economic market environment by focusing on the internal and job specific cost drivers. In this model, the selling price is set by the customer and the market, and the expected return in the form of profit is fixed. From here, the cost of operations needed to complete the project is identified and worked on for better-than-estimated profits. See Fig. 2 (click here to see Fig. 2) for a comparison of these two models. If you want to be a profitable and competitive PBC contractor, you need to know the cost drivers of various activities and learn how to manage them.\nA contractor’s bottom line is driven by its negotiation skills and ability to manage and contain costs. You must be able to clearly identify cost drivers and opportunities for their improvement. With this in mind, you must make strategic and tactical decisions on where to make cuts in the estimating and project production phases of the project, all while having confidence that these cuts are feasible and will not arbitrarily require you to give up your gross margins.\nThe fixed cost of the company has to be separated from its variable cost. Many contractors believe that if they allocate their fixed cost to the jobs, the jobs will carry them. This can only work if the fixed cost can be reduced accordingly with the reduced revenue payoff.\nFor example, let’s say a contractor has an accountant that is fully engaged when the company has annual revenue of $10 million. Naturally, this person’s hours will now be allocated across whatever jobs still remain in the mix. This will drive up the cost of these remaining jobs. This person can only be considered as a variable cost if you can reduce his hours or reduce the portion allocated. Otherwise, he is a fixed cost and needs to be recognized as such.\nTaking Care of Your People\nTypically, the very first thing contractors do when the going gets tough is take away perks from their employees, such as trucks and gas cards. If the fixed and variable costs are segregated correctly, trucks and gas are going to be a smaller part of the overhead cost when the volume drops. However, the people who made the company money during the good times should not be punished during the tough times. A contractor has to have a war chest for the bad economic times to take care of its people.\nThe paradox is that this war chest can only be built if, in the good times, the same principles outlined in this article are followed, and the extra profits are stored in this chest. If a contractor made a few million dollars during the good times, for example, a portion of this amount should go into some kind of savings account to make sure its loyal and diligent employees do not suffer during the bad times.\nIf everyone else is cutting their cost by getting rid of trucks, can you imagine how proud your labor force will be if they are driving to work with their shiny trucks every day? That is the best marketing and advertising campaign you can ever embark on — by letting your customers know that you will take care of them like you take care of your people.\nBy allocating costs correctly, taking care of employees, increasing job productivity, and reducing rework and obstacles on jobs, an electrical contractor can make money in a tough economy and add extra profits to the bottom line in a good one. These practices are not just self serving. They will also prove to your customers that you’re not only business savvy but also cognizant of the value an electrician’s skill and effort brings into a building’s electrical systems. This transfer of value is done most optimally when people are taken care of and the focus is on transferring this value with minimal losses and friction.']	['<urn:uuid:481f4ba0-5071-4607-80f3-f6be2f4b5d31>']	open-ended	direct	verbose-and-natural	similar-to-document	single-doc	novice	2025-05-13T04:02:16.770989	23	82	1542
83	do family judges approve custody restrictions	Most judges do not favor rights of first refusal. Family law judges have stated that a right of first refusal is a way to create or increase conflict between parents. Judges want to reduce conflict and keep it amicable between parents, and do not want parents back in court if it is avoidable.	"['Is a Right of First Refusal a Good or Bad Idea in Child Custody Cases?\nRight of first refusal in child custody orders is often a terrible idea...here is why\nThe right of first refusal is an often misunderstood principle in child custody cases. Most people do not understand how the right of first refusal works, nor why it may be a good idea in some cases but often a bad idea in most cases.\nThis article will cover the right of first refusal in detail. Let\'s get started.\nWhat is a right of first refusal?\nA right of first refusal is a court order that does not allow one parent to place the child in the care of another person without first giving the other parent the first right to care for the child.\nWe call it a right of first refusal because the other parent has the first right to refuse (or accept) the childcare responsibilities.\nThat ""other person"" may mean anyone. It can be a daycare provider, a family member, a friend, a babysitter, etc.\nWhat are the different types of first refusal rights in custody orders?\nThe different types of first refusal rights are as follows:\n- A right of first refusal to care for the child if the child will be away from the custodial parent for a certain number of hours.\n- A right of first refusal to care for the child if the child will be away from the custodial parent for an overnight.\n- A first refusal right that does not focus on the number of hours but instead the person who cares for the child.\nFormal daycare is one example of the third situation. A parent may argue before a child goes into daycare, they want the opportunity to care for the child during that same time, regardless of how long that may be.\nThe first two are the most common.\nWhy do some parents want a right of first refusal for their custody order?\nMost of the time, a parent wants a right of first refusal because they don\'t want a stranger or someone other than them to care for the child.\nCan parents agree to a custody order that includes a right of first refusal?\nYes, parents can agree on the right of first refusal in their custody stipulation (which means agreement), which can become a court order.\nWhat if parents disagree about including the right of first refusal language in their custody order?\nIf one parent wants a right of first refusal and the other does not, the first parent has a choice to make. Does that parent who wants it have the facts and evidence to persuade the court that a right of first refusal is consistent with the child or children\'s best interest.\nWhat are good arguments for including a right of first refusal in a custody order?\nIn our opinion, there is usually not a good argument for a right of first refusal that does not involve overnight visitation. Even then, the right of first refusal should not be for every overnight visitation. For example, does the first refusal right make sense if a child is having a sleepover with friends?\nIf you intend to argue for right of first refusal, be reasonable. Here are examples where it may be reasonable.\n- A right of first refusal that triggers if there are more than a certain number of overnights per year.\n- A right of first refusal that triggers for any overnight where the child will not be with family, friends or certain designated people.\n- A right of first refusal that triggers if there are two or more overnights away from the parent with custody but not certain events such as a camp, sleepover with friends, etc.\nWe understand some parents cannot handle extended parenting time but still request it to lower their child support obligation.\nA first refusal right can rein in a parent like that, so a child or children are not spending significant parenting time cared for by family, friends, or daycare providers. For those situations, the first refusal right makes sense. Rarely is that a situation that does not regularly involve overnight visitation or multiple overnights.\nWhat are good arguments against a right of first refusal?\nSome parents request a right of first refusal for any time away from the other parent or non-overnight time away. With some exceptions, that is usually not reasonable.\nParents who want this often argue for it because the other parent works during the day (Monday through Friday) and does not want the child in childcare. That should be a failing argument based on California law.\nWe will quote from the case of Marriage of Loyd. That was a case where the trial court gave more time to the mother because she did not work and denied that time to the father because the child would be in childcare during regular work hours. The appellate court stated to the trial court its ruling was not proper. Here is a quote.\n""The trial court in the present case based its decision upon the fact that Bryan would place his children in day care while he worked. The trial court assumed, without any supporting evidence, that the mother could provide better care for the children because she was in the position of being able to remain in the home with the children during the day. The investigator\'s report, upon which the trial court heavily relied, opined that both parents were adequate providers, but that the ""children should be in the care of a parent whenever possible."" It is interesting to note that the investigator who made this recommendation also recommended that the parents consider allowing H.L. to continue his day care arrangement, as it encompassed a preschool component. No specific evidence was presented at the hearing demonstrating that Bryan\'s work schedule had any negative impact on the best interests of the children.""\nThe best way to argue against a right of first refusal is to show how it is not consistent with a child\'s best interest but rather the other parent\'s unhealthy attachment to the child or children being away from that parent. That is what first refusal rights sometimes are - not a concern for the child\'s best interest but the requesting parent\'s anxiety resulting from being away from the child.\nA request for this right may come from a subjective belief that is genuine. But just because the parent subjectively feels the way they do does not mean it is objectively reasonable or consistent with how California family courts view such requests.\nDo judges like a right of first refusal provision in custody orders?\nJudges are human beings, and you will get different perspectives on the right of first refusal. Our experience with the family law judges we come across (as well as the general judicial attitude) is they do not favor rights of first refusal.\nWe have heard family law judges state a right of first refusal is a way to create or increase conflict between parents. Judges want to reduce conflict and keep it amicable between parents. They do not want parents back in court if it is avoidable. Rights of first refusal may invite conflict by limiting the freedom parents have to care for the child or delegate that childcare for reasonable times.\nHow can you remove a right of first refusal from an existing child custody order?\nThe best way to remove a right of first refusal is to file a request for order with the court and ask for the modification of that provision. The situation assumes negotiations with the other parent fell apart.\nThis request for order should explain to the court why the right of first refusal is working against the child or children\'s best interest. If the other parent who wants the right is using it to create conflict, you should give the court compelling examples of those facts.']"	['<urn:uuid:54a49519-7b70-4fe1-9055-f2c0e96c61ba>']	factoid	direct	short-search-query	distant-from-document	single-doc	novice	2025-05-13T04:02:16.770989	6	53	1332
84	How do modern smart buildings manage to save energy while still keeping people comfortable throughout the day, and what systems make this possible?	Smart buildings use an intelligent network of sensors and actuators that automate and optimize energy consumption, water usage, air conditioning, security and lighting. The buildings can redistribute energy flows based on needs - for example, excess heat from one area can be diverted to heat other spaces like saunas. They also employ various storage systems including ice storage units, geothermal probes, supercondensators and battery packs that can store energy from hours to seasons. These systems work together through computing and communication networks to maintain comfort while increasing efficiency compared to traditional buildings.	['Research platform “ehub”\nEnergy revolution underground\nState-supporting or independent?\nHomes of the future can self-supply with energy for extended periods. However, they are not entirely independent. They connect to the public electricity grid at regular intervals, feeding in electricity from solar units or collecting additional energy at times of peak load or over longer periods, like in winter.\nBut what’s the best way to regulate this system? And whose interests ultimately determine how it is run? Is it the energy suppliers, who understandably want an electricity network with maximum stability and predictable loads as well as access to emergency reserves at times of peak demand? Should they be allowed in such cases to switch appliances in private households on and off in order to keep the grid stable, serve the public good (and maximize their profits at the same time)? Should energy suppliers install and operate new technologies for residents, or is it the job of the private households to use energy in the most economical way? Is it up to the residents to run their homes ecologically and reduce their carbon footprint – or should they instead use energy from the most reasonably priced source in each case?\nWhat about suppliers who are looking to establish new, personal services with knowledge gathered from the internet – and thus overload the grid in a way hardly foreseeable for network operators? What if a storage battery in the building is not just used to optimize one’s own consumption, but also to avoid high tariffs and any usage restrictions from the operator?\nThese questions are relevant not only from a social and economic perspective but also from a technical point of view, as there has been insufficient research to date on the technical solution for future feed-in and procurement rules. Empa’s energy research demonstrator, the “Energy Hub” (“ehub” for short) aims to provide answers and demonstrate what is possible. Once NEST is fully occupied, up to 15 research units with apartments, offices and leisure facilities will be supplied by ehub. This means that it will cover the energy consumption of 40 residents as well as 40 people working in the building during the day. The energy consumption of the individual units will change several times during the day, thus altering the direction of the energy flow. For example, the midday sun will shine on the solar panels on the roofs of the residential modules where no-one is using energy, while at the same time energy is needed in the office section. In the evenings, the excess heat from the modules with southwest-facing façades can be diverted to heat the sauna in the gym and spa.\nSummer heat for the winter\nTogether with energy management throughout the course of a day, storage media are also being tested that can store energy over a day, a week or even an entire season. The interplay of all these components should then show what is possible in terms of the optimum distribution and use of energy in a renewables age. ehub has an ice storage unit comprising 65 cubic meters, two geothermal probes drilled 260 meters into the earth and one spiral geothermal probe that goes down twelve meters into the ground. In the summer time, heat from the sun is used to defrost ice, while in the winter a heat pump cools the water to freezing. This allows the crystallization heat released upon freezing to also be used.\nWarm water with a temperature of up to 80 degrees is circulated around the three geothermal probes in the summer, and the stored heat in the ground can then be recuperated into the homes during the winter half-year. NEST also has supercondensators for fast electricity storage as well as a battery pack with a capacity of 96 kWh (kilowatt hours). That corresponds to the capacity of five BMW i3 cars or one Tesla Model S at the top of the range. According to the plan, the batteries should be able to store enough energy to fuel the fully occupied NEST for approximately one day.\nOnce the batteries are full, excess electricity can be diverted to move, where it is used to produce hydrogen in an electrolyzer. Hydrogen can be stored for several weeks in pressurized gas containers or can be used directly in fuel cell cars. NEST itself can also reuse hydrogen, as there is a high-temperature fuel cell in the basement that normally converts natural gas into electricity and heat. This system is to be used to test how much internally generated hydrogen can be mixed in with natural gas.\nFlexibility as a research object\nThe building technology components integrated in NEST are not prototypes. Instead, they are generally commercially available appliances in line with the state of the art. The trick is the innovative method used to interconnect the components, which the researchers hope to use to flexibly evaluate new energy management scenarios and analyze their effectiveness. Not only can researchers and partners from industry install and validate new control modules or prototypes there, maximum flexibility of regulation is also possible. All of the equipment that runs in an automated manner in normal operation can be overridden by internal and external researchers, who can also add new algorithms and combine the equipment to form new consumer groups.\nResearch at ehub started in November. The first project for the ehub researchers is to compile theoretical advance calculations of the effects of electricity production tariffs on the distribution network. The hypotheses resulting from that project will then be implemented in ehub under real-world conditions and tested in practice in collaboration with the residents. NEST can also be used to simulate the effects of appliances and users that have a positive or negative impact on the stability of the network – in an extreme scenario even blackouts or the breakdown of the heating and ventilation system. The research platform allows for risk-free simulations, as it has a fallback level that can quickly re-establish normal operations.\nThe ehub research project will provide findings on how much energy is needed in residential areas and what the peaks are as well as on how the required energy volume can be sensibly reduced to a minimum. Some of the information gained will tell us how independently residential and office districts can manage their energy supply, and to what extent future legislation and directives can be used to encourage behavior that serves the interests of the grid. This makes ehub a political as well as a technical and ecological research project.', '“Smart buildings are the solution to check the energy consumed by buildings & the carbon emission caused by them. They are more than automatic lighting & CCTVs. These buildings are controlled by an intelligent network of sensors and actuators with computing & communication systems that greatly increases the efficiency of buildings while supporting the inhabitants in their day-to-day activities. Everything from energy consumption, water consumption to air conditioning, security & lighting are automated.”\n– Annrin K Thomas, Environmentalist & Civil Engineer at Advenser Engineering Services\nThe foundation of a smart building is made out of data. In order to leverage the most out of smart buildings everything starting from design, procurement, fabrication, assembly & implementation to commissioning, operation & maintenance has to be done through a fully integrated platform.\nWhere does BIM come in the case of smart buildings?\nUnlike constructing conventional buildings, constructing a smart building involves the integration of the core systems of a building such as lighting, electricity meters, water, Heating Ventilation & Air conditioning systems, firefighting system, water pumps with a network of sensors and an integrated control system.\nThis is where BIM comes into play!\nBuilding Information Modeling (BIM) is all about integrating the several aspects that go into construction and it is the pre requisite in constructing a smart building. Which makes BIM the right tool in the construction of smart buildings.\nHow does a Smart Build Environment (SBE) work?\nBefore we dwell deep into the benefits of incorporating the various BIM services in the construction of smart buildings, let’s have a quick look into how a smart build environment work.\nTraditional buildings have provided the inhabitant’s shelter, protection from extreme weather & safety at the same efficiency level for years. Unlike these buildings, smart buildings can be considered as living organisms connected to an intelligent network.\nSmart buildings are constantly evolving while significantly improving efficiency. There will be dozens of smart objects like sensors and actuators installed in the smart buildings. These smart objects will constantly monitor & interact with their immediate environment and will be in communication with each other either through Ethernet cables or over an internal wireless network.\nSmart buildings are known to make its inhabitants more productive with better lighting, thermal comfort, better air quality and better security at a lower cost and environmental than the traditional buildings.\nChallenges faced in a Smart Build Environment\nLike we discussed, dozens of smart objects will be ubiquitously installed in an SBE to perform sensing and control of the immediate environment. The three mail challenges faced in an SBE are\nChallenge 1: The physical location where smart objects such as sensors are embedded can greatly affect their performance and ability tocarry out certain tasks. For e.g. The location of light detecting sensor can greatly affect the ambient light or occupancy it senses.Apart from this, the wireless network of the Ethernet cable through which these smart objects communicate should be designed to enable perfect communication between them.\nChallenge 2: The way these smart objects embedded in SBEs interact with their environment is very crucial. These objects can’t really function solely on the data they collect from their immediate surrounding rather they need to be fed the space data such as floor plans of the buildings too. In the case of conducting a performance analysis or energy analysis of the SBE building, along with the information from the sensors & meters data on building architecture and geometry are also needed.\nChallenge 3: Maintaining the smart objects in the building and properly documenting the data from an SBE building is not a walk on the beach. In an SBE building, the data will be more complicated than the traditional structures\nBattling the challenges with BIM\nIn the pre-construction stages of a project, BIM can be extremely vital. The data rich graphical model can be utilized to identify any shortcomings before first breaking ground.\nThe primary advantage of designing an SBE building with BIM lies in the fact that a data rich BIM model can be used to plan the layout and placement of the sensors, actuators, tags and meters inside the SBE building. The performance of the SME building can be verified against the known parameters and the layout and location can be optimized for the best functional performance.\nIncorporating BIM in SBE buildings can be the answer to the challenge of asset tracking & maintenance during the post construction phases. A BIM model can store the physical information of smart objects & their installed location these data can be visualized in 3D.\nIt is time to embrace the fact that the buildings we work & live in shape us! A better building always influences how happy and productive the inhabitants are. Smart buildings are the future of the construction industry.\nThe journey to constructing these buildings start long before first breaking ground. BIM is the only futuristic technology that can drive that journey.']	['<urn:uuid:9225cfa7-3e3f-4825-b3e4-2bd174f49e48>', '<urn:uuid:2c8fbb53-810a-4c2d-a156-c9e9abd7e5dc>']	factoid	direct	verbose-and-natural	distant-from-document	three-doc	novice	2025-05-13T04:02:16.770989	23	92	1907
85	relationship between coastline tilting foraminifera changes and megathrust earthquakes in pacific north america	Studies have shown that before major megathrust earthquakes, there's a change in foram composition in coastal sediments, shifting from species living in slightly salty water to those preferring saltier conditions. This indicates coastline tilting downward toward the ocean. This occurs because the Pacific plate, while sliding under the North American plate, pulls down the edge of the North American plate before suddenly releasing, causing the earthquake. Research has identified three such megathrust earthquakes preceded by coastline tilting over the past 3000 years.	['Earthquake Warning Signs in Tiny Marine Fossils\nTiny shelled marine organisms called foraminifera can provide clues about earthquake occurrence in the past—and the future. Photo: UCMP.\nIt feels like the world is still shaking from the earthquake and ensuing tsunami that hit northern Japan on Friday. The 8.9 magnitude quake created enormous waves of water, which moved quickly through the ocean and hit the coast of Japan with waves that in some areas were over 10 feet high. This animation shows how earthquakes give rise to tsunamis. When tsunamis hit shore, they can carry with them sediment that they’ve picked up from the bottom of the ocean. This sediment differs from the sediment close to shore, leaving a long-term record of the tsunami’s occurrence.\nPaleontologists can look at the layers of sediment along the coast and see records of past tsunamis. They can also see that before tsunamis occur, the land along the coast often starts to subside, as one tectonic plate slips underneath another. The clue that tells paleontologists that the coastline tilts before an earthquake is a group of tiny marine organisms, called foraminifera. By studying these organisms in the sediment along the shore of the West Coast, scientists can learn how frequently tsunamis occurred here in the past, and whether we can predict a big quake in the future.\nThe tiny marine organisms in the sediment are called foraminifera, or forams for short. They are protists—neither animals nor plants, protists are a grab bag of simple organisms that includes amoebas, seaweeds, and single-celled algae. Forams are unicellular, and they build a shell, called a test, out of calcium carbonate. The test has little opening from which pseudopods—thin strands of the cell’s cytoplasm—protrude. The pseudopods help the forams move around. However, it is the calcium carbonate tests that make forams so useful as records of geological events.\nThe tests of foraminifera are often well preserved in marine sediment, as fossils. Forams evolve relatively quickly, so micropaleontologists (folks who study tiny fossils) can determine the age of the sediment by identifying the species of foram that is preserved. Also, each species of foram can survive only in a narrow range of environmental conditions. If the water is too salty, a given species can’t survive; if the water is too fresh, that species won’t survive either. The salinity of the water has to be just right. This means that micropaleontologists can use foram fossils to estimate the salinity of the water in the past. (For similar reasons, forams are also good indicators of the proximity of oil deposits, and a good proxy for past climates.)\nA few years ago, UC Berkeley Professor Emeritus Jere Lipps and a few colleagues, including Dalhousie University professor David Scott, travelled along the coast from Alaska to Baja, taking cores of coastal sediment along the way. They found that several years before a big earthquake and tsunami, the foram composition in the sediment changed slightly. The forams shifted from species that live in very slightly salty water to species that live in water that is even saltier. This is a sign that the land had begun to tilt downward towards the ocean.\nThe Pacific plate is slowly sliding underneath the North American plate. But the plates stick together, and the edge of the North American plate gets pulled down slightly along with the Pacific plate. Suddenly, the plates will un-stick; the North American plate will release and move upwards again, and the Pacific plate will slide underneath. This kind if quake is called a megathrust earthquake. Dr. Lipps and his colleagues found that there have been three megathrust earthquakes, preceded by a tilt in the coastline, over the past 3000 years.\nForams are good measurements of past coastline tilt. But to measure coastlines in real time today, scientists can deploy seismometers. By placing seismometers in areas that have undergone a pre-earthquake tilt in the past, we may be able to detect early warning signs of potentially destructive megathrust earthquakes and resultant tsunamis.']	['<urn:uuid:5d274d06-24f1-4c4f-9ba2-e1cd495740ad>']	open-ended	with-premise	long-search-query	similar-to-document	single-doc	expert	2025-05-13T04:02:16.770989	13	82	667
86	I am researching safeguarding policies need to know difference between abuse reporting requirements for vulnerable adults versus children in terms of confidentiality and consent	There are important differences in how confidentiality and consent are handled when reporting abuse of adults versus children. For children, there is an absolute duty to report information to Gateway Social Services Teams immediately to keep the child safe - confidentiality cannot be promised even if requested by the child. With adults, the approach must be person-led with their involvement and choice throughout the safeguarding process, focused on improving life according to how they want to live. However, both frameworks require staff to explain that complete confidentiality cannot be maintained as the organizations must work within wider statutory systems. Both also emphasize that suspicions, concerns, knowledge or allegations of abuse must be reported to statutory authorities, but the adult framework provides more emphasis on supporting the adult's choices and control in how this is done, while child protection prioritizes immediate reporting to ensure safety.	['2.1 What is safeguarding?\nSafeguarding is defined as ‘protecting an adult’s right to live in safety, free from abuse and neglect.’ (Care and Support statutory guidance, chapter 14). Adult safeguarding is about preventing and responding to concerns of abuse, harm or neglect of adults. Staff should work together in partnership with adults so that they are:\n- Safe and able to protect themselves from abuse and neglect;\n- Treated fairly and with dignity and respect;\n- Protected when they need to be;\n- Able easily to get the support, protection and services that they need.\n2.1.1 The aims of Adult Safeguarding are to:\n- Stop abuse or neglect wherever possible;\n- Prevent harm and reduce the risk of abuse or neglect to adults with care and support needs;\n- Safeguard adults in a way that supports them in making choices and having control about how they want to live;\n- Promote an approach that concentrates on improving life for the adults concerned;\n- Raise public awareness so that communities as a whole, alongside professionals, play their part in preventing, identifying and responding to abuse and neglect;\n- Provide information and support in accessible ways to help adults understand the different types of abuse, how to stay safe and what to do to raise a concern about the safety or well-being of an adult; and\n- Address what has caused the abuse.\nSection 2 of the Care Act requires Local Authorities to ensure the provision of preventative services (i.e. services which help prevent or delay the development of care and support needs, or reduce care and support needs). Organisations should take a broad community approach to establishing safeguarding arrangements, working together on prevention strategies. A core responsibility of a SAB is to have an overview of prevention strategies and ensure that they are linked to the Health and Wellbeing Boards, Quality Surveillance Groups (QSG), and Community Safety Partnerships prevention strategies (See appendix 4). Prevention strategies might include:\n- Identifying adults at risk of abuse;\n- Public awareness;\n- Information, advice and advocacy;\n- Inter-agency cooperation;\n- Training and education;\n- Integrated policies and procedures;\n- Integrated quality and safeguarding strategies;\n- Community links and community support;\n- Regulation and legislation;\n- Proactive approach to Prevent.\nPartners should embrace strategies that support action before harm can occur. Where abuse or neglect has occurred, steps should be taken to prevent it from reoccurring wherever possible, doing so within relevant parameters but sharing intelligence to support a holistic partnership approach to prevention. For example, visiting staff might identify an adult with a combination of characteristics that may render them more vulnerable to a fire risk and take action to refer to Royal Berkshire Fire and Rescue Service for a fire safety check.\nOrganisations should implement robust risk management processes that identify adults at risk of abuse or neglect and take timely appropriate action. Safeguarding functions should be integrated into quality management and assurance structures.\nPrevention should be discussed at every stage of safeguarding, and is especially important at the closure stage (which can happen at any time) when working with adults on resilience and recovery. Discussions between staff and adults, their personal network and the wider community (if appropriate) help build up resilience as part of the recovery process. Where support is needed to prevent abuse, this needs to be identified and put into safeguarding planning.\n2.1.3 Raising awareness\nPublic awareness campaigns can make a significant contribution to the prevention of abuse. They are more effective if backed up by information and advice about where to get help, and there is effective training for staff and services to respond. Joint initiatives to raise awareness can be very effective.\nThe term ‘information’ means the communication of knowledge and facts regarding care. ‘Advice’ means helping a person to identify choices and/or providing an opinion or recommendation regarding a course of action in relation to care and support. Local Authorities are required to establish and maintain an information and advice service relating to all local residents within its area, not just adults with care and support needs.\nInformation and advice is critical to preventing or delaying the need for services and, in relation to safeguarding, can be the first step to responding to a concern. Section 4, the Care Act states that Local Authorities must: ‘establish and maintain a service for providing people in its area with information and advice relating to care and support for adults and support for carers.’ This includes information and advice about safeguarding and should include:\n- How to raise concerns about the safety or wellbeing of an adult who has needs for care and support;\n- Awareness of different types of abuse and neglect;\n- How people can keep safe, and how to support people to keep safe;\n- The safeguarding adults process;\n- How SABs work.\nAll organisations should ensure that they are able to provide this service and can signpost adults to receive the right kind of help by the right organisation.\nWhereas information may be generic to a lesser or greater extent, advice needs to be tailored to the person seeking it, recognising people may need different mediums through which to communicate. Advice and information should, where possible, be provided in the manner preferred by the person and in a way to help them understand the information being conveyed. This should be cognisant of the Equality Act 2010. ‘Reasonable adjustments’ should be made to ensure that disabled people have equal access to information and advice services. Reasonable adjustments could include the provision of information in accessible formats or with communication support.\nOrganisations have a number of direct opportunities to provide, or signpost people to information and advice, in particular for safeguarding:\n- At first point of contact;\n- During or following an adult safeguarding enquiry;\n- Safeguarding planning;\n- Risk management;\n- Through complaints and feedback about a service which identifies a safeguarding concern.', 'Child Protection Policy\nSafeguarding Children Policy & Standards for the Children’s Cancer Unit Charity (CCUC)\nForeword from the Children’s Cancer Unit Charity (CCUC) board of Trustees\nWe are very pleased to introduce Safeguarding Children: Policy & Standards for the Children’s Cancer Unit Charity 2020.\nA child means anyone below the age of eighteen years.\nWe must remember that children are an integral part of the Children’s Cancer Unit Charity and must be cherished, cared for and safeguarded.\nIn the light of development in legislation, policy and guidance, alongside learning from reviews of safeguarding practice and standards within Charity Organisations we began an internal review of our Safeguarding Practices: which lead to the development of our Safeguarding Children Policy.\nFelix Mooney, Chairperson\nLaurie Jones, Trustee\nIntroduction by the Chairperson of the Children’s Cancer Unit Charity\nFamilies need to know that the Children’s Cancer Unit Charity is making every effort to protect children. The safety of Children is the paramount consideration.\nRaising awareness and understanding regarding the seriousness of implementing correct safeguarding environments and procedures at all levels of the Children’s Cancer Unit Charity is part of ensuring accountability.\nThe policy element of our document sets out our commitments to keeping children safe through:\n- Duty of care to report any concerns regarding children\n- Caring for the welfare of all children involved in the Children’s cancer Unit Charity,and of the adults who work with them\n- Responding appropriately to child protection suspicions, knowledge of allegations,and to the people who bring these to the attention od the Children’s Cancer Unit Charity.\nChild Safeguarding Policy Statement of the members of the Children’s Cancer Unit Charity\nAs a Trustee of the Children’s Cancer Unit Charity in Northern Ireland, we recognise and uphold the dignity and rights of all children, are committed to ensuring their safety and well- being, and will work in partnership with all parents/guardians to do this.\nAll Children’s Cancer Unit Charity personnel (including paid staff and volunteers) have a responsibility to safeguard children through promoting their welfare, health and development in a safe and caring environment that supports their best interests and prevents abuse.\nDetails of Personnel to Contact if you are Concerned about the Welfare and Safety of Children\nInsert below the names and contact details of the relevant Designated Child Protection Officers (DCPO), and statutory authorities (PSNI and your local Health and Social Care Trust)\nRole/ Service Contact Details\nDesignated Child Protection Officer: Sheila Ferguson – 0759 636 4246\nDeputy Child Protection Officers: Jacqueline Wilkinson – 0771 043 6208\nAnna McDonald – 075 076 942 51\nGateway Social Services Team: (9am-5pm) 028-9050-7000\n(Out-of-hours Emergency Service): 028-9504-9999\nIn developing and implanting the Child Safeguarding Policy, the Children’s Cancer Unit Charity is guided by:\n1. Children’s rights, international and national law\nThe United Nations Convention on the Rights of the Child (UNCRC) outlines the forty-two fundamental rights to be implemented in national law by signatories to the convention. Full realisation of these rights will ensure that children will be “brought up in a spirit of peace, dignity, tolerance, freedom, equality and solidarity”, (1) whilst respecting the culturalidentity of each child.\n2. Northern Ireland law, policy & guidance\n- Safeguarding Board Act (NI) 2011\n- Cooperating to Safeguarding Children, 2003\n- Children (NI) Order, 1995\n- Criminal Law Act (NI), 1967\n(1) Preamble to the United Nations Convention on the Rights of the Child, 1989 (United Nations)\nDuty of Care\nEach of us has a duty to notify the statutory authorities of suspicions, concerns, knowledge or allegations that a child is being or has been abused.\nSuspicions, concerns, knowledge or allegations may relate to possible abuse by a member of the Children’s Cancer Unit Charity personnel, but they can also relate to incidents in the child’s family, or elsewhere in the community.\nCaring for the welfare of all children and the adults who work with them\nMeasures to create and maintain environments that are safe for children, that prevent abuse, and that create nurturing, caring conditions within the Children’s Cancer Unit Charity for the children and adults who work with them, will continue to be strengthened and reviewed. This will be done through training, support, communications and quality assurance.\nResponding appropriately to child protection suspicions, concerns, knowledge or allegations\nAnyone who brings any suspicion, concern, knowledge or allegation of current or past abuse of a child to the notice of the Children’s Cancer Unit Charity will be responded to sensitively, respectfully, actively and in a timely manner, in line with child protection procedures and Charity Organisation requirements.\nScope of the Policy\nThis policy applies to all Children’s Cancer Unit Charity personnel who are required to comply with it. Full understanding of and adherence to this policy should lead to a more in depth understanding of the rights of children and young people. Everyone has a role to play in safeguarding children.\nPutting the Policy into Action\nThe Children’s Cancer Unit Charity will implement this policy by ensuring that all support and activities comply with:\n- Duty of care to report any concerns regarding children\n- Caring for the welfare of all children involved in the Children’s cancer Unit Charity, and of the adults who work with them\n- Responding appropriately to child protection suspicions, knowledge of allegations, and to the people who bring these to the attention of the Children’s Cancer Unit Charity.\nCommitment by the Children’s Cancer Unit Charity\nOn behalf of the Children’s Cancer Unit Charity Chairman and Trustees, I commit to safeguarding children by agreeing to follow this Child Safeguarding Policy.\nChildren’s Cancer Unit Charity\nThe Promotion & Prevention activity of creating and maintaining safe environments which enables children to grow up safely from abuse and harm…AND Safeguarding also allows staff (paid or voluntary) to protect themselves by following clear policies & procedures.\nSafeguarding is everyone’s business.\nWe all have a duty of care to protect children.\nChild Protection falls under the umbrella of Safeguarding. It is one part of safeguarding. “It is the specific activity that is undertaken to protect children who are suffering, or are\nlikely to suffer significant harm”. [Co-operating to Safeguard Children (revised August 2017].\nIf an employee is informed about or concerned about the abuse of a child, young person, or adult at risk, they must take the following steps:\n- Always place the child or adult’s welfare and interests as the paramount consideration.\n- Make safeguarding personal using a person-led and outcomes-focused approach. Employees must talk with the child, young person, or adult at risk about how best to respond to their safeguarding situation in a way that enhances their involvement, control, and choice throughout the safeguarding process.\n- Listen carefully and actively to the person – at this stage, there is no necessity to ask questions. Let the person guide the pace and remember their ability to recount an allegation will depend on age, culture, language and communication skills, and disability.\n- Do not show shock at what is being said. This may discourage the child or adult from talking, as they may feel you are unable to cope with what they’re saying, or perhaps that you’re thinking badly of them.\n- Do not investigate. If anything needs to be clarified in order to understand the safeguarding risk, ask clear, open questions:* Practice being SILENT…just listen 10\n* ‘Is there anything else you wanted to tell me?’…If they say ‘no’…Do not ask again- and RECORD exactly (using quote marks) what was said by the child and employee.\n* Do not ask any ‘why’ questions as these can suggest guilt or responsibility.\n- Remain calm and reassure the person that they have done the right thing by talking to a responsible adult.\n- Never promise to keep a secret or confidentiality. CCUC works within wider statutory systems and must collaborate in order to effectively support and care for children, young people, and adults at risk. It is important that this fact, and its implications of transparency and reporting, are emphasised in early and ongoing conversations.\n- Ensure the child or adult at risk understands what will happen next with their information.\nIf the person disclosing is a child, employees have a duty to ensure that the information is passed on to Gateway Social Services Teams immediately in order to keep the child safe.\nIf a child requests confidentiality, employees must explain CCUC requirements, for example, ‘I’m really concerned about what you have told me and I have a responsibility to ensure that you are safe’.\nAs concerns arise, employees must talk to their Designated Child Protection Officer\nWhere there are concerns or allegations about an adult employee or volunteer who is working with children or adults at risk (often called someone in a “position of trust”) within CCUC, employees must follow up with the DCPO.\nTypes of Abuse\nPhysical Abuse is deliberately physically hurting a child. It might take a variety of different forms, including hitting, biting, pinching, shaking, throwing, poisoning, burning or scalding, drowning or suffocating a child.\nThe persistent emotional maltreatment of a child/young person. It is also sometimes called psychological abuse & it can have severe & persistent adverse effects on a child’s emotional development.\n- Emotional abuse may involve deliberately telling a child that they are worthless, or unloved & inadequate.\n- It may include not giving a child an opportunity to express their views, deliberately silencing them, or ‘making fun’ of what they say or how they communicate.\n- Emotional abuse may involve bullying through social networks, online games or mobile phones – by a child’s peer.\nSBNI, core child protection policies and procedures, 2017\nSexual Abuse occurs when others use and exploit children sexually for their own gratification or gain or the gratification of others. Sexual abuse may involve physical contact, including assault by penetration (for example, rape, or oral sex) or non-penetrative acts such as masturbation, kissing, rubbing and touching outside clothing.\n“Co-operating To Safeguard Children and Young People in Northern Ireland” (DHSSPS 2016)\nNeglect is the failure to provide for a child/young person’s basic needs, whether it be adequate food, clothing, hygiene, supervision or shelter that is likely to result in the serious impairment of child/young person’s health & development.\nChildren/young people who are neglected often suffer from other types of abuse. It may include neglect of, or unresponsiveness to a child’s basic emotional, social & educational needs.\n-The intentional ill treatment, manipulation or abuse of power and control.\n-To take selfish or unfair advantage of a child or young person or situation for personal gain. -Could be child labour, slavery, servitude, engagement in criminal activity, begging, benefit or other financial fraud or child trafficking.\n-Extends to the recruitment, transportation, transfer, harbouring or receipt of children for the purpose of exploitation.\nCan be child sexual exploitation.\n- Actions deliberately undertaken with aim of befriending & establishing an emotional connection with a child, to lower the child’s inhibitions in preparation for sexual abuse and / or exploitation.\n- Women/family (& sometimes professionals) are targeted & groomed in the same manner as the children.\n- Offenders will create distance between the child & their supports / protections.\n- Grooming creates dependency. Offenders can be regarded as ‘boyfriends’, & their residences places of safety where victims could bring their friends.\n- Sometimes victims actually believe that they are exploiting the abuser.\n‘Threatening, controlling, coercive behaviour, violence or abuse (psychological, virtual, physical, verbal, sexual, financial or emotional) inflicted on anyone (irrespective of age, ethnicity, religion, gender, gender identity, sexual orientation or any form of disability) by a current or former intimate partner or family member.’\nStopping Domestic and Sexual Violence and Abuse in Northern Ireland A Seven Year Strategy: March 2016.\n(Please note as of Apr 2020: new criminal laws exist in NI around domestic abuse and coercive control).\nDesignated Child Protection Officer (DCPO) Role & Responsibilities:\nThe DCPO is a resource to any staff member (paid or voluntary) who has a child protection concern. DCPO’s are responsible for ensuring that reporting procedures are followed correctly and promptly. The DCPO is the person who contacts Gateway or PSNI services when a child protection concern arises.\nThe DCPO’s are required to attend full day (6 hours) in the room DCPO training- each certificate lasts 3 years. It is recommended that they attend a half day (3 hours) DCPO Refresher training once per year to promote best practice and keep up-to-date with any legislative or policy updates.\nThe Designated Child Protection Officer has the responsibility for updating the policies and procedures and for ensuring that staff are aware of them.\nPhotography and video usage on social media\nWritten permission/consent by the person(s) who hold Legal Parental Responsibility of the child/children must be sought before filming or photographing any child or saving or releasing images on social media.\nGDPR (General Data Protection Regulations) Policy is required by the CCUC.\nImplementation Process for Responding and Reporting a concern\nImmediate risk of harm\nIf an employee believes a child or adult to be at immediate risk of harm or abuse, and/or a criminal offence is taking place, they must take immediate steps to protect that person by calling PSNI on 999.\nCall 999 only in an Emergency.\nEmployees must then contact their Designated Child Protection Officer to let them know what has happened, discuss recording procedures and Incident Reporting Sheets and to take advice on next steps, such as debriefing and support for the employee and contacting Gateway Social Services Teams.\nAll employees (paid and voluntary) must be informed of all safeguarding policies and procedures at the start of their employment.\nRefresher and Full Training Requirements: All CCUC employees are recommended to complete the Refresher Child Protection (3 hours in the room) training once per year to achieve best practice.\nAll employees who complete the full day (6 hours in the room) Safeguarding Children Training course -the certificate will last 3 years.\nNo immediate risk of harm\nCCUC Employees/Volunteers must consult with the Designated Child Protection Officer as soon as possible on the same working day of the safeguarding concern. Record and date all information and store in a locked, fire proof safe.\nIf there are concerns that a child is, or has been, at risk of abuse, employees must make a referral on the same working day without delay to the local authority children’s services – Gateway Social Services Team (Tel: 028-9050-7000) in the area where the child is living (or is found). Employees must take guidance from their manager as needed.\nFor safeguarding concerns raised by employees (paid or voluntary), a Designated Child Protection Officer must make the referral to Gateway Social Services –with the employee present. This must be done as soon as possible on the same working day.\nThe Designated Liaison Officer must (subject to issues of confidentiality or other sensitivities) keep employees informed as to the outcome of the referral.\n3 Recording safeguarding concerns\nAs soon as possible, employees must factually record what the child or adult has told them (in the child or adult’s own words) or what the employee has observed. (The Incident Report Forms location should be made known to all paid and voluntary staff)\nEmployees must include the date, time, place and observations of behaviour. Record verbatim (using quote marks) exactly what was said and not your own interpretation.\nIf employees fail to record accurately, or if they write down their interpretation of the child or adult’s account (as opposed to a factual account), this may lead to inadmissible or unusable evidence should the information be required for court processes.\nEmployees must not contact any individual about whom an allegation or concern is being raised. This could be putting the person making the allegations in serious danger, for example, where domestic violence is taking place. It could also prejudice an investigation.\nIf a Designated Child Protection Officer decides that a referral to the local authority children’s services or adults social care is not warranted, this decision must be recorded by the Designated Child Protection Officer as a Recorded case note under the case note type: ‘Decision not to make a referral to social care’ (with evidence to support decision making).Designated Child Protection Officers must be sure to include the reasons why this decision was reached. The advice would be to consult with the Social Services Gateway Team, even if a full referral is not made. Record the full name and details of the social worker that you spoke with.\nWritten Code of Behaviour – The CCUC will have this devised and made available to all staff (paid and voluntary) and the public- electronically.\nAll parents and employees should know where to easily access the Safeguarding Child Protection Polices and confirm that they have read them\nHealth & Safety considerations\n- The building and environment (items to consider may include: stairs, floors, toilets etc). Toilets: do not toilet a child or provide personal care- this is a role for the parents/guardian. Never be alone with a child in the toilets or any area.\n- First aid box – to contain bandages (pay attention to allergies and never administer medication to someone else’s child).\n- Fire alarms- need to be checked to ensure they are in working condition']	['<urn:uuid:0e5075b8-37dd-47b1-84c0-50b07042b572>', '<urn:uuid:2a600597-a766-4ae4-a141-1cc5f06496f6>']	open-ended	with-premise	long-search-query	similar-to-document	comparison	expert	2025-05-13T04:02:16.770989	24	144	3847
87	why coaches prefer let ball in play rather than steal inbound pass run jump defense	Letting the ball in play is preferred because if players miss a steal attempt on the initial pass, they immediately become out of position. This causes all other defensive players to get out of position while helping that player recover. The goal is to make the offense make several decisions rather than giving them easy opportunities from failed steal attempts.	['Our team played a run and jump press defense this past season. In a previous post, I documented the reasons for the switch to run and jump. This week I am going to attempt to write a “curriculum” for my team’s principles in run and jump. There are coaches out there that use different principles, and I think we will evolve in our principles. That said, I like the system we used after playing run and jump for a season.\nThe Core Three Principles\nThese are what I would consider “elementary school” for run and jump. Calling them elementary is not to say that they are easy to master. Errors are inevitable in a system like this that requires many quick decisions. The elementary school label is more to demonstrate that they are the core fundamentals, and without them our run and jump system broke down. When teaching anything, it is a good idea to teach no more than three things at a time. If you have the time, I suggest isolating these principles one by one. Here are the three principles for “elementary school” run and jump:\nLet the Ball in Play\nLet the ball in play is a new concept to our players. In past seasons when we pressured with straight man to man, players attempted to steal the inbounds pass. Hall of Fame Canadian coach Coleen Dufresne teaches players to steal the inbound pass in the run and jump. I am sure other coaches do too. We play it more cautiously. Typically, coaches want to teach players to be aggressive first, and conservative later. In the case of run and jump, I think it is easier to get players to be conservative first. If players miss a steal or deflection on the initial pass, they are instantly out of position. In turn, every other player in the defense gets out of position helping this player recover.\nWe were ok with the offense advancing the ball, but we wanted to make them have to make several decisions in order to do so. The video above illustrates the offense attacking immediately on the catch. Our defender got caught behind and we gave up contain. In the last clip, the defender that gambled is the tenth player to arrive in the half court and eventually a player gets a wide open look. The offensive decisions are easy and the results are usually bad for our defense.\nThe term I stole (not sure where it came from originally) is “decision fatigue.” A huge goal in the run and jump is decision fatigue. In the course of a possession, the more decisions individuals need to make, the more likely they will make a wrong decision. And over the course of a game, the same principle gets magnified. Coaches might tell players in practice to pass through the press. In the heat of a game where they throw it out of bounds, the seed of doubt is planted in the game plan. None of these decisions are difficult if the offense does not have a defender in front of them because the defender swung and missed going for a steal.\nThe video below shows turnovers that share two common traits. First, they take place in the second half. Psychologically speaking, the game shifts a little for players. Second, the role of the defender is simply to contain. We are not encouraging a second defender to jump in the play because the play is not sped up.\nMost of the time players make the right decision on offense. The two teams in the clips above are good teams and their players generally attack our defense well. Each game though we want to try to get a couple possessions where we put forth a minimal effort physically, but mentally we are in the right spots to force mistakes.\nNo Home Run Passes\nThere is an additional benefit to letting the offense complete the inbound pass. We are not susceptible to giving up a home run pass for a lay-up. Many teams try to take the top off a defense with a baseball pass for a lay-up. If a team scores on this type of play, we are not executing. A deep pass that results in a lay-up means that the offense only made one decision. The worst possible outcome for a defense.\nLetting the ball in play implies a hint of laziness. I think this is being a bit harsh. We specifically chose the language “let the ball in” for the purpose of undoing an aggressive habit. The real goal with the first pass as we eventually drilled home was to ensure that the first pass was caught so that the offensive player’s momentum is going toward the inbounder (whom I will refer to as the QB from here on out). If the offense catches a pass while seeing their own basket, the defense is lazy.\nContain the Ball.\nOnce the QB enters the ball, the player covering the ball’s main goal is to contain the ball. Ideally, the on-ball defender forces the player with the ball to change directions. In general, the more dribbles the offensive player takes with a defender pressuring them, the more likely they make an error. By getting beat, the defender is not inducing any decision fatigue on the offense. Containing means that the offense needs to think about every dribble and pass. If the court is open, any player with average skill and court awareness will dribble up stress free.\nIn the video here, the defender contains the ball well. The offensive player is skilled and athletic. This clip came in game number one of the season. Eventually, we want the other four defenders to take a risk and accelerate the point guard’s decision process. We probably were not ready yet for such a tactic.\nThe most important question we need to think about when it comes to containing is personnel. We want the most athletic player on their point guard. Even in matchups where a team’s best scorer is a different player, we still put our best on ball defender on the point guard. If an opportunity to switch in the half-court presents itself, we will do that. If a team has two really good ball handlers, we might have to tell a less athletic defender to match up and give space.\nContaining the ball is not heroic. It might not ever generate a steal in a possession or even create a trap opportunity, but it disrupts how a team runs offense. In Massachusetts, we have a shot clock, so teams contend with a few less seconds to get a shot up.\nFouling Negates Hustle.\nThe final principle of elementary school run and jump is that players cannot foul. This rule goes hand in hand with contain the ball, but deserves its own language. Fouling comes generally in two forms. First, the player containing the ball picks at the low hanging fruit and reaches in. Second, players that are coming to trap might sprint into the player with the ball if they change direction. The same technique of short choppy steps that is taught for a closeout can be applied in the instance of a second defender attacking the ball.\nFouling in run and jump got really ugly one game. Our opponent shot 14 fourth-quarter free throws and made them count on the scoreboard. At the next practice, our team agreed on a new rule. Anytime a player committed a foul in run and jump they were immediately subbed out of the game. We technically defined any foul outside the shell as being a foul in run and jump.\nTheir sin was not unforgivable. By its nature, run and jump requires players to be aggressive, so we quickly sought an opportunity to get the fouling player back in the game. The penalty definitely served as notice for players to be more cognizant of dumb aggression. In one instance, I took out our team’s best defender and she looked like she wanted to kill me. I asked her if we should change the rule pushing forward at the next practice. “No way. It holds us accountable,” she told me.\nHow to Reach without Fouling\nWe discourage reaching, but there are exceptions to the rule. Time and score make reaching a necessity of course. A not so obvious exception is knowing your personnel. Certain players are better at reaching and getting a steal than others. John Fortunato tells players “take, but don’t reach.” In other words if a great defender is making the offense work, the offense will take errant dribbles.\nFormer Duke point guard and author of Stuff Good Players Should Know Dick DeVenzio uses the acronym KUP. Keep up palms. As part of our dynamic warm up, players did foot fire every day and the coaches preached “KUP”. KUP is effective because when players reach with palms down they tend to lose balance and referees love to blow the whistle. When players reach with palms up, they stay in a defensive stance and refs call less fouls.\nNone of these first three principles make mention of a player leaving to double team or switching. These are vital principles of a run and jump defense, but without these three prerequisites everything else will not happen. You can spend a whole season teaching these three principles and still never master them. At the same time, a team will improve on them if you emphasize them early and do not overload new information. After about two weeks of focusing on contain principles, we were ready for teaching the ambiguous decisions of how to play off the ball. And that is what I will attempt to breakdown in the next post on “The Puberty Principles” of run and jump.']	['<urn:uuid:9ee3e2e4-8ee3-4394-acb4-55349552eace>']	factoid	direct	long-search-query	similar-to-document	single-doc	expert	2025-05-13T04:02:16.770989	15	60	1637
88	brain cell creation elderly vs youth numbers	Research has shown that healthy older men and women can generate just as many new brain cells (neurons) as younger people. A study examining 28 brains from individuals aged 14-79 found similar numbers of intermediate neural progenitors and thousands of immature neurons across all ages, though older individuals had less vascularization and potentially reduced ability for these new neurons to form connections.	"['Nice to hear that a new study found that across the lifespan, human brains are capable of producing new neurons (neurogenesis). Neurons are nerve cells, what we popularly call brain cells, and are the basic working unit of the nervous system. The human brain contains about 100 billion neurons.\nThe researchers did find some age differences (e.g. with age there was less neuroplasticity or the brain\'s ability to reorganize itself by forming new neural connections, and a decline in angiogenesis - the development of new blood vessels). But still... the findings are reassuring. Interesting how the researchers did the study. They examined 28 brains (specifically, newly formed neurons and the state of blood vessels within the hippocampus) right after death from previously healthy people (aged 14 to 79), who died suddenly.\nWhile they found age differences, they did not find gender differences. The researchers summarized that healthy older subjects without cognitive impairment (meaning they were mentally healthy), neuropsychiatric disease, or treatment (e.g. depression drugs or psychotropic drugs) display preserved neurogenesis (produce new neurons) throughout life. From Science Daily:\nResearchers show for the first time that healthy older men and women can generate just as many new brain cells as younger people.\nThere has been controversy over whether adult humans grow new neurons, and some research has previously suggested that the adult brain was hard-wired and that adults did not grow new neurons. This study, to appear in the journal Cell Stem Cell on April 5, counters that notion. Lead author Maura Boldrini, associate professor of neurobiology at Columbia University, says the findings may suggest that many senior citizens remain more cognitively and emotionally intact than commonly believed.\n""We found that older people have similar ability to make thousands of hippocampal new neurons from progenitor cells as younger people do,"" Boldrini says. ""We also found equivalent volumes of the hippocampus (a brain structure used for emotion and cognition) across ages. Nevertheless, older individuals had less vascularization and maybe less ability of new neurons to make connections.""\nThe researchers autopsied hippocampi from 28 previously healthy individuals aged 14-79 who had died suddenly. This is the first time researchers looked at newly formed neurons and the state of blood vessels within the entire human hippocampus soon after death. (The researchers had determined that study subjects were not cognitively impaired and had not suffered from depression or taken antidepressants, which Boldrini and colleagues had previously found could impact the production of new brain cells.)\nIn rodents and primates, the ability to generate new hippocampal cells declines with age. Waning production of neurons and an overall shrinking of the dentate gyrus, part of the hippocampus thought to help form new episodic memories, was believed to occur in aging humans as well.\nThe researchers from Columbia University and New York State Psychiatric Institute found that even the oldest brains they studied produced new brain cells. ""We found similar numbers of intermediate neural progenitors and thousands of immature neurons,"" they wrote. Nevertheless, older individuals form fewer new blood vessels within brain structures and possess a smaller pool of progenitor cells -- descendants of stem cells that are more constrained in their capacity to differentiate and self-renew.\nBoldrini surmised that reduced cognitive-emotional resilience in old age may be caused by this smaller pool of neural stem cells, the decline in vascularization, and reduced cell-to-cell connectivity within the hippocampus. ""It is possible that ongoing hippocampal neurogenesis sustains human-specific cognitive function throughout life and that declines may be linked to compromised cognitive-emotional resilience,"" she says.']"	['<urn:uuid:dd4fc920-e7fd-4378-aa31-1832c5cfff21>']	open-ended	with-premise	short-search-query	distant-from-document	single-doc	expert	2025-05-13T04:02:16.770989	7	62	585
89	As an astronomer studying variable stars, I'm curious about the cepheid stars mentioned in Cepheus - what's particularly interesting about their location in this constellation?	In the constellation Cepheus, there is a notable cepheid star located at the top point of the house-like shape of the constellation. Additionally, there is another cepheid just below the constellation, which is a red star that would serve as the North Star if viewed from Mars.	"['The constellation Cepheus.\nClick on image for full size\nWindows to the Universe original image\nCepheus was king of a land called Ethiopia in Greek myth. He had a wife named Cassiopeia and a daughter, Andromeda. Cassiopeia liked to brag about her beauty so much, that she said she and Andromeda were more beautiful than the Nereids. Poseidon got very angry, and sent a sea monster to kill Cepheus and his family.\nAndromeda was offered as a sacrifice, and just when the sea monster was going to eat her, Perseus saved her. All four people, along with the monster, are in the sky as constellations.\nCepheus looks like a house. The point on top is a special star called a cepheid. These stars are used to measure long distances. Just below the constellation is another cepheid. This red star would be the North Star if we lived on Mars.\nThere are several galaxies, star clusters and nebulae within Cepheus. However, most are very dim and can only be seen with a telescope. If you have a telescope to use, browse this old constellation to find many celestial objects.\nShop Windows to the Universe Science Store!\nThe Summer 2010 issue of The Earth Scientist\n, available in our online store\n, includes articles on rivers and snow, classroom planetariums, satellites and oceanography, hands-on astronomy, and global warming.\nYou might also be interested in:\nHow did life evolve on Earth? The answer to this question can help us understand our past and prepare for our future. Although evolution provides credible and reliable answers, polls show that many people turn away from science, seeking other explanations with which they are more comfortable....more\nIn Greek mythology, Andromeda was the daughter of Cassiopeia and Cepheus, the king of Ethiopia. Andromeda\'s mother claimed that they were more beautiful than the sea nymphs, the Nereids. The Nereids felt...more\nThe constellation Cetus represents the Sea Monster. It is one of the largest constellations known. In classical civilizations, the figure was the giant sea monster that almost ate Andromeda. King Cepheus...more\nPerseus was an ancient Greek hero. His mother was Danae, the daughter of Acrisius, the king of Argos. When a prophecy revealed to Acrisius that his grandson would kill him, Acrisius imprisoned his daughter...more\nAndromeda is a ""V"" shaped constellation best viewed in the fall if you live in the Northern Hemisphere. Andromeda lies close to the north pole, so only a few in the Southern Hemisphere can see this strangely...more\nPerseus, the Hero, can be found in the sky during the winter in the Northern Hemisphere. With a little imagination, you can see the image of a man in the stars. He has a sort of triangular body, with...more\nUrsa Major is probably the most famous constellation, with the exception of Orion. Also known as the Great Bear, it has a companion called Ursa Minor, or Little Bear. The body and tail of the bear make...more\nWhat\'s in a Name: Star designated 40 in the constellation Eridanus. Claim to Fame: One of the first white dwarfs found. A white dwarf is the exposed extremely hot core of a star that has blown off its...more']"	['<urn:uuid:1f2b1e05-e0ae-444c-95b7-d1ffef5151e5>']	open-ended	with-premise	verbose-and-natural	similar-to-document	single-doc	expert	2025-05-13T04:02:16.770989	25	47	527
90	What affects chromatography resolution and how can particle shape influence it?	Resolution in chromatography is influenced by three factors: cartridge efficiency (plates/band width), compound retention, and compound selectivity. While particle shape (spherical vs granular) mainly affects backpressure rather than actual chromatographic separation, particle size does impact resolution - halving the particle size doubles theoretical plates but only increases resolution by 41%. The resolution calculation shows efficiency has moderate impact through its square root, while selectivity has the largest direct influence on resolution.	"[""There are many factors which influence successful flash column chromatography. One of those factors is sample load, which itself is influenced by things like selectivity, efficiency, dissolution solvent, and load technique. Several of these factors I have addressed in previous posts. Of these, selectivity and efficiency are specific to a media's physical and chemical characteristics.\nIn this post I will show if particle size and/or particle shape can influence loading capacity. Additionally, I will show the positive impact that surface area has on flash column chromatography purification.\nIn the beginning times of flash chromatography there was only irregular (aka granular) silica and chemists around the world were generally pleased with the results. W. Clark Still, in his seminal paper on flash chromatography (1978), found that 40-63 µm silica with 60Å pores worked best for his purification needs. As flash chromatography became more popular in the labs of organic and medicinal chemists, entrepreneurial companies started commercial production of prefilled glass and disposable polypropylene columns with the same particle size silica.\nOver time, however, the need arose for silica with better separating power and increased loading capacity. To address this need, disposable columns with smaller particles of the same or similar silica became available. This change did increase the separating power and loading capacity compared to the original 40-63 µm (Figures 1 and 2) but at the cost of higher backpressure when operating at the same flow rate and with the same solvents.\nIn the chromatograms above, a “standard” 40-63 µm granular silica-filled 50 gram column and a column packed with 50 grams of a finer “high-performance” granular 15-40 µm silica were used to separate 2 grams of a multi-component mixture. Column dimensions, mobile phase gradient, and flow rates were identical and the 15-40 µm cartridge did provide an improved separation and, therefore, an inferred increase in loading capacity.\nA halving of particle size doubles the number of theoretical plates (e.g. efficiency) but that alone will only increase compound resolution by 41% and it is resolution that dictates loading capacity. A halving of particle size will also increase flow resistance or back pressure ~4 times compared to the larger particle media as shown in Figure 3.\nResolution is influenced by three factors - the cartridge efficiency (plates or band width), compound retention, and compound selectivity (relative spacing between adjacent peaks). Plate count (efficiency), however, has just moderate impact on resolution.\nAs can be seen in the calculation for resolution (Rs) below the influence of efficiency (N) is based on its one fourth of its square root. Selectivity (α), however, is directly proportional to resolution so it has the biggest impact on resolution and therefore on loading capacity.\nRs = ¼*N1/2 *(α-1)*(k/(1+k))\nN = efficiency\nα = selectivity\nk = capacity factor (retention)\nSo, in order to increase loading capacity you need to improve selectivity, which may be possible with a change in elution solvents or stationary phase. If that is not possible then improve separation efficiency by moving to a smaller particle media.\nThere is a way chemists can enjoy the benefits of faster purification (without sacrificing purity); when spherical silica particles are used. Spherical shaped particles pack more uniformly into the columns which can slightly improve peak shape and resolution while generating lower backpressure.\nGranular silica columns often have “pockets” of dead space where there is no silica. These pockets allow solvent and sample components to become trapped and pool which causes bandspreading and reduced resolution (eddy effect). Generally though, the physical shape of the particle influences pressure more than it does the actual chromatography, Figure 4.\nTo help show the performance differences, or lack there of, between granular and spherical silica, two different commercially available 12-gram high-performance flash columns, one with granular silica and the other with spherical silica, were used with the same elution method to separate 200 mg of a 5-component mix, Figure 5. Because the media and columns are from different vendors, compound retention is different but the ability to separate the compounds, especially the last three, has not been influenced by particle shape.\nIt is the silica surface area that impacts load more so than its shape. Figure 6 shows how an increase in surface area impacts sample load and the resulting chromatography.\nIn the data above, the spherical silica (Biotage® KP-Sphere) has a similar particle size (60 µm) as the granular silica (40-63 µm) but because its surface area is 50% greater (750 m2/g vs. 500 m2/g), it is able to accommodate a higher sample load without separation loss or increase in back pressure.\nSmaller particle size silica with higher surface area can further improve resolution and therefore loading capacity, which I have discussed previously. In Figure 7 we see the impact of both reduced particle size and increased surface area on chromatography - sharper peak shape, more complete separation, and increased load capacity.\nSo, the bottom line is changing particle size will alter loading capacity but a switch from granular to spherical will only change back pressure. To obtain the best performance use a high surface area spherical silica and you will maximize load and minimize backpressure.\nHave you evaluated spherical silica columns? Share your experiences with us.\nFor more flash chromatography information, please download our white paper - Successful Flash Purification."", 'Few methods of chemical analysis are truly specific to a particular analyte. It is often found that the analyte of interest must be separated from the myriad of individual compounds that may be present in a sample. As well as providing the analytical scientist with methods of separation, chromatographic techniques can also provide methods of analysis.\nChromatography involves a sample (or sample extract) being dissolved in a mobile phase (which may be a gas, a liquid or a supercritical fluid). The mobile phase is then forced through an immobile, immiscible stationary phase. The phases are chosen such that components of the sample have differing solubilities in each phase. A component which is quite soluble in the stationary phase will take longer to travel through it than a component which is not very soluble in the stationary phase but very soluble in the mobile phase. As a result of these differences in mobilities, sample components will become separated from each other as they travel through the stationary phase.\nTechniques such as H.P.L.C. (High Performance Liquid Chromatography) and G.C. (Gas Chromatography) use columns - narrow tubes packed with stationary phase, through which the mobile phase is forced. The sample is transported through the column by continuous addition of mobile phase. This process is called elution. The average rate at which an analyte moves through the column is determined by the time it spends in the mobile phase.\nThe distribution of analytes between phases can often be described quite simply. An analyte is in equilibrium between the two phases;\nThe equilibrium constant, K, is termed the partition coefficient; defined as the molar concentration of analyte in the stationary phase divided by the molar concentration of the analyte in the mobile phase.\nThe time between sample injection and an analyte peak reaching a detector at the end of the column is termed the retention time (tR ). Each analyte in a sample will have a different retention time. The time taken for the mobile phase to pass through the column is called tM.\nA term called the retention factor, k\', is often used to describe the migration rate of an analyte on a column. You may also find it called the capacity factor. The retention factor for analyte A is defined as;\nt R and tM are easily obtained from a chromatogram. When an analytes retention factor is less than one, elution is so fast that accurate determination of the retention time is very difficult. High retention factors (greater than 20) mean that elution takes a very long time. Ideally, the retention factor for an analyte is between one and five.\nWe define a quantity called the selectivity factor, a , which describes the separation of two species (A and B) on the column;\nWhen calculating the selectivity factor, species A elutes faster than species B. The selectivity factor is always greater than one.\nTo obtain optimal separations, sharp, symmetrical chromatographic peaks must be obtained. This means that band broadening must be limited. It is also beneficial to measure the efficiency of the column.\nThe Theoretical Plate Model of Chromatography\nThe plate model supposes that the chromatographic column is contains a large number of separate layers, called theoretical plates. Separate equilibrations of the sample between the stationary and mobile phase occur in these ""plates"". The analyte moves down the column by transfer of equilibrated mobile phase from one plate to the next.\nIt is important to remember that the plates do not really exist; they are a figment of the imagination that helps us understand the processes at work in the column.They also serve as a way of measuring column efficiency, either by stating the number of theoretical plates in a column, N (the more plates the better), or by stating the plate height; the Height Equivalent to a Theoretical Plate (the smaller the better).\nIf the length of the column is L, then the HETP is\nThe number of theoretical plates that a real column possesses can be found by examining a chromatographic peak after elution;\nwhere w1/2 is the peak width at half-height.\nAs can be seen from this equation, columns behave as if they have different numbers of plates for different solutes in a mixture.\nThe Rate Theory of Chromatography\nA more realistic description of the processes at work inside a column takes account of the time taken for the solute to equilibrate between the stationary and mobile phase (unlike the plate model, which assumes that equilibration is infinitely fast). The resulting band shape of a chromatographic peak is therefore affected by the rate of elution. It is also affected by the different paths available to solute molecules as they travel between particles of stationary phase. If we consider the various mechanisms which contribute to band broadening, we arrive at the Van Deemter equation for plate height;\nwhere u is the average velocity of the mobile phase. A, B, and C are factors which contribute to band broadening.\nA - Eddy diffusion\nThe mobile phase moves through the column which is packed with stationary phase. Solute molecules will take different paths through the stationary phase at random. This will cause broadening of the solute band, because different paths are of different lengths.\nB - Longitudinal diffusion\nThe concentration of analyte is less at the edges of the band than at the center. Analyte diffuses out from the center to the edges. This causes band broadening. If the velocity of the mobile phase is high then the analyte spends less time on the column, which decreases the effects of longitudinal diffusion.\nC - Resistance to mass transfer\nThe analyte takes a certain amount of time to equilibrate between the stationary and mobile phase. If the velocity of the mobile phase is high, and the analyte has a strong affinity for the stationary phase, then the analyte in the mobile phase will move ahead of the analyte in the stationary phase. The band of analyte is broadened. The higher the velocity of mobile phase, the worse the broadening becomes.\nVan Deemter plots\nA plot of plate height vs. average linear velocity of mobile phase.\nSuch plots are of considerable use in determining the optimum mobile phase flow rate.\nAlthough the selectivity factor, a, describes the separation of band centres, it does not take into account peak widths. Another measure of how well species have been separated is provided by measurement of the resolution. The resolution of two species, A and B, is defined as\nBaseline resolution is achieved when R = 1.5\nIt is useful to relate the resolution to the number of plates in the column, the selectivity factor and the retention factors of the two solutes;\nTo obtain high resolution, the three terms must be maximised. An increase in N, the number of theoretical plates, by lengthening the column leads to an increase in retention time and increased band broadening - which may not be desirable. Instead, to increase the number of plates, the height equivalent to a theoretical plate can be reduced by reducing the size of the stationary phase particles.\nIt is often found that by controlling the capacity factor, k\', separations can be greatly improved. This can be achieved by changing the temperature (in Gas Chromatography) or the composition of the mobile phase (in Liquid Chromatography).\nThe selectivity factor, a, can also be manipulated to improve separations. When a is close to unity, optimising k\' and increasing N is not sufficient to give good separation in a reasonable time. In these cases, k\' is optimised first, and then a is increased by one of the following procedures:\nYou should now be familiar with the terms used in chromatography, how species become separated from one another, and how various conditions can be manipulated to obtain well-resolved chromatograms with a minimum elution time.']"	['<urn:uuid:c32cbe84-6d4a-45db-81bd-8b1090bcc251>', '<urn:uuid:3212a1e0-3674-404f-94af-d8686557dc75>']	factoid	with-premise	concise-and-natural	similar-to-document	multi-aspect	expert	2025-05-13T04:02:16.770989	11	71	2181
91	iso 45001 hazard control vs psychological traits impact	ISO 45001 focuses on proactive hazard prevention and risk evaluation, moving beyond A/NZS4801's focus on hazard control. Psychologically, successful implementation depends on four key traits: Control (belief in ability to influence outcomes), Awareness (attention to surroundings), Rules (tendency to follow policies), and Caution (risk aversion level). These psychological factors are crucial as they determine how effectively employees will implement and utilize the standard's requirements.	"['What the New ISO 45001 Standard Means for your Organization\nWhat is ISO 45001?\nThe International Organization for Standardization (ISO) released the new health and safety management system standard, ISO 45001, in March 2018. This is the world’s first international standard dealing with health and safety. Created by occupational health and safety experts, the standard follows a generic management system approach similar to ISO 9001:2015 and ISO 14001:2015. The new global standard has an increased emphasis on management commitment, worker involvement and risk control, which is applicable to all organizational industry types and sizes.\nISO standards are developed by experts and committees to ensure it captures all necessary aspects and that it is fit for purpose. During the five years of developing ISO 45001, ISN participated as part of the Technical Advisory Group and even hosted the ISO Technical Committee at ISN’s HQ office in Dallas.\nFurther information on the requirements of the ISO 45001 standard and any actions organizations need to address to adhere to this standard can be found on the ISO website.\nThe Purpose of the Standard\nOrganizations are responsible for the occupational health and safety (OH&S) of all workers, including part-time and contracting personnel. Visitors who may be affected by a company’s scope of work should also be considered in an organization’s health and safety plan. The ISO 45001 standard includes being responsible for workers’ physical and mental health and promoting best practices throughout the organization.\nThe purpose of an OH&S management system that meets the requirements of ISO 45001 is for organizations to provide safe and healthy workplaces and prevent work-related injury and ill health while continuing to improve health and safety practices. Organizations can minimize or eliminate risks associated with hazards by taking effective preventative and protective measures and implementing ISO 45001 recommendations.\nEach element of the ISO 45001 standard is a reference to the Plan, Do, Check, Act (PDCA) cycle, which those in the health and safety field will most likely be familiar with from other ISO standards. The purpose of implementing this cycle to the standard as a whole and to each element is:\n- Plan: determine and assess OH&S risks and opportunities and establish objectives and processes necessary to deliver results in accordance with the organization’s OH&S policy\n- Do: implement the processes as planned\n- Check: monitor and measure activities and processes with regard to the OH&S policy and objectives and report the results\n- Act: take actions to continually improve OH&S performance to achieve the intended outcomes\nTimeline of ISO 45001 Implementation in Australia\nAustralia is one of the first countries to introduce the ISO 45001 OH&S management system country-wide. Like all new standards, ISO has ensured a generous grace period for organizations that are currently accredited in Australia to A/NZS4801 to migrate to the new ISO 45001 standard by October 2021. The ISO organization is promoting a positive collaboration culture amongst the standards until October 2021 to ensure organizations can promote a safe and positive culture through their management systems.\nISN has proactively created a timeline that offers a grace period to allow ISN Hiring Clients complete understanding of the new management systems and how it amends written program requirements within ISNetworld. During this time period, ISN has hosted Roundtables with Hiring Clients in Australia and the U.S. to ensure Hiring Clients understand the standard, the effects on their contractors and the next stages.\nSimilarities Between A/NZS4801 and ISO 45001\nWhile developing the ISO 45001 standard, the experts and technical committee took into consideration the elements of the A/NZS 4801 standard and the ability for organizations to comply with the new standards. There are a number of similarities between the standards, such as their overall intent to prevent injuries, illnesses and fatalities within the workplace. Other similarities exist, such as the PDCA cycle, policy requirements; identification of legal and other requirements, improvement objectives, awareness requirements, competency requirements, resources needed to support the system and requirements for monitoring, measuring and analyzing OH&S performance and improvement.\n|New ISN ISO 45001|\n|Current ISN A/NZS 4801|\nManagement System Protocols\n|OH&S Policy||Occupational Health & Safety Policy|\n|Risks and Opportunities||Hazard Identification & Risk Assessment|\n|OH&S Objectives||Key Performance Indicators|\n|Leadership & |\n|Leadership & Commitment|\n|Competence||Training & Competency|\n|Awareness and |\n|Document Control||Document Control|\n|Emergency Preparedness & Response||Emergency Preparedness |\n|Incidents & |\n|Audits||Inspections & Audits|\n|Management Review||Review of Mnaagement System|\n|Partly covered in OHS Meetings and|\nleadership & commitment\n|Performance Evaluation||Partly covered in Key Performance|\nDifferences Between A/NZS4801 and ISO 45001\nAlthough the ISO 45001 framework is based upon similar ISO standards, the structure differs from A/NZS4801. The new structure allows organizations to be more proactive in preventing accidents and injuries and evaluating hazard risks, while A/NZS4801 focuses mainly on hazard control.\nISO 45001 also evaluates workers’ involvement and responsibility to allow for broader employee participation within organizations. This looks at employees receiving relevant training and education in order to complete their tasks safely and to help create a successful safety program.\nSome other key differences between A/NZS 4801 and ISO 45001 include:\n- Management Representative (Clause 5.1) has changed from appointing a management representative and replaced by 13 responsibilities that need to be allocated to Senior Management\n- Health & Safety Policy (Clause 5.2) has additional requirements to be included in the policy.\n- Risks have been extended to go beyond hazards (Clause 6.1)\n- Psychosocial hazards (Clause 220.127.116.11) have been added to the standard\n- Documented information (Clause 7.5) changed to allow organizations to determine what documented information will be retained to demonstrate compliance (unless there is a legal requirement to retain certain documentation)\n- Procurement (Clause 8.1.4) requirements added as part of the overall standard\n- Evaluation of compliance (Clause 9.1.2) requires organizations to evaluate their compliance with legal and other requirements and retain documented information of the evaluation results.\nGet Support Complying with ISO 45001\nIf you are a Hiring Client interested to learn how the new ISO 45001 standard will impact you and your contractors’ use of ISNetworld, contact your ISN representative for more information.\nAre you a Hiring Client and interested to learn how ISN could help you manage your contractors and adhere to ISO 45001 standards? Request a demo of our contractor management system, ISNetworld.\nIf you are a contractor and need support submitting the new standards within ISNetworld, contact our customer support team for additional resources.', 'If you’re in charge of OHS at your workplace, you’ve probably considered whether the new ISO 45001 standard makes sense for your company. You’ve likely read about it or heard people in the industry discussing it. Or you may be wondering whether your company is ready for the requirements and the process involved. There are several factors which can impact the implementation and eventual success of any ISO standard within an organization, such as its size, nature of operations, current OHS policies, or available resources. However, one factor you will not typically hear about is arguably the most important – the people who make up the organization.\nWe sometimes forget that it’s ultimately the people who really run an organization and determine its success. Let’s face it – while processes and standards are very useful, they will only be as good as the people who implement and utilize them. In last week’s post I wrote about the ways in which assessing for people’s psychological safety traits and using this data to develop safer behaviors can be a valuable and proactive part of an organization’s ISO 45001 implementation strategy.\nSo, what sorts of psychological traits should we measure as part of that strategy? Which ones would have the most impact on safety? Based on decades of research in the field of Industrial & Organizational Psychology, the four traits below make up a person’s unique SafetyDNA. Each can play an important part in a successful ISO 45001 roll out.\nControl is the extent to which you believe that you can control future outcomes through your present actions. Some individuals feel that they decide their own fate, while others are more fatalistic and believe that things happen based on luck and circumstance. As I noted last week, one of the most important goals of the new ISO standard is to help make safety a shared responsibility across all parts of the business instead of putting the burden solely on OHS staff. Implementing ISO 45001 at your company will be much easier for employees who are naturally high on the Control trait already. They will already tend to see safety as something that is within their control. These individuals are the ones who tend to take personal ownership for safety and often do things to improve safety without being told. Those who are lower in control may struggle to see how they can personally mitigate risks within their workplace and are less likely to get involved in your ISO 45001 implementation.\nHow Can I Help Those Low on Control?\nThe key with these individuals will be to help them believe that they do play an important role and that they have the ability and authority to bring up safety concerns, stop unsafe work, and make safety suggestions. By reminding these individuals that they have many opportunities to impact safety every day and showing them that their opinion matters, individuals can learn to exhibit more control over their personal safety. It can also be helpful to give them feedback when you hear them blaming others, or saying things such as “There’s nothing I can do” or “How was I supposed to know?”\nThe Awareness factor deals with how much people see and remember in their immediate surroundings, especially when doing multiple tasks. People who are high on awareness simply see and remember more information than others, are less distracted, and tend to have better working memory.\nISO 45001 is predicated largely on assessing potential risks rather than just mitigating hazards. This means that your employees have to start seeing things a little bit differently. To properly implement the new standard, people must go beyond the usual known hazards that they’ve been identifying for years and start looking below the surface at their everyday environment in more detail. Attention to detail and vigilance are critical for this, as employees must look for things that they are not necessarily on the usual hazard checklist. Some will find it harder to do this because their natural, resting state of awareness is lower, especially when they are busy working on multiple tasks. These folks will only notice the same old things they always noticed before – unless they get some help.\nHow Can I Help Those Low on Awareness?\nWhile you can’t really raise a person’s innate awareness levels, you can coach them on the types of things to look for and how to identify potential risks. Invite them to walk through the work site with you and ask them to point out any hazards or risks to you. Show them potential risks that you see and coach them on WHY those situations have inherent risk. Another helpful suggestion is to have an employee who is low on Awareness partner up on work assignments and ask their co-worker to provide a “second set of eyes” in case they missed a critical detail. Many an injury has been avoided by a helpful and attentive co-worker who spotted an issue or mistake before it was too late!\nThe Rules factor is essentially the degree to which you follow rules versus bend them – especially the ones you don’t like. Rule-bound individuals see rules in a very strict and narrow fashion, and will sometimes even create a rule where none exists because they like the structure and predictability of rules. They like to know there’s a “right” way to do something. Those who are low on Rules, however, tend to see rules in a very flexible manner. They see rules as mere general guidelines that can be ignored depending on the overall situation.\nWhile the new ISO standard tends to emphasize risk assessment rather than providing various recommended policies, it’s safe to say that a good ISO 45001 process will likely lead your company to implement some critical new safety policies for high exposure activities, or at least provide clearer reinforcement of these policies. These are often referred to as ""Life Saving Rules"" or ""Cardinal Rules"" of safety, and those should be part of any good safety management system. However, a Life Saving Rule is only effective when people follow it consistently. So as your ISO implementation takes place, it’s important to remember that some employees will find it easy to follow the safety rules and others will be voicing their opinion and asking endless questions about why they have to follow these rules.\nHow Can I Help Those Low on Rules?\nUsually, these folks are not trying to be obstinate or put themselves in danger. They usually have a good rationale in their mind for why a rule doesn’t make sense or why it is preventing them from doing a good job. As a result, they tend to question why certain rules are in place, and they are often satisfied by simply knowing the logic behind a safety policy. Therefore, you will find that in many cases if you simply take the time to talk with them, answer their concerns, and provide honest, logical reasons for why safety rules are in place, it will help them to see things differently and abide by the rule. Whenever possible, you should show any data or evidence (e.g., past injuries or near hit events) that support the safety policy which they are questioning. This will help them see that you are not trying to make their job harder by having rules “just for the sake of rules” but rather, because you want to make sure they go home safely every day to their family.\nLastly, the Caution factor deals with the level of discomfort you feel with risk-taking. Those who are higher on Caution are naturally risk-averse and tend to really think things through before they take action. Conversely, those who are low on Caution are naturally more comfortable with risk, tend to be impulsive, and don’t consider all the potential consequences of their actions. This factor becomes essential in the new ISO 45001 framework, which is all about assessing risk. While we have good methods in place to quantitatively measure risk in the workplace, ultimately, there is always a human who is responsible for assessing the situation and assigning a risk level based on likelihood, severity, and other factors. An employee who is inherently lower on Caution will naturally perceive less risk and think of fewer preventive actions when they complete a job hazard analysis (JHA) compared to a person who is higher on Control.\nHow Can I Help Those Low on Caution?\nIn my experience coaching and working with thousands of employees and leaders over the years, it can be very helpful to these individuals if you first help them be aware of their higher risk propensity relative to the general population. This holds for all of the factors I’ve listed here, but it is especially true for Caution. Once they have this valuable self-insight, it can be very helpful to identify a list of most frequent exposures based on their usual work activities and identifying one or two simple actions they can take in those specific instances to reduce their risk. Ultimately, the goal is to help low Caution employees – before starting any work with potential risks – develop a habit of asking themselves, “What could go wrong here?”\nBy understanding these important safety traits and helping your people see how their own SafetyDNA influences their behavior, your organization can further support an ISO 45001-based safety management system that results in a safer workplace for the long haul.']"	['<urn:uuid:f69128e9-bce4-4874-9670-b9fef820c3ba>', '<urn:uuid:e255ad64-4c8b-489a-a7dc-60ed591c0aea>']	factoid	with-premise	short-search-query	similar-to-document	multi-aspect	expert	2025-05-13T04:02:16.770989	8	64	2638
92	I'm researching seasonal respiratory infections, and I'd like to know about the transmission patterns of RSV, its typical manifestations, and available preventive medical interventions for vulnerable populations. Can you provide comprehensive information about these aspects?	RSV is more prevalent in winter and spring months, spreading through droplets from coughs and sneezes, either directly person-to-person or via contaminated items like doorknobs or toys. The symptoms resemble a bad cold, including runny nose, poor feeding, low energy, and breathing difficulties. In severe cases, it can cause bronchiolitis and pneumonia, particularly in babies under 1 year. For prevention, especially in high-risk cases, palivizumab can be administered monthly during RSV season for up to 5 months. This preventive treatment doesn't interfere with regular immunizations. Additional preventive measures include avoiding close contact with sick individuals, not sharing contaminated items, frequent hand washing, and avoiding face touching. While some infants experience mild symptoms, others, particularly those with lung disease or premature babies, may face life-threatening complications.	"[""How to spot and treat RSV in babies\n- babies younger than 6 months\n- babies born prematurely\n- babies who have a disease of the lungs or immune system\nRSV is a virus that is present in droplets from a person's coughs and sneezes. These germs can spread directly from person to person, or when someone comes into contact with a contaminated item, like a doorknob or toy.\nIt is more prevalent in the winter and spring months than at other times of the year.\nIn this article, we examine RSV in babies, including the symptoms they may experience and what caregivers can do to help treat them. We also take a look at when to see a doctor and how to prevent the virus from spreading.\nA fever is one potential symptom of RSV.\nThe symptoms of RSV are similar to a bad cold and can include:\n- a runny nose\n- poor feeding or sleeping\n- low energy\n- difficulty breathing\n- the chest wall pulling in with breathing\n- fast breathing\n- stopping breathing\nRSV is also the most common cause of bronchiolitis and pneumonia in babies younger than 1 year. These conditions cause swelling in the lungs, which can lead to the airways filling up with mucus. This combination of mucus and swelling can make breathing difficult.\nEvery infant experiences RSV a little differently. Some have very mild symptoms while others can have life-threatening issues.\nRSV is a virus, and there are few specific treatments to help cure it.\nAntibiotics do not work on viruses, and there is no vaccine to prevent the disease. Instead, RSV treatment generally aims to manage the symptoms and prevent complications.\nMost cases of RSV in babies go away without treatment after 1 to 2 weeks. Sometimes, caregivers can treat babies at home until the virus passes.\nRegular fluid intake can prevent dehydration in babies with RSV.\nSome simple home remedies can help, including:\n- Encouraging fluid intake. If the baby is over 6 months old, try giving them extra water. Encourage breastfed babies to feed as much as possible as this can prevent dehydration and the need for more aggressive hydration.\n- Over-the-counter medication. Acetaminophen can treat discomfort and lower a fever. It is essential to talk to a doctor before giving a baby acetaminophen if they have never had it before or are under 3 months old.\n- Clearing mucus from the airways. Removing excess mucus from a baby's mouth or nose using a bulb syringe can make it easier for the baby to breathe and eat.\n- Sitting in a steamy bathroom. Turn a hot shower on in a closed bathroom and let it fill with steam. Steam can help to reduce inflammation in the airways, thin mucus, and make it easier to breathe.\nAlways speak to a doctor before giving cold or cough medications to children and babies. Some medicines contain substances that are not suitable for children under 6 years old. People should avoid giving most cold and cough medicines to infants under 2 years old.\nMedication and other treatments\nIf a baby experiences severe symptoms of RSV, treatment options that can provide relief include:\nIf a baby is having difficulty breathing, their blood oxygen level will drop, which can be very dangerous if not treated.\nWhen a baby is struggling to breathe, they will need to use a lot more energy. Eventually, the baby can go into respiratory failure and stop breathing, which is an emergency situation.\nGiving extra oxygen can increase blood oxygen levels and reduce the effort needed to breathe.\nBabies that struggle with breathing may not have the energy to eat or find it difficult to drink enough fluids. Very young babies, especially sick ones, can become dehydrated very quickly.\nIf the baby is not drinking enough, they may need intravenous hydration or a feeding tube to help them stay hydrated.\nIn some situations, doctors can give medications to open the baby's airways to help them breathe.\nVery sick or high-risk babies may need antiviral medications to help the immune system attack or clear the virus from their system.\nWhen to see a doctor\nIt is essential to call the doctor immediately or seek emergency care if the baby is showing any signs of breathing difficulty, such as:\n- rapid breathing\n- the chest wall pulling in when breathing\n- a blue tinge around the lips or fingernails\nOther reasons to see a doctor include if the baby:\n- is not eating or drinking enough\n- is becoming weak or not as active as usual\n- has cold symptoms that are severe or getting worse instead of better\n- has a cough that is not going away\nWashing hands regularly can help prevent the transmission of RSV.\nRSV is highly contagious, meaning that it spreads between people very easily.\nSome straightforward measures can help people avoid contracting the disease or spreading it to others. A few of these measures include:\n- Avoiding close contact with anyone who may be sick. Contact includes kissing, hugging, and shaking hands.\n- Avoiding sharing contaminated items with other people. Cups, bottles, and toys are all potential carriers of the virus, which can survive on them for hours.\n- Frequently washing hands.\n- Avoiding touching the face, eyes, mouth, or nose.\nIn most cases, RSV causes a mild, cold-like illness in babies or young children who will experience a full recovery.\nHowever, RSV can cause life-threatening complications in some babies, particularly those at risk for respiratory disease or premature infants.\nCaregivers who suspect their children may have RSV should watch them closely for breathing difficulties and dehydration and speak to their doctor if they have any concerns."", ""Monoclonal Antibodies to Prevent Respiratory Syncytial Virus (RSV) Infection\nHow It Works\nPalivizumab stops respiratory syncytial virus (RSV) from reproducing. This medicine contains antibodies that are made in a lab.\nWhy It Is Used\nPalivizumab is used to prevent RSV infection. It is mainly used for children who have a high risk of developing complications, such as those who have chronic lung disease or heart problems. If your baby was born early or has health problems, talk to your doctor about the need to prevent RSV.\nIf palivizumab does not prevent a child from becoming infected with RSV, it may make the illness less severe. This reduces the child's chance of having complications, such as bronchiolitis or pneumonia.\nHow Well It Works\nUsing palivizumab monthly during the RSV season lowers the chance of needing to go to the hospital (for RSV-related illnesses) by almost half, and it shortens the length of stay in the hospital by more than half.1\nPalivizumab does not decrease how often children get other illnesses, such as ear infections.\nAll medicines have side effects. But many people don't feel the side effects, or they are able to deal with them. Ask your pharmacist about the side effects of each medicine your child takes. Side effects are also listed in the information that comes with the medicine.\nHere are some important things to think about:\nCall your doctor right away if your child has:\nSide effects of this medicine include:\nPalivizumab may cause pain at the site where the medicine was given.\nSee Drug Reference for a full list of side effects. (Drug Reference is not available in all systems.)\nWhat To Think About\nPalivizumab is given as an injection, and it is given at a doctor's office. During the RSV season (late fall to early spring), this shot is given once a month for up to 5 months. The number of doses depends on your child's risk factors.\nYour child may need to take this medicine for most of the RSV season, whether he or she gets RSV infection or not. Different strains of RSV can be present in a community during the same year, so treatment may still offer protection from infection.\nPalivizumab does not interfere with the regular immunization schedule.\nMedicine is one of the many tools your doctor has to treat a health problem. If your child takes medicine as your doctor suggests, it will improve your child's health and may prevent future problems. If your child doesn't take the medicines properly, his or her health (and perhaps life) may be at risk.\nThere are many reasons why people have trouble taking their medicine. But in most cases, there is something you can do. For suggestions on how to work around common problems, see the topic Taking Medicines as Prescribed.\nFollow-up care is a key part of your child's treatment and safety. Be sure to make and go to all appointments, and call your doctor if your child is having problems. It's also a good idea to know your child's test results and keep a list of the medicines your child takes.\neMedicineHealth Medical Reference from Healthwise\nTo learn more visit Healthwise.org\n© 1995-2014 Healthwise, Incorporated. Healthwise, Healthwise for every health decision, and the Healthwise logo are trademarks of Healthwise, Incorporated.""]"	['<urn:uuid:fab643bc-4c3d-4d4a-b393-c2ac2faa1ddc>', '<urn:uuid:a38df0e2-0575-4224-866c-8ac62d528ff1>']	open-ended	with-premise	verbose-and-natural	distant-from-document	three-doc	expert	2025-05-13T04:02:16.770989	35	125	1499
93	difference accuracy belt drive vs screw drive positioning systems linear motion	Screw-driven systems provide higher positioning accuracy compared to belt drives. Ball or lead-screw drives offer superior precision, while belt drives have lower accuracy due to backlash and tooth-to-tooth variations. However, this precision advantage of screw drives is limited to shorter stroke lengths (around two meters maximum) due to practical limitations, while belt drives can maintain consistent performance across longer strokes.	['Modern electromechanical machine design\nJune 2018, System Integration & Control Systems Design\nEngineers from the older generation will remember the days when machine design had to be based around catalogued electromechanical actuators. Variations from standard were rare, in addition to being expensive. Fast forward around 40 years and the modern experience is somewhat different. Today’s machine designers not only desire highly configurable and adaptable products, they expect them.\nWith this in mind, many leading motion technology suppliers have developed their product portfolio specifically for machine designers. Explained below are some key factors that will aid the selection of electromechanical motion products for use in the machines of today.\nAmong the fundamental questions to ask is: Does the actuator offer various stroke lengths as standard? A product using a ball or lead-screw drive is commonly restricted to stroke lengths up to around two metres maximum for practicality. There are some actuators offering strokes to four metres, however at lengths such as these, speed is often limited due to screw ‘whip,’ so the product that achieves a particular speed at one stroke will not usually achieve that speed at a longer stroke length.\nVery long stroke lengths can, however, be achieved by belt drives, which perform to a similar level regardless of stroke length, but lack the precision of a screw-driven product.\nA further option is linear motor-driven products, which provide performance levels that scale extremely well with increases in stroke. In addition, linear motors do not demonstrate speed restrictions at longer strokes and offer the same repeatability over the full stroke.\nWith regard to scalability, machine builders should determine if the actuator is available in a number of different frame sizes or widths. Having a family of products to select from allows the project to be cost-optimised. Moreover, many multi-axis applications demand different loading for each axis.\nHaving multiple drive train choices in the same product is often overlooked, but the availability of screw or belt options within a given product can prove extremely useful to a machine designer. In the same form factor, designers can tailor the drive train to specific requirements, be it thrust density normally obtainable from a screw-type drive, or speed from a belt drive. The ability to bounce between the two without having to rethink the machine’s layout can be highly beneficial.\nModularity and performance\nIt is a common requirement for electromechanical actuators to be connected to other actuators or mechanical devices. The ability to combine linear actuators into XY, XZ, or XYZ assemblies quickly and effortlessly is vital. As a result, most modern electromechanical products can be bolted together like building blocks, without the use of transition plates for XY systems (plates are often unavoidable for the Z or vertical axes to maintain stability).\nA further factor here is performance-to-size ratios, which should be considered carefully. Using a product that is highly condensed leaves more space for machine designers to include end effectors and tooling. For this reason, metrics such as thrust or rated load per height-by-width become important.\nSelectable resolutions and encoder types\nTo retain good servo control, an actuator should have 5-10 times more resolution available than the repeatability of motion required. With this in mind, having multiple options is the optimum solution as high-resolution encoders can be quite costly.\nBeing able to adjust the resolution is also important. Some of the latest encoder products can vary their resolution through a relatively simple hardware change. A further approach is to deploy analog feedback devices and compatible servo drives. In using analog feedback signatures (typically 1 V peak-to-peak), two analog signals are passed from the encoder to the drive, 90° out of phase with one another. Equivalent resolution is established within the drive, and is dependent upon the pitch of the linear scale and resolution of the drive’s analog input.\nAs well as flexible resolution, the availability of flexible encoder technologies is another major benefit. Optical encoders with glass scales have been a popular choice for many years, but today there are many alternative technologies that provide competitive resolutions and costs.\nFor example, in applications that do not require especially high levels of precision, magnetic encoder technology is a cost-effective option, while applications that do require high precision but not long stroke lengths benefit from the very high resolutions of capacitive encoders. Inductive encoders are often popular for applications directly exposed to heavy contamination, such as coolant from a machine tool. Applications which require constant positional information regardless of an axis being homed will require an absolute feedback source.\nWith regard to communications, until recently, most encoder protocols were based on embedded propriety signals, which meant that designers had to use a limited list of manufacturers. Today, open standard protocols such as the single cable Hiperface DSL solution allow design engineers to use a variety of products and even reduce installation and cabling efforts.\nIn cutting-edge design software, finite element analysis (FEA) can be used to understand not only the deflection characteristics, but also the thermal or magnetic variations within the product. Naturally, these simulations cannot give results with 100% certainty as they are only as good as the algorithms and assumptions that are used, but modern machine design is starting to leverage these digital design methodologies more heavily to expedite development.\nMetrology test data\nTest data from metrology can be used to take ball-screw backlash into account, and improve overall system accuracy. For applications with very specific requirements, these tests can be performed to mirror the actual application characteristics. Cleanroom applications are a good example as there are many characteristics, such as speed, acceleration, orientation and air flow, which can greatly impact product performance. Selecting products from a design partner that understands the mission-critical aspects of the application and tests will prove particularly advantageous.\nToday, the demand for faster turnaround time on machines has become critical. The same design engineer who might have allowed for a machine to be developed in several months, now expects it in weeks. Key to the machine-building race is selecting the right product from a manufacturer which understands the daily design hurdles and has systems in place that allow for rapid machine development.\nFactors such as breadth of product, range of options, modularity and product test data should be taken into account when designing the machines of today. This strategy will enhance the machine builder’s ability to respond to customer needs, and provide faster ROI.\nFor more information contact Lisa de Beer, Parker Hannifin SA, +27 (0)11 961 0700, firstname.lastname@example.org, www.parker.com/za', 'Old machines need not be scrapped. They can be given new life with modern servosystems to meet increasing demands for higher accuracy and throughput.\nEmerson Electric Co.\nMany machines are too expensive to replace entirely when they can’t meet increasingly stringent production goals. Rather than trash outdated equipment, it’s often possible to trade in the old embedded motion controls for new servosystems. However, an upgrade is not always easy. Getting deeper into a machine analysis may uncover problems disguised as hapless bandages.\nFor instance, belts and pulleys of various diameters may have been added to increase speed and change torque for manufacturing new products. Unfortunately, this type of change also increases load inertia, which may be acceptable or not. Also, a clutch and brake may have been added when another technique might have served better. These changes were originally perceived as improvements and added periodically during the machine’s life. But, in the face of a retrofit, all such fixes need reevaluating to determine why they were installed so they can become an integral part of the new design — if still needed.\nLoad, Distance, and TimeThe first step in a redesign considers the machine’s main function, which is usually to move an object or a load a specified distance in a certain a\nmount of time. The load, distance, and time are the three primary design factors. All others stem from them.\nAfter defining the load in terms of weight and size, consider the distance the load moves next. Analyze the longest distance first, since it establishes the machine’s throughput, making it the most difficult path to work with. For example, loads composed of 10-ft tubes require longer actuators to move and position for machining than do 10-in. tubes. In the case of ballscrew actuators, speeds and tolerances are more difficult to control. Also check the shorter paths for throughput, especially if machine timing changes when product size changes.\nThe distance a load moves is usually linked to machine output cycle time and the load’s position, so the time for that move can be quickly determined. However, look for redesign requirements that the basic machine might not be able to deliver, such as moves that can’t be made in an allotted period without unusually expensive modifications. Likewise, when the move can be made in the specified time, check acceleration forces, because those that exceed 1 g could destroy the product the machine makes.\nAfter calculating distance and timing, select an actuator. For linear motion less than 25 ips, a ball-screw system fits particularly well. Screws produce high mechanical efficiency and accuracy because their motors turn more times per inch than in other systems. But screws have a practical rotational speed limit which comes from vibration generated by a combination of unsupported length and the diameter of the screw. All ball-screw manufacturers offer sizing specifications for long operating life.\nScrew vibration usually becomes a problem when linear speeds exceed 25 ips. Belt and pulley drives provide an alternative. They come in 40-ft lengths and can move objects up to 200 ips. Their downside comes from backlash in tooth-totooth variations that affect accuracy. In addition, belt and pulley drives do not have the built-in mechanical advantage of screw systems. Screw actuators typically run at higher shaft-to-load speed ratios than belt and pulley systems.\nHowever, because a driven pulley speed is likely to be slower than the servomotor driving it, a speed reducer can lower the needed motor torque. The speed reducer also diminishes the load inertia reflected back to the motor by the square of the reduction, while raising the driving speed by a multiple of the reduction.\nSpeed reducers provide another advantage: Servomotor speed can now be in a range where it is most efficient, typically between 1,500 and 2,500 rpm. Servomotors can run at speeds above 3,000 rpm, but only when the system operates from full-rated input voltage and current. For example, when only 208 Vac is available for a system rated at 230 Vac, the motor may not reach full-rated speed. A conservative design, however, lets the motor normally run below maximum rated speeds. This means production won’t suffer when the line voltage is low.\nPosition accuracy is the final consideration. Many factors influence system accuracy, but a design engineer must be clear about the machine’s expectations. Users tend to overspecify systems requirements for the upgrade, hoping to have power in reserve for further increases in throughput.\nOne user, for instance, requested a servosystem vendor design an applicator machine that would deposit a drop of glue in the middle of a 0.25-in. paper tab moving at 600 ft/min. The user wanted position accuracy of ±0.00010 in., a wish the designer’s best controller couldn’t meet. When the servosystem designer informed the user that ±0.004 in. was possible, the user replied that would be good enough. The user offhandedly thought that ±0.00010 in. would be a good place to start.\nServosystems are controlled by microprocessors and other hardware components with a finite capability. Limits should be considered in the original specifications. If someone had provided this demanding customer with a system that could reach the accuracy at the speeds specified, it would have been more expensive, extremely difficult to install, and almost impossible to maintain and operate.\nAnother manufacturer provides a more realistic example of expectations. It ordered a new servosystem to replace an older one as a first step in modernizing a production machine.\nThe working mechanism consisted of two arms linked together which oscillated over a 90° sweep angle. The arms were driven by a set of elliptical gears coupled to an ac motor. The elliptical gears provided a sine-wave motion to the arms which was necessary to produce linear motion at the tips of the arms. The tips moved a sheet of paper over a straight-line path.\nOne goal was to eliminate the elliptical gears, so the new servosystem had to be programmed to duplicate the sinewave motion. This would also allow the manufacturer to make quick adjustments for different product lengths.\nAnalysis of the process led the servosystem supplier to an alternative approach based on the fundamental objective — to move the paper in a straight line. The replacement actuator relies on a packaged belt and pulley drive available from a number of suppliers. This approach removes a large inertial mass from the motor load, and a fairly complex servoprogramming task from the operating system. The belt and pulley actuator and servosystem can be programmed to move in inches or millimeters, with the servosystem responsible for all math conversion.']	['<urn:uuid:051c65cb-7925-4237-8f5c-bc7aa61c5e01>', '<urn:uuid:2a47e0cd-2d00-46b1-b7e5-42e6a91507be>']	factoid	with-premise	long-search-query	similar-to-document	comparison	novice	2025-05-13T04:02:16.770989	11	60	2175
94	first manufactured synthetic blue pigment history and modern applications	Egyptian Blue was the first true synthetic pigment, made before 3000 BCE by heating together powdered limestone, malachite, and quartz sand to form calcium copper silicate. Though its manufacturing process was lost after the Roman Empire, it has found new applications in modern times due to its photoluminescence properties, being used in biomedical analysis, telecommunications, and security and crime detection.	['Over the last millennium or so, Art and Science have developed to mutual benefit. Whether it’s a synthetic pigment like Prussian Blue, colour theory, or modern oil and acrylic paints, there’s a great deal that painting has benefitted from chemistry, physics and physiology. In return, paintings of scientists at work have set their stories in our cultural history. This new series looks at these exchanges through time.\nAlthough sciences such as chemistry and physiology developed much later, scientific and mathematical exploration of the world around us goes right back to the earliest civilisations.\nOne of the first great milestones in the development of modern painting, the discovery of linear perspective projection, is attributed to the Florentine architect Filippo Brunelleschi (1377-1446) in about 1420, although it may have been as early as 1414. Antonio Manetti, his biographer, wrote an account in which Brunelleschi constructed two paintings of churches in Florence according to geometrical optical principles, and made an arrangement using a small hole and a mirror so that a viewer could compare the 2D painted view with the observed view at the correct locations. Those who tried this out were apparently amazed at the similarities between the 2D and observed views.\nThe first substantial painting to have survived which employed Brunelleschi’s system is Masaccio’s magnificent Holy Trinity, painted in 1426-28 in the Basilica of Santa Maria Novella in Florence. It relies completely on that development of optics and geometry.\nPaintings rely not on dyes, which are relatively simple colourants which are too vulnerable and fugitive to survive the passage of time, but on particles of colourant, pigments. For a long period, painting was reliant on natural pigments, some of which, like the carbon blacks, remain in common use today. The first true synthetic pigment was in fact so ancient that it was forgotten completely in the Middle Ages: Egyptian Blue was first made before about 3000 BCE by heating together powdered limestone, malachite, and quartz sand, to form calcium copper silicate. But that was an exception. It wasn’t until the early years of the eighteenth century that a hydrated iron hexacyanoferrate complex known quickly as Prussian Blue was synthesized.\nNo one knows who first made Prussian Blue, nor exactly when they made it. It seems to have appeared initially around 1704, and its origins have been attributed variously to Diesbach in Berlin, or Mak in Leipzig. For once its name is appropriate, as it was a product of the Prussian Empire. Its potential as a colourant was recognised by 1710 when it went on sale in Berlin, and by about 1724 it was being manufactured in several countries across Europe.\nAmong the very first surviving oil paintings to use Prussian Blue is that by Adriaen van der Werff and Henrik van Limborch, of Jacob Blessing the Sons of Joseph. This was started by van der Werff before he died in 1722, and the blue paint is thought to have been applied by him to the curtain at the upper left; it is that paint which has been shown to contain Prussian Blue. After van der Werff’s death, his pupil Henrik van Limborch finished the work between 1727-28.\nDuring the eighteenth century, European civilisations underwent an Enlightenment in which reason became valued, and with it came a revolution in science and the arts. For the first time, painters made a theme of scientific experiments.\nJoseph Wright of Derby painted An Experiment on a Bird in the Air Pump in 1768, which epitomises this culture of enlightenment. Here the ‘philosopher’ (in a red gown) is seen at the climax of his lecture on pneumatics, inspired by the radical chemist Joseph Priestley (1733-1804). A precious white cockatoo has been taken from its cage, at the left of the table, and placed inside the large glass jar at the top. A vacuum pump has then been used to evacuate the air from within the jar, and the cockatoo has collapsed near death.\nWright shows the moment the philosopher is about to open the tap at the top of the jar and restore the air to the bird, hopefully resulting in its revivification, and transformation of the anguish and horror being expressed by the two girls at the table.\nUltramarine Blue is another of the oldest pigments still used in painting, and its history could fill a book. Over a similar period, artists also used Smalt, made from powdered blue-coloured glass, in which the active pigment is cobalt oxide. Thénard discovered cobalt aluminate in 1803-04, and recognised its potential as a pigment. As this preceded the introduction of artificial Ultramarine, Cobalt Blue was quickly introduced into artists’ paints, becoming available in oil paints and watercolours from around 1806-08.\nPossibly the earliest recorded use of Cobalt Blue is in the sky of JMW Turner’s oil sketch of Goring Mill and Church, thought to have been painted in 1806-07. This shows how similarly Turner started his oil and watercolour paintings. Once brought to this state, Turner could return to the sketch later and add foreground detail before completing it.\nBy the nineteenth century, alchemy had been replaced by the new science of chemistry, with a sound theoretical and experimental basis. Science and technology were also introduced into traditional crafts such as dyeing and tapestry manufacture, where they helped develop theories of colour.\nIn about 1867, the artist Charles Blanc (1813-1882) used this colour star in his educational books for artists. It differs little from the much older colour line of Aguilonius, but the chemist Michel-Eugène Chevreul (1786-1889) advanced a more sophisticated colour hemisphere. Chevreul was the director of the dyeing department of the royal tapestry manufacturer of Gobelins, who daily wrestled with problems trying to achieve consistent dyeing of textiles for use in tapestry-making. Chevreul was an important influence on the Impressionists and their use of colour.\nThe ‘softer’ human sciences trying to rationalise the functions of the body were slower to adopt the rigour of the physical sciences. The late nineteenth century saw major influence of the German physicist and physiologist Hermann Ludwig Ferdinand von Helmholtz (1821-1894). Von Helmholtz awakened interest in the psycho- and neuro-physiology of colour, and the importance of perception as well as physics, although it was one of von Helmholtz’s scientific adversaries, Ewald Hering (1834-1918), who brought the most important and immediate improvements in colour ordering, by applying principles of colour perception.\nThe strange silver-white metal cadmium wasn’t discovered until 1817, and then only by a chance observation of abnormal yellow colouration of a sample of what should have been zinc carbonate. The brilliant yellow colour of its salt cadmium sulphide was noticed the following year, but it wasn’t exploited as a pigment until the 1840s, when it became possible to manufacture in quantity.\nNevertheless, it has been claimed that it was used as a pigment for oil paints as early as 1829, and by 1851 it was shown by Winsor & Newton at the Great Exhibition at Crystal Palace in London. But it remained extremely costly.\nFew artists could afford to use Cadmium Yellow until its price fell late in the nineteenth century. Claude Monet was among its early users, in this painting of The Artist’s House at Argenteuil from 1873. Before this, William Holman Hunt and others had reported that its colour was “capricious”, sometimes fading rapidly to “the colour of dirty beeswax”. With the alternative of Chrome Yellow more readily available and much cheaper, most artists steered well clear of the new pigment until the twentieth century.\nNineteenth century painters were more strongly motivated to paint scientists and science in action. Although not a theme in Impressionism, many Naturalists were keen to depict scientific subjects.\nClaude Bernard (1813-1878) was a pioneering physiologist whose writings were of great influence to Naturalists, including Émile Zola. Following Bernard’s death, the Sorbonne (where he had taught) commissioned Lhermitte to paint his portrait in 1886. This is a faithful anonymous copy of Claude Bernard and His Pupils, which was exhibited at the Salon in 1889.\nBernard stressed the importance of not just observational science, but the experimental too, which inspired Naturalist writers to pursue what they saw as an experimental approach. Zola watched people in life, filling notebooks with those observations. He then set characters up in the scenario for a novel, and they behaved according to his observations. He then documented this imaginary experiment, which became his next novel.\nLhermitte’s painting shows Bernard in the midst of performing an experiment on a rabbit, his students discussing its results, and one writing the experimental observations in the laboratory daybook.\nIn the USA, Thomas Eakins painted the retiring professor of surgery, Dr. David Hayes Agnew, at work in the University of Pennsylvania School of Medicine. The patient is unconscious thanks to a volatile liquid general anaesthetic administered via a mask, a technique which had been developed over the previous fifty years. Bright surgical lighting puts six figures literally in the limelight, including that of Agnew, who is holding a scalpel at the left.\nA few who originally intended to become artists went on to become great scientists. The best-known of these was the founding father of modern neuroanatomy, Santiago Ramón y Cajal, from Navarre, in Basque Spain. It was he who discovered the fine structure of the human retina, crucial information for our understanding of the sense of sight. It seems very appropriate that a scientist who wanted to paint but ended up spending so much of his life drawing should have played such a key role in understanding this sense. And as always, it was his painstaking draughtsmanship which showed to others what he had seen under his microscope.\nJoaquín Sorolla’s portrait of this scientist shows him in an academic gown rather than a cloak. On the wall behind is one of his neuroanatomical drawings, looking like a work of art.\nThe twentieth century brought the first completely new medium for painting since the development of oil paints before the Renaissance. In the nineteen-thirties, Otto Röhm invented a new synthetic resin formed from acrylate molecules, dubbed acrylic resin. This first became available dispersed in liquid during that decade, and was steadily developed into paints during the nineteen-forties. Their biggest market was in general-use commercial paints, particularly for external use on buildings.\nIn the late nineteen-forties, Leonard Bocour and Sam Golden developed and brought to market Magna paints, in which the acrylates were suspended in mineral spirits to form an emulsion. Golden later developed a paint based on water, which lives on in his company Golden Artist Colours. In the nineteen-fifties, they were joined by Liquitex, then in the sixties by Rowney’s Cryla paints. Acrylic paints started to rival oils.\nOil paints remain to a degree rooted in the alchemy which was replaced by chemistry during the Age of Enlightenment; although modern commercially made oil paints are sophisticated combinations of natural and synthetic ingredients, using them and controlling their visual effects owes as much to tradition as it does to industrial chemistry. Acrylics are thoroughly modern in their formulation and use, carefully packaged blends of polymers with surfactants, plasticisers, dispersants, defoamers, stabilisers, and of course pigments – the ultimate fusion of art and science.\nI hope you will join me in the coming weeks as I explore this relationship in paintings.', 'Colours of Ancient Egypt – Blue\nBy Anna Pokorska, on 16 October 2018\nThis is the second in the Colours of Ancient Egypt series; if you want to start at the beginning, click here.\nThe colour blue has already featured in a couple of posts in this blog (e.g. check out Cerys Jones’ post on why the Common Kingfisher looks blue) but it seems impossible to me to discuss colour, especially in Ancient Egypt, and not start with blue. Arguably, blue has the most interesting history of all the colours, which can be attributed to the fact that it is not a colour that appears much in nature – that is, if you exclude large bodies of water and the sky, obviously. Naturally occurring materials which can be made into blue colourants are rare and the process of production is often very time-consuming. In Ancient Egypt, pigments for painting and ceramics were ground from precious minerals such as azurite and lapis lazuli; indigo, a textile dye now famous for its use in colouring jeans, was extracted from plants.\nLeft: two pieces of azurite (Petrie Museum, UC43790); Right: lapis lazuli (Image: Hannes Grobe)\nHowever, all the above-mentioned colourants presented issues which limited their use. Azurite pigment is unstable in air and would eventually be transformed into its green counterpart, malachite. Lapis lazuli had to be imported from north-east Afghanistan (still the major source of the precious stone) and the extraction process would produce only small amounts of the purest colourant powder called ultramarine. Finally, indigo dyes can fade quickly when exposed to sunlight.\nAnd yet it seems that the Ancient Egyptians attributed important meaning to the colour blue and it was used in many amulets and jewellery pieces such as the blue faience ring, lapis lazuli and gold bracelet or the serpent amulet from the Petrie Museum collection (below).\nFrom left to right: blue faience ring with openwork bezel in form of uadjat eye (Petrie Museum, UC24520); lapis lazuli serpent amulet (UC38655); fragment of bracelet with alternative zig-zag lapis lazuli and gold beads (UC25970).\nTherefore, the race to artificially produce a stable blue colourant began rather early. In fact, the earliest evidence of the first-known synthetic pigment, Egyptian blue, has been dated to the pre-dynastic period (ca. 3250 BC). It was a calcium copper silicate (or cuprorivaite) and – although the exact method of manufacture has been lost since the fall of the Roman Empire – we now know that it was made by heating a mixture of quartz sand, a copper compound, calcium carbonate and a small amount of an alkali such as natron, to temperatures over 800°C.\nFragment of fused Egyptian blue (Petrie Museum, UC25037).\nThis resulted in a bright blue pigment that proved very stable to the elements and was thus widely used well beyond Egypt. In fact, its presence has recently been discovered on the Parthenon Marbles in the British Museum due to its unusually strong photoluminescence, i.e. when the pigment is illuminated with red light (wavelengths around 630 nm) it emits near infrared radiation (with a max emission at 910 nm).\nAfter its disappearance, artists and artisans had to make do with natural pigments and, being the most stable and brilliant, ultramarine became the coveted colourant once again. In fact, during the Renaissance, it is reputed to have been more expensive than gold and, as a result, often reserved for the pictorial representations of the Madonna and Christ. And so, the search for another replacement was back on. But it wasn’t until the early 1700s that another synthetic blue pigment was discovered, this time accidentally, by a paint maker from Berlin who, while attempting to make a red dye, unintentionally used blood-tainted potash in his recipe. The iron from the blood reacted with the other ingredients creating a distinctly blue compound, iron ferrocyanide, which would later be named Prussian blue. Naturally, other man-made blue pigments and dyes followed, including artificial ultramarine, indigo and phthalocyanine blues.\nHowever, it wasn’t quite the end of the line for Egyptian blue, which was rediscovered and extensively studied in the 19th century by such great people as Sir Humphry Davy. And not only are we now able to reproduce the compound for artistic purposes, scientists are finding more and more surprising applications for its luminescence properties, such as biomedical analysis, telecommunications and (my personal favourite) security and crime detection.\n Lorelei H. Corcoran, “The Color Blue as an ‘Animator’ in Ancient Egyptian Art,” in Rachael B.Goldman, (Ed.), Essays in Global Color History, Interpreting the Ancient Spectrum (NJ, Gorgias Press, 2016), pp. 59-82.\n Benjamin Errington, Glen Lawson, Simon W. Lewis, Gregory D. Smith, ‘Micronised Egyptian blue pigment: A novel near-infrared luminescent fingerprint dusting powder’, Dyes and Pigments, vol 132, (2016), pp 310-315.\n2 Responses to “Colours of Ancient Egypt – Blue”\nColours of Ancient Egypt – Introduction | UCL Researchers in Museums wrote on 11 January 2019:\n[…] can now read about the colours blue and […]\n[…] Colours of Ancient Egypt – Blue […]']	['<urn:uuid:e1ea24e1-24c6-4710-8b6c-b6154d6e0c58>', '<urn:uuid:2cabec81-3fc7-423b-b6f6-6f7652a65d85>']	factoid	with-premise	long-search-query	distant-from-document	multi-aspect	novice	2025-05-13T04:02:16.770989	9	60	2707
95	What happened to pet adoptions during COVID?	Nearly 11 million new pets were welcomed to US homes in 2020, representing an unprecedented surge that was largely driven by the COVID-19 pandemic.	['New wind farm investment will ensure enough renewable energy to provide for all Mars hospital operations in the US following the expansion of Mars Veterinary Health\nMars, Incorporated is announcing a new power-purchase agreement with Apex Clean Energy to provide renewable energy that will cover more than 100 per cent of the electricity needed for its 2,000 veterinary hospitals in the US This allows Mars to continue to meet its sustainability goal to source 100 per cent renewable electricity in the US, as it has since 2015.\nThis agreement is designed to address the company’s significant business growth, including the expansion of Mars Veterinary Health.\nThe company estimates nearly 11 million new pets were welcomed to US homes in 2020, an unprecedented surge largely driven by the COVID-19 pandemic. With the average vet visit using enough electricity to charge more than 600 smartphones, this power-purchase agreement will allow for more sustainable pet ownership in the US and model greener business growth as the economy recovers from the effects of the pandemic.\nBarry Parkin, Chief Procurement and Sustainability Officer at Mars, said: “As our business in the US continues to grow, Mars is committed to embedding sustainable solutions throughout our operations. And, as the world looks to rebuild from the devastating effects of the pandemic, it will be critical for businesses to lead. This partnership is further evidence that we are moving full steam toward our emissions targets and driving climate action throughout our extended value chain.”\nThe partnership between Mars and Apex, facilitated by Commodity Risk Solution, includes Mars suppliers BHJ and Silgan Containers and will enable the construction of a new 121.26 MW wind farm in Ford County, IL, set for completion by the end of 2021. The Ford Ridge Wind facility is jointly owned by Apex, with funds managed by Ares Management Corporation’s Infrastructure and Power strategy.\nTogether with an existing wind farm in Texas, Ford Ridge will generate enough power for the entire Mars confectionery, food, and pet care businesses in the US This includes all Banfield Pet Hospital, BluePearl, and VCA veterinary hospitals, and more than 70 Antech Diagnostics laboratories.\nDoug Drew, President, Mars Veterinary Health North America, said: “It’s imperative to Mars Veterinary Health that we take steps now to ensure a better future for people, pets, and the planet. This is a clear expectation from our clients and Associates. Being part of Mars allows us to take immediate climate action and make an impact beyond the walls of our veterinary hospitals. Ensuring that all of our hospitals are powered by renewable electricity is a significant step, with more to come.”\nThe announcement signifies important progress by the company towards its goal of using renewable energy in 100% of its direct operations by 2040. When the project is completed, the US will be one of eleven countries where Mars is already purchasing or using renewable electricity for its entire operations, covering more than 50 per cent of its global electricity needs. Ford Ridge will add to the existing wind power Mars sources from the Mesquite Creek Wind Farm in Lamesa, TX, which has powered the remainder of the company’s US operations since 2015.\nMark Goodwin, President and Chief Executive Officer of Apex Clean Energy, said: “Ford Ridge Wind represents monumental progress: not only does it bring Mars a significant step closer to achieving its renewable energy targets; it also brings their suppliers along with on the journey to net-zero.\nMars, BHJ, and Silgan Containers are signalling to the market and to consumers that sustainability is a priority—and that supply chain partners can work collectively to bring new renewable energy online, generating meaningful environmental and economic benefits.”\nThe article Mars announces 100% renewable electricity for 2,000 veterinary hospitals appeared first on World Branding Forum.']	['<urn:uuid:4540f9ba-fbc3-45e9-bd6d-ad24c6a1ef88>']	open-ended	direct	concise-and-natural	distant-from-document	single-doc	novice	2025-05-13T04:02:16.770989	7	24	628
96	my child struggles with speech how does telepractice work	Telepractice is a virtual service delivery method where therapy is provided through devices like tablets, iPads, or laptops. For speech support, we can provide direct therapy to target skills like joining in conversations, plus coach parents on strategies to use at home. Sessions typically last 1 hour and include coaching for parents/caregivers to help support their child's development.	['- Speech Pathology, Occupational Therapy and Early Childhood Intervention support through Telepractice from the comfort of your home.\n- Eliminate wait times and reduce travel costs.\n- Available throughout Victoria for children aged from birth to 7 years.\n- iPads/tablet available through your NDIS Plan for Telepractice services.\nOnline Speech Pathology, Occupational Therapy and Early Childhood Intervention via Telepractice\nAccessing quality occupational therapy, speech pathology services and group services is no longer a barrier thanks to technology and smart devices.\nMCM can help you access early childhood intervention through our telepractice services while eliminating wait times and removing travel cost. Telepractice protects our health and safety during COVID-19.\nTalk to us today about how you can avail or transition to this service.\nGet in touch\nWhat is telepractice?\nTelepractice is used with a child and their family or carer to deliver supports virtually. We are able to provide services either to individual children or to small groups of children. Our approach delivers therapy and also coaching for parents/caregivers.\nHow can telepractice work for me?\nThere are many ways you can engage in telepractice. We can tailor a program just for you. Here are some examples:\n- Conversations with you about your child’s goals and what you would like to achieve\n- Coaching strategies to use at home during routine times such as sleeping, eating, toileting\n- Direct therapy to target skills, such as following instructions, writing your name, joining in conversations, managing emotions and behaviour\n- Liaising with your child’s education settings to help them transfer skills to all environments.\nFAQs about ECIS Telepractice Services\nYes, reports can be completed related to supports and therapy that have occurred during the last plan.\n- Sessions work best on a larger screened device such as a tablet, iPad or laptop. See next paragraph on how devices can be purchased through your NDIS Plan for Telepractice services.\n- Telepractice can be provided over the phone should the goals be focused on coaching and building parent/carer capacity or involve liaison with the child’s wider network such as other therapists or their education setting.\nYes, once the device is necessary for the continuation of your services and you don’t already own such a device.\nIn the case of computer tablets or iPads for telehealth or participating in online video classes, the NDIA advice is that most NDIS participants will not need more than a standard tablet, which costs no more than $600.\nFurther information on the purchasing of such devices can be found here https://www.ndis.gov.au/media/4518/download?attachment\n- No, sessions will not be recorded.\n- Should a recording be deemed useful for therapy progress it will be discussed with yourself prior to the session e.g. recording of a specific strategy or recording of your child’s speech to help feedback.\n- Sessions typically last 1 hour with notes either written during or after the session (15 minutes). 15 minutes preparation time is added to each session.\n- Telepractice doesn’t work for everyone.\n- Telepractice is the best option for your child to receive the supports they need during the Coronavirus pandemic.\n- If you do not want to engage in telepractice, we are happy to keep your child on the waitlist for when face to face services recommence.\n- Most definitely. Anyone who is significant in the child’s life can participate if they are a support not a distraction.\n- It’s OK. The key worker / therapist will try to work with you to bring the child back to the screen and keep them engaged.\n- Telepractice is not appropriate for all children and we will work with you to see what works best.\n- It’s OK. Your child may need a brain break or 1-hour sessions maybe too long for them.\n- Your key worker / therapist will work with you to see what works best.\nMost of the time, so you can learn new skills with your child.\n- Some sessions may require more than just yourself, the child and the digital device\n- Your key worker and/or therapist will let you know if other resources are required and try to work with what you have available at home\n- If a paper or visual resource is recommended we have the capacity to create these resources and post to your home.\nGet in touch\nContact our friendly Customer Service Team to find out more about how we can assist you. Call us on 1800 343 287 or send us an enquiry below.']	['<urn:uuid:132c54c9-d276-4135-8688-ab8e6a3b5148>']	open-ended	with-premise	short-search-query	similar-to-document	single-doc	novice	2025-05-13T04:02:16.770989	9	58	746
97	I work on urban safety initiatives and would like to know what specific safety problems Atlanta is trying to address with their new street safety plan?	Through September of that year in Atlanta, three scooter riders and 17 pedestrians were killed in traffic crashes. The city is responding to these safety issues by planning to redesign over 20 streets, including adding more than triple the protected bike network and establishing new connections around popular corridors and destinations.	"['Atlanta Mayor Keisha Lance Bottoms recently announced an action plan designed to make the streets of Atlanta much safer for the people who use them. The two-year “Action Plan for Safer Streets” calls for rapidly redesigning over 20 of the City’s streets—including more than tripling the city’s protected bike network and establishing new connections in and around popular corridors and destinations in Atlanta. By the end of 2021, Atlanta residents will see over 20 miles of safer streets, including at least eight miles of traffic-separated bikeways.\nNew Designs Will Make Atlanta’s Streets Safer for All\nMayor Bottoms is seizing an opportunity to accelerate building Atlanta’s protected bikeway network. Dedicated infrastructure for bikes, scooters, and other active transportation options will create safer places to ride, leveraging electric scooters\' evolving role in the urban transportation landscape and providing more high-quality transportation options citywide. Through September of this year in the City of Atlanta, three scooter riders and 17 pedestrians have been killed in traffic crashes, underscoring the urgency of designing safer streets.\nWith technical assistance from NACTO as part of the Bloomberg American Cities Climate Challenge, Atlanta’s newest bikeways will be built to national best practice standards. Separated lanes will give people on bikes dedicated space on the street, reducing interactions with motor vehicles and directly improving safety. And with more people than ever adopting e-scooters as a way to travel in Atlanta, providing infrastructure to match riders’ enthusiasm is crucial for making streets safe for everyone.\nSeparated bikeways also make streets safer for people who walk and drive. Redesigning streets to best-practice standards discourages dangerous speeding and gives drivers more consistent travel times. With narrower crossings and other street design changes, it’s also easier and safer for people to walk across the street.\nIn addition to these new bikeway projects, the City is further prioritizing pedestrian safety with a commitment to build and repair 25 miles of sidewalks over the next two years. Projects will include sidewalk improvements along heavily-trafficked routes and corridors with significant pedestrian travel. The city is currently constructing new sidewalks along Campbellton Road and Anderson Road after receiving federal grant funding, with more sidewalk improvements in the pipeline.\nDelivering Safety and Sustainability, Fast\nThese changes are happening against the backdrop of wider changes coming soon to Atlanta, where the City is in the process of creating a new Department of Transportation (DOT). The new department’s launch is an opportunity to set a new strategic direction for the City’s transportation system. It’s also an opportunity to establish new project implementation routines that accelerate the pace of delivering safe and sustainable transportation infrastructure.\nThat is exactly what Atlanta is leveraging NACTO’s support to accomplish through the Climate Challenge. As a Climate Challenge Accelerator city, Atlanta is working with NACTO to develop internal procedures to quickly deliver the street design projects laid out in Atlanta’s Action Plan. Working across agency lines with City Planning, Public Works, and RENEW Atlanta, NACTO is providing design and implementation best practices that will help City staff deliver projects efficiently now and moving forward.\nWith safety and with climate change work, it is critical to move fast. Mayor Bottoms’ announcement prioritizes ‘quick-build’ projects, which use low-cost, easy-to-install materials (like paint and bollards) to build new lanes, and build momentum for change by making project benefits real rather than merely describing them in a public meeting. The City can then see how their designs work and make modifications before implementing projects in costly concrete—enabling Atlanta to build momentum and move nimbly to deliver safer, more comfortable streets for everyone.\nA Win for Safety, Transportation Access, and Climate Action\nIn a statement, Mayor Bottoms said, ""We have heard from residents of Atlanta loud and clear—people want safer streets, and they want to see real changes before another tragedy occurs."" The Action Plan for Safer Streets ensures safety for all street users, fostering a more inclusive transportation network across the City of Atlanta and enabling lower-carbon commutes by making it safer to walk, bike, or even to ride an electric scooter.\nMayor Bottoms’ ambitious plan to fund and quickly implement 20 miles of safer streets kicks off during “Biketober”—Georgia Commute Options’ month-long challenge to grow metro Atlanta’s bike commute mode share—with the City’s first-ever “pop-up” bike lane. This pop-up was installed along 10th Street for one week starting October 19th. The pop-up lane extends for two blocks from the end of the existing 10th Street Cycle Track at Myrtle Street. City officials will measure and evaluate the lane’s impact on safety and transportation access to inform more permanent street design changes.\nThis type of creative thinking, nimble implementation, and holistic planning are the result of changes happening in Atlanta, both in city offices and on city streets. City agencies are refining their ability to plan and deliver projects together, and increasing their capacity to implement quick-build infrastructure, with the larger goal of building a city that is safer, more equitable, and more environmentally sustainable.\nAtlanta’s Action Plan for Safer Streets is also a great example of leveraging the Bloomberg American Cities Climate Challenge strengths to support City goals. By working at the intersection of climate change mitigation and government innovation, process and institutional reform accelerate the delivery of ambitious projects that improve quality of life for city residents—reducing climate pollution in the process.']"	['<urn:uuid:6e022619-2c63-4f2f-a6aa-0b6c0e37a48a>']	factoid	with-premise	verbose-and-natural	similar-to-document	single-doc	expert	2025-05-13T04:02:16.770989	26	51	885
98	steel countertops compared to quartz durability maintenance	Stainless steel and quartz countertops differ in their durability and maintenance characteristics. Stainless steel countertops can last up to 100 years, are impervious to heat and stains, don't corrode easily, and can withstand harsh cleaning. They are also non-porous, preventing bacterial spread. Quartz countertops are extremely durable against chips, scratches, and cracks, ranking 7 out of 10 on the Mohs hardness scale, and are non-porous requiring only simple soap and water cleaning. However, quartz requires professional installation due to its weight (20-25 pounds per square foot) and can be damaged by heat.	['Home chefs take their cooking seriously and as a result they want all the best equipment, as well as all the essential accessories. In addition, home chefs also want their kitchen equipped with the cabinetry needed to house all their culinary goodies with care and have the functional countertops needed to accomplish all the essential kitchen tasks. Let’s take a look at the best countertops for cooks serious about their food and its preparation.\nCharacteristics of the Best Countertops\nThe best countertops are capable of handling the heat from the oven and the stovetop, as well as taking the heat from hot pots, pans, and baking dishes. Since laminates, wood, and most solid surface countertops don’t handle heat well, they simply aren’t the best choices for cooking enthusiasts. Countertops which are resistant to stains are important too, after all, as a home chef you’ll be using lots of foods and liquids – lemons, tomatoes, wine, oils, and more – which can stain porous countertops. Porous countertops include marble, sandstone, granite (though it can stand up to the heat), wood, and bamboo. The right countertops for serious cooks are made of material that can be easily cleaned. Raw proteins, vegetables, and fruits can harbor bacteria which remains on the countertops during food preparation. Once again, porous materials aren’t the best choice for those who take cooking to another level.\nThe Best Countertops for Serious Home Cooks\n- Glass Countertops made of heat-resistant glass can be an excellent choice for home chefs. With a wide assortment of styles, glass countertops are often designed of tiles. Glass also allows for the option of being back-lit by LED lighting creating a distinct look. Recycled glass countertops are an eco-friendly option manufactured from crushed glass which is embedded in resin and deliver beautiful countertops in a multitude of colors and designs.\n- Stainless Steel countertops are the favorite among professional chefs because stainless steel is impervious to heat and stain while cleaning easily. Stainless steel doesn’t corrode or rust easily and can stand harsher cleaning when needed. Like recycled glass countertops, stainless is also an environmentally friendly option, lasting up to 100 years and manufactured in the United States from recycled scrap metal. Because it is not porous, liquid can’t penetrate the stainless steel surface which means it helps prevent the spread or cross-contamination from bacteria, viruses, or fungi.\n- Ceramic Tile and Porcelain Tile are classic choices for kitchens and one of the ideal substances to use for countertops because they can withstand the heat in the kitchen and don’t stain easily. Add a water resistant grout and tiles will provide the results serious home cooks are looking for in their kitchens. Plus, ceramic and porcelain tiles offer up a vast selection of colors, patterns, shapes, sizes, and styles which means the options for cooking enthusiasts to show off their personal styles are endless. Tile is a great choice for countertops because it is easy to clean and promises to also serve in complementary and functional backsplashes.\nWhen seeking a countertop able to stand up to the heat and resist the stains prevalent in a cook’s kitchen, glass, recycled glass, stainless steel, ceramic tile, and porcelain tile are among the best options for both performance and functionality for years to come. Additionally, these materials are easy to clean and offer incredible options for style – sleek and modern, timeless and traditional, or funky and eclectic.', 'The average homeowner spends just shy of $3000 on countertop installation.\nNew countertops are a significant investment, which is why you want to take your time when choosing the materials, colors, patterns, and contractors.\nFor many people, the biggest decision when it comes to choosing countertops is the material. Without a doubt, quartz is one of the most popular countertop materials.\nBut, is this material right for your kitchen? Does it live up to the hype?\nCheck out this guide to learn about the top pros and cons of quartz countertops.\nWhat is Quartz?\nBefore we dive into the pros and cons, let’s take a close look at what exactly quartz is. Many people think that quartz is a humanmade material. However, quartz is a natural mineral that’s composed of silicon and oxygen. And, it’s the most abundant mineral on earth.\nThe confusion usually comes from the fact that even though quartz is natural, quartz countertops are humanmade. To make a quartz countertop, one must grind quartz into dust and then combine it with other natural and synthetic materials.\nSynthetic materials that quartz is usually combined with include pigments, polymers, and resins. The polymers and resins work to bind the quartz together to make it durable and hard. The dyes work to give the quartz countertop its color.\nTypically, natural quartz makes up 90 percent of the entire countertop, while the other ten percent is made out of synthetic materials.\nPros of Quartz Countertops\nLet’s start by looking at why people love quartz countertops:\nQuartz countertops come in a wide range of colors and patterns. If you wish, you can even get your quartz countertop in a design that very closely mimics natural stone.\nOr, if you’re looking for an extremely contemporary look, you can purchase a quartz countertop made from recycled materials or one that has metallic flecks.\nIf you’re looking for a countertop material that’s sleek, elegant, and modern, then quartz is your answer.\nBecause manufacturers of quartz countertops can mimic pretty much any design, they can make your quartz countertop look as classy as a real marble countertop.\nOne of the main reasons to invest in a quartz countertop is because of its strength.\nIf you’re looking for a material that doesn’t chip, scratch, or crack, then quartz is your answer.\nIn fact, on the Mohs scale of hardness, which is a scale that geologists use to measure the scratch resistance and hardness of a mineral, quartz ranks as a 7 on a scale from 1 to 10.\nIn contrast, marble falls between a rating of 3 and 5.\nManufacturers are so confident in quartz’s durability, that many of them offer a very generous warranty.\nMost companies offer a warranty between 10 and 25 years.\nIf the material is porous, it means that liquids can seep beneath its surface. This can lead to discoloration, staining, and irreversible damage.\nEven worse, bacteria and germs can make their way into the pores, making the countertops hard to clean and disinfect.\nBecause of this, if you invest in a porous surface, you’ll need to seal it to prevent staining.\nLuckily, because quartz is a non-porous material, you never have to worry about sealing it. This also means that quartz is incredibly stain-resistant.\nOne of the other main benefits of quartz is that it’s incredibly low maintenance.\nBecause it’s non-porous, cleaning quartz is a breeze. For the most part, all you need to do is wipe down your countertops with soap and water, and you’ll be good to go.\nCons of Quartz\nAs you can see, there are a lot of benefits to quartz countertops. But, there are also some drawbacks, such as:\nIf you’re on a tight budget, then quartz might not be the best choice for you.\nAll the beautiful benefits of quartz- non-porousness, durability, ability to customize- come with a cost.\nTypically, you can expect to pay between $65 to $100 per square foot for your quartz countertop.\nSusceptible to Heat Damage\nWhile quartz is incredibly durable, it is vulnerable to heat damage. While quartz is heat resistant, the polymers and resins it’s made out of, are not.\nTherefore, if you expose your quartz countertop to hot cookware, there’s a chance that the resins could melt, causing permanent damage and discoloration.\nSo, if heat is a significant concern for you, you may want to reconsider purchasing a quartz countertop.\nIf you want to install quartz countertops, it’s essential to know that this is not an afternoon DIY project.\nQuartz should always be installed by a trained professional. This is in part due to its extreme heaviness, as quartz weighs about 20 to 25 pounds per square foot.\nInstallers also need to be very careful about minimizing the appearance of seams when installing quartz countertops.\nIn other words, if you’re looking for a countertop material that you can install yourself, this isn’t it.\nCan’t Use Outdoors\nIf you’re looking to build an outdoor kitchen, quartz is not the right countertop material for you.\nQuartz can discolor when exposed to direct sunlight for extended hours.\nPros and Cons of Quartz Countertops: Is it Right for You?\nNow that you know about the top pros and cons of quartz countertops, it’s time to decide if this material is right for you.\nIf you decide that quartz is the right material for you, then you need to make sure you choose the correct installer. The right installer can make all the difference in the final appearance of your quartz countertops.\nBut, if you don’t think quartz is the right material for you, we suggest looking at other materials such as graphite, marble, or quartzite.\nAnd, if you’re looking to get new countertops installed soon, contact us today.']	['<urn:uuid:e6c13ae3-7000-49df-a4f6-01361dc293c5>', '<urn:uuid:e34878c8-2c9c-48ff-a0a1-f4d85072c540>']	open-ended	direct	short-search-query	distant-from-document	comparison	novice	2025-05-13T04:02:16.770989	7	92	1526
99	I love traditional artists like Van Gogh but I'm curious about new ways to see their work - how are famous paintings being shown differently in modern exhibitions?	Famous artworks by artists like Van Gogh, Klimt, Klee, and Picasso are now being presented in immersive digital formats. Instead of displaying the original canvases, these exhibitions project the artworks in immense spaces, animating them and adding music for greater emotional impact. For example, L'Atelier des lumières in Paris attracted 2.2 million people to its Klimt and Van Gogh exhibition. These digital presentations allow the works to be shared worldwide without moving valuable original pieces, and they create new ways to experience classic masterpieces through large-format projections and multimedia elements.	['Art exhibition: a new ambitious show\n4 Nov, 2019\nIncreasingly spectacular, art exhibition as we knew it has mutated profoundly. It is digitalized, interactive, offers ever more immersion and takes the “visitor” on board towards a denser, stronger experience, disturbing the senses. Turn on your projector, we’re taking you to the museum!\nImmersion may be trendy, but the idea is not new. As the director and RV specialist Pierre Friquet points out, the first immersive art experience dates back to the Paleolithic and cave paintings. The torches of our ancestors swept the walls and the painted animals seemed to come to life.\nMore than 30,000 years have passed and technological developments have taken us to another level. We no longer discover works with a torch but armed with a smartphone. And even though paintings continue to attract crowds, visitors became spectator-actors in the midst of floods of pixels and illuminations.\nWhen augmented reality tells more about the works… or hacks them!\nMuseums understood early on that digital technology would enable them to enrich the traditional circuit from room to room and seized the opportunities offered by digital tools.\nVisitors’ assistance, tailor-made tours via dedicated apps, augmented reality… have become essential. The works become interactive and thanks to augmented reality, sometimes it is enough to point your phone at a painting or sculpture to learn more about its history or its underside. Picking up your smartphone and discovering the inside of a mummy enriches the visit of all audiences.\nThe possibilities are endless, especially for those with a creative -or even dissident – soul. A collective created by eight artists has been using augmented reality since 2018 to superimpose its animated content on the works of art presented in the “Jackson Pollock” section at MoMA New York. This content is accessible via a mobile application called MoMAR. Their objective is to denounce the elitism of the galleries and give back an active role to the visitor. Virtual hacking, a space to conquer…\nDigital creation combined with technological developments makes it possible to offer ultra-immersive virtual experiences, starting with virtual reality.\nFor years, the VR Arles Festival, which takes place at the prestigious Rencontres photographiques, has invited visitors to immerse themselves in other worlds, virtual or not. Alongside short films anchored in our reality (reports or fictions), 100% digital creations are proposed. The essential RV helmet is sometimes accompanied by a connected vest that vibrates to the rhythm of creation, making the experience even stronger and more immersive. We know the power of these helmets, which literally deceive our brains and make us lose our bearings.\nThe possibilities are obviously infinite, the powers of creation being also in the hands of coders, developers, engineers…\nWhen pixels and programs replace paint\nBeyond the individual experience offered by RV headphones, digital works are displayed in large format and attract a growing audience. The Immersive Art Festival, dedicated to immersive digital design and offered by the essential Culturespaces, gave the public a chance to immerse themselves in the works of 11 artists’ collectives.\nThese creations of 4 minutes each, combining video, photo, motion design and sound spatialization, were tailor-made for the Atelier des Lumières. Broadcast thanks to 140 video projectors, 50 speakers, spread over 3,000 m2 of projected area, the 50-minute show is complete. Despite its price (26$), the festival largely found its audience who had the opportunity to vote for their favorite work.\nThese places of immersion in digital art are multiplying all over the world and the figures are dizzying. One of the latest born is in Tokyo. Launched in June 2018, the Mori Building Digital Art Museum is a 10,000m2 modern and interactive art gallery created by the teamLab collective. Composed of 40 artists with various profiles, engineers, designers, graphic designers, architects, or artists from the audiovisual world, teamLab has given birth to more than a hundred projects around the world since the year the collective was created. He performed in La Villette in 2018, bringing together 300,000 spectators.\nFrance is not to be outdone since in April 2020, Les Bassins de Lumières will open a new venue in Bordeaux, managed by Culturespaces. Located in one of the five underwater bases of the Kriegsmarine on the Atlantic, this remnant of the Second World War will become the largest immersive art venue in the world with its 14,500m2 of projection area and 350,000 visitors expected.\nThe visit is reinvited. Immersive creations are constantly in motion and interact with the gestures and movements of visitors, even integrating real-time contributions (drawings or other) made by the public.\nThe spaces can be walked around standing upright… but the lying position is not so unusual to admire the projections. Visitors no longer hesitate to touch the walls since the works are elsewhere! The organizers even provide cushions, balls and sometimes…. climbing walls as in Tokyo at the Mori Building Digital Art Museum!\nAll the traditional codes of the exhibition spaces are overturned and everyone is strongly encouraged to share their experience on Instagram.\nThe master canvases in Waow effect version\nThis movement also affects the most emblematic artists.\nVan Gogh, Klimt, Klee, Picasso… Their works are now projected into immense spaces and there are few detractors to challenge the legitimacy of such a staging. Today, these works are broadcast in large format, animated with music for ever greater emotion, and take on a new dimension.\nWe no longer extol the painter’s brushstroke, we no longer approach the canvas by scrutinizing the material. We can discuss zooms, animations that disturb the original work.\nBut the advantages of these exhibitions are numerous: after negotiations with the beneficiaries on cropping and other staging requests, there is no longer a need to be moving works worth several millions of euros around the world. These events can travel the world very easily and bring together a wide audience.\nInaugurated eighteen months ago in eastern Paris, L’Atelier des lumières welcomed 2.2 million people with its Klimt and Van Gogh event.\nIt is now in La Sucrière, in Lyon, that the new exhibition “Imagine Picasso” offers, without any painting or drawing, 200 works by Picasso projected not only on the walls, but also on the floor and inclined walls, incorporating the codes of digital arts that play on architecture.\nWelcoming instagrammers, a new type of visitors walking around with their smartphones and staging themselves in the middle of screenings.\nEven the Louvre, with its mega exhibition on Leonardo da Vinci’s work, is offering to rediscover the Mona Lisa in virtual reality in a dedicated room at the end of the journey, while it remains quietly in the room assigned to it in the Louvre.\nWith these new digital narratives, art and entertainment are now one. The field of play is huge and brands should soon take over…\nFrance TV Info']	['<urn:uuid:9bd6a446-a586-4403-8c20-bf74c7634690>']	open-ended	with-premise	verbose-and-natural	similar-to-document	single-doc	novice	2025-05-13T04:02:16.770989	28	90	1136
100	natural medicine addiction recovery studies safety	Studies have examined the use of natural remedies like chamomile for addiction withdrawal symptoms. While research in mice has investigated chamomile's effects on morphine withdrawal, the safety and effectiveness of chamomile for therapeutic use in humans is not well established through reliable research. The German Commission E has authorized topical chamomile use for skin conditions, but there are significant safety concerns including reports of serious allergic reactions and potential interactions with medications.	"['. Orang J. A research on addiction. Tehran, FarhangvaErshad e Eslami Department. 2008: 85-88.\n. Hajihasani M, ShafiAbadi A, Pirsaghi F, Kiyanipour O. Relationship between aggression, assertiveness, depression and addiction potential in female students of Allameh Tabbatabai. Knowledge & Research in Applied Psychology, 2012; 13(3): 65-74.\nRL. Participation in narcotics anonymous and alcoholics anonymous and abstinence outcomes of 322 methadone maintenance patients. Journal of Groups in Addiction & Recovery. 2014; 9(1): 14-30.\nS. A review of alcoholics anonymous/ narcotics anonymous programs for teens. Eval Health Prof.March. 2010; 33: 26-55.\n. Andrabi S, Greene S, Moukaddam N, Li B. New drugs of abuse and withdrawal syndromes review article. Emergency Medicine Clinics of North America. 33(4); 2015; 779-795.\n. Benich J. Opioid dependence review article primary care: Clinics in office practice. 2011; 38(1), 59-70.\n. Shoara R, Hashempur MH, Ashraf A, Salehi A, Dehshahri S, Habibagah Z. Efficacy and safety of topical Matricariachamomilla L. (chamomile) oil for knee osteoarthritis: A randomized controlled clinical trial. Complementary Therapies in Clinical Practice. 2015; 21: 181-187.\n. Hashempurmh NasiriLari Z, Ghoreishi P, Daneshfard B, Ghasemi MS, Homayouni K, Zargaran A. A pilot randomized double-blind placebo-controlled trial on topical chamomile (Matricariachamomilla L.) oil for severe carpal tunnel syndrome. Complementary Therapies in Clinical Practice. 2015; 21(4): 223-228.\n.Honarvaran F, Kesmati M, Ismaili MH, Jahani JH, Jafari H, Esmaeeli A. The effect of chronic administration of alcoholic extracts of chamomile on morphine withdrawal symptoms in adult male mice. Daneshvar Journal .2008; 14(69): 27-32.\n.Salehi M, Safavi P, Barkatin M. The effect of sodium valproate in controlling the symptoms of withdrawal in patients dependent on opium. Journal of Lorestan University of Medical Sciences. 2006; 7(1): 37-42.\n. Aflatoonian M, Ziaaddini H, Kheradmand A, Shamsi Meimandi M, Divsalar K, Mahmoodi M. Substance misuse patterns and blood types of self-introduced addicts to substance rehabilitation centers of Bam City. Addiction & Health, 2011; 3: 95. [in Persian]\n. Seragi A, Momeni H, Salehi A. Investigation of factors on tendency to narcotic agents and to stability abandon in Narcotics Anonymous in Khomain. Arak University of Medical Sciences Journal. 2010; 13(3): 68-75. [in Persian]\n. Miladi Gorji H, Vafaie AA, Taherian AA, Vaezi T. The effects of aqueous extracts of Melissa Officinalis on withdrawal syndrome in rats. Sci J of Kurdistan Uni of Med Sci. 2008; 13(2): 27-33. [Persian]\n. Jadidi M, Vafaie AA, Miladi Gorji H, Babaie Saeidabadi A. The effect of Ferulapersica L extracts on symptoms of morphinewithdrawal and sleeping time in mice. J of Res in Med Sci. 2011; 34(4): 225-30. [in Persian]\n. Kerachian N, Alaee H, Gharavi-Naini H, Pilevarian A, Moghim A. Effects of alcoholicextract of Avena sativa, Hypericumper foratum, Passifloraincarnata and Lavandulaofficinalis on symptoms of morphine withdrawal syndrome in rats. Physiol & Pharmacol. 2007; 10: 313-22. [Persian]\n.Coleta M, Batista MT, Campos MG, Carvalho R, Cotrim MD, Lima TC, et al. Neuropharmacological evaluation of the putative anxiolytic effects of Passifloraedulis Sims, its sub-fractions and flavonoid constituents. Phytother Res. 2006; 20(12): 106-7.\n. Akhondzadeh S, Kashani L, Mobaseri M, Hosseini SH, Khani M. Passion flower in the treatment of opiates withdrawal, A double-blindrandomized controlled trial. J Clin Pharm Ther. 2001; 26: 369-73. In [Persian]\n. Malek A, Amiri SH, HabibiAsl B. The rapeutic effect of adding dextromethorphan to clonidine for reducing symptoms of opioid withdrawal: A randomized clinical trial. Hindawi Publishing Corporation ISRN Psychiatry. 2013; Article ID 546030, 5. [in Persian]', 'Anthemis arvensis, Anthemis cotula, Anthemis nobile, Anthemis nobilis, Anthemis xylopoda, apigenin, Asteraceae/Compositae (family), baboonig, babuna, babunah, babunah camomile, babunj, bunga kamil, camamila, camamilla, camomile, camomile sauvage, camomilla, Camomille Allemande, Campomilla, chamaemeloside, Chamaemelum nobile L., chamomile flowers, Chamomilla, Chamomilla recutita, chamomillae ramane flos, chamomille commune, classic chamomile, common chamomile, double chamomile, Echte Kamille (Dutch), English chamomile, feldkamille (German), fleur de chamomile (French), fleurs de petite camomille (French), Flores Anthemidis, flos chamomillae, garden chamomile, German chamomile, Grosse Kamille, Grote Kamille, ground apple, Hungarian chamomile, Kamille, Kamillen, kamitsure, kamiture, Kleine, kleme kamille, lawn chamomile, low chamomile, manzanilla, manzanilla chiquita, manzilla comun, manzanilla dulce, matricaire, Matricaria chamomilla, Matricaria maritime (L.), Matricaria recutita, Matricaria suaveolens, matricariae flos, matricariae flowers, may-then, Nervine, pin heads, rauschert, Romaine, romaine manzanilla, Roman chamomile, Romische Kamille, single chamomile, STW 5 (containing Iberis, peppermint, chamomile), sweet chamomile, sweet false chamomile, sweet feverfew, true chamomile, whig-plant, wild chamomile.\nChamomile has been used medicinally for thousands of years and is widely used in Europe. It is a popular treatment for numerous ailments, including sleep disorders, anxiety, digestion/intestinal conditions, skin infections/inflammation (including eczema), wound healing, infantile colic, teething pains, and diaper rash. In the United States, chamomile is best known as an ingredient in herbal tea preparations advertised for mild sedating effects.\nGerman chamomile (Matricaria recutita) and Roman chamomile (Chamaemelum nobile) are the two major types of chamomile used for health conditions. They are believed to have similar effects on the body, although German chamomile may be slightly stronger. Most research has used German chamomile, which is more commonly used everywhere except for England, where Roman chamomile is more common.\nAlthough chamomile is widely used, there is not enough reliable research in humans to support its use for any condition. Despite its reputation as a gentle medicinal plant, there are many reports of allergic reactions in people after eating or coming into contact with chamomile preparations, including life-threatening anaphylaxis.\nThese uses have been tested in humans or animals. Safety and effectiveness have not always been proven. Some of these conditions are potentially serious, and should be evaluated by a qualified healthcare provider.\nChamomile is not well-known for its cardiac effects, and there is little research in this area. Large, well-designed randomized controlled trials are needed before a firm conclusion can be made.\nIn early study, inhaling steam with chamomile extract has been reported to help common cold symptoms. Further research is needed to confirm these results.\nDiarrhea in children\nPreliminary study reports that chamomile with apple pectin may reduce the length of time that children experience diarrhea. Further research is needed before a strong recommendation can be made.\nThe German Commission E authorizes the use of topical chamomile for diseases of the skin. However, little research has been done on topical chamomile for eczema and further research is needed.\nChamomile is used traditionally for numerous gastrointestinal conditions, including digestion disorders, ""spasm"" or colic, upset stomach, flatulence (gas), ulcers, and gastrointestinal irritation. However, currently there is a lack of reliable human research available in any of these areas. Additional study is needed.\nHemorrhagic cystitis (bladder irritation with bleeding)\nPreliminary study reports that the combination of chamomile baths plus chamomile bladder washes and antibiotics is superior to antibiotics alone for hemorrhagic cystitis. Additional research is necessary before a conclusion can be reached.\nPreliminary study reports that chamomile ointment may improve hemorrhoids. Better evidence is needed before a strong recommendation can be made.\nChamomile is reputed to have anti-spasmodic activity, but there is little research to substantiate this claim. Additional research evaluating chamomile alone is needed.\nMucositis from cancer treatment (mouth ulcers/irritation)\nPoor-quality studies have used chamomile mouthwash for the prevention or treatment of mouth mucositis caused by radiation therapy or cancer chemotherapy. Results are conflicting, and it remains unclear if chamomile is helpful in this situation.\nQuality of life in cancer patients\nA small amount of research suggests that massage using chamomile essential oil may improve anxiety and quality of life in cancer patients. However, this evidence is not high quality. Additional study is needed before a firm conclusion can be reached.\nTopical chamomile preparations have traditionally been used to soothe skin inflammation. The existing human evidence shows that chamomile may be of little, if any, benefit while animal studies support its anti-inflammatory action. Additional human research is needed in this area.\nSleep aid / sedation\nTraditionally, chamomile preparations, such as tea and essential oil aromatherapy, have been used for insomnia and sedation (calming effects). Better research is needed before a recommendation can be made.\nVaginitis (inflammation of the vagina)\nVaginitis may involve itching, discharge, or pain with urination. Chamomile douche may improve symptoms of vaginitis with few side effects. Because infection (including sexually transmitted diseases), poor hygiene, or nutritional deficiencies can cause vaginitis, medical attention should be sought by people with this condition. Better research is needed before a conclusion can be drawn regarding the role of chamomile in the management of vaginitis.\nThere is promising preliminary evidence supporting the topical use of chamomile for wound healing. However, the available literature is not adequate to support a recommendation either for or against this use.\nPost-operative sore throat/hoarseness due to intubation\nChamomile spray has not been found to prevent post-operative sore throat and hoarseness any more than normal saline.\n*Key to grades:\nA: Strong scientific evidence for this use;\nB: Good scientific evidence for this use;\nC: Unclear scientific evidence for this use;\nD: Fair scientific evidence against this use (it may not work);\nF: Strong scientific evidence against this use (it likely does not work).\nThe below uses are based on tradition, scientific theories, or limited research. They often have not been thoroughly tested in humans, and safety and effectiveness have not always been proven. Some of these conditions are potentially serious, and should be evaluated by a qualified healthcare provider. There may be other proposed uses that are not listed below. Abdominal bloating, abortifacient, abrasions, abscesses, acne, anorexia, antibacterial, anticoagulant, antifungal, antioxidant, antipruritic, antispasmodic, antiseptic, anxiety, aromatic, arthritis, asthma, back pain, bedsores, bladder disorders, blood purification, bruises, burns, cancer, canker sores, carpal tunnel syndrome, catarrh, chicken pox, constipation, contact dermatitis, cough, Crohn\'s disease, croup, delirium tremens (DTs), diaper rash, diaphoretic, diuretic (increasing urination), diverticulitis, dry skin, dysmenorrhea (painful menstruation), ear infections, eye disorders (blocked tear ducts), eye infections, fatty liver, fever, fistula healing, frostbite, gallstones, gingivitis, gout, hay fever, headaches, heartburn, hives, hypoglycemia (low blood sugar), hysteria, impetigo, inflammatory conditions, insect bites, insomnia, intestinal cramps, irregular menstrual cycles, irritable bowel syndrome, kidney disorders, leg ulcers, liver disorders, low back pain, malaria, mastitis (breast inflammation), menopause, menstrual cramps, menstrual disorders, morphine withdrawal, motion sickness, muscle strength, nasal inflammation, nausea, nervous stomach, neuralgia (nerve pain), nightmares, oral hygiene (mouthwash), osteoporosis, parasites/worms, peptic ulcers, perineal trauma, poison ivy, post-natal depression, psoriasis, rash (heat), respiratory inflammatory, restlessness, rheumatism, Roehmheld\'s syndrome, sciatica, seizure disorder, sinusitis, stomach cramps, sunburn, sunstroke, teething pain (mouth rinse), tension, tics, toothache, travel sickness, tuberculosis, ulcerative colitis, ulcers, uterine disorders, uterine stimulant, uterine tonic, vaginal infections, viral infection (flu-like symptoms or polio), vomiting, vomiting/nausea during pregnancy.\nThe below doses are based on scientific research, publications, traditional use, or expert opinion. Many herbs and supplements have not been thoroughly tested, and safety and effectiveness may not be proven. Brands may be made differently, with variable ingredients, even within the same brand. The below doses may not apply to all products. You should read product labels, and discuss doses with a qualified healthcare provider before starting therapy.\nAdults (18 years and older)\nCapsules/tablets containing 400 to 1,600 milligrams in divided doses have been taken by mouth daily. As a liquid extract (1:1 in 45% alcohol), 1 to 4 milliliters three times daily has been taken by mouth. As a tincture (1:5 in alcohol), 15 milliliters three to four times per day has been used. As a mouth rinse, a 1% fluid extract or 5% tincture has been used.\nChamomile is frequently consumed as tea, and 1 to 4 cups of chamomile tea taken daily (from tea bags) is a common dose.\nThere are no standard doses for chamomile used on the skin. Some natural medicine publications have recommended paste, plaster, or ointment containing 3% to 10% chamomile flower heads. Chamomile has been also used as a bath additive and as a douche.\nChildren (younger that 18 years)\nThere is not enough reliable scientific data available to recommend the safe use of chamomile products in children.\nThe U.S. Food and Drug Administration does not strictly regulate herbs and supplements. There is no guarantee of strength, purity or safety of products, and effects may vary. You should always read product labels. If you have a medical condition, or are taking other drugs, herbs, or supplements, you should speak with a qualified healthcare provider before starting a new therapy. Consult a healthcare provider immediately if you experience side effects.\nThere are multiple reports of serious allergic reactions to chamomile taken by mouth or as an enema, including anaphylaxis, throat swelling, and shortness of breath. Skin allergic reactions have been frequently reported, including dermatitis and eczema. Chamomile eyewash can cause allergic conjunctivitis (pinkeye).\nPeople with allergies to other plants in the Asteraceae (Compositae) family should avoid chamomile. Examples include: aster, chrysanthemum, mugwort, ragweed, and ragwort. Cross-reactions may occur with celery, chrysanthemum, feverfew, tansy, and birch pollen. Individuals with allergies to these plants should avoid chamomile. Contact skin allergy has been reported.\nImpurities (adulterants) in chamomile products are common and may cause adverse effects. Atopic dermatitis (skin rash) has been reported.\nChamomile in various forms may cause drowsiness or sedation. Use caution when driving or operating heavy machinery. In large doses, chamomile can cause vomiting. Due to its coumarin content, chamomile may theoretically increase the risk of bleeding. Caution is advised in patients with bleeding disorders or taking drugs that may increase the risk of bleeding. Dosing adjustments may be necessary. Increases in blood pressure are possible.\nPregnancy and Breastfeeding\nIn theory, chamomile may act as a uterine stimulant or lead to abortion. It therefore should be avoided during pregnancy. There is not enough scientific data to recommend the safe use of chamomile while breastfeeding.\nMost herbs and supplements have not been thoroughly tested for interactions with other herbs, supplements, drugs, or foods. The interactions listed below are based on reports in scientific publications, laboratory experiments, or traditional use. You should always read product labels. If you have a medical condition, or are taking other drugs, herbs, or supplements, you should speak with a qualified healthcare provider before starting a new therapy.\nInteractions with Drugs\nChamomile interactions are not well studied scientifically.\nChamomile may increase the amount of drowsiness caused by some drugs. Examples include benzodiazepines such as lorazepam (Ativan©) or diazepam (Valium©), barbiturates such as phenobarbital, narcotics such as codeine, some antidepressants, and alcohol. Caution is advised while driving or operating machinery.\nIn theory, chamomile may increase the risk of bleeding when used with anticoagulants or antiplatelet drugs. Some examples include aspirin, anticoagulants (""blood thinners"") such as warfarin (Coumadin©) or heparin, anti-platelet drugs such as clopidogrel (Plavix©), and non-steroidal anti-inflammatory drugs (NSAIDs) such as ibuprofen (Motrin©, Advil©) or naproxen (Naprosyn©, Aleve©).\nChamomile may interfere with the way the body processes certain drugs using the liver\'s ""cytochrome P450"" enzyme system. As a result, the levels of these drugs may be increased in the blood and may cause increased effects or potentially serious adverse reactions. Patients using any medications should check the package insert and speak with a healthcare professional including a pharmacist about possible interactions.\nBe aware that many tinctures contain high levels of alcohol and may cause vomiting when taken with metronidazole (Flagyl©) or disulfiram (Antabuse©).\nAn extract containing Matricaria chamomile, Sideritis euboea, Sideritis clandestine, and Pimpinella anisum was associated with selective estrogen receptor modulator (SERM) properties against osteoporosis. Theoretically, chamomile may interact with SERM drugs like raloxifene (prescription drug used for osteoporosis) or tamoxifen (a prescription drug used for cancer).\nConstituents in chamomile may alter blood sugar or blood pressure. Patients taking medications that affect blood sugar or blood pressure should be cautious.\nChamomile may have anti-inflammatory effects. Theoretically, use of chamomile with other anti-inflammatory drugs, such as NSAIDs or ibuprofen, may have additive effects.\nChamomile may interact with medications that act as cardiac depressants, central nervous system depressants, calcium channel blockers, cardiac glycosides, and respiratory depressants.\nChamomile may also interact with antibiotics, antifungals, antihistamines, diuretics, as well as drugs for high cholesterol, ulcers, diarrhea, or gastrointestinal disorders.\nInteractions with Herbs and Dietary Supplements\nChamomile may increase the amount of drowsiness caused by some herbs or supplements. Caution is advised while driving or operating machinery.\nIn theory, chamomile may increase the risk of bleeding when taken with other products that are believed to increase the risk of bleeding. Multiple cases of bleeding have been reported with the use of Ginkgo biloba, and fewer cases with garlic and saw palmetto. Numerous other agents may theoretically increase the risk of bleeding, although this has not been proven in most cases.\nChamomile may interfere with the way the body processes certain drugs using the liver\'s ""cytochrome P450"" enzyme system. As a result, the levels of other herbs or supplements may become too high in the blood. It may also alter the effects that other herbs or supplements possibly have on the P450 system. Patients using any medications should check the package insert and speak with a healthcare professional including a pharmacist about possible interactions.\nChamomile may have anti-estrogenic effects and interact with herbs and supplements like red clover or soy.\nBased on preliminary study, constituents in chamomile may alter blood sugar or blood pressure. Patients taking herbs or supplements that affect blood sugar or blood pressure should be cautious.\nChamomile may have anti-inflammatory effects. Theoretically, the use of chamomile with other anti-inflammatory herbs and supplements may have additive effects.\nChamomile may interact with herbs and supplements that act as cardiac depressants, cardiac glycosides, respiratory depressants, or spasmolytics.\nChamomile may also interact with antibacterial, antifungal, antihistamine, or diuretic herbs and supplements, as well as herbs and supplements used for high cholesterol, ulcers, diarrhea, or gastrointestinal disorders.\nThis information is based on a systematic review of scientific literature edited and peer-reviewed by contributors to the Natural Standard Research Collaboration (www.naturalstandard.com).\nNatural Standard Bottom Line Monograph, Copyright © 2011 (www.naturalstandard.com). Commercial distribution prohibited. This monograph is intended for informational purposes only, and should not be interpreted as specific medical advice. You should consult with a qualified healthcare provider before making decisions about therapies and/or health conditions.\nWhile some complementary and alternative techniques have been studied scientifically, high-quality data regarding safety, effectiveness, and mechanism of action are limited or controversial for most therapies. Whenever possible, it is recommended that practitioners be licensed by a recognized professional organization that adheres to clearly published standards. In addition, before starting a new technique or engaging a practitioner, it is recommended that patients speak with their primary healthcare provider(s). Potential benefits, risks (including financial costs), and alternatives should be carefully considered. The below monograph is designed to provide historical background and an overview of clinically-oriented research, and neither advocates for or against the use of a particular therapy.\nThe information in this monograph is intended for informational purposes only, and is meant to help users better understand health concerns. Information is based on review of scientific research data, historical practice patterns, and clinical experience. This information should not be interpreted as specific medical advice. Users should consult with a qualified healthcare provider for specific questions regarding therapies, diagnosis and/or health conditions, prior to making therapeutic decisions.\n- Aertgeerts P, Albring M, Klaschka F, et al. [Comparative testing of Kamillosan cream and steroidal (0.25% hydrocortisone, 0.75% fluocortin butyl ester) and non-steroidal (5% bufexamac) dermatologic agents in maintenance therapy of eczematous diseases]. Z Hautkr 2-1-1985;60(3):270-277.\n- Benetti C, Manganelli F. [Clinical experiences in the pharmacological treatment of vaginitis with a camomile-extract vaginal douche]. Minerva Ginecol 1985;37(12):799-801.\n- de la Torre MF, Sanchez MI, Garcia Robaina JC, et al. Clinical cross-reactivity between Artemisia vulgaris and Matricaria chamomilla (chamomile). J Investig Allergol Clin Immunol 2001;11(2):118-122.\n- Glowania HJ, Raulin C, Swoboda M. [Effect of chamomile on wound healing—a clinical double-blind study]. Z Hautkr 9-1-1987;62(17):1262, 1267-1271.\n- Hormann H, Korting H. Evidence for the efficacy and safety of topical herbal drugs in dermatology: part 1: anti-inflammatory agents. Phytomedicine 1994;1(2):161-171.\n- Ikram M. Medicinal plants as hypocholesterolemic agents. J Pak Med Assoc 1980;30(12):278-281.\n- Konig GM, Wright AD, Keller WJ, et al. Hypoglycaemic activity of an HMG-containing flavonoid glucoside, chamaemeloside, from Chamaemelum nobile. Planta Med 1998;64(7):612-614.\n- Kyokong O, Charuluxananan S, Muangmingsuk V, et al. Efficacy of chamomile-extract spray for prevention of post-operative sore throat. J Med Assoc Thai 2002;85 Suppl 1:S180-S185.\n- Maiche A, Grohn P, Maki-Hokkonen H. Effect of chamomile cream and almond ointment on acute radiation skin reaction. Acta Oncol 1991;30:395-397.\n- Maiche A, Maki-Kokkonen H, Grohn P. [Comparative trial of chamomile cream in radiotherapy]. Suomen Laakarilehti 1991;46(24):2206-2208.\n- Patzelt-Wenczler R, Ponce-P©schl E. Proof of efficacy of Kamillosan cream in atopic eczema. Eur J Med Res 2000;5:171-175.\n- Rycroft RJ. Recurrent facial dermatitis from chamomile tea. Contact Dermatitis 2003;48(4):229.\n- Saller R, Beschomer M, Hellenbrecht D, et al. Dose dependency of symptomatic relief of complaints by chamomile steam inhalation in patients with common cold. Eur J Pharmacol 1990;183:728-729.\n- Weizman Z, Alkrinawi S, Goldfarb D, et al. Efficacy of herbal tea preparation in infantile colic. J Pediatr 1993;122(4):650-652.\n- Wilkinson S, Aldridge J, Salmon I, et al. An evaluation of aromatherapy massage in palliative care. Palliat Med 1999;13(5):409-417.\nCopyright © 2011 Natural Standard (www.naturalstandard.com)\nCopyright © 2011 Natural Standard (www.naturalstandard.com)']"	['<urn:uuid:01bfb3ec-851d-4d8e-b851-b0be6fee1bd5>', '<urn:uuid:f9fc6c94-b923-49b6-b31d-6780d8cd7ea0>']	factoid	direct	short-search-query	distant-from-document	multi-aspect	novice	2025-05-13T04:02:16.770989	6	72	3487
