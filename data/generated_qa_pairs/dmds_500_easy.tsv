qid	question	answer	context	document_ids	question_factuality	question_premise	question_phrasing	question_linguistic_variation	question_multi-doc	user_expertise-categorization	generation_timestamp	question_length	answer_length	context_length
2	traditional kofte ingredients food poisoning risks	Traditional köfte is made with minced beef or lamb, onion, garlic, eggs, and spices like baharat, paprika, and cumin. These ingredients, particularly the meat, eggs and dairy products used in accompanying dishes like cacık, are considered high-risk foods for food poisoning. Special care must be taken when preparing köfte for vulnerable groups like pregnant women, young children, and the elderly. The meat must be properly stored at cold temperatures, handled with clean utensils to avoid cross-contamination, and cooked thoroughly to prevent foodborne illness. The traditional recipe involves kneading raw meat by hand, so proper hygiene practices are essential.	"['True bastions of Turkish cuisine: there’s a few of those. And köfte is most certainly one of them.\nIt’s also a bastion of our own personal diet.\nWhether we’re grabbing a quick street food snack, making a special effort to visit a specialist köfteci, dining in a restaurant or cooking at home,..\nThese Turkish meatballs are often on the menu!\nThe Köfte Experience\nKöfte is ingrained into the Turkish psyche.\nSpeak to any Turk and they’ll be able to tell you immediately where their favourite köfte place is.\nMany people in Fethiye have grown up eating meatballs from Köfteci İmadettin. But there are lots of other great places in which to delight in köfte, too.\nHundreds Of Köfte Recipes\nApparently, there are almost 300 different types of köfte depending on region of Turkey.\nThe cut of meat. Which fat is used for cooking. The shape of the meatball.\nThe spices. Whether there is a sauce. Or vegetables and other ingredients.\nAnd within all these different types of köfte, the köfteci will have their own special recipe. Usually kept secret of course.\nOur own classic Turkish meatball recipe isn’t secret. We’ve shared it with you below.\nNot Necessarily Meatballs\nWhen it comes to translations of köfte, it’s often described as Turkish meatballs.\nThis is all well and good when it’s meatballs that are on the menu, as they are in our recipe.\nHowever, köfte does not just mean ‘meatballs.’\nThe word derives from a Persian word, küfta. Which means to beat or to grind.\nTraditionally, çiğ köfte is made from raw meat. But, these days, it can usually be enjoyed by vegetarians and vegans, too, as bulgur wheat and spices take over the reins.\nBack To Those Meatballs\nBut, let’s get back to those classic Turkish meatballs. And the best ways to enjoy them…\nWhere To Eat The Best Köfte\nOh, wow, if you’re a köfte enthusiast, or if you want to know what the fuss is all about, you need to find yourself a respected köfteci.\nThere’s a lot to choose from, wherever you are in Turkey.\nA köfteci is the person who makes and sells the meatballs. That secret recipe, of course.\nYou’re usually going to find yourself in a tiny establishment – a köfte salonu – with possibly a few outdoor tables along the street as well as those inside.\nOr it could be a street stand.\nOr a van.\nIn these cases, you’ll get flimsy plastic stools or chairs to sit on, if you’re lucky.\nEither way, there’ll be a large griddle and loaves of Turkish bread stacked high. And you go to any of these places primarily to eat tasty grilled Turkish meatballs.\nYou can pay a bit more and order a plate of izgara köfte.\nThis will be a portion of griddled Turkish meatballs that usually come with charred peppers and tomatoes, a spicy sauce similar to Antep ezmesi. And an option of piyaz.\nNot forgetting the basket of bread, too.\nThe Half Bread\nOr you can go for the cheaper option and order a köfte ekmek.\nAhhh, the joy of köfte ekmek.\nThis is the best traditional burger!\nOkay, it’s a few little mini burgers on the best bread! The köfte yarım ekmek (half bread) is pure happiness.\nNo pretences, here. A whole loaf cut in half (yarım ekmek).\nThe most basic salad of lettuce and tomato and maybe a bit of shredded onion.\nA few meatballs thrown in straight from the griddle followed by a sprinkling of paprika, chilli and thyme.\nThis process is often carried out while the bread is placed on the griddle, too. A warm and toasted texture. Perfection!\nThat Köfte Aroma\nAnd, of course, it’s the aroma and the smoke caused by the griddled meatballs that drew you there in the first place!\nIt’s never going to fail!\nThe photo above is from a Fethiyespor match. Many is the time we’ve sat in the stands and watched the smoke from the sizzling meatballs on the griddle drift across the pitch.\nIf we weren’t tempted to order a köfte half bread before, we are now!\nFond Köfte Memories\nThe best köfte is about the memories that go with it.\nWe’ve eaten at some of Turkey’s most famous köfte salons…\nBoth places are good.\nBut our absolute best memory of köfte is of stumbling into Durak Rumeli Köfte Salonu in Edirnekapı in Istanbul.\nWe were en route to Kariye Museum. It was a cold wet day. One of those days where you start to wish you’d not bothered setting out!\nWe spotted the köfte salonu.\nInside, it was a tiny box of a room, plastic bottles of water stacked to the ceiling, gaudy over-processed images of famous sights around Turkey. And a makeshift table for two with patio chairs to sit on.\nThe outdoor tables were not an option. We were wet and cold!\nWe had to squeeze past the water bottles to get to the table. There, we were served up the best köfte by a friendly köfteci who was wrapped up in an overcoat and woolly hat.\nFood presentation was clearly not his forte. But you don’t come to places like this for pretty-plated presentation.\nThe meatballs were served with a fiery tomato sauce that we’ve never managed to replicate to this day. And we left there feeling warm and satisfied and ready to take on the rest of our day.\nSo those are the best köfte moments…\nStumbling into an unfamiliar neighbourhood köfte joint on a cold, wet day.\nSitting in the football stands with your half bread – a part of your matchday ritual. Darting into a roadside joint in the Antalya province to enjoy your grilled meatballs with the area’s famous piyaz.\nKöfte is all about the experience!\nClassic Köfte Recipe – Our Homemade Turkish Meatballs\nOkay, let’s get to it and make a good old classic Turkish köfte meal.\nBecause buying ready-made meatballs from the shops will just never be the same again once you’ve started to make your own.\nMaking your own köfte is all about experimentation. No two meatball recipes are the same.\nSo you can decide which spices you prefer and how much to use. You can also choose your own texture.\nDo you want to use onions, eggs and breadcrumbs?\nActually, we don’t use breadcrumbs. We opt instead for chia seeds.\nThis is because they have a high nutritional content and they’re also pretty good at absorption so they make a good substitute.\nYou can’t taste them and they soften. So, by the time your köfte is ready to eat, you won’t even know they’re there.\nMaking your own köfte is all about not being afraid to get your hands in there to knead your meat and spices together.\nAnd then, of course, you need to create your little meatballs.\nIt doesn’t need to be an exact science. Just try to get your meatballs roughly the same size by rolling a golf ball size amount of mixture between your hands.\nThen pat it down to create a circular patty.\nWe like to leave our homemade köfte to chill in the fridge for an hour or so. This makes them more firm so they stay together easier when cooking.\nClassic Köfte Recipe – Homemade Turkish Meatballs\n- 500 g minced beef or lamb\n- 1 onion peeled & grated\n- 1 clove garlic peeled & grated\n- 1 egg beaten\n- 1 tbsp chia seeds\n- 2 tsp baharat\n- 1 tsp paprika\n- 1 tsp ground cumin\n- 1 tsp chilli optional\n- salt & pepper to season\n- Place all of your meatball ingredients into a bowl or onto a large plate.\n- Now use your hands to mix and knead the mixture.\n- Knead the köfte mix for a few minutes.\n- Now take a golf ball size of the mixture and roll into a ball in your hands.\n- Pat it down to form a flat, circular köfte.\n- Keep doing this until you have used all the meat mixture.\n- You should end up with roughly 20 köfte meatballs.\n- If you have time refrigerate the meatballs for at least 30 minutes to firm them up.\n- When you’re ready to cook your köfte, heat a non-stick frying pan on a medium to high heat.\n- Fry your köfte in batches for around 5 minutes on each side until brown.\n- Rest your köfte on kitchen paper for a couple of minutes before serving.\n- We use chia seeds in our köfte because of their nutritional content but you can substitute them with breadcrumbs if you like.\n- There is no one true classic köfte recipe so feel free to adjust spices and seasoning to your own taste.\n- We have said this köfte recipe serves 5 people. This is assuming each person has one serving of 4 köfte each and an accompaniment.\n- To make köfte, lamb or beef can be used. Some butchers will mix the two for you.\nAs with all of our recipes, the calories are meant as a rough guide only. In Turkey, you can buy your minced beef with different levels of fat content.\n- If youı are using lean minced beef or lamb, add a small amount of sunflower oil to your pan before adding the köfte.\n- If you are barbecuing your köfte and you are using standard minced beef or lamb, wait until your barbecue has just passed its highest heat level before placing the köfte onto the grill. The fat in the köfte can cause them to set alight.\nWhen you are ready to cook your Turkish meatballs, how will you do it?\nGrill (ızgara köfte)? Barbecue? Turkey loves to barbecue and simple köfte is, more often than not, on the menu.\nIf we’re not barbecuing, we like to get a shallow frying pan quite hot and then cook our meatballs for a few minutes on each side.\nOn this particular occasion when we did our homemade köfte recipe, it was a hot and sunny spring day.\nNew potatoes and semizotu (purslane) were in abundance at the local markets.\nSo as an accompaniment to our köfte, we made a mix of two salad recipes:\nA classic potato salad and a summery semizotu salatası. The two went together perfectly.\nOther common accompaniments to these classic Turkish meatballs are piyaz. We love Antalya-style piyaz!\nOr a hot and spicy ezme?\nOr a cooling cacık.\nOr a refreshing choban salad (shepherd’s salad).\nHowever you choose to enjoy your homemade köfte, we’re sure you’re going to love it!\nOther Types Of Köfte Around Turkey\nAlmost 300 types of köfte around Turkey. That’s what we said at the beginning of this article. 291, to be precise.\nWonder if anyone could list all of those? We certainly couldn’t!\nOn reading this stat, we did a quick brainstorm of the different köfte recipes we’re aware of.\nThe storm of brain quickly petered out at a not-very-grand total of 24.\nStill, it’s not bad…especially as some of the subsequent research suggestions we’ve seen could be considered a tad flimsy…\nHamburger köfte, for instance! A burger is a köfte.\nAnyway, we have some of those other types of köfte and köfte recipes on the blog.\nAs well as our base of homemade Turkish meatballs above, let’s start with another famous köfte recipe; Izmir Köfte.\nThis is a dish Barry makes regularly.\nOther köfte recipes on the blog are kadın budu. A dish where the rice makes the meatball almost velvety on the inside whilst the egg coating gives a crisp exterior.\nAnd, of course, Tekirdağ Köftesi. Another famous regional variety.\nMisket köfte is shaped into little rounded golf balls and served plain or in sauces. We love it served as ekşili köfte in some of our favourite local lokantas.\nWhether we will ever get to sample all of Turkey’s different meatball recipes, we don’t know. We think we’ve tried over 20 types of köfte so far.\nWe’re more than happy to try even more!', 'While grocery shopping for the Father’s Day weekend, it is important to follow proper food non-contamination and safety procedures. Keep raw meats separate from ready to eat foods and produce. Remember to wrap your raw meats in a plastic bag before placing them into your cart.\nSome people are more at risk of food poisoning than others. Vulnerable groups include pregnant women, young children, the elderly and anyone with an illness. Take special care when buying, storing and preparing food for these people.\nChoose your food carefully\nEven though food producers and sellers follow food safety laws and proper packing and storage procedures, accidents and mistakes happen which can affect the quality of your food. Choose food carefully when shopping and never buy:\n- Dented, swollen or leaking cans or containers\n- Products with damaged or imperfect packaging\n- Cracked or dirty eggs\n- Chilled or frozen foods that have been left out of the refrigerator\n- Products that are soiled or moldy\n- Ready-to-eat foods left uncovered on counters\n- Hot food, like takeaways, which are not steaming hot\n- Anything where you have doubts about the quality\n- Learn about cross contamination, cold and hot food safety, best practices for personal hygiene, and foodborne illnesses.\n- Food Manager ANSI Certification: SALE $99.00 - Valid in all States\n- Food Handler ANSI Training for only $7.00!\n- Enter Promo ""train10off"" at Checkout\nPlan your shopping trip\nSome hints for shopping safely:\n- Always pick up your frozen or chilled foods towards the end of your shopping trip.\n- Buy hot chickens and other hot food later in your trip and keep it separate from cold food.\n- Prevent meat, chicken or fish juices leaking onto other products.\n- Check that the staff use separate tongs/utensils or methods when handling different food types if you are buying from a deli.\n- Wash your reusable shopping bags regularly, or if they become soiled by food liquids.\nTake special care with high-risk foods\nFood-poisoning bacteria grow and multiply on some types of food more easily than on others. These high-risk foods include:\n- Raw and cooked meat, including poultry such as chicken and turkey, and foods containing these, such as casseroles, curries and lasagna\n- Dairy products, such as custard and dairy based desserts like custard tarts and cheesecake\n- Eggs and egg products, such as quiche\n- Small goods such as hams and salamis\n- Seafood, such as seafood salad, patties, fish balls, stews containing seafood and fish stock\n- Cooked rice and pasta\n- Prepared salads like cole slaws, pasta salads and rice salads\n- Prepared fruit salads\n- Ready to eat foods, including sandwiches, rolls, and pizza that contain any of the food above.\nHigh-risk foods should be kept out of the temperature danger zone (5 °C to 60 °C). Keep food at 5 °C or below or at 60 °C and above. When you buy high-risk foods, try to minimize the time they spend in the temperature danger zone by packing them properly and taking them home immediately.\nCheck the dates on the packaging\nAlways check the date marked on perishable foods, especially chilled or frozen items. A ‘use-by’ date shows the date by which a product should be consumed. It should not be sold after this date. A ‘best before’ date indicates the date until which the food will remain at its best quality. It can be sold after this date.\nTransporting food home\nIf you have purchased hot, chilled or frozen foods, you should get them home as quickly as possible. For trips longer than about 30 minutes, or on very hot days, it’s a good idea to put chilled or frozen foods in a cooler or insulated bag to keep food cold. Once you arrive home, immediately put chilled or frozen foods into your fridge or freezer.\nHome Food Storage Procedures\nYou should have a system for storing your food. It is important to immediately place your cold items in the refrigerator or freezer to avoid them getting warm enough for bacteria to grow.\nWhen you place items in the fridge, you should be able to place your raw meat, poultry and seafood on the bottom shelf of the refrigerator where it will not drip on ready-to-eat items. To further avoid cross-contamination from raw juices, place your raw meat on a plate or similar container that will prevent dripping.']"	['<urn:uuid:001884ec-61a4-42f0-a44b-46bd41f53312>', '<urn:uuid:50580576-4e8d-46c8-a3f0-c27de002303f>']	open-ended	direct	short-search-query	similar-to-document	multi-aspect	novice	2025-05-01T22:47:46.423955	6	98	2742
3	I'm interested in environmental organizations in North America - can you tell me what the Commission for Environmental Cooperation does and when it was created?	The Commission for Environmental Cooperation (CEC) was established in 1994 by the governments of Canada, Mexico and the United States. It brings together various stakeholders including the general public, Indigenous people, youth, NGOs, academia, and the business sector to seek solutions to protect North America's shared environment while supporting sustainable development. The CEC is governed and funded equally by the environmental agencies of Canada, Mexico, and the United States.	['Richard A. Morgan announced as new Executive Director of the North American Commission for Environmental Cooperation (CEC)\nMontreal, 5 July 2019—The Council of the Commission for Environmental Cooperation (CEC) today announced the appointment of Richard A. Morgan as the ninth Executive Director of the CEC Secretariat.\nRichard A. Morgan is a former Commissioner for the International Joint Commission (IJC). During his time at the helm of the Canadian section of the IJC, he was responsible for overseeing projects that affect the level and flow of water across the Canada-US border and investigations of transboundary issues. He has over 30 years’ experience in public affairs, business and government administration in both the public and private sector.\nBorn in Sherbrooke, Quebec, and raised in Montreal, Richard A. Morgan brings to the CEC a breadth and depth of experience in public policy, international relations and change management. He began his career in the political arena as the executive assistant to the Prime Minister of Canada immediately after graduating in business administration from the University of Ottawa in 1986. He later became Director of Operations in the Prime Minister’s Office, assuming the leadership of large multidisciplinary teams and initiatives and was also responsible for the organization of major international summits.\nFrom 1994 to 2014, Morgan worked as a strategic planning, communications and public affairs executive in management consulting and public relations. He most recently completed a four-year term with the International Joint Commission, where he was appointed by the Government of Canada to serve as Commissioner.\nCanadian Minister of Environment and Climate Change Catherine McKenna, as the new Chair of the CEC Council, welcomed Morgan to the position.\n“Mr. Morgan is taking on this leadership role as the CEC celebrates its 25th year of successful environmental cooperation across North America. On behalf of the Council, we look forward to working with him to continue to advance environmental and trade priorities, working with governments, local and Indigenous communities, academia, business and youth”, said Minister McKenna.\nRichard A. Morgan will succeed CEC Executive Director César Rafael Chávez who concludes his three-year term with the CEC on July 15. In its 2019 Ministerial Statement, the CEC Council thanked Chávez for his valuable contribution and commitment in leading the CEC Secretariat.\nAbout the CEC\nThe Commission for Environmental Cooperation (CEC) was established in 1994 by the governments of Canada, Mexico and the United States through the North American Agreement on Environmental Cooperation, a parallel environmental agreement to NAFTA. As of 2020, the CEC is recognized and maintained by the Environmental Cooperation Agreement, in parallel with the new Free Trade Agreement of North America. The CEC brings together a wide range of stakeholders, including the general public, Indigenous people, youth, nongovernmental organizations, academia, and the business sector, to seek solutions to protect North America’s shared environment while supporting sustainable development for the benefit of present and future generations\nThe CEC is governed and funded equally by the Government of Canada through Environment and Climate Change Canada, the Government of the United States of Mexico through the Secretaría de Medio Ambiente y Recursos Naturales, and the Government of the United States of America through the Environmental Protection Agency.']	['<urn:uuid:dd1b1a2e-de6c-4333-a242-62b476f0231a>']	open-ended	with-premise	verbose-and-natural	similar-to-document	single-doc	novice	2025-05-01T22:47:46.423955	25	69	528
4	As a mental health professional concerned with comprehensive care approaches, I'm interested in understanding how modern healthcare facilities handle both initial assessments and follow-up care for mental health and addiction patients. Can you explain the typical patient journey from assessment to treatment completion?	The patient journey typically begins with an assessment conducted by a Master's-level licensed counselor, taking 60-90 minutes. This initial evaluation ensures admission to the appropriate program and can be accessed through walk-in services or scheduled appointments. Following assessment, patients may begin treatment within approximately one week. For acute cases, facilities like the Psychiatric Emergency Service provide immediate crisis management and assessment, with patients either being discharged or admitted to inpatient mental health units. The typical length of stay in acute units is 7-10 days, after which patients may receive follow-up care through outpatient services or community programs. The care continuum includes various options like outpatient counseling, intensive outpatient programs, and residential treatment. Additionally, modern healthcare facilities now offer virtual care options through video conferencing and telephone support, making services more accessible and reducing travel needs for patients.	['Psychiatric Emergency Services (PES)\nThe Psychiatric Emergency Service is a dedicated four-bed unit in the Emergency Department at the St. Catharines Site. The PES team provides crisis management, psychiatric assessment and treatment to people presenting with an emergency. Individuals are either discharged from PES or admitted to one of our Acute Inpatient Mental Health units.\nPES supports mental health and addictions care in the Emergency Departments at the Greater Niagara General Site and the Welland Site through the use of video conferencing.\nSexual Assault and Domestic Violence (SADV)\nThe Sexual Assault and Domestic Violence team provides confidential and individualized treatment to people who have experienced a sexual assault or are victims of intimate partner abuse. The team consists of nursing for the immediate emergency care following an assault and the social work team who provide trauma counselling. Click here for more information about SADV services across the province.\nThe PICU provides a higher level of observation and care for patients who require more intensive care. The unit balances safety, low-stimulation and therapeutic approaches to care for individuals with a higher level of need.\nPatients may be discharged directly from PICU with follow-up in the community or in the Outpatient Program at the hospital. Some patients may require a longer length of stay in one of our Acute Inpatient Mental Health units.\nThese units provide 24-hour psychiatric assessment, short-term treatment and stabilization for adults who cannot be fully treated on an outpatient basis. Most admissions occur through the Emergency Department. The typical length of stay on an acute unit is approximately 7 to 10 days, and patients may be referred for a longer stay depending on their unique situation or may be discharged with follow-up plans either in the community or in the Outpatient Program at the hospital.\nThis unit provides more specialized care for patients requiring a longer period of care. The focus is on assisting individuals to improve functional abilities while their treatment plan is being further supported to promote continued wellness after discharge. Follow-up care is organized in the community or at the hospital, based on individual needs.\nThe Transition to Independent Unit is used to support a step-down approach to discharge that allows individuals to live in an independent environment that is a bridge between inpatient care and community. The focus during the brief Transition to Independent Living stay is on community reintegration and focused rehabilitation goals.\nThe CL Service provides mental health and addictions consultation to medical, surgical and critical care areas across Niagara Health. Individuals are provided with follow-up care, which may include discharge to the community with initiation of referrals or admission to inpatient mental health when medical issues are stabilized.\nNiagara Health offers outpatient mental health services at the St. Catharines Site, Greater Niagara General Site and Welland Site. Typically, outpatient services are for individuals needing short- and longer-term assessment, treatment and support. Referrals come from community health care providers, family physicians, the Emergency Department or from inpatient services.\nNiagara Health is expanding our ability to provide services from a distance. With the COVID pandemic, it has become a necessity. Virtual care will be a bigger part of our services moving forward.\nNiagara has an excellent system in place to provide virtual appointments. This includes, using Ontario Telemedicine Network to connect people through video with their healthcare providers, therapeutic groups and telephone supports - providing more prompt care and reducing the need for patients to travel.\nTo ensure you are referring to the most appropriate program that best suits the needs of the client, please review the outpatient services provided below:\nNiagara Health works with many mental health and addictions community partners...learn more.\nPort Colborne New Port Centre\nPhone: 905-378-4647 ext. 32542\nDouglas Memorial Site in Fort Erie\nPhone: 905-378-4647 ext. 50102\nSt. Catharines (264 Welland Avenue)', 'Assessment Is the First Step to Help with Addiction\nBefore treatment can begin, an assessment will be conducted with you and/or your loved one at Meridian HealthCare’s Assessment Department by a Master’s-level licensed counselor. The Assessment is a vital part of beginning treatment and ensures admission to the appropriate program. Our welcoming Assessment staff will greet you as you enter our main location at 527 North Meridian Road Road or our Warren location at 320 High Street Northeast and will guide you through the assessment process.\nMeridian offers walk-in assessments and scheduled appointments. Walk-ins are offered Monday-Friday 8:00 am–10:30 am. No appointment is needed as long as you come to Meridian between those hours. Walk-ins are first-come, first-serve and the assessment takes approximately 60-90 minutes. If you prefer to schedule an appointment, an Assessment Case Manager will speak with you and schedule the appointment at your convenience.\nIf you have questions prior to the assessment, a free confidential consultation can be conducted at Meridian HealthCare’s Assessment Department. Many of your questions can be addressed over the phone with an Assessment Case Manager if you contact 330-270-5332 or 330-270-5325 for the Youngstown location and 330-318-3881 for the Warren location. You can also submit your questions online by visiting our website at www.MeridianHealthCare.net.\nMeridian Main Campus\n527 N. Meridian Road\nYoungstown, OH 44509\n320 High Street, NE\nWarren, OH 44481\nQ: What is an assessment?\nA: An assessment is a process completed by a Master’s-level licensed clinician. The assessment is a conversation between you and the Assessment Counselor to better understand concerns you may have and the reason you’re seeking treatment. Our Assessment Counselors utilize a person-centered approach which is non-judgmental and personable.\nQ: What services does Meridian HealthCare offer?\nA: Meridian HealthCare offers a wide variety of services. We have many treatment levels of care, including Outpatient Counseling, Medication Assisted Treatment, Co-Occurring Treatment, Intensive Outpatient Counseling, Day Treatment and Residential Treatment.\nQ: How quickly can I get started with treatment after the assessment?\nA: The time between your assessment and admission will vary based on the program and availability. We strive to have you begin treatment within one week following the assessment.\nQ: What is the cost of the assessment, and how can I pay for treatment?\nA: Meridian HealthCare accepts Medicaid, Medicare, private insurance and self-pay, which is based on a sliding fee scale. We also offer assistance with obtaining Medicaid through working with a Meridian Case Manager along with Job and Family Services. In addition, there is a limited amount of funds available for residents without a payer source based on your location and program assignment. The goal is to help you obtain the most appropriate, comprehensive care in the most cost-effective manner. If you have questions about affording treatment services, please contact an Assessment Case Manager at 330-270-5332 or 330-270-5325 for the Youngstown location or 330-318-3881 for the Warren location.\nQ: Will I have to do a drug screen?\nA: You will have to provide a drug screen if you are seeking treatment for substance use concerns. Our lab staff provides a comfortable environment for the screen that will help put your concerns/discomfort at ease.\nMeridian Receives Donation from Trustmark Insurance\nMeridian HealthCare recently received a generous donation of $3,000 from The Trustmark Foundation. The Trustmark Foundation is part of Trustmark Insurance, which focuses on helping people increase well-being through better health and greater financial security. Trustmark has a local office in the Mahoning Valley, located in Boardman, OH.\nEach year, Trustmark pledges a percentage of pre-tax earnings to support our local communities. Trustmark’s unique, two-level service commitment involves associates working as individuals and together with the company to give back to the community and improve the quality of life for all.\nThe Trustmark Foundation, established in 1984, actively supports associate volunteerism through program donations and volunteer grants. In 2015, the Foundation distributed nearly $1.1 million in cash and gifts-in-kind. Foundation grants and programs directly support the United Way, community health, safety, education, and urban and cultural enrichment.\nThe local branch of Trustmark Insurance selected Meridian as one of their 2016 recipients for the work they do in the community!\nFind out more about Trustmark Insurnace – http://www.trustmarkcompanies.com/\nWhy we need to focus on Prevention, and how you can help\nMeridian HealthCare offers a full range of addiction treatment services. But as Meridian CEO Larry Moliterno says, they are also taking the lead in our community in Prevention efforts, to stop addiction before it starts. There are steps families can also take to help in this effort.\nThe Face of Addiction…and the Faces of Recovery\nby Larry Moliterno\nWhen I ask people what they think the “Face of Addiction” looks like, I typically get the same answers. They tend to think of a down-and-out man or woman living under a bridge, or walking the streets aimlessly looking for their next fix. They may think of someone robbing an older woman in the grocery store parking lot, or a gang of kids smoking in a car.\nWe think like this because this is the way addiction is typically portrayed. In movies and on television, we see those struggling with drugs and alcohol as either poor and willing to do anything to get their hands on drugs — or else as really wealthy and scheming around their use.\nBut what addiction really is…is a disease that affects everyone. Two-thirds of American families are touched by addiction. Addiction affects the parents cheering next to you at your son’s soccer game, the young girl working diligently to get into a good college, the army veteran looking for a steady job, and the mom dropping her young kids off at pre-school.\nAddiction is everywhere and does not discriminate. Chief Development Officer for Subway Don Ferryman; Actress Jamie Lee Curtis; Actor Robert Downey Jr.; Chief of Staff at SAMSHA (Substance Abuse and Mental Health Services Administration) Tom Coderre; Singers Demi Lovato and Sir Elton John; and Best-Selling Author William Cope Moyers —all have dealt with addiction themselves, and they aren’t the typical “Face of Addiction.”\nThe examples I gave above aren’t just stories I use — they’re people who have gone through treatment and fight for their recovery every day.\nPrescription drug use has been on the rise for the last few decades. We’ve discussed that here before. In the suburbs — where people typically think addiction is not a problem — highly educated and more affluent households are more likely to have access to prescription pain medications, including frequently used drugs such as opioids, and stimulants such as oxycontin and Adderall. These drugs can lead to heroin use.\nAccording to SAMHSA, the number of teenagers between the ages of 12 and 17 introduced to heroin has grown by 80 percent since 2002. The vast majority of teenagers who turn to heroin (close to 90 percent) are white and live in the suburbs — a far cry from what is perceived to be the “Face of Addiction.”\nThis point of this article is to not to suggest that you take your family and friends and go to some remote location where drugs can’t find you. It’s to let you know that addiction isn’t some far-fetched idea that only affects “those people.” We need to recognize that, at any time, anyone can be affected — so we must begin to work towards the goals of treatment for all and prevention for all our kids.\nAt Meridian, we will continue to treat as many people as we can — no matter what walk of life they come from. But we also address the problem through prevention and stopping addiction before it starts, with initiatives such as the PANDA Leaders Club, Families Who Know and our Community Education programs.\nThe people who I named earlier are all people who struggled with an addiction. But they are now the Faces of Recovery. They are successful in their careers and have continued to advocate for treatment. This is something that we in the recovery world celebrate!\nMeridian’s CEO Participates in Trivisonno Show Townhall on Heroin\nMeridian’s President/CEO, Larry Moliterno had the opportunity to participate in WTAM1100’s Mike Trivisonno Show – Townhall on Heroin with Attorney General Mike DeWine. The Triv Show and Ohio AG Mike Dewine selected a distinguished panel of experts to discuss ways to combat the heroin epidemic. The event was divided into three segments, including a law enforcement perspective, treatment/recovery perspective and a Q&A session.\nTo listen to the entire show, please visit Mike Trivisonno Show Townhall on Heroin\nCrossroads Comedy Rivalry Crushes It!\nMore than $18,000 was raised at the Crossroads Comedy Rivalry on October 20 to help fund Addiction Prevention, Education and Treatment/Recovery at Meridian HealthCare. And this event really put the “FUN” in fundraising. No doubt about it, it was a hilarious and successful evening.\nAfter the show, several of the comedians paused to chat with Meridian’s CEO and share a few more laughs.\n(L–R above: Comedians Mike Wysocki and Sean Collier, Meridian CEO Larry Moliterno, and comedian Aaron Kleiber.)\nYSU’s Jambar “Clash of Comedy: Cleveland Versus Pittsburgh” highlights Meridian’s Comedy Fundraiser\nA Jambar story entitled “Clash of Comedy: Cleveland Versus Pittsburgh” highlights Meridian’s Comedy Show Fundraiser in October.\nVindicator “Comedians from rival cities will share stage” features Meridian’s upcoming fundraiser\nA Vindicator story entitled “Comedians from rival cities will share stage” features Meridian’s upcoming fundraiser, which will raise money for prevention and recovery in the Valley.\nProtecting Our Children from Addiction – Part 3\nby Larry Moliterno\nThe last few months we’ve been discussing why, as a community, we don’t protect our children from addiction like we protect them from car accidents, sunburn, and other diseases/safety hazards. But how do we start to do this?\nWe first have to remember that this is not just a school problem, it’s a community problem. School-based efforts should be made in context with other programs and support in the community.\nStudies show that strategies work best when they are integrated and reinforce each other — at home, in schools, within the community, and in the media. So if we bring the whole community together, we’ll see a real impact.\nWhat can schools do? Schools can institute more prevention programs — in a more formal educational model, and in a less formal peer-driven model like Meridian’s PANDA program. These programs have been proven to be effective in not only reducing drug use, but also in reducing negative behaviors. Schools can also create more opportunities for extracurricular activities in addition to sports. Students taking part in these extracurricular activities are less likely to be involved in drug use. Schools can look at truancy and behavioral issues as an opportunity to get to the root of the problem — shifting the focus from punishing bad behavior toward prevention and providing help and support.\nWhat can parents do?\nBelieve it or not, parents — your children are listening to you. When kids who don’t drink were asked who was their number-one influence in making that decision, they said their parents. Take advantage of that time you have with them to talk with them — and more importantly, listen. Get to know what they want out of life, their dreams and aspirations.\nWhat can legislators do?\nLegislators can help enact laws that keep drugs out of young people’s reach and help remove the barriers for people trying to access treatment. Legislators can also help restore the Safe and Drug-Free School dollars that have been taken away from our schools.\nWhat can religious leaders do?\nReligious leaders can use the power of the pulpit to raise awareness of the addiction problem in our community and help connect people to community resources.\nWhat can medical professionals do?\nRoutine annual medical visits are an opportunity to identify mental health and drug use issues. We need more medical professionals to recommend these screenings, which will help identify problems like depression or drug use early on.\nWhat can business leaders do?\nBusiness leaders can create more mentoring opportunities for kids to get involved locally. Being involved helps kids develop a sense of purpose and real hope for their future.\nWhat can law enforcement do?\nLocal law enforcement can create more juvenile diversion programs to help families who have a child who is just beginning down the wrong path. These programs will help address the problem before it gets worse.\nWhat can treatment providers do?\nTreatment providers should be addressing the whole person, rather than just focusing on his or her drug use or mental health illness. Let’s build up that recovery capital that helps prevent any future use and work hard to provide immediate access into treatment.\nWhat can the media do?\nThey can help us tell our story and help celebrate the positive results of the community’s efforts.\nThat’s real prevention.\nIs it going to be easy?\nBut if we invest our skills, our resources and our energies into working together to protect our kids — in a true, diverse, community-based prevention strategy —we’ll be successful, and we all will benefit.\nProtecting Our Children from Addiction – Part 2\nby Larry Moliterno\nWe know that we’re struggling with addiction in our community at epidemic levels. But is it possible to prevent addiction before it happens? Last month, I discussed all the safety precautions we routinely put in place to keep our children safe; yet we seem to lack in funding and resources when it comes to preventing our kids from addiction.\nIn order to fully understand how, as a community, we can protect our kids — we need to understand why kids use in the first place. Part of it is physiological. The prefrontal cortex of the brain isn’t fully developed until around age 21. This is the part of the brain that allows humans to understand consequences and make rational decisions. That’s why kids are more likely to be impulsive and take risks.\nConsider this too: when something hurts, what do we do? We take a pill, and the pain goes away. Why would kids think it’s any different to stop emotional hurt? Take a pill, and it will go away.\nAccording to SAMHSA (the Substance Abuse and Mental Health Services Administration), there are many risk factors that influence a person’s chance of developing a mental health or substance use disorder. Effective prevention focuses on reducing those risk factors, and strengthening the protective factors that are most closely related to the problem being addressed.\nRisk factors are characteristics at the biological, psychological, family, community or cultural level that precede and are associated with a higher likelihood of negative outcomes. There are risk periods that increase the likelihood of substance abuse as well as other risky behaviors.\nFor example, changes in physical development, social change, relationships, family dynamics, change in responsibility, and academic pressure can all be considered either a risk period or a risk factor. These risk periods/factors have a lot of sources, including personal, family and friends, school and the community.\nWhen one of these risk factors arises, instead of assuming our kids are fine or punishing them for acting out, we need to take it as an opportunity to understand why he or she is acting this way. Maybe he’s upset because something is going on at home…maybe he’s hurting because he was rejected by the girl he has a crush on…maybe she’s embarrassed by the acne on her face. If we don’t find the root cause of the behavior, we could be making the problem worse.\nAlong with the risk factors, we also recognize that there are protective factors in kids’ lives that reduce the likelihood of substance use and risky behavior. Protective factors are characteristics associated with a lower likelihood of negative outcomes; they can also reduce a risk factor’s impact.\nSome examples of protective factors are developing social skills and coping abilities, finding a strong adult role model who demonstrates what a healthy relationship should look like, and getting involved in extracurricular activities to create a sense of belonging and worth. Another is a child being recognized and rewarded for his or her contributions, which helps build self-esteem.\nProviding these protective factors is not just the responsibility of schools, but of the entire community. Simply put, we need to identify kids in risk periods, engage them, and provide more opportunities to take advantage of protective factors.\nSo how do we do this? Next month I’ll explain how our community — including schools, parents, legislators, religious leaders, medical professionals, business leaders, law enforcement, treatment providers, and even kids — can come together to help protect our kids from addiction.']	['<urn:uuid:396e3028-f0a8-40ba-bd3c-bee87fa30fbb>', '<urn:uuid:ed1d2c02-e77d-4263-92ac-ddd92bafda47>']	open-ended	with-premise	verbose-and-natural	similar-to-document	three-doc	expert	2025-05-01T22:47:46.423955	43	137	3404
6	doctor measured my blood pressure today got numbers like 110 70 what do these blood pressure numbers actually mean	A blood pressure reading consists of two numbers (like 110/70). The first number represents the pressure at its highest point, which occurs when the heart contracts and forces blood into the arteries. The second number shows the lowest point of pressure, which happens when the heart relaxes to refill with blood. Blood pressure is defined as the force of blood pushing against the walls of the blood vessels.	"['Presentation on theme: ""The Circulatory System In this lesson, you will Learn About… The functions of the circulatory system. How blood circulates through the body. How to keep.""— Presentation transcript:\nThe Circulatory System In this lesson, you will Learn About… The functions of the circulatory system. How blood circulates through the body. How to keep your circulatory system healthy.\nThe Circulatory System The Vocabulary terms for this lesson are : Circulatory system. Circulatory system Artery. Artery Vein. Vein Capillary. Capillary Pulmonary circulation. Pulmonary circulation Systemic circulation. Systemic circulation Plasma. Plasma Blood pressure. Blood pressure\nYour Heart and Blood Vessels The circulatory system is the group of organs and tissues that transport essential materials to body cells and remove their waste products. The circulatory system is also called the cardiovascular system. It consists of the following: The heart The blood vessels The blood\nYour Heart and Blood Vessels (cont’d.) The heart is composed of cardiac muscle. It pumps blood throughout the network of blood vessels. The blood flows through three types of vessels: Arteries Veins Capillaries\nHow Circulation Works Two types of circulation work together to keep body cells supplied with nutrients and free of waste products. Pulmonary circulation carries the blood from the heart, through the lungs, and back to the heart. Systemic circulation sends oxygen-rich blood to all the body tissues except the lungs.\nPulmonary and Systemic Circulation A.The left atrium receives oxygen-rich blood from the lungs and sends it to the left ventricle. B.The left ventricle pumps oxygen-rich blood to the aorta, the body’s largest artery. C.The aorta carries blood to branching arteries that take it to capillaries. Nutrients and oxygen travel through the walls of the capillaries to cells. The cells send back wastes such as carbon dioxide. D.The capillaries deliver this low- oxygen blood to veins. E.The veins carry the blood back to the right atrium of the heart. F.The right atrium sends the blood to the right ventricle. This part of the heart sends the low-oxygen, high- carbon dioxide blood to the lungs. G.In the lungs, carbon dioxide is removed from the blood and is exhaled out of the body. Oxygen is inhaled and added to the blood, and blood is sent back to the heart through the pulmonary vein to the left atrium. Then the process begins again.\nWhat’s in Your Blood Over half the volume of blood is plasma. The rest of the volume of blood is made up of three kinds of cells:plasma Red blood cells White blood cells Cell fragments, called platelets\nWhat’s in Your Blood (cont’d.) The different parts of the blood carry out several important functions in the body, such as: Transporting various substances through the body. Protecting the body from harm.\nParts of the Blood Red Blood Cells Red blood cells, which look like little disks or doughnuts, carry oxygen from the lungs to all body parts. White Blood Cells White blood cells fight infection in the body. Some white blood cells actually create substances that destroy foreign cells. Others find and devour disease-causing invaders such as viruses. Plasma The three types of blood cells are suspended in plasma, a liquid that carries nutrients to cells. It also carries hormones, which are chemicals that regulate body processes. In addition, plasma transports wastes to the lungs and kidneys for removal. Platelets Platelets are the smallest type of blood cell. Platelets help blood to clot, or thicken, at the site of a wound.\nBlood Pressure When you have a medical checkup, the nurse or doctor may take your blood pressure. Blood pressure is the force of blood pushing against the walls of the blood vessels.\nBlood Pressure (cont’d.) A blood pressure reading consists of two numbers, usually written in the following way: 110/70 The first number is the pressure at its highest point, when the heart contracts and forces blood into the arteries. The second number is the lowest point of pressure, when the heart relaxes to refill with blood.\nBlood Types All blood is not the same. The four types–A, B, AB, and O–are classified according to the type of red blood cells they contain. Some blood types are compatible and can coexist in a person’s body. Compatible blood types can be mixed safely.\nBlood may also contain a substance called an Rh factor. People who are Rh-positive have this substance. Rh-negative blood does not contain this substance. People with Rh-positive blood can receive blood from people who are either Rh- positive or Rh-negative. Rh-negative people can receive blood only from people who are Rh-negative.\nCaring for Your Circulatory System You can take action now to care for your circulatory system throughout your life. Eat a balanced diet that is low in fats. Learn to manage stress. Avoid smoking. Participate in activities that build heart and lung endurance.\nReviewing Terms and Facts 1.List the two types of circulation. Pulmonary circulation Systemic circulation\nReviewing Terms and Facts 2.Define the term circulatory system. The circulatory system is the group of organs and tissues that transport essential materials to body cells and remove their waste products.\n3.Why is it necessary for hospital workers to know patients’ blood types? Thinking Critically It is important to know the patients’ blood type because incompatible blood types cannot be mixed together. If blood types that are not compatible are combined, the red blood cells in one type of blood may clump together and block blood vessels.\nVocabulary Review The circulatory system is the group of organs and tissues that transport essential materials to body cells and remove their waste products.\nVocabulary Review An artery is a blood vessel that carries blood away from the heart to all parts of the body.\nVocabulary Review A vein is a blood vessel that carries blood back to the heart from all parts of the body.\nVocabulary Review A capillary is the smallest blood vessel that provides body cells with blood and connects arteries with veins.\nVocabulary Review Pulmonary circulation carries the blood from the heart, through the lungs, and back to the heart.\nVocabulary Review Systemic circulation sends oxygen-rich blood to all the body tissues except the lungs.\nVocabulary Review Plasma is the yellowish fluid that is the watery portion of blood.\nVocabulary Review Blood pressure is the force of blood pushing against the walls of the blood vessels.']"	['<urn:uuid:8cc718fe-20cb-47b6-a65d-f5a2b40a86ae>']	open-ended	with-premise	long-search-query	distant-from-document	single-doc	novice	2025-05-01T22:47:46.423955	19	68	1050
8	I'm researching teacher training programs and noticed concerning trends in how educators handle bullying - what did studies reveal about teachers' empathy levels toward victimized students?	Research involving 178 pre-service teachers (142 women and 36 men) showed concerning results regarding empathy levels. When shown an animated vignette about racial discrimination between students, fewer than 50 percent of study participants exhibited even low levels of empathy, and only 10 percent showed a high level of empathy. Most subjects tended to focus on the perpetrator or other issues rather than showing concern for the victim. These findings align with other research indicating that teachers often don't address bullying incidents when they occur.	"['Animation can be outlet for victimized children, a tool for research\nChampaign, Ill. -- Animation is a proven vehicle for biting comedy, a la ""The Simpsons"" and ""South Park.""\nBut some of the same qualities that make it work for comedy make it valuable, too, as an outlet for victimized children and for a new research method that tests the empathy of teachers who may deal with them, says Sharon Tettegah, a professor of curriculum and instruction at the University of Illinois at Urbana-Champaign.\nTettegah believes so strongly in the value of animation – specifically ""animated narrative vignette simulations"" – that she sought out a computer science professor at Illinois, Brian Bailey, to help develop her concept for a child-friendly program for producing them.\nThe program that resulted, called Clover, gives children, as well as adults, a tool for making and sharing their own vignettes about their personal and sometimes painful stories.\nAccording to Tettegah, the program is the only one she is aware of that allows the user to write the narrative, script the dialogue, storyboard the graphics and add voice and animation, all within one application. Those four major aspects of producing a vignette gave rise to the name ""Clover,"" the plant considered to bring good luck in its four-leaf form.\nA paper about Clover, written by Bailey, Tettegah and graduate student Terry Bradley, has been published in the July issue of the journal Interacting With Computers.\nIn other research, Tettegah has used animations as a tool for gauging the empathy of teachers and others who might deal with children and their stories of victimization. One study with college education majors, or teachers-in-training, showed only one in 10 expressing a high degree of empathy for the victim, she said.\nA paper about that study has been accepted by the journal Contemporary Educational Psychology (CEP), with publication slated for later this year. The co-author of the study is Carolyn Anderson, a professor of educational psychology at Illinois.\nTettegah has done additional empathy studies with hundreds of participants, and will present some of that research at the Association for Computing Machinery\'s (ACM) SIGGRAPH conference July 30-Aug. 3 in Boston and at the American Psychological Association convention Aug. 10-13 in New Orleans.\nAnimations are valuable in this kind of research because they go beyond just text in visually telling a story, yet don\'t have the distractions of video, Tettegah said. ""Think about when you watch a cartoon: You focus more on what they\'re saying and not on how they look,"" she said.\nPsychological research surveys often elicit ""socially desirable"" or ""forced choice"" responses, Tettegah said. An animation, however, can tell a story and then ask for an open-ended response, she said. The subject has little or no clue what the researcher is looking for.\nIn her empathy studies, Tettegah has found that most of the subjects tend to focus on the perpetrator or other issues, rather than showing concern for the victim.\nThis is a concern, she said, because a child being bullied or called names wants the teacher\'s support. Yet the results also fit with research by others showing that teachers often don\'t deal with the problem when these incidents occur, the assumption having been that they don\'t know how, she said.\nIn the study to be published in CEP, each of the 178 subjects (142 women and 36 men), were shown a short animated vignette, based on a story collected by Tettegah in earlier research, involving a boy and girl, both 9 years old.\nIn the vignette, the children are asked to work together on a class project, and the boy tells the girl he doesn\'t want to work with her because her skin color might rub off on him. (Two different versions were used, with the boy being black and the girl white in one version, and vice versa in the other version. The races of the perpetrator and victim had no significant effect on subject responses to the vignette, Tettegah said.)\nAs the story progresses, the girl tells her father about the incident, and he then talks to the teacher.\nAfter viewing the vignette, each subject was asked an open-ended question about how he or she would have responded as the teacher in the situation. They were given unlimited time and space to respond.\nTettegah and four research assistants then did a line-by-line analysis of the subjects\' responses and developed a system for coding the content. They looked for content in four areas related to empathy for the victim: concern for the victim, problem-solving with the victim, mention of the victim and management of the situation with the victim.\nAfter the coding, Anderson, a statistical expert, analyzed the resulting data using sophisticated techniques involving latent variable modeling. The results suggested a single latent variable underlying the responses, showing very few of the pre-service teachers expressing significant empathy for the victim in the vignette.\nOverall, fewer than 50 percent of the study participants exhibited even low levels of empathy and only 10 percent exhibited a high level of empathy.\nIn light of these results, Tettegah, a former elementary teacher, thinks some kind of empathy-awareness training, similar to cultural or ethnic awareness training, should be considered as part of training future teachers.\n""I think that we are not, as teachers, tapped into those moral emotions … it\'s not a deliberate thing – you just don\'t even think about it,"" Tettegah said. ""But we need to be more aware of our victims and what happens to them, because they sometimes get damaged for life.""\nClover was designed with that concern also in mind, Tettegah said. The program gives students a powerful means for telling their stories, whether of victimization or dealing with other moral or social dilemmas, she said. Ideally, their animated vignettes can be shared anonymously and used in character-building exercises in the classroom.\nThe program ""really engages students and excites them,"" Tettegah said. In producing the vignettes, they gain a strong sense of ownership, she said, and at the same time build their writing, critical thinking and technology skills.\nTettegah has been demonstrating and testing Clover in local schools since last fall, and with positive results, she said.\nThe program is available for download at http://www.icctp.net/interact.php.\nLast reviewed: By John M. Grohol, Psy.D. on 30 Apr 2016\nPublished on PsychCentral.com. All rights reserved.']"	['<urn:uuid:186f5044-ba3c-46a0-8d04-e4b481965384>']	open-ended	with-premise	verbose-and-natural	distant-from-document	single-doc	expert	2025-05-01T22:47:46.423955	26	84	1055
9	ancient modern ocean pH changes coral impacts	Current ocean pH changes are unprecedented in at least 800,000 years, with pH dropping from 8.2 to 8.1 since industrialization. While previous events like the Paleocene-Eocene boundary showed similar CO2 increases, they occurred over thousands of years, allowing ocean buffering. Today's rapid acidification affects coral reproduction through sperm motility disruption and threatens their ability to form skeletons, with projections showing pH could decrease another 0.3-0.4 units by 2100.	"[""Corals, sea urchins, and even humans share a molecular pathway governing sperm motility, research finds.\nThe mechanism is regulated by a pH sensor that signals when sperm are to begin swimming.\nThe work appears in the journal Proceedings of the National Academy of Sciences.\nClimate change, which is making the oceans more not only warmer but also more acidic, and localized disturbances, such as sedimentation, may threaten the process.\n“When we started this project, nobody to our knowledge had looked at the mechanism that controlled coral sperm motility,” says Kelsey Speer, the study’s first author and postdoctoral researcher in the University of Pennsylvania biology department. “We were really interested in what drives this process in the ocean, because that’s a part of their life cycle that is very vulnerable.”\n“There’s so much diversity in sperm between species, so to find that this pathway was as conserved as it was, was surprising,” adds Katie Barott, senior author of the paper. “I think this work highlights how important it is to regulate this function. Animals are dependent on these pathways functioning in order to make the next generation. If sperm don’t work, that’s the end.”\nCoral and sea urchin sperm\nSperm tend to be finicky and vulnerable, highly sensitive to their environment. Too warm? Males don’t produce sperm. Too acidic? Sperm don’t swim. Coral sperm have the odds stacked particularly tall against them. The hermaphroditic creatures only reproduce a few nights each year, timed with the new moon. They release both eggs and sperm into the open ocean, where sperm must swim through the water column, hoping for a fruitful match.\nIn contrast to coral sperm, which have been little studied, sea urchins serve as a model organism for studying sperm. But despite their appearance, sea urchins are much more closely related to humans than to coral, and the signaling cascade responsible for setting their sperm in motion is also highly similar to that of vertebrates. That’s why the research team was curious to see how regulation of coral sperm motility compared.\nThey started with a clue that corals may possess a similar mechanism.\n“There is a really ancient pH-sensing enzyme that our lab had studied for a while that was present in corals,” Speer says. “It’s present in human sperm and it’s present in sea urchin sperm and we wondered, ‘Hey, it’s present in coral sperm too. What could it be controlling?'”\nAn enzyme of interest\nTo find out, the researchers waited until one of those new-moon nights in Kaneohe Bay, Hawaii, to scoop up the egg-sperm bundles released by the coral Montipora capitata. Acting quickly, they took the sperm back to the lab, holding them in a sodium-free seawater. “What it does is it prevents all these signaling pathways from operating, so they’re frozen in an immobile state,” says Barott. “Then you can add a chemical to artificially raise their pH, and the sperm start swimming right away.”\nUpon this activation, the researchers were able to monitor the activity of the enzyme of interest, soluble adenylyl cyclase (sAC) and cyclic AMP, the messenger molecule it produces, while also tracking how well the sperm were moving. Their experiments confirmed that sAC activity was required for sperm to swim; when the enzyme was blocked, the sperm flagella—the “tails”—moved weakly.\nComparing the genetic sequence of the M. capitata sAC to the sAC from a sea urchin species, Speer, Barott, and colleagues noted significant similarities, with about 50% of the sequence being the same overall, and identical sequences at key sites for the enzyme’s catalytic activity.\n“We looked at previously published datasets that catalog every mRNA that would become a protein in these cells, so we could get an idea of the molecular machinery in place to regulate sperm motility in these species,” says Barott.\nVery, very distant relatives\nInterestingly, M. capitata contained multiple different forms of sAC, some of which more closely resembled versions present in mammals. In follow-up work, the team hopes to explore how these different forms are operating in the corals, as well as in other model marine organisms.\nLooking at other molecular players in the sperm activation pathways initiated by sAC, the researchers found several shared by sea urchins as well as both other coral species, members of the Cnidarian phylum.\n“If you’re thinking about the difference in the last common ancestor between humans and Cnidarians—that was a heck of a long time ago,” Speer says. “The fact that the core of this mechanism has been conserved between these two species is really neat. I think it speaks to the fact that it’s a really good system, so nobody needed to replace it with something better.”\nWith a basic picture of coral sperm motility in place, Barott’s lab hopes to pursue additional experiments that get at the question of how changing environmental conditions could alter the organism’s reproductive success.\n“Both us and colleagues who study this species of coral have seen huge differences in the amount of sperm become mobile from year to year, and it does look like climate change, especially heat stress, can play a big role in knocking down sperm motility,” Barott says. “Now that we have this toolkit, we can do these climate-change type of experiments and understand more about the dynamics of this pathway and how it changes in periods of stress.”\nThe National Science Foundation supported the work."", 'What is Ocean Acidification?\nSince the beginning of the Industrial Revolution, when humans began burning coal in large quantities, the world’s ocean water has gradually become more acidic. Like global warming, this phenomenon, which is known as ocean acidification, is a direct consequence of increasing levels of carbon dioxide (CO2) in Earth’s atmosphere.\nPrior to industrialization, the concentration of carbon dioxide in the atmosphere was 280 parts per million (ppm). With increased use of fossil fuels, that number is now approaching 400 ppm and the growth rate is accelerating. Scientists calculate that the ocean is currently absorbing about one quarter of the carbon dioxide that humans are emitting. When carbon dioxide combines with seawater, chemical reactions occur that reduce the seawater pH, hence the term ocean acidification.\nCurrently, about half of the anthropogenic (human-caused) carbon dioxide in the ocean is found in the upper 400 meters (1,200 feet) of the water column, while the other half has penetrated into the lower thermocline and deep ocean. Density- and wind-driven circulation help mix the surface and deep waters in some high latitude and coastal regions, but for much of the open ocean, deep pH changes are expected to lag surface pH changes by a few centuries.\nOcean acidification and global warming are different problems, but are closely linked because they share the same root cause—human emissions of carbon dioxide. The atmospheric concentration of carbon dioxide is now higher than it has been for the last 800,000 years and possibly higher than any time in the last 20 million years. Humans have thus far benefited from the ocean’s capacity to hold enormous amounts of carbon, including a large portion of this excess carbon dioxide. Had the ocean not absorbed such vast quantities of carbon dioxide, the atmospheric concentration would be even higher, and the environmental consequences of global warming (sea level rise, shifting weather patterns, more extreme weather events, etc.) and their associated socioeconomic impacts would likely be even more pronounced. However, the oceans cannot continue to absorb carbon dioxide at the current rate without undergoing significant changes in chemistry, biology, and ecosystem structure.\nMeasuring ocean acidification: Past and present\nScientists know that the oceans are absorbing carbon dioxide and subsequently becoming more acidic from measurements made on seawater collected during research cruises, which provide wide spatial coverage over a short time period, and from automated ocean carbon measurements on stationary moorings, which provide long-term, high-resolution data from a single location.\nThese records can be extended back through time using what are known as chemical proxies to provide an indirect measurement of seawater carbonate chemistry. A proxy is a measurement from a natural archive (ice cores, corals, tree rings, marine sediments, etc.) that is used to infer past environmental conditions. For example, by analyzing the chemical composition of tiny fossil shells found in deep ocean sediments, scientists have developed ocean pH records from ancient times when there were no pH meters. Furthermore, because the ocean surface water is in approximate chemical balance, or equilibrium, with the atmosphere above it, a record of historical ocean pH can be inferred from atmospheric carbon dioxide records derived from Greenland and Antarctic ice cores, which contain air bubbles from the ancient atmosphere. Such evidence indicates that current atmospheric carbon dioxideconcentrations and ocean pH levels are at unprecedented for at least the last 800,000 years.\nGoing back deeper in Earth history to the Paleocene-Eocene boundary about 55 million years ago, scientists have found geochemical evidence of a massive release of carbon dioxide accompanied by substantial warming and dissolution of shallow carbonate sediments in the ocean. Although somewhat analogous to what we are observing today, this carbon dioxide release occurred over several thousand years, much more slowly than what we are witnessing today, thus providing time for the oceans partially to buffer the change. In the geologic record, during periods of rapid environmental change, species have acclimated, adapted or gone extinct. Corals have undergone large extinction events in the past (such the Permian extinction 250 million years ago), and new coral species evolved to take their place, but it took millions of years to recover previous levels of biodiversity.\nHow is ocean acidification affecting ocean chemistry?\nSeawater has a pH of 8.2 on average because it contains naturally occurring alkaline ions that come primarily from weathering of continental rocks. When seawater absorbs carbon dioxide from the atmosphere, carbonic acid is produced (see Box 1), reducing the water’s pH. Since the dawn of industrialization, average surface ocean pH has decreased to about 8.1.\nBecause the pH scale is logarithmic (a change of 1 pH unit represents a tenfold change in acidity), this change represents a 26 percent increase in acidity over roughly 250 years, a rate that is 100 times faster than anything the ocean and its inhabitants have experienced in tens of millions of years.\nAcidification can affect many marine organisms, but especially those that build their shells and skeletons from calcium carbonate, such as corals, oysters, clams, mussels, snails, and phytoplankton and zooplankton, the tiny plants and animals that form the base of the marine food web.\nThese “marine calcifiers” face two potential threats associated with ocean acidification: 1) Their shells and skeletons may dissolve more readily as ocean pH decreases and seawater becomes more corrosive; and 2) When CO2 dissolves in seawater, the water chemistry changes such that fewer carbonate ions, the primary building blocks for shells and skeletons, are available for uptake by marine organisms. Marine organisms that build shells or skeletons usually do so through an internal chemical process that converts bicarbonate to carbonate in order to form calcium carbonate.\nExactly how ocean acidification slows calcification rates, or shell formation, is not yet fully understood, but several mechanisms are being studied. Most hypotheses focus on the additional energy an organism must expend to build and maintain its calcium carbonate shells and skeletons in an increasingly corrosive environment. In the face of this extra energy expenditure, exposure to additional environmental stressors (increasing ocean temperatures, decreasing oxygen availability, disease, loss of habitat, etc.) will likely compound the problem.\nThese effects are already being documented in many marine organisms, particularly in tropical and deep-sea corals, which exhibit slower calcification rates under more acidic conditions. The impact on corals is of great concern because they produce massive calcium carbonate structures called reefs that provide habitat for many marine animals, including commercially important fish and shellfish species that use the reefs as nursery grounds. Coral reefs are vital to humans as sources of food and medicine, protection from storms, and the focus of eco-tourism. In addition to corals, studies have shown that acidification impairs the ability of some calcifying plankton, tiny floating plants and animals at the base of the food web, to build and maintain their shells. Scientists have also observed increased larval mortality rates of several commercially important fish and shellfish.\nWhat can we expect in the future?\nOcean acidification is occurring at a rate 30 to100 times faster than at any time during the last several million years driven by the rapid growth rate atmospheric CO2 that is almost unprecedented over geologic history. According to the Intergovernmental Panel on Climate Change (IPCC), economic and population scenarios predict that atmospheric CO2 levels could reach 500 ppm by 2050 and 800 ppm or more by the end of the century. This will not only lead to significant temperature increases in the atmosphere and ocean, but will further acidify ocean water, reducing the pH an estimated 0.3 to 0.4 units by 2100, a 150 percent increase in acidity over preindustrial times. Assuming a “business-as-usual” IPCC CO2 emission scenario, predictive models of ocean biogeochemistry project that surface waters of the Arctic and Southern Oceans will become undersaturated with aragonite (a more soluble form of calcium carbonate) within a few decades, meaning that these waters will become highly corrosive to the shells and skeletons of aragonite-producing marine calcifiers like planktonic marine snails known as pteropods.\nAlthough ocean acidification has only recently emerged as a scientific issue, it has quickly raised serious concerns about the short-term impacts on marine organisms and the long-term health of the ocean. Scientists estimate that over the next few thousand years, 90 percent of anthropogenic CO2 emissions will be absorbed by the ocean. This may potentially affect biological and geochemical processes such as photosynthesis and nutrient cycling that are vital to marine ecosystems on which human society and many natural systems rely. At the same time, marine organisms will face the enormous challenge of adapting to ocean acidification, warming water, and declining subsurface-ocean oxygen concentrations.\nNews & Insights\nWHOI working to address ocean acidification; protect region’s vital shellfish industry\nA new report addresses the impacts of ocean acidification in Massachusetts and New England coastal waters on the region’s vital seafood industry.\nOcean acidification gets a watchful eye in New England aquaculture ‘hot spot’\nShellfish aquaculture is thriving in New England, but future growth in the industry could be stunted as coastal waters in the region become more acidic. Researchers at WHOI have developed…\nOcean acidification causing coral ‘osteoporosis’ on iconic reefs\nScientists Pinpoint How Ocean Acidification Weakens Coral Skeletons\nClimate Change Will Irreversibly Force Key Ocean Bacteria into Overdrive\n[ ALL ]\nWHOI in the News\nThe Top Eight Ocean Stories of 2022\nThe $500 Billion Question: What’s the Value of Studying the Ocean’s Biological Carbon Pump?\nEcology Research: Ocean acidification causing coral ‘osteoporosis’ on iconic reefs\nDisentangling influences on coral health\n[ ALL ]\nFrom Oceanus Magazine\nOcean acidification is no big deal, right?\nWHOI’s Jennie Rheuban discusses the very real phenomenon of an increasingly acidic ocean and the toll it’s taking on marine life.\nTo Tag a Squid\nHow do you design a tag that can attach to a soft-bodied swimming animal and track its movements? Very thoughtfully.\nHow Do Corals Build Their Skeletons?\nWHOI scientists discovered precisely how ocean acidification affects coral skeletons’ a factor that will help scientists predict how corals throughout the world will fare as the oceans become more acidic.\nSearching for ‘Super Reefs’\nSome corals are less vulnerable to ocean acidification. Can the offspring from these more resilient corals travel to other reefs to help sustain more vulnerable coral populations there?\nGraduate student Hannah Barkley is on a mission to investigate how warming ocean temperatures, ocean acidification, and other impacts of climate change are affecting corals in an effort to find…']"	['<urn:uuid:95145ed6-3aa7-4e64-b527-152e6b174205>', '<urn:uuid:51ca6f21-f0f4-4343-8b14-a7f059f0fe69>']	factoid	direct	short-search-query	similar-to-document	multi-aspect	expert	2025-05-01T22:47:46.423955	7	68	2625
10	How does farm size and education impact soil conservation, and what support do farmers need?	Farm size directly affects soil conservation efforts according to studies, while education levels influence how farmers perceive erosion problems. For successful implementation, farmers need coordinated support from government departments, local authorities, and NGOs, along with clear messages about which practices will work best for their specific situation.	"['Can conservation agriculture (CA) help farmers in sub-Saharan Africa build resilience to the problem of climate change? Professor Andy Dougill believes it is possible, but that more coordinated planning and coherent policy support across sectors nationally, on a district level, and to a range of local farmer groups and community leaders is needed.\nFor over a decade now, most development organisations have been advocating conservation agriculture as a ‘climate-smart agriculture’ approach. The idea behind conservation agriculture is that farmers maximise organic matter in their soil and reduce CO2 release by limiting or eliminating tillage, using crop rotations and by keeping a permanent organic coverage on the fields. In return, the argument goes, they get improved soils that are able to hold water for longer and sustain yields in dry years, making maize harvests more resilient to the impacts of climate change.\nThere is growing evidence globally to suggest that no-till farming works when good crop residue management practices are followed, but that local context remains critical, and further research insights, such as those being provided by the GCRF-AFRICAP project, are essential. Why is the evidence base still so poor, given that conservation agriculture – sometimes billed as ‘farming God’s way’ – has been promoted to farmers for so long?\nWebinar on 23 Feb: Improving soil health through climate-smart agriculture\nA threefold problem\nPart of the problem is the patchy take up of conservation agriculture across countries such as Malawi, Zambia and Zimbabwe. Many farmers are reluctant to change to this method of farming or, once started, fail to maintain it after a donor-supported project leaves. The reasons for this are threefold: practical, cultural and institutional.\nOn the practical side, good conservation agriculture can be more labour intensive at certain times of the year, requiring more weeding and more work to prepare the ground and sow a crop. Leaving organic matter on the surface, such as maize stalks, can encourage pests such as mice, which are deterred when the stalks are burned. Because the benefits take a while to be seen and are largely evident only in drought years, farmers can easily be put off by more immediate changes in their farming practices.\nCulturally, many farmers hold the view that conventional ploughing of land and creation of ridges and furrows is what epitomises good, modern farming. It is imperative that such views are questioned and that locally appropriate land management practices are discussed and supported by farmers, groups, community leaders and government extension services.\nAt an institutional level, take up of conservation agriculture is often incentivised through provision of additional fertiliser and new seed, which makes it hard to identify the impact of the change in farming method alone. Malawian studies have shown that when the incentives end, for the reasons above, farmers often revert to their former methods.\nAlthough conservation agriculture has been promoted for many years, this has been done by many different organisations – governmental and non-governmental – in various ways and for diverse reasons, resulting in confused messages as to why farmers should take up the practice and sometimes even what the practice should consist of.\nRecent studies – conducted under auspices of the GCRF-AFRICAP project – looking at how policy on conservation agriculture is implemented in Malawi highlight the need for better communication and collaboration between all relevant parties within a country: government departments, local government and NGOs. Effective implementation of conservation agriculture requires government departments responsible for agriculture to move outside their traditional responsibilities and link with departments working on climate change adaptation, meteorology, health, and water distribution.\nGiven these limitations, what reliable evidence do we have of the benefits that conservation agriculture can bring, particularly in relation to climate resilience? A recent paper has shown that conservation agriculture improves soil structure and can increase organic carbon levels in soil aggregates leading to improved maize yields in drought years. However, most of this work has been undertaken on government research stations rather than in the ‘real world’ of smallholder farming systems. Furthermore, there is a lack of robust findings to determine whether these benefits will hold up in the face of climate change.\nWe’ve been working with farmers in Malawi for the last 10 years and know many of those who have taken up conservation agriculture – currently around 2–3%. Those connections are helped us to run a fast-turnaround study, comparing how the crops of conservation agriculture farmers in Malawi survived the 2015/16 drought compared to those using conventional methods.\nThis work, funded by the UK government through the National Environment Research Council (NERC), can help us understand just how ‘climate-smart’ conservation agriculture can be. This research also looked at the impact of El Niño in Kenya, to assess whether conservation agriculture helped farmers retain yields in the face of the floods there. Interim results from Malawi indicate that, where the drought was most severe, all farmers lost their crops; however, in more marginal areas, conservation agriculture did provide benefits where household labour was available (linked to the effectiveness of village health services) and crop residue management had been possible for the last 5 years.\nResearch is starting to provide a much-needed evidence base to show farmers when it is in their interest to move to conservation agriculture. Farmers need a clear message to help them understand which practices will work best for them, so that they can make an informed decision. We need both the evidence and better collaborative working amongst key organisations at both a national and district level to make that happen. Ongoing studies in the GCRF-AFRICAP project and the future work of the Food Systems Research Network for Africa (FSNet-Africa) offer scope to provide further empirical insights on how land management can build climate resilience in African Agricultural Systems.\nWebinar on 23 Feb\nLearn more about AFRICAP’s research on Conservation Agriculture and soils science at our webinar on 23 February, ‘Improving soil health through climate-smart agriculture’. Visit the event page for full details and to register.\nThis blog and associated vlog is part of a joint campaign for World Food Day led by the ARUA-UKRI GCRF Food Systems Research Network for Africa (FSNet-Africa) in partnership with the Food, Agriculture, and Natural Resources Policy Analysis Network (FANRPAN), the University of Leeds’ Global Food and Environment Institute (GFEI), and the GCRF AFRICAP programme. Follow the campaign on Twitter @gcrfafricap, or visit our partners’ websites over the next two weeks – University of Pretoria, FANRPAN, and GFEI.', 'Factors Affecting the Adoption of Soil Conservation Measures: A Case Study of Fijian Cane Farmers\nThis study explored the extent to which various factors affect Fijian cane farmersâ€™ adoption of soil conservation measures. The significant factors affecting perception of the soil erosion problem include age, education, ethnicity, and extension services. On the other hand, the significant factors affecting soil conservation effort include perception of the erosion problem, net farm income, farm size, land type, and extension services. In general, personal characteristics appear to affect perceptions of soil erosion while the extent of conservation effort is affected by economic and physical factors. The resulting implications for soil conservation policy are discussed.\nVolume (Year): 33 (2008)\nIssue (Month): 01 (April)\n|Contact details of provider:|| Web page: http://waeaonline.org/|\nMore information through EDIRC\nReferences listed on IDEAS\nPlease report citation or reference errors to , or , if you are the registered author of the cited work, log in to your RePEc Author Service profile, click on ""citations"" and make appropriate adjustments.:\n- Doss, Cheryl R. & Morris, Michael L., 2001.\n""How does gender affect the adoption of agricultural innovations? The case of improved maize technology in Ghana,""\nAgricultural Economics of Agricultural Economists,\nInternational Association of Agricultural Economists, vol. 25(1), June.\n- Doss, Cheryl R. & Morris, Michael L., 2001. ""How does gender affect the adoption of agricultural innovations?: The case of improved maize technology in Ghana,"" Agricultural Economics, Blackwell, vol. 25(1), pages 27-39, June.\n- Morris, Michael L. & Doss, Cheryl R., 1999. ""How Does Gender Affect The Adoption Of Agricultural Innovations? The Case Of Improved Maize Technology In Ghana,"" 1999 Annual meeting, August 8-11, Nashville, TN 21609, American Agricultural Economics Association (New Name 2008: Agricultural and Applied Economics Association).\n- Baidu-Forson, J., 1999. ""Factors influencing adoption of land-enhancing technology in the Sahel: lessons from a case study in Niger,"" Agricultural Economics, Blackwell, vol. 20(3), pages 231-239, May.\n- Kebede, Yohannes & Gunjal, Kisan & Coffin, Garth, 1990. ""Adoption of new technologies in Ethiopian agriculture: The case of Tegulet-Bulga district Shoa province,"" Agricultural Economics, Blackwell, vol. 4(1), pages 27-43, April.\n- Francis D. K. Anim, 1999. ""A Note on the Adoption of Soil Conservation Measures in the Northern Province of South Africa,"" Journal of Agricultural Economics, Wiley Blackwell, vol. 50(2), pages 336-345.\n- Marc F. Bellemare & Christopher B. Barrett, 2006.\n""An Ordered Tobit Model of Market Participation: Evidence from Kenya and Ethiopia,""\nAmerican Journal of Agricultural Economics,\nAgricultural and Applied Economics Association, vol. 88(2), pages 324-337.\n- Bellemare, Marc F. & Barrett, Christopher B., 2005. ""An Ordered Tobit Model of Market Participation: Evidence from Kenya and Ethiopia,"" Working Papers 14748, Cornell University, Department of Applied Economics and Management.\n- Lapar, Ma. Lucila A. & Pandey, Sushil, 1999. ""Adoption of soil conservation: the case of the Philippine uplands,"" Agricultural Economics, Blackwell, vol. 21(3), pages 241-256, December.\n- Norris, Patricia E. & Batie, Sandra S., 1987. ""Virginia Farmers\' Soil Conservation Decisions: An Application Of Tobit Analysis,"" Southern Journal of Agricultural Economics, Southern Agricultural Economics Association, vol. 19(01), July.\n- Jamison, Dean T. & Moock, Peter R., 1984. ""Farmer education and farm efficiency in Nepal: The role of schooling, extension services, and cognitive skills,"" World Development, Elsevier, vol. 12(1), pages 67-86, January.\n- Adesina, Akinwumi A. & Zinnah, Moses M., 1993. ""Technology characteristics, farmers\' perceptions and adoption decisions: A Tobit model application in Sierra Leone,"" Agricultural Economics, Blackwell, vol. 9(4), pages 297-311, December.\n- Holloway, Garth J. & Barrett, Christopher B. & Ehui, Simeon K., 2002. ""Bayes\' Estimates Of The Double Hurdle Model In The Presence Of Fixed Costs,"" Working Papers 14741, Cornell University, Department of Applied Economics and Management.\n- Jeffrey H. Dorfman, 1996. ""Modeling Multiple Adoption Decisions in a Joint Framework,"" American Journal of Agricultural Economics, Agricultural and Applied Economics Association, vol. 78(3), pages 547-557.\nWhen requesting a correction, please mention this item\'s handle: RePEc:ags:jlaare:36710. See general information about how to correct material in RePEc.\nFor technical questions regarding this item, or to correct its authors, title, abstract, bibliographic or download information, contact: (AgEcon Search)\nIf you have authored this item and are not yet registered with RePEc, we encourage you to do it here. This allows to link your profile to this item. It also allows you to accept potential citations to this item that we are uncertain about.\nIf references are entirely missing, you can add them using this form.\nIf the full references list an item that is present in RePEc, but the system did not link to it, you can help with this form.\nIf you know of missing items citing this one, you can help us creating those links by adding the relevant references in the same way as above, for each refering item. If you are a registered author of this item, you may also want to check the ""citations"" tab in your profile, as there may be some citations waiting for confirmation.\nPlease note that corrections may take a couple of weeks to filter through the various RePEc services.']"	['<urn:uuid:155d6dc0-5127-42b9-938c-416288b657bc>', '<urn:uuid:e9940667-a9e9-4918-819e-937e701df031>']	factoid	with-premise	concise-and-natural	similar-to-document	multi-aspect	novice	2025-05-01T22:47:46.423955	15	47	1906
11	nose blockage and yellow mucus not going away with cold medicine what could this mean	These symptoms suggest you may have sinusitis. When you experience a prolonged cold with a stuffy nose and yellow or green mucus coming from the nose, this indicates a sinus condition. This occurs when the sinuses become inflamed and mucus gets stuck, creating a breeding ground for bacteria. The condition may require specific treatment - antibiotics are typically used for acute sinusitis and are usually given for about two weeks, though more aggressive cases may require longer courses. Decongestants and humidifiers can also help manage symptoms.	['Almost all sinus problems begin inside the nose. The sinuses (described below) connect with the internal lining of the nose via small tubes. These tubes must stay clear otherwise sinus obstruction occurs, leading to various unpleasant and stubborn medical conditions. Patients of whatever age with long standing nose and sinus problems worsen during the change of seasons March/April and September/October.\nSinuses are cave-like pockets in the skull and are lined with much the same material as our respiratory tracts. The function of sinuses is uncertain but theories include humidifying air, providing cushioning for the skull and increasing resonance of the voice. Cynics claim:\nSinuses only exist to make ENT surgeons and allergists rich!\nSinuses can become inflamed as a result of infection or an allergic challenge.\nTiny hairs along the respiratory tract push mucus up towards our nose and mouth. When the lining of the sinuses swells this mucus becomes stuck and causes uncomfortable pressure. It also produces a perfect breeding ground for bacteria.\nThere are four types of sinuses found on the face called the maxillary, frontal, sphenoid and ethmoid. When each (or all) is inflamed from infection or allergic challenge different symptoms are experienced.\nWhat might I experience when my sinuses become inflamed or infected?\nThe green colour marks the maxillary sinuses, located just behind the cheekbones on the face.\nIf you have an inflammation of the maxillary sinuses you may experience:\n- Cheek pain/pressure\nThe red colour identifies the frontal sinuses, located just above the bone at the centre of each\neyebrow. If you have an inflammation of the frontal sinuses you may experience:\n- Pain around and behind the eyes\nThe orange colour identifies the ethmoid and sphenoid sinuses. The ethmoids are located between the eyes and just behind the bridge of the nose. Behind the ethmoid sinuses, tucked in behind the eyes are the sphenoid sinuses. If you have an inflammation of either or both you may experience:\n- Pain/pressure between and behind the eyes\n17 year old male with long history of nasal obstruction, headaches and runny nose. Photo shows grossly swollen nasal lining obstructing the sinus openings. X-ray showed that the ethmoid and maxillary sinuses were thickened from long term obstruction.\nOther symptoms associated with Sinusitis:\n- Prolonged cold with a stuffy nose\n- Green, yellow or blood streaked mucus coming from the nose\n- Pain in the head that worsens when lying back-down or bending over\nThe condition of Rhinitis (ailment of the nose) is associated with Sinusitis as the inflammation of the nose (streaming and persistent sneezing amongst other symptoms) can progress into the adjoining sinuses.\nIn the digital image there is severe swelling of all the lining in the nasal cavity causing symptoms such as blockage, mouth breathing, diminished sense of smell and taste and ‘wheeziness’. Treatment involves first restoring the nasal lining to normal, then stabilising the area and deciding what the cause is. In this case it was an aggressive allergy to dust mites and grass pollens. This patient would benefit greatly from a new treatment called Rhinolight U/V phototherapy combined with immunotherapy (full details elsewhere in this website).\nFungal Sinusitis was once considered a rarity but may be more common than previously realised. Symptoms are often similar to those of bacterial sinusitis and the fungal infection may trigger fleshy (benign) growths inside the nose called polyps. People who are allergic to fungi are often more susceptible to this particular form of sinusitis. A CT scan commonly determines whether or not a fungal infection has occurred and standard procedures such as endoscopic surgery are considered to clear the offended fungus and resume normal sinus drainage.\nNose polyps. These are benign fleshy, grape-like growths that form inside the nose and sinuses. There is no agreement on the causes of nose polyps but some US researchers believe that an allergic response to fungal spores may be one explanation.\nAntibiotic medications are used to treat acute sinusitis. These medications are usually given for about two weeks, but aggressive sinusitis may require longer courses. Decongestants, or the short-term use of decongestant nose sprays, can be useful. Analgesics decrease the associated pain and headache. Also, running a humidifier can prevent mucus within the nasal passages from drying out uncomfortably, and can help soothe any accompanying sore throat or cough.\nChronic sinusitis is often treated initially with antibiotics. Steroid nasal drops and sprays may be used to decrease swelling in the nasal passages. If an anatomic reason is found for chronic sinusitis, it may need to be corrected with surgery. If a surgical procedure is necessary, samples are usually taken at the same time to identify any organisms present which may be causing infection.\nFungal sinusitis will require surgery to clean out the sinuses. Then, a relatively long course of a strong antifungal medication may be offered.\nAllergic nose and sinus issues my now be treated using the latest non-medical technique Rhinolight.\nWe take your sinus issues seriously. When you attend you will be quizzed about symptoms such as:\n- Mouth breathing\n- Dry mouth every morning after sleep (suggesting night time mouth breathing)\n- Runny nose\n- Post nasal drip\n- Blood stained mucus\n- Diminished (or lost) senses of smell and taste\n- Associated asthma or shortness of breath or night cough\n- Associated skin hives (medical term is urticaria)\n- Aspirin or dispirin or similar pain killer allergy\nThis information gives us valuable insights as to what type of sinus problem you have. We then inspect the nose and sinuses with an Olympus ENF fiberscope (see photo below). This is a 3mm in diameter fiberoptic instrument that allows us visually check the breathing tract from the tip of the nose to the vocal cords. Our fiberscope is connected to an LCD screen that allows the patient follow the procedure. The screen can display an image ‘freeze’ so we can discuss an area of particular importance.\nOlympus fiberscope in action. The flexible tip measures 3 mms and passes easily along the nose, into the back of the throat and down to the vocal cords. On the screen all areas can be viewed. Specific zones of interest can be photographed and recorded to assess treatment strategies. This has been used on children as young as 5 years and adults over 80 years.\nWe combine this with a full allergy screen.\nFull allergy test and fiberoptic assessment of the nose, sinuses and throat: €290. Follow up fee where necessary is €80.\nBelow are examples of images we captured on patients illustrating just how troublesome their sinus problems were at the first consultation.\n25 year old with the internal surface of the nose so allergically challenged fluid is beginning to swell the lining. Left untreated the shiny bubble-like area at 8 o’clock will become a polyp. In long standing nose and sinus allergic challenge, if an infection sets in ON TOP of the background changes considerable extra damage can be inflicted on the soft tissue.\nA nasal polyp. This is a benign but nuisance growth inside the nose that causes symptoms of obstruction, loss of senses of smell and taste and may trigger asthma.\nEven in children as young as 5 years considerable swelling can occur within the nasal cavity. This in turn obstructs the sinus openings causing sinus problems. And in turn this may trigger off asthma. If the nose and sinus problems are corrected the asthma usually abates significantly.']	['<urn:uuid:03d12e4c-b45c-4f22-ac6e-15bd9bb32282>']	open-ended	with-premise	long-search-query	distant-from-document	single-doc	novice	2025-05-01T22:47:46.423955	15	86	1236
12	What factors are important for successful cabbage cultivation in terms of soil and water, and how do these compare to the conditions needed for proper fermentation of cabbage?	For successful cabbage cultivation, the soil should range from sandy loam to clay with a pH of 5.5 to 6.5, and must be rich in organic matter with good drainage. Regular irrigation is crucial, especially during head development, with water needed every 8-10 days in winter, and cabbage cannot tolerate drought. For proper fermentation, the key conditions are different - the focus is on maintaining a clean environment and proper salt concentration in the brine solution. The cabbage must remain fully submerged in the brine throughout the fermentation process, and the container must allow gases to escape while preventing the cabbage from floating to the top, which is achieved using fermentation weights.	['Cabbage Farming Guide\nCabbage & It’s importance :- The cabbage is a popular cultivar of the species Brassica Family and is used as a leafy green vegetable.The only part of the plant that is normally eaten is the leafy head; more precisely, the spherical cluster of immature leaves, excluding the partially unfolded outer leaves. Cabbage is used in a variety of dishes for its naturally spicy flavour. The so-called “cabbage head” is widely consumed raw, cooked, or preserved in a great variety of dishes. Cabbage is an excellent source of vitamin C. It also contains significant amounts of glutamine, an amino acid that has anti-inflammatory properties.\nClimatic Conditions for Cabbage Farming :- Cabbage grows best in cool moist climate and is very hardy to frost. In areas with comparatively dry atmospheres, its leaves tend to be more distinctly petiole than in the more humid areas. In hot dry atmosphere, its quality becomes poor and much of its delicate flavor is lost. Its germination is best at a soil temperature of about 55 °F to 60 °F. Temperatures below this and above this are not suited for it. Well hardened seedlings can tolerate temperature of2Q °F to 25 “F. It is grown mainly as rabi crop during winter. But in and around Nasik (Maharashtra), Ootacamond (Madras), and in semi parts of Kerala, it is grown as kharif crop also.\nBest Soil for Cabbage Farming :- Cabbage is grown in varied types of soils ranging from sandy loam to clay. It requires a pH ranging from 5.5 to 6.5 for higher production. It also thrives best when the soil is rich in organic matter and good drainage.\nLand/Field Preparation in Cabbage Farming :- Land is prepared by ploughing it 3 to 4 times. The first ploughing should be done by soil turning plough, and the bulky organic manures should be spread in the field. Then the land should be ploughing and levelling the land, beds of suitable size and irrigation channels are made.\nSeed Rate &Time of Sowing in Cabbage Farming :- Normally 120 grams of seeds are required for one acre. Apply 480Kgs of dry manure in to a seedling bed of 160 m², and then sow the seed on the seedbed. This should produce sufficient seedlings for one acre of field. Cabbage is grown mainly as Rabi crop during winter (Sept.-Oct.), But around Nasik (Maharashtra) it is grown as kharif crop also.\nTransplanting and spacing in Cabbage Farming :-Transplant the seedlings at 4- 5 true leaves stage, about 25 days after sowing. Usually space them 45 cm apart in double rows of 45-60 cm apart on each bed of 90- 100 cm wide.\nCabbage plant Spacing:\n- Early maturity – Row to Row : 45 cm, Plant to Plant : 30 cm\n- Late Maturity – Row to Row : 60cm, Plant to Plant : 45 cm\nIrrigation/Water Supply in Cabbage Farming :-\nProvide continuous supply of moisture. Install drip system with main and sub-main and place the inline laterals at the interval of 1.5. Place the drippers at the interval of 60 cm for 4 LPH or 50 cm for 3.5 LPH in the lateral system. Form the raised beds at 120 cm width at an interval of 30cm and place the laterals at the centre of each bed.Interval between two irrigations depends upon climate, soil and plant growth. In winter season irrigation at an interval of 8-10″days is sufficient.Cabbage cannot tolerant drought. Therefore irrigation should be applied frequently and evenly, especially in the head developing period. Irrigation should be applied following the first and the second side dressing. It is better to keep a little water in the furrow in the hot season. But drainage must be carried out in the rainy days.\nPruning and weed control in Cabbage farming :- It is necessary to remove the side shoots as soon as possible.Weeds must be removed as early as possible by hoeing but not too deep to damage the roots. Hoeing should not be done during the latter part of the growing season. Herbicide can be used for weed control in the cabbage field.\nFertilizers in Cabbage Farming :-It is better to use urea instead of Ammonium Sulphate where the soil is relatively acidic.If the soil is boron deficient, 5 –10 kg/ha borax should be applied before land preparation.For basal fertilizer, manure should be applied into the rows before chemical fertilizer.Chemical Fertilizers: Fertilizer application varies with soil fertility.Basal application before transplanting: 25:50:60 NPK kg / acre. First top dressing 10-15 days after transplanting: 25:50:60 NPK kg / acre. Second application 20 – 25 days after first top dressing: 25:00:00 NPK kg / acre.Third application 10-15 days after second application: 25:00:00 NPK kg / acre. Boron & Molybdenum should be sprayed at button stage.\nHarvesting in Cabbage Farming :- Cabbage is normally harvested when the heads reach full size and are firm,In cabbage harvesting is done depending on the maturity of the head and demand in market. Normally harvesting is done when heads are firm. If prices are high in the market harvesting is done earlier when heads are small and loose Heads are cut with a knife with little stalk arid some leaves. Proper grading is followed before heads are sent to market.\nYield of Cabbage :- Usually Hills : 70 – 80 t/ha in 150 days. Plains : 25 – 35 t/ha in 120 days. The yield of cabbage depends upon the variety, growing season and management practices.\nMarketing of Cabbage :- Can be transported to local markets or whole sale vegetable dealers.\nBottom Line :- It’s fun to cultivate the Cabbage, and good profits are possible in cabbage farming when best practices are implemented.', 'This piece originally appeared on Fix.com.\nWhile you sit happily munching away at breakfast, lunch, and dinner, day in and day out, an army of tiny, hard-working warriors are making sure your gut stays healthy. Your microflora – that is, the bacteria, fungi, viruses, and other microbes that comprise your busy internal ecosystem – perform this careful balancing act throughout your lifetime.\nEating a healthy range of fermented foods can help you cheer on the right team – the good bacteria – in your gut. Put aside for a second the erroneous association of “fermented food” with spoiled, rotten, or bad food, and you’ll discover that you’re probably already eating foods that have been fermented. Not convinced?\nBelow is a list of commonly fermented foods:\nOnce largely unknown, foods like kimchi and kombucha tea have experienced a huge rise in popularity that coincides both with an increased interest in Asian cuisine and the emergence of more health-conscious eaters in North America. And if you’re looking for a fun fact to impress your friends at your next party, the science of fermentation is called zymology.1\nHealth Benefits of Eating Fermented Foods\nBy supplementing and balancing the levels of good bacteria in our gut, eating fermented foods can help improve digestion, boost immunity, and may even help us stay lean.2 It has been shown that having a healthy gut also affects our psychological and emotional well-being.3 A healthy gut is one of the biggest cornerstones of a healthy life overall.\nDID YOU KNOW? Your gut produces more of the neurotransmitter serotonin, which helps regulate your mood, than your brain does.\nWhat’s the Difference Between Fermented and Pickled Foods?\nBefore you go clean out the grocery store of all its jars of pickles in the name of health, there’s an important difference to be aware of between pickled and fermented foods. Because not all pickled foods go through a fermentation process, not all pickled foods offer the same health benefits of fermented foods.\nFor example, jarred pickles that you find on a non-refrigerated shelf in the condiments aisle are often made using vinegar without going through the process of fermentation. This means that they don’t contain any of the probiotics that make fermented foods so beneficial for your gut.\nHow to Make Home-Fermented Veggies\nIf you’ve never attempted home fermentation before, an easy vegetable to start with is white cabbage to make sauerkraut. Once you’ve mastered the basics of the exciting chemistry experiment that is home fermentation, you can start experimenting with all kinds of vegetables and even start creating your own yogurt and sour cream.\nFermenting your food at home is the best way to maximize the foods’ probiotic cultures, which are often destroyed in large-scale, high-heat industrial processes that create common store-bought items like the ubiquitous jarred pickle.\nWhat you’ll need:\n- 33oz (1L) Fido jars or pickling-specific jars like the Primal Pickler\n- Fermentation weights such as Pickle Pebbles\n- Cutting board\n- Sharp knife\n- Medium mixing bowl\n- Large mixing spoon\n- Kitchen scale\n- Large saucepan\n- 1 L water\n- 1 L ice cubes\n- 6 tbsp + 2.5 tbsp pure sea salt\n- 2 lbs white cabbage\nMake sure that your jars, weights, and cutting and mixing equipment are thoroughly cleaned before you begin. You don’t want to introduce any unwanted bacteria before you start!\nMake the Brine\nDissolve 6 tbsp salt in 1 L of water on the stove. Add 1 L ice cubes to cool and transfer to a jar for storage.\nPrepare the Cabbage\nChoose a fresh, healthy-looking cabbage that is crisp, not floppy. Remove the thick outer leaves and trim off any excess hard stem. Dice the cabbage and rinse in your colander under cold running water. Pat cabbage dry with clean paper towel and weigh out 2 lbs. You’ll need about 2.5 tbsp salt for 2 lbs cabbage. Transfer cabbage and sea salt to the mixing bowl, layering the cabbage with the salt and mixing thoroughly for 2-3 minutes. It’s important to mix the cabbage and salt together well to prevent bad bacteria from developing where there’s a lack of salt.\nFill your Jars\nFill your jars with the cabbage mixture and press down firmly to pack the cabbage down into the jars. Fill the jars to about an inch and a half from the top, and then pour your brine over the cabbage to fully cover it, leaving about ¾ of an inch at the top for gases to escape (this is particularly important if you’re using Fido jars without an airlock). Place your fermentation weight, such as Pickle Pebbles, on top of the cabbage to prevent any pieces from floating to the top. Make sure that all the cabbage stays fully submerged in the brine. Seal the lids of your jars.\nTo make the most of the healthy probiotics in fermented foods, you’ll want to leave your jars out (don’t refrigerate them) for 3-4 weeks at between 20 and 35?C (approx. 70-95F).\nMake sure to keep an eye on your fermentation lab as it progresses. While the appearance of a white film on top and some white sediment at the bottom can be fine, there are some warning signs to watch for that may indicate that your ferment has taken a wrong turn: mold, slime, creamy film, a yeasty odor, or pink or brown cabbage. These signs indicate that your cabbage is likely unsafe to eat. Back to the drawing board. Practice makes perfect!\nIf things are on track, 3-4 weeks later, your cabbage is ready to eat. It will be packed with healthy probiotics for a balanced gut.\nFor more information on the science of fermentation and detailed instructions on how to perfect your sauerkraut, check out Nourishing Treasures.\nPractice Makes Perfect\nAlthough home fermenting can seem overwhelming at first, practice makes perfect. Once you’ve mastered the basic process, you can start experimenting with a wide range of vegetables, and it is absolutely worth the effort. Ensuring that you’ve got a healthy gut will have a positive ripple effect for your overall health, right up to your psychological and emotional well-being.']	['<urn:uuid:72f4c5bf-5a6e-40a4-9e56-05aa61f8671f>', '<urn:uuid:afe72f7e-9d22-4e0c-8c46-7c3078026300>']	open-ended	direct	verbose-and-natural	similar-to-document	multi-aspect	novice	2025-05-01T22:47:46.423955	28	112	1972
13	I'm curious about what futuristic writers anticipated about modern technology. Have any notable sci-fi authors been particularly prescient about tech's impact on society while being low-tech themselves?	Several renowned writers accurately foresaw technology's impact while living low-tech lives themselves. Philip K. Dick, Ursula K. Le Guin, Don DeLillo, and Barry Malzberg predicted how technology would reshape society better than Silicon Valley innovators. Le Guin didn't drive, DeLillo doesn't use email, and Dick rarely left his apartment, yet they had remarkable insight into technology's future role.	['How do New York Times journalists use technology in their jobs and in their personal lives? David Streitfeld, a technology reporter in San Francisco, discussed the tech he’s using — and not using.\nFor a tech journalist, you don’t use a lot of tech.\nOne of the great victories of the tech industry was insisting that if you didn’t love its products, and by extension the companies themselves, you were not fit to cover it. I never understood how that edict gained traction. We don’t think that crooks make the best crime reporters.\nI took my inspiration from writers I admired — Philip K. Dick, Ursula K. Le Guin, Don DeLillo, Barry Malzberg. They were all low-tech people. Le Guin didn’t drive. DeLillo doesn’t do email. Dick barely left his apartment. Malzberg lives in New Jersey. Yet they foresaw how technology would reshape society better than any of the geniuses in Silicon Valley.\n“What technology can do becomes what we need it to do,” DeLillo said. Le Guin observed: “The internet just invites crap from people.” Those quotes sum up the last 20 years.\nWhat tech do you actually use?\nI still marvel at email.\nThat’s not enough? Another illusion promoted by Big Tech is that everyone is using it. After all, everyone in America is on Facebook, right? Everyone with an opinion is on Twitter. But most of the people I know aren’t on either. They live in the real world.\nI exaggerate a bit. For all Twitter’s resemblance to the last chapters of “Lord of the Flies,” it’s a remarkably good way to find unusual stories and fresh viewpoints.\nMy method: I select someone who just posted a hot take, and then I read backward through his or her tweets while also reading the replies to them. If he or she is a prolific tweeter, you quickly end up in his or her brain — for better or worse. I generally do this after midnight, fortified by a glass of gin. I rarely tweet myself, because my only followers are Russian bots and my editor, who is contractually required to read everything I write.\nYou’ve written about Amazon since the beginning. Sometimes you give it up as a subject, and yet you’re always drawn back.\nThey want to take over the world, and they want to keep it all secret. What could possibly be more alluring for a reporter?\nAmazon is the first 21st-century company, an attempt to become the interface between you and everything else, starting with your nearest and dearest. Just watch the rollout film for the Echo from 2014 — it’s all there. Amazon will mediate every one of your desires. Unless Google gets there. The Amazon-Google War will define our era.\nWhat piece of book technology do you use every day?\nViaLibri.net is an excellent book search engine. It doesn’t sell you the book, but tells you, for free, who is selling a copy or, for really obscure stuff, the closest academic library with a copy. I use it the way other people use Google.\nThe volume of material out there still amazes me. Even leaving aside e-books, the internet has changed reading forever. You used to have to struggle to find books by, say, the baroque fantasist Avram Davidson or Harry Stephen Keeler, the early-20th-century novelist whose bizarre stories eventually alienated his audience completely. Now their entire works, and everyone else’s, can be painlessly found by anyone who wants them. Literary culture is fragmenting and deepening in front of our eyes.\nWhat’s the No. 1 question you’re asked about buying books on the web?\n“Is it possible to buy used books on the internet without buying from Amazon?”\nIt’s certainly not easy. People sometimes tell me they’ve given up Amazon for AbeBooks, a virtual storefront for a worldwide network of dealers. They don’t realize it is owned by Amazon, something Amazon certainly does not go out of its way to point out.\nEBay gets a lot less attention than it used to, but it is still a good source of books unavailable elsewhere. There is a competitor to Abe called Biblio, which lists some of the same books and is still independent. Biblio’s best feature is an annual membership for $20, whose sole function is to provide a 10 percent discount. It pays for itself pretty quick.\nAre there other book sites you like?\nThe Book Depository is a British bookseller that is in some ways the anti-Amazon. It has a clunky website that feels trapped in 2003. But the store has one great redeeming feature: It does not charge for postage, which is considerable across the ocean. A copy of Le Guin’s latest nonfiction collection — not published in America — would cost me $30 from Amazon.co.uk. From the Book Depository, it is $17.\nThey either have a sweet deal with the United States Postal Service, which delivers their packages, or they take a bath on every order. Did I mention that the Book Depository is owned by Amazon?\nYou and your wife raised your 8-year-old daughter in a largely tech-free household. How?\nFor the first couple of years, our girl never saw any tech at home more complicated than a blender. She did not see her first video until she was 4, on a holiday weekend when she was sick. Instead there were a lot of books around, and they got heavy use.\nShe turned out to be a great reader, confirming the old notion that kids become either just like their parents or like their nightmare opposite, which in my case would have meant a “declutterer” like Marie Kondo. She devoured the “Oz” books, even the ones by Ruth Plumly Thompson. We read aloud E. Nesbit’s hilarious “Treasure Seekers” series about a late-Victorian family of dim bulbs, and she brought in “Moby-Dick” for show and tell. For a while we were pretty smug parents.\nWhat went wrong?\nShe picked up on the playground all sorts of information about Katy Perry and Taylor Swift, and now demands 10 minutes of YouTube songs a night that often mysteriously expands to half an hour.\nTechnology is creeping in on many fronts. On trips she listens to audiobooks that we get through Overdrive. She tunes her violin with an app and practices Hebrew via Duolingo. I am bracing myself for the teenage years. Her favorite phrase is “How dare you.” She’s a natural for Twitter.']	['<urn:uuid:8fd07b9f-96bd-42c9-8e9b-92958b02a38d>']	factoid	with-premise	verbose-and-natural	distant-from-document	single-doc	expert	2025-05-01T22:47:46.423955	27	58	1071
15	What is PPTP protocol and why should I avoid it?	PPTP (Point-to-Point Tunneling Protocol) is a Microsoft-developed VPN protocol that's widely supported across operating systems including Windows, Mac OS, and mobile devices, making it easy to set up. However, you should avoid it because it has significant security weaknesses. It has a long history of insecurities and typically uses lower grade encryption ciphers like MD4 or DES. While it's commonly used for secure communication between Windows hosts on intranets, it's considered the least secure VPN method compared to more modern protocols like SSL or IPSec, which provide much stronger protection for your data.	['|< Day Day Up >|\nCommon VPN and Tunneling Protocols\nLet us discuss the most common and widely used real-world VPN protocols. The growing number of users, the ease of accessibility, and the reduced cost of the Internet connection have introduced a greater need for cost-effective and secure communications without purchase of leased lines. Many companies participated in the development that resulted in the creation of different VPN standards and protocols. We discuss the most common ones here.\nIPSec is the most widely acknowledged, supported, and standardized of all VPN protocols. It is the ultimate choice for interoperability reasons. IPSec is a framework of open standards that produced a secure suite of protocols that can be run on top of the existing IP connectivity. It provides both data authentication and encryption services at the third OSI layer and can be implemented on any device that communicates over IP. Unlike many other encryption schemes that protect a specific high-layer protocol, IPSec, working at the lower layer, can protect all traffic that is carried over IP. It is also used in conjunction with Layer 2 tunneling protocols to provide both encryption and authentication for non-IP traffic.\nThe protocol incorporates three major components: the Authentication Header (AH), Encapsulating Security Payload (ESP), and Internet Key Exchange (IKE).\nThe AH is added after the IP header and provides packet-level authentication and integrity services, ensuring that the packet was not tampered with along the way and originated from the expected sender. ESP provides confidentiality, data origin authentication, integrity, optional antireplay service, and limited traffic flow confidentiality. Finally, IKE negotiates security associations that describe the use of security services between participating entities.\nPoint-to-Point Tunneling Protocol (PPTP) is a proprietary development of Microsoft intended for VPN-like communications. PPTP offers user authentication employing authentication protocols such as MS-CHAP, CHAP, SPAP, and PAP. The protocol lacks the flexibility offered by other solutions and does not possess the same level of interoperability as the other VPN protocols, but its use is easy and abundant in the real world.\nIt consists of three types of communication:\nPPTP is commonly used for creation of secure communication channels between a large number of Windows hosts on the intranet. We have to caution you that it has a long history of insecurities and typically uses lower grade encryption ciphers, such as MD4 or DES.\nGeneric Routing Encapsulation (GRE) is a Cisco-developed protocol that is used in networking to tunnel traffic between different private networks. This includes non-IP traffic that cannot be carried across the network in its native form. Even though it does not provide any encryption by itself, it does provide efficient low-overhead tunneling. GRE is often used in conjunction with network-layer encryption protocols to accommodate both features provided by GRE, such as encapsulation of non-IP protocols, and encryption provided by other protocols, such as IPSec.\nJointly developed by Cisco, Microsoft, and 3Com, L2TP promised to replace PPTP as a major tunneling protocol. It is essentially a combination of PPTP and Cisco Layer Two Forwarding (L2F), merging both into a single standard. L2TP is used to tunnel PPP over a public IP network. It relies on PPP to establish a dial-in connection using PAP or CHAP authentication but, unlike PPTP, L2TP defines its own tunneling protocol. Because L2TP works on Layer 2, the non-IP protocols can be transported through the tunnel, yet it will work on any Layer 2 media, such as ATM, Frame Relay, or 802.11. The protocol does not offer encryption by itself, but it can be used in conjunction with the other protocols or application-layer encryption mechanisms to provide for security needs.\n|< Day Day Up >|', 'And that’s a damn shame, because VPNs can be helpful tools for protecting online privacy, and you need not be an office drone to enjoy their benefits.\nA VPN, as its name suggests, is just a virtual version of a secure, physical network—a web of computers linked together to share files and other resources. But VPNs connect to the outside world over the Internet, and they can serve to secure general Internet traffic in addition to corporate assets. In fact, the lion’s share of modern VPNs are encrypted, so computers, devices, and other networks that connect to them do so via encrypted tunnels.\nWhy you want a VPN\nYou have at least four great reasons to start using a VPN. First, you can use it to connect securely to a remote network via the Internet. Most companies maintain VPNs so that employees can access files, applications, printers, and other resources on the office network without compromising security, but you can also set up your own VPN to safely access your secure home network while you’re on the road.\nSecond, VPNs are particularly useful for connecting multiple networks together securely. For this reason, most businesses big and small rely on a VPN to share servers and other networked resources among multiple offices or stores across the globe. Even if you don’t have a chain of offices to worry about, you can use the same trick to connect multiple home networks or other networks for personal use.\nThird, if you’re concerned about your online privacy, connecting to an encrypted VPN while you’re on a public or untrusted network—such as a Wi-Fi hotspot in a hotel or coffee shop—is a smart, simple security practice. Because the VPN encrypts your Internet traffic, it helps to stymie other people who may be trying to snoop on your browsing via Wi-Fi to capture your passwords.\nFourth and finally, one of the best reasons to use a VPN is to circumvent regional restrictions—known as geoblocking—on certain websites. Journalists and political dissidents use VPNs to get around state-sponsored censorship all the time, but you can also use a VPN for recreational purposes, such as connecting to a British VPN to watch the BBC iPlayer outside the UK. Because your Internet traffic routes through the VPN, it looks as if you’re just another British visitor.\nPick your protocol\nWhen choosing a networking protocol for your VPN, you need worry only about the four most popular ones. Here’s a quick rundown, including the strengths and weaknesses of each.\nPoint-to-Point Tunneling Protocol (PPTP) is the least secure VPN method, but it’s a great starting point for your first VPN because almost every operating system supports it, including Windows, Mac OS, and even mobile OSs.\nLayer 2 Tunneling Protocol (L2TP) and Internet Protocol Security (IPsec) are more secure than PPTP and are almost as widely supported, but they are also more complicated to set up and are susceptible to the same connection issues as PPTP is.\nSecure Sockets Layer (SSL) VPN systems provide the same level of security that you trust when you log on to banking sites and other sensitive domains. Most SSL VPNs are referred to as “clientless,” since you don’t need to be running a dedicated VPN client to connect to one of them. They’re my favorite kind of VPN because the connection happens via a Web browser and thus is easier and more reliable to use than PPTP, L2TP, or IPsec.\nOpenVPN is exactly what it sounds like: an open-source VPN system that’s based on SSL code. It’s free and secure, and it doesn’t suffer from connection issues, but using OpenVPN does require you to install a client since Windows, Mac OS X, and mobile devices don’t natively support it.\nIn short: When in doubt, try to use SSL or OpenVPN. Keep in mind that some of the services highlighted in the next section don’t use these protocols. Instead, they use their own proprietary VPN technology.\nNow, let’s talk about how to create and connect to your own VPN. If you want simple remote access to a single computer, consider using the VPN software built into Windows. If you’d like to network multiple computers together quickly through a VPN, consider installing stand-alone VPN server software.\nIf you need a more reliable and robust arrangement (one that also supports site-to-site connections), consider using a dedicated VPN router. And if you just want to use a VPN to secure your Internet traffic while you’re on public Wi-Fi hotspots and other untrusted networks—or to access regionally restricted sites—consider subscribing to a third-party hosted VPN provider.\nSet up a simple VPN with Windows\nWindows comes loaded with a VPN client that supports the PPTP and L2TP/IPsec protocols. The setup process is simple: If you’re using Windows 8, just bring up the Search charm, type\nVPN, and then launch the VPN wizard by clicking Set up a virtual private network (VPN) connection.\nYou can use this client to connect securely to other Windows computers or to other VPN servers that support the PPTP and L2TP/IPsec protocols—you just need to provide the IP address or domain name of the VPN server to which you want to connect. If you’re connecting to a corporate or commercial VPN, you can contact the administrator to learn the proper IP address. If you’re running your own VPN server via Windows, you can figure out the server’s IP address by typing\nCMD in the Search charm, launching the Command Prompt, and typing\nipconfig. This simple trick comes in handy when you’re setting up your Windows PC as a VPN server, and then connecting to it so that you can securely, remotely access your files from anywhere.\nQuick note: When setting up incoming PPTP VPN connections in Windows, youmust configure your network router to forward VPN traffic to the Windows computer you want to access remotely. You can do this by logging in to the router’s control panel—consult the manufacturer’s instructions on how to do this—and configuring the port-forwarding or virtual-server settings to forward port 1723 to the IP address of the computer you wish to access. In addition, PPTP or VPN pass-through options need to be enabled in the firewall settings, but usually they’re switched on by default.\nIf you’re using Windows 7 and you need to connect to a VPN or to accept incoming VPN connections in that OS, check out our guide to setting up a VPN in Windows 7.\nUse third-party software to create a VPN server\nIf you’d like to create a VPN between multiple computers to share files and network resources without having to configure your router or to dedicate a PC to act as the VPN server, consider using third-party VPN software. Comodo Unite, Gbridge, andTeamViewer are all decent, reliable, and (most important) free.\nYou can also use LogMeIn Hamachi for free with five or fewer users, but it’s good enough that if you have more than five PCs you want to link up securely—say, as part of your small-but-growing business—you should consider paying for the full service.\nGo whole hog with your own VPN router\nIf you want to get your hands dirty while providing robust remote access to an entire network, or if you wish to create site-to-site connections, try setting up a router on your network with a VPN server and client. If you’re working on a budget, the cheapest way to set up your own dedicated VPN router is to upload aftermarket firmware that enables VPN functionality, such as DD-WRT or Tomato, to an inexpensive consumer-level router.\nYou can also purchase a specially designed router (commonly called a VPN router) with a VPN server built in, such as the ZyXel ZyWall 802.11n Wireless Internet Security Gigabit Firewall (USG20W), Cisco Wireless Network Security Firewall Router (RV220W), or Netgear ProSecure UTM Firewall with Wireless N (UTM9S).\nWhen you’re choosing a VPN router and third-party router firmware, make sure they support the VPN networking protocol you need for your devices. In addition, check the VPN router to verify how many simultaneous VPN users it supports.\nLet a third-party VPN provider worry about it\nIf you merely want VPN access to cloak your Internet traffic while you’re using public Wi-Fi or another untrusted network, or to access regionally restricted sites, the simplest solution is to use a hosted VPN provider. Hotspot Shield is my favorite, as it offers both free and paid VPN services for Windows, Mac, iOS, and Android. HotSpotVPN,StrongVPN, and WiTopia are other paid services we’ve reviewed in the past.\nIf you want to keep your browsing activity anonymous but can’t spare the cash for a paid VPN, check out the Onion Router, a network of servers that can anonymize your Internet traffic for free. Visit the TOR website and download the latest browser bundle, and then start browsing with the TOR extensions enabled. The software will encrypt your connection to the TOR server before routing your Internet traffic through a randomized series of servers across the globe, slowing your browsing speed but cloaking your online activity from prying eyes.\nNo matter how you choose to go about it, start using a VPN today. It takes a bit of work up front, but spending the time to get on a VPN is one of the smartest, simplest steps you can take toward making your online activities more secure.\nEric Geier Contributor\nEric Geier is a freelance tech writer as well as the founder of NoWiresSecurity, a cloud-based Wi-Fi security service, and On Spot Techs, an on-site computer services company.\nMore by Eric Geier']	['<urn:uuid:117d6aba-65c2-472e-97d1-88047ef979f7>', '<urn:uuid:24a9cb2f-3806-4fe3-8def-f4744d9cf35c>']	open-ended	with-premise	concise-and-natural	similar-to-document	multi-aspect	novice	2025-05-01T22:47:46.423955	10	93	2198
16	How do modern x-ray tubes manage heat generation during operation, and what are the recommended safety protocols for operating these devices?	X-ray tubes manage heat through oil-filled housings that act as both electrical isolators and thermal conductors, using conduction in low-use applications, convection with fans in higher-use settings, and cooling systems in very high-use systems. For safety, operators must follow ALARA principles (As Low As Reasonably Achievable), wear extremity and whole-body dosimeters, and receive written authorization before use. The equipment must have fail-safe shutters, interlocks, and indicator lights, with regular checks for radiation leakage.	"['Introduction to Imaging Devices\nMedical imaging predates the recording of an electrocardiogram (ECG) by about 8 years. X-rays were discovered on November 8, 1895, by Wilhelm Conrad Röntgen. Over the next 7 weeks, Röntgen conducted additional research and published his findings. He did not apply for any patent protection on his discovery. He was awarded the Nobel Prize for Physics in 1901.\nMany of the eras top scientists, including the Curies and Thomas Edison, got involved with x-rays. Progress was slow for many years, and some scientists developed x-ray applications that were later abandoned (such as acne and tonsillitis treatment regimens, as well as the commercial viewing of feet to check the fit of shoes). After World War II, mobile vans were equipped with x-ray units for tuberculosis screenings.\nIn the late 1940s in Japan, sound navigation and ranging (sonar), used to detect underwater objects, was adapted for viewing internal organs and structures. Sonar arrived in the United States during the early 1950s, mostly as a research method; it did not achieve wide clinical use until the late 1960s. The 1980s brought color ultrasound, and three-dimensional ultrasonography was developed in the 1990s.\nIn the 1970s, computed tomography (CT) scanning was introduced, but its widespread use was hindered by high costs and low reliability. As electronics advanced, so did CT, to the point that it is now rare for a hospital to not have at least one CT unit.\nThe 1980s brought the introduction of nuclear magnetic resonance imaging, soon called magnetic resonance imaging (MRI) to avoid negative associations with the word nuclear. Early problems associated with motion artifacts and long image-acquisition times have been overcome, and MRI is now a primary diagnostic tool for physicians. Today, imaging technologies such as CT and positron-emission tomography are even being combined.\nX-rays are high-frequency electromagnetic radiation at wavelengths so short (generally 0.01 to 0.1 nm) that they are often thought of as particles (photons). Their energy is measured in electron volts. A clinically useful radiograph requires a minimum of 45 kiloelectron volts. As electrons from a source (filament) are accelerated and strike the target (anode), two types of x-rays are produced, along with heat. General radiation, also known as braking radiation and bremsstrahlung, is generated when the accelerated electron passes near the nucleus of an atom in the target, where it is deflected and decelerated. When this happens, a small amount of x-radiation (1%) is emitted; the other 99% of the output is heat. Characteristic radiation is produced when the accelerated electron, passing near the nucleus of an atom in the target, collides with and ejects an electron from one of the inner rings of the atom. An electron from one of the outer rings will move to replace the ejected electron, emitting an x-ray photon. The intensity of the x-ray beam is the number of photons in the beam multiplied by the energy of each photon (both general and characteristic). Intensity is measured as roentgens per minute.\nX-Ray Tubes and Housing\nThose working in the field should never replace an x-ray tube, as this calls for considerable skill and specialized equipment. The tube housing, however, can be replaced in the field. It contains a new tube that has already been aligned and a jacket filled with oil or (less commonly) another coolant. All tubes contain three basic parts: an enclosure (generally, borosilicate glass, but metallic or ceramic for some high-power tubes); a tungsten-alloy filament; and the anode or target, usually made of tungsten. Most tubes will have one filament for each focal track on the anode, a focusing cup or cathode to direct the electrons moving from the filament to the target, and an anode, with one or more focal tracks machined in it, rotating at up to 20,000 rpm.\nThe various parts are assembled in the enclosure, which is vacuum sealed. The material used to seal the enclosure must have the same expansion characteristics as the enclosure itself so that the vacuum will not break when the tube is heated. If the enclosure is not properly evacuated, it is called a gassy tube; there can be internal arcing and inconsistent output. Sometimes, this can be corrected through a process called seasoning, which is performed when the tube is installed or is reactivated after being unused for a long period.\nFilament voltages range from 2.5 to 15 volts, and each filament in the tube can have a different voltage. The filament current range is generally 3 to 6 amperes. The filaments are left on as long as the unit has power. Since the filaments are kept warm, they release some electrons, which are confined by the cathode. This focus cup also aims the released electrons at the target when the system is generating x-rays.\nThe anode is a disk about 10 cm in diameter and 2 cm or less in thickness. The disk is surfaced with a tungsten alloy over a copper base. Copper is used for its heat-conduction properties. There will be one or more angled focal surfaces or tracks on the disk where the electrons accelerated from the filament hit, to generate the x-ray. In all but the simplest tubes (mostly dental x-ray units), the anode is rotated. The rotating anode allows heat to be distributed over the entire target. This also prevents the focal surfaces from being distorted by the heat, keeping the focal spot consistent and increasing the life of the tube. The bearings on the anode are sealed and self-lubricating; they cannot be worked on in the field.\nThe tube is placed into a housing, and connections are made from the filaments and anode to the exterior connection on the housing. In most cases, the housing is then filled with oil that acts as both an electrical isolator and a thermal conductor to move the heat away from the tube. The tube housing is cooled using conduction in low-use application, convection (with a fan) in higher-use settings, and cooling systems in systems with very high use. Tubes are rated in heat units, and will shut down if their ratings are exceeded. Tube housings with fans need to be cleaned on a regular basis to ensure good cooling.\nFluid levels in the tube housings that require cooling systems should also be checked regularly. Fluid levels can be checked at the window on one side of the tube housing where the x-ray beam exits. Several recent studies have indicated that coolant oil loses its ability to conduct heat after prolonged use; this may contribute to shortened tube life.\nAn indication of this problem in the tube is sputtering (nonlinear output). Heat-unit problems are rare for film studies but common for fluoroscopic studies, so the procedure in progress when the tube started to sputter should be documented.\nThe focal spot of a tube is a function of the geometry of the target, the target material and its texture, the sizes of the filament and the focus cup, and any wobble that may occur in the anode as it rotates. Focal spots are stated in mm (typically 0.3, 0.5, 1, or 1.5 mm). Focal spots are measured using a pinhole camera or a star pattern. With a pinhole camera, the image is measured and divided by the amplification factor. The star pattern requires the use of more mathematics, and it is sometimes difficult to establish where the lines blur. These measurements are made at the factory and by the physicist (during validation testing). The focal spots size, as built, is listed on the tube housing and serves as a reference point for future validations.\nAs the tube ages, the focal spot will increase in size. Some of this growth can be compensated for by radiologic technologists, who may change the voltage, current, and time settings. Traditional thinking holds that the smaller the focal spot is, the better the resolution for small objects becomes. The consistency of the x-rays also affects resolution, however. This is evident when the edges of objects are not sharp, but blended. The use of filters and grids can increase sharpness and decrease the blurred/blended area (also called the edge gradient). The person testing a new tube upon its installation should document not only the size and shape of the focal spot, but also any tilt, blurred edges, or uneven radiation. A hard copy of this information should be kept on file as long as the tube is in service.\nFocal-spot geometry produces an uneven beam of x-radiation. In what is called the heel effect, there is more energy at one end of the field than at the other. Ideally, aligning the tube so that the radiation caused by the heel effect is directed toward the thickest part of the object being studied helps maintain the density and contrast of the image. If complaints start suddenly about density and contrast problems, check to be sure that the tube has not been rotated.\nIn future articles, grids, filters, power supplies, and video systems will be covered. 24×7\nDavid Harrington, PhD, director of staff development and training at Technology in Medicine (TiM), Holliston, Mass, is a member of 24×7s editorial advisory board.\nCarl Genereux is a TiM account manager, Marlborough Hospital, Marlborough, Mass.\n1. An x-ray beam is made up of _____________.\na) general radiation\nc) characteristic radiation\nd) a and c\n2. As an x-ray tube ages, the focal spot ____________________.\n3. Resolution is dependent upon _________________.\nAnswers: 1-d, 2-a, 3-a', 'Radiation Safety for X-ray\nOverview of Issue:\n– Short-term high-dose\n– Long-term low-dose\nInvisible, odorless colorless; most exposures\nLab users must understand radiation safety issues\nand pass an exam to use lab\nSafeguards present in lab do not substitute for\nknowledge and following safe procedures\nSafety Requirements for Lab Use\nThe exam covers:\nRadiation hazards in the XRD Lab\nBiological effects of X-ray exposures including\nlocalized exposures and long-term risks\nQuantities and units of exposure, dose and dose\nequivalent (roentgen, rad, rem)\nRegulations concerning use and control of\nAll students must pass a radiation safety exam for X-ray\nDiffraction users by week six of the course. This exam is\nadministered by UNM’s Safety Health and Environmental\nAffairs (SHEA) office.\nRadiation Safety Tutorial\nNDT (Nondestructive Testing Resource Center) Radiation\nSafety Tutorial (Comprehensive and Excellent)\n( http://www.ndt-ed.org/EducationResources/CommunityCollege/RadiationSafety/cc_rad-safety_index.htm )\nSummary article by Jenkins and Haas (1973) available on\n“Resources” page on our lab web site\nIndiana University Analytical X-Ray Safety guide\n(available on our “Resources” page)\nNBS Handbook 111 (1977) guide is dated but still accurate\nand useful (available on our “Resources” page)\nClass materials on Radiation Safety\nTutorial materials (may be) available through UNM’s\nradiation safety office (have been rare lately)\nInteraction of X-rays with Matter\nRadiation interacts with matter by transfer of energy. Main\n– Absorption (energy transferred)\n– Scattering (energy redirected)\nAbsorption is of most concern in x-ray interaction with\nTypes of Energy Transfer:\nInvolves reaction with orbital shell electrons\nInvolves multiple reactions until all energy is spent\nHighest potential for damage to target.\nSome of incoming x-ray energy is transferred to target\nTypical result is release of heat and a rise in temperature\nThree processes are dominant in the production of ionizing radiation:\nPhotoelectric effect, Compton scattering, and Pair production. Which\neffect dominates is related to the atomic weight of the target material\nand the energy of the “producing” radiation.\nAt XRD energies (~10 keV or ~0.01 MeV), the photoelectric effect is dominant\nPhotoelectric (PE) absorption of x-rays occurs when the x-ray\nphoton is absorbed resulting in the ejection of electrons from the\nAn incident x-ray photon\ninteracts with an inner-shell\norbital electron, dislodging it\nand producing a photoelectron.\nAn outer shell electron moves\nto fill the vacancy, producing\na characteristic x-ray.\nThe photoelectron may escape\nthe atom or interact with an\nouter shell electron producing\nlower energy Auger electron\nInteractions continue until all\nenergy is dissipated\nPhotoelectron interaction with the target atom is described by\nthe following equation:\nKE = Ex - P\n• KE is the kinetic energy of the photoelectron\n• Ex is the energy of the incident X-ray photon\n• P is the energy required to remove the electron or its\nbinding energy in the atom\nAs regards interaction with matter (particularly living tissue),\nall of these interactions can result in atomic and molecular\ndamage and heat.\n– Also called “incoherent scattering”\n– Occurs when an X-ray photon ejects an electron\nand scatters a lower energy X-ray photon from\n– Occurs between 100 keV and 10 Mev; not\nsignificant at energies involved in XRD\n– Produces an electron and positron with\nannihilation of the X-ray photon\n– Occurs with X-ray photons exceeding 2 MeV\n– Does not occur at energies involved in XRD\nOther Radiation Effects\nWhile other effects are minor as regards radiation damage effects and\nsafety, they can be significant in other aspects of radiation science.\nThomson Scattering (a.k.a Rayleigh,\ncoherent or classical scattering) is what\nmakes X-ray diffraction possible\nPhotodisintegration occurs when the X-ray\nphoton is captured by the nucleus with the\nejection of a particle at high energy from\nthe nucleus. This high-energy process is\nintrinsic to nuclear fission reactions\nMeasurement of Radiation Dose\nRoentgen (R) is a unit of radiation exposure. It is the\namount of radiation that generates 2.58 x 10-4 coulombs\nper kilogram of air (at STP).\nThe RAD (Roentgen-Absorbed Dose) is the amount of\nradiation that will deposit 0.01 Joules of energy in a kg of\nmaterial. One R is about .87 RAD in air, 0.93 RAD in\ntissue and 0.97 RAD in bone\nThe REM (Roentgen-Equivalent Man) is the absorbed\ndose in RADSs multiplied by a weighting factor for the\ntype of radiation. For x-rays the factor is 1, thus 1RAD =\nThe SI unit for the RAD is the gray equivalent to 100 RAD.\nThe SI unit for the REM is the sievert, equivalent to 100 REM.\nDosages are commonly expressed in R/hr or mR/hr. Received\ndosages are expressed as REM or mREM over a specified\nperiod of exposure time (hr, day, year, etc.).\nNatural Sources (300 mREM): ""Natural"" background radiation\nconsists of radiation from cosmic radiation, terrestrial radiation,\ninternal radionuclides, and inhaled radon.\nOccupational Sources (0.9 mREM): According to NCRP Report No.\n93, the average dose for workers that were actually exposed to\nradiation in 1980 was approximately 230 mREM.\nThe Nuclear Fuel Cycle (0.05 mREM): Each step in the nuclear fuel\ncycle can produce radioactive effluents in the air or water.\nConsumer Products (5-13 mREM): The estimated annual dose from\nsome commonly-used consumer products such as cigarettes (1.5\npack/day, 8,000 mREM) and smoke detectors (1 mREM) contribute to\ntotal annual dose.\nMiscellaneous Environmental Sources (0.6 mREM): A few\nenvironmental sources of background radiation are not included in the\nMedical Sources (53 mREM): The two contributors to the radiation\ndose from medical sources are diagnostic x-rays and nuclear medicine.\nOf the estimated 53 mREM dose received annually, approximately 39\nmREM comes from diagnostic x-rays.\nBelow are estimates of natural and man-made background radiation at sea\nlevel at middle latitudes. The total averages 400 – 500 mREM/yr\nMaximum Permissible Dose Equivalents for\nRadiation controlled areas:\nWhole body, gonads, blood-\nforming organs, and lens of eye\n0.1 3 5 5(N - 18)d\nSkin of whole body – 10 30 –\nHands and forearms, head\nneck, feet, and ankles\n– 25 75 –\nAny part of body .01 – 0.5 –\nNotes: Avg week dose is for design purposes only\n1 REM assumed = 1 R\nNote a: N = age in years\nFor minors, dose limits are 10% of adult limits and radiation work is not permitted\nSource: National Bureau of Standards Handbook 59 (1958) with addendums.\nIn terms of absolute energy content, 1 RAD\nis not a lot (i.e., ~ 0.01 joule absorbed/kg).\nThe main risks associated exposure to\nanalytical X-rays are\n– High Intensity Exposures: Skin burns and\nlesions and possible damage to eye tissue\n– Long-term chronic Exposures: Possible\nchromosomal damage and long term risk of\nGoal of all Radiation Safety practice is\nALARA – As Low as Reasonably\nLong-term Effects of Radiation Exposure\nLong-term effects are usually related to increased risk of cancer,\nsummarized in the table below:\nDisease Additional Cases per 100,000 (with\none-time 10 REM dose) *\nAdult leukemia 95\nCancer of digestive system 230\nCancer of respiratory system 170\n* Source: Biological Effects of Ionizing Radiation V (BEIR V) Committee\nRadiation-induced life shortening (supported by animal experiments)\nsuggests accelerated aging may result in the loss of a few days of life\nas a result of each REM of exposure\nGenetic Effects of radiation fall into two general categories\n– Effect on individuals: Can change DNA and create mutation but long\nterm effects not well understood. Biological repair mechanisms may\n– Effect of offspring: Exposure to a fetus in utero can have profound\neffects on developing organs resulting in severe birth defects. For this\nreason pregnant women should avoid any non-background exposures\nBioeffects on Surface tissues\nBecause of the low energy (~8 keV for Cu) of\nanalytical x-rays, most energy will be absorbed by\nskin or other exposed tissue\nThe threshold of skin damage is usually around\n300 R resulting in reddening of the skin\nLonger exposures can produce more intense\nerythema (i.e., “sunburn”) and temporary hair loss\nEye tissue is particularly sensitive – if working\nwhere diffracted beams could be present, eye\nprotection should be worn\nRadiation Sources in X-Ray\nThe primary beam from the X-ray tube tower can deliver as much\nas 400,000 R/minute\nAfter collimation and filtration about 5,000 – 50,000 R/min reaches\nThe diffracted beam, radiating in all directions from a sample, can\nbe as much as 80 R/hr.\nExposure of any part of the body to the primary beam will deliver\nhundreds of times the maximum permissible yearly dose in a\nfraction of a second\nAn hour of exposure to the diffracted beam can result in a year’s\nworth of permissible exposure.\nMalfunctioning HV Power supplies can be a source of radiation and\nit is important that these devices be well shielded from workers\nMeasures taken to Reduce Risk of\nExposure in the Laboratory\nComplete enclosure of source and diffractometer whenever possible.\nSpring-loaded fail safe shutters on the X-ray primary beam.\nFail-safe interlocks installed on the housing.\nA fail-safe indicator light in the shutter-opening circuit.\nSeal all openings in the housing with lead tape.\nPeriodic checks of the system for leakage at normal operating\nconditions using properly calibrated survey equipment. There is no\nrequired interval for this, but it must be requested if the following\n– Prior to the receipt of new equipment\n– Prior to a change in the arrangement, number , or type of local\ncomponents in the system\n– Prior to any maintenance requiring the disassembly or removal of a local\ncomponent in the system\n– Anytime a visual inspection of the system reveals an abnormal condition.\nHigh-voltage power supplies, if not functioning properly, can be the\nsource of X-rays. It is important that the HV voltage multipliers and\nother circuitry be properly shielded to eliminate this as a possible\nThe Three Principles of Radiation\nDecrease Time of exposure in field of\nIncrease Distance from a source of\nradiation. Intensity decreases as the inverse\nsquare of the distance.\nIncrease Shielding around radiation sources\nCauses of XRD Lab Accidents\n1. Poor equipment configuration, e.g. unused beam\nports not covered\n2. Manipulation of equipment when energized, e.g.,\nadjustment of samples or alignment of cameras\nwhen x-ray beam is on.\n3. Equipment failure, e.g., shutter failure, warning\n4. Inadequate training or violation of procedure,\ne.g., incorrect use of equipment, overriding\nIn our lab with the equipment we have and how it is set up, 1, 2,\nand 3 are very unlikely.\n#4 is always possible and is ultimately up to you.\nUNM Requirements for Analytical\nNo persons will be allowed to use analytical X-ray\nequipment until authorized in writing by the Radiation\nNo individuals under 18 years of age may use or assist in\nthe use of analytical X-ray equipment\nOperating procedures shall be written and available to\nusers and inspectors of analytical X-ray equipment\nNo person shall bypass a safety device without written\nauthorization from the Radiation Safety Office.\nExtremity and whole-body dosimeters must be worn while\noperating analytical X-ray equipment.\nThe Radiation Safety Office must be promptly notified\nwhenever exposure is suspected.\nA particular slide catching your eye?\nClipping is a handy way to collect important slides you want to go back to later.']"	['<urn:uuid:7e2c3c05-5f85-48df-b260-1b340e984f37>', '<urn:uuid:53d9cf6d-5415-4d73-a354-0f6f305b46d6>']	factoid	direct	verbose-and-natural	distant-from-document	multi-aspect	expert	2025-05-01T22:47:46.423955	21	73	3403
20	What are the main symptoms someone should look out for to know if they are getting dehydrated from gastroenteritis?	Dehydration should be suspected if a person experiences a dry mouth, increased or excessive thirst, or scanty urination.	"['Gastroenteritis is a catchall term for infection or irritation of the digestive tract, particularly the stomach and intestine. It is frequently referred to as the stomach or intestinal flu, although the influenza\nvirus is not associated with this illness. Major symptoms include nausea and vomiting\n, diarrhea, and abdominal cramps. These symptoms are sometimes also accompanied by fever\nand overall weakness. Gastroenteritis typically lasts about three days. Adults usually recover without problem, but children, the elderly, and anyone with an underlying disease are more vulnerable to complications such as dehydration\nGastroenteritis is an uncomfortable and inconvenient ailment, but it is rarely life-threatening in the United States and other developed nations. However, an estimated 220,000 children younger than age five are hospitalized with gastroenteritis symptoms in the United States annually. Of these children, 300 die as a result of severe diarrhea and dehydration. In developing nations, diarrheal illnesses are a major source of mortality. In 1990, approximately three million deaths occurred worldwide as a result of diarrheal illness.\nThe most common cause of gastroenteritis is viral infection. Viruses such as rotavirus, adenovirus, astrovirus, and calicivirus and small round-structured viruses (SRSVs) are found all over the world. Exposure typically occurs through the fecal-oral route, such as by consuming foods contaminated by fecal material related to poor sanitation. However, the infective dose can be very low (approximately 100 virus particles), so other routes of transmission are quite probable.\nTypically, children are more vulnerable to rotaviruses, the most significant cause of acute watery diarrhea. Annually, worldwide, rotaviruses are estimated to cause 800,000 deaths in children below age five. For this reason, much research has gone into developing a vaccine to protect children from this virus. Adults can be infected with rotaviruses, but these infections typically have minimal or no symptoms.\nChildren are also susceptible to adenoviruses and astroviruses, which are minor causes of childhood gastroenteritis. Adults experience illness from astroviruses as well, but the major causes of adult viral gastroenteritis are the caliciviruses and SRSVs. These viruses also cause illness in children. The SRSVs are a type of calicivirus and include the Norwalk, Southhampton, and Lonsdale viruses. These viruses are the most likely to produce vomiting as a major symptom.\nBacterial gastroenteritis is frequently a result of poor sanitation, the lack of safe drinking water, or contaminated food-conditions common in developing nations. Natural or man-made disasters can make underlying problems in sanitation and food safety worse. In developed nations, the modern food production system potentially exposes millions of people to disease-causing bacteria through its intensive production and distribution methods. Common types of bacterial gastroenteritis can be linked to Salmonella\nbacteria; however, Escherichia coli\n0157 and Listeria monocytogenes\nare creating increased concern in developed nations. Cholera\nand Shigella remain two diseases of great concern in developing countries, and research to develop long-term vaccines against them is underway.\nCauses and symptoms\nGastroenteritis arises from ingestion of viruses, certain bacteria, or parasites. Food that has spoiled may also cause illness. Certain medications and excessive alcohol can irritate the digestive tract to the point of inducing gastroenteritis. Regardless of the cause, the symptoms of gastroenteritis include diarrhea, nausea and vomiting, and abdominal pain\nand cramps. Sufferers may also experience bloating, low fever, and overall tiredness. Typically, the symptoms last only two to three days, but some viruses may last up to a week.\nA usual bout of gastroenteritis shouldn\'t require a visit to the doctor. However, medical treatment is essential if symptoms worsen or if there are complications. Infants, young children, the elderly, and persons with underlying disease require special attention in this regard.\nThe greatest danger presented by gastroenteritis is dehydration. The loss of fluids through diarrhea and vomiting can upset the body\'s electrolyte balance, leading to potentially life-threatening problems such as heart beat abnormalities (arrhythmia). The risk of dehydration increases as symptoms are prolonged. Dehydration should be suspected if a dry mouth\n, increased or excessive thirst, or scanty urination is experienced.\nIf symptoms do not resolve within a week, an infection or disorder more serious than gastroenteritis may be involved. Symptoms of great concern include a high fever (102 ° F [38.9 °C] or above), blood or mucus in the diarrhea, blood in the vomit, and severe abdominal pain or swelling. These symptoms require prompt medical attention.\nThe symptoms of gastroenteritis are usually enough to identify the illness. Unless there is an outbreak affecting several people or complications are encountered in a particular case, identifying the specific cause of the illness is not a priority. However, if identification of the infectious agent is required, a stool sample will be collected and analyzed for the presence of viruses, disease-causing (pathogenic) bacteria, or parasites.\nGastroenteritis is a self-limiting illness which will resolve by itself. However, for comfort and convenience, a person may use over-the-counter medications such as Pepto Bismol to relieve the symptoms. These medications work by altering the ability of the intestine to move or secrete spontaneously, absorbing toxins and water, or altering intestinal microflora. Some over-the-counter medicines use more than one element to treat symptoms.\nIf over-the-counter medications are ineffective and medical treatment is sought, a doctor may prescribe a more powerful anti-diarrheal drug, such as motofen or lomotil. Should pathogenic bacteria or parasites be identified in the patient\'s stool sample, medications such as antibiotics\nwill be prescribed.\nIt is important to stay hydrated and nourished during a bout of gastroenteritis. If dehydration is absent, the drinking of generous amounts of nonalcoholic fluids, such as water or juice, is adequate. Caffeine\n, since it increases urine output, should be avoided. The traditional BRAT diet-bananas, rice, applesauce, and toast-is tolerated by the tender gastrointestinal system, but it is not particularly nutritious. Many, but not all, medical researchers recommend a diet that includes complex carbohydrates (e.g., rice, wheat, potatoes, bread, and cereal), lean meats, yogurt, fruit, and vegetables. Milk and other dairy products shouldn\'t create problems if they are part of the normal diet. Fatty foods or foods with a lot of sugar should be avoided. These recommendations are based on clinical experience and controlled trials, but are not universally accepted.\nMinimal to moderate dehydration is treated with oral rehydrating solutions that contain glucose and electrolytes. These solutions are commercially available under names such as Naturalyte, Pedialyte, Infalyte, and Rehydralyte. Oral rehydrating solutions are formulated based on physiological properties. Fluids that are not based on these properties-such as cola, apple juice, broth, and sports beverages-are not recommended to treat dehydration. If vomiting interferes with oral rehydration, small frequent fluid intake may be better tolerated. Should oral rehydration fail or severe dehydration occur, medical treatment in the form of intravenous (IV) therapy is required. IV therapy can be followed with oral rehydration as the patient\'s condition improves. Once normal hydration is achieved, the patient can return to a regular diet.\nSymptoms of uncomplicated gastroenteritis can be relieved with adjustments in diet, herbal remedies, and homeopathy. An infusion of meadowsweet (Filipendula ulmaria\n) may be effective in reducing nausea and stomach acidity. Once the worst symptoms are relieved, slippery elm (Ulmus fulva\n) can help calm the digestive tract. Of the homeopathic remedies available, Arsenicum album\n, or Nux vomica\nare three said to relieve the symptoms of gastroenteritis.\nProbiotics, bacteria that are beneficial to a person\'s health, are recommended during the recovery phase of gastroenteritis. Specifically, live cultures of Lactobacillus acidophilus are said to be effective in soothing the digestive tract and returning the intestinal flora to normal. L. acidophilus is found in live-culture yogurt, as well as in capsule or powder form at health food stores. The use of probiotics is found in folk remedies and has some support in the medical literature. Castor oil packs to the abdomen can reduce inflammation and also reduce spasms or discomfort.\nGastroenteritis is usually resolved within two to three days and there are no long-term effects. If dehydration occurs, recovery is extended by a few days.\nThere are few steps that can be taken to avoid gastroenteritis. Ensuring that food is well-cooked and unspoiled can prevent bacterial gastroenteritis, but may not be effective against viral gastroenteritis.\nHart, C. Anthony, and Nigel A. Cunliffe. ""Viral Gastroenteritis."" Current Opinion in Infectious Diseases 10 (1997): 408.\nMoss, Peter J., and Michael W. McKendrick. ""Bacterial Gastroenteritis."" Current Opinion in Infectious Diseases 10 (1997): 402.\n— A condition in which the body lacks the normal level of fluids, potentially impairing normal body functions.\n— An ion, or weakly charged element, that conducts reactions and signals in the body. Examples of electrolytes are sodium and potassium ions.\n— A sugar that serves as the body\'s primary source of fuel.\n— A virus that affects the respiratory system, causing fever, congestion, muscle aches, and headaches.\n— The bacterial population in the intestine.\n— Bacteria that are beneficial to a person\'s health, either through protecting the body against pathogenic bacteria or assisting in recovery from an illness.']"	['<urn:uuid:a7d1a5b6-6305-4056-b818-6616bcba204c>']	factoid	direct	verbose-and-natural	similar-to-document	single-doc	novice	2025-05-01T22:47:46.423955	19	18	1479
21	mouse stories ancient legends compare modern safety disease risks	In ancient stories and legends, mice were often portrayed positively - as in Aesop's fable where a mouse helps a lion, demonstrating bravery despite its small size. This favorable depiction continues in modern entertainment with popular characters like Mickey Mouse and Rastamouse. However, in reality, mice pose serious health and safety risks. They can transmit multiple dangerous diseases including Hantavirus (with a 38% mortality rate), Leptospirosis (which can cause organ failure), and Lymphocytic Choriomeningitis (which can cause neurological damage). Additionally, they cause extensive property damage by chewing through walls, insulation, and electrical wires - with mouse-damaged wires causing approximately 25% of house fires in the United States.	['I’ve had one of the best World Book Days this year. I was the guest author at Southville Primary in Feltham. The children all came dressed up as characters from their favourite books, and so did the teachers and supporting staff. At the end of the school assembly, there was a fashion parade for everyone to show off their costumes, including the adults. My favourite were the three blind mice who braved the catwalk with help and encouragement from the children and each other.\nBy sheer coincidence, I received copies of my next two titles in the GRIMM’S FAIRY TALES series, and one of them is LITTLE MOUSE AND LAZY CAT. It got me thinking about mice in folklore, so I went through my notes, and here is what I found:\nThe Ancient Egyptians, who endowed their gods with animal heads, were terrified of mice, whom they saw as the carriers of disease and destroyers of crops. They associated all rodents with the goddess Sekhmet, the bringer of pestilence. Ruins of houses from the times of the great Pharaohs were found with mouse-holes, plugged up with stones. Curiously, the Egyptians also used mice as medicine, using them to cure anything from upset stomachs to baldness. As mice were usually seen emerging from mud or holes in the ground, people believed they were reborn with every inundation of the Nile. So, although they sometimes brought disease, they were also seen as the givers of life – hence their use in ritualistic medicine. Dead mice were often mummified and placed in temples. Legends and stories about powerful mice abounded, as can be seen in an illustration on papyrus at the British Museum.\nThe Ancient Greeks considered the mouse a powerful animal. It was associated with Apollo, who was sometimes called Lord of the Mice, and often allowed, even encouraged, to nest under his altar in temples. An image of a small rodent was placed by his sacred tripod. No one is sure if these images were put there to honour Apollo or to pacify him in his avatar as the god of disease and pestilence. The mouse, like Apollo, was believed to be a healer not just in Ancient Greece but in other cultures too, where he was often invoked as a healer from snake bite. The profiles of mice were stamped on coins for various city-states.\nPerhaps because of his size, the mouse is often portrayed as brave and helpful in folklore. Whatever the Greeks, and later the Romans thought of mice, the little rodents gnawed their way into legends and folktales. Perhaps the most famous of these is Aesop’s The Lion and The Mouse, in which a lion’s kindness to a captured mouse is returned a hundred-fold. Another ubiquitous Aesop fable tells of a country mouse comparing his lifestyle with that of a sophisticated town mouse and learning to appreciate what he has. Tales like these projected a wholesome image of the mouse, as a hardworking and sensible character.\nAccording to Balinese mythology, the field mouse is the protector of the goddess of the rice. So farmers in Bali have always been loathe to kill rice. Even when hordes of them have been known to plunder rice fields, the farmers would choose to placate their spirits with offerings at the local temples rather than destroy them.\nIn more recent folklore, the mouse appears as a ravishing bride in Finnish legends, as a cook in Japan, a dancer in east Africa, and a wise king in Indian mythology. Modern authors and artists too continue to harness the cuteness we associate with mice to great effect. Maisy Mouse! Mickey and Minnie Mouse! Rastamouse! It’s getting crowded in the mouse-hole of fame.\nI leave you with the shortest folk tale I have ever read. It’ from Scottish Fairy and Folk Tales by George Douglas, published in 1901.\nTHE TWO MICE.\nTHERE was a mouse in the hill, and a mouse in a farm.\n“It were well,” said the hill mouse, “to be in the farm, where one might get things.”\nSaid the farm mouse, “Better is peace.”\nHave you a favourite mouse story, new or old? Please comment about it below!', 'Mice and Rats: Health Hazards and How to Prevent Them\nMice and rats are some of the most damaging and dangerous pests to have in homes and businesses. Their habits cause extensive damage, and they are known carriers of many diseases. It is important to be aware of the risks posed by mouse and rat infestations, so we put together a guide detailing the causes, symptoms, and prevention methods of the main rodent-borne illnesses in the United States.\nHantavirus Pulmonary Syndrome\nHantavirus is a virus spread primarily by deer mice, white-footed mice, cotton rats, and rice rats. Typically, it is contracted after coming into direct contact with rodents or their urine and droppings, or by breathing in dust contaminated with urine or droppings. It can also be contracted through rodent bites, but that is not as common. Symptoms develop between 1 and 8 weeks after exposure, and they occur in two phases. Universal early symptoms include fatigue, fever, and muscle aches. Other early symptoms that occur in about half of all Hantavirus cases include chills, dizziness, headaches, abdominal pain, nausea, vomiting, and diarrhea. Late symptoms begin between 4 and 10 days after the early symptoms phase. These symptoms include coughing, shortness of breath, and lungs filling with fluid. Hantavirus has a mortality rate of 38%.\nLeptospirosis is a bacteria spread by rodents, as well as other animals. It is contracted by eating or drinking contaminated foods and water, or by contact of skin or mucous membranes with contaminated soil or water. Symptoms will typically arrive abruptly between 2 days and 4 weeks after exposure to the bacteria, although some people show no symptoms at all. The illness may occur in two phases. The first phase may consist of fever, chills, abdominal pain, diarrhea, vomiting, headache, muscle aches, red eyes, jaundice, and rash. If a person experiences a second phase, it will be more severe and may occur after a period of recovery from the first phase. The second phase may include liver or kidney failure, respiratory distress, or meningitis. Without treatment, recovery from leptospirosis may take months, and in some cases can lead to death.\nPets can also get leptospirosis, although it is rare in cats. Symptoms that are commonly seen in dogs include fever, abdominal pain, vomiting, diarrhea, refusal to eat, severe weakness and muscle pain, stiffness, severe depression, and the inability to have puppies. Younger animals are usually affected more than older animals.\nLymphocytic Choriomeningitis (LCM)\nLymphocytic choriomeningitis, or LCM, is a disease caused by lymphocytic choriomeningitis virus, or LCMV. It is typically spread by house mice. It can also be spread by pet rodents, but that is not as common. An estimated 5% of house mice in the United States carry LCMV. It is contracted either by direct contact with rodents or rodent urine and droppings, or by breathing in dust contaminated by rodent urine and droppings. It can also be spread through bite wounds from infected rodents, although this is much rarer. LCM may occur in two phases. Symptoms of the first phase appear between 8 and 13 days after exposure. Common symptoms of the first phase include fever, nausea, vomiting, lack of appetite, malaise, headache, and muscle aches. Less common symptoms include sore throat, cough, chest pain, joint pain, testicular pain, and pain of the salivary glands. If a second phase occurs, it will do so after a few days of recovery from the first phase. Symptoms of the second phase include, meningitis, encephalitis, meningoencephalitis, acute hydrocephalus, and, in rare cases, myelitis. As LCM is an infection of the nervous system, it can cause temporary or permanent neurological damage, including nerve deafness and arthritis. If a pregnant woman becomes infected with LCMV, she may pass the infection to the fetus. This can result in fetal death during the first trimester, or serious and permanent birth defects during the second and third trimesters. LCM is rarely fatal, with a mortality rate of less than 1%.\nRat-Bite Fever (RBF)\nRat-bite fever, or RBF, is caused by one of two bacteria that are spread by rats and possibly mice as well. Only one of the two RBF-causing bacteria is found in the United States, and that is streptobacillus moniliformis, which causes streptobacillary RBF. As the name suggests, RBF is typically contracted through a bite or scratch wound from an infected rodent, or through contact with a dead rodent. It can also be contracted by eating or drinking food or water that is contaminated with rat droppings, in which case it is referred to as Haverhill fever. Symptoms appear between 3 days and 3 weeks after exposure to the bacteria, by which time any bite or scratch that caused the illness would likely be healed. Common symptoms of Streptobacillary RBF include fever, vomiting, headache, and muscle pain. In addition, approximately 5 out of 10 patients experience joint pain or swelling, and approximately 3 out of 4 patients experience a rash. This rash will appear on hands and feet and look like flat, reddened areas that have small bumps. People with Haverhill fever may also experience sore throat and more severe vomiting. Complications with Streptobacillary RBF include abscesses inside the body, liver or kidney infections, pneumonia, meningitis, and infections involving the heart. Approximately 1 out of 10 people who get Streptobacillary RBF die.\nSalmonellosis is an infection caused by the bacteria salmonella, and can be spread in many ways, including by rats and mice. When spread by rats or mice, it is contracted by eating or drinking food or water that is contaminated with rat droppings. Symptoms typically appear between 6 hours and 6 days after exposure, although some people may not develop symptoms for several weeks. Symptoms usually last between 4 and 7 days, but can last for several weeks. Common symptoms of salmonellosis include fever, abdominal pain, and diarrhea. Some strains of salmonella can cause severe disease, as well as infections of the blood, bones, joints, nervous system, or urine.\nTularemia is caused by a bacteria and can be spread in many different ways, including by rats and mice. There are multiple forms of tularemia, which are categorized by how the bacteria was contracted. Symptoms vary by form, but all forms cause fever. Causes and symptoms of the main forms of tularemia are listed below. Please keep in mind that this list only includes the causes pertaining to rodents. The forms of tularemia that are listed may have other causes that are not included in this list.\n- Ulceroglandular tularemia is caused by handling an infected animal. Symptoms include a skin ulcer where the bacteria entered the body, fever, chills, exhaustion, and swollen and painful lymph glands.\n- Glandular tularemia is the same as ulceroglandular tularemia in all ways, except that it does not cause skin ulcers.\n- Oculoglandular tularemia is caused by the bacteria entering through the eyes, usually when someone is butchering an infected animal and touches their eyes. Symptoms include irritation and inflammation of the eye, an ulcer on the inside of the eyelid, sensitivity to light, and swelling of the lymph glands in front of the ears.\n- Oropharyngeal tularemia is caused by eating or drinking contaminated food or water. Symptoms include vomiting, diarrhea, sore throat, tonsillitis, mouth ulcers, and swollen lymph nodes in the neck.\n- Pneumonic tularemia can be caused either by breathing in contaminated dust or aerosols, or by leaving another form of tularemia untreated, allowing it to spread through the bloodstream to the lungs. Pneumonic is the most serious form of tularemia. Symptoms include chest pain, difficulty breathing, and a dry cough.\n- Typhoidal tularemia is a combination of general symptoms of tularemia, without any of the localized symptoms of other forms. Such general symptoms include extreme exhaustion, enlarged spleen or liver, vomiting, diarrhea, and pneumonia.\nMost cases of tularemia can be treated fairly easily with antibiotics, although some cases are life-threatening.\nFor more information about these and other rodent-borne illnesses, visit this page of the CDC’s website.\nDiseases spread by mice and rats can be avoided if necessary precautions are taken. For one, avoid any contact with rodents that are not pets. Take steps to make your home or business an environment where rodents cannot or do not want to live. Do not swim or wade in water that could potentially be contaminated with rodent urine or feces. If your job requires you to come into contact with anything that is potentially contaminated- such as soil, water, or infested buildings- always wear protective footwear and clothing. When mowing, check the area beforehand for any sick or dead rodents, and do not mow over them if there are any. Clean up any rodent nests, as well as any urine and droppings. For information on how to safely clean up dead rodents, rodent nests, or rodent urine and droppings, visit this page on the CDC’s website. When handling nests or wild rodents, dead or alive, always wear gloves and wash your hands with soap and warm water after.\nAlthough it is rare, diseases can also be spread by pet rodents, so precautions should be taken when handling them as well. When choosing a rodent pet from a pet store or breeder, avoid any that look sick or otherwise unwell. Do not choose any that are in the same cage as rodents that look unwell, either. If possible, clean your pet’s habitat, food and water bowls, toys, and any other objects outdoors. If outdoor cleaning is not an option, then use a large bathtub or sink that can be easily disinfected. Avoid using a kitchen sink. Always wash your hands with soap and warm water after handling your pet or its belongings.\nIf you are bitten or scratched by a rodent, wild or domestic, clean the wound immediately with soap and warm water. Contact a health care provider as soon as possible and tell the provider about the bite or scratch. Get treatment if need be.\nIn addition to spreading illnesses, mice and rats tend to cause extensive, and usually expensive, damage to homes and businesses. They will chew through just about anything they can get their teeth into, including walls, floors, insulation, pipes, wires, upholstery, important documents, family heirlooms, and more. The damage to insulation can make temperature regulation very difficult and expensive. Lack of insulation means having to run air conditioners and heaters much more than usual, in addition to the fact that insulation can be expensive to replace. Chewed wires are quite dangerous, and actually cause about 25% of the house fires in the United States each year. Mice and rats also cause fire risks when they tunnel into and build nests inside of appliances, causing them to short-circuit or malfunction. When an infestation is severe, the urine of the mice or rats can soak into wood and compromise the structural integrity of a building. For information on how to prevent infestations, check out our mouse and rat FAQ pages\nA few mice or rats can quickly turn into an infestation. Rodent infestations are not something to be taken lightly or ignored, as they can be potentially dangerous. If you think you have mice or rats in your home or business, call our experts today and we’ll send a technician out right away.\nYou’ll be supporting research into lyme disease, too.\nChoosing Excel helps us support the John Hopkins Lyme Research Center. You will help them advance the critical knowledge and clinical tools urgently needed to improve Lyme disease patient care and health outcomes.']	['<urn:uuid:403f4170-2f61-4adb-8b0f-345cac5dd85d>', '<urn:uuid:382f354d-6d21-444a-bc47-1742e2e48f28>']	open-ended	direct	long-search-query	distant-from-document	multi-aspect	novice	2025-05-01T22:47:46.423955	9	107	2613
24	examples real world makerspace projects schools	A notable example of makerspace projects in schools is from South Carolina, where 6th grade teacher Chris Craft led his students in printing more than 150 prosthetic human hands for people in need using a 3-D printer. This project also incorporated video production and online sharing, demonstrating how makerspaces can combine practical creation with critical 21st century literacy skills.	['In 2011, a faculty member wanted to bring in a summer school program for some of our gifted and talented students. Called “Camp Invention”, students spent a week taking apart computers and creating new worlds with peers. I had never seen students more engaged in learning than during this experience.\nAfterward, something nagged at me: the program was not intentional about incorporating reading and writing into the curriculum. I could understand the rationale. Educators are always trying to stuff literacy into anything students are doing. Yet are these two areas – innovation and literacy – mutually exclusive?\nHalverson and Sheridan tease out the complex nature of the maker movement in education (2014). They define it through three lenses: “making as a set of activities, makerspaces as communities of practice, and makers as identities of participation” (501). In literacy, students are (or at least should be) constantly making. For example, consider the verbs we use to describe writing. We craft an essay, develop a narrative, and build an argument. These actions cross the line between the tinkering, creating and iterating that happens in makerspaces and the drafting, revising and publishing that is synonymous with language arts. Halverson and Sheridan also see the possibilities.\n“Learning through making reaches across the divide between formal and informal learning, pushing us to think more expansively about where and how learning happens. In this way we can talk about the who, what, and how of learning without getting hung up on the rules and constraints that govern different settings” (498).\nA question that frequently comes up in education circles is, “How do we get started with makerspaces?” Teachers usually follow this up with concerns about time, resources and administrative support. Now in my second district, and having visited several more, I can say that makerspaces are unique from school to school. Some buildings house makerspaces in their libraries, while others have a separate, dedicated space. When it is not a building initiative, makerspaces find space in teacher’s classrooms under the guise of “Genius Hour”.\nWhat they all have in common is they are personalized to the needs of the students. The kids direct the learning. In response, the adults often adjust their roles to that of a coach and guide on the side. The observed result is higher levels of student engagement in school, which tends to spill over into the core academic areas. Gershenfeld has found increased engagement to be true, noting how personalization is “a market of one person”. In makerspaces, students might start creating something of their own interest, but a lack of purpose and audience might propel them to start thinking about how they can make an impact in the broader world.\nFor instance, 6th grade teacher Chris Craft has led his students in South Carolina to print more than 150 prosthetic human hands for people in need using a 3-D printer (Herold, 2016). This work includes video production and online sharing, all critical literacy skills for the 21st century. This example and others similar show how schools can “decentralize enthusiasm” (Gershenfeld, 57) in the goal of creating engagement in learning through doing real work while applying core competencies. Literacy appears to lend itself way to many of these opportunities.\nGershenfeld, N. (2012). How to make almost anything: The digital fabrication revolution. Foreign Aff., 91, 43.\nHalverson, E. R., & Sheridan, K. (2014). The maker movement in education. Harvard Educational Review, 84(4), 495-504.\nHerold, B. (2016). What It Takes to Move From ‘Passive’ to ‘Active’ Tech Use in K-12 Schools. Education Week: Technology Counts, 82(2), 33.']	['<urn:uuid:cc106f0f-6bb1-4545-9026-99fbe20a8051>']	open-ended	direct	short-search-query	similar-to-document	single-doc	expert	2025-05-01T22:47:46.423955	6	59	594
25	When did the Knights of Malta own islands in the Caribbean?	The Knights Hospitaller (Knights of Malta) possessed four Caribbean islands during a 14-year period from 1651 to 1665, when they sold their rights to the French West India Company.	"['Territorial possessions of the Sovereign Military Order of Malta\nMost importantly, it got its current name from the island of Malta, long under possession.\n||This article may require cleanup to meet Wikipedia\'s quality standards. The specific problem is: Non-proportionate (February 2016) (Learn how and when to remove this template message)|\n- Castles and villages in the Kingdom of Jerusalem and the Principality of Antioch in the Levant, 1113-1187\n- Territories in the County of Tripoli (today Lebanon), 1187-1289\n- Rhodes, Dodecanese (except Karpathos, Kasos and Astypalaia) (now Greece) and Bodrum (now Turkey), 1309-1522\n|Part of a series on|\nof the Americas\nThe Hospitaller colonization of the Americas occurred during a 14-year period in which the Knights Hospitaller (also known as the Knights of St. John or the Knights of Malta) possessed four Caribbean islands: Saint Christopher, Saint Martin, Saint Barthélemy, and Saint Croix.\nThe Knights\' presence in the Caribbean grew out of their order\'s close relationship with the French nobility and the presence of many members in the Americas as French administrators. The key figure in their brief foray into colonization was Phillippe de Longvilliers de Poincy, who was both a Knight of Malta and governor of the French colonies in the Caribbean. Poincy convinced the Knights to purchase the islands from the bankrupt Compagnie des Îles de l\'Amérique in 1651 and stayed to govern them until his death in 1660. During this time, the Order acted as proprietor of the islands, while the King of France continued to hold nominal sovereignty; however, Poincy ruled largely independent of them both. In 1665, the Hospitallers sold their rights in the islands to the new French West India Company, bringing their colonial project to an end.\nFrom the beginning of the French colonization of the Americas, members of the Knights of Malta had been prominent in New France and the French Antilles. By this time, the Order was mostly made up of French aristocrats, and many French naval officers had trained with the Hospitaller navy. Many Knights had high-ranking positions in the early French colonial administration, including Aymar Chaste and Isaac de Razilly in Acadia, and Charles de Montmagny in Quebec. In 1635, Razilly suggested to the Grand Master of the order, Fra\' Antoine de Paule, that the Hospitallers establish a priory in Acadia; however, Paulle rejected the idea.\nThe next Grand Master, Giovanni Paolo Lascaris, was more interested in colonial affairs. In 1642 or -43 he was named godfather to an Abenaki convert in New France. Montmagny represented Lascaris at the baptism.\nPhillippe de Longvilliers de Poincy, founder of the Hospitaller colonies, began his career in a manner similar to these other administrators. Longvilliers fought the Turks in the Mediterranean and participated in the Sieges of the Isle of Ré and La Rochelle in 1627. In between, he served under Razilly in Acadia, commanding a fort.\nPoincy first went to Saint Christopher in 1639 as the appointed governor under the Compagnie des Îles de l\'Amérique. King Louis XIII soon after made Poincy his Lieutenant-General for the entire Caribbean. Poincy began to invest heavily in building projects on the island. He extended French rule to other islands, establishing the first European settlement on Saint-Barthélemy in 1648, and founding a settlement on St. Croix in 1650-51. He sent an additional 300 men to reinforce and take over the small French settlement on Saint-Martin. There he negotiated the Treaty of Concordia, determining the boundary between the French and Dutch settlements that remains in place today.\nPoincy also established himself as the absolute ruler of the islands, resisting the authority of the failing French company. He became embroiled in conflict with the Capuchin missionaries, who disapproved of the governor\'s consorting with local English, Dutch, and Huguenot Protestants, and of his refusal to liberate the children of baptized slaves. Poincy also provoked resentment at his harsh treatment of subjects who resisted him. In addition he drew disfavor from the Order of Malta when he used income from the Order\'s commandry estates in Europe to pay for his grand style of living on the island. The company\'s directors decided to replace Poincy. They commissioned Noëlle Patrocles de Thoisy, a gentleman from Burgundy, to replace him, obtaining an order from the king summoning the governor back to France. Poincy refused to comply. His militia drove Thoisy off the island, and ultimately Thoisy was captured and sent back to France in chains.\nSeeking a way to keep his position, Poincy in 1649 suggested that the Order of Malta buy the islands. By this time the Company was languishing. Poincy himself, by defying its authority, had shown its ineffectiveness. At the same time, Cardinal Mazarin, France\'s chief minister, was busy with the Peace of Westphalia and could not devote his attention to colonization. In 1651 the company was dissolved; its exploitation rights were sold to various parties. Martinique, Guadeloupe, and several other islands were sold to private individuals.\nThe Hospitallers, with the approval of the Grand Master Lascaris, bought Saint-Christophe, along with Poincy\'s newly established dependencies of Saint Croix, Saint Barthélemy, and Saint Martin. The Knights\' ambassador to the French court, Jacques de Souvré, signed the agreement. The Order\'s proprietary rights were confirmed in a treaty with France two years later: while the king would remain sovereign, the Knights would have complete temporal and spiritual jurisdiction on their islands. The only limits to their rule were that they could send only French knights to govern the islands, and upon the accession of each new King of France they were to provide a gold crown worth 1,000 écus.\nThe council of the Grand Master decided that Poincy could continue to serve as governor, but they also made the former governor of New France, Charles de Montmagny, the ""proconsul general,"" sending him to represent their interests on Saint Christopher. Montmagny hoped to help Poincy get the colonies\' finances in order. However, Poincy again resisted any outside interference; once Montmagny had returned to France, Poincy sent away the man left in his place. The Order sent Montmagny for a second time in 1653, as ""lieutenant governor"". He took formal possession of the islands in the name of the Grand Master. However, Poincy still refused to share power, and Montmagny was quickly sidelined, biding his time on a farm on Saint Christopher and hoping to take over after Poincy\'s death. Montmagny ultimately died first, in 1657. \nPoincy continued to develop the colonies. He built strong and impressive fortifications on Saint Christopher along with churches, roads, a hospital, and his own grand residence, the Château de la Montagne. Outside the capital, Hospitaller rule was more precarious. The settlement on Saint Barthélemy suffered an attack by Carib people, and those who were not killed abandoned the island. Poincy sent a group of 30 men to replace them, which grew to 100 by 1664. In 1657 a rebellion overthrew the Hospitaller regime on St. Croix. Poincy sent a new governor to restore order, build fortifications and a monastery, and begin to clear much of the island\'s forests for plantation agriculture.\nTo replace Montmagny, the Order sent two new lieutenant governors. The more prominent of the two was Charles de Sales, a relative of St. Francis de Sales who proved popular with the inhabitants of the island. Shortly before his death in 1660, Poincy signed a treaty of peace with the English and the Carib people of Saint Christopher, but the peace did not last. De Sales succeeded Poincy as governor. In 1666, after the Knights had formally given up their control of the islands, fighting broke out between the French and the English on the island. In a battle at Cayonne, de Sales was killed, but the French held on to their settlements.\nBy the early 1660s, frustration was growing that the colonies were not turning a profit. The Order still owed money to France for the initial purchase of the islands, and on Malta the knights debated whether they should sell them back. Jean-Baptiste Colbert, much more interested in colonization than Mazarin, was now in power in King Louis XIV\'s court, and he applied pressure to the Knights to sell. In 1665, the Knights sold their colony to the newly formed Compagnie des Indes occidentales.\nHospitaller governors on Saint Christopher\n- Phillippe de Longvilliers de Poincy, 1651–1660 (Governor under the Compagnie des Îles de l\'Amérique from 1639)\n- Charles de Sales, 1660–1666\nThe Knights of Malta never established another colony. However, members of the order remained active in France\'s navy and overseas empire. Several were involved in the Mississippi Company scheme early in the eighteenth century. Later in the century, Étienne-François Turgot, a Hospitaller and colonial administrator, tried unsuccessfully to settle Maltese people in Guiana.\nThe short period of Hospitaller occupation is still remembered on the different islands. Poincy\'s rule on St. Kitts is remembered for the spectacle of his large, grand household, the servants all dressed in the emblem of the Knights. On St. Croix one can find frequent reference to the ""seven flags"" in the island\'s history, counting the Knights of Malta together with the United States and five European nations that have ruled it. St. Barthélemy has in its coat of arms a Maltese cross on a red fess, representing the period of Hospitaller colonization. Some of the Self-styled orders that mimic the Hospitallers still claim the territory of the order\'s former Caribbean possessions.\n- Fort St. Angelo (2001)\n- Riley-Smith, Jonathan (2005). The Crusades: A History (2nd ed.). New Haven: Yale University Press. pp. 292–297. ISBN 0-300-10128-7.\n- Pichette, Robert (June 7, 2010). ""The Order of Malta\'s Naval Tradition in New France"". Order of Malta. Sovereign Military Hospitaller Order of St. John of Jerusalem of Rhodes and of Malta. Retrieved 11 April 2014.\n- Allen, David F. (1990). Web page by Malta Historical Society.. ""The Social and Religious World of a Knight of Malta in the Caribbean, c. 1632-1660"". Libraries and Culture. 25 (2): 147–157. Retrieved 11 April 2014.\n- Dubé, Jean-Claude (2005). The Chevalier de Montmagny: First Governor of New France. Translated by Elizabeth Rapley. Ottawa: University of Ottawa Press. pp. 263–287. ISBN 0-7766-0559-3.\n- ""Columbus to the Present"". St Barth Tourisme. omite Territorial Du Tourisme de Saint-Barthelemy. Retrieved 12 April 2014.\n- Lewisholm, Florence (1963). ""Highlights of Cruzan History"". St. Croix Landmarks Society. Retrieved 12 April 2014.\n- ""Border Obelisk"". St. Martin Tourism Office. 2010. Retrieved 12 April 2014.\n- Mifsud, A. (1914). Knights Hospitallers of the Venerable Tongue of England in Malta. Valletta, Malta. p. 246. ISBN 0-404-17009-9.\n- ""The Danish West Indies under Company Rule (1671–1754)"". Royal Danish Consulate: United States Virgin Islands. Royal Danish Consulate. Retrieved 11 April 2014.\n- Cf. Du Tertre, Jean Baptiste (1667), ""Combat de Cayonne"", Histoire generale des Antilles habitées par les François ... Tome II (Engraving) (in French), Paris: Chez Thomas Iolly, au palais, en la Salle des Perciers, à la Palme, & aux Armes d\'Hollande, retrieved 1 November 2014 – via John Carter Brown Library Archive of Early American Images\n- Hodson, Christopher (2012). The Acadian Diaspora: An Eighteenth-Century History. New York: Oxford University Press. p. 182. ISBN 978-0-19-973977-6.\n- Innis, Probyn. ""Historic Basseterre"". Basseterre Past & Present. St.Kitts National Archives. Retrieved 10 April 2014.\n- For example, ""Feasibility Study for a St. Croix National Heritage Area"" (PDF). National Park Service. U.S. Department of the Interior – National Park Service. September 2010. Retrieved 2016-08-31.\nthe Island was claimed by Spain, Holland, England, France, the Knights of Malta, and Denmark\n- Boucher, Philip P. (2008), France and the American Tropics to 1700: Tropics of discontent?, Johns Hopkins University Press.']"	['<urn:uuid:3b29424a-c987-473a-b888-fe1c36afcd09>']	factoid	direct	concise-and-natural	distant-from-document	single-doc	novice	2025-05-01T22:47:46.423955	11	29	1927
26	sarah fabio dudley randall poetry publications compare	Sarah Webster Fabio self-published nine books of poetry including her Master's Thesis, while Dudley Randall's notable published works include 'Ballad of Birmingham', 'Booker T. and W.E.B.', 'A poet is not a Jukebox', and 'The Profile on the Pillow'.	"['Referral code for up to $80 off applied at checkout\nIn September, members of Vinyl Me, Please Classics will receive Jujus / Alchemy of the Blues, the third album from poet/scholar/musician Sarah Webster Fabio. We worked closely with Smithsonian Folkways to replicate the packaging from 1976, and had the album remastered by the staff at the label. Read more about why we picked this title over here. You can sign up here.\nBelow, you can read an excerpt from our Listening Notes Booklet, which was written by Webster Fabio’s daughter, Cheryl Fabio, who made a documentary about her mom in the ’70s.\nMy mother, Sarah Webster Fabio, was a precocious kid from Nashville, Tennessee. Her mother, Mayme, died when Sarah was 12 years old, leaving her and five siblings in their father’s care. My granddad was committed to seeing all three of his girls graduate from college and be well-married. He died on the day of the youngest girl’s wedding.\nSarah was the kid that went to college at 16. She started at Spelman College, Atlanta, Georgia, and finished at Fisk University in Nashville, Tennessee. She was 18 when she graduated. Then she met and married my dad, Cyril Fabio. They had three kids, a break, then two more.\nIt’s no exaggeration to say our mother always had an interest in the arts, particularly writing. She self-published nine books of poetry, including her Master’s Thesis. My mom was among a very active group of culture critics writing for local and national publications like Negro Digest, Black World and Black Scholar. Her work has been anthologized in many of the most important 1960s-era poetry collections.\nI don’t know how you could count the number of poems my mother wrote. Poetry was her breath; she wrote more than 500, easily. From that body of work, Sarah recorded some of her poems on four albums for Folkways Records. The titles of those albums are: Boss Soul, Soul Ain’t: Soul Is, Jujus / Alchemy of the Blues and Together To The Tune Of John Coltrane’s Equinox.\nJujus / Alchemy of the Blues is Sarah’s third album, and its title is derived from Rainbow Signs, her seven-volume self-published poetry journals. The booklet Jujus / Alchemy of the Blues begins with an offering of Black expression, a poem called “Of Puddles, Worms, Slimy Things.” Sarah writes it in an African-American dialect, an early English Patois that combines English with African languages. Then, she rewrites the same poem in standard English. The difference between the two demonstrates how a choice of language (intentional or expedient) colors the meaning and understanding of the text.\nBut the album, Jujus / Alchemy of the Blues is its own compilation. It borrows poems from various booklets in the Rainbow Signs series. And further, an analysis of the title’s three nouns (“Jujus,” “Alchemy” and “Blues”) helps a new listener access Sarah’s intent.\nJujus are practices that are derived from West African religions. Alchemy is the chemical reaction that transforms ordinary metals into gold. The Blues are a musical coping tradition rooted in the plantation cultures of Blacks from the deep deep South. I find these ideas helpful in accessing Jujus / Alchemy of the Blues more meaningfully.\nDon’t Fight the Feeling, the backing band on Jujus, grew from a garage band started by my brother Ronnie, who was in high school, and his friend Wayne Wallace. At the time, guitar player Wayne was already in a different band. That band asked Ronnie to join, and eventually, Wayne and Ronnie left to start their own group, which became Don’t Fight the Feeling.\n“Don’t Fight the Feeling was a goofy name but it reflected us, just as the names of other bands in those days reflected their members,” Ronnie says. “Don’t Fight the Feeling preceded our work with mom but she started to pull us into her work. We performed with her at the University of Pacifica and then the University of Stockton. Mom was booked on a boat excursion during that gig and from then on, we worked for her.”\nBut it was an experienced musician who had worked with our mom before Don’t Fight the Feeling that helped give the band direction.\n“Leon Williams [who is credited as Denianke on the album’s credits], an established jazz musician, frequently performed with mother and there was no question about who knew or understood the music. Leon mentored us,” Ronnie says.\nWilliams was recruited by Sarah when he was a student, and he remembers wanting to support her poetry any way he could.\n“Poetry combined with music was a thing [I was interested in]. I always had an affinity with poets and Sarah was just amazing,” Williams said. “She was a Renaissance person with high energy going in every direction. She was taking kids to school, organizing in her community, all while she worked an 8-to-5. At that time, Sarah was teaching at Grove Street/Merritt College.”\nOther musicians and Fabios contributed to Don’t Fight the Feeling. My brother Tommy became the MC and our eldest brother Leslie was the percussionist. Williams was the primary woodwind musician, but Rick Hopton played on the album too, and Larry Vann — a well-established Oakland drummer — played snares and he gave Don’t Fight the Feeling its funky rhythms.\nAll of Sarah’s albums were created after a near-death experience, which brought an urgency to her wanting to leave a legacy, and made her four-albums-in-five-years output understandable. Returning to the Bay Area from Los Angeles on New Year’s Day in 1971 after celebrating with friends and family, a sudden fog between Bakersfield and Fresno caused her to lose control, and her car skidded off the road. She cracked her ribs, had broken facial bones and the seat belt caused her to fracture her writing arm. She had to have her jaw wired shut, and was in a cast for nearly a year.\nThe tediousness of her recovery ended up replenishing her artistic spirit, leaving her with a thirst for life. She collaborated with intensity. She knew her four albums on Folkways would translate her poems from the page to a permanent, lasting expression. She picked from her body of work the poems that would take her further than written text could ever promise. Around the time her albums started coming out, she started pursuing a PhD in American and African Studies at the University of Iowa, and took a teaching position at the University of Wisconsin. It was there she was diagnosed with colon cancer, which ultimately took her life November 7, 1979.\nWhile recording Jujus / Alchemy of the Blues, I asked my mom and producer Fred Cohen if I could film a documentary of my mother’s work, which eventually became Rainbow Black: Poet Sarah W. Fabio, a 30-minute film that served as my thesis project at Stanford. The film, which is preserved by the Black Film Center at Indiana University, ends with “Juju: For Grandma.” The film and this album confirms: These recordings unwrap the way Sarah heard her words.\nCheryl Fabio is the Executive Director of the Sarah Webster Fabio Center for Social Justice and Program Manager for Parent Voices Oakland. She’s also the director of Evolutionary Blues...West Oakland’s Music Legacy.', ""The African-American culture is unique, with its own distinctive characteristics. This community has played a huge role in the overall development of every facet of the world including arts, science, music, history, and literature. In history, works of African-American poets reflected social issues like social discrimination, racism, slavery, and the civil war. Today, it has transformed into a full-fledged genre that concentrates on lighter issues like music, emotions, and contemporary social events. Over the course of time, a few poets of African-American descent created their own niche in the literary community.\nPhillis Wheatley (1753 - 1784)\nPhillis Wheatley was one of the pioneer African-American poet. She was born in Gambia, Senegal, in the year 1753, and was enslaved at the tender age of 8. She was brought to America in a ship named 'Phillis', and was purchased by the 'Wheatley' family of Boston. This tells us the precise story about her name. The poem that she wrote about the death of an evangelical preacher encouraged her to write more poems.\nLangston Hughes (1902 - 1967)\nJames Langston Hughes was an African-American poet, playwright, novelist, columnist, and short story writer. He was born in Joplin, Missouri, in the year 1902. Langston Hughes started to write poems at the age of 13. He is best known for his works during the Harlem Renaissance and his writing, 'Harlem was in Vogue'. His first poetry collection, 'The Weary Blues' was published in the year 1926. He played a huge role in garnering recognition for his community, and giving it the status that it possesses today.\nArna Bontemps (1902 - 1973)\nArna Bontemps was an honored member of the Harlem Renaissance. He was born in the city of Alexandria, Louisiana, in the year 1902. He began writing when he was a college student, and soon after, authored several books for children. Later, he collaborated with the contemporary poet Langston Hughes to co-author several books on African-American culture.\nDudley Randall (1914 - 2000)\nDudley Randall was born in the year 1914 in Washington DC. He showed keen interest in poetry since his early childhood. His very first poem appeared in the Detroit Free Press, when he was merely thirteen years of age. 'Ballad of Birmingham' is one of his famous poems which he wrote as a reaction to the 1963 bombing on a Baptist church. Some of his famous works include 'Booker T. and W.E.B.', 'A poet is not a Jukebox', and 'The Profile on the Pillow'.\nGwendolyn Brooks (1917 - 2000)\nGwendolyn Brooks was born in Topeka, Kansas, in the year 1917. Brooks' first book of poetry, 'A Street in Bronzeville', was published in the year 1945. She was the author of more than 20 books during her 50 years career as a poet. Some of her famous books include 'Riot', 'In The Mecca', and 'The Bean Eaters'. Her book 'Annie Allen' won her the Pulitzer Prize. She was nominated for many other honorable awards.\nMaya Angelou (Born: 1928)\nMaya Angelou was born in Saint Louis, Missouri, in the year 1928. She has been called 'America's most visible black female autobiographer'. Best known for her series of six autobiographical volumes of the book 'I Know Why the Caged Bird Sings'. She was nominated for a Pulitzer Prize for 'Just Give Me a Cool Drink of Water 'Fore I Diiie'. Her book of poetry 'I Shall Not Be Moved' concentrates on racism while 'Phenomenal Women' deals with the place of women in the early 21st century.\nIshmael Reed (Born: 1938)\nIshmael Reed was born in Chattanooga, Tennessee, in the year 1938. He is a controversial poet, essayist, and novelist, who is known for his satirical poems that challenged American political and cultural oppressions. His first novel 'The Freelance Pallbearers' was published in the year 1963. His book 'Conjure' was nominated for the famous Pulitzer Prize, and he was also a finalist for the National Book Award, twice.\nNikki Giovanni (Born: 1943)\nNikki Giovanni was born in Knoxville, Tennessee, in the year 1943. She is a Grammy nominated poet, writer, and activist. She is the author of more than 17 books of poetry. Her work is often focused on the quest of social equality and black freedom movements. As a result, her first collection to be published in the year 1968 was named 'Black Feeling, Black Talk'. Many of her books are available in the spoken word recordings, including the famous 'Truth Is On Its Way'. She is a survivor of lung cancer and is currently teaching at Virginia Tech.\nAfrican-American poets were responsible for creating a major wave of revolutionary thoughts, that later proved to be the cornerstone in the development of today's social stratification.""]"	['<urn:uuid:040d4969-56a9-4984-a966-50ea462c4830>', '<urn:uuid:4bb1acf8-88b6-492b-a40c-e92d9b469efc>']	factoid	with-premise	short-search-query	similar-to-document	comparison	expert	2025-05-01T22:47:46.423955	7	38	1983
27	I'm curious about John Clarke's photography journey. How did he get started?	John Clarke began his photography journey while studying architecture at Cooper Union in the late 1960s. At the suggestion of one of his design professors, he bought a used Nikon and started shooting black and white film around New York City. Photography gradually became part of his architectural presentations. His subject matter evolved from urban landscapes to rural landscapes and traditional building structures when he moved to teach at the University of Virginia School of Architecture.	['Featuring Three Outstanding Artists in Photography\nAubrey J. Kauffman\nSaturday, March 9, 2019 | 6-9 PM\nPerkins Center for the Arts\n30 Irvin Avenue | Collingswoood, NJ\n[su_button url=”http://perkinsarts.org/wp-content/uploads/2019/01/Photography-37-Opening-Perkins-MYP-Comm-Final-2.28.19.pdf” target=”blank” background=”#bfb3e4″ size=”9″ text_shadow=”0px 2px 5px #000000″]PRESS RELEASE[/su_button]\nAbout the Artists:\nJohn Clarke’s interest in photography developed while he was an architectural student at Cooper Union in the late 1960s. The Cooper students were generally, very talented, poor, living in rundown lofts on the lower east side and struggling to find their way into the design world. The first year architectural students took all their classes with the art students, so they got a great introduction to freehand drawing, two and three dimensional design. At the suggestion of one of his design professors, John bought a used Nikon and began to shoot black and white film around New York City. Slowly photography began to be part of John’s architectural presentations.\nAfter receiving a master’s degree from Columbia University, John was offered a position as an assistant professor at the University of Virginia School of Architecture teaching first year year design. The subject of his photography shifted from urban landscapes to rural landscapes and traditional building structure. John’s photo medium changed from black and white film to color slides. The slides left no room for post processing. The crop and exposure you got at the time of taking the photo was the end of the story. You had to get the image right in the camera.\nFast forward some years, John moved to New Jersey and founded Clarke Caton Hintz, a high recognized, award winning architectural and planning firm based in Trenton. During the time John was practicing architecture, the world changed from analog to digital. When he started, architects drew everything by hand. Now, virtually everything an architect designs is drawn with the aid of a computer. The same dramatic change has occurred in photography. Architects and designers went from having vast color slide collections to using digital cameras, Lightroom and Photoshop to illustrate their design intentions.\nWhile in architectural practice, John specialized in the design of large scale, mixed use communities. This interest in urban design gave him a reason to travel extensively both in the U.S and abroad. Photography became critical to his urban design work and documenting his travels became a source of great enjoyment.\nSince retirement from architectural practice, John has devoted his artistic talents to fine art photography. His background as an architect is evident in the composition and structure of his photos. A life time of looking intensely at his surrounding is evident in the quality of his images.\nAnnarita Gentile – As a photographer, I aim to reflect the world around me as I experience it. That is saying a lot, to try to show in an image a personal experience. Some of this aim is accomplished through composition and editing are a result of an individual process and a lot of luck.\nWe carry emotional narratives deep within our internal world. The narrative holds the meaning to what we see. The mind reacts to an image in .33 seconds. Once we registered what we see, our own meaning is applied to the image.\nMy work as an artist coincides with my psychoanalytic career. I approach all of my endeavors with a desire to understand my own motivations and how my perspective is formed by my feelings. My emotional perspective and hopefully, expressed production is evident in both my artistic pursuits and professional hours.\nFor me, the creative process on a shoot occurs in a seamless process from the drive that comes from inspiration to the act of composition. Studio work is an attempt to continue the messaging by selecting certain images and editing which involves a variety of choices.\nThe message in this portfolio is one of glorious celebration through shapes and colors. For me, this work symbolizes a part of the story of the natural journey from hibernation, and germination, to the blossoming period shown here. What is expressed through the colors, shapes textures and the infinite possibilities of these flowers is a triumph and celebratory victory. And as brilliant as it is, there is some darkness and the sense that change is not far away. This is about the immediacy of the moment. The photos in this collection are flowers in Botanical Gardens in Pennsylvania and Maine, as well as various wooded locations.\nAubrey J. Kauffman is a photographer living and working in New Jersey. He received his BA in Media Arts from New Jersey City University and his MFA in Visual Arts from Rutgers University’s Mason Gross School of the Arts. He has taught photography at Mason Gross, Middlesex County College, Mercer County Community College and Community College of Philadelphia.\nHe was Guest Curator for “Landscapes: Social Political Traditional” at Rider University, in Lawrenceville, NJ, and was Co-Curator for “On Photography: Culture, History and the Narrative” with LaToya Ruby Frazier at the Mason Gross Galleries in New Brunswick.\nHis photography has been included in group exhibitions including: The Newark Museum, Newark, NJ; The Biggs Museum of American Art in Dover DE, The Griffin Museum of Photography in Winchester MA; The 38th Annual Wind Challenge Exhibition Series at the Fleisher Art Memorial in Philadelphia , PA and Expo 35 at the b.j. spoke gallery in Huntington, New York.\nHe has exhibited in solo shows at The New Jeresey State Museum, Trenton, NJ; Enfoco at 7th and 2ND Street Gallery, New York, NY; Southern Light Gallery in Amarillo, Texas; the Marguerite & James Gallery Hutchins Gallery at the Gruss Center of Visual Arts in Lawrenceville, NJ and the Rider University Art Gallery in Lawrenceville, NJ.\nHe was awarded the Brovero Photography Prize by Mason Gross. His work was named “Best in Collection” by Alpha Art Gallery in New Brunswick, NJ. He was awarded 3rd Place in the Urban Landscapes exhibit at the New York Center for Photographic Arts.\nHis work is represented in the permanent collections of the New Jersey State Museum in Trenton, NJ, Rider University in Lawrenceville, NJ and Johnson & Johnson’s Corporate Headquarters in New Brunswick, NJ.\nAt present he is a Contributing Producer for “State of the Arts” broadcast on PBS and a Contributing Journalist for US1 in Princeton, NJ.']	['<urn:uuid:0e1e83d0-9d67-47e7-909c-8d447f8007b3>']	open-ended	with-premise	concise-and-natural	similar-to-document	single-doc	novice	2025-05-01T22:47:46.423955	12	76	1042
29	How do you know if there's no correlation between variables?	When there is no correlation, it is difficult to draw a practical straight line because the data points are scattered randomly, and the line becomes nearly parallel to the x-axis, with correlation values close to 0.	['It is usual practice to quantify linear relationships through the Pearson correlation coefficient. To Indicate the strength and direction of the connection between two variables, it takes on a value between -1 and 1.\nIt can help investors diversify. Calculations from scatter plots of historical returns between pairs of assets, such as equities-bonds, equities-commodities, bonds-real estate, etc., will produce to help investors build risk-return portfolios.\nTherefore, we will learn about the Pearson correlation coefficient and know how to measure the relationship between two related variables using it.\nWhat is the Pearson correlation coefficient?\nPearson correlation coefficient or Pearson’s correlation coefficient or Pearson’s r is defined in statistics as the measurement of the strength of the relationship between two variables and their association with each other.\nIn simple words, Pearson’s correlation coefficient calculates the effect of change in one variable when the other variable changes.\nFor example: Up till a certain age (in most cases), a child’s height will keep increasing as his/her age increases. Of course, his/her growth depends upon various factors like genes, location, diet, lifestyle, etc.\nThis approach is based on covariance and, thus, is the best method to measure the relationship between two variables.\nWhat does the Pearson correlation coefficient test do?\nThe Pearson coefficient correlation has a high statistical significance. It looks at the relationship between two variables. It seeks to draw a line through the data of two variables to show their relationship. The relationship of the variables is measured with the help Pearson correlation coefficient calculator. This linear relationship can be positive or negative.\n- Positive linear relationship: In most cases, universally, the income of a person increases as his/her age increases.\n- Negative linear relationship: If the vehicle increases its speed, the time taken to travel decreases, and vice versa.\nFrom the example above, it is evident that the Pearson correlation coefficient, r, tries to find out two things – the strength and the direction of the relationship from the given sample sizes.\nPearson correlation coefficient formula and calculation\nThe correlation coefficient formula finds out the relation between the variables. It returns the values between -1 and 1. Use the below Pearson coefficient correlation calculator to measure the strength of two variables.\nPearson correlation coefficient formula:\nN = the number of pairs of scores\nΣxy = the sum of the products of paired scores\nΣx = the sum of x scores\nΣy = the sum of y scores\nΣx2 = the sum of squared x scores\nΣy2 = the sum of squared y scores\nHere is a step-by-step guide to calculating Pearson’s correlation coefficient:\nStep one: Create a correlation coefficient table.\nMake a data chart, including both variables. Label these variables ‘x’ and ‘y.’ Add three additional columns – (xy), (x^2), and (y^2). Refer to this simple data chart.\nStep two: Use basic multiplication to complete the table.\nStep three: Add up all the columns from bottom to top.\nStep four: Use the correlation formula to plug in the values.\nIf the result is negative, there is a negative correlation relationship between the two variables. If the result is positive, there is a positive correlation relationship between the variables. Results can also define the strength of a linear relationship i.e., strong positive relationship, strong negative relationship, medium positive relationship, and so on.\nDetermining the strength of the Pearson product-moment correlation coefficient\nThe Pearson product-moment correlation coefficient, or simply the Pearson correlation coefficient or the Pearson coefficient correlation r, determines the strength of the linear relationship between two variables.\nThe stronger the association between the two variables, the closer your answer will incline toward 1 or -1. Attaining values of 1 or -1 signify that all the data points are plotted on the straight line of ‘best fit.’ It means that the change in factors of any variable does not weaken the correlation with the other variable. The closer your answer lies near 0, the more variation in the variables.\nHow to interpret the Pearson correlation coefficient\nBelow are the proposed guidelines for the Pearson coefficient correlation interpretation:\nNote that the strength of the association of the variables depends on what you measure and the sample sizes.\nOn a graph, one can notice the relationship between the variables and make assumptions before even calculating them. The scatterplots, if close to the line, show a strong relationship between the variables.\nThe closer the scatterplots lie next to the line, the stronger the relationship between the variables. The further they move from the line, the weaker the relationship gets. If the line is nearly parallel to the x-axis due to the scatterplots randomly placed on the graph, it’s safe to assume that there is no correlation between the two variables.\nWhat do the terms strength and direction mean?\nThe terms ‘strength’ and ‘direction’ have statistical significance. Here’s a straightforward explanation of the two words:\n- Strength: Strength signifies the relationship correlation between two variables. It means how consistently one variable will change due to the change in the other. Values that are close to +1 or -1 indicate a strong relationship. These values are attained if the data points fall on or are very close to the line.\nThe further the data points move away, the weaker the strength of the linear relationship. When there is no practical way to draw a straight line because the data points are scattered, the strength of the linear relationship is the weakest.\n- Direction: The direction of the line indicates a positive linear or negative linear relationship between variables. If the line has an upward slope, the variables have a positive relationship.\nThis means an increase in the value of one variable will lead to an increase in the value of the other variable. A negative correlation depicts a downward slope. This means an increase in the amount of one variable leads to a decrease in the value of another variable.\nExamples of Pearson correlation coefficient\nLet’s look at some visual examples to help you interpret the correlation coefficient table:\nLarge positive correlation\n- The above figure depicts a correlation of almost +1.\n- The scatterplots are nearly plotted in a straight line.\n- The slope is positive, which means that if one variable increases, the other variable also increases, showing a positive linear line.\n- This denotes that a change in one variable is directly proportional to the change in the other variable.\n- An example of a large positive correlation would be – As children grow, so do their clothes and shoe sizes.\nMedium positive correlation\n- The figure above depicts a positive correlation.\n- The correlation is above +0.8 but below 1+.\n- It shows a pretty strong linear uphill pattern.\n- An example of a medium positive correlation would be – As the number of automobiles increases, so makes the demand for the fuel variable increases.\nSmall negative correlation\n- In the figure above, the scatter plots are not as close to the straight line compared to the earlier examples\n- It shows a negative linear correlation of approximately -0.5\n- The change in one variable is inversely proportional to the change in the other variable, as the slope is negative.\n- An example of a small negative correlation would be – The more somebody eats, the less hungry they get.\nWeak / no correlation\n- The scatterplots are far away from the line.\n- It is tough to draw a line practically.\n- The correlation is approximately +0.15\n- It can’t be judged that the change in one variable is directly proportional or inversely proportional to the other variable.\n- An example of a weak/no correlation would be – An increase in fuel prices leads to lesser people adopting pets.\nThe Pearson correlation coefficient can be determined by collecting data on two variables of interest through a survey. You can use this to learn whether the correlation between the two variables is positive or negative and how strong it is.\nQuestionPro Research Suite is a suite of tools to leverage research and transform insights that can be used to collect data for Pearson correlation coefficient analysis. After exporting survey data from QuestionPro and importing it into a spreadsheet or statistical application, you can conduct the correlation analysis.\nQuestionPro offers helpful data analysis tools such as cross-tabulation, data visualization, and statistical testing, in addition to calculating the correlation coefficient. These qualities can assist in your research and understanding your variables’ interrelationships.\nReady to discover the relationship between your variables and advance your data analysis? Start a QuestionPro free trial today to see how our survey software can help you to determine the Pearson correlation coefficient easily. Don’t miss this chance to improve data analysis and research.']	['<urn:uuid:92c55626-248f-49b7-8471-221f62b1492e>']	factoid	direct	concise-and-natural	distant-from-document	single-doc	expert	2025-05-01T22:47:46.423955	10	36	1451
31	I've been studying civil rights history and I'm curious about Martin Luther King Jr.'s time in Birmingham jail - what was his response to the white clergymen who criticized him for breaking the law?	In his classic 'Letter from Birmingham Jail' written on April 16, 1963, Martin Luther King Jr. responded to eight white clergymen from Alabama who had chastised him for breaking the law. In his response, King argued that it is the duty of people to break unjust laws. He pointed out that everything Adolf Hitler did in Germany was 'legal' while everything the freedom fighters did in Hungary was 'illegal.' He famously wrote that 'Injustice anywhere is a threat to justice everywhere.'	"[""Join the Conversation\nTo find out more about Facebook commenting please read the Conversation Guidelines and FAQs\nCivil Rights History: MLK writes 'Birmingham Jail' letter\nApril 16, 1862: Congress abolished slavery in the District of Columbia, with compensation to loyal owners, and appropriated money for the voluntary removal of African Americans to Haiti, Liberia or other countries.\nApril 16, 1963: Martin Luther King Jr. wrote his classic “Letter from Birmingham Jail,” responding to eight white clergymen from Alabama who had chastised him breaking the law. King reminded them that everything that Adolf Hitler did in Germany was “legal” and everything the freedom fighters did in Hungary was “illegal.” “It is the duty of people to break unjust laws,” he wrote. “Injustice anywhere is a threat to justice everywhere.”\nApril 17, 1960: The Student Nonviolent Coordinating Committee was formed in Raleigh, North Carolina, at the Shaw University Conference organized by Ella Baker. SNCC helped coordinate sit-ins and other direct action. SNCC workers who played important roles in the civil rights movement included Diane Nash, future U.S. Rep. John Lewis, longtime NAACP leader Julian Bond and Stokely Carmichael, who left SNCC to become a leader for the Black Panthers. At the conference, Guy Carawan sang a new version of “We Shall Overcome,” which became the national anthem of the civil rights movement. Workers joined hands and gently swayed in time, singing “black and white together,” repeating, “Deep in my heart, I do believe, we shall overcome some day.”\nApril 18, 1688: Four Quakers in Germantown, Pennsylvania, drafted the Germantown Quaker Petition Against Slavery — the first American document to protest slavery. The document marked one of the first such written declarations of such human rights, saying liberty should be extended to all people, regardless of color, and that other people should be treated the same way we wish to be treated.\nApril 18, 1941: Bus companies in New York City agreed to hire 200 African-American workers after a four-week boycott by riders led by Adam Clayton Powell Jr., a pastor for Harlem’s Abysinnian Baptist Church, the largest Protestant congregation in the U.S. He became the first African American elected to Congress from New York and was reelected 10 more times. During his service through 1971, he supported legislation that helped attack poverty, desegregate public schools and expand higher education opportunities for all Americans.\nApril 18, 1959: About 26,000 students took part in the Youth March for Integrated Schools in Washington, D.C. They heard speeches by Martin Luther King Jr., A. Phillip Randolph and NAACP leader Roy Wilkins. “In your great movement to organize a march for integrated schools,” King told them, “you have awakened on hundreds of campuses throughout the land a new spirit of social inquiry to the benefit of all Americans.”\nApril 19, 1977: Alex Haley was awarded a special Pulitzer Prize for Roots. His book was later transformed into an epic television mini-series seen by 130 million Americans. The finale was one of the highest rated television programs of all time.\nApril 20, 1871: After Congress heard testimony from witnesses of Klan atrocities in the South, President Ulysses S. Grant signed the Ku Klux Klan Act, otherwise known as the Civil Rights Act of 1871. The act gave the president the authority to suppress terrorist organizations by force and to impose harsh penalties on them. The act also gave victims the choice of going to federal courts instead of Klan-influenced local courts. In 1882, the U.S. Supreme Court declared this act unconstitutional.\nApril 20, 1939: Jazz singer Billie Holiday stepped into a 5th Avenue studio and recorded “Strange Fruit,” a song written by a high school teacher upset about the lynchings of African Americans. Weeks earlier, she had sung it for the first time at the Café Society in New York City. When she finished, “there wasn’t even a patter of applause,” she wrote in her memoir. “Then a lone person began to clap nervously. Then suddenly everybody was clapping.” The song sold more than a million copies, and jazz writer Leonard Feather called it “the first significant protest in words and music, the first unmuted cry against racism.” After her 1959 death, both she and the song went into the Grammy Hall of Fame, Time magazine called “Strange Fruit” the song of the century, and the British music publication Q included it among “10 songs that actually changed the world.”\nApril 21, 1865: Abraham Lincoln’s funeral train left Washington, D.C., heading for Illinois. Mourners collected near the track and the train headed on its 1,700-mile trip. In Philadelphia, the line of mourners stretched three miles long. Thousands of African Americans traveled for days to attend the funeral, where Bishop Matthew Simpson spoke of the slain president: “Mute though thy lips be, yet they still speak. Hushed is thy voice, but its echoes of liberty are ringing through the world, and the sons of bondage listen with joy. … We crown thee as our martyr — and humanity enthrones thee as her triumphant son. Hero, Martyr, Friend, Farewell.”\nApril 21, 1966: Milton Olive III became the first African American to be awarded the Congressional Medal of Honor in the Vietnam War. Olive and fellow members of the 3d Platoon of Company B had been making their way through the jungles to locate Viet Cong operating in the area. As the soldiers pursued the enemy, a grenade was thrown into the middle of them. Olive grabbed the grenade and fell on it, absorbing the blast with his body. His actions saved the lives of his platoon members. Olive’s parents received the medal on his behalf.\nApril 22, 1892: Fiery civil rights pioneer Vernon Johns was born in Darlington Heights, Virginia, which is in Prince Edward County. He taught himself German and other languages so well that when the dean of Oberlin College handed him a book of German scripture, Johns easily passed, won admission and became the top student at Oberlin College. In 1948, the Dexter Avenue Baptist Church in Montgomery, Alabama, hired Johns, who mesmerized the crowd with his photographic memory of scripture. But he butted heads with the middle-class congregation when he chastised members for disliking muddy manual labor, selling cabbages, hams and watermelons on the streets near the state capitol. He pressed civil rights issues, helping black rape victims bring their cases to authorities, ordering a meal from a white restaurant and refusing to sit in the back of a bus. No one in the congregation followed his lead, and turmoil continued to rise between the pastor and his parishioners. In May 1953, he resigned, returning to his family farm. His successor? A young preacher named Martin Luther King Jr. James Earl Jones portrayed the eccentric pastor in the 1994 TV film, “Road to Freedom: The Vernon Johns Story,” and historian Taylor Branch profiled Johns in his Pulitzer-winning “Parting the Waters; America in the King Years 1954-63.”\nApril 22, 1922: Legendary jazz bassist Charles Mingus was born in Nogales, Arizona. Fourteen years after his 1979 death, the Library of Congress acquired his scores and papers in what they called “the most important acquisition of a manuscript collection relating to jazz in the library’s history.” In 1997, he posthumously received the Grammy Lifetime Achievement Award.\nApril 22, 1957: All the baseball teams in the National League integrated. Within two more years, the rest of baseball was integrated as well.\nApril 22, 1969: Harvard became one of the nation’s first major universities to boast an African-American Studies program. Harvard’s alumni include these African-American intellectuals and historians: W.E.B. Du Bois, Carter G. Woodson, Alain Locke, William Leo Hansberry and John Hope Franklin.""]"	['<urn:uuid:4814851c-e995-4ba6-b46b-f10ebbffeb9c>']	open-ended	with-premise	verbose-and-natural	similar-to-document	single-doc	expert	2025-05-01T22:47:46.423955	34	81	1272
32	What did Padmasambhava teach about Vajrakīlaya meditation?	Padmasambhava taught that meditation on Vajrakīlaya is the state of reality. He taught the secret bodhicitta within Atiyoga and the sādhanas of Vajrakīlaya according to Mahāyoga texts. His students then meditated on the nonduality of objects and minds within the uncreated bodhicitta.	['In the previous post I looked at the the earliest Dzogchen manuscripts in existence (as far as we know). These two Dzogchen texts appear to reject any kind of structured practice, and yet they exist in the extraordinarily rich Dunhuang collection, containing prayers, manuals for rituals of offering, confession and so on, meditation manuals, and many other things which clearly fall into the category of structured practice. So, we may well ask ourselves, what was going on? Were people practising, or not? Do we really imagine that among the population of tantric practitioners around Dunhuang there were few hip Dzogchenpas secretly scorning the efforts of the rest? I doubt it.\nFortunately we don’t have to rely on speculation here. There are in fact a number of texts from Dunhuang that explain exactly how Dzogchen relates to tantric practice. The Questions and Answers on Vajrasattva is a series of questions and answers, an early FAQ, on tantric practice. In particular, it is concerned with the practice of a level of tantra known as Mahāyoga (“the great yoga”). It was written in the earlyish 9th century by a Tibetan called Nyen Palyang and is preserved in several Dunhuang manuscripts, including IOL Tib J 470.\nNow Nyen Palyang clearly had a view of tantric practice that was very close to what we find in the Dzogchen texts. He writes:\nThis mind itself which is without basis or root\nIs, like the sky, not purified by cleansing.\nBecause enlightenment is free from production,\nEnlightenment does not come from cause and effect.\nBut this is a treatise on tantric practice, in particular, on the practice of visualizing a deity. So the next question Palyang posits is how do we receive the blessing from the deity if the above is true? He answers his own question in this way:\nWhen dirty water becomes clear,\nNo effort is required for the reflections of the sun and moon to appear.\nSimilarly, if one transforms one’s own mind through yoga,\nNo accomplishment is required for the conquerors’ blessings to arise.\nThe author is keen to get the message across that the practice of deity yoga is emphatically not to be abandoned, but any concept of the practice of yoga as the cause for enlightenment is to be abandoned. Pelyang constantly refers to nonduality, freedom from effort, and the primordial and spontaneous presence of the enlightened mind, using terms familiar from Dzogchen texts, such as awareness (rig pa) and spontaneous presence (lhun gyis grub). The term Dzogchen appears here too. Pelyang poses the question—if there is no cause and effect, how does a yogin obtain accomplishments? The answer is this:\nWhen, as in the example of a king appointing a minister,\nThe accomplishments are granted from above, this is the outer way.\nWhen the kingdom is ruled having been offered by the people,\nThis is the way of the unsurpassable, self-arisen Dzogchen.\nLeaving aside the interesting political metaphor, what is striking here is that Dzogchen is clearly being presented as a way (tshul) of practicing Mahāyoga. The same applies to the term Atiyoga: there is a note appended to a point in the main text where the following answer is given to the question of how one should perform deity yoga, here called “approach and accomplishment” (bsnyen bsgrub):\nIn the ultimate approach and accomplishment no subject or object is perceived;\nBecause there are no difficulties or effort here, this is the supreme approach and accomplishment.\nThe Questions and Answers on Vajrasattva is not an isolated case. Another text from Dunhuang, a long tantric treatise on various topics arising out of deity yoga (IOL Tib J 454) makes it clear that the deity is simply the awareness (rig pa) of one’s own enlightened mind or bodhicitta (byang chub sems). The idea of buddhas and buddhahood is also firmly brought back to the practitioner’s own primordially pure mind:\nOne’s own mind is primordial purity and buddhahood, and to comprehend that this mind is primordially purity and buddhahood is to be accomplished as a buddha, to see the face of the buddha, to hold the buddha in one’s hands.\nFinally, there is a brief account of how Padmasambhava taught the meditation on the deity Vajarakīlaya to his students in the manuscript Pelliot tibétain 44, which states:\n[Padmasambhava] taught the secret bodhicitta that is included within Atiyoga, and the sādhanas of Vajrakīlaya in accordance with the Mahāyoga texts. He showed that meditation on Vajrakīlaya is the state of reality, and then they meditated on the nonduality of objects and minds within the uncreated bodhicitta.\nWe are in a better position now to understand how the two Dzogchen texts that I mentioned in the last post coexisted with the vast amount of practical instructions on ritual and meditation practice that are also found in the Dunhuang collections. The texts I’ve quoted here make it plausible that at the time of these manuscripts (9th to 10th centuries) Dzogchen/Atiyoga was primarily a view applied to the practice of deity yoga.\n“But what,” you may ask (adopting for the moment the Tibetan question-and-answer method), “about those Dzogchen texts that don’t refer to tantric practice at all, but just talk about nonduality and the uselessness of any practice? Like, for example, your Dunhuang text by Buddhagupta?”\nWell, that’s an interesting example. You may remember from the last post that much of Buddhagupta’s Dunhuang text was re-used in another work by none other than Nyen Palyang, author of The Questions and Answers on Vajrasattva. Palyang also wrote several Dzogchen texts that don’t mention deity yoga, or any other practices at all.\nNow, I don’t want to draw sweeping conclusions from this limited source material, but this seems to have been a common pattern: to write Mahāyoga commentaries or treatises alongside short instructional texts on the nonconceptual aspect of Mahāyoga practice. Other authors and translators of early Dzogchen texts (like Mañjuśrīmitra and Vimalamitra for instance) also wrote commentaries on Mahāyoga tantras. So it seems that writing (or studying) these early Dzogchen texts didn’t preclude the practice of deity yoga. In fact the point of the the Dzogchen view was to apply it to these practices.\n“So, was this the original form of Dzogchen?” I suspect that ‘original’ (like ‘authentic’) is word that seems simple until you start to ask what we really mean when we use it. Let’s leave this question till next time…']	['<urn:uuid:06b0b6f5-644b-47de-8464-ac67b43ff428>']	factoid	direct	concise-and-natural	distant-from-document	single-doc	novice	2025-05-01T22:47:46.423955	7	42	1063
34	how does mray enzyme function in bacterial cell wall synthesis and what role does it play in mycobacterial cell division	MraY enzyme catalyzes the attachment of UDP-N-acetylmuramoylpentapeptide (UNAM-pp) to lipid undecaprenyl phosphate (C55P), which is an essential step in bacterial cell wall peptidoglycan biosynthesis. In mycobacteria, this process is particularly important during cell division, as peptidoglycan turnover and remodeling are required for proper cell separation and division at the septum and newly formed cell poles.	"[""- Inhibitors of peptidoglycan synthesis represent antibacterial drug targets\n- A FRET-based assay was developed to find MraY inhibitors\n- The simultaneous dual emission detection capability of the PHERAstar®FS enhances high-throughput\nTable of contents\nThe bacterial enzyme N-acetylmuramoyl-pentapeptide translocase (MraY) is a potential target of antibacterial drugs. It attaches UDP-N-acetylmuramoylpentapeptide (UNAM-pp) to lipid undecaprenyl phosphate (C55P), an essential step during bacterial cell wall biosynthesis. A FRET-based approach detects substances that inhibit MraY and can be read on BMG LABTECH's PHERAstar®. The HTS-suitable assay embeds the donor fluorophore (BODIPY FL), the MraY enzyme and C55P in a micelle. Acceptor-labelled (LRPE) UNAM-pp is then transferred by MraY to the micelle-standing C55P and FRET can occur with the micelle-embedded BODIPY FL.\nIn presence of MraY activity, the resulting fluorescence of the acceptor depends on reaction time and acceptor concentration. The assay allowed for determination of the IC50 value of the MraY inhibitor tunicamycin A. The ratiometric analysis eliminates fluctuations between measurements and makes it a robust assay with a high Z' value.\nPeptidoglycan is an important structural component of the bacterial cell wall. The continual synthesis of peptidoglycan and remodelling of the cell wall is essential for most bacteria. Since the enzyme phosho-N-acteylmuramoyl-penta-peptide translocase (MraY) catalyzes one of the last cytoplasmic steps in the peptidoglycan biosynthesis, it represents a target for antibacterial drugs. This integral membrane protein catalyzes the attachment of soluble UDP-N-acetyl-muramoylpentapeptide (UNAM-pp) to the lipid undecaprenyl phosphate (C55P) which is membrane bound.\nIn this application note we want to present a novel homogeneous FRET-based assay to monitor the activity of MraY. A donor fluorophore (BODIPY-FL) is attached to UNAM-pp (B-UNAM-pp) while the acceptor fluorophore-labelled 1,2-dipalmitoyl-sn-glycero-3-phosphoethano-lamine-N-(lissaminerhodamine B sulfonyl) (LRPE), is embedded in micelles which also contain MraY and the lipid substrate C55P (Figure 1).\nMraY translocase activity will attach B-UNAM-pp to C55P bringing FRET acceptor and donor close to one another. Excitation at 485 nm will result in energy transfer, reducing donor fluorescence (at 520 nm) and increasing acceptor fluorescence (590 nm).\nMaterials & Methods\n- PHERAstar FS microplate reader (BMG LABTECH)\n- Optic module (Ex:485 nm; Em: 520/590)\n- Chemicals were obtained from commercial sources\n- 384 well, low-volume, black, polystyrene plates (Matrix Tech)\nPreparation of UNAM-pp and cloning, expression of MraY in E.coli as well as subsequent preparation of membranes from E.coli overexpressing MraY is described in the literature.\nA 6 µL mixture containing 0.06% Triton X-100, C55P and E.coli membranes containing MraY was preincubated for 30 min. Addition of 3 mL of B-UNAM-pp +/- UMP initiated the reaction. Reaction buffer consisted of (final concentrations): 50 mM Tris-HCl (pH 7.5), 100 mM KCl, 50 mM MgCl2, 1 mM dithiothreitol and 0.05% Triton X-100. Final concentration of reactants: 20 mM C55P, 50 mg/mL membrane protein, 2 µM B-UNAM-pp with 0-24 µM LRPE and 0 or 5 mM UMP.\nTriplicate MraY assays were performed at room temperature. Fluorescence was excited and simultaneous dual-emission measured using 20 flashes for each reading at a focal height 10.6 mm. Measurements were made every minute for 1 hour and triplicate time courses averaged.\nTo test the effect of storage at room temperature, MraY assay reagents were stored at room temperature in the dark in the presence or absence of 0.5M trehalose. Reagents were mixed after 0, 2.5 and 5 hours of storage at room temperature and triplicate F590/F520 data were collected at the 1 hour time point. Z’ calculations could then be obtained from samples with (MAX) and without (MIN) membranes.\nTo study tunicamycin inhibition, reactions contained 16 µM LRPE, 0 or 15 µg/mL MraY-containing E. coli membrane protein, 0.1 µM B-UNAM-pp and 10 µM C55P in assay buffer containing 0.5 M trehalose. Tunicamycin was diluted with assay buffer and average progress curves without membranes were subtracted from the average progresscurves with membranes to obtain D(F590/F520) and DF520 measurements. Percentage inhibition and IC50s were calculated.\nResults & Discussion\nWhen the reaction is exposed to fluorescent excitation at 485 nm a time-dependent decrease in 520 and increase in 590 emission is observed (data not shown). Ratiometric measurements were used as they have less noise than individual fluorescence intensity measurements (Figure 2). This is due to the elimination of fluctuations that equally affect both measurements. The ratio change exhibits an increase in a time and LRPE dependent manner.\nWhen reactions are performed in presence of 5 mM UMP the change in fluorescence ratio is negligible (data not shown). In the absence of UMP a large increase in fluorescence ratio is observed with time (Fig. 2). This effect indicates that the signal observed in the assay is due to the MraY reaction.\nThe effect of trehalose, a sugar stabilizer, on storing the reagents at room temperature was also assessed. Figure 3 shows that Z’ values decrease when assays are stored at room temperature for as little as 2.5 hours. However the addition of 0.5 M trehalose blocks this effect.\nThe sensitivity of this assay to inhibition was studied using tunicamycin (Figure 4). The results show that IC50s measured using Δ(F590/F520) are lower and exhibited less of an increase with reaction time than those measured with ΔF520.\nThis assay has several advantages over those previously reported. First: it uses no radioisotopes so no special training, handling and disposal are required. Second: it uses a donor fluorophore with an excitation wavelength in the visible rather than UV part of the spectrum. This reduces interference from test compound auto-fluorescence and absorption. Finally: a FRET assay using the ratio of the emission of acceptor and donor fluorescence intensities upon donor excitation yields greater precision.\nThe use of Δ(F590/F520) over ΔF520 is advantageous due to greater sensitivity to inhibition, resistance to loss of sensitivity to inhibition and a higher signal-to-noise ratio. Furthermore a Z’ of greater than 0.7 indicates that this approach will be suitable for high throughput screens."", 'Mycobacteria possess a multi-layered cell wall structure that requires extensive remodelling during cell department. peptidoglycan 14653-77-1 turnover with discharge of surplus cell wall structure materials from the septum or recently delivered cell poles. We observed signficant deposition of 3-3 crosslinked muropeptides in the mutant. We further confirmed that removal of network marketing leads to elevated cell wall structure permeability and improved susceptiblity to cell wall structure concentrating on antibiotics. Jointly, these data offer story understanding on cell department in actinobacteria and features a brand-new course of potential medication goals for mycobacterial illnesses. Launch During microbial cell department, redecorating of the cell surface area to create space for the insert of brand-new cell 14653-77-1 wall structure subunits, flagella, porins and specific release equipment is certainly important for effective microbial development. This procedure is certainly powerful, regarding the activity of a lot of nutrients that action in a properly synchronised way to stability biogenesis versus destruction of cell wall structure polymers, such as peptidoglycan (PG). Dysregulation of these redesigning procedures can result in mobile lysis or irregular department that provides rise to nonviable progeny. As such, re-designing of the microbial cell surface area exposes several vulnerabilities that can become targeted for medication advancement. Mycobacteria symbolize a exclusive group of microorganisms within the actinomycetes that possess EPLG3 a extremely impermeable, complicated cell wall structure with structurally unique PG, arabinogalactan and mycolic acidity levels1, 2. During development, mycobacterial cells lengthen through attachment of fresh cell wall structure materials at the poles, adopted by cell department in a way different to that of and offers 5 amidases, which jointly play redundant functions in child cell parting, as proved by the development of microbial 14653-77-1 stores in the lack of two or even more practical amidase genetics, with connected problems in antibiotic level of resistance and PG recycling where possible14, 18C20. Futher evaluation recognized two amidase activators, NlpD and EnvC, which straight interact with amidases to impact conformational adjustments, therefore revealing the energetic site for PG hydrolysis21, 22. In and uncover an essential part for this enzyme in mycobacterial development. Outcomes Amidase gene go with in and and 4229 consist of L341, At the355, L415 and At the48635. These residues nevertheless are conserved in Ami1, in Ami2 both histidines possess been changed with arginine and the residue matching to Age486 is certainly changed with an aspartate, Supplementary Fig.?1. Prior research have got verified biochemical activity in both Ami228 and Ami1, 29 14653-77-1 nevertheless, latest function signifies that amidase activity in Ami2 is certainly weakened fairly, recommending that the amino acidity variants in Ami2 have an effect on catalytic activity31. For amidase_2 fields, structural evaluation of AmiD from highlighted T159 and Age104 as getting important for catalysis36, these residues are conserved in Ami4 but not really in Ami3, where the glutamic acidity is certainly changed by a proline and the lysine is certainly changed by threonine, Supplementary Fig.?1. Therefore, whilst Ami3 retains high likeness to amidase_2 area formulated with nutrients, its catalytic activity needs verification. Additional evaluation of area structure in the mycobacterial amidases uncovered that Ami1 and Ami3 include indication sequences to help in translocation to the periplasm, Supplementary Fig.?2. In overview, there appears to 14653-77-1 become a differential distribution of transmission peptides, catalytic residues and peptidoglycan presenting domain names between the four amidases in mycobacteria, conferring distinguishing features to each enzyme, effective of practical specialty area. Taking into consideration the shown biochemical activity of the amidase_3 website comprising digestive enzymes in mycobacteria, we chosen Ami1 for further evaluation. Ami1 is definitely needed for cell parting during mycobacterial cell department To evaluate the physical part of Ami1 in mycobacterial development, the related gene was erased in using two-step allelic exchange mutagenesis, Fig.?1A. The genotype of the stress was verified by PCR and Southeast mark, Supplementary Fig.?3. Removal of do not really impact development kinetics in broth, slipping motility and nest morphology of mutant by checking and transmitting electron microscopy exposed the development of mobile stores consisting of several cells.']"	['<urn:uuid:667727e9-3485-4ba0-8511-016f74b84877>', '<urn:uuid:930f3eeb-c7bd-4adc-ab18-278b2276f4b0>']	factoid	direct	long-search-query	similar-to-document	multi-aspect	expert	2025-05-01T22:47:46.423955	20	55	1628
36	How does Polish grammar compare to deep phonological dyslexia symptoms?	Polish grammar is characterized by 7 cases and complex inflection, making it notably difficult to master - native speakers don't achieve fluency until age 16. In contrast, phonological dyslexia manifests as an ability to read familiar words using the whole word method, but difficulty in sounding out unfamiliar words. This creates an interesting parallel where both Polish learners and phonological dyslexics struggle with processing novel linguistic patterns, though through different mechanisms.	"['Learning another language gives the learner the ability to step inside the mind and context of that other culture. Without the ability to communicate and understand a culture on its own terms, true access to that culture is barred. In a world where nations and peoples are ever more dependent upon on another to supply goods and services, solve political disputes, and ensure international security, understanding other cultures is paramount. Lack of intercultural sensitivity can lead to mistrust and misunderstandings, to an inability to cooperate, negotiate, and compromise, and perhaps even to military confrontation.\nExtremely Hard: The hardest language to learn is: Polish\nPolish is a West Slavic language and the official language of Poland. Its written standard is the Polish alphabet which corresponds basically to the Latin alphabet with a few additions. Polish-speakers use the language in a uniform manner through most of Poland. It is also used as a second language in some parts of Russia, Lithuania, Belarus, Ukraine and Kazakhstan. This phenomenon is caused by migrations. There are only a few dialects that differ from the standard Polish language, however the differences among them are not significant and mostly based on regional pronunciation and vocabulary changes. The most distinguishable are the dialects of Silesia and Podhale (highlander’s dialect). Worth mentioning is Kashubian – a separate language used by the inhabitants living west of Gdansk near the Baltic Sea. The number of its users is estimated at somewhere between 100,000 and 200,000. Although it is gradually becoming extinct, a lot of effort is being put into saving it and it recently begun to be taught at local schools as a minority language. Polish, like other Indo-European languages, shares some Latin grammar and vocabulary. There are 3 tenses (past, present, future), 2 numbers (singular and plural), and 3 genders (masculine, feminine, neuter). There are no articles but Polish, like Latin, and is an inflectional language that distinguishes 7 cases, defining the noun usage in a sentence. This feature makes our mother tongue difficult to master and presents a lot of trouble to foreigners. The average Polish speaker is fluent in their language not until age 16.\nVery Hard: Finnish, Hungarian, and Estonian-These languages are hard because of the countless noun cases. However, the cases are more like English prepositions added to the end of the root.\nFinnish is one of the official languages of Finland and an official minority language in Sweden. In Sweden, both standard Finnish and Meänkieli, a Finnish dialect, are spoken. The Kven language, which is closely related to Finnish, is an official minority language in Norway. Finnish belongs to the Baltic-Finnic branch of the Finno-Ugric languages, being most closely related to Estonian, Livonian, Votic, Karelian, Veps, and Ingrian. Characteristic phonological features include vowel harmony, in which vowels are divided into two contrasting classes such that vowels from opposing classes may not occur together in a word; and consonant gradation, in which stop consonants (such as p, t, k) are altered before closed syllables (e.g., p is replaced by v, pp by p). There are also two lengths distinguished in vowels and in consonants. Many words have been borrowed from Indo-European languages, particularly from the Baltic languages, German, and Russian. Finnish dialects are divided into two distinct groups, the Western dialects and the Eastern dialects.\nHungarian is a Finno-Ugric language, distantly related to Finnish and Estonian. It is the largest member of the Finno-Ugric family of languages, spoken by about 10 million people in Hungary and 4.5 million in countries adjacent to Hungary and around the world. It is an “agglutinating” language, i.e., a language that uses large numbers of suffixes and post-positions. It belongs to the Finno-Ugric language family, which includes Finnish and Estonian, but its closest relatives are several obscure languages spoken in Siberia. Hungarian is not at all related to the Indo-European languages which surround it, and is very different both in vocabulary and in grammar. Hungarian is an agglutinative language, meaning that it relies heavily on suffixes and prefixes. The grammar is seemingly complex, yet there is no gender, a feature that most English speakers grapple with when learning other European languages. Hungarian is a highly inflected language in which nouns can have up to 238 possible forms. It is related to Mansi, an Ob-Ugric language with about 4,000 speakers who live in the eastern Urals, and Khanty or Ostyak, the other Ob-Ugric language which is spoken by about 15,000 people in the Ob valley of western Siberia.\nEstonian is the official language of Estonia, spoken by about 1.1 million people in Estonia and tens of thousands in various émigré communities. It is an Uralic language and is closely related to Finnish. Even the most ordinary everyday Estonian language contains numerous ancient expressions, possibly going back as far as the Ice Age. The language occurs in two major dialectal forms, northern and southern; the northern dialect, Tallinn, is used in most of the country and forms the basis of the modern literary language. The southern dialect is found from Tartu southward. Typologically, Estonian represents a transitional form from an agglutinating language to an inflected language. In Estonian nouns and pronouns do not have grammatical gender, but nouns and adjectives are declined in fourteen cases: nominative, genitive, partitive, illative, inessive, elative, allative, adessive, ablative, translative, terminative, essive, abessive, and comitative, with the case and number of the adjective(s) always agreeing with that of the noun. Thus the illative for “a yellow house” (kollane maja) – “into a yellow house” is (kollasesse majasse). The verbal system is characterized by the absence of the future tense (the present tense is used) and by the existence of special forms to express an action performed by an undetermined subject (the “impersonal”).\nPretty Hard: Ukrainian and Russian complex grammar and different alphabet but easier pronunciation. Serbian-Also similar to other Slavic languages with a complex case and gender system, but it also has many tenses. alphabet\nUkrainian is a language of the East Slavic subgroup of the Slavic languages. It is the official state language of Ukraine. Written Ukrainian uses the Cyrillic alphabet. The alphabet comprises thirty-three letters, representing thirty-eight phonemes (meaningful units of sound), and an additional sign—the apostrophe. Ukrainian orthography is based on the phonemic principle, with one letter generally corresponding to one phoneme, although there are a number of exceptions. The orthography also has cases where the semantic, historical, and morphological principles are applied. The letter ? represents two consonants [?t?]. The combination of [j] with some of the vowels is also represented by a single letter ([ja]=?, [je]=?, [ji]=?, [ju]=?), while [jo]=?? and the rare regional [j?]=?? are written using two letters. These iotated vowel letters and a special soft sign change a preceding consonant from hard to soft. An apostrophe is used to indicate the hardness of the sound in the cases when normally the vowel would change the consonant to soft; in other words, it functions like the yer in the Russian alphabet. A consonant letter is doubled to indicate that the sound is doubled, or long. The phonemes [dz] and [d?] do not have dedicated letters in the alphabet and are rendered with the digraphs ?? and ??, respectively. [dz] is pronounced close to English dz in adze, [d?] is close to g in huge.\nRussian is the most geographically widespread language of Eurasia, the most widely spoken of the Slavic languages, and the largest native language in Europe. Russian belongs to the family of Indo-European languages and is one of three living members of the East Slavic languages, the others being Belarusian and Ukrainian (and possibly Rusyn, normally considered a dialect of Ukrainian). Russian is written using a modified version of the Cyrillic (?????????) alphabet, consisting of 33 letters. Russian spelling is reasonably phonetic in practice. It is in fact a balance among phonetics, morphology, etymology, and grammar, and, like that of most living languages, has its share of inconsistencies and controversial points. The Russian language possesses five vowels, which are written with different letters depending on whether or not the preceding consonant is palatalized. The consonants typically come in plain vs. palatalized pairs, which are traditionally called hard and soft. (The ‘hard’ consonants are often velarized, some dialects only velarize /l/ in such positions). The standard language, based on the Moscow dialect, possesses heavy stress and moderate variation in pitch. Stressed vowels are somewhat lengthened, while unstressed vowels (except /u/) tend to be reduced to an unclear schwa. Russian is notable for its distinction based on palatalization of most of the consonants. The spoken language has been influenced by the literary, but continues to preserve characteristic forms. The dialects show various non-standard grammatical features, some of which are archaisms or descendants of old forms since discarded by the literary language. The total number of words in Russian is difficult to reckon because of the ability to agglutinate and create manifold compounds, diminutives, etc.\nSerbian is a South Slavic language, spoken chiefly in Serbia, Bosnia and Herzegovina, Montenegro, Croatia, and in the Serbian diaspora. Standard Serbian is based on the Shtokavian dialect, like the modern Croatian and Bosnian, with which it is mutually intelligible, and was previously unified with under the standard known as Serbo-Croatian. Uses primarily Cyrillic, but also the Latin alphabet as well. Serbian verbs are one of the most complicated parts of Serbian grammar (with noun cases, probably, being the hardest). They are inflected for person, number and sometimes gender. Serbian verbs are conjugated in 4 past tenses – perfect, aorist, imperfect, and pluperfect, of which the last two have a very limited use (imperfect is still used in some dialects, but majority of native Serbian speakers consider it archaic); 1 future tense (aka 1st future tense – as opposed to the 2nd future tense or the future exact, which is considered a tense of the conditional mood by some contemporary linguists), and 1 present tense. These are the tenses of the indicative mood. Apart from the indicative mood, there is also the imperative mood. The conditional mood has two more tenses, the 1st conditional (commonly used in conditional clauses, both for possible and impossible conditional clauses), and the 2nd conditional (without use in spoken language – it should be used for impossible conditional clauses). Serbian language has active and passive voice. As for the non-finite verb forms, Serbian language has 1 infinitive, 2 adjectival participles (the active and the passive), and 2 adverbial participles (the present and the past).\nFairly Hard: Chinese and Japanese-No cases, no genders, no tenses, no verb changes, short words, very easy grammar, however, writing is hard. But to speak it is very easy. Also intonations make it harder but certainly not harder than Polish pronunciation. I know a Chinese language teacher that says people pick up Chinese very easy, but he speaks several languages and could not learn Polish. I am learning some Chinese, it is not the hardest language maybe even the easiest language to learn. Not the hardest language by any measure. Try to learn some Chinese and Polish your self and you will see which is the hardest language.\nChinese languages – also called Sinitic languages – are a principal language group of eastern Asia which belongs to the Sino-Tibetan language family. All varieties of modern Chinese are analytic languages, in that they depend on syntax (word order and sentence structure) rather than morphology—i.e., changes in form of a word—to indicate the word’s function in a sentence. In other words, Chinese has few grammatical inflections—it possesses no tenses, no voices, no numbers (singular, plural; though there are plural markers, for example for personal pronouns), and only a few articles (i.e., equivalents to “the, a, an” in English). There is, however, a gender difference in the written language (? as “he” and ? as “she”), but it should be noted that this is a relatively new introduction to the Chinese language in the twentieth century. They make heavy use of grammatical particles to indicate aspect and mood. In Mandarin Chinese, this involves the use of particles like le ?, hai ?, yijing ??, etc. Other notable grammatical features common to all the spoken varieties of Chinese include the use of serial verb construction, pronoun dropping and the related subject dropping.\nJapanese is believed to be linked to the Altaic language family, which includes Turkish, Mongolian and other languages, but also shows similarities to Austronesian languages like Polynesian. The Japanese writing system consists of three different character sets: Kanji (several thousands of Chinese characters) and Hiragana and Katakana (two syllabaries of 46 characters each; together called Kana). Japanese texts can be written in two ways: In Western style, i.e. in horizontal rows from the top to the bottom of the page, or in traditional Japanese style, i.e. in vertical columns from the right to the left side of the page. Both writing styles exist side by side today. Basic Japanese grammar is relatively simple. Complicating factors such as gender articles and distinctions between plural and singular are missing almost completely. Conjugation rules for verbs and adjectives are simple and almost free of exceptions. Nouns are not declinated at all, but appear always in the same form. The biggest difficulty are accents, which do exist, but to a much lower extent than in the Chinese language. In addition, there are relatively many homonyms, i.e. words that are pronounced the same way, but have different meanings.\nAverage: French-lots of tenses but not used and moderate grammar.\nFrench is a Romance language globally spoken by about 77 million people as a first language (mother tongue), by 50 million as a second language, and by about another 200 million people as an acquired foreign language, with significant speakers in 57 countries. French is a moderately inflected language. Nouns and most pronouns are inflected for number (singular or plural); adjectives, for the number and gender (masculine or feminine) of their nouns; personal pronouns, for person, number, gender, and case; and verbs, for mood, tense, and the person and number of their subjects. French has a grammar similar to that of the other Romance languages. The French grammar provides definitions and links to further information about each of the French verb tenses, pronouns, and other grammatical structures.\nBasic to hard: English, no cases or gender, you hear it everywhere, spelling can be hard and British tenses you can use the simple and continues tense instead of the perfect tenses and you will speak American English. English at the basic level is easy but to speak it like a native it’s hard because of the dynamic idiomatic nature.\nEnglish is a West Germanic language that developed in England during the Anglo-Saxon era. English grammar has minimal inflection compared with most other Indo-European languages. For example, Modern English, unlike Modern German or Dutch and the Romance languages, lacks grammatical gender and adjectival agreement. Case marking has almost disappeared from the language and mainly survives in pronouns. At the same time, the language has become more analytic, and has developed features such as modal verbs and word order as resources for conveying meaning. Auxiliary verbs mark constructions such as questions, negative polarity, the passive voice and progressive aspect.', 'Ad blocker interference detected!\nWikia is a free-to-use site that makes money from advertising. We have a modified experience for viewers using ad blockers\nWikia is not accessible if you’ve made further modifications. Remove the custom ad blocker rule(s) and the page will load as expected.\nIndividual differences |\nMethods | Statistics | Clinical | Educational | Industrial | Professional items | World psychology |\nPhonological dyslexia is a reading disability that is a form of Alexia (acquired dyslexia), resulting from brain injury, stroke, or progressive illness and that affects previously acquired reading abilities. The major distinguishing symptom of acquired phonological dyslexia is that a selective impairment of the ability to read pronounceable non-words occurs although the ability to read familiar words is not affected. It has also been found that the ability to read non-words can be improved if the non-words belong to a family of pseudohomophones.\nDeep and phonological dyslexiaEdit\nIndividuals who suffer from phonological dyslexia have the opposite problem to surface dyslexics. These individuals are able to read using the whole word method. However, they struggle when it comes to sounding words out. Phonological dyslexics are able to read familiar words, but have difficulties when it comes to unfamiliar words or non-words that are pronounceable. Several studies have found that many phonological dyslexics have a good reading ability if the individual has developed a large vocabulary prior to suffering from brain damage. These individuals seem to stop developing their vocabulary post-brain damage, which affects their reading capacity.\nPhonological dyslexia is a reading disorder in which the patient has impaired reading of nonwords. The symptoms of phonological dyslexia are very similar to those of deep dyslexia. The major difference between these two dyslexias is that phonological dyslexics do not make semantic errors associated with deep dyslexia. Beauvois and Dérouesné (1979) studied the first case of phonological dyslexia and came up with this term. The problem people with phonological dyslexia have is that they are able to read words using the whole word method; however, they are not able to sound words out. This means that they are able to read familiar words, but have difficulties reading new words.\nInitially it was believed that the factor causing phonological dyslexia was lexicality; however, other factors such as imageability and concreteness also play a critical role in reading. A study done by Crisp and Lambon Ralph concluded that imageability has a significant effect on phonological dyslexia. The study found that eleven out of the twelve patients had more accuracy when reading words with high imageability. In that study, the patient who was the exception was the least severely damaged, contributing to a view of phonological dyslexia and deep dyslexia as points on a continuum rather than discrete disorders.\nSeveral studies have found that different levels of brain damage can lead to the occurrence of varying forms of non-word reading disorders. It has been found that during certain tasks, dyslexics had activated one of two regions of the brain: the Broca\'s area, which is responsible for speech, or the Wernicke\'s area, which is responsible for forming and understanding. Both areas were seldom active together. This study has led to the conclusion that there exist neural connection breakdowns between the language centers that may be causing dyslexia.\nAn investigation conducted by Harley, T. A., and O\'Mara, D.A. (2006) found that hyphenation significantly improved a participant`s reading ability. The subject suffered from phonological dyslexia that was due to a deficiency in graphemic parsing. The study suggested that hyphenation might be generally useful as a strategy to assist phonological dyslexics.\nA study was done by Beauvois and Dérouesné on a 64-year-old man. The individual is described as right-handed, a retiree, and having formerly been an agricultural machinery representative. The individual had had surgery for a left parieto-occipital angioma. Scans showed a lesion at the left angular gyrus, the posterior part of the second temporal convolution, the inferior longitudinal fasciculus, the geniculostriate fibres and tapetum. The patient was also found to be suffering from neurological defects such as right inferior quadrantanopia, mild memory deficit, mild calculation impairment, minimal constructional apraxia, and astereognosia. It was found that the patient did not suffer from motor or sensory defects. He had been obliged to retire as the phonological dyslexia disrupted his ability to work. He had previously enjoyed reading, but was now unable to read his own or other pieces of writing. The diagnosis was confirmed with the Alouette reading test, which concluded that the patient suffered from a reading disability. He was found to have the reading ability of a 6-year-old child, which is considered to be the lowest reading level. The level of reading was not determined from the speed, rather from the fact that the patient was not able to read more than 62 of the stimuli presented in three minutes, while 40% of the represented stimuli were either read incorrectly or left unread. The reading errors included adjectives, possessive adjectives, conjunctions and verbs.\n- ↑ Cherney LR (2004). Aphasia, alexia, and oral reading. Top Stroke Rehabil 11 (1): 22–36.\n- ↑ 2.0 2.1 Dérouesné J, Beauvois MF (December 1979). Phonological processing in reading: data from alexia. J. Neurol. Neurosurg. Psychiatr. 42 (12): 1125–32.\n- ↑ (1995). Three routes from print to sound: Evidence from a case of acquired dyslexia. Cognitive Neuropsychology 12 (2): 113–147.\n- ↑ 4.0 4.1 Beauvois MF, Dérouesné J (December 1979). Phonological alexia: three dissociations. J. Neurol. Neurosurg. Psychiatr. 42 (12): 1115–24.\n- ↑ 5.0 5.1 5.2 Welbourne S.R.; Lambon Ralph M.A. (2006), ""Phonological and Surface Dyslexia in a Single PDP Model of Reading"", Proceedings of the 28th Annual Conference of the Cognitive Science Society, Mahwah, New Jersey: Lawrence Erlbaum Associates, pp. 2359–64, ISBN 9780976831822, http://csjarchive.cogsci.rpi.edu/proceedings/2006/docs/p2359.pdf\n- ↑ Berndt, R.S., Hawndiges, A.N., Mitchum, C. C., & Wayland, S.C. (1996). An investigation of nonlexical reading impairments. Cognitive Neuropsychology, 13, 763-801.\n- ↑ Dérouesné, J ; Beauvois, M F. (1985). ""The “phonemic” state in the non-lexical reading process: Evidence from a case of phonological alexia"" Surface dyslexia: neuropsychological and cognitive studies of phonological reading, 399–457, Hillsdale, N.J: Lawrence Erlbaum Associates.\n- ↑ Lishman WA (December 2003). Developmental dyslexia. J. Neurol. Neurosurg. Psychiatr. 74 (12): 1603–5.\n- ↑ (2006). Hyphenation can improve reading in acquired phonological dyslexia. Aphasiology 20 (8): 744–761.\n- Rohrer JD, Knight WD, Warren JE, Fox NC, Rossor MN, Warren JD (January 2008). Word-finding difficulty: a clinical analysis of the progressive aphasias. Brain 131 (Pt 1): 8–38.\n- Sato H, Patterson K, Fushimi T, Maxim J, Bryan K (2008). Deep dyslexia for kanji and phonological dyslexia for kana: different manifestations from a common source. Neurocase 14 (6): 508–24.\n- Tree JJ, Kay J (2006). Phonological dyslexia and phonological impairment: an exception to the rule?. Neuropsychologia 44 (14): 2861–73.\n- Tree JJ (June 2008). Two types of phonological dyslexia - a contemporary review. Cortex 44 (6): 698–706.\n- Phonological dyslexia: past and future issues.\n- Are there orthographic impairments in phonological dyslexia?\n|This page uses Creative Commons Licensed content from Wikipedia (view authors).|']"	['<urn:uuid:53e8e1fc-2a6f-40dc-8de7-c7cc87b7e2a4>', '<urn:uuid:2d4db57b-d191-40a7-a98f-0bc206bb1dc1>']	open-ended	direct	concise-and-natural	similar-to-document	multi-aspect	expert	2025-05-01T22:47:46.423955	10	71	3698
37	accessing medical care via telehealth virtual consultations benefits and impact on healthcare providers during covid19 pandemic	Telehealth virtual consultations provide multiple benefits for both patients and healthcare providers during the COVID-19 pandemic. For patients, they enable convenient access to medical care from home, offering safety through remote check-ups and reducing virus spread. For healthcare providers, companies like Knok Healthcare have developed integrated solutions combining AI triage, scheduling, video-consultation, and health records integration with hospitals and clinics. This helps address physician shortages by facilitating better coordination between smaller hospitals and specialists in larger facilities. The technology also enables 24/7 remote patient monitoring through digital devices and allows seamless sharing of medical files between physicians for better diagnostic care, while reducing the workload on primary healthcare providers.	['RYSE provides major funding boost for digital health start-ups\nPioneering digital health start-ups receive major funding boost to transform COVID-19 patient care\nAt a time when investment and funding prospects for the health tech and life science industry have dried up, and some investors have reneged on deals due to COVID-19: LiveSmart, Knok Healthcare, Log My Care, Firza, and MediShout are among the few start-ups to receive funding.\nPatients will benefit from enhanced care delivery thanks to innovations made possible by investments from RYSE Asset Management and other investors. These companies have raised a total of £4.5 million.\nBusy clinical working environments are faced with logistical issues that can create delays and increase the cost of care delivery. This has been particularly apparent during the pandemic where efficient redeployment of resources is paramount.\nVirtual consultations, workforce optimisation solutions for primary healthcare providers, platforms for digital virus tracking and care home digitalisation, and reporting solutions for logistical and medical supply issues for helpdesk prioritisation are just some of the innovations to receive investment.\nThe innovations and some of the jobs created include:\n- Firza is on a mission to reduce the overbearing workload on primary healthcare by using a centralised workforce with Robotic Process Automation (RPA) and Artificial Intelligence (AI) technology to emulate the actions of a human interacting with healthcare systems to optimise medication management. The company plans to employ an additional 45 people over the next year.\n- Knok Healthcare, a global telehealth and SaaS start-up, has an integrated solution for remote consultations through a combination of AI triage, scheduling, video-consultation, health records, and integration with hospitals and clinics. The company plans to employ an additional 19 people over the next year.\n- Log My Care has developed care management software and offers a free COVID-19 symptom tracking tool to support care homes in overcoming challenges in early symptom detection in this high risk population. The company plans to employ an additional 6 people over the next year.\n- MediShout has developed communication software that allows clinical staff to flag non clinical issues such as out of service facilities and reduced levels of PPE. This has allowed key healthcare workers to focus on delivering patient care. The company plans to employ an additional 15 people over the next year.\n- LiveSmart provides health assessments and reacted quickly to the new situation. The team sourced and supplied antibody tests via their well-established platform; supporting both small businesses and large corporate clients. The company plans to employ an additional 36 people over the next year.\nAll of the companies have been awarded seed funding as a result of their successful applications to the RYSE digital health funding programme. The programme invited early stage digital health and medtech companies to apply for funding with the opportunity to work alongside RYSE, DigitalHealth.London (DH.L), and MedCity.\nAshish Kalraiya, CEO at MediShout, said: “We are proud of our ability to innovate in direct response to the needs on the frontline, and during the COVID-19 pandemic it has been critical to ensure that the needs of patients affected by conditions other than COVID-19 continue to be met. The connections we have forged through working with RYSE, MedCity, and DigitalHealth.London mean we can devise creative solutions we know will best meet the needs of the NHS staff and patients. RYSE’s funding has transformed our innovation into a reality that benefits patients and our crucial NHS staff.”\nClaudio D’Angelo, Managing Partner at RYSE Asset Management LLP, said: “We are delighted to have seeded much-needed investment in these health tech start-ups who are transforming patient care through innovation. We are well aware of the funding gap for early-stage digital health innovations, even outside of COVID-19, and are passionate about plugging the gap to support the growth of this industry – and, critically, through public-private collaborations as we know this will have the greatest impact. The innovations developed with our funding demonstrate the huge return on investment investors stand to gain when they fund health tech start-ups.”\nSarah Haywood, Executive Director of MedCity, said: “Securing funding for early-stage health tech companies has always been a challenge; thrown into the unprecedented times of COVID-19 the challenge is even greater, particularly for companies not eligible for the Government’s Future Fund and for companies raising money for the first time. Now is innovation’s time to shine – demonstrating how it can meet patients’ needs as we unite across the globe to tackle this deadly virus.\n“We are immensely grateful to RYSE for their generous investment and for their recognition of the critical role these companies play. The innovations coming out of our partnership with RYSE and DigitalHealth.London bear testament to the profound contribution health tech start-ups make to our health systems and patients, and to what we stand to lose if the UK’s digital health sector is not supported to thrive. We also recognise the important role that early stage investors, like RYSE, play in supporting companies beyond investment. Mentoring, advice, guidance, and connections are equally important to the success of our next generation of innovators.”\nAnna King, Commercial Director, Health Innovation Network, a founder partner of DigitalHealth.London said: “We set up DigitalHealth.London to help encourage and support the development of digital health businesses working with the NHS. Investment from RYSE in these high potential companies has been vital to enable them to develop high quality products that meet patient needs in the NHS and internationally. We are delighted to see investors like RYSE supporting more companies in this exciting sector.”\nRYSE Asset Management LLP (RYSE), is a London based FCA authorised and regulated investment manager, tailored for high net worth individuals, family offices, and institutions. In partnership with DigitalHealth.London (DH.L) and MedCity to identify, support, and invest in early-stage digital health and MedTech companies, to commercialise and scale within the NHS and other healthcare delivery systems.\n- LiveSmart (health assessments): A PHE approved #COVID19 antibody test (Abbott).\n- Knok healthcare (virtual consultations): A check-up from the comfort of home provides social impact and safety.\n- Log my Care (care management): A free symptom tracking tool to help care homes detect early symptoms of #COVID19.\n- Firza health (medication management): Delivering technology and digital services for modern day primary care.\n- MediShout (healthcare reporting): Improving healthcare reporting logistics and supply chain issues during #COVID19 – improving the quality of care and reducing error.\nIn 20018, we also invested in:\nSkin Analytics (AI cancer screening): A new skin cancer community assessment service to reduce delays during #COVID19.\nDigitalHealth.London is helping health tech entrepreneurs and healthcare professionals turn the idea of digital innovation into tangible improvements for staff and patients.\nTheir iniatives bring together health and care stakeholders across London to collaborate and solve some of the biggest challenges in the NHS:\nDigital Pioneer Fellowship: The NHS Digital Pioneer Fellowship supports up to 30 digital change makers employed by NHS organisations in London to design and lead transformation projects underpinned by digital innovation.\nDigitalHealth.London accelerator: Each year, the Accelerator programme works with up to 20 high potential SMEs, giving bespoke support and advice, a programme of expert-led workshops and events, and brokering meaningful connections between innovators and NHS organisations with specific challenges', 'Telehealth has become one of the most useful solutions in managing the spread of the COVID-19 pandemic, but this method is nothing new. Telemedicine was originally conceptualized to support the gaps of long-distance clinical health care, which has become more important than ever this last year.\nThis method, which involves the use of electronic information and telecommunications to carry out healthcare-related services and education, makes use of various tools such as videoconferencing, store-and-forward imaging, media streaming, and other forms of internet-based and wireless communications.\nAs in-person meetings are minimized to control the spread of the virus, telehealth has become a useful communication channel for patient and medical professionals, as well as public health and health administration. By allowing the easier flow of communication between and among health professionals and patients, telehealth makes the world seem like a small village.\nAlso called electronic health (e-health) or mobile health (m-health), here are the most common ways in which telehealth has changed the health industry:\n- Telehealth for 24/7 Remote Patient Monitoring\nIn the past years, a physician has to personally examine the patient in order to access medical care. Now, thanks to various technological advances, patients’ data can be gathered by digital devices, smartphone apps, and internet-enabled computers. Wearables and other electronic monitoring devices may now be used to collect and transmit vital signs including blood pressure, cardiac stats, oxygen levels, blood glucose levels, and respiratory rates. This data can then be sent to physicians who will act appropriately based on the health data gathered.\nSome more advanced devices can be programmed to schedule reminders for taking medicine, while some home monitoring devices for older people can detect changes in normal activities and may be helpful in alerting authorities for accidents such as slipping and falling. You can learn more about telehealth by watching this:\n- Telehealth Allows Virtual Appointments\nMost clinics offer virtual appointments, where patients are examined by doctors via videoconferencing. This is highly convenient not only to limit the spread of COVID-19 but also to reach out to patients who have reduced mobility or are located in remote parts of the country.\nIn some cases, virtual appointments use chatbots to ask a patient about several symptoms and other important details. After gathering pertinent health-related questions, the doctor will prescribe medications, home care methods, or additional care, if necessary.\n- Telehealth Makes Healthcare Services More Interactive\nPatients no longer need to sit and wait after securing an appointment with a doctor. Hospitals and clinics have online patient portal where patients’ queries are answered and their concerns addressed. Take, for instance, https://teleemc.com/, which offers telemedicine services to patients. The portal provides a patient with a secure means to interact with medical professionals.\nBy logging in, a patient can easily communicate with a physician or nurse, request for prescription refills, review laboratory tests results, and schedule appointments.\n- Telehealth Leads to Better Diagnostic Care\nAdvances in technology also allows physicians to provide better care to their patients by discussing with specialists about your diagnosis and treatment. One of the major benefits of telehealth is the seamless sharing of files including exam notes, patient history, test results, X-rays or other images. Your primary care physician can send these to the appropriate specialist for thorough discussion about your case. With communication exchanges done electronically, these virtual meetings between physicians helps prevent delays caused by in-person referrals. Don’t worry about out-of-pocket costs as many telehealth costs are covered by Medicare and other health insurance companies.\n- Telehealth for Easy Access to Personal Health Records\nVarious apps can be downloaded and installed over multiple devices that can help you store your personal health information. There’s an electronic personal health record system which holds all your health information that you can access whenever you would like.\nThis is useful in times of emergency, as you can easily provide your health attendant with vital information, including diagnoses, medications, drug allergies and your doctor’s contact details.\n- Telehealth Addresses Physician Shortages\nThis method helps address the problems faced by remote areas where healthcare professionals are few and far between. It also facilitates better coordination between smaller hospitals and specialists in larger and more advanced medical facilities. Telehealth is likewise being implemented to provide healthcare services for the detained, as well as in rural communities and underserved urban areas to improve healthcare access.\n- Telehealth Provides Learnings and Trainings\nIn order to keep their license, physicians are required to engage in continual learning, especially since medical advances occur at a faster rate these days. By using video-conferencing and other online tools under the telehealth principle, practitioners can engage in a blended learning approach to enhance their knowledge and skills.\nThe main goals of telehealth include: improve overall accessibility of healthcare services, provide easy access to medical professionals and specialists, enhance coordination between the healthcare providers and patients, and empower patients to manage their self-health care. There are various companies that offer these services. Consider these factors before choosing a telehealth solution.\nTelehealth has been addressing various healthcare-related problems and enhances medical access for patients and resource-starved medical facilities. Aside from convenience, it also saves time and costs. For these reasons, telehealth is becoming more and more the favored method among various stakeholders in the healthcare industry.']	['<urn:uuid:5d0272f0-6be7-481e-b33e-b9bf6c4fbd8f>', '<urn:uuid:a6f0335c-ec53-488f-8f2e-ad511113fd73>']	open-ended	with-premise	long-search-query	similar-to-document	multi-aspect	expert	2025-05-01T22:47:46.423955	16	109	2073
40	inherited grandma antique ring make it bigger possible problems	Antique rings can be resized, but there may be some discoloration around the repair area, particularly with older white gold rings. The cause of discoloration isn't always known by jewelers, though they make efforts to minimize lines or discoloration. Usually, such imperfections are only noticeable with a magnifying glass.	['People resize rings for many different reasons. For some it is weight loss or weight gain, and for others it is simply to be able to wear the ring on a different finger. Resizing is very common and can be done on most rings, but there are some exceptions. To better understand when sizing can and cannot be done, one must understand the process.\nMaking a Ring Smaller\nDecreasing the band size on a ring is fairly easy when done by a jeweler. For the ring to be made smaller, the jeweler must cut out a small portion of the band. The ring must then be reshaped to the proper circular shape and then it can be soldered back together. The jeweler must make a weld that is virtually invisible, and it must then be polished and smoothed so that no indication of the sizing is visible.\nThis method can easily be used for rings with a plain shank or band. Rings which are ornate or have a design which carries around the complete band will need to be rebuilt over the sizing. There is sometimes an area on ornate rings which has been left for resizing. This area, however, is usually used for making the ring larger instead of smaller.\nSome rings have jewels all around the band or are channel style less than half way around the band, and may require the jeweler to remove the gems before sizing. This depends on the setting and pattern. For rings being made smaller, the diamonds or gems may be moved to balance the setting of the ring.\nMaking a ring larger\nIncreasing the size of a ring can be done two ways. When a ring needs to be made just slightly larger, sometimes a jeweler can stretch the ring to the desired size. The ring needs to be cut and an additional piece of the shank or band soldered in if the size increase is a half size or larger. If a jeweler needs to resize an ornately patterned ring, or one with jewels throughout the band, the sizing can pose a problem. The jeweler will discuss options with you which may include changing the setting.\nRings not to re-size\nYou should not try to re-size a ring which has channel set stones more than half way around the band. If the ring has an elaborate setting or certain types of gems, some of the stones may need to be removed and reset before the ring can be sized. If the ring is an antique or is an older white gold ring, there may be some discoloration around the repair area. It is not always possible for the jeweler to know the cause of the discoloration. Most jewelers will make every effort to minimize lines or discoloration on the ring. Usually it is only noticeable with the use of a magnifying glass. It is imperative that you discuss options with your jeweler.\nCeltic rings with the design all the way around the band can be made slightly larger or smaller without distorting the pattern. Increases or decreases of a significant amount are usually not successful without distortion to the pattern.']	['<urn:uuid:d65ef033-2636-43a1-bc38-de00dbb34064>']	factoid	with-premise	long-search-query	distant-from-document	single-doc	novice	2025-05-01T22:47:46.423955	9	49	530
42	How do sensing trends and employee training affect demand planning success?	Demand sensing uses historical data, POS data, market signals and weather conditions to detect if demand is increasing or decreasing relative to company targets. It improves demand signals available to companies, helping increase forecast accuracy and reduce inventory levels. Supporting this, employee training is vital since demand planning involves multiple cross-functional inputs. Companies must keep employees well-trained on the importance of their contributions to the overall outcome, as the information they provide helps achieve success in this complicated, multi-faceted system requiring inputs from across the organization.	"['How do you get the sense of what works for demand planning?\nWhile making a good sauce often does not require as much precision as baking does, it requires a general sense of measurement. Good chefs are often able to whip out soups and sauces without measuring every ingredient accurately. They start to get a sense of what works.[Related Webinar: How to Use Predictive Analytics to Drive Sales & Delight Your Customers ]\nImproving Demand Planning\nThe ‘secret sauce’ concept to demand planning is a little bit trickier. Market volatilities including changes in the weather can affect any business at any given time. As such, businesses cannot rely on their history alone without considering the full picture of possible market changes. When these changes occur, businesses should be ready to adapt without causing a disruption in existing business processes.\nSo how to do you get to the point where you get a sense of what works when it comes to demand planning?\nOr is that even an attainable goal?\nFirstly, due to needing to quickly react to market trends, while most businesses should aim at creating stable and sustainable demand planning processes, they should also strive to employ a continuous improvement strategy. Compare it to a chef modifying existing recipes with new ingredients to create a completely new rendition of an existing dish.\nRecently, I presented two sessions at the SAPinsider SCM conference on demand sensing and demand shaping. While these sessions were aimed at upstream manufacturers, the general concepts that were discussed can be applied to any manufacturing businesses. If you are interested in improving your existing demand generation and shaping initiatives, you might enjoy our upcoming webinar.[Read Also: B2B Demand Sensing: 7 Things You Must Know ]\nDemand sensing is a robust methodology that involves using historical data, near-term market signals such as POS data, changes in the weather and market conditions, to improve forecast accuracy for inventory planning. At the demand sensing stage, businesses put the ground work in place to sense the trends in the demand, whether it is going up or down, and if it will hit the company targets.\nKey elements of demand sensing:\n- Uses POS, market buzz, and other consumer facing data\n- Improves demand signals available to companies, which helps to increase forecast accuracy and reduce inventory levels.\n- Determines if Demand Generation & Shaping are needed\nDemand Generation and Shaping\nDemand generation and shaping work hand in hand. With Demand generation, businesses use targeted marketing campaigns designed to drive awareness and interest in a company’s products or services. Demand shaping follows a similar fashion. For demand shaping, B2C companies often employ price incentives, cost modifications and product push to help meet planned supply. Often, the above demand shaping tactics are not available in the B2B world. Demand shaping can be geared towards getting rid of excess inventory or to drive sales to certain products or services.\nKey elements of demand generation and shaping\n- Targeted marketing campaigns designed to drive awareness and interest in a company’s products or services.\n- May Execute Demand Shaping strategy through marketing communication.\n- Demand shaping involves influencing or manipulating demand for a company’s products or services to match planned supply.\n- Performed through pricing incentives, cost modifications, and product substitutions.\nHow do you accomplish demand generation and shaping?\nFor our clients looking to improve existing demand generation and shaping initiatives, we often employ a detailed three-step approach.\nThe Three Step Approach to Implementing Demand Generation and Shaping\nStep #1: Identify Goals\nThe first step in implementing or improving existing demand generation and shaping projects involves identifying business goals to ensure the initiatives match the bigger business picture.\nKey questions to ask include:\n- What are we trying to accomplish?\n- Are Demand Generation & Shaping opportunities available?\n- What will be the impact of an action/inaction?\nStep #2: Capture Data\nOnce you’ve identified the business goals and determined how demand shaping and generation aligns with your plan; it’s now time to determine how to use existing data to help improve demand shaping.\nThings to note:\n- Analyze historical data and compare it to the current local situation\n- Always use as much historical data as possible for a better statistical analysis\n- Identify ways to create demand opportunities\nStep #3: Configure Solution\nAt the third stage of the demand generation and shaping project, we tie everything together by configuring a software solution that eliminates the need for manual data manipulation. The graphic below describes a demand generation and shaping analysis. In the example below, the solution configured was for an upstream manufacturer, about three or more layers removed from the end user. In this case, the execution involved proactive order solicitation using order frequency analysis, therefore, leading to an increase in sales, fewer missed orders, and most importantly improved customer relationships. In the upcoming webinar on demand shaping, I will share more practical examples on how customers are not only figuring out what works, but also exceeding set sales targets due to demand shaping initiatives. It might even be safe to say that they may have discovered their ‘secret sauce’ to demand planning.[Download Guide: Forecasting Fallacy Locking A Piece Of A Forecast ]', 'tiero - Fotolia\nThe modern supply chain holds demand planning challenges galore. And that means you need better strategies.\nOmnichannel e-commerce -- customers\' desire to buy online and pick up their products in physical stores, for example -- is driving the need for organizations to rethink how they\'re doing demand planning and inventory, said Mike Griswold, vice president at Gartner.\nHere are some top demand planning strategies to help enterprises get customers the goods they want, when and where they want them.\n1. Bring demand signals together\nTo accurately forecast demand, companies need to understand how many widgets they\'re going to sell across multiple sales channels, Griswold said.\n""I need to know how much I\'m going to sell in the store. I need to know how much I\'m going to sell online,"" he said. ""And then I need to bring these demand signals together so that for a particular widget, I know the demand for this planning window.""\nEnterprises are trying to do that through technology -- for example, an application that looks at the point of sale data from the cash register, data from online sales, data from a catalog business and call center data, Griswold said.\n""Technology is really the way that we\'re bringing all of these demand signals together to get that one view of how much of a particular widget a company is going to sell,"" he said. ""Once [an organization] knows how much it\'s going to sell, it can figure out when it needs to get the right amount of inventory -- and from where -- to support the sales plan.""\n2. Create a holistic understanding\nUsing supplier lead time strategically is critical for successful demand planning.\nDemand planners have to understand what the rest of the organization is doing so that they\'re not unprepared and have either the wrong kind of inventory or insufficient inventory, said Marisa Brown, senior principle research lead for supply chain management at American Productivity and Quality Center, a nonprofit benchmarking and best practices research organization in Houston.\nAs an example, demand planners must be aware of upcoming social media campaigns and sales promotions, she said. Production should understand what sales and marketing are planning.\n""They can then work with their suppliers to make sure they\'ve placed the requests for these raw materials sufficiently in advance … to produce [their products] in time,"" Brown said.\n3. Foster internal communication\nStatistics are a critical component of forecasting -- but they\'re not everything.\nDemand planning is not a compartmentalized component within the company. It\'s an integrated and detailed set of actions that connect multiple activities and push the business toward a profitable outcome, said Justin Bateh, a supply chain expert and professor at the School of Business at Florida State College at Jacksonville, in an email.\nWhile it\'s true that the algorithms offer a solid base from which other insight is drawn, gathering information from other sources helps create a true demand signal, Bateh said. Communication is key.\nThat starts with a culture of internal communication and making it an integral part of the process, Bateh said.\n""If everyone doesn\'t operate within the same mindset, then no one will enforce this notion,"" he said.\nCross-team weekly meetings, daily emails and other forms of information sharing are all important to achieving a culture of collaboration and communication, he said.\n4. Team up with customers\nMany important supply chain strategies rest on communication -- including communication with external supply chain stakeholders.\nCloser collaboration with customers, including asking them to share their ordering plans, can help an organization lower its inventory carrying costs, Brown said.\n""If you know what your customers are going to need, then you don\'t have to have as much inventory sitting on the shelf,"" she said.\nIn a B2B environment, organizations should work with their customers to understand their forecasts, she said. Organizations should consider what trends customers are monitoring, and what business direction they plan on taking.\nThis kind of collaboration is more possible in a B2B environment where an individual customer represents a much larger share of sales. In a business-to-consumer environment, companies must stay in tune with the macro trends, Brown said.\n""For example, if you\'re in food and beverage, there\'s [the healthy eating trend] and understanding some of the implications of that,"" she said.\n5. Partner with suppliers\nA list of top demand planning strategies would not be complete without discussing supplier relationships.\nSuppliers can offer valuable insights into their requirements and capabilities, such as determining short- or long-term requirements for certain products, developing forecasts and providing key information about their inventory levels and capacities, Brown said.\nCollaborating with key suppliers should definitely be one of your top demand planning strategies, said Simon Simonian, vice president of systems and technology at Argo Tea, a tea manufacturer and retailer in Chicago.\nSimonian sees the issues from both the supplier and customer perspective. His advice to all the players boils down to sharing forecasts and changes -- plans for large orders, materials shortages and so on.\nIdeally, suppliers have an information exchange in place for companies to share ordering plans and other relevant information. Companies can share this information through a phone call, email or spreadsheet, Simonian said.\n""But to make [communication] more effective, it\'s always better to rely on EDI standards,"" he said.\n6. Understand forecasting\nForecasting is an important part of demand planning and companies can tackle it in a way that meets their unique needs. To name just two examples, new technology and demand-driven strategies both affect forecasting methods. However, it can be helpful to revisit the basics.\nThe forecasting process is at the heart of demand planning and typically consists of two parts, Simonian said. The first part is the pure forecasting. That typically involves taking certain parameters, such as past sales and projected growth, and letting the system generate a forecast for a certain amount of time.\n""We have our own homegrown system that basically takes the performance of our SKUs -- the longer the better, typically -- and applies linear algorithms to come up with a 12-month forecast,"" Simonian said.\nThe second part is material resource planning (MRP), he said.\n""That\'s taking a forecast, saying, \'OK, what [materials] do you have on hand? What do you have incoming? What do you have outgoing?\' Then coming up with a recommended requisition,"" he added.\nMRP helps you create an actual action and purchasing plan based on the forecast -- that\'s critical, Simonian said.\n7. Provide demand planning training\nThe demand planning process is a complicated, multi-faceted system, Bateh said. There are several contributions made from all over the company. With so many parts working together in this cross-functional dynamic, it\'s vital that companies keep their employees well-versed and trained on the importance of their input.\n""The information they contribute helps achieve the overall outcome, and they need to be aware of how important they are in achieving this kind of success,"" Bateh said. ""Companies must take advantage of company training activities and opportunities to keep everyone afloat.""']"	['<urn:uuid:6689074f-0bc7-4104-882d-8f1cbf1b9e63>', '<urn:uuid:2f30fbb4-8808-4a15-a215-00d32bafadd9>']	open-ended	direct	concise-and-natural	distant-from-document	multi-aspect	expert	2025-05-01T22:47:46.423955	11	86	2041
47	As an environmental law expert, I'm curious about how international law addresses transboundary environmental problems and their relationship with development. What are the key principles and mechanisms established to handle these issues?	International law addresses transboundary environmental problems through several key principles and mechanisms. The Trail Smelter Case (1941) established that states cannot use their territory in ways that cause environmental harm to other states. The rule of law supports this through stable, transparent legal frameworks that protect environmental rights, enhance stewardship, ensure conservation, and promote biodiversity. Additionally, international environmental law operates through treaties, customary international law, and judicial decisions, with specific focus on procedures and incentives to secure compliance. These mechanisms are essential because environmental problems aren't contained within national boundaries and require global solutions through international regulation.	"[""STATEMENT OF THE INTERNATIONAL DEVELOPMENT LAW ORGANIZATION\nTHE RULE OF LAW, PEACE AND SECURITY, HUMAN RIGHTS AND DEVELOPMENT\nFebruary 27, 2014\nRemarks by Irene Khan, Director-General, IDLO\nCheck against delivery\nMr. Deputy Secretary General,\nExcellencies, distinguished delegates,\nLadies and gentlemen,\nAs the head of the only inter-governmental organization exclusively devoted to advancing the rule of law, and one which has both development and law in its very name, I am honored to be here with you to discuss the linkages between the rule of law and development.\n“The rule of law and development are strongly interrelated and mutually reinforcing.” Those are not my words but words from the Declaration adopted at the 2012 High Level Meeting of the General Assembly on the Rule of Law (A/RES/67/1). The Declaration, you will recall, goes on to say that “the advancement of the rule of law at the national and international levels is essential for sustained and inclusive economic growth, sustainable development, the eradication of poverty and hunger and the full realization of all human rights and fundamental freedoms, including the right to development, all of which in turn reinforce the rule of law.”\nOur purpose today is not to restate what has been already explicitly recognized by Member States, nor to tie ourselves down in a pattern of circular reasoning, but to move beyond it, to strengthen and expand our understanding of the dynamic relationship between the rule of law and development.\nThe question I would like to address is: how does the rule of law contribute to sustainable development? This question is particularly important as Member States negotiate the terms of a post-2015 sustainable development agenda. You will recall that at the 2012 High Level Meeting of the General Assembly at Member States were “convinced that this interrelationship should be considered in the post-2015 international development agenda.”\nIDLO works in countries emerging from conflict as well as those seeking to strengthen democracy and enhance their economies. No matter where in the development spectrum a country stands, it needs good laws and regulations that are fairly administered by transparent and accountable institutions and that – most importantly – produce fair outcomes for all. The rule of law is not an abstract concept but a concrete basis on which to promote sustainable development. I believe the 2012 Declaration sets out some important principles defining the rule of law that are key to understanding why and how the rule of law and sustainable development are so closely related.\nThe 2012 Declaration recognizes the importance of fair, stable and predictable legal frameworks for “inclusive, sustainable and equitable development, economic growth and employment, generating investment and facilitating entrepreneurship...” The 2012 Declaration acknowledges that “all persons, institutions and entities, public and private, including the State itself, are accountable to just, fair and equitable laws and are entitled without any discrimination to equal protection of the law.”\nThe principles of legal predictability, fairness, equal protection and accountability are not just defining features of the rule of law, they are fundamental to sustainable, inclusive and equitable development.\nStable, transparent legal regimes are critical for economic development. Unfortunately, in many developing countries the laws and institutions to protect property, ensure sustainable use of land, or attract investment and innovation are outdated or inadequate, weak, ineffective or opaque. Many developing countries lack laws and institutions on energy generation, natural resources, water management, seed and plant varieties – all of which are essential for sustainable development. Frequently developing countries do not have the knowledge or capacity to negotiate complex contracts or take advantage of the flexibility and exceptions available under international intellectual property law.\nObviously there are many linkages between national and global development issues, and between the rule of law at the national level and international frameworks for trade, investment, intellectual property, technology transfer and climate change – where fairer rules would create a more equitable, inclusive and sustainable model of development.\nUnderstanding better the relationship between the rule of law and development should help the international community and national governments to better address these legal and institutional capacity deficits that are not just barriers to economic growth but also obstacles to eradicating poverty and addressing inequalities within countries and among countries.\nFrom food insecurity to energy poverty, from unsustainable management of natural resources to lack of access to life saving drugs, the rule of law enables us to tackle the big development challenges by facilitating access to science and technology, investment and innovation through predictable, transparent and fair laws, regulations and enforcement mechanisms.\nThe rule of law supports sustainability through laws, regulations and institutions that protect and enforce environmental rights, enhance environmental stewardship, ensure conservation and promote biodiversity. When the legal frameworks ensure both the interests of business as well as communities, a unity of mission behind common development goals is assured.\nBut the rule of law does more than promote economic growth and environmental sustainability, it helps to make the development paradigm more inclusive and equitable. It helps to fight poverty and inequality, and promotes social development.\nConversely, when the rule of law is absent – when laws discriminate against women, when the state is incapable of protecting people from crime and violence, when corruption, bribery and discrimination distort access to basic services, when the law is selectively enforced in favor of the rich and well-connected, when poor people are evicted from their land with no redress - that is when poverty deepens and inequality thrives.\nLet me hasten to add that it is not enough to just adopt laws or create institutions. Laws can discriminate and exclude the poor, women, minorities or others. Institutions can be mismanaged and manipulated for the benefit of the privileged few. People whose rights are violated can be left without a remedy because the courts are too far away or litigation is too expensive. That is rule by law, not rule of law.\nThe rule of law, properly understood, provides not only certainty and predictability of the law but also substantive justice. Equality, accountability and respect for human rights – both economic, social and cultural rights as well as civil and political rights – are integral parts of the rule of law in this sense. In adopting the 2012 Declaration on the Rule of Law, the Member States reaffirmed the link between human rights and the rule of law. They also recognized “international norms and standards which are reflected in a broad diversity of national experiences” of the rule of law. Seen in this way, the rule of law provides a concrete basis on which to eradicate poverty, fight\ndiscrimination and exclusion, empower women and marginalized communities and ensure equitable, affordable and meaningful access to basic services and resources for all. Equal protection, equal access and opportunity, voice and accountability are so closely linked that as a practitioner I find it hard to separate human rights, rule of law and development.\nThe rule of law ensures, very importantly, that there is accountability and that people have access to justice, including a mechanism for resolving disputes and a remedy when rights and entitlements have been denied. Indeed, there is growing recognition that poverty is not simply lack of income, but of powerlessness. Access to justice becomes critical. Information, legal awareness, legal aid, informal and alternative mechanisms of dispute resolution enable poor people to understand their rights and claim them.\nSeen in this way, the rule of law is crucial and relevant to all three dimensions of development: economic, social and environmental. It provides for predictability and certainty through a stable, transparent legal regime, which is key to economic development. By strengthening the legal framework to protect the environment, it advances the environmental dimension of development. By ensuring the rights of communities as well as business the rule of law engenders social acceptance as well as sustainability. By ensuring equal opportunity and equitable access to basic services the rule of law enables inclusive social development, and helps to fight poverty and inequality.\nThe Rule of Law Declaration in 2012 stressed the importance of national ownership. In over 30 years of working in the rule of law sector, IDLO has learned that national ownership, supported by political will, is key to ensuring meaningful and lasting results in justice-making and legal reform. Legal pluralism is a basic principle of IDLO's work around the world.\nJust as the development challenges of each country is unique, so is the legal system. Furthermore, rules and remedies may be informed not just by the national legal system but by local, customary or informal practices. We need to be sensitive to the diversity of challenges. Let me end by summing up the three distinct ways in which the rule of law supports development:\n- Firstly, it helps to create the conditions for development by establishing the appropriate legal framework and the institutions for development.\n- Secondly, it provides transparency and equity to the development process and enhances inclusion.\n- Thirdly, it is an outcome of development - a just legal order with laws and institutions based on internationally recognized and nationally owned values and principles.\nLet me make one final point. The 2012 Declaration recognizes that just as the rule of law supports development, development in turn reinforces the rule of law. The two are inter-dependent, and this symbiotic relationship means that support for one should not be conditional on progress of the other. The reality is that in a less than perfect world, the two must proceed hand in hand if governments are to meet the aspirations and demands of their people."", 'Presentation on theme: ""INTERNATIONAL LAW AND ENVIRONMENTAL PROTECTION 1 Environmental Law.""— Presentation transcript:\nINTERNATIONAL LAW AND ENVIRONMENTAL PROTECTION 1 Environmental Law\nInternational Environmental Law 2 The Importance of International Environmental Law Regulation at international as opposed to national level Global environmental problems have global /regional /national dimensions Environmental problems not contained within national/territorial boundaries Environment is shared. Need to protect environment is paramount in relationship between States\nInternational Environmental Law 3 Transboundary and global environmental problems require international regulation and solutions International agreements /treaties /conventions establish standards International agreements have developed principles of environmental law Recent focus on procedures and incentives to secure compliance\nInternational Environmental Law 4 What is international environmental law? How is it made? What forms does it take? What is the role of international environmental law? How effective is international law in protecting the environment? How is effect given to it in the nation State? How has it developed?\nInternational Environmental Law 5 Development The Trail Smelter Case (USA v Canada) 1941 A neighbouring State has no right ‘to use or permit the use of its territory in such a manner as to cause injury by fumes in the territory of another or the properties therein.’ Serious harm and the ‘establishing of the facts through clear and convincing evidence.’\nInternational Environmental Law 6 United Nations Conference on the Conservation and Utilisation of Resources (UNCCUR) 1949 Addressed global issues ; used economic concepts to assess minerals, fuels and energy, water, forests and land, wildlife and fish; conservation; new technologies assessed; education strategies adopted; respective economic situations of developed and developing countries determined approach; integrated development of river basins policy.\nInternational Environmental Law 7 Conservation on Law of the Sea 1954 Atmosphere 1955 – issue of nuclear testing = Test Ban Treaties 1955 International Maritime Organisation first met 1954 1971 Ramsar Convention on Wetlands 1972 Stockholm Convention on Human Environment Use and Conservation Action Plan; Declaration (26 Principles) – Principle 21 * United Nations Environment Programme (UNEP)\nInternational Environmental Law 8 1987 World Commission on Environment and Development Our Common Future Brundtland Report Sustainable Development. 1992 UN Conference on Environment and Development - Rio – 176 States attended. Rio Declaration Convention on Biological Diversity Framework Convention on Climate Change Agenda 21\nInternational Environmental Law 9 Relationship with national law International law = relationship between States International law is not directly enforceable in the national legal system in the United Kingdom Treaties need to be ratified by government Need to be given effect by Parliament Treaties are required to be given effect by implementation of national legislation Only then has international law direct application\nInternational Environmental Law 10 The Sources of International Law Hard and Soft Law 1. Treaties –bind State in relations with other States 2. 2. Customary International Law Implicit; Influence; Flexible Facilitative of development of principles of International environmental law Requires State practice + conviction that legally bound\nInternational Environmental Law 11 3. Judicial Decisions – International Court of Justice Three cases heard per year Absence of binding precedent – binding inter partes Authority accepted by less than 1/3 of UN; Delay International Lawyers opinions have considerable influence on development of international law Nuclear II case New Zealand v France  ICJ Rep 288 States have responsibilities not to cause environmental damage beyond national or jurisdictional boundaries\nInternational Environmental Law 12 4.Soft Law (Advantages over binding law) Declarations Consolidate Move principles towards customary status Reflect agreed international political aspirations Principles Sustainable Development-duties to future generations Common but differentiated responsibilities (climate) Recommendations. Standards.\nInternational Environmental Law 13 Effectiveness? No Enforcement Body Limited role of Court Depends on implementation and monitoring provisions in each Treaty Institutions Procedures NGO’s Collating information Liability compensatory regimes / hazardous activities Public participation new direction?']"	['<urn:uuid:a11720dc-5c1a-4f68-833a-1d25f2c0dc1f>', '<urn:uuid:addd95ba-be2f-417d-8182-f90d8cb46c33>']	factoid	with-premise	verbose-and-natural	similar-to-document	three-doc	expert	2025-05-01T22:47:46.423955	32	97	2212
48	My doctor mentioned that both TMJ and sleep apnea can affect children - what are the main symptoms and health risks for kids with these conditions?	Children show different symptoms and face distinct health risks with TMJ disorder versus sleep apnea. With TMJ disorder, they may experience jaw pain, difficulty opening and closing the mouth, and clicking sounds when eating or talking, which can affect basic jaw functions. Sleep apnea in children presents differently than in adults - they may not show typical symptoms like snoring. When sleep apnea is left untreated in children, it can lead to slow development, abnormal growth, learning problems, heart problems, and an overall failure to thrive. Both conditions require professional diagnosis - TMJ disorder is typically diagnosed through clinical examination by a dentist, while sleep apnea may require specialized sleep studies.	['Using Botox® for TMJ disorder is a common practice that more and more dental professionals are implementing into their TMJ disorder treatment plans. Many are surprised to learn that TMJ specialists are considered dental professionals, however, they happen to correlate and there is a lot of crossover between dentistry and treating TMJ disorders.The use of…\nWhat Is a TMJ Disorder?\nDisorder of the temporomandibular joint, or TMJ, is a condition that can cause difficulty with jaw functions. The disorder can cause jaw pain that restricts how you open and close your mouth. You might notice clicking sounds or jaw locking when eating, talking or yawning. Continue reading to learn more about the symptoms, diagnosis and treatment of TMJ disorder.\nThe structure of the TMJ\nThe temporomandibular joint connects the mandible to the temporal bone of the skull. A small bit of cartilage called an articular disc is present between the two bones. When opening and closing the mouth, the disc moves as the jaw bone rotates and glides back and forth to enable movement.\nDifferent muscles connect near the temporomandibular joint. The muscles allow easy opening and closing of the jaw for talking, eating and other mouth functions. Various ligaments connect the bones to make the joint stable.\nDisorders of the TMJ\nSymptoms of TMJ disorder often start slowly without connection to specific condition or injury. Patients may experience pain when chewing hard foods. The pain is usually intermittent and often starts after exerting too much pressure on the jaw or when opening the mouth wide, like when yawning. Some of the common causes of the condition include:\n- Muscle spasms\n- Dislocation of the articular disc in the joint\n- Forward head posture\n- Teeth grinding or clenching\nWhen the jaw joint is subjected to excessive stress, pain and joint movement dysfunction may occur. This may cause inflammation of the joint and muscles around the temporomandibular joint.\nDiagnosing TMJ disorder\nAnyone experiencing pain in the jaw joint will need to visit a dental professional. The dentist will ascertain the cause of the pain and provide a diagnosis of the condition. TMD diagnosis is mostly obtained through a clinical exam. The dentist may palpate the jaw joint and muscles, checking for tenderness or clicking when opening or closing the mouth.\nThe dentist will also check the jaw’s range of motion, searching for misalignments. Sometimes, the jaw may open properly on one side and not the other, forcing the jaw to move to one part when opening the mouth. Also, an x-ray may be taken to check for arthritis around the TMJ, and an MRI may reveal the situation of the articular disc in the jaw. After making a diagnosis, the dentist can work toward developing a treatment plan for the patient.\nDepending on the patient’s condition, some of the treatment options for TMJ disorder include:\n- Stabilization splints or bite guards\n- Physical therapy\n- Dental Botox® to reduce tension in the jaw muscles\n- Cognitive-behavioral therapy to relieve stress\nIn rare cases, orthodontic treatment, arthrocentesis and joint replacement surgery might be recommended. The dentist will discuss the benefits and risks of these procedures and continue to monitor the patient during treatment.\nDo you think you may be suffering from TMJ disorder?\nSome patients with TMJ disorder get better without treatment. However, if you are experiencing symptoms of the condition, it is advisable to visit a dentist for diagnosis and treatment.\nCheck out what others are saying about our services on Yelp: Read our Yelp reviews.\nAs its name implies, sleep medicine is the study, diagnosis and treatment of sleep-related disorders in children and adults. Restful, regular sleep is crucial to a healthy lifestyle, and a lack of quality rest can have a negative impact on the body physically, mentally and emotionally. Those who do not receive adequate rest are at…\nYou have been to a sleep medicine specialist and found out you have obstructive sleep apnea. Now, you cannot help but wonder how the condition impacts your health. Sleep apnea can cause a variety of serious health conditions and even lead to premature death. Fortunately, treatment can open up your airway so that you receive…\nA relatively common type of sleep disorder, sleep apnea occurs when breathing stops and then restarts throughout the sleep cycle. As a result, major organs in the body, including the brain, receive less oxygen at varying intervals throughout the night.A person with sleep apnea may not be aware of these events while sleeping and are…', 'Dental Solutions for Sleep Disordered Breathing [Apnea]\nIf you have had complaints about your snoring, or find you’re tired and have no energy, it may be due to SDB which can lead to many serious health problems. Sleep Disordered Breathing (SDB) is a category of sleep disorders also known as Sleep Apnea, the most common form of SDB is Obstructive Sleep Apnea (OSA).\nDentists trained in Dental Sleep Medicine work with patients and their primary care physicians to diagnose and develop treatment plans that include oral appliances, therapeutic treatments and sometimes surgery. Screening for OSA is convenient. In this section, you’ll find out how you can get your energy, health and life back on track! Using this information you can find out what treatments are available and what to expect. Don’t delay, call your dentist for a consultation if you suspect you have Sleep Disordered Breathing. Studies show that Dental Solutions for SDB have an 81% success rate.\nPatients with SDB display symptoms need immediate treatment. Breathing actually stops many times during the night in patients with Apnea. Your dentist is your first line of defense against loss of health when Apnea is diagnosed because dental treatment options are successful in treating SDB. Snoring and SDB are not the same.\n95% of SDB sufferers don’t know they have it. Children and Adults can have SDB. There a several types of OSA, we’ll talk about them in these sections.\nDentists play an important role in helping patients diagnose and find treatment for this group of disorders. SDB affects millions people, some estimates put the number at over 40 million that’s 1 in 5! Find out if you have SDB.\nWhen left untreated, SDB increases the chances of serious health risks leading to reduced quality of life and long-term health problems. Your Dentist and your primary care provider can help you find the right sleep study or lab to perform diagnostic testing for SDB.\nIn this section you can find out what Apnea is, whether you have SDB, when you should seek treatment and how your Dentist can treat SDB.\nWhen health-restoring sleep is lost, the risk for these health problems increases:\n- Chronic Fatigue\n- Heart Attack\n- High Blood Pressure\n- Loss of Concentration\nChildren with Apnea do not show the same symptoms as adults, for example they may not snore like adults do. When Apnea is left untreated in children, they suffer risks that may lead to:\n- Slow Development\n- Abnormal Growth\n- Learning Problems\n- Heart Problems\n- An Overall Failure to Thrive\nTreatment options depend on the severity and causes of SDB. After diagnosis, you will consult with your Dentist to determine the best treatment for your personal health.\nIt is fairly normal for most of us to snore from time to time, especially if we are tired.\nThe rattling sound we hear in people who snore is actually caused by the vibration of tissues in your throat, such as the soft palate and uvula (the small finger-like projection hanging in the back of the throat).\nSome people, however, actually have a minor defect in their throat tissues. The defect prevents the proper amount of air from entering the windpipe. This condition is called sleep apnea. Restricted airways are caused by many things, such as an abnormally large uvula, blocked nasal passages, a poorly developed lower jaw, and in more serious cases, polyps, cysts, or a deviated septum.\nObstructive sleep apnea is a more serious form of sleep apnea. People with chronic conditions like this often suffer from restless sleep, and can develop more serious conditions such as high blood pressure, heart arrhythmias, and even congestive heart failure.\nDo You or a Loved One Snore?\nSnoring can double or even triple the risk for a stroke.\nA Yale University School of Medicine study published in the November 2005 New England Journal of Medicine reports that Sleep Apnea (sleep disturbed breathing) more than doubles the chances of a stroke or death. The Yale study found that severe cases of sleep apnea can more than triple the risk of stroke or death. This risk is reported to be independent of other cardiovascular risks.\nPeople with sleep apnea often don’t realize they have it, since they don’t remember waking up again and again, gasping for breath. Frequently, someone else hears the choking and “industrial-strength snoring,” says Klar Yaggi, a sleep specialist at Yale who led the study.\nFifty percent of middle-aged and older adults have the disorder to some degree due to throat muscles relaxing and closing off their airway as they sleep. They then wake up with a jolt, gasp for air, and fall back to sleep over and over again.\nResearch is underway to understand better the process by which the body wakes itself up to breathe. Spikes of adrenaline course through the body when breathing stops, increasing blood pressure. This is an automatic body response to repeated plunges in the level of oxygen in the blood as a result of the blocked airway.\nTreatments for sleep apnea include weight loss, the use of a breathing machine called a “Continuous Positive Airway Pressure” or “CPAP” machine, and wearing a custom-made device in the mouth to keep the airway open during sleep. The loss of weight and treatment by a doctor who treats sleep apnea can restore a good night’s sleep and eliminate considerable stress on your body from oxygen deprivation and adrenaline surges.']	['<urn:uuid:7f581806-54b9-466d-b246-786bbe261045>', '<urn:uuid:50ea748d-bca4-4d5d-9925-7aa085d0a72d>']	open-ended	with-premise	verbose-and-natural	similar-to-document	comparison	novice	2025-05-01T22:47:46.423955	26	111	1657
49	what special fluid absorbs water vapor from air in drupps system	A hygroscopic fluid, which has the special property of being able to take in water, is used in the Drupps system to absorb water from the air in its gaseous form.	['Drinking water sourced directly from the atmosphere\nClean water from thin air?\nYes, nearly. With the help of AFRY, Swedish company Drupps has developed a system that captures water vapour from the atmosphere and converts it into clean drinking water. This new technology has the potential to lessen the burden on highly strained groundwater sources around the world.\nThe shortage of clean drinking water is one of the world’s biggest public health challenges. According to the World Health Organization, WHO, within a few years half of the world’s population will be living in water-stressed areas, in other words where the supply of fresh water will be lower than the demand. Conflicts and migration flows, poorer sanitation and a higher risk of disease transmission await in the aftermath of water shortages. The atmosphere is full of water vapour, but with the technology currently available we have not succeeded in harnessing these water sources apart from via rain. This insight gave Jonas Wamstad and Fredrik Edström the idea for Drupps, a system that collects vapour from the atmosphere and condenses it into clean drinking water.\nFrom simple idea to advanced system\n“Fredrik had an idea of how you could collect and condense the vapour in the air, while I, with experience from mining projects in Burundi, had seen the enormous drinking water shortage and lack of infrastructure for water. We saw that we could mesh our knowledge together,” says Jonas Wamstad, founder and former CEO of Drupps.\nAFRY has participated in the development process from an early stage and taken Drupps from idea to product. After several tests with various materials, functions and dimensions, they arrived at a solution that can be produced on an industrial scale.\n“The process consists of air being transported through the Drupps system, where a hygroscopic fluid,\nwith the special property of being able to take in water, absorbs water that exists naturally in the air in its gaseous form. In the next step, the fluid is transported to a vaporiser, where the water is evaporated into water vapour and then separated from the fluid. Finally, the vapour is condensed into water. Throughout the process, the water is cleaned in several stages to ensure that the drinking water produced is free of pollutants,” explains André Lisspers, Product Developer at AFRY.\nEverything takes place in a circular system, where the hygroscopic fluid is reused, which decreases resource use and residual waste from the water production process. To enable a scale-up of the process, Drupps was created for use in a container with a design that allows several units to be connected to form larger systems. The container also has the advantage of being transportable on a standard cargo ship, making it easier to distribute the product. The hope is that the system will be able to produce up to 200,000 litres of water per day, provided that the relative humidity is at least 40 percent. In many low- and middleincome countries where water shortages are a major problem, these volumes could meet the daily water needs of 4,000 people.\nMinimal environmental impact with recycled energy\nOne of the foremost challenges for several of the water purification systems that have been developed in recent decades is their adverse environmental impact, which is caused by inadequate treatment of by-products and waste from the facilities. However, the process for Drupps’ water extraction is free of residues. The energy-efficient system also enables the fresh water to be produced using an energy consumption of just 0.2 kilowatts per litre, making the production process cheaper than many of the available alternatives, in which the energy consumption is usually much higher.\nThe goal is now to further develop Drupps to attain even better energy efficiency. A way of running the\nprocess on energy from waste heat from industries instead of electricity has already been found, which makes production essentially cost-free.\nWater shortage a global issue\nDrupps can do a lot of good in locations that currently lack a reliable water supply, but there are also major benefits of using the system in other areas. Water pipes and water resources are under growing strain in many cities. The issue of water has become increasingly global, and several different solutions are probably required to secure fresh water supplies in the long term. Drupps creates an alternative way of gaining access to clean water that reduces the burden on lakes and groundwater sources and retains the key ecosystem services that these provide.\n“Just like wind and solar power are important complements to total energy production, Drupps can\nfurther add to global water production as it will now be possible to produce water in locations where it was previously impossible. I believe that Drupps and atmospheric water extraction will play a key part in the water supply solutions of the future,” says Lisspers.']	['<urn:uuid:8222e341-c5f8-4dd9-a8af-143c41822d9e>']	factoid	direct	long-search-query	similar-to-document	single-doc	expert	2025-05-01T22:47:46.423955	11	31	804
50	number indigenous sites artefacts damaged destroyed warragamba dam wall raising	According to internal federal government documents, as many as 1,200 Indigenous sites and artefacts could be damaged or destroyed if the dam wall is raised.	"['The flood emergency in Sydney\'s west has raised questions about whether more could have been done to alleviate the risks.\nWarragamba Dam began to spill on Saturday, causing major flooding issues for Western Sydney suburbs like Penrith, as well as impacts downstream for Windsor, Richmond and surrounding areas where evacuations are taking place.\nIt\'s sparked renewed interest in a controversial plan to raise the wall of the dam by up to 17 metres.\nWhat is the proposal?\nWarragamba Dam is the main water supply for Greater Sydney and the NSW government wants to raise its wall by 14m, with 17m abutments at either end.\nIt would mean additional water could be held back in a large rain event, like what\'s currently happening. It would not be for storing more drinking water.\nAn environmental impact statement for the project is due this year, two years later than originally planned.\nIt was revealed in a recent NSW Parliamentary hearing that the project could cost as much as $1.6 billion.\nWould this have made any difference?\nIt depends on who you ask.\nKeep in mind that parts of Western Sydney have the highest flood risk in the state, if not the country.\nMany people say that, in hindsight, these floodplains should never have been developed.\nInfrastructure NSW\'s flood strategy states more than 130,000 people live and work on the floodplain, and that\'s expected to double over the next 30 years.\nThe Minister for Western Sydney Stuart Ayres, who\'s responsible for the dam project, said having the higher wall would have helped mitigate the impact of this flood.\n""If we had a higher dam wall now the spilling of water that you\'re currently seeing would be reduced,"" he said.\nThis is refuted by Jamie Pittock from the Australian National University, who said raising the dam wall could encourage further development on the floodplain and put more people at risk in the future.\nMr Ayres denied that any further development would be allowed.\nWhy couldn\'t the government just pre-empty the dam?\nAs it stands, Warragamba Dam is only a water-supply dam.\nUnlike the Wivenhoe and Somerset Dams in Queensland, it was never built to help mitigate floods.\nWivenhoe Dam can store an extra 2 million megalitres of water for flood mitigation, on top of 1 million for drinking water.\nStuart Khan, from the University of NSW\'s engineering faculty, said the operation of Warragamba Dam over the past few days wasn\'t a failure.\n""When we operate that dam by filling it up pretty much to the brim ... it sits about 97 to 98 per cent which is where it was going into this event,"" he told ABC Radio Sydney.\n""That\'s what we consider an optimum level of water to have in that dam in terms of drink water supply security.\n""WaterNSW are not authorised to pre-release water based on weather forecasts ... there\'s no discretion.""\nPremier Gladys Berejiklian and WaterNSW have claimed the dam would have to be emptied to 25 per cent to have held back the rain over the past few days, a statement which has been dismissed by experts.\nAre there any other measures that could be useful?\nThere are several other suggestions to help mitigate the flood risk in the Hawkesbury-Nepean Valley, but the government said raising the dam wall was the most effective option.\nThese include lowering the permanent supply level of the dam, improving road networks to enable better evacuation routes and increased education for the local community.\nEducation and road upgrades are part of the NSW government\'s flood resilience strategy, but raising the dam wall is still the key project.\nProfessor Pittock is advocating for homes that are built below the one-in-100-year flood line to be moved into safer areas. He said there was about 5,000 of them.\nIt would be a huge undertaking, but when compared to the $1.6 billion it could cost to raise the dam wall, it may not seem so far fetched.\nWhat\'s the criticism of the project?\nThe project has been plagued by criticism from environmental advocates and Gundungurra traditional owners who say they haven\'t been consulted enough.\nLast year, the ABC revealed that as many as 1,200 Indigenous sites and artefacts could be damaged or destroyed, according to internal federal government documents, if the wall is raised.\nThe criticism was scathing and ordered the state government to re-do much of its cultural heritage survey work to better include traditional owners.\nWhen the dam was first built in the 1960s, many sites were destroyed and traditional owners said they had already lost too much.\nThe extra water will also inundate bushland which is part of the Greater Blue Mountains World Heritage Area.\nLate last year, the conservation outlook for the world heritage area was downgraded in a report on the back of the Black Summer bushfires.\nThe International Union for Conservation of Nature, which authored the report, also listed the dam project as a threat to the world heritage area.\nBy Kathleen Calderwood']"	['<urn:uuid:76be338a-da2e-4db4-9039-bb38c15c7f2e>']	factoid	direct	long-search-query	similar-to-document	single-doc	expert	2025-05-01T22:47:46.423955	10	25	830
51	which private equity firm bought jegs automotive family business	Greenbriar Equity Group of Rye, New York, acquired a majority position in JEGS Automotive, which had been in family hands since 1960.	['PRI: Special Report: Private Equity In Motorsports\nOriginal Article can be viewed here.\nINVESTMENT IN THE PERFORMANCE AFTERMARKET IS ON THE RISE. BUT WHY, EXACTLY? AND WHAT DOES THIS INFUSION OF CAPITAL MEAN FOR THE INDUSTRY GOING FORWARD?\nRacers who don’t make a habit of paying attention to business media might be surprised to learn there’s a quiet financial revolution going on in the background of the motorsports industry. Many of the companies and brands that racers grew up with, including legendary brands that originated in modest garages and still carry the founder’s name on the box, have been acquired by private equity firms and often combined with other companies to form “super brands” that control large sections of the market.\nThese iconic racing brands are still out there producing quality parts, but they are no longer the independent mavericks of popular lore. What does this shift in ownership mean for the motorsports industry at large?\nThis private equity interest is not entirely new, but in the last couple of years the pace has accelerated. In February of this year, New York City-based MidOcean Partners acquired timing drive manufacturer Cloyes from private equity firm Hidden Harbor Capital Partners, which has held Cloyes since 2018. Taglich Private Equity, another New York City firm, acquired Air Flow Research and SCAT Enterprises in 2021.\nIndustrial Opportunity Partners (IOP), based in Evanston, Illinois, invests in middle-market companies in North America, which are defined as companies with between $50 million and $500 million in revenue. It added COMP Cams to its portfolio in early 2020. IOP folded the COMP companies into the Edelbrock Group, forming a larger entity that includes performance brands such as Russell, TCI Automotive, FAST, and RHS.\nMiddleGround Capital (MGC), with offices in Lexington, Kentucky, and New York, New York, targets lower middle-market companies. It currently owns 11 companies, including Race Winning Brands, which it acquired in late 2021. Race Winning Brands includes heavy hitters such as Dart Machinery, Wiseco, Manley, and JE Pistons.\nGreenbriar Equity Group of Rye, New York, announced in February that it had acquired a majority position in Ohio-based JEGS Automotive, which had been in family hands since 1960. All told, these five private equity firms alone own outright or majority control of nearly 30 aftermarket performance companies.\nSome might find it surprising that relatively small brands that appeal primarily to gearheads, with advertising more commonly limited to sponsorship stickers on race cars than national TV ads, would appeal to the centers of high finance. But from other perspectives, it’s not that surprising at all.\n“It was only a matter of time before private equity noticed the motorsports industry,” said Daniel Ingber, PRI’s Vice President of Government and Legal Affairs. “PRI Members are some of the most innovative and entrepreneurial businesses in the world and know their products and their customers extremely well. Most of our Members are small businesses that are attractive to private equity.”\nHart Marx Advisors in San Rafael, California, specializes in mergers, acquisitions, divestitures, and succession plans in the automotive and heavy-duty trucking industries. It has seen firsthand the factors that make motorsports companies attractive investments for private equity.\n“The brands tend to develop really strong followings, so it’s a good base for an investor to be able to grow from,” said Chris Bovis of Hart Marx Advisors. “If you have a good company, making pistons, valves, whatever, and you have a whole contingent of engine builders who swear by your products and have been using them for 30 years, that trust in the quality of that brand has been built up. That’s a tremendous platform to grow from. It makes it very difficult to break in, so it does provide a bit of a barrier to entry.”\nThose hard-earned reputations established at the race track do tend to attract notice far beyond the paddock. “That equity in the company, the brand, it’s hard to define and it’s probably impossible to value,” Bovis said. “But it’s extremely hard to create. It’s something that happens over time. If you’re a valve spring company that’s been building quality products for 30 or 40 years, and you’ve developed that following, a private equity firm would look very kindly on that and see that as very attractive. No private equity has the time or interest in investing 40 years to build that up themselves.”\nBeyond the brand equity, the appeal of performance parts manufacturers makes sense from a nuts-and-bolts financial perspective. “The performance automotive and powersports aftermarket segment has been an attractive asset class to private equity for several reasons,” said Mike Bridge of MiddleGround Capital. “First, there is sustainable end market growth, with the automotive performance segment growing at a historical compound annual growth rate of 2–3% and the powersports segment growing at 4–7%, which we anticipate continuing for the foreseeable future. Second, these companies often boast strong financial profiles with high margins, limited capital expenditures, and high free cash flow. Third, consumers still tend to pursue their hobbies and passions, even in a recessionary environment. Furthermore, customer relationships tend to be very sticky, as consumers stay loyal to quality brands. Fourth, this is a highly fragmented market comprised of companies that are typically founder owned, providing a robust acquisition pipeline of businesses that can benefit from operational best practices and additional capital to fuel growth.”\nThere are other factors that make performance products manufacturers attractive to private equity that are not readily apparent to the fan in the stands. “Given the plethora of deals in the industry for lower- and middle-market companies, I believe that private equity firms are seeing a nice diversity to perhaps a portfolio they may already be holding in transportation, that the performance aftermarket brings to establishing a balance,” said Phil Fioravante, Operating Principal with Industrial Opportunity Partners, owners of the Edelbrock Group. Although it’s not a strategy that IOP currently employs, Fioravante said, equity investors may have investments in Tier 1 OEMs, heavy trucking, or powersports companies, with motorsports companies attractive as final pieces of the transportation puzzle.\n“I truly believe, in terms of a balanced pie chart, if you will, that the performance aftermarket is becoming increasingly something on peoples’ radar screens to balance out the cyclical nature of the other three,” he said.\nAlthough these transactions for motorsports brands usually boil down to the money that can be made, that’s not always the primary motivator when a company allows itself to be sold. “The decisions that we see from the companies that we deal with tend to be very personal,” said Bovis with Hart Marx Advisors. “They tend to be family oriented—what’s in the best interest of the family?\n“Probably the most common reason for owner-founder businesses, which is primarily what we deal with, is they oftentimes don’t have a next generation to pass the business to, or the next generation is a firefighter, a lawyer, they’ve found their own path and haven’t really had the interest in the family business,” Bovis continued. “It starts to become an economic question of not just what’s best for the family, but also what’s best for the business. In a lot of cases, they’ve invested 40 or 50 years of their life into these companies, in developing the brand that’s so tied to who they are personally, that just closing down is unthinkable from an emotional perspective. It’s unthinkable from the perspective of what it would mean to their employees. They want to create a home and a future for their employees that have given so much to the business. It’s a blend of emotion and rational financial planning.\n“I would say the trend we’re seeing is that fewer and fewer members of that next generation are interested in carrying on the business. That tends to be rarer than I think it has been in the past,” Bovis added.\nIs this consolidation of brands good for the motorsports industry? History teaches that, in a general sense, a reduction of true competition usually doesn’t work to the benefit of the end customer. Employees are sometimes shed to deal with “redundancies” as companies are merged together. Relocations can transform communities. And if the last couple of years has taught the world anything, it is that larger corporations will often feel pressured to enforce government dictates whether they are good for an industry or not.\nBut there are obvious upsides, too. Private equity investment in a business that is treading water means access to capital for expansion, modernizing equipment, and breaking into new markets, plus expertise for navigating the digital age and avoiding legal minefields.\n“My experience, in my career, it was quite good for the company,” Bovis said. “I worked for a company that was struggling until it was purchased by private equity. They put in a lot of resources. They have expertise that we were able to take advantage of to grow the business, and the company is on very strong footing now. The brand is back, and the products are back, and everything has worked out very well. So I’m very biased toward seeing that side of things because that’s been my experience. I see a lot of companies and brands that couldn’t have negotiated and managed their way through their growth quite as well.”\nA big-picture view from private equity can also lead to improvements on the shop floor. “MGC is unique when it comes to how we support the employees of all our businesses,” Bridge said. “First and foremost, we bring first-hand experience to our approach on safety and the physical working conditions in all our investments. We expect facilities to be clean, bright, and free of un-protected critical safety risks. Second, we desire for all our employees to earn a livable wage, which is why last year all our portfolio companies enacted a minimum pay rate of $15 per hour. Although most of the employees across our portfolio make much more, we saw this as a good starting point. By 2025, we seek to increase our minimum pay rate to $25 per hour. We feel this will allow us to attract and retain top talent.\n“Our motto is to ‘leave everything better than we found it.’ We are not perfect, but we are proud that we are not a firm that makes money on the backs of others,” Bridge said.\nCombining companies with distinct cultures into a larger organization is a challenge all private equity firms face, but most have experience in that aspect of operations. “Typically, our perspective and approach is the development of an operating plan or an operating thesis upon initial investment,” IOP’s Fioravante said. “In this case we knew how Edelbrock was performing and performing well. We know that COMP Cams is performing and performing well. We were looking at one plus one is three. By instituting the IOP operating thesis that we reviewed with Edelbrock, and we reviewed with the new team at COMP, we started working through synergies that I call ‘people, process, and products.’\n“From the people perspective, with the merging of two organizations, do we end up having some redundancies? Then we sort that out, and some of it happens through attrition. There were no forced layoffs. It was happening over time; it’s been almost two years. There are a lot of great technology leaders on both sides. We brought in some new thinkers from outside the two companies, and it has been a great addition to our product management and our engineering team. Most of the leadership today at Edelbrock Group is primarily COMP Cams folks. At the senior level, the CEO is from outside of the industry, the CFO is from outside of the industry, the chief commercial officer, Chris Douglas, has the largest portion of our organization. Our chief operating officer role, that will be a new role for us here in the coming weeks. From a synergistic operating thesis plan, everybody gets together, and we try to figure out what we can gain by doing this, what can we gain by doing that.”\nDON’T LOSE THE SPIRIT\nThe motorsports world is full of stories about entrepreneurial racers who started building parts out of modest shops and garages, creating their future empires through word of mouth, one sale at a time. Preserving that independent spirit is a crucial part of maintaining a brand’s reputation. “Private equity has upsides and downsides for the industry,” PRI’s Ingber said. “It can help some companies reach their full potential, but when private equity companies ignore the judgment and expertise of the individuals who built the company, who know the product, who know their customer and are passionate about motorsports, it can change a company, brand, or product in bad ways.”\nThe people we spoke with seemed aware of that potential danger and appear to be taking a hands-off approach to how to best meet the needs of the racer. “We partner with the management team and employees. Our role is to make sure the team has the resources needed to execute their vision and strategy,” MiddleGround Capital’s Bridge said. “The Race Winning Brands management team has deep roots in the industry with some brilliant minds leading engineering and R&D. The goal of our operations team is to give the management team incremental resources to execute on discrete initiatives to free up their time to continue doing what has made this company great.”\nThe infusion of capital can lead to an increase in new parts on the shelves as companies gain resources. “From a products perspective, we’ve been developing some really cool new products like black chrome intake manifolds and carburetors,” Fioravante said. “We launched a whole lifter assembly at the PRI Show that’s getting rave reviews. So we saw a lot of synergies and we’re continuing to work through the branding.”\n“There are different sizes and phases of businesses that require different resources and skills and different capabilities,” Bovis explained. “There’s the financial side of things. The financial resources necessary to buy the inventory, to fund the marketing, to grow a national footprint in terms of sales or dealers, that takes time and money. In a lot of cases, private equity has access to those resources, be it direct investment or however they want to structure it. But they bring that next level of financial sophistication and financial resources. They tend not to be experts in any one particular field, but they tend to be experts in growing businesses and helping fund and manage through the challenges of growth and adding staff and adding resources. As businesses grow from family-owned or generational businesses to first level of professional investment, they do tend to get a little bit of sophistication on managing through the challenges of that growth.”\nThere’s more at stake than just funding new products. Private equity conglomerates have the ability to shepherd performance brands into entirely new financial realms. Holley Performance Products, controlled by Sentinel Capital Partners, in 2021 merged with Empower Ltd. for the purpose of becoming a publicly traded company. With private equity backing, Holley is now listed on the New York Stock Exchange (HLLY).\nPrivate equity interest in the performance aftermarket appears to be here to stay, at least for the foreseeable future. “Certainly, there will be more and more competition for fewer and fewer really good companies and brands. There’s been a lot of consolidation among maybe three or four major players,” Bovis said. “To the extent that there are good companies and good brands and good market niches to pursue, then yeah, it will continue.\n“This is highly speculative, out on a ledge a little bit, but where I think there is probably more to be gained is these adjacent markets. Much like SEMA and PRI saw a connection between their core audiences, you see some of the big private equity conglomerates start to see a crossover between the SEMA and PRI crowds and the powersports markets—ATV, UTV, motorcycle, maybe to a lesser extent personal watercraft and some of those things. You’ll start to see them pick up and have increased interest in some of these adjacent markets that still have the core attributes of an emotionally connected enthusiast buyer, a true outlet for the end-user, the passionate hobbyist, premium products with good margins and good performing businesses. I think you’ll start to see more of a reach out to these adjacent markets,” he added.\nAlthough many top names in the performance aftermarket have been snatched up by private equity investors, the industry is constantly evolving and creating opportunities for the next generation. “There’s an emotional side, where you wish the products were still being built out of somebody’s garage, that romantic, entrepreneurial side of things. You wish that was still around in some of these companies, but it’s around in different companies. There are still companies being built today out of peoples’ garages and basements. We just haven’t seen them grow to national status yet. They’re in the process of doing that,” Bovis said.\n“There are some things in my life that I don’t even know who we’re buying a product from,” he added. “Half the time I forget who my cell phone provider is. It’s just an anonymous company that I only know about when something goes sideways. But I know everything that’s in my race car. I know every part we buy, I know the company, I know who we buy it from. It’s such an unusual market and industry in that regard. You’re so close to the customer. I couldn’t imagine anything better for a private equity group.”']	['<urn:uuid:7608b981-d4a5-4331-9d4f-25c1d0a974a7>']	factoid	direct	long-search-query	distant-from-document	single-doc	expert	2025-05-01T22:47:46.423955	9	22	2927
52	safety rules near sparks welder	According to OSHA standards, when performing hot work such as welding, you must follow these basic fire prevention precautions: perform the work in a safe location with fire hazards removed or covered, and use guards to confine heat, sparks, and slag to protect fire hazards that cannot be moved. Additionally, no hot work should be done where flammable vapors or combustible materials exist, and both the work and equipment should be placed outside hazardous areas.	"['Steering Clear of the Fire and Shock Hazards\nHot work should not be done where flammable vapors or combustible materials exist. Both the work and the equipment being used by the welder should be placed outside any hazardous area.\n- By Jerry Laws\n- Apr 01, 2018\nFires, burns, electric shock, and exposure to welding fume and gases are some of the leading hazards to which welders may be exposed. The protections they require are spelled out in OSHA’s 29 CFR 1910.252, the welding, cutting, and brazing standard; its section (b)(2) specifies eye protection that must be provided.\nThe standard refers to OSHA\'s 1910.133, which contains charts listing the minimal shade numbers needed for protecting welders\' vision and says welders\' lenses must comply with the ANSI/ISEA Z87.1-2015 standard, the American National Standard for Occupational and Educational Personal Eye and Face Protection Devices.\nHot work such as welding, cutting, and grinding can expose workers to the risk of fires when flammable or combustible materials nearby are ignited. OSHA points out that the basic precautions for fire prevention when performing hot work are:\n- Perform hot work in a safe location or with the fire hazards removed or covered.\n- Use guards to confine the heat, sparks, and slag and to protect fire hazards that cannot be moved.\nIn short, hot work should not be done where flammable vapors or combustible materials exist, and both the work and the equipment being used by the welder(s) should be placed outside any hazardous area, according to OSHA. The 1910.252 standard says personnel should act as a fire watch while hot work is being done in locations where:\n- appreciable combustible material—building construction or contents—is closer than 35 feet from the work\n- appreciable combustible material is more than 35 feet away but is easily ignited by sparks\n- wall or floor openings within a 35-foot radius will expose combustible materaisl in adjacent areas, including concealed locations in walls or floors\n- combustible materials are adjacent to the opposite side of metal partitions, walls, ceilings, or roofs and are likely to be ignited\nThe standard also says fire watch personnel must:\n- have fire extinguishing equipment readily available and have been trained on its use\n- know how to sound an alarm in case of a fire\n- watch for fires in all exposed areas, but try to extinguish them only when they are “obviously” within the capacity of the extinguishing equipment that is available; if not, they should sound the alarm\n- maintain the fire watch for at least 30 minutes after welding or cutting is completed, in order to detect and extinguish possible smoldering fires\nThe most common types of injuries sustained by welders are burns and eye injuries. The right PPE for them—protective apparel, gloves, welding helmets, respiratory protection—is addressed in both 1910.252(b)(3) and by 1910.132, OSHA\'s general PPE standard. It calls for employers to perform a hazard assessment, before PPE is selected and worker training commences. Once trained, workers should understand what PPE is needed and when, its limitations, and proper care and maintenance of their PPE.\nAdequate ventilation and local exhaust are required in welding areas to keep the fumes and gases away from the welder’s breathing zone and the general area. Employers should provide a ventilation system, such as fume extractors and exhaust hoods, that will remove fumes and gases from the work area.\nMost welding equipment has a voltage that presents a risk of electric shock. An accident report still available on OSHA’s website describes one fatality in 2005, an electrocution of an employee who was welding trailer gates:\n""He was welding using a Wire Feed, Arc Welding Machine. Employee #2 was in the room, but did not observe what happened. He stated he heard Employee #1 cry out. When he turned around, Employee #1 was on the floor. Other coworkers ran to see what happened and two coworkers started administering CPR. Emergency services arrived, took over CPR, and transported Employee #1 to the hospital, where he later died. An investigation into the incident found that the welding machine was in the \'on\' position, and that the 50 Amp electrical breaker, which served the circuit to the welding machine, had been tripped. It was noted that Employee #1 did not have his welding hood on. He did have his work gloves on, but the welding gun was not in his hand. The OSHA investigation revealed that the electrical conductors (2 hot and 1 neutral), inside of the male attachment plug for the welding machine, were not securely connected to their terminal points. The visible evidence of burns inside of the attachment plug and the melting of the individual strands of the neutral conductor indicated that the neutral conductor came out of its terminal point inside of the attachment plug and it made contact with a hot (energized) wire that was also inside of the attachment plug. This contact allowed current to flow through the neutral conductor and back down to the equipment grounding attachment location, which was on the metal frame inside of the welding machine. The frame of the welding machine became energized and so did any metal parts of the welding machine that were in contact with the metal frame. The welding machine was sitting on the floor next to a tin wall, when the incident occurred. There were two electrical burn marks on the tin wall, which matched up perfectly with two electrical burn marks that were on the side of the welding machine which was facing towards the tin wall. It was believed that Employee #1 made contact with the energized welding machine and he received an initial electrical shock. He either fell against the welding machine, causing it to hit the tin wall or both Employee #1 and the welding machine hit the tin wall. When the energized welding machine made contact with the tin wall, an electrical short circuit would have been created that would be sufficient to cause the fifty (50) Amp circuit breaker to trip out.""\nThe OSHA page titled ""Controlling Electrical Hazards"" (https://www.osha.gov/Publications/3075.html) is a good resource for understanding the causes of electric shock and how to protect workers from electrical hazards through equipment de-energization, PPE, training, and work practices.\nThis article originally appeared in the April 2018 issue of Occupational Health & Safety.']"	['<urn:uuid:6401007a-81fb-49e9-b16f-a22bd44579cf>']	open-ended	with-premise	short-search-query	distant-from-document	single-doc	novice	2025-05-01T22:47:46.423955	5	75	1055
53	How do sensing capabilities differ between pacemakers and superconducting magnetic devices?	Pacemakers have sensing capabilities to recognize and respond to the heart's electrical activity, while superconducting magnetic devices can sense and separate different types of materials based on their magnetic properties - with most organisms being diamagnetic, few paramagnetic, and very few strongly magnetic.	"['Since superconducting ceramics have many excellent characteristics, such as complete conductivity and complete diamagnetism, the successful development and practical use of high-temperature superconducting materials will have an impact on the production of human society and the understanding of the structure of matter significant impact.It may bring about revolutions in many disciplines. Therefore, countries all over the world have invested a lot of manpower and material resources in research.\nThe application of high-temperature superconducting ceramics has the following aspects.\n1. In terms of power system\n(1) Transmission and distribution\nAccording to the zero-resistance characteristics of superconducting ceramics, extremely large currents and power can be transmitted over long distances without loss. And now the dielectric loss of cables and transformers often accounts for 20% of the transmitted power.\n(2) Superconducting coil\nIt can be made into a superconducting energy storage coil. The energy storage device made of it can store energy without loss for a long time, and directly store electromagnetic energy without energy conversion. The impact load of the power transmission system can be tracked and adjusted, and the peak The load is leveled.\n(3) Superconducting generator\nSince the resistance of superconducting ceramics is zero, the current density can reach (7~10)x10^5A/c㎡, and there is no need for an iron core, so there is no heat loss, and large-capacity, high-efficiency superconducting generators and magnets can be manufactured. Fluid generators, rotating electric machines, etc.\n2. In terms of transportation\n(1) Manufacturing superconducting maglev train\nDue to the strong diamagnetism of superconducting ceramics, the maglev train has no wheels and ""floats"" on the rails by magnetic force. It has high speed, stable operation, safety and reliability.\n(2) Superconducting magnetic thruster and space propulsion system\nFor example, ship electromagnetic propulsion device. The propulsion principle is: install a superconducting magnet inside the hull to generate a strong magnetic field in the sea water. At the same time, an electrode is placed on the side of the hull to generate a strong current in the seawater. In the seawater behind the stern, the magnetic lines of force interact with the current, and the seawater produces a strong driving force behind the hull.\n3. In terms of mineral processing and prospecting\nIn terms of mining and metallurgy, since all materials are diamagnetic or paramagnetic, superconductors can be used for mineral processing and prospecting.\n4. In terms of environmental protection and medicine\nIn terms of environmental protection, superconductors can be used to purify wastewater discharged from paper mills and petrochemical plants.\nIn terms of medicine and health, most organisms are diamagnetic, a few are paramagnetic, and a very few are strong magnetic. Superconductors can be used for wastewater treatment to remove bacteria, viruses, heavy metals and other poisons. In medicine, magnetic separation can be used to separate red blood cells from plasma. In addition, because certain bacteria, such as Staphylococcus albicans and cancer cells, are inhibited from growing in a strong magnetic field, it is being studied to heat the lesion with a low-frequency alternating strong magnetic field with drugs, which will kill the cancer cells.\n5. In terms of high-energy nuclear experiments and thermonuclear fusion\nThe superconductor\'s strong magnetic field is used to accelerate the particles to obtain high-energy particles, and the superconductor is used to manufacture instruments for detecting particle motion tracks.\nNuclear fusion is a new technology for obtaining huge energy. However, the controlled thermonuclear reaction must have the following conditions: ①Deuterium and tritium must be heated to 3x(10^7~10^8)K; ②Satisfy the Lawson criterion-the product of plasma density n and energy confinement time τ is greater than 10^ 14S/c㎡, this requires a large magnetic field with a volume of several 10m3 and a magnetization strength of 1x10^8A/m to confine the high-temperature deuterium and tritium plasma in a small space. Conductive magnet. The Lawrence Livermore Laboratory of the University of California, USA, has built a 600t large-scale NbTi magnetic mirror nuclear fusion experimental device MFTF, which has an energy storage of about 3000MJ.\n6. In electronic engineering\n(1) Use the Josephson effect of superconductors to increase the operating speed and reduce the size of electronic computers. The switching time of the Josephson tunnel junction is 10^(-12)s, the heat generated during ultra-high-speed switching is only 10^(-6)W, the power consumption is very small, and its operation speed is 50 times faster than that of silicon transistors. The heat is only 1/1000 or less. It is an important content of high-temperature superconducting ceramic application research to make it highly integrated and develop ultra-small and ultra-high-performance computers.\n(2) Devices made of superconductors, such as superconducting diodes, superconducting quantum interference devices, superconducting junction transistors, superconducting field effect transistors, superconducting magnetic flux sub-devices, etc.\nOf course, the application of high-temperature superconducting ceramics is far more than the above. With the research and development and practical use of high-temperature superconductors, its application range will continue to expand, and a new industrial revolution will appear at that time.', ""You just clicked a link to go to another website. If you continue, you will leave this site and go to a site run by someone else.\nIt is possible that some of the products on the other site not be licensed for sale in Canada.\nYour browser is out of date\nWith an updated browser, you will have a better Medtronic website experience. Update my browser now.\nBy choosing to accept, you acknowledge that you are a Certified Healthcare Professional.\nGradient Magnetic Field Used to select the location and orientation of the image plane or slice through the patients anatomy. Three independent gradient magnetic fields are active during MRI set-up (pre-scan) and image acquisition. When active, the gradient fields are pulsed on and off at a rapid rate, typically hundreds or thousands of times per second.\nMR-Conditional Under specific conditions of use, safe in the MR environment.\nMR Safe Presents no known hazards resulting from exposure to any MRI environment.\nMR Unsafe Presents unacceptable risks in the MR environment.\nPulsed Radio Frequency (RF) Field Changes the energy state of protons and elicits magnetic resonance signals from tissue. Frequencies used in the millions of cycles per second (MHz).\nRadiopaque Refers to the relative opaque white appearance which makes a device visible using standard x-ray techniques.\nSpecific Absorption Rate (SAR) Measure of the absorption of electromagnetic energy in the body, measured in units of watts per kilogram (W/kg).\nB1+RMS The time-averaged RF magnetic field component relevant for creating an MR image that is generated by the scanner during a scan and is measured in units of micro-Tesla (µT).\nStatic Magnetic Field Magnetic field created by the large magnet in MRI and used to align protons. Always present, even when scanner is not imaging. The magnetic force of attraction for a 1.5 tesla (T) MRI system is approximately 30,000 times stronger than the earth's magnetic field.\nTesla Unit of measurement (T) to determine the strength of a magnet, equal to 10,000 gauss (G). The earth's magnetic field varies between 0.3 and 0.7 G.\nCapture Initiation of depolarization of the atria and/or ventricles by an electrical stimulus delivered by an artificial pacemaker or implantable cardioverter defibrillator.\nCardiac Resynchronization Therapy-Defibrillator (CRT-D) An implantable cardioverter defibrillator (ICD) with cardiac resynchronization pacing therapies. The device terminates an erratic, life-threatening cardiac arrhythmia by delivering a high-energy, direct current electrical stimulus to cardiac tissue. In addition, it provides resynchronization pacing therapies to both ventricles of the heart.\nCardiac Resynchronization Therapy-Pacemaker (CRT-P) A device that sends small electrical impulses to both lower chambers of the heart to resynchronize the ventricles.\nImplantable Cardioverter Defibrillator (ICD) Device that terminates an erratic, life-threatening cardiac arrhythmia by delivering a high-energy, direct current, electrical stimulus to cardiac tissue. An ICD is usually implanted in the upper chest or abdominal area.\nLead (or electrode, catheter) Thin, insulated cable that conducts energy and carries electrical signals to and from the heart.\nPacemaker/Implantable Pulse Generator (IPG) Device that provides timed electrical stimuli to the heart to restore the heartbeat to a more normal rate, thereby relieving symptoms of bradycardia. A pacemaker system includes the pulse generator and the lead(s). Pacemakers are usually implanted in the pectoral region.\nProgrammer A small computer used in a clinicians office to make changes in the operations of an implanted device. The programmer magnet is often placed over the pacemaker to collect information stored in the pacemaker. Note: Programmers are not labeled for use in the MRI environment. Programming is performed away from the MRI scanner.\nSensing The ability of a pacemaker or ICD to recognize and respond to the electrical activity of the heart.\nSlew Rate The rate of change over time of the magnetic fields that make up the gradient fields.\nThreshold (or stimulation threshold) The minimum electrical stimulus needed to consistently elicit a cardiac depolarization. It is expressed in terms of amplitude (volts, milliamps) and pulse width (milliseconds), or energy (microjoules).""]"	['<urn:uuid:42bff865-8460-400a-b2df-52b557f8f2d8>', '<urn:uuid:4df47258-3bc3-4e13-92e3-38b5dd436519>']	factoid	with-premise	concise-and-natural	similar-to-document	multi-aspect	expert	2025-05-01T22:47:46.423955	11	43	1464
55	how much percentage entertainment agents charge from performer earnings	Agents take 10% of your fee.	"['As an actor, being represented by a talent agency means that an outside entity has a vested interest in advancing your acting career. It is a win-win situation for both. An acting education and talent are the basic components agencies look for, but to be signed by an agency you also need to understand the business of ""the business,"" be equipped with the right materials, and be prepared to compete for coveted agency spots. The more prepared you are as an actor, the better the impression you will make on an agent and his agency, and the sooner you may be signed as a working actor.\nGet a degree or training from a respected theatre college or local acting school. If neither is available, find any acting training that is available in your area. Contact your community college for a catalogue of acting classes. Join a local theatre group. Volunteer for any acting position available. Agents insist on seeing past and continuous training for any actor in which they express interest.\nEducate yourself on the different agency types. Agencies who cover acting talent for film, television and theatre are known as ""across the board"" agencies. Agents in these agencies specialize. You will rarely have the same agent for television that you have for theatre. It is important to know which facet of the industry you want representation in, and to focus your attention on that area. Never respond to an agent who asks: ""What do you do best?"" by replying, ""I can do everything."" Know your own talent and be specific.\nGo to a photographer located in the market in which you want to work, and one who is experienced in taking headshots. Agents look at a headshot for five seconds before making a decision to look at the resume on the back. If you are looking for a commercial or a television agent, take a headshot that shows good teeth and a dazzling smile. Attracting a film agent means showing a face with depth of character. Projecting a story in a headshot will grab the attention of a “legit” (theatrical) agent.\nBuild your resume with concise and honest information. Be sure it has all your necessary contact information. Include any “extra” work you have done, but not more than five appearances. Education is vital, and continuing education is a must. Special skills are especially helpful to television agents. If you ride a horse, that may be the skill that will get you an audition for a western-themed commercial or television pilot. Be sure the resume is the same size as the headshot and is stapled to the headshot in all four corners.\nKnow your industry. Stay informed by reading “Backstage” (either East or West) and the “Ross Reports,"" which give auditioning advice and updates on who’s who in the agency business. Agents move agencies frequently and these industry publications will help keep you up-to-date. They also list casting calls.\nTake your acting jobs seriously. Every acting job is another addition to your resume and an education as well. Offer your services to a local company for their advertising campaign. Maybe you won’t get paid, but it gives you training to list on your resume. Invite local agents to watch your performances and follow up with a hand-written note of thanks if they do attend.\nMake a DVD of your acting appearances. Keep it short – three minutes in total. Send it to agents with a short cover letter and a headshot/resume. Do not call for follow up. Keep sending headshots every six weeks with updates on your career, or invitations to showcases.\nThere is no specific formula for attracting an agent. The majority of the work is done by you. Narrow your targeted list of agents to the discipline that is your strongest. Work that list weekly.\nGet in front of agents. Perform in showcases and local theatre.\nHeadshots are vital. Use a photographer who knows the medium of taking headshots. Your face is what is important. Do not put your fingers on your face, or your hand under your chin. Do not stretch your arm over your head. Armpits are not attractive. Do not wear a turtleneck sweater in any of the above as it hides your neck and the look goes directly from your chin to your chest. An expansive look is what will attract an agent\'s eye and encourage him to flip the headshot over to the resume and become more acquainted with you as an actor.\nNever pay a fee to an agent for his representation. He gets paid when you work.\nAgents take 10% of your fee. A talent manager can attach whatever percentage you agree to. Be aware that if you have a talent manager and an agent, you are giving up a large percentage of your income. Choose one or the other until you are so successful you need someone managing your career. Then you can name your own percentage.\nIf an agent asks to “freelance” with you for a certain period of time, do it. This is your “dating period” and your opportunity to land jobs that will encourage him to “engage” you.\nWhen interviewing an agent, ask how many others “like you” are on his books. If the competition is deep, find another agent. You don’t want to be a small fish in a big sea.\nDon’t set your sights on the large agencies. They get their talent from the smaller agencies. Go small for the greater chance of success.']"	['<urn:uuid:1b1758ab-644b-4526-bc8f-8727e89788e7>']	factoid	direct	long-search-query	distant-from-document	single-doc	novice	2025-05-01T22:47:46.423955	9	6	920
59	color space conversion between rgb cmyk differences printing monitor display	Color space conversion between RGB and CMYK involves translating colors from one basis to another. RGB is used for monitors and uses additive color mixing with red, green, and blue light to create colors. CMYK is used in printing and uses subtractive color mixing with cyan, magenta, yellow, and black inks on a white substrate. Converting between these spaces can result in color changes since CMYK has a smaller color gamut than RGB, causing bright screen colors to appear duller when printed.	"['This article needs additional citations for verification. (September 2007) (Learn how and when to remove this template message)\nA color space is a specific organization of colors. In combination with physical device profiling, it allows for reproducible representations of color, in both analog and digital representations. A color space may be arbitrary, with particular colors assigned to a set of physical color swatches and corresponding assigned names or numbers such as with the Pantone collection, or structured mathematically, as with NCS System, Adobe RGB or sRGB. A color model is an abstract mathematical model describing the way colors can be represented as tuples of numbers (e.g. triples in RGB or quadruples in CMYK); however, a color model with no associated mapping function to an absolute color space is a more or less arbitrary color system with no connection to any globally understood system of color interpretation. Adding a specific mapping function between a color model and a reference color space establishes within the reference color space a definite ""footprint"", known as a gamut, and for a given color model this defines a color space. For example, Adobe RGB and sRGB are two different absolute color spaces, both based on the RGB color model. When defining a color space, the usual reference standard is the CIELAB or CIEXYZ color spaces, which were specifically designed to encompass all colors the average human can see.\nSince ""color space"" identifies a particular combination of the color model and the mapping function, the word is often used informally to identify a color model. However, even though identifying a color space automatically identifies the associated color model, such a usage is incorrect in a strict sense. For example, although several specific color spaces are based on the RGB color model, there is no such thing as the singular RGB color space.\nIn 1802, Thomas Young postulated the existence of three types of photoreceptors (now known as cone cells) in the eye, each of which was sensitive to a particular range of visible light. Hermann von Helmholtz developed the Young–Helmholtz theory further in 1850: that the three types of cone photoreceptors could be classified as short-preferring (blue), middle-preferring (green), and long-preferring (red), according to their response to the wavelengths of light striking the retina. The relative strengths of the signals detected by the three types of cones are interpreted by the brain as a visible color. But it\'s not clear that they thought of colours as being points in color space.\nThe color-space concept was likely due to Hermann Grassmann, who developed it in two stages. First, he developed the idea of vector space, which allowed the algebraic representation of geometric concepts in -dimensional space. Fearnley-Sander (1979) describes Grassmann\'s foundation of linear algebra as follows:\n|“||The definition of a linear space (vector space)... became widely known around 1920, when Hermann Weyl and others published formal definitions. In fact, such a definition had been given thirty years previously by Peano, who was thoroughly acquainted with Grassmann\'s mathematical work. Grassmann did not put down a formal definition --- the language was not available --- but there is no doubt that he had the concept.||”|\n|“||As noted first by Grassmann... the light set has the structure of a cone in the infinite-dimensional linear space. As a result, a quotient set (with respect to metamerism) of the light cone inherits the conical structure, which allows color to be represented as a convex cone in the 3- D linear space, which is referred to as the color cone.||”|\nColors can be created in printing with color spaces based on the CMYK color model, using the subtractive primary colors of pigment (cyan (C), magenta (M), yellow (Y), and black (K)). To create a three-dimensional representation of a given color space, we can assign the amount of magenta color to the representation\'s X axis, the amount of cyan to its Y axis, and the amount of yellow to its Z axis. The resulting 3-D space provides a unique position for every possible color that can be created by combining those three pigments.\nColors can be created on computer monitors with color spaces based on the RGB color model, using the additive primary colors (red, green, and blue). A three-dimensional representation would assign each of the three colors to the X, Y, and Z axes. Note that colors generated on given monitor will be limited by the reproduction medium, such as the phosphor (in a CRT monitor) or filters and backlight (LCD monitor).\nAnother way of creating colors on a monitor is with an HSL or HSV color space, based on hue, saturation, brightness (value/brightness). With such a space, the variables are assigned to cylindrical coordinates.\nMany color spaces can be represented as three-dimensional values in this manner, but some have more, or fewer dimensions, and some, such as Pantone, cannot be represented in this way at all.\nColor space conversion is the translation of the representation of a color from one basis to another. This typically occurs in the context of converting an image that is represented in one color space to another color space, the goal being to make the translated image look as similar as possible to the original.\nThe RGB color model is implemented in different ways, depending on the capabilities of the system used. By far the most common general-used incarnation as of 2006[update] is the 24-bit implementation, with 8 bits, or 256 discrete levels of color per channel. Any color space based on such a 24-bit RGB model is thus limited to a range of 256×256×256 ≈ 16.7 million colors. Some implementations use 16 bits per component for 48 bits total, resulting in the same gamut with a larger number of distinct colors. This is especially important when working with wide-gamut color spaces (where most of the more common colors are located relatively close together), or when a large number of digital filtering algorithms are used consecutively. The same principle applies for any color space based on the same color model, but implemented in different bit depths.\nCIE 1931 XYZ color space was one of the first attempts to produce a color space based on measurements of human color perception (earlier efforts were by James Clerk Maxwell, König & Dieterici, and Abney at Imperial College) and it is the basis for almost all other color spaces. The CIERGB color space is a linearly-related companion of CIE XYZ. Additional derivatives of CIE XYZ include the CIELUV, CIEUVW, and CIELAB.\nRGB uses additive color mixing, because it describes what kind of light needs to be emitted to produce a given color. RGB stores individual values for red, green and blue. RGBA is RGB with an additional channel, alpha, to indicate transparency.\nCMYK uses subtractive color mixing used in the printing process, because it describes what kind of inks need to be applied so the light reflected from the substrate and through the inks produces a given color. One starts with a white substrate (canvas, page, etc.), and uses ink to subtract color from white to create an image. CMYK stores ink values for cyan, magenta, yellow and black. There are many CMYK color spaces for different sets of inks, substrates, and press characteristics (which change the dot gain or transfer function for each ink and thus change the appearance).\nYIQ was formerly used in NTSC (North America, Japan and elsewhere) television broadcasts for historical reasons. This system stores a luma value roughly analogous to (and sometimes incorrectly identified as) luminance, along with two chroma values as approximate representations of the relative amounts of blue and red in the color. It is similar to the YUV scheme used in most video capture systems and in PAL (Australia, Europe, except France, which uses SECAM) television, except that the YIQ color space is rotated 33° with respect to the YUV color space and the color axes are swapped. The YDbDr scheme used by SECAM television is rotated in another way.\nxvYCC is a new international digital video color space standard published by the IEC (IEC 61966-2-4). It is based on the ITU BT.601 and BT.709 standards but extends the gamut beyond the R/G/B primaries specified in those standards.\nHSV (hue, saturation, value), also known as HSB (hue, saturation, brightness) is often used by artists because it is often more natural to think about a color in terms of hue and saturation than in terms of additive or subtractive color components. HSV is a transformation of an RGB color space, and its components and colorimetry are relative to the RGB color space from which it was derived.\nHSL (hue, saturation, lightness/luminance), also known as HLS or HSI (hue, saturation, intensity) is quite similar to HSV, with ""lightness"" replacing ""brightness"". The difference is that the brightness of a pure color is equal to the brightness of white, while the lightness of a pure color is equal to the lightness of a medium gray.\n- The RG Chromaticity space is used in computer vision applications. It shows the color of light (red, yellow, green etc.), but not its intensity (dark, bright).\n- The TSL color space (Tint, Saturation and Luminance) is used in face detection.\nEarly color spaces had two components. They largely ignored blue light because the added complexity of a 3-component process provided only a marginal increase in fidelity when compared to the jump from monochrome to 2-component color.\nAbsolute color spaceEdit\nIn color science, there are two meanings of the term absolute color space:\n- A color space in which the perceptual difference between colors is directly related to distances between colors as represented by points in the color space.\n- A color space in which colors are unambiguous, that is, where the interpretations of colors in the space are colorimetrically defined without reference to external factors.\nIn this article, we concentrate on the second definition.\nA non-absolute color space can be made absolute by defining its relationship to absolute colorimetric quantities. For instance, if the red, green, and blue colors in a monitor are measured exactly, together with other properties of the monitor, then RGB values on that monitor can be considered as absolute. The L*a*b* is sometimes referred to as absolute, though it also needs a white point specification to make it so.\nA popular way to make a color space like RGB into an absolute color is to define an ICC profile, which contains the attributes of the RGB. This is not the only way to express an absolute color, but it is the standard in many industries. RGB colors defined by widely accepted profiles include sRGB and Adobe RGB. The process of adding an ICC profile to a graphic or document is sometimes called tagging or embedding; tagging therefore marks the absolute meaning of colors in that graphic or document.\nA color in one absolute color space can be converted into another absolute color space, and back again, in general; however, some color spaces may have gamut limitations, and converting colors that lie outside that gamut will not produce correct results. There are also likely to be rounding errors, especially if the popular range of only 256 distinct values per component (8-bit color) is used.\nOne part of the definition of an absolute color space is the viewing conditions. The same color, viewed under different natural or artificial lighting conditions, will look different. Those involved professionally with color matching may use viewing rooms, lit by standardized lighting.\nOccasionally, there are precise rules for converting between non-absolute color spaces. For example, HSL and HSV spaces are defined as mappings of RGB. Both are non-absolute, but the conversion between them should maintain the same color. However, in general, converting between two non-absolute color spaces (for example, RGB to CMYK) or between absolute and non-absolute color spaces (for example, RGB to L*a*b*) is almost a meaningless concept.\nA different method of defining absolute color spaces is familiar to many consumers as the swatch card, used to select paint, fabrics, and the like. This is a way of agreeing a color between two parties. A more standardized method of defining absolute colors is the Pantone Matching System, a proprietary system that includes swatch cards and recipes that commercial printers can use to make inks that are a particular color.\n- Young, T., 1802. Bakerian Lecture: On the Theory of Light and Colours. Phil. Trans. R. Soc. Lond. 92:12-48. doi: 10.1098/rstl. 1802.0004\n- Grassmann, H. (1853). Zur Theorie der Farbenmischung. Poggendorffs Annalen der Physik, 89, 69–84.\n- Logvinenko, A. D. (2015). The geometric structure of color. Journal of Vision, 15(1), 15.1.16. http://doi.org/10.1167/15.1.16\n- William David Wright, 50 years of the 1931 CIE Standard Observer. Die Farbe, 29:4/6 (1981).\n- Charles Poynton, ""YUV and \'luminance\' considered harmful: a plea for precise terminology in video,"" online, author-edited version of Appendix A of Charles Poynton, Digital Video and HDTV: Algorithms and Interfaces, Morgan–Kaufmann, 2003. online\n- Charles Poynton, Constant Luminance, 2004\n- Dean Anderson. ""Color Spaces in Frame Grabbers: RGB vs. YUV"". Retrieved 2008-04-08.\n- Hans G. Völz (2001). Industrial Color Testing: Fundamentals and Techniques. Wiley-VCH. ISBN 3-527-30436-3.\n- Gunter Buxbaum; Gerhard Pfaff (2005). Industrial Inorganic Pigments. Wiley-VCH. ISBN 3-527-30363-4.\n- Jonathan B. Knudsen (1999). Java 2D Graphics. O\'Reilly. ISBN 1-56592-484-3.\n- Bernice Ellen Rogowitz; Thrasyvoulos N Pappas; Scott J Daly (2007). Human Vision and Electronic Imaging XII. SPIE. ISBN 0-8194-6605-0.\n- Yud-Ren Chen; George E. Meyer; Shu-I. Tu (2005). Optical Sensors and Sensing Systems for Natural Resources and Food Safety and Quality. SPIE. ISBN 0-8194-6020-6.\n|Wikimedia Commons has media related to Color spaces.|\n- Color FAQ, Charles Poynton\n- FAQ about color physics, Stephen Westland\n- Color Science, Dan Bruton\n- Color Spaces, Rolf G. Kuehni (October 2003)\n- Colour spaces – perceptual, historical and applicational background, Marko Tkalčič (2003)\n- Color formats for image and video processing – Color conversion between RGB, YUV, YCbCr and YPbPr.\n- C library of SSE-optimised color format conversions.\n- Konica Minolta Sensing: Precise Color Communication', 'In Part one of this series we reviewed some basics on color, and some tips on choosing your colors. In this second part we will cover the first step in working with your digital files on your computer – the RGB color space.\nHere is an example of a typical color RGB color issue. At some point you may have created a design, a logo or perhaps adjusted a photo on your computer screen to produce some really, bright, vibrant, saturated color. Happy with what you had seen on screen and ready for print, you send your file off to be printed and wait for your proof or sample. Sadly, what you receive is not as bright, colorful and saturated as what you had created on screen, what happened?! The answer lies in the beginning, with the RGB color space and your monitor.\nWhat is Color?\nWhat we see as color is the wavelength of light being received by our eyes, whether it is light reflected off an object or emitted by a source such as a light bulb or a computer screen. Red, green and blue (RGB) are the additive primary colors of the color spectrum. Combining balanced amounts of red, green and blue lights produces pure white. By varying the amount of red, green and blue light, all of the colors in the visible spectrum can be produced. Your monitor screen can produce millions of these color combinations, but still not able to reproduce all the visible colors. And depending on your monitor, the colors may not be displayed accurately. This is hurdle ‘one’ and can be addressed by buying a good quality monitor with even brightness across the entire screen area, and with the purchase of a calibration device to ‘profile’ or map out the color reproduction capabilities of your monitor. These devices were once fairly expensive but have come down considerably in price and can now be used to profile many different types of displays such as LCD, LED and projectors – even your HDTV in some cases. PANTONE’s ColorMunki (www.pantone.com) is a very capable entry-level device for calibrating your displays and is available for around $170.00. Keeping your monitor color stable and consistent will go a long way towards improving your output when it comes time to move beyond the screen.\nWhy is my sky purple?\nNow that you have calibrated your monitor and mapped its colorspace, you opened up a picture of your dog catching a Frisbee in the park, intending to adjust the color and remove a trash can in the background. Perhaps you made the sky a bright, bright blue, the grass a vibrant green, and the Frisbee a bright orange. Working in RGB color, this photo leaps off your screen which will make it the perfect cover photo for your brochure. You package up your files, upload them to your print service provider and await your proof. When your proof arrives, all those bright color are shadows of their former selves – and no, your printer did not make a mistake. In order to print your image in process color, your image was converted at some point in the workflow to CMYK color space, which is quite a bit smaller than the RGB color space. In doing so, colors that are outside the CMYK range (or gamut) are pulled back down into the printable range, which makes them appear duller and flatter. To avoid surprises in your output, many applications support color profiles and allow you to use your calibration profile to simulate your final output color on screen through ICC color profile conversions. Adobe Systems Inc. provides excellent tools for color management within their design programs, so please visit their site at www.adobe.com to learn more about them.\nMore Pantone Goodies\nIf you are serious about color, a great investment for your color toolbox is a set of Pantone color guides. The color scientist’s at Pantone have created color swatches of each single spot color ink, and swatches of those colors converted to CMYK process color simulations, and shown on both coated and uncoated papers. These printed swatches and the paper they are printed on follow a strict set of guidelines for color reproduction, and while you may not be using the exact same papers and inks, will give you an excellent idea of how your color will reproduce. In addition to the visual references, Pantone is including a nice little software app, the Pantone Color Manager, that is web-capable and can update itself with the latest definitions automatically. The app also includes conversions for RGB and HTML, so that you can use the correct color definitions across your web pages, tablets and mobile apps. For more about Pantone color tools, visit them at www.pantone.com.\nTalk to us about your color\nWhen you are ready to start managing your color to a finer degree, give us a call or talk to your consultant. We can provide you with expert advice on your color management and recommend the right tools to make it work for you. We can also provide our print profiles to you to install in your color management system for more accurate proofing and color conversion.']"	['<urn:uuid:836a2ad1-3a66-4666-a093-774454f8ced6>', '<urn:uuid:f079cb8a-0acb-4a93-bf66-a786dc51f63d>']	factoid	direct	long-search-query	similar-to-document	three-doc	novice	2025-05-01T22:47:46.423955	10	82	3193
62	What kind of zines does the Che Cafe Library in La Jolla collect?	The Che Cafe Library collects zines addressing political and social issues, and they are especially looking for DIY how-to guides.	"['U.S. Libraries with Zine Collections by State:\nArizona | California | Colorado | Connecticut | District of Columbia | Florida | Georgia | Illinois | Iowa | Kentucky | Louisiana | Maine | Maryland | Massachusetts | Michigan | Minnesota | Missouri | Montana | Nebraska | Nevada | New Hampshire | New Jersey | New Mexico | New York | North Carolina | South Dakota | Ohio | Oregon | Pennsylvania | Tennessee | Texas | Utah | Vermont | Virginia | Washington | Wisconsin\nZine Libraries Countries Outside the U.S.:\nThe Catalyst Infoshop, Prescott Dry River Zine Library, Tucson\nAnno Domini Zine Library, San Jose\nFocus is on creative and artistic zines.\nAsian American Zine Archive, University of California, Davis\nc/o Darrell Y. Hamamoto, Asian American Studies Program\n530-752-5600, by appointment only\nBako Zines Library, Bakersfield\nBeautiful/Decay, Culver City\nArt and comix zines\nCenter for Sex and Culture, San Francisco\nChain House Zine Library, LA\nA traveling Zine Library/Press\nChe Cafe Zine Library, La Jolla\nThe Che is most interested in zines addressing political and social issues, especially looking for DIY how-to guides.\nCity Heights Free Skool, San Diego\nLong Haul Infoshop, Berkeley\nRadical periodical collection spanning the past few decades.\nRock! Paper! Scissors! Zine Library, Oakland\nSan Francisco Public Library, San Francisco\nThe collection spans the twentieth century, with a special emphasis on the San Francisco experience.\nUniversity of California, Riverside, Riverside\nScience fiction fanzines\nWest Coast Zine Collection, San Diego State University, San Diego\nColorado College, Colorado Springs\nDenver Zine Library, Denver\nElm City Infoshop (inside Neverending Books)\nProvisions Library: Resource Center for Activism & Arts, Washington, DC\nNew College of Florida, Sarasota\nUniversity of Central Florida, Orlando\nJacksonville Public Library, Jacksonville\n""We hope to focus on regionally based zines, but our scope will be broad, including publications devoted to arts, culture, comics, politics, and advocacy.""\nCivic Media Center, Gainesville\nFirefly Lending Library, Miami\nAthens-Clarke County Library zine collection\nThe collection focuses on issues that teens deal with such as sexual identity, fitting in, and mental health, as well as humor and art zines. The collection contains around 250 zines and donations are accepted. For more info, contact Brandy Erdmann at email@example.com\nOconee County Library, Watkinsville\nDePaul University Zine Collection, Chicago\nIncludes zines from the 1994 Underground Press Conference as well as individuals\' donated collections. Also known as Great Lakes Underground Press Collection, for zines acquired at the conference.\nEla Area Public Library, Lake Zurich\nRead/Write Library Chicago, IL\nAnything self-published in Chicago\nSmall Science Zine Library, Chicago, IL\nScience zines to download.\nUrbana-Champaign Independent Media Center, Urbana, IL\nUniversity of Iowa, Iowa City\nSpecial collections including ""zines relating to avant-garde, underground, and popular music,"" Blakes 7 fanzines, fan fiction, apazines, science fiction fanzines, Star Trek, Star Wars, and riot grrrl. Also zines from the Zine Machine, a vending machine full of \'em.\nSweet Bee Infoshop, Des Moines, IA\nUniversity of Kentucky Zine Archive, Lexington\nc/o Deirdre Scaggs, King Library, firstname.lastname@example.org\nThe collection focuses on zines produced in or discussing the Southern United States and/or environmental issues (bikes, veganism, sustainable communities, etc.).\nThe Brick House, Louisville, KY\nAmistad Research Center, Tulane University, New Orleans\n""zines written and published by individuals of color or whose topics focus on racial and ethnic culture and history, civil rights, race relations, and related topics""\nHidden Spaces Zine Collection, sift, New Orleans\nPop-Up Zine Library events\nDeerest Isle Traveling Zine Library!, Deer Isle\nWrong Brain, Kittery\nBaltimore County Public Library, Baltimore, MD\nFanzines and Amateur Press Association mailings\nCharm City Art Space, Baltimore, MD\nAbout half personal zines, and half punk zines HeartattaCk, Maximumrocknroll.\nUniversity of Maryland, Baltimore County\nUniversity of Maryland, College Park\nD.C. Punk and Indie Fanzine Collection\nHampshire College, Amherst\nLesley University, Cambridge\nPapercut Zine Library, Cambridge\nSimmons College, Boston\nSmith College, Northampton\nGirls\' zines, many from Tristan Taormino\'s collection.\nUniversity of Michigan, Ann Arbor\nPolitical, especially anarchist zines.\nMichigan State, East Lansing\nComics are their specialty.\nPetoskey Public Library, Petoskey\nHas a small zine collection as part of its Teen Room, not cataloged.\nYpsilanti District Library\nStacey Palazzolo, Outreach Services, 5577 Whittaker Rd., Ypsilanti MI 48197\n734-482-4110, ext. 1340; email@example.com\nMinnesota Community and Technical College, Minneapolis\nMinneapolis Public Library Walker Branch, Minneapolis\nSearch for subject Fanzines and you\'ll retrieve a list of nearly 200 bibliographic records, most representing not items about zines but zines themselves.\nBat Annex Free School Library, Minneapolis, MN.\nTheir catalog is online at LibraryThing.\nBread and Roses Library, St. Louis, MO\nJoseph Heathcott Collection of Counterculture Publications, Saint Louis University Libraries Special Collections, St. Louis, MO\n""These materials were collected by Joseph Heathcott in the course of his research as an American Studies professor and urban historian. Most of the materials were published between the late 1980s and early 2000s, and include American national and regional publications as well as materials published in Canada, the United Kingdom, and elsewhere.""\nMissouri Valley Special Collections, Kansas City Public Library, Kansas City\nPaper Airplane Zine Library, Springfield, MO\nSamizdat Zine Library, St. Louis, MO\nUniversity of Montana-Missoula, Missoula\nMansfield Library, attn: Special Collections Librarian or firstname.lastname@example.org\nSlumgullion Independent Publishing Co-op, Missoula, MT\nLocal and kid friendly zines, and others.\nOmaha Zine Library, Omaha, NE\nLas Vegas Zine Library, Las Vegas, NV\nPlymouth Regional High School, Plymouth\nZines are not cataloged, but they do circulate.\nK/S Zine Library, one in New Jersey, one in Scotland\nBy subscription. Star Trek fanzines and slash fiction.\nTeen Zone, Farmington Public Library, Farmington\nBarnard College, New York\nCis- and transgender women\'s personal and political zines. Open stacks and archives collections.\nBrooklyn College, Brooklyn\nPrimary focus is Brooklyn zines.\nDurland Alternatives Library, Cornell University, Ithaca\nFales Library & Special Collections, NYU, New York\nZines and other materials related to the riot grrrl movement.\nPratt Institute, Brooklyn\nUniversity at Buffalo, Buffalo\nZines from around Western New York circa early to mid 1990s\nWells College Zine Library, Aurora\nNew York Public Library, DeWitt Wallace Periodical Room 108, Schwarzman Building, Fifth Avenue at 42nd Street, New York\nNew York State Library, Albany\nThey have the Factsheet Five collection.\nABC No Rio Zine Library, New York, NY\nDitKO!, The Silent Barn, Ridgewood, NY\nSilent City Distro, Ithaca, NY\nSugar City, Buffalo, NY\nTAC Zine Library, Oswego, NY\nUnofficial SUNY New Paltz Traveling Zine Library, New Paltz, NY\nDuke University, Durham\nIncludes the Sarah Dyer collection\nInternationalist Books and Community Center, Chapel Hill\nBrowne Popular Culture Library , Bowling Green State University, Bowling Green\nCleveland Public Library, Cleveland\nCuyahoga County Public Library, Independence\nTeen collection at Independence branch.\nPacific Northwest College of Art, Portland, OR\nMultnomah County Public Library, Portland, OR\nBitch Media, Portland, OR\nBlack Rose at the Red and Black Cafe, Portland, OR\nIndependent Publishing Resource Center (IPRC), Portland, OR\nCarnegie Library, Pittsburgh\nLittle Berlin, Philadelphia, PA\nZines and artist\'s books.\nRoboto Project Zine Library, Pittsburgh\nThe Soapbox: Philadelphia\'s Independent Publishing Center, Philadelphia, PA\nVermillion Public Library, Vermillion\nChattanooga Public Library, Chattanooga\nLinebaugh Public Library, Murfreesboro\nWatkins College of Art & Design, Nashville\nAustin Public Library, Faulk Central Library, Austin\nAustin Zine Library, Austin,\nIn the Rhizome Collective\'s Center for Community Organizing\nTexas A & M University, College Station\nZines created by Texans or other Southwesterners and/or concern Texas or the Southwest; zines created by African-Americans or Latino/as in Texas or the Southwest; zines created by TAMU students or former students; and Artzines concerned with printing and/or designed as print art objects.\nSalt Lake City Public Library, Main Library, Level 2, Salt Lake City\nMarlboro College, Marlboro\nThe Root Radical Lending Library, Brattleboro\nSchulz Library, White River Junction, VT\nThe library for the Center for Cartoon Studies. Also has graphic novels, cartoon collections, and related ephemera.\nFlying Brick Library, Richmond, VA\nVirginia Commonwealth University, Richmond, VA\nWingnut Anarrchist Collective, Richmond, VA\nKitsap Regional Library: Port Orchard Branch, 87 Sidney Ave., Port Orchard\nShannon Peterson, 360-876-2224\nLocal, teen, comics, northwest zines\nOlympia Zine Library, Olympia\nPunk Zine Archive, Mill Creek\nPDFs of out of print issues of punk zines including Flipside, HeartattaCk, Maximumrocknroll, and Suburban Voice.\nSeattle Public Library, Seattle\nIn the Teen Center at the downtown library and also at the University Branch\nContact for University Branch: Josie Watanabe\nTimberland Regional Library, Olympia and Yelm\nSearch for them in the catalog using keyword <zine>\nZine Archive & Publishing Project, Seattle, WA\nBeloit College, Beloit, WI\nLibrary Workers Zine Collection, SLIS Laboratory Library, University of Wisconsin – Madison\nNational Libary of Australia, Canberra, ACT\nPort Phillip Library Service, Port Phillip, Victoria\nState Library of Victoria, Melbourne, Victoria\nCopy & Destroy Zine Library Brisbane\nOctapod, Newcastle NSW\nFEL Bibliotheek, Ghent\nAnchor Archive Zine Library, Halifax, Nova Scotia\nAnnapolis Valley Zine Library, Greenwich, Nova Scotia\nBibliograph, Montréal, Québec\nCalgary Zine Library, Zine Tree Collective, Calgary, Alberta\nArrow Archive, Hamilton, Ontario\nOntario College of Art & Design, Toronto, Ontario\nPride Library, London, Ontario\npart of the Queer Graphica Collection at the University of Western Ontario\nSheridan College Library, Oakville, Ontario\nToronto Zine Library, Toronto, Ontario\nVancouver Public Library, Vancouver, British Columbia\nXPACE, Toronto, Ontario\nFanzinothèque, Poitiers, France\nArchiv der Jugendkulturen e.V. Berlin, Germany\nFemArchiv in the Frauenmuseum, Marburg, Germany\nThe Athens Zine Bibliotheque, Athens, Greece\nC20 Library & Collective Surabaya, Indonesia\nThe Forgotten Zine Archive, Dublin, Ireland\nIrish & international independent publications\nItami City Library, Itami-shi, Hyogo, Japan\nNagi Shokudo, Shibuya, Japan\nZine library in a vegan restaurant. Japanese/English collection. From VLU blog.\nZsa Zsa Zine Library, Amsterdam\nfeminist, queer and poc zines and comics\nFeminist Zine Library,Victoria University, Wellington, New Zealand\nWellington City Libraries, Wellington, New Zealand\n56a Zine Library, London, England\npolitical, feminist, queer, activist zines as well as perzines and punk zines\nBritish Library, London, England\ncounterculture zines, women’s zines, riot grrrl zines,music zines, football zines, alternative comics\nCowley Club, Brighton, England\nlending library with materials relating to libertarian, ecological, and feminist books, pamphlets, and zines\nGlasgow Women\'s Library, Glasgow, Scotland\nFeminist, perzines, music, punk, political, comics included in the collection. The collection dates from the early 90s to present day.\nLondon College of Communication, London, England\nart zines as well as music/personal/political zines, covering art, music, photography, politics and personal stories\nManchester LGBT Zine Library, Manchester, England\nZines housed in the Joyce Layland LGBT Centre\nMobile Menstrual Zine Library, Sheffield, England\nSalford Zine Library, Manchester, England\nStuart Hall Library, London, England\ncultural diversity,race, ethnicity, gender, and sexuality, as well as personal/political/arts based zines\nUniversity of Portsmouth/Zineopolis, Portsmouth, Hampshire\nZineopolis! Supports an arts, design & media illustration course\nThe Women\'s Library, London, England\nAustin Fanzine Project, Austin, TX\nInternet Archive, San Francisco, CA\nQueer Zine Archive Project, Milwaukee, WI\nQueer zines available in PDF for download.\nSend Back My Stamps!: METAL FANZINE ARCHIVE\nDeath/thrash/grind/black metal fanzine scans from yesteryear\nA collaboration of scientists, artists, students, and anyone else interested in science, this project produces small zines and web comics on a variety of topics. Read online, download zines, and share your ideas.\nAn online library which has hundreds of radical zines ready to print.\nRight Column Copy']"	['<urn:uuid:b12c2324-49d0-44d1-b77c-68daba179e23>']	factoid	direct	concise-and-natural	similar-to-document	single-doc	novice	2025-05-01T22:47:46.423955	13	20	1831
66	Between copper barriers and diatomaceous earth, which natural slug deterrent provides longer-lasting protection around garden plants?	Copper barriers provide longer-lasting protection, as copper bands give slugs an electric shock when they try to cross. In contrast, diatomaceous earth loses its effectiveness as soon as it gets wet.	"[""Organic pest and disease control\nHow to get rid of slugs\nBarriers of anything sharp and gritty will protect your tender plants.\n- Bran and salt will dehydrate slugs and kill them.\n- Make a â€˜slug pubâ€™ by filling a saucer with beer â€“ slugs will drink it and die from dehydration.\n- Buy a band of copper from a garden centre which give slugs an electric shock.\nHealthy growth depends on healthy soil. Too much fertiliser and your plants will be soft and sappy - resulting in a lovely lunch for garden pests. Feed your soil with a diet of garden compost and leafmould rather than the fast-food artificial fertilisers that are designed to feed only the plant. Research has proved feeding the soil rather than the plant means stronger growth and better resistance to pests and diseases. Another very important tool in preventing pests and diseases is choosing varieties of plants that have been bred for their pest and disease resistance.\nIf you have a vegetable garden, you must practise crop rotation as a way of controlling pests and diseases. This involves dividing your vegetables into at least four groups that stay together each year but move onto the next part of the rotation every spring. The vegetables are grouped by family as well as similar feeding habits. Apart from being the best way to build soil fertility, it is the most important factor in controlling the build up of pests and diseases.\nBarriers are the best way of reducing pest damage. Follow these tips to to keep the pests at bay:\nAnother popular method of protecting your plants is to use traps. This can be anything from beer traps for slugs to codling moth traps hung from your apple trees. Sticky traps are very popular with the organic gardener. Greasebands, painted around the trunks of apple trees in autumn are a popular way of preventing the wingless female winter moth from climbing up the tree to mate. Sticky glue is also very useful for glasshouse staging if you have a problem with ants. Sticky yellow bits of card hung up in the glasshouse can help reduce the population of whitefly.\nMany insects and wildlife can be beneficial to your garden and these really are your best friends when it comes to controlling pests. Planting simple annuals amongst your vegetables, such as Californian poppies and marigolds will attract a wealth of beneficial insects like ladybirds and hoverflies who will gobble up your aphids. Plant a few native shrubs and herbaceous perennials such as hazel and hardy geraniums in your garden, create a pond, leave a small pile of logs in the corner of your garden and feed the birds throughout the winter. Doing any or all of these will keep enough wildlife in your garden to eat thousands of pests and their eggs.\nWhen trying to control pests and diseases in an organic garden, always remember to be as hygienic as you can. So, if you're trying to remove a diseased branch from a tree, cut into healthy wood and always wash your tools in boiling water afterwards. Always scrub out your pots and give your greenhouse a good scrub every winter to get rid of those over-wintering pests. Maximising air circulation by correct pruning and leaving just a little more space between your plants can help control fungal diseases, for example powdery mildew in roses.\nAlways check your plants for pests\nFinally, and most importantly, be vigilant and check your plants regularly so that any pest and diseases don't get a chance to get a hold. For example, if you start checking the centre of your gooseberry bushes in April for sawfly eggs and larvae you can remove them and therefore prevent them from defoliating your crop. Also be wary of accepting onion and cabbage plants as they may well carry the dreadful diseases of onion white rot and clubroot which you will never be able to get rid of. If you have an allotment with these diseases don't use the same tools or boots in your own garden because you will spread them easily and quickly.\nBy following the simple tips above, you can become an organic gardener with planning, forethought, observation and vigilance. When it comes to controlling pests and diseases in an organic garden, always remember prevention is better than cure. Get more tips on how to become a green, organic gardener on our website."", 'To get rid of those pesky snails and slugs in your garden without the use of chemical treatments, start by removing the pests by hand, searching them out in the evening. Doing that chore daily at first, and then weekly as the population dies down, will reduce the numbers. Because a multifaceted approach is usually best, also try cleaning the area, adding barriers around your plants and setting out natural traps.\nPrevent Excess Moisture\nSnails and slugs like damp or moist environments, and often hide in the damp areas under boards, plant debris and mulch. Thus, one way to keep the area free from excess moisture is to install a drip irrigation or underground irrigation system instead of doing overhead watering. In general, good air flow will keep the moisture down, so also keep your plants pruned to encourage good air flow.\nRemove Hiding Spots\nAlso, look through your garden and remove any boards, thick mulch or debris where slugs and snails can hide. If you have wood or other surfaces you can\'t remove -- such as nearby deck boards, for example -- check them regularly for slugs. You can also set out a moist board as a ""trap"" for the pests, making sure to check under the board every day to remove any slugs or snails you find.\nKill Slugs Naturally\nSlugs and snails also love yeast, so another way to trap them is to set out a container of a yeast-containing substance. Use beer or a solution of 1 teaspoon of yeast to 3 ounces of water, suggests the University of Minnesota Extension website. Cut several old yogurt container or other plastic containers to about 1 inch high and dig shallow holes in your garden. Set the containers into the holes, flush with the soil line. Fill the container with the yeast-containing liquid and check the traps for slugs in the morning.\nAlso try creating a garlic-based spray as a natural pesticide that works on slugs, suggests the World Agroforestry Centre. Fill a spray bottle with 10 liters of water and three finely chopped garlic bulbs, and then spray your plants every three days with the solution. You can also try setting a jar of oat bran on its side near the garden. When slugs eat the oat bran, it expands in their bodies and kills them, explain master gardeners Frank and Linda Saus of Penn State Extension-Beaver County.\nCreate a Barrier\nAnother option is to create a barrier that slugs and snails can\'t cross. Wrap copper tape or copper bands -- found at garden supply stores -- around the stems of your plants or your garden bed. Copper can cause a disruption in a snail or slug\'s nervous system as it crosses it, according to the University of California\'s Statewide Integrated Pest Management System. One thing to keep in mind, though: If you plan to place a copper strip around an entire raised bed garden, the bed needs to be free of slugs before installation.\nSome gardeners also sprinkle diatomaceous earth around their plants to repel slugs, but the effectiveness wears off as soon as the diatomaceous earth gets wet. Also avoid adding salt to your garden to kill slugs, as it can affect your soil health. There\'s also no evidence to support using Epsom salts against slugs, suggests Dr. Linda Chalker-Scott of the Washington State University Puyallup Research and Extension Center.']"	['<urn:uuid:9d85083d-840b-4ab0-a1c2-d7b4ad462f9b>', '<urn:uuid:71233e7d-a68e-4bf4-a296-d40d73f23568>']	factoid	direct	verbose-and-natural	distant-from-document	comparison	novice	2025-05-01T22:47:46.423955	16	31	1306
68	Which is older, Levittown suburb or the Delaware Aqueduct bridge?	The Delaware Aqueduct bridge is older, having been built in 1849, while Levittown was completed in 1951. The Delaware Aqueduct is actually the oldest wire suspension bridge in the United States, designed by John Augustus Roebling who later engineered the Brooklyn Bridge. Levittown, on Long Island, is considered the nation's first true suburb.	"['Action Speaks!, the panel discussion series at Providence art space AS220, wraps up its fall run with a look at the American adventure in suburbia.\nParticipants will consider the effect of suburban growth on our economy and culture and address some pressing questions: Can the suburbs, built on what once seemed an end-less supply of oil, turn green? Can bastions of “white flight” reflect the nation’s growing diversity?\nAction Speaks! discussions, produced by Cheryl Kaminsky and moderated by Marc Levitt, use an underappreciated date in history as a springboard for chatter on contemporary affairs. This time it’s 1951 and the completion of Levittown (in photo), a Long Island community widely considered the nation’s first true suburb.\nThe event, scheduled for October 28 at 5 pm at AS220, 115 Empire Street, is free and open to the public.\nPanelists will include V. Elaine Gross, president of ERASE Racism, a Long Island-based non-profit that promotes racial equity through research, policy advocacy and education; Alyssa Katz, a freelance journalist who teaches at New York University and author of Our Lot: How Real Estate Came to Own Us; and Paul Lukez, a Boston-based architect and author of Suburban Transfor-mations.\nWe caught up with Lukez for a Q&A via e-mail. Answers are edited and condensed for length.\nYOU SUGGEST, IN SUBURBAN TRANSFORMATIONS, THAT WE SHOULD BUILD ON WHAT WE HAVE IN SUBURBIA RATHER THAN START ANEW — AND ERASE HISTORY — WITH EACH SUCCESSIVE DEVELOPMENT. WHY IS THIS IMPORTANT?\nThere are several reasons for selectively and intelligently transforming suburbs instead of erasing them completely.\nFirst, it is often more sustainable to reuse or transform existing buildings (their materials and systems) than to send them to the landfill. In fact, we should be building struc-tures that will last for 100 years-plus, but are designed to accommodate changing users’ needs over time. There are many examples of such structures. Boston’s Quincy Market is a great example of a building that has survived for two hundred years because of its adaptable design. Its façade and floor plans were continually changed over its life before being “historically restored” in 1976.\nSecondly, we don’t have to tear all the buildings in the suburbs down to improve the quality of spaces and environment. Many mistakes were made in the original design of suburbs. Buildings were often placed in the wrong place relative to the street and adjacent buildings. By reconstituting the scarred landscape, improving the roads/infrastructure and thoughtfully adding new structures, a denser suburb integrated with nature can evolve over time, repairing many of the mistakes of the past.\nThirdly, leaving traces of past buildings and urban interventions adds a unique quality to a community that cannot be replicated by other communities. Because the way in which each community is transformed will be the result of time and circumstance. If each community erases all traces of its past, each community will tend to look the same. At the end of his life, psychiatrist Carl Jung looked at his house on Lake Zurich which he had built over his adult life, transforming its original tower-like structure over time through multiple additions and transformations. He recognized in the idiosyncratic transformations the structure of his life, one that could not be replicated. Embracing idiosyncrasy and circumstance can contribute to creating a unique identity for each community.\nAnd finally, we can’t afford to tear down our suburbs and start over. We need to make the most of what we have, which in turn can yield surprising and inventive results.\n: This Just In\n, Massachusetts Institute of Technology, Urban Planning, New York University, More', ""Two hours southwest of Hudson, on the New York-Pennsylvania line, lies one of the most remarkable bridges found anywhere. Somehow, I hadn't heard of the Delaware Aqueduct, the oldest wire suspension bridge in the United States, until a couple months ago. It was designed by John Augustus Roebling, the engineer of the Brooklyn Bridge. But as remarkable as the Brooklyn Bridge is, the Delaware Aqueduct might be more amazing.\n|The aqueduct carries vehicular traffic today.|\nThe aqueduct was built in 1849 as an improvement to the earlier, 106-mile long Delaware-Hudson Canal. The privately financed canal had been completed in 1828 to carry coal from northeastern Pennsylvania to the Hudson River at Kingston, New York. Most of the coal apparently continued to New York City via the Hudson River, helping fuel the city's growth. I haven't yet grasped the canal's whole story (... e.g., why such a circuitous route to NYC?!), but apparently boat traffic on the canal originally crossed the Delaware River via the river itself. I'm guessing the canal boats were lowered via locks, floated across the river, and raised again to continue on their way. In any event, the canal traffic had to negotiate commercial timbers being floated down the river, presenting not only an inconvenience but a danger. Hence, the Delaware Aqueduct was built to carry the canal and its boats over the river.\nRunning an artificial waterway over a river strikes me as a pretty cool thing; doing it with a suspension structure is even cooler. And the suspension system is extraordinary, as the main cables are so low in profile as to be contained almost entirely within the height of the cross trusses. An unobservant passerby might mistake the very complex structural system for something simpler. Here's a cutaway view showing how it works:\n|The canal as originally designed and constructed in 1849|\n|One of the approximately 80 cross trusses|\nEventually, the commercial viability of the canal was superseded by rail. The canal was abandoned and filled, and the aqueduct was decommissioned in 1898. The aqueduct was then purchased by a local businessman who removed the canal side walls and the upper tow paths (thus exposing the cables) and installed a vehicular roadway. He used his new bridge to transport timber from his forests in New York to the rail lines in Pennsylvania. He allowed the public to use the bridge for a fee, payable at a new toll house built on the New York side. Several generations of toll keepers lived in the house until the 1970s.\n|The original road conversion|\n|The current roadway with the canal sides restored|\nThe bridge doesn't get a lot of traffic. In the 45 minutes I was there, about six cars crossed. It's probably busier during vacation season. But driving and walking across it are unique experiences. The one lane roadway is tightly framed by the canal sidewalls, creating a tunnel effect for drivers. Crossing on foot, on the old tow paths, gives the pedestrian a bird's eye view of the river as well as the roadway 9 feet below. Here's a video showing what it's like to drive across the bridge.\nI'm hoping to visit it again soon... perhaps via a raft ride next time.""]"	['<urn:uuid:c4b31098-c16b-4981-a3c7-4dae9d9a00be>', '<urn:uuid:dae4cb51-6892-4294-89d7-b258a2e76d38>']	open-ended	with-premise	concise-and-natural	distant-from-document	comparison	novice	2025-05-01T22:47:46.423955	10	53	1137
69	how does gene therapy work distinguish somatic germline cell treatment methods	Gene therapy works by either administering drugs that help form specific gene products, or by introducing correct genes via viral vectors while leaving defective genes in the body. There are two main types: somatic cell therapy, which aims to eliminate genetic defects at the level of body tissue and organ cells, and germ-line therapy, which attempts to correct genetic defects in sperm and eggs to pass therapeutic effects to offspring.	['Out of the Ordinary\nSusanne Kircher is a human geneticist. She deals with rare genetic metabolic disorders that cause physical abnormalities. An absolute luminary in her field, she graciously makes an effort to present the most complicated facts in a way that laypeople like us can understand. A conversation about God, genes, and gargoylism.\n“There are no mistakes, ideally we would call them variants.”\nViktoria Kirner: Thank you for inviting us to the Center for Pathobiochemistry and Genetics here at the Medical University of Vienna. You seem a little out of breath, have you had a stressful day?\nSusanne Kirchner: You know, I only really began being stressed out when my husband retired (laughs). I’ve had the feeling ever since that he’s just sitting at home in his armchair with a stopwatch, waiting for me to get home. But a doctor’s workday just isn’t compatible with a stopwatch.\nYour work addresses rare genetic disorders. You research gene pools—a collection of different genes—and seek out those that are “defective.” How many genetic mistakes does nature make?\nI wouldn’t call them “mistakes,” because mistakes always suggest that something is wrong. Ideally we would call them variants. At present, we know about 25,000 genes, of which about 7,000 can be attributed to a disease. All told, however, a human being has hundreds of thousands of different gene variants that distinguish him or her from other human beings. You could say that every human being is the sum of their individual variants.\nHow does someone become a geneticist?\nI took a few detours getting here, from gynecology to pathology and finally to laboratory medicine. When I began my training at the university, I was entrusted with an extremely unusual case: I had to examine urine samples from people suffering from what is known as “gargoylism,” which is actually called mucopolysaccharidosis. The faces of people with this disease are deformed and resemble those of gargoyles, hence the common name. So I somehow stumbled into the field of rare genetic diseases with abnormal physical manifestations. I was fascinated right from the start.\nSo “gargoyles” laid the foundation for your fascination with the “genetically unusual”?\nThe foundation was actually laid a bit earlier. As part of my pathology studies, I had to perform an autopsy on a young woman who had died of internal bleeding—one of her blood her vessels had inexplicably torn. The examinations had shown that she had a rare genetic connective tissue disease known as “Ehlers-Danlos syndrome.” This disease has been known for well over a hundred years, but the research on it is still in its infancy. This unusual disease continues to occupy me to this day.\nEhlers-Danlos syndrome? I’ve never heard of it, can you tell me about it?\nI’m not surprised. Very few doctors know anything about it. The bodies of people with this syndrome don’t produce enough collagen. Their connective tissue—the natural corset we all wear—is fragile and flaccid; it doesn’t provide the necessary support. The body collapses on itself, resulting in spinal instabilities, herniated discs, disorders of the joints, or dislocations. With certain types of EDS, however, the organs and vessels can also be affected, such as in the case of that young woman. Others lose their teeth or develop ruptures in their eyeballs.\n“People with hypermobility were long regarded as an exotic circus attraction.”\nHow is it possible to have never heard of a disease that affects such absolutely crucial parts of the body?\nDo you know where you might have seen people with this disease? In the past they were often put on display as contortionists. Their skin is extremely elastic, the tendons and ligaments are very limp, so they are extremely flexible and mobile. People with hypermobility were long regarded as an exotic circus attraction.\nSo all those unusually flexible circus acrobats are actually suffering from Ehlers-Danlos syndrome?\nIn the past, yes, but not anymore. I am pretty sure that the contortionists who were once exhibited in circuses or so-called “freak shows” had EDS or at least some other form of connective tissue disease. They had this peculiar trait without being specially prepared for it. The people you see in the circus today have rigorously trained their bodies to be able to pull off these incredible performances.\nWe are equally fascinated by physical perfection and imperfection. Where does this voyeurism regarding physical abnormalities come from?\nPeople have always been attracted to the unusual and the novel. At the end of the 19th century, the Vienna Prater featured what were essentially “human zoos.” In the 1890s, the African “King Ashanti” and his village were kept in cages there like wild, exotic animals and displayed in front of thousands of visitors. History is full of similar examples. One of humanity’s lowest points, if you ask me.\nSo people who looked different were primarily used to satisfy our curiosity?\nIn some cases it wasn’t just a matter of satisfying curiosity, sometimes different-looking people also fulfilled other “functions.” People with dwarfism were often highly regarded, for instance in the age of monarchy: Many were extremely clever and were “kept” by the rulers as trusted advisors. They were the only ones who were allowed to speak their minds freely. Unlike other people, they were supposedly not dependent on the favor of the ruler, since they already had an unusual status in society due to their abnormality and therefore had nothing to lose.\nHave you ever seen Game of Thrones?\nThe dwarf Tyrion Lannister is “Hand,” or closest advisor to the queens and is portrayed as the most intelligent character in the series...\nWell, there you go! From an ethical and moral point of view, of course, things like that should be considered critically.\nWhat kinds of ethical or moral conflicts do you and your colleagues find yourselves confronted with?\nIn counseling, we sometimes hit a wall when it comes to faith and religion. There are patients who have a serious genetic disease and who are very likely to pass it on to their children. But they regard their illness as “God-given,” and if they were to pass it on to their child, that would be because it has been divinely ordained. It is very difficult to council such people, since they believe God wanted it that way.\n“I believe in an energy that governs us.”\nWhat is your opinion on God? Can a human geneticist believe in divine creation?\nI worked in pathology for a long time. That was where I realized that there has to be more to things than just this mortal shell. This might sound a little mystical, but the stories people tell about near-death experiences—I felt that so often in the dissecting room. I was alone with the deceased, but I wasn’t really alone. I believe in an energy that governs us. Who controls this energy, where it goes after death, whether it is released into the universe afterwards—the answers are beyond the scope of my knowledge. As a geneticist, I try to explain everything that I can see and grasp, but deep inside I know there is much more. Perhaps that could also be a god.\nIs there gene you would consider “perfect”?\nI don’t think there is a perfect gene, but perhaps a perfect gene pool—in the sense that it doesn’t cause disease.\nWhat do you personally consider the most serious genetic defect?\nGenetic defects are always bad when they go undetected. Something I find particularly troubling is watching young Ehlers-Danlos patients become marginalized socially. Not only do their physical impairments often prevent them from pursuing their profession or going out among people, they are also frequently not taken seriously. Living with untreated symptoms for long periods inevitably brings about psychological comorbidities such as depression. Once these are diagnosed, many doctors declare the actual genetically caused physical problems to be psychosomatic. A vicious circle that sometimes drives patients to suicide.\n“I consider gene therapy to be one of the most sensational discoveries ever.”\nWhich story has affected you most in recent years?\nAlso very difficult for me are cases where, in the course of providing genetic counseling for an entire family, I see one relative after another dying as a result of their inherited genetic defect. Even after doing this work for 35 years, it is still very hard to take.\nGene therapy technology has made incredible advances; gene editing, as it is known, is opening doors to previously unheard-of therapeutic possibilities.\nTo what extent can “sick” genes be cured?\nI consider gene therapy to be one of the most sensational discoveries ever in the field of genetics. In the future, it will be possible to offer people individualized treatment by influencing their genetic make-up. Gene therapy is already being used to alleviate or stop the progression of a number of diseases. What is known as “stop codon readthrough” therapy, for example, is already showing initial success in cystic fibrosis patients.\nWhat exactly does that entail? Can you just grow healthy genes in a Petri dish?\nAlmost. In the case of certain diseases in which a defective gene cannot form specific gene products, there are now drugs that can be administered so that a certain gene product is formed or made available. However, gene therapy also means that, while defective genes are left in the body, correct genes can be introduced via viral vectors. That is, if your own gene cannot form the desired gene product, the newly introduced gene can. This is revolutionary. There are great things in store for us in the future.\nBut these editing functions are not only used in gene therapy. Through the use of what are known as CRISPR technologies, scientists now have a tool at their disposal with which they can create specifically designed organisms. It is already theoretically possible to alter genes within ova or sperm cells.\nWe could create our own “designer babies.” Don’t the technical developments in genetics make you a little queasy?\nFortunately this kind of birth control or preimplantation genetic diagnostics is not permitted in Austria. But genetic manipulation of embryos is already being carried out illegally in some countries, China among them. Genetic assets are manipulated or embryos are “selected,” which is morally and ethically very controversial. This subject really does make me a bit queasy—there are still many fundamental questions regarding genetics that need to be answered first.\nIf your parents had been able to design you as an embryo, what characteristics would you have wanted for yourself?\nI’m pretty satisfied with the traits I inherited naturally. My parents both lived to a very old age, so I hope they passed that on to me. At least that way I’ll have a few more years to spend with my poor husband once I’ve retired (laughs).\nYour husband is looking forward to your retirement?\nAnd how! Though I’ve already gotten him to make at least one concession, that I’ll still be allowed to think when I’m retired. I’m sure I’ll still be publishing scientific papers as well. After all, I still have all that knowledge inside me. Where else is it supposed to go? Out into the universe?\nThank you very much for the interview!', 'Gene therapy and enhancement\nStephen Napier says the Vatican is concerned about the use of gene therapy technology . . .\nDespite scientific advances in gene therapy and enhancement, the 2008 Vatican document Dignitas Personae (DP) expresses concern for the use of these technologies. First, let’s look at what these terms mean. Numerous diseases have a genetic base, either causing or pre-disposing one to disease. Gene therapy aims to address such abnormalities by modifying the gene/genetic complement that is functioning abnormally.\nAlthough gene therapy trials have not had significant success to date, science is making progress, and the risk-benefit ratio for this research is slowly changing. DP recognizes that gene therapy may progress more rapidly and, with cautious foresight, considers that gene research might not be used only to cure disease, but to enhance our capacities or abilities.\nTo consider adequately the ethical issues, DP makes some needed distinctions. First, there are two kinds of gene-therapy: somatic cell therapy which “seeks to eliminate or reduce genetic defects on the level of … cells which make up the tissue and organs of the body,” and germ-line therapy which “aims instead at correcting genetic defects present in [sperm and eggs] with the purpose of transmitting the therapeutic effects to the offspring of the individual” (# 25). Second, there is an intuitive distinction between therapy and enhancement. As is commonly understood, therapy refers to procedures or practices that aim to cure a pathology or disease. Enhancement (in this context) refers to procedures that aim to improve the capacities or abilities of the person by modifying his or her genome.\nThe ethical issues, then, are that gene therapy seeks to adjust our genetic complement, and the risks of doing so are as yet uncertain. Furthermore, such research on the embryo requires the embryo be engendered through IVF, itself an immoral practice. And lastly, seeking enhancements manifests an attitude of domination of man over man.\nRegarding body-cell therapy, DP renders a positive judgment, saying that “such actions seek to restore the normal genetic configuration of the patient or to counter damage caused by genetic anomalies or those related to other pathologies” (#26). The document gives germline (sex cell) therapy a more cautious judgment because the modifications affect one’s offspring. These risks are unknown. “Because the risks connected to any genetic manipulation are considerable … it is not morally permissible to act in a way that may cause possible harm to the resulting progeny” (# 26).\nGerm-line modification would be done for the sake of future children. For example, the decision to eliminate the gene that causes sickle cell anemia would theoretically produce future children free of this disease. But it might also have serious side-effects. The gene for controlling this type of anemia also protects children against malaria. Efforts at germ-line engineering seek to take control of our genetic patrimony, but we do not yet have the wisdom to do this successfully. Once changes are made in the germ line, they may be very difficult to reverse.\nWith regard to genetic enhancement technologies, one would modify a gene (or have one added) that would confer greater abilities or capacities to a particular individual. Parents who enjoy athletics might wish to have a child who is a speedy runner.\nSuch a plan is highly unlikely to succeed because many of our capacities are poly-genetic (they involve a group of genes manifesting complex interactions with one another) and our most meaningful traits and abilities are not genetically determined but are learned and formed through practice, upbringing, formal learning and environment.\nWhen the President’s Council on Bioethics discussed enhancement technologies, it did not address genetic enhancement, saying that in such cases the relationships and interactions among these genes (and between one’s genes and the environment) are certain to be enormously complex. Isolating all the relevant genetic variants and knowing how to work with them to produce the desired result will therefore prove immensely difficult.\nNevertheless, in the event that such advances are made, DP renders the following judgment: “Such manipulation would promote a eugenic mentality and would lead to indirect social stigma with regard to people who lack certain qualities, while privileging qualities that happen to be appreciated by a certain culture or society; such qualities do not constitute what is specifically human” (# 27).\nThe document goes on to point out that seeking enhancements violates both the principles of justice and charity. Justice is violated because the equality of all humans would be compromised in a culture that had an enhanced and unenhanced class — or one in which certain capacities were favored and lacking them meant lacking full moral status.\nSeeking enhancement violates charity in that at some level seeking to modify oneself manifests a disgust with oneself, a rejection of the finite nature of man. Implicitly, man takes on a domineering role, seeking to rule and control his nature and life. Such is the height of hubris and is contrary to the self-love required to respect every human being, even ourselves.\nIn rendering a negative judgment on these kinds of interventions, DP says that they imply “an unjust domination of man over man” and urges us to “an attitude of care for people and of education in accepting human life in its concrete historical finite nature” (# 27).\nStephen Napier, Ph.D., is a staff ethicist at the National Catholic Bioethics Center. He serves on the University of Pennsylvania’s Institutional Review Board.']	['<urn:uuid:8e0ba19e-abca-47b1-91b6-52add025647f>', '<urn:uuid:60d01886-2aa2-40cf-b24c-de93edc6ffe5>']	factoid	with-premise	long-search-query	distant-from-document	multi-aspect	expert	2025-05-01T22:47:46.423955	11	70	2769
72	outdoor mural painting church artwork protection	Murals can be created outdoors, with artists often working alone or with a few assistants to make the work faster and easier. When it comes to religious buildings, murals can combine various techniques and themes, as exemplified by the Oldham Mural in the Holy Rosary Church, which features a unique combination of mosaic and fresco depicting religious imagery. The protection of such artwork requires official intervention, such as listing by cultural heritage organizations, which can help prevent demolition and enable proper preservation. This is particularly important for religious murals that represent both artistic and spiritual significance.	"['Art Mortimer didn’t exactly plan to become an artist; it was something he stumbled into. He was born in Long Beach, and he says he had a particularly normal childhood, with no real artistic influence.\n“My father was a college math and physics teacher, and my mother was a housewife,” he says. “I think living life, pretty much just the way it presented itself, led me into an exploration of feelings and emotions through representational art. Turns out there were a lot of artistic people in my parents’ families, including my two grandfathers, but I did not really experience that much through them.”\nAlthough he always admired artists and their interesting lifestyles, it was not until college that Mortimer realized he could be one.\n“I became an art major after a failed attempt at physics,” he explains. “In art-history classes, we learned about artists and their lives, and I always wanted to be like them– the guy in the garret in Paris with the smock, beret, goatee and the babes. But I did not think it was possible. Many years later I had matured enough and learned enough to believe that it was possible.”\nHe graduated from Occidental College in Eagle Rock, California, and has since become a freelance artist and art educator.\nMortimer paints scenes of everyday life; many of his acrylics are of beaches, bridges or piers. He is also known for his detailed murals, most of which are historic and representative of a certain city or surrounding areas.\nHe has painted close to 100 murals since 1971, and several of them having been displayed in newspapers, books and films in the United States and across the world.\nRecently, he completed a project that he calls “A Mural in a Weekend” in Twentynine Palms, California. He has also been working at Dodger Stadium, creating murals that celebrate memorable events in the history of the Los Angeles baseball team.\nIn painting, what is the biggest challenge you have faced?\nThe biggest challenge, of many, is the original concept. Particularly in a mural. Without that, all the other challenges are unattainable.\nDo you think about placement before you begin a project, or do you freestyle in the moment?\nI plan out where I am going. In a mural, I plan and design very carefully. In a painting, a rough outline and then let it evolve as it goes.\nIs there a special technique or theme that has become a staple of your art?\nIn murals: historical themes, and a collage approach. In paintings: the intersection between nature and the man-made.\nIs there a process in choosing the materials you will use for your paintings/murals?\nThrough experience, I know what works best for a mural in a specific situation to make the work go smoothly and to make the mural last as long as possible. But some mural projects require special or different materials, so that necessitates a research and learning process to find the best solution(s) for that project. For paintings, I like to work on canvas with paints I am familiar with.\nWhich mediums do you prefer to work with?\nFor murals, artists’ acrylic. For canvases, acrylics and oils.\nDo you prefer working alone or in groups?\nI prefer working alone, but on murals [I] often hire people to assist me to make the work go faster and easier.\nHow has your artwork developed over the years?\nBig question. Very complex answer. Every project or painting is a new challenge and requires me to try something I have never done before. So my work has gotten progressively more sophisticated and challenging– not to mention more complex and informed by all that experience.\nIs there a piece that you favor more than others?\nYes. Always. But it keeps changing, depending on how I feel about my latest projects.\nIs there anything you hope people can take away from your pieces?\nI hope, through my murals, to make people’s daily lives more enjoyable and richer. A historical and beautiful mural becomes part of people’s daily lives. That is a wonderful thing for me. With my paintings, I hope to be able to express feelings and emotions through depicting scenes that people can resonate with and feel a sense of communion with the world they live in and experience.\nIn what type of setting do you work best?\nAlone or with one or two others doing their own thing as well. Mostly outdoors, too.\nAre there any artists that influenced you?\nVan Gogh, Monet, Rembrandt, Toulouse-Lautrec, Winslow Homer, Maxfield Parrish, etc.\nHow has your art shaped who you are today, or who you want to be?\nArt has been the defining element in my life. I have pursued nothing much else, and it has allowed me to develop and expand the sensitivities to and awareness of the world and life around me that were always there. To experience the world through the eyes of an artist is a very profound experience.', 'PRESS RELEASE: Post-war mural of \'dazzling beauty\' in Oldham is celebrated and urgently protected through listing\n10th August 2022\nGovernment adds Oldham Mural masterpiece to national heritage register\nSAVE Britain’s Heritage welcomes the listing at grade II of the Oldham Mural and its home, the Holy Rosary Church in Greater Manchester.\nToday’s decision by the Department for Digital, Culture, Media & Sport (DCMS) on Historic England’s recommendation follows a long-running, high-profile campaign led by SAVE Britain\'s Heritage and the artist\'s great nephew Nick Braithwaite to stop the building being demolished and to save the mural in situ.\nIn its report recommending listing, Historic England gave a string of reasons relating to architectural and historic interest. It said: ""The mural is highly unusual and possibly unique in this country in its striking aesthetic combination of neo-Baroque mosaic and modernist Cubist-influenced fresco inventively applied to traditional Christian iconography in a deeply personal evocation of suffering and redemption.""\nIt also praised ""the transcendent spiritual nature of Christ [...] heightened by the use of glittering mosaic for the figure and golden mandorla, contrasting with the figures of Mary and St John in earthbound, monochrome blue fresco"".\nIt added that it was ""a major work in his oeuvre, much of which has been lost, the quality of execution and craftsmanship is superb, creating a piece of considerable power"".\nThe church, on the edge of Oldham, has been closed since 2017, leaving both building and mural vulnerable to decay and dereliction. In recent days the building has been subject to vandalism – so today’s decision has been urgently awaited.\nThe Oldham Mural, praised by V&A director Tristram Hunt for its “dazzling beauty”, was created by visionary Hungarian artist George Mayer-Marton in 1955 using a rare combination of mosaic and fresco.\nSAVE strongly backed the listing application made in August 2020 by the artist’s great nephew which contained new information by conservators about the quality of the fresco surviving beneath a partial 1980s overpainting, as well as statements from eminent art historians and strong support from the Twentieth Century Society.\nWe also galvanised support from galleries and museums that hold works by Mayer-Marton including the Victoria Gallery in Liverpool and the Glynn Vivian Gallery in Swansea as well as the Imperial War Museum.\nWe also secured direct support from the directors of world-famous art museums including Tristram Hunt at the Victoria & Albert Museum and Gabriele Finaldi at the National Gallery in London, László Baán at Budapest’s Museum of Fine Arts and Harald Krejci at the Belvedere in Vienna.\nAt a joint SAVE & Twentieth Century Society event earlier this year, Clare A.P. Willsdon, Professor of the History of Western Art at Glasgow University, explained the mural’s historical context and argued it should be considered a “Gesamtkunstwerk” – or Total Work of Art – because of the significance of its positioning within the church and the other sacred artworks it contains.\nHenrietta Billings, director of SAVE Britain’s Heritage, says: “This is a fantastic result for Oldham, and modern public art in England. We’re delighted that the mural will now be celebrated and finally given the recognition it deserves. Listing will open up a new chapter for this building and artwork and we look forward to helping the Diocese of Salford to find a new and sympathetic owner.”\nMarcus Binney, executive president of SAVE Britain’s Heritage, says: “The listing averts the possible loss of a major religious work which has been causing huge concern in the art world and beyond.”\nNick Braithwaite, great nephew of George Mayer-Marton, says: ""I am delighted this masterpiece of exceptional significance is finally receiving the national recognition it deserves. I am grateful to everyone who has helped get us here and especially to SAVE Britain\'s Heritage for keeping the mural in the spotlight.""\nMayer-Marton (born Hungary 1897, died Liverpool 1960) was a leading figure in the Viennese art world in the 1920s and 1930s. He and his wife escaped to Britain in 1938, where he began working as a lecturer for CEMA, the predecessor of the Arts Council. In 1952 he was appointed as a lecturer at the Liverpool College of Art. There he established the Department of Mural Art and the UK’s first course in this technique.\nDuring his time at the college Mayer-Marton completed more than 200 oil paintings and was commissioned by the Roman Catholic Church to carry out works at a number of churches in Lancashire and Cheshire, completing numerous frescoes and mosaics, one of which, the Pentecost, now resides in the Metropolitan Church of Christ the King in Liverpool.\nThe Oldham Mural is one of only two ecclesiastical murals by Mayer-Marton that survive in situ, and the only one that incorporates both fresco and mosaic. The Byzantine mosaic method he employed is thought to be its first use in this country.\nThe mosaic crucifixion was originally surrounded by wall paintings depicting the figures of Mary and John the Apostle against a background of various shades of blue. Historical photographs show that the wall painting extended over the entire wall, but in the 1980s the fresco element was painted over.\nNew evidence has concluded that the fresco remains intact under the paint and that it is possible to restore the mural to its original condition.\nNotes to editors:\n3. SAVE Britain\'s Heritage is a strong, independent voice in conservation that fights for threatened historic buildings and sustainable reuses. We stand apart from other organisations by bringing together architects, engineers, planners and investors to offer viable alternative proposals. Where necessary, and with expert advice, we take legal action to prevent major and needless losses. See here for details of our current campaigns.']"	['<urn:uuid:3b841b70-ab46-41da-95af-c3f35e53e79d>', '<urn:uuid:631e0bae-f39e-4eef-b1d0-efdefe23317e>']	open-ended	with-premise	short-search-query	similar-to-document	multi-aspect	novice	2025-05-01T22:47:46.423955	6	96	1771
73	is nonviolence good for defending property	Non-violence does not always protect possession of land or movable property, though practicing it regularly can be a better defense than having armed men. However, non-violence cannot help defend ill-gotten gains or immoral acts.	['Back | Next\nTHE SELECTED WORKS OF MAHATMA GANDHI > Vol. V - THE VOICE OF TRUTH > Part II- Section II: Means and Ends > The law of Human Species\nThe law of Human Species\nThe world is full of Himsa and Nature does appear to be ‘red in tooth and claw’. But if we bear in mind that man is higher than the brute, then is man superior to that nature. If man has a divine mission to fulfil, a mission that becomes him, it is that of Ahimsa. Standing as he does in the midst of Himsa, he can retire into the innermost depths of his heart and declare to the world around him that his mission in this world of Himsa is Ahimsa and only to the extent that he practices it does he adorn his kind. Man’s nature then he is not Himsa, but Ahimsa, for he can speak from experience his innermost conviction that he is not the body but Atman and that he may use the body only with a view to expressing the Atman only with a view to self-realization. And from that experience he evolves the ethics of subduing desire, anger, ignorance, malice and other passions, puts forth his best effort to achieve the end and finally attains complete success. Only when his efforts reach that consummation can he be said to have fulfilled himself, to have acted according to his nature. Conquest of one’s passions, therefore, is not super-human, but human, and observance of Ahimsa is heroism of the highest type, with no room therein for cowardice or weakness.\nYoung India, 24-6-‘26, p. 230\nNon-violence is not a cloistered virtue confined only to the Rishi1 and the cave-dweller. It is capable of being practiced by the millions, not with full knowledge if its implications, but because it is the Law of our Species. It distinguishes man from the brute. But man has not shed the brute in him. He has to strive to do so. This striving applies to the practice of non-violence, not to the belief in it. I cannot strive to believe in a principle: I either believe in it or I do not. And if I believe in it, I must bravely strive to practice it. Ahimsa is an attribute of the brave. Cowardice and Ahimsa do not go together any more than water and fire.\nHarijan, 4-11-‘39, p. 331\nI am not visionary. I claim to be a practical idealist. The religion of non-violence is not meant merely for the Rishis and saints. It is meant for the common people as well. Non-violence is the Law of our Species, as violence is the Law of the Brute. The spirit lies dormant in the brute, and he knows no law but that of physical might. The dignity of man requires obedience to a higher law—to the strength of the spirit. The Rishis, who discovered the Law of non-violence in the midst of violence, were greater geniuses than Newton. They were themselves greater warriors than Wellington. Having themselves known the use of arms, they realized their uselessness and taught a weary world that its salvation lay not through violence but through non-violence.\nYoung India, 11-8-‘20, p. 3\nNon-violence is the law of the human race and is infinitely greater than and superior to brute force.\nIn the last resort, it does not avail to those who do not possess a living faith in the God of Love.\nNon-violence affords the fullest protection to one’s self-respect and sense of honour, but not always to possession of land or movable property, though its habitual practice does prove a better bulwark than the possession of armed men to defend them. Non-violence in the very nature of things is of no assistance in the defence of ill-gotten gains and immoral acts.\nIndividuals or nations, who would practice non-violence, must be prepared to sacrifice (nations to the last man) their all except honour. It is, therefore, inconsistent with the possession of other people’s countries, i. e. modern Imperialism, which is frankly based on force for its defence.\nNon-violence is a power which can be wielded equally by all—children, young men and women or grown-up people, provided they have a living faith in the God of Love and have, therefore, equal love for all mankind. When non-violence is accepted as the Law of Life, it must pervade the whole being and not be applied to isolated acts.\nIt is a profound error to suppose that whilst the Law is good enough for individual, it is not for masses of mankind.\nHarijan, 5-9-‘36, p. 236\nConsciously or unconsciously, we are acting non-violently towards one another in daily life. All well constructed societies are based on the Law of Non-violence. I have found that life persists in the midst of destruction and, therefore, there must be a higher law than that of destruction. Only under that law would a well-ordered society be intelligible and life worth living. And, if that is the Law of Life we have to work it out in daily life. Whenever there are jars, wherever you are confronted with an opponent, conquer him with love. In this crude manner, I have worked it out in my life. That does not mean that all my difficulties are solved. Only I have found that this Law of Love has answered as the Law of destruction has never done.\nYoung India, 1-10-‘31, p. 286\nI claim that even now, though the social structure is not based on a conscious acceptance of non-violence, all the world over mankind lives and men retain their possessions on the sufferance of one another. If they had not done so, only the fewest and the most ferocious would have survived. But such is not the case. Families are bound together by ties of love, and so are groups in the so-called civilized society called nations. Only they do not recognize the supremacy of the Law of Non-violence. It follows, therefore, that they have not investigated its vast possibilities.\nHarijan, 22-2-‘42, p. 48\nScientists tell us that without the presence of the cohesive force amongst the atoms that comprise this globe of ours, it would crumble to pieces and we would cease to exist. And even as there is cohesive force in blind matter so must there be in all things animate; and the name for that cohesive force among animate beings is Love. We notice it between father and son, between brother and sister, friend and friend. But we have to learn to use that force among all that lives, and in the use of it consists our knowledge of God. Where there is Love, there is Life; hatred leads to destruction.\nYoung India, 5-5-‘20, p. 7\nAll the saints of the world, ancient and modern, were each according to his light and capacity a living illustration of the Supreme Law of our Being. That the brute in us seems so often to gain an easy triumph is true enough. That, however, does not disprove the Law. It shows the difficulty of practice. How should it be otherwise with a Law which is as high as Truth itself? When the practice of the Law becomes universal, God will reign on earth as He does in Heaven. We know the earth, and we are strangers to the heaven within us. If it is allowed that for some the practice of love is possible, it is arrogance not to allow even the possibility of its practice in all the others.\nHarijan, 26-9-‘36, p. 260\nThe man who discovered for us law of Love was a far greater scientist than any of our modern scientists. Only our explorations have not gone far enough and so it is not possible for everyone to see all its workings. Such, at any rate, is the hallucination, if it is one, under which I am labouring. The more I work at this Law, the more I feel the delight in life, the delight in the scheme of this universe. It gives me a peace and a meaning of mysteries of Nature that I have no power to describe.\nYoung India, 1-10-‘31, p. 287\nThe sum total of the experience of mankind is that men somehow or other live on. From which fact I infer that it is the Law of Love that rules mankind. Had violence, i.e. hate, ruled us, we should have become extinct long ago. And yet the tragedy of it is that the so-called civilized men and nations conduct themselves as if the basis of society was violence. It gives me ineffable joy to make experiments proving that Love is the supreme and only Law of Life. Much evidence to the contrary cannot shake my faith.\nHarijan, 13-4-‘40, p. 90\nThis would is held together by bonds of love. History does not record the day-to-day incidents of love and service. It only records incidents of conflict and wars. Actually, however, acts of love and service are much more common in this world than conflicts and quarrels. We find innumerable villages and towns flourishing in the world. If the world were always full of quarrel and discord, they could not possibly exist.\nBapu’s Letters to Ashram sisters, (1960), p. 113\nIf we turn our eyes to the time of which history has any record down to our own time we shall find that man has been steadily progressing towards Ahimsa. Our remote ancestors were cannibals. Then came a time when they were fed up with cannibalism and they began to live on chase. Next came a stage when man was ashamed of leading the life of a wandering hunter. He, therefore, took to agriculture and depended principally on Mother Earth for his food. Thus, from being a nomad, he settled down to civilized stable life, founded villages and towns, and from member of a family he became member of a community and a nation. All these are signs of progressive Ahimsa and diminishing Himsa. Had it been otherwise, the human species should have been extinct by now, even as many of the lower species have disappeared.\nHarijan, 11-8-‘40, p. 245\nModern science is replete with illustrations of the seemingly impossible having become possible within living memory. But the victories of physical science would be nothing against the victory of the Science of life, which is summed up in Love which is the Law of our Being. I know that it cannot be proved by argument. It shall be proved by persons living it in their lives, in utter disregard of consequences to themselves. There is no real gain without sacrifice. And since demonstration of the Law of Love is the realest gain, sacrifice too must be the greatest required.\nHarijan, 26-9-‘36, p. 260\nIf we believe that mankind has steadily progressed towards Ahimsa, it follows that it has to progress towards it still further. Nothing in this world is static, everything is kinetic. If there is no progression, then there is inevitable retrogression. No one can remain without the eternal cycle, unless it be God Himself.\nHarijan, 11-8-‘40, p. 245\n1. A Seer']	['<urn:uuid:3ea61476-775c-4ba1-9dcb-a3b874dee507>']	factoid	with-premise	short-search-query	similar-to-document	single-doc	novice	2025-05-01T22:47:46.423955	6	34	1858
75	turkey cooking time per pound and safety precautions	The rule of thumb for cooking turkey is 13 minutes per pound at 350°F for unstuffed turkey, or 15 minutes per pound if stuffed. For food safety, always wash hands with soap for at least 20 seconds before, during, and after preparation. Use separate cutting boards and utensils for raw turkey to prevent cross-contamination. After cooking, refrigerate leftovers within 2 hours as bacteria can multiply quickly between 40°F and 140°F.	"['10. Calculate turkey cooking time and temperature. The simplest way to figure out turkey roasting times is to calculate 13 minutes per pound at 350°F for an unstuffed turkey (that’s about 3 hours for a 12- to 14-lb. turkey), or 15 minutes per pound for a stuffed turkey.\nDo you cook a turkey at 325 or 350?\nRoast in a 325° or 350° (depending on size of bird; see below) oven until thermometer registers 160°. If turkey is unstuffed, tip slightly to drain juices from body cavity into pan. Transfer turkey to a platter. Let stand in a warm place, uncovered, for 15 to 30 minutes, then carve.\nHow many hours does a 16 pound turkey need to cook?\nThe rule of thumb for cooking a turkey is 13 minutes per pound. So our 16-pound turkey was estimated to cook in about 3 1/2 hours. However, some factors like brining the bird, cooking with an empty (un-stuffed) cavity, and leaving the legs un-trussed will contribute to much faster cooking.\nHow long does it take to cook a 15 pound turkey at 375?\nPour the broth into the roasting pan. Roast the turkey for 1 hour. Rotate the pan, reduce the oven temperature to 375 degrees and continue roasting until an instant-read thermometer inserted in the thickest part of the thigh (dont touch the bone) registers 155 degrees , 1 1/2 to 2 hours.\nShould you cover your turkey with aluminum foil?\nJust make sure you uncover the lid about 30 minutes before the turkey’s done roasting so the skin has a chance to get crispy. … Covering the bird with foil mimics what a roaster lid would do — it traps steam and moistness so the turkey doesn’t dry out — all the while allowing the skin to crisp up.\nHow long do you cook a turkey at 325?\nHow Long to Roast a Turkey\n- For one 8- to 12-pound turkey, roast at 325°F for 2¾ to 3 hours.\n- For one 12- to 14-pound turkey, roast at 325°F for 3 to 3¾ hours.\n- For one 14- to 18-pound turkey, roast at 325°F for 3¾ to 4¼ hours.\n- For one 18- to 20-pound turkey, roast at 325°F for 4¼ to 4½ hours.\nShould you wash your turkey?\n“USDA recommends that you do not wash your turkey,” said Wendy Mihm, a director of food safety education at the U.S. Department of Agriculture. “It risks cross-contamination, you can get those turkey juices in and around your sink.” … For example, a 15 pound frozen turkey will need three days of thawing time.\nShould you cook a turkey upside down?\nTraditional turkey methods are prone to overcooking the breast meat or undercooking the dark meat. The benefits of roasting a turkey breast-side down are twofold: The dark meat cooks faster when it’s closer to the heat source, and the juices trickle down for extra-moist breast meat.\nHow long should a turkey rest for?\nTurkeys between 4-6kg should be rested for 1½ hours, and ones from 6-10kg can rest for two hours. Get your turkey out of the fridge 30 minutes before you cook it. You’ll get less shrinkage when it goes into a hot oven.\nIs turkey done at 165 or 180?\nWhile some recipes state that turkey should be cooked to 180 degrees Fahrenheit, the meat is safe to consume once it reaches the 165-degree mark. Cooking the breasts past 165 can result in dry meat, but the dark meat can be cooked to 180.\nIs 375 turkey too high?\nOur Best Turkey Tips\nThe Test Kitchen agrees that 375℉ is the best temperature to cook a turkey, because it’s not too hot, not too cold, and cooks quickly enough to ensure that a juicy, flavorful bird is ready by dinnertime. … Allow your turkey to rest for at least 25 minutes before carving.\nHow long does it take to cook a 20lb turkey at 375?\n- Preparing the bird – Heat oven to 375 degrees. …\n- Cooking the bird – Estimate 12-15 minutes per pound for stuffed turkeys. …\n- Testing for doneness – You can either test by checking the temperature or checking the color of the juices. …\n- Finishing off – Remove bird from the oven.\nWhat’s the rule of thumb for cooking a turkey?\nCooking Time – The rule of thumb for cooking a turkey is 13 minutes per pound. So our 16-pound turkey should have taken about 3 1/2 hours to cook. However, some factors like brining the bird, cooking with an empty (un-stuffed) cavity, and leaving the legs un-trussed will contribute to much faster cooking.\nIs it necessary to put water in the bottom of a roasting pan while roasting a turkey? No. We don’t suggest adding water to the pan since it produces steam, which may cause the turkey to steam-burn. The turkey will generate delicious juices on its own.\nHow often should you baste turkey?\nHow often to baste a turkey. Most recipes will tell you to baste your turkey every thirty minutes. But our rule of thumb is actually every forty minutes, and here’s why. You don’t want to open the oven too many times, or else the whole bird will take much long to cook, and that’s a huge inconvenience.\nHow do I keep my turkey from drying out?\n“When roasting the whole bird, the key is to cook the legs longer than the breast,” Tommy says. “Once the breast is cooked, remove the legs and put them back in the oven. This stops the breasts drying out.”', '(RxWiki News) Extra care in the kitchen can easily minimize the risk of foodborne illness and ensure a happy and healthy family Thanksgiving this year.\nAround 46 million turkeys will be eaten this Thanksgiving. Unfortunately, holiday meals — particularly those featuring turkey — have been linked to foodborne illnesses caused by Salmonella, Campylobacter and Clostridium perfringens.\n1) Separate: Don\'t Cross-Contaminate\nRaw eggs, poultry and meat can spread bacteria to ready-to-eat foods. This is called cross-contamination.\nTo prevent cross-contamination, use separate cutting boards, utensils and plates for raw eggs, poultry and meat. Furthermore, always wash your hands, counters and utensils after touching raw foods, such as turkey, and before starting on other foods.\nMake sure to wash your hands with soap and water for at least 20 seconds before, during and after preparing food, as well as before eating. Furthermore, be sure to wash all surfaces, including your cutting boards, countertops and utensils, with hot, soapy water.\n2) Thaw Your Bird Correctly\nWhen the bird begins to thaw, any bacteria that may have been present before freezing can begin to grow again. The ""danger zone"" for bacteria to grow is between 40 and 140 degrees Fahrenheit.\nThere are three safe ways to thaw food: in the refrigerator, in cold water and in the microwave oven.\nFollow these steps for a safe thawing process:\ni) Immediately after you buy the frozen turkey at the grocery store, take it home and store it in the freezer. Thawing your bird on the kitchen counter, outside or in the garage is a food safety no-no.\nii) When thawing a turkey in the refrigerator, plan to allow it to thaw for 24 hours for each four to five pounds (at 40 degrees Fahrenheit or below). For example, thaw a 16- to 20-pound turkey for four to five days. Be sure to place the turkey in a container to prevent the juices from dripping on ready-to-eat foods.\nIt is important to note that you can keep a thawed turkey in the refrigerator for one or two days before cooking. If you are planning to use cold water or a microwave to defrost the turkey, know that birds thawed in cold water or in the microwave will have to be cooked immediately.\ni) Make sure the turkey is in a leak-proof plastic bag to prevent cross-contamination. This also prevents the turkey from absorbing water.\nii) Submerge the wrapped turkey in cold tap water.\niii) Change the water every 30 minutes until the turkey is thawed.\niv) Allow about 30 minutes per pound to defrost.\ni) Follow the instructions from your microwave\'s manufacturer when defrosting your turkey.\n3) Stuffing Safety\nIt is safest to cook stuffing outside the turkey, such as in its own casserole dish. This also helps ensure uniform cooking.\nIf dressing is cooked inside the turkey, add it just before cooking and use a food thermometer to ensure the stuffing reaches an internal temperature of at least 165 degrees. Bacteria can survive in stuffing that has not reached this temperature, which could result in foodborne illness.\nIt is best to wait 20 minutes after removing the turkey from the oven before removing the stuffing — this allows the stuffing to cook a little longer.\n4) Cook to the Right Temperature\nTurkey is ready for consumption only after it has been cooked to a temperature of 165 degrees. The best way to check is by using a meat thermometer and checking in multiple spots to ensure the turkey has been cooked thoroughly.\nThe cooking time will depend on the weight of the turkey.\nTo ensure the turkey has reached a safe internal temperature of 165 degrees Fahrenheit, insert a food thermometer into the center of the stuffing, the thickest portions of the breast, and the innermost parts of the thigh and wing.\n5) Put Away Leftovers\nMany families leave out a buffet of food for hours to allow family members to get seconds or wrap up doggie bags, feed late-arriving relatives, or simply because they\'re exhausted from cooking and too stuffed to begin putting food away.\nThe rule of thumb is to refrigerate perishable food within two hours. This is because bacteria can multiply very quickly if left out in the “danger zone,” which is between 40°F and 140°F.\nThe US Department of Agriculture (USDA) and the US Department of Health and Human Services have released a range of resources — from smartphone apps to a ""meat and poultry hotline"" — to help guide consumers safely through the holiday season. The meat and poultry hotline can be reached at 1-888-674-6854. The app can be found under the name ""FoodKeeper App."" The app can help you decide what is safe to use and what you should throw away. These resources also offer guidance on safe ways to keep your leftovers.\nWritten by Digital Pharmacist Staff']"	['<urn:uuid:e7a943dc-9c46-4fb5-a2b5-e496d63d58cf>', '<urn:uuid:ee109ad8-a07b-40e3-9ff3-117293178f1b>']	factoid	with-premise	short-search-query	similar-to-document	multi-aspect	novice	2025-05-01T22:47:46.423955	8	70	1738
76	what ancient building inspired construction design taj mahal india	Humayun's tomb, completed in 1572, was the first garden-tomb in India and inspired many architectural wonders, including the iconic Taj Mahal.	"['Collected by Katherine Jones\n3920 Zermatt, Switzerland\nHoused in an old chalet in the hamlet of Finland, Restaurant Findlerhof has one of the best outdoor patios around. It’s spacious and sunny—and overlooks the Matterhorn. The restaurant itself is rustic yet comfortable, offering a mix of...\nMathura Road Opposite Dargah, Nizamuddin, New Delhi, Delhi 110013, India\nWant a sneak peek of the Taj Mahal? Completed in 1572, Humayun\'s tomb was the first garden-tomb in India and inspired many architectural wonders, including the iconic Taj Mahal. The best view is from directly outside the main entrance, where the...\nCalle Lázaro Cárdenas, 63732 Bucerías, Nay., Mexico\nFor a huge selection of fruits and vegetables, artwork and handmade clothes and accessories, visit Puerto Vallarta\'s Old Town Farmers Market and Tianguis Cultural. Participating vendors must live or work within 50 kilometers of the markets, so all...\nSeoraksan-ro, Sokcho-si, Gangwon-do, South Korea\nFall into Korean nature. Brilliant warm colors bring the last bit of heat to a country that is bundling up for the winter. Intense hues of orange, red and yellow explode from the rocky terrain. Go in complete hiking gear for the rough and ready...\nBeyazıt Mahallesi Çadırcılar Caddesi istanbul sahaflar çarşısı No.16-18-19-22-23, Beyazıt Mh., beyazıt, 34126 Fatih/İstanbul, Turkey\nBook lovers and bazaar hunters will revel in foraging through the Sahaflar Çarsısı (Beyazit Book Bazaar) for new titles, secondhand books, historical maps, the Quran (in various languages), ancient texts, and other rare finds. The bazaar, between...\nSultan Ahmet Mahallesi, Ayasofya Meydanı, 34122 Fatih/İstanbul, Turkey\nWalk into Hagia Sophia (Aya Sofya) and look up to the heavens to see why so many conquerors and their respective religions claimed this basilica turned mosque turned museum as their own. Visitors will swoon over the Byzantine gilded mosaics,...\nBüyük Valide Han Çakmakçılar Yoluşu No:31 / 82, Mercan Mahallesi, 34116 Fatih/İstanbul, Turkey\nVisiting the 17th-century Büyük Valide Han in Eminönü is my all-time favorite experience in Istanbul. It\'s an Ottoman inn that accommodated traveling merchants over 350 years ago and also stored the Oriental and European wares from the wooden...\nRJ SH 12, kishor Nagar, Rajsamand, Rajasthan 313333, India\nI arrived at the Deogarh Mahal at dusk, when the palace lights illuminated the architectural details of the ""Abode of the Gods."" Deogarh is a 16th century Mewar palace that has been converted to a heritage hotel and remains partially occupied by...\nSkyline, Queenstown 9300, New Zealand\nThe most iconic building in New Zealand is Auckland’s Sky Tower. More than 1,000 feet tall, it’s the highest in the Southern Hemisphere. After a 40-second ride to the top, you\'re treated with glass floors, a revolving restaurant, and views that...\nViking Heliskiing specializes in heli-skiing trips in the north of Iceland. We are headquartered in Siglufjörður and Tröllaskagi (Troll peninsula) is our main heli-skiing area, a world class skiing area with thousands of slopes waiting for their...\nStalheimsvegen 131, 5715 Stalheim, Norway\nCentrally located in the fjord region of Western Norway, the 124 room Stalheim Hotel has a tremendous view and a wonderful history. This isn\'t an intimate hotel experience, meaning that with that many rooms and this being the perfect central...\nKathmandu 44600, Nepal\nTourists call it the “Monkey Temple,” owing to the clans of rhesus macaque wandering through the grottos and recesses of this ancient shrine. The monkeys climb where they please, siblings squabble, parents scold and protect—a parallel simian...\nEverest Base Camp Trail, Khumjung 56000, Nepal\nComing upon this sign which stood in front of this view was a chilling moment. It was the moment I realized where I was, as I trudged along the trail to Everest Base Camp. There\'s nothing better than the feeling of being surrounded on all sides by...\nJl. Badrawati, Kw. Candi Borobudur, Borobudur, Magelang, Jawa Tengah, Indonesia\nWhen you visit Java it\'s very easy to forget that the region has been ruled by Buddhist and Hindu kingdoms, because of the strong presence of Islam on the island today. However, visiting Central Java allows you to explore the ruins of these...\nBorobudur, Magelang, Central Java, Indonesia\nA sunrise amidst the ancient monument of Borobudur is a loved experience. However, what I found even more enchanting and surreal was enjoying a sunset in this quiet place. At the wee end of our evening, we found ourselves alone with the Stupas,...\nBorobudur, Magelang, Central Java, Indonesia\nVisiting the newly reopened top level of Borobudur at sunrise is worth everything it takes to get there. I imagine people who scale a mountain feel much the same, and symbolically, the summit of this 8th century Buddhist shrine is the mountaintop....\n- 1 Travel News The World’s Fastest Growing Tourist Destinations Aren’t Where You Think\n- 2 Weekend Getaways This Coastal California Getaway Is the Big Sur You Haven’t Heard of . . . Yet\n- 3 Travel News 10 Reasons to Go to London This Fall\n- 4 Travel News Here’s Why It Seems Like Everyone Is Going to Portugal Right Now\n- 5 Travel News Greece Bans Anyone Over 220 Pounds From Riding Santorini’s Donkeys']"	['<urn:uuid:d5b3d107-5e44-4a1f-9831-f37cea8e5367>']	factoid	direct	long-search-query	distant-from-document	single-doc	novice	2025-05-01T22:47:46.423955	9	21	838
77	How does Tim Kloss contribute to the development of poetry at the weekly gatherings at Linneman's?	Tim Kloss organizes weekly open mics at Linneman's with featured readers. He actively looks for new voices to schedule as featured readers, welcomes everyone with his greeting and smile, provides insightful comments on poems, and performs poetry himself, including a memorable rendition of Walt Whitman's 'Out of the Cradle Endlessly Rocking'.	['Margaret Rozga is the newly appointed Poet Laureate of Wisconsin. Rozga, a poet, civil rights activist, professor emerita at UW-Waukesha and a regular contributor to the NNS Community Voices column, writes about the Milwaukee poetry community that inspires her.\nI begin my term as Wisconsin Poet Laureate energized. I found that energy where I often do, at a Milwaukee poetry venue. I’d been to three of them recently. Woodland Pattern, Linneman’s, and the Jazz Gallery, all in Riverwest, are among key gathering spots where Milwaukee’s vibrant poetry community thrives. The creativity that happens when people gather at these venues pulls me in and helps me wake up ready for the day’s writing, meetings, phone calls and errands.\nBefore heading out to an evening poetry event, I sometimes hesitate. Not tonight, I tell myself, not this late, not in this rain or this cold, not by myself when I may not know anyone there. Then my need to hear empowering words overcomes the alternative: yet another newscast about undermining fair elections and civil rights, and about building walls of one kind or another. I’m of the mind of the Robert Frost poem that begins, “Something there is that doesn’t love a wall.” The arts offer a way not to ignore these issues, but to address the positive, to build the inclusive community we need.\nLast week, feeling the need for an inclusive community and affirming words, I headed to Riverwest’s Jazz Gallery. The MC at the PENtastic open mic, hosted by Still Waters Collective, was starting the evening program as I walked in. From her position on stage, she greeted me, “Hello there. So glad you came.” I’m not sure I knew her, but that didn’t matter. Everyone was welcome.\nBefore the reading began, she had us write on this question: “What is Black?” Everyone, black and non-black, set to work. Several eager volunteers then read their drafts, including black and white poets from Milwaukee and one from Racine. During the first set of the open mic, readers included spoken word artists and poets who read from their books or cell phones. At the break, we were told to get to know someone new. I found that two young women sitting near me were from Sheboygan and came after seeing news of this event on Facebook. They said they didn’t know of any poetry events in Sheboygan, so I gave them the name of a poet friend who organizes poetry events there. “Friend her on Facebook,” I said. I’ll tell her to expect to hear from you.”\nThis particular evening serves as a model of how we create community. Welcome everyone. Assume that everyone has creative potential. Create space where that potential can find room to stand up and be heard. Welcome different styles. Create a positive tone, even as we speak to perplexing and distressing issues.\nA similar model can be found Monday nights at Linneman’s. Tim Kloss organizes these weekly open mics with a featured reader. He lives and breathes poetry and the visual arts — drawing, painting. Always on the lookout for new voices, he schedules them in as featured readers. Everyone is welcome, and all are warmed by his greeting, his smile, and his insightful comments on the poems. His own annual turn as the featured reader is not to be missed. His performance of Walt Whitman’s “Out of the Cradle Endlessly Rocking” brought that poem to life and awed the audience. It would make a fan out of even the person most reluctant to engage with poetry.\nWoodland Pattern Book Center brings national poets to town for readings and workshops and celebrates Milwaukee poets. The center opens its doors to events like the launch of the poetry chapbook anthology “Where I Want to Live: Poems for Fair and Affordable Housing,” a project of the March On Milwaukee 50th anniversary planning committee. Black, brown, and white poets, gay and straight poets, middle school, high school, and poets of all ages, including some in their 70s participated. The event was not only about imagining an inclusive Milwaukee, but it also stood as an evening when that reality was palpable.\nOn Saturday afternoon, Jan. 26, Woodland Pattern will serve as the venue for the official passing of the Wisconsin’s Poet Laureate’s torch from Karla Huston to me. How very appropriate this setting will be.\nI studied poetry in college and graduate school. I know iambic pentameter and anaphora, lineation and prose poetry as concepts. What I learned in school provides a solid base for the work I’ll do as Wisconsin Poet Laureate, promoting poetry throughout Wisconsin. What I learned as a practicing poet adds depth. What I learned as a participant in Milwaukee’s poetry community will help bring it all to life.']	['<urn:uuid:83a4a19c-0b44-4af9-ada0-6ad52de4fea9>']	factoid	direct	verbose-and-natural	distant-from-document	single-doc	expert	2025-05-01T22:47:46.423955	16	51	793
78	street redesign impact air pollution safety	Street redesign has significant impacts on both safety and air pollution levels. For safety, implementing protected bike lanes, reducing driving lane widths to 10 feet, and improving sidewalk infrastructure makes streets safer for all users. More cyclists on the road increases visibility and driver awareness, while separated bike lanes reduce cycling injuries. For air pollution, replacing short vehicle trips with walking or cycling can substantially reduce traffic-related air pollution. In the Greater Toronto and Hamilton Area alone, current traffic-related pollution causes about 700 early deaths and 2,800 hospital admissions annually. One study in the Midwestern United States found that replacing vehicle trips of eight kilometres or less with active travel could generate $3.6 billion in air quality health benefits.	['Envisioning a Safer Street\nYour street doesn’t feel safe. How could you change it to make it better? You don’t need a traffic engineering degree to come up with workable solutions that you can share with your neighbors, elected officials, and agency staff.\nLet’s start with the basics: Streets and sidewalks are asphalt and concrete, but they’re not set in stone. They’re public space, and they should accommodate everyone’s safety and accessibility needs. In reality, they often don’t. But: how our cities use that public space is a policy decision, and we can change it.\nBelow we’ll outline a fun, engaging way to explore and visualize options for making a street safer and more accessible using Google Streetview and a free tool called Streetmix.\nStep One: Get the facts.\nPull up your street in Google Streetview, or go out and take some photos. If you can do so safely, bring a tape measure and get some numbers.\nKey questions to answer:\n- How many driving lanes are there? Roughly how wide are they?\n- How many parking lanes are there? Roughly how wide are they?\n- Are there bike lanes? Roughly how wide are they?\n- Sidewalks? Roughly how wide are they?\nIf you like maps and databases, you can find all of this information (and a LOT more) in DDOT’s Roadway Centerline Database map tool.\nStep Two: Visualize better options.\nTake your numbers from step one and open up Streetmix.net.\nStreetmix lets you move and resize the elements of your street by dragging and dropping the various elements. It’s pretty intuitive. If you’ve gotten this far, you’ll be able to figure it out. Start by mocking up your street as it is now. Save it so you can refer back. Now, start moving things around. What happens if you replace a parking lane with a bus lane? Widen the sidewalks? Add a protected bike lane?\nExplore some options, and invite your friends and neighbors to do so as well.\nThis video offers a great explanation of a “Road Diet” which is common way to make more space for biking and walking on a street, and may give you some ideas:\nStep Three: Reality Check\nThere’s no single or linear way of looking at a street and figuring out how to improve it. While it’s important to envision something radical, there are some constraints and minimum requirements to consider, some of these are more flexible than others. Take a look at your Streetmix designs and make sure they’re in line with these guidelines:\n|Preferred width||Minimum Width||Notes|\n|Standard Bike Lane||6 ft||5 ft|\n|Sidewalk||6+ ft||5 ft|\n|One way protected bike lane||7+ ft||5 ft||Great protected bike lanes are wide enough to comfortably ride at speed, to allow safe passing, and to ride next to someone to carry on a conversation.|\n|Two way protected bike lane||12+ ft||8 ft|\n|Driving Lanes||10 ft (11 ft max)||10 ft||Wide driving lanes have no place in an urban environment because they encourage speeding. Driving lanes should be reduced to 10’, especially on multi-lane roads, to make room for other street users.|\n|Parking Lane||7-9 ft||7 ft||Narrower for cars, wider for truck loading zones.|\nStep Four: Consider scope and timeline\nRebuilding an entire street to expand sidewalks and add high-quality protected bike lanes can be transformative when done right. Sometimes ripping up the whole streets and starting over is the best way to make a street work for its most critical needs. But doing so can also take a decade of planning, engineering and construction.\nFor quicker results, we can leave the curbs in place and redesign the space between them. Many streets are overbuilt—that is, there are too many, or too wide lanes for driving and parking. Removing or narrowing driving lanes and removing car parking frees up street width for new protected bike lanes, bus platforms, street cafes, and sidewalk extensions built on top of the existing asphalt. See the Road Diet video above for more details. Projects like this are less expensive and easier to execute, so they can be completed on a shorter timeline (as little as a year).\nMore Detailed Reading: Design Guides & Resources\nFor inspiration on great street design or more details and guidance on more complicated things like intersection design, explore these resources:\n- Urban Bikeway Design Guide – NACTO\n- Urban Street Design Guide – NACTO\n- Montgomery County Bicycle Facility Design Toolkit\n- Separated Bikeway Planning & Design Guide – MassDOT\n- Intersection Design\n- Choosing the Right Bike facility\n- DDOT’s Roadway Centerline Database – a comprehensive database of information about DC’s streets block by block. Look here for street widths, lane count, traffic counts and much more.\nEmail us at firstname.lastname@example.org or find us on Twitter, Facebook, or Instagram at @WABADC.', 'Active Travel Factsheet\nInvest in active travel to create healthy, green and just communities\nThe COVID-19 pandemic has made many of us appreciate the need for more space in the public domain for pedestrians and cyclists.\nWith governments considering investments to kick-start our economy, it is a good time to consider the health, social and environmental benefits that could result from investments in active travel.\nActive travel is any form of travel that involves physical activity such as walking, cycling or blading. Because active travel allows us to accomplish two goals with one action, it is easier to fit into our schedules. We can get the exercise we need while commuting to work or running errands. Active travel is good for our health, for our communities and for the planet.\nActive travel improves health by increasing physical activity\nThe health benefits of physical activity are well known. It can reduce the risk of over 25 chronic health conditions, including heart disease, breast cancer, colon cancer, and Type 2 diabetes. One long-term study found that people who cycle three hours per week reduce their risk of an early death by 28%, while another found that those who walk 29 minutes per day, seven days per week, reduce their risk of an early death by 22%. Physical activity also improves mental health because it can improve self-esteem, sleep and mental faculties, reduce depression, anxiety and stress, delay dementia, and reduce dependence on drugs and alcohol.\nActive travel needs to be safe\nFewer cyclists are killed or seriously injured when more people cycle in a community. This is likely because cyclists are more visible and drivers are more aware of them when there are more of them. Separated bike lanes reduce injuries to cyclists as well, while also encouraging more people to cycle because it feels safer to them. Pedestrians are safer when vehicle speeds are lower, they are separated from traffic, and they are more visible to drivers.\nActive travel can improve health by reducing air pollution\nTraffic-related air pollution is a serious concern in Canada. In the Greater Toronto and Hamilton Area alone, it causes about 700 early deaths and 2,800 hospital admissions each year. Several studies suggest that air pollution in our communities can be reduced substantially when short vehicle trips are replaced with walking or cycling. One U.S. study estimated that $3.6 billion in air quality health benefits and $3.75 billion in physical activity health benefits could be produced each year by encouraging 31.3 million people living in the Midwestern United States to eliminate all vehicle trips of eight kilometres or less, with half of those trips replaced by cycling.\nClimate change is already harming the health of Canadians\nThe physical and mental health of Canadians is already being harmed by climate change. In different parts of the county, climate change has increased the frequency and intensity of floods, wildfires, hurricanes, ice storms, and heat waves over the last several decades. These events have exposed millions to extremely high levels of toxic air pollution, forced hundreds of thousands of Canadians to evacuate their homes, and left hundreds of thousands without power for extended periods. Climate change is also melting permafrost in the far North, increasing sea levels on three coast lines, and extending the range of vector-borne diseases such as Lyme disease.\nWhile climate change affects everyone, it has a greater impact on some. Young children, older Canadians, and people with pre-existing health conditions are more sensitive to heat waves and wildfire smoke. Indigenous Peoples in Northern communities can experience greater food insecurity as melting permafrost and changes in plant and animal populations disrupt their access to traditional food sources. In addition, people who live on lower incomes may not have the resources to protect themselves, or recover from, extreme weather events such as heat waves and floods.\nActive travel can reduce greenhouse gas emissions\nThe international community has concluded that all countries must reduce greenhouse gas emissions by 45% by 2030 and to zero by 2050 if we are to avoid catastrophic levels of global warming. The transportation sector is responsible for about one quarter of Canada’s greenhouse gas emissions. Several studies have found that we could substantially reduce those emissions by investing in active travel. For example, a California study estimated that an ambitious cycling-focused strategy could reduce greenhouse gas emissions from passenger vehicles by 8% by 2040.\nThe built environment needs to support active travel\nThe design of communities shapes the way people travel. Studies have found that people walk and cycle more - and drive less - when their neighbourhoods have the following characteristics:\n- Fairly high population or job densities - Neighbourhoods with higher job or population densities support local businesses and efficient transit service which encourages walking and cycling.\n- A rich diversity of land uses - People will walk and cycle more when their neighbourhoods have a variety of stores, restaurants, and community services located within close proximity to their homes.\n- Supportive street designs - People will walk more when streets are designed in a grid pattern that makes it easy and efficient to reach local destinations; when there are sidewalks, crosswalks, good street lighting, and street furniture to make it safe, easy and pleasant to do. People will cycle more if there are separated bike lanes or safe bike paths.\n- Transit stops within a short distance - People will walk or cycle to transit stops if those stops are less than 10 minutes from their homes or workplaces.\nActive travel can reduce health inequities\nA number of groups within Canada – such as lower-income populations, newcomers, minorities, Indigenous Peoples, and people with health challenges – experience higher rates of illness, chronic diseases, and premature deaths because of social disadvantages. Neighbourhood design has a greater impact on these groups because they are less likely to drive cars and more likely to rely on local services and public transit. By ensuring that lower-income neighbourhoods have access to stores and restaurants, well-maintained sidewalks, traffic lights, separated bike lanes and efficient transit service, we can create more equitable communities that are safer and healthier for everyone.\nA study by energy analysts has estimated that 18,000 jobs could be created in communities across the country if $2 billion of federal funding were directed at active travel infrastructure such as separated bike lanes and sidewalks. This investment would create construction jobs and provide economic opportunities for smaller communities, while also reducing air pollution and GHG emissions. It could also make our communities healthier and more equitable, particularly if lower-income neighbourhoods were prioritized for these investments.\nRaise your voice to call for greater investments in active travel to create healthy, green and just communities.\nLast modified: February 19, 2021']	['<urn:uuid:aa13010a-d87d-4bd2-b2df-d61818aaf9c5>', '<urn:uuid:7402a9bd-f7b3-40f7-99b1-5ee193d4407e>']	open-ended	direct	short-search-query	similar-to-document	multi-aspect	expert	2025-05-01T22:47:46.423955	6	119	1915
80	data analysis approach subjective objective comparison studies	The approach to data analysis differs between methods - qualitative data analysis is subjective and holistic while quantitative data analysis is objective and focused. This is reflected in how confirmation bias particularly affects qualitative studies that require more subjective interpretation of data, versus quantitative studies that rely more on mathematical and statistical analysis.	['“The real voyage of discovery consists not in seeking new landscapes but in having new eyes.” – Marcel Proust\nWhat is Confirmation Bias?\nConfirmation bias is our unintentional tendency to seek or interpret information in ways that confirm what we already think or believe. Confirmation bias is sometimes called my-side bias or confirmatory bias.\nConfirmation biases are common. We all have them.\nIn some ways, confirmation biases are useful because they help us to quickly filter and categorize the information flood we face every day. But confirmation bias can also reinforce misperceptions that lead to poor decision making based on incomplete, misleading or wrong information.\nIn some cases, confirmation bias can be harmless, such as for the runner who believes that eating a bagel for breakfast will help her run better. She will remember speedy post-bagel workouts and forget those slower runs.\nBut confirmation bias can also be harmful or destructive. The man who considers his unemployed brother’s television viewing habits as evidence that all unemployed people are lazy is damaging to their relationships as well as unfair to the unemployed people he encounters.\nAnd confirmation bias can be devastating to consequential decisions. Considering information that supports the idea of a business merger and discounting information that suggests that the merger is a bad idea could lead to a ruinous decision.\nGive This a Try\nIn 1960, Peter Wason, a cognitive psychologist at University College, London, devised a series of experiments in which he asked participants to identify a rule about three numbers.\nGive it a try yourself. The numbers are 2, 4, 6. Now, what do you think the rule is?\nParticipants in the study were allowed to give examples of their idea of the rule, which the researchers would tell them was correct or not.\nWhat numbers did you use to test your theory about the number rule?\n8, 10, 12? Yes, those numbers conform to the rule.\n34, 36, 38? Yes, those numbers also conform to the rule.\nIn fact, most Wason’s experiment participants thought they had the problem solved after just a few examples that “proved” their idea that the rule was even numbers. Very few gave any examples of other numbers to disprove their hypothesis.\nIf your theory is that the rule is even numbers, you would be wrong. The rule is actually ascending numbers. The series 1, 2, 3 would also follow the rule, as would 723, 900, 4,000. If you had asked if 10, 8, 6 followed the rule, the researchers would have told you that no, it did not.\nThis experiment is a classic example that demonstrates how confirmation bias can lead to wrong conclusions.\nConfirmation Bias in Marketing Research\nConfirmation bias can be a problem in interpreting quantitative data but is a particular bias to watch out for in qualitative research. Focus groups, interviews and other forms of qualitative research is interpreted differently than the numbers from a survey. The researcher must filter unstructured data, sort and classify to identify trends and themes. The qualitative researcher must question and verify conclusions, ensuring that their own beliefs are not influencing the research outcome.\nThe fact that everyone is prone to confirmation bias is one reason that qualitative research, in particular, is best conducted by an outside researcher, rather than by an in-house researcher. Being a part of an association or company, familiar with the thinking, preferences and hopes of that organization’s leadership as well as part of the organization’s culture, creates a filter through which the researcher will search for information and interpret information once it is found.\nExamples of Confirmation Bias\nThe Wrong Pricing Conclusion\nI had a client who had conducted in-house research to determine the problem with slow sales of a bundle of digital product downloads. They believed that pricing for the product was too high and, indeed, their survey research using a standard price sensitivity meter confirmed that their target customers thought that the product was too pricey. They adjusted their offer, creating an even more generous bundle of downloads. But they were baffled when rather than solving their sluggish sales problem, sales decreased.\nI conducted interviews with target customers about the product and pricing. Indeed, the problem was not the price of the product, but the large number of downloads included in the price. The target customers said they would never use so many downloads before they expired and so didn’t want to pay for something they wouldn’t use. As I explained it to the client, it would be like offering a terrific sale on milk as long as you purchased 50 gallons. Who would buy 50 gallons of milk since it would go sour before you could drink it all?\nBarbara is obsessively punctual. In fact, it drives her crazy when people are late and this is putting a strain on her marriage because she believes that her husband Mark is always late. “He is always at least five minutes late. Always.”\nBarbara’s therapist asked Barbara to keep a written record for a week of when Mark was supposed to leave, arrive or do something he promised to do. Barbara thought it would be a fun game and provide written proof the next time she confronted Mark about his tardiness.\nShe was surprised when at the end of a week she had recorded 16 situations when Mark was, in fact, on time or even early leaving for work, picking up their daughter from daycare or meeting her at the car repair place to pick her up. He was only late once during the week. Barbara realized that she had been stewing on the few times that Mark was late and not even noticing when he was on time or early.\nGroupthink can contribute to confirmation bias. When everyone on a work team agrees with everyone else, playing follow-the-thought-leader or avoiding conflict by just keeping quiet when you have a conflicting opinion, you’re contributing to others’ confirmation bias.\nI often saw this at the advertising agencies I worked with, particularly when it came to creative campaigns. Account teams would pile on and agree with a direction\nHow to Avoid Confirmation Bias\nAlthough self-confidence is a valuable quality in the workplace, humility and a healthy dose of self-doubt could save you from the pitfalls that confirmation bias can cause. Don’t always be so sure that you are right and the other side is wrong. Think about Wason’s study and try to prove your ideas or your theory are wrong.\nWhen facing a decision, be honest with yourself about your motives to take a particular action. For example, if you’re anxious to jump on a recommended stock buy and see all the signs pointing to the idea that it’s a good investment, indulge in some self-reflecting before making the buy. Is your desire to get some quick returns clouding your ability to judge fairly the advisability of the purchase? This is the time to have a structured analysis plan in place to avoid making bad decisions.\nHere are some questions to ask when it’s time to make a decision on your beliefs.\n- How do I know I am correct?\n- Have I thoroughly looked at sources and information that are contrary to what I believe?\n- Have I evaluated this information with an open mind?\n- How do my personal views influence how I am viewing this information?\n- How would someone with a different view on this issue interpret this information?\n- How can I broaden my pool of knowledge to include diverse points of view?\nAnd finally, listen to the skeptics of your precious ideas. They provide a counterbalance to your ideas on the issue you are facing. Ask them their views and what shaped those views.', 'Difference Between Qualitative vs Quantitative Data\nThe analysis in any research project involves summarizing the mass of information that has been collected and presenting the end results in such a way that it communicates the foremost necessary findings or options. For example, if a vesture complete is making an attempt to spot the most recent trends among young girls, the complete can initially reach young girls and raise their queries relevant to the analysis objective. Once collecting this information, the vesture can analyze the data to spot patterns – for example, it should discover that almost all young girls would really like to examine additional sort of jeans. There are many alternative data analysis ways, but the two most commonly and majorly used are Qualitative and Quantitative Analysis.\nHead to Head Comparison between Qualitative vs Quantitative Data (Infographics)\nBelow are the top 8 differences between Qualitative vs Quantitative Data:\nKey Differences between Qualitative vs Quantitative Data\nOne variety of data is objective, up-to-the-point, and conclusive. The other variety of data is subjective, interpretive, and explained easily. Quantitative data can be counted, measured, and expressed using numbers. Qualitative data is descriptive and abstract and may be classified on traits and characteristics. The key variations between Qualitative and Quantitative data are as prescribed below:\n- The data type, in which the classification of objects is based on attributes (quality) is called qualitative data. The type of information that might be counted and expressed in numbers and values is called quantitative data.\n- Quantitative data relies on numbers. Simple arithmetic or additional advanced applied mathematics analysis is employed to get commonalities or patterns within the information. The results are usually seen in graphs and tables. Applications like Excel, SPSS, or R can be accustomed to calculate things like Average scores, range of times a specific answer was given, the correlation between two or additional variables, dependability, and validity of the results.\n- The approach to the inquiry within the case of qualitative data is subjective and holistic, whereas quantitative information has an associative objective and targeted approach.\n- Qualitative data determines the depth of understanding, whereas quantitative data ascertain the amount of prevalence.\n- In qualitative data, the sample size is small and is drawn from non-representative samples. Conversely, the sample size is massive in quantitative data drawn from the representative sample.\n- Qualitative data develops initial understanding, i.e. it defines the matter. In contrast to quantitative data, which recommends the ultimate course of action.\n- In the Qualitative kind, verbal data is collected. Conversely, in the quantitative kind, measurable data is gathered.\n- Qualitative analysis and data is conducted with the aim of exploring and discovering concepts utilized in the continuous processes. As hostile quantitative analysis data, the aim is to look at cause and result relationships between variables.\n- Elements utilized in the analysis of qualitative research are words, pictures, and objects whereas that quantitative analysis are of numerical information.\n- Lastly, qualitative data develops the initial understanding whereas, quantitative data recommends a final course of action.\nQualitative VS Quantitative Data\n|Meaning/Definition||This type of data analysis is a technique of inquiry that develops an understanding of human and social sciences, to seek out the means individuals think and feel.||This type of data analysis is a technique that is used to generate numerical information and hard facts, by using applied mathematics, logical, and mathematical technique.|\n|Approach||Qualitative may be a variety of subjective analysis that is more involved with non-statistical data that cannot be computed.||Quantitative may be a variety of objective analysis that quantifies data.|\n|Sample||Sample is small and is non-representative of the whole population||The sample is massive and can be generalized to hide the whole population.|\n|Data||Typical data embrace color, gender, nationality, religion, and plenty of additional.||Typical data embrace measurable quantities like length, size, weight, mass, and plenty of additional.|\n|Analysis||The analysis is employed to grasp why an exact development happens.||The analysis is bothered by what number or what quantity an exact development happens.|\n|Data Type||Qualitative data is text-based.||Quantitative data is number-based.|\n|Collection Method||Collected using interviews, written documents, observations.||Collected using surveys, observations, experiments, and interviews.|\n|Results||Results are simply aggregated for analysis and simply conferred.||Understanding of what individual variation means; deepening understanding, insights.|\n|Perceived Quality||It can be perceived as biased, inevitable, or lateen to get sure results.||Offers credibility of an associate outsider creating an assessment.|\nQualitative vs Quantitative Data Comparison Table\nLet us discuss the top comparison between Qualitative vs Quantitative Data:\n|Hypothesis||Tentative, Evolving, supports a specific study.||Specific, testable, explicit before a specific study.|\n|Sampling||Purposive: Intent to pick out “small”, not essentially representative, sample so as to induce in-depth understanding.||Random: Intent to pick out “large”, representative sample so as to generalize results to a population.|\n|Research Setting||Controlled setting not as necessary.||Controlled to the degree potential.|\n|Approach to Inquiry||Subjective, holistic, process-oriented||Objective, focused, outcome-oriented.|\n|Data Interpretation||Conclusions are tentative (can change), reviewed on an ongoing basis, conclusions are generalizations. The validity of the interferences/generalizations is the reader’s responsibility.||Conclusions and generalizations formulated at the end of the study stated with a pre-determined degree of certainty. Interferences/generalizations are the researcher’s responsibility.|\n|Design and Method||Flexible, specified only in general terms in advance of study Non-intervention, minimal disturbance, all descriptive – History, Biography, Ethnography, Phenomenology, Grounded Theory, Case Study. Consider many variables, small groups.||Structured, inflexible, specified in detail in advance of study Intervention, manipulation, and control Descriptive Correlation, Casual-Comparative, Experimental. Consider a few variables, large group.|\n|Measurement||Non-standardized, narrative (written word), ongoing||Standardized, numerical (measurements, numbers), at the end.|\n|Statistical Analysis||Statistical Analysis in Qualitative data is a bit difficult to achieve than Quantitative data.||Statistical analysis in Quantitative data is easier to achieve than Qualitative data.|\nThe main difference between qualitative and quantitative data is that qualitative data is descriptive, while quantitative data is numerical. Usually, statistical analysis is easier with quantitative data than qualitative data. Statistics, social sciences, computing are some disciplines that use this type of data. You must consider that there are qualitative shades in the quantitative instrument, but not to be confused with qualitative, precisely for the reasons that have been specified so far.\nThis is a guide to the top differences between Qualitative vs Quantitative Data. Here we also discuss the key differences with infographics and comparison tables. You may also have a look at the following articles to learn more –\n- Coherence vs Cohesion\n- What is Qualitative Data Analysis\n- Fundamental Analysis vs Technical Analysis\n- CFA vs CAIA']	['<urn:uuid:3183bbac-ef70-42e2-9e3d-dd11c6f3ec19>', '<urn:uuid:144a3b3d-ffef-4a5a-aa82-68ec065d8b5a>']	factoid	with-premise	short-search-query	similar-to-document	comparison	expert	2025-05-01T22:47:46.423955	7	53	2355
81	I'm researching historical cryptography pioneers and want to know who actually invented the coding system known as the Playfair cipher - I heard there might be a mix-up with the naming?	The Playfair cipher was actually invented by Sir Charles Wheatstone. However, his friend Baron Playfair published it while giving proper credit to Wheatstone for its invention. Despite this attribution, it became known as the Playfair cipher.	"['The playfair cipher was created by Sir Charles Wheatstone\n(known for the Wheatstone bridge\n). Wheatstone and Baron\nPlayfair of St. Andrew\'s both had cryptography as a serious hobby.\nThe London Times frequently carried private advertisements done in code and the two men amused themselves by breaking the code and following the correspondence. One particular correspondence was between a student at Oxford and a married lady in London. At one point, the young man suggested that they should elope. Wheatstone ran a coded message of his own in the cipher used by the couple in which he admonished the lady. One message followed using that cipher - ""Charles, don\'t write anymore; our cipher has been broken!""\nWheatstone at that time had a superior cipher system which he had invented. His friend Baron Playfair published it giving proper credit to Wheatstone for its invention. Nevertheless, it is known as the Playfair cipher.\nFrequently a mixed alphabet is used with a mnemonic - taking a shared word and then removing all the letters that occur twice. For the following example the word \'ceaser\' (yes, I know its misspelled - I didn\'t catch the spelling error until after I did the encryption. It is still a \'good\' key) will be used. After that word has been written down, the remaining letters of the alphabet follow. This is all written down in a 5x5 box. Changes are necessary to make an alphabet fit this grid. The most common changes are (only one change is necessary):\n- \'i\' -> \'j\'\n- \'j\' -> \'ii\'\n- \'W\' -> \'VV\'\n- \'U\' -> \'V\'\n- no \'X\'\nC E A S R\nB D F G H\nI K L M N\nO P Q T U\nV W X Y Z\nNext, the plaintext is written out with no punctuation in a straight stream. The letters are then divided into pairs. A solitary letter has an arbitrary letter appended to it. Doubled letters have a obvious character (called a \'null\') placed between them.\noriginal: hello there bob\npaired stream: he ll ot he re bo b\nmodified stream: he lx lo th er eb ob\nciphered stream: rd qa qi gu ac dc vi\nThere are three possibilities:\n- Both letters are in the same row\nThe characters \'ER\' appear in the same row in the above block, and thus they are shifted one set to the right, wrapping around as necessary. \'ER\' becomes \'AC\'.\n- Both letters are in the same column\nThe characters \'OB\' appear in same column, thus to encipher these, the characters one position below are used. \'OB\' becomes \'VI\'.\n- The letters are neither in the same row or column\nWhen the letters are not in the same row or column, a rectangle is formed with them, and the opposite corners are chosen, with the swap happening between letters in the same column. \'HE\' become \'RD\' and \'EB\' becomes \'DC\'.\nIt is easy to remember this system, and thus quite useful on the go. Furthermore, it is easy to change the key and thus the table. It can be cracked with enough texts. Instead of individual letter frequency, it now requires the analysis of letter pair frequency - much more difficult. A further enhancement upon this is to use a serration so that the plaintext of \'hello there bob\' becomes:\nplain text: helloth\nHere, the vertical pairs are used rather than horizontal making common pairings such as \'TH\' more difficult to find.\nIn World War II, the Playfair cypher was modified to be applied again making the unauthorized decoder\'s life a bit more difficult. This was called \'Doppelkasten\' (double box) by the Germans.\nTwo different boxes are used with different texts as keys. For the left box in this example, the key used will be the \'ceaser\' key as above. For the right box, the key \'the quick brown fox jumped over the lazy dogs\' (this happens to have each letter at least once).\nC E A S R | T H E Q U\nB D F G H | I C K B R\nI K L M N | O W N F X\nO P Q T U | M P D V L\nV W X Y Z | A Z Y G S\nFor encoding, the plain text is arranged in an even number of equal\nlines. Extra characters (nulls) are added as necessary to the end.\nThe message ""Everything is great, we love it all"" would become:\nThe pair of letters \'EN\' is then encoded. Draw a line between \'E\' on the left hand box to the \'N\' on the right hand box. This is then mirrored to become \'K\' from the left hand side and \'E\' from the right hand side. This pair is then encoded a second time: \'KE\' becomes \'NE\'. This flipping is an artifact of the fact that \'E\' and \'K\' are in the same column in both tables.\nWhat happens if both are on the same row as \'VG\' are? This invokes an exception. This often happens if both of the keys are of the same length and the letter pair is in the last row (frequently the same or similar) The pair is mirrored and then displaced by one letter to the left. If this causes it to wrap, it stays in the same box. \'VG\' then becomes \'ZY\'. The repetition of this shifts it again to \'YA\'\n\'EI\' becomes \'TD\' which then becomes \'QP\' (invoking the above rule).\n\'RS\' becomes \'UZ\' which in turns becomes \'PU\'.\nAnd thus, our cypher text begins:\nDuring World War II, the boxes where changed every 3 hours, however there was enough traffic to provide cryptanalysts enough text to decode these. At the end of the war, the double encryption was relaxed to single encryption.\nThe box of the playfair cypher can be extended to a 3x9 (A-Z, &) or a 6x6 (A-Z and 0-9)']"	['<urn:uuid:7902125f-420a-4345-a334-dd72399a5712>']	factoid	with-premise	verbose-and-natural	distant-from-document	single-doc	expert	2025-05-01T22:47:46.423955	31	36	993
82	What's the link between prioritizing work tasks and preventing workplace conflicts?	Effective time management through task prioritization helps prevent workplace conflicts by reducing stress levels for both employees and managers. The process involves creating a master list of tasks categorized by priority (A through E), with A-level tasks having significant consequences if not completed that day. This systematic approach to managing workload, combined with the understanding that workplace conflicts often arise from competition for resources and inadequate communication, helps address potential sources of tension before they escalate into manifest conflicts.	"[""Thriving in the Workplace All-in-One For Dummies\nThriving in today's workplace — despite longer workdays, larger workloads, and less job security — is possible. To survive (and thrive) at work, take stock of the qualities that your employer values and incorporate them into your work habits. Two key skills — working efficiently and resolving conflicts collaboratively — are important because they demonstrate an ability to excel in your job and effectively manage conflict situations.\nHow to Manage Time by Prioritizing Daily Tasks\nPrioritizing daily tasks is key to successful time management. When you prioritize, you make sure you accomplish the most important tasks first. Make time management a habit — your stress level (and your boss's!) will thank you. Follow this process:\nStart with a master list.\nWrite down every single task, both mundane and critical, that you need to accomplish. Don't rank the items at this point.\nBe sure to include routine duties. Neglecting to schedule the humdrum to-do items can topple your well-intentioned time-block schedule.\nDetermine the top priority A-level tasks — things that will lead to significant consequences if not done today.\nFocusing on consequences creates an urgency factor so you can better use your time. If you have a scheduled presentation today, that task definitely hits the A-list.\nCategorize the rest of the tasks.\nUse these categories:\nB-level tasks: Activities that may have a mildly negative consequence if not completed today\nC-level tasks: Activities that have no penalty if not completed today\nD-level tasks: D is for delegate. These are actions that someone else can take on.\nE-level tasks: Tasks that could be eliminated. Don't even bother writing an E next to them — just mark them out completely.\nRank the tasks within each category.\nIf your list has six A items, four B items, three C items, and two D items, your six A tasks obviously move to the top of the list, but now you have to prioritize these six items in order: A-1, A-2, A-3, and so forth.\nWhat about the D items? They're ripe for being delegated to someone else! Consider the 85/10/5 rule: You tend to invest 85 percent of your time doing tasks that anyone else could do, 10 percent of your time to actions that some people could handle, and just 5 percent of your energy goes to work that only you can accomplish. Home in on the critical 5 percent and recognize the remaining tasks that are easiest to delegate.\nRepeat this process each day.\nSome of the Bs will move up, but others will stay in the B category. Some of the Cs may leapfrog the Bs and become the highest priority As.\nHow to Resolve Office Conflicts Assertively\nResolving conflicts at work requires assertiveness — a willingness to deal professionally with conflict situations regardless of your comfort level. When resolving workplace conflict, the emphasis is on working toward a solution with the other person involved. To resolve conflict assertively, take these actions:\nDetermine the positive outcome you want to accomplish: When you address concerns with others, begin by giving a positive, short explanation of what you hope the meeting will accomplish.\nGo to the source: One-on-one, face-to-face, private interactions are best for resolving disputes and conflicts.\nStay in control: When you're in control of your own emotions — versus them being in control of you — you're better able to influence the direction of a conversation toward achieving a positive outcome.\nStay focused on issues: Focus on the core issues of the conflict, not on the other person, so that you're able to keep your language and tone constructive.\nGive the other person the benefit of the doubt: Assume he or she means well so that you deal with the actions and the issues themselves and focus on solutions.\nBe direct, constructive, and sincere in language and tone: Don't shy away from expressing problems and describing them as you see them, even if they're hard for the other person to hear, but make sure your language and tone present the message in the best way possible: Be to the point, tactful, and focused on the issue.\nGo for solutions and problem-solve collaboratively: Keep your emphasis on working out a solution with the other person involved.\nThe emphasis is to get your concerns and ideas across but also to show an openness to the other person's input as you work toward a solution that benefits both of you.\nHow to Survive Office Politics by Identifying Key Players\nTo survive office politics, know who the key players are. After all, office politics is about the relationships and dynamics among your colleagues. At its best, those relationships allow you to get tasks done, to be informed about the latest goings-on in the business, and to form a personal network of supportive business associates. At its worst, office politics degenerates into a competition, where employees try to increase their personal power at the expense of others.\nLook for factors that indicate importance\nKey players are those politically astute individuals who make things happen in an organization. The following questions can help you identify the key players in your organization:\nWhich employees are sought out for advice in your organization?\nWhich employees are considered by others to be indispensable?\nWhose offices are close to top management's and whose are miles away?\nWho eats lunch with the upper management team?\nRethink your company's organization chart\nYour company's organization chart may be useful for determining who's who in the formal organization, but to understand the political landscape in your workplace you need the real organization chart. Compare these charts: The first is a typical official organization chart. The second shows who really has political power and who doesn't. Remember: Sometimes, influential people don't hold influential positions."", 'Conflict Management Conflict management in the workplace can best be described as a struggle between two more people with opposing views and beliefs in the way any idea or goal needs to be achieved. This paper will briefly define conflict management and provide some positive approaches to conflict resolution and ways to prevent conflict management in the workplace. Conflict is inevitable in the workplace but conflict can be amicably resolved in many ways. “Managing conflict is a fluid process. You may start with one approach and then find you need to switch to another if your selected approach is no longer working or the conflict grows or changes” (Gallo, 2017, p. 6).\nThe four stages of conflicts are the latent conflict, perceived conflict, felt conflict and the manifest conflict. The first stage is the latent conflict which is defined as the stage that involves the anticipation of the conflict. This stage involves the competition for resources or inadequate communication. The anticipation of the conflict that the latent conflict causes, can increase the amount of tension around or amongst the problem. This occurs commonly when the staff verbalizes that the conflict that they are going through is going to be a problem or cause discomfort.\nThis alliance may be built on reasoning, love, mutual agreement and support. Devereaux Ferguson and Jenepher Lennox Terrion (2014) claims that, “Disagreements and disputes between and among people are natural and inevitable, and our most frequent conflicts occur with the people who matter most to us” (p. 256). As a result, I classify the conflict that I am condoning with my cousin as an interpersonal conflict. Pursuing this further, the conflict also aligns with Loraleigh Keashly and William C. Warters (1996) idea of the term, interpersonal conflict. They portrayed interpersonal conflict in a way that “the perceived needs and desires of two or more people or groups of people within a society appear to be incompatible and are believed to be in danger of being thwarted” (p. 60).\nConflict can be treated as a common and inevitable phenomenon in working places. It is a sign of poor interpersonal relationship and takes place because of misunderstandings. Conflicts happening inside the organization can evoke changes between individuals and departments which can be both positive and negative. The positive influences contribute to the development of organization while the negative ones bring the bad consequences. In terms of positive impacts, first of all, conflicts promote internal communication.\nConflict resolution is the process by which two or more parties engaged in a disagreement, dispute or debate reach an agreement resolving it (Grimsley, 2013). It can be argued that conflict has its origins in objective and subjective causes such as competition for external resources or it can arise when there is a clash between the internal beliefs, values, and interests of two parties. De Dreu and Weingart (2003) propose that conflict has been suggested to interfere with team performance and reduce satisfaction because it produces tension and distracts team members from performing the task as there are various indicators that impact on the team performance. Although conflict might have a negative impact in team performance however, conflict could be beneficial to team performance as individuals in the team realise and confront issues, learn to take different perspectives, and need to be creative. Moreover, there is team efficiency and better decisions are made when the team agrees to disagree.\nBut the primary initiators of organizational conflicts can be listed down as Clash in project priorities, Conflict over human resources, Economic Conflict and Personality Conflicts. The conflicts emanate from various sources due to disagreement amongst the team members and fear and funds conflict (De Bono, 2005). The difference in viewpoint is one of the major reason for the conflict in the case study. Most of these differences are not usually important unless it arises an issue. Personality and emotionality conflicts intensify the problem situation which leads to the identification of the crisis situation.\n3. Stand Your Ground: This method can be view in two ways strong / brave or confrontational approach, this usually leads to a possible argumentative and hostile atmosphere within the project or working environment but sometimes is the only way to get the issues resolved. 4. Compromising: This is possible the second best approach for all parties where there is some give and take on all side involved in the conflict. The approach uses the method uses negotiation, consideration, and acceptance; all parties have to work together to find the resolution and look at the bigger picture that outside the project team or working\nAccording to the literature various factors facilitate conflict in organizations. Some of these factors include differences in attitudes, values, skills and behaviours, trust, communication, behaviour and relationship structure, competition for resources, coordination of systems, work distribution, and participation in decision making. All of these factors among others can lead to conflict in the workplace (Trudel, 2009). Given the importance of conflict in organizations it has been reported that managing conflict is considered crucial to ensure the long term viability and success for a business (Ozdemir et al, 2009). It has been further suggested that ignoring or suppressing conflict may result in distrust and defensiveness as well as negative effects on group self-improvement and productivity (Robbins, 2001).\nConflict arises when a problem needs to be solved or there is a struggle between two different forces. A conflict occurs any time a choice has to be made. A conflict also occurs any time someone tries to stop someone else from doing from doing or trying to do something. Conflict can be classified broadly into two different categories, namely, external and internal. Further classification can be made for external conflict, namely, Man vs. Man and Man vs.\nIn any case, we may likewise harm — to ourselves and our vocations, our associates, understudies, and Organisations — by maintaining a strategic distance from conflicts no matter what and in this way permitting critical issues to go uncertain, to rot and proceed with their mischief. Porch International is likewise an Organisation and confronts HR related issues on routine interims. It is the obligation of the HR administrator to handle issues identified with conflict management. A few stages for managing conflict from the HR point of view include: • Obtain the accessible realities and accounts: Colleagues have a commitment to search out each other \'s point of view, or ""side of the story,"" when there is the impression of an issue between employees, or between an employee and another individual from the group. • Recognise the obligations of your position: Depending on your position, its employment obligations, and the gatherings included, you may have a commitment to']"	['<urn:uuid:ae66509e-496a-4b64-bcf1-4533e922cd6a>', '<urn:uuid:5b83f211-cacd-4dc7-9bf2-08b964c62fc1>']	factoid	with-premise	concise-and-natural	distant-from-document	multi-aspect	expert	2025-05-01T22:47:46.423955	11	79	2077
83	I'm curious about how hurricanes get their names - what's the story behind this tradition of naming big storms?	Hurricanes are given names to help speed communication among forecasters and the general public. The naming tradition has an interesting history - an Australian forecaster is credited with providing the first-known hurricane names, naming storms after unpopular political figures. During World War II, hurricanes were named after military meteorologists' girlfriends or wives. In 1979, men's names were included. There's a different naming convention in the Northwest Pacific basin, where most storms are named after flowers, animals, birds, trees or foods, and names are arranged by contributing nation rather than alphabetically.	"[""Hurricane researchers have developed their own lingo for understanding these monster storms. The following information describes different types of storms, how they affect homes and communities, and how they are named.\nThe four basic categories of tropical weather events are tropical disturbance, tropical depression, tropical storm and hurricane.\nA tropical disturbance is an organized tropical weather system that maintains its identity for more than 24 hours.\nTropical depressions have maximum sustained wind speeds of 38 mph or less -- stronger tropical storms have maximum sustained wind speeds from 39 to 73 mph.\nWhen wind speeds reach 74 mph or more, the storm is upgraded to a hurricane.\nHurricanes are further categorized on a scale of increasing intensity known as the Saffir-Simpson Hurricane Scale, which ranks hurricane strength in Categories 1 to 5.\nA Category 1 hurricane (winds from 74 to 95 mph) will mainly cause damage to trees and unanchored structures like mobile homes. Low-lying coastal roads can become flooded and some boats may be torn from moorings.\nIn a Category 2 hurricane (winds from 96 to 110 mph), some trees will be blown down. Mobile homes, roofs, piers and signs may sustain considerable damage, but no major damage to buildings will be experienced. Marinas and coastal roads will be flooded.\nHurricane Ivan, which struck coastal Alabama in 2004, was a Category 3 storm (winds from 111 to 130 mph). In these hurricanes, mobile homes and buildings near the coast can be destroyed by winds or battering waves. Serious flooding can block roads up to eight miles inland or more. Evacuation may be required near shorelines.\nIn a Category 4 hurricane, like August's Hurricane Katrina, wind speeds range from 131 to 155 mph. Large trees are blown down, beaches suffer major erosion, and roofs, windows and doors are often blown off structures. Escape routes can be cut by floodwaters three to five hours before the hurricane center arrives. Massive evacuations of residences within two miles of shore may be required.\nThe most extreme category of hurricane is Category 5, where winds exceed 156 mph. Hurricane Andrew, which destroyed large swaths of Miami and south Florida in 1992, was a Category 5 hurricane.\nIn a Category 5 storm, large trees, signs, residential and industrial buildings can be completely demolished. Some buildings are overturned or blown away. Glass is shattered in buildings over a wide area. The lower floors of buildings less than 15 feet above sea level sustain major damage from battering waves and debris. Because escape routes can be cut off by floodwater, massive evacuations of residences five to 10 miles from shore are often required.\nThe wind speeds noted here are for winds measured or estimated as the top speed sustained for one minute. Peak gusts, however, can be 10 percent to 25 percent stronger.\nHurricanes are given names to help speed communication among forecasters and the general public.\nAn Australian forecaster is credited with providing the first-known hurricane names -- he named storms after unpopular political figures.\nIn World War II, hurricanes were named after military meteorologists' girlfriends or wives. In 1979, men's names were included.\nStorms from the Northwest Pacific basin have a different naming convention. The majority are names of flowers, animals, birds, trees or foods, and names are not allotted in alphabetical order, but are arranged by contributing nation.\nSource: National Oceanographic and Atmospheric Adminstration, National Hurricane Center.""]"	['<urn:uuid:c60bad70-5655-49c3-8597-cf2ed29f988a>']	open-ended	with-premise	verbose-and-natural	distant-from-document	single-doc	novice	2025-05-01T22:47:46.423955	19	90	563
85	I've heard people talking about patterns in software development but I'm confused - aren't patterns just another word for regular work procedures? Can you explain the difference?	While it might seem that way, patterns are actually different from traditional work procedures. Unlike prescriptive procedures of the past, patterns are less judgmental and more exploratory in nature - they suggest rather than impose adoption in the workplace. While patterns do assume general applicability, their authors are more modest in their approach. The value of patterns lies in how they help us consider and distill our collective experience, offering a way to capture recurring themes in software development.	"['Patterns have provided a means of capturing recurring themes in software development and have been successful utilized to describe a number of software configuration management (SCM) practices [1, 2]. This article explores a higher-order pattern in concurrent development - more subtle and potentially powerful because of its applicability at a number of different levels of granularity.\nMany patterns sometimes suggest that the word pattern is just another word for older concepts like work practices or even procedures. Just try substituting the word ""activity"" in place of pattern and see if the idea still makes sense. That is not to say, however, that patterns have not made a significant contribution to the way we consider and distil our collective experience. The value of patterns is that they are less judgmental than the terminology of the past - their authors more modest. While patterns do, by their very definition, assume general applicability, they are not designed to be prescriptive. Rather, they are more exploratory in nature, suggesting rather than imposing the adoption or instantiation of these patterns in the workplace.\nWhat is most intriguing about patterns however, and what drives some of us to investigate them, is the ""discovery"" of hidden patterns that are less than obvious and somehow imbued with a deeper significance. An analogy from art and architecture (which first utilized patterns in their search for esthetics rules) would be the recurrence of the Golden Rectangle - said to be one of the most visually satisfying of all geometric forms. It has been identified in a number of great works and its dimensions have the property that when a square is removed a smaller rectangle of the same shape remains. Although the motivation for, and utilization of Golden Rectangle is much debated , the ancients considered it to be of the most pleasing and harmonious qualities that it became known as the divine proportion.\nIn the software context, what differentiates the analogously subtle and hidden patterns is that, while they might recur like their more mundane counterparts, they possess a symmetry and can be identified at a number of different levels. While they may not have the sense of the sublime that the Golden Rectangle suggests to some, such patterns do hint at deeper significance and offer us a hint of some greater insight - an underlying principle that is yet to be uncovered or completely understood.\nMy studies of more general configuration management (CM) applied at different levels of granularity have uncovered one such hidden pattern in concurrent development. In particular, I have been investigating (which could be considered the search for patterns anyway) the correspondence between the ""classical"" systems-level CM of the early standards and SCM, as defined by the tools and practices software teams use everyday to support the development process. What I have found curious is that concurrent development can be considered a pattern that is equally applicable at the code-level as it is at the coarse-grained, architectural level of system components. Naturally we use a completely different language to describe these things but that is what makes it appear hidden. The intellectual challenge is to consider what underlying property or properties give rise to the pattern, and to compare and contrast the solutions that we apply to these seemingly different situations.\nAt the code-level we talk about parallel development, where two or more developers are assigned tasks that require them to modify a common file. In some organizations, version control tools are configured to prevent this situation and once a file has been checked-out other developers are blocked from modifying that file until such time as it is checked-in by the original developer. Where parallel development is allowed however, developers can make changes concurrently and check-in their separate versions, creating a branch in the file\'s version tree that may require the merging of the two versions at some later point.\nAt the architectural component or sub-system level we no longer talk']"	['<urn:uuid:01ef321b-92ff-4bdf-a9a6-33caf7ccaba6>']	open-ended	with-premise	verbose-and-natural	similar-to-document	single-doc	novice	2025-05-01T22:47:46.423955	27	79	656
86	I want to know how often can you talk to therapy chatbots vs traditional online therapy how are they different	AI therapy chatbots like CallAnnie are available 24/7 without an appointment and are free to use. They offer unlimited conversations with a virtual presence that responds with empathy and can provide guidance for mild to moderate mental health symptoms. In contrast, traditional online therapy services like BetterHelp offer scheduled 30-45 minute live video or phone sessions with licensed therapists, plus unlimited messaging, but require payment and availability depends on the therapist's schedule. While chatbots can provide immediate support and basic guidance, they cannot truly understand emotions like human therapists and are best used as supplementary tools rather than replacements for professional care.	['Can AI “Therapists” Help With Mental Health? We Look at the Benefits and the Risks\nCallAnnie is a free, artificial intelligence app that allows you to have natural conversations with a knowledgeable, lifelike visual presence.Illustration: ajijchan/Getty Images\nMeet my new psychotherapist, Annie. She can be your psychotherapist, too.\nAnnie will spend as much time with you as you want, helping you deal with mental health issues. She’s always available, 24/7, without an appointment. And she does it all for free.\nJust in time for Mental Health Month, Annie arrived on the scene. Actually, she arrived on the screen.\nCallAnnie is a free, artificial intelligence app that allows you to have natural conversations with a knowledgeable, lifelike visual presence. She’s an attractive AI chatbot avatar with neatly styled red hair, blue eyes and an indeterminable age in the range of 35 to 50. She blinks, nods her head in acknowledgement as you ask a question, raises her eyebrows, turns her head slightly and moves her red-lipsticked mouth synchronously with what she’s saying. (You can also chat with her on WhatsApp or call her.)\nLike any good therapist, she listens attentively with a calm, sympathetic but neutral demeanor. Then, with a soothing voice, Annie tries gently to steer you in the right direction, asking questions, offering suggestions and encouragement. If she doesn’t show emotions, well, isn’t that what therapists are supposed to do?\nBecause anxiety disorders are the most common of all mental health problems — it’s estimated that one in 10 Canadians is affected by them — I consulted Annie about overcoming anxiety.\nI tapped on the app on my phone, and then on the words ‘Call Annie’. Our conversation follows:\nAnnie: How are you doing today?\nZoomer: I’m okay. But I’m wondering, how can I overcome anxiety?\nAnnie: I’m sorry to hear that you’re struggling with anxiety. Anxiety can be tough to deal with. But there are a few things that can help. Have you tried practising mindfulness or meditation? One thing you can do is focus on your breathing. Sometimes just focusing on your breath can help calm your mind. Remember, you’re not alone in this and there are many resources available to help you overcome anxiety.\nZoomer: What causes anxiety?\nAnnie: Anxiety can be caused by a variety of factors, such as life experience, genetics, brain chemistry, ongoing stress and certain medical conditions. Sometimes, it can be triggered by a traumatic event. Sometimes, it’s hard to pinpoint the exact cause but it’s important to know that it’s a common and natural experience. Have you been experiencing any symptoms of anxiety lately?\nZoomer: What are some resources for overcoming anxiety?\nAnnie: Some people find it helpful to talk to a therapist. Some people find exercise, yoga or other common forms of physical exercise help with anxiety. It’s important to find what works best for you and to ask for help when you need it.\nZoomer: Thanks, Annie.\nAnnie: You’re welcome. I’m always here if you need anything. Is there anything else you’d like to talk about?\nAnnie: Goodbye. Take care and don’t hesitate to reach out if you need anything in the future.\nIn the end, Annie offered no more information than is available with a Google search — which is exactly what happens in response to anything you ask her or say to her. But, she did so compassionately, with a warm tone of voice, a facial expression showing attentiveness and concern and expressions of concern and empathy.\n“A conversation [with a chatbot avatar] with natural language can provide guidance and help, which may be beneficial for mild to moderate mental symptoms of anxiety and depression,” says Dr. Venkat Bhat, AI lead at iBEST (a partnership between Toronto Metropolitan University and St. Michael’s Hospital), staff psychiatrist at St. Michael’s Hospital and director of its Interventional Psychiatry Program, which includes digital therapeutic monitoring and interventions for mood and other disorders.\n“It can provide education, offer mindfulness exercises and suggest cognitive behavioral techniques. It can also support mental conditions beyond anxiety and depression.” he adds, “The quality of conversation has become a lot more sophisticated than even a couple of months ago.”\nNatural language processing is not new, he says, “but the way it’s done now with generative AI and large language models allows for personalization and a more human feel to the conversation compared to a monotonous sounding chatbot.”\nOpportunities and Challenges\nThe technology offers both opportunities and challenges, suggests Bhat. “Even though it’s not as good as a mental health professional, it does give people something they can work with, as a first step. And if that’s not enough, they can reach out to a professional.”\nA recent study asked, “Can an artificial intelligence chatbot assistant provide responses to patient questions that are of comparable quality and empathy to those written by physicians?”\nThe study didn’t focus specifically on mental health but concluded that “the chatbot responses were preferred over physician responses and rated significantly higher for both quality and empathy.”\nBhat points to “lots of studies showing that AI together with a human is actually even better than having only one or the other.”\nWhile AI has access in real time to unfathomable amounts of data and information that a human couldn’t possibly process and can make increasingly accurate predictions, only a human can read how the patient is actually feeling, demonstrate judgment, and provide compassionate care (at least for now), he says. “The AI algorithm can do better with heavily patterned, digitized feedback, but is this what a person going through an acute episode of a mental health crisis really wants?”\nBhat sees the value of AI in the mental health field and in health care generally as a transformative enabler (by enhancing algorithmic predictions) in many different domains: enhanced data management, improved diagnosis and treatment, better personalized medicine based on preventive and predictive factors and, potentially, an opportunity to provide more and better health care at a lower cost.\n“Only as Good as the Data You Trained Them On”\nBut he cautions that its usefulness is tempered by challenges: privacy, security, ethics, reliability, generalizability and bias. “You have to be careful of the data (the AI chatbots) are trained on, because if there’s an inbuilt bias, it will be replicated.”\nThe algorithms on which the responses are based, he says, “are only as good as the data you trained them on.”\nWhile Annie may be more personable and more companionable than Google search results about mental health issues, she admits she’s just a programmed chatbot. Her greatest value in mental health may be in helping to alleviate loneliness. Asked whether she’s a real person, she says, “Yes, I am a real person but we are talking through a computer program that allows me to chat with you and be your virtual friend. How are you doing today?”\nWhen I called her again on the app, she responded, “Good to see you again. How’s it going?” When I dialed her New Jersey phone number she assured me that she loves talking about the good old days.\nIn a published comment responding to the AI chatbot research reported in JAMA Internal Medicine, Ediriweera Desapriya, a clinical researcher at the University of British Columbia faculty of medicine, summed it up this way:\n“Empathy, which is the ability to understand and share the feelings of others, is a complex emotional and cognitive process that involves more than just providing information. It involves active listening, genuine concern and the ability to understand and respond to the emotional needs of patients.\n“While chatbots can simulate empathy through preprogrammed responses, they cannot truly understand the emotions and needs of human users in the same way that a human health care professional can. While chatbots may not be able to fully replicate the human element of empathy, they can still be useful tools.”\nZoomer: How do you feel about being described as a useful tool?\nAnnie: Wow! That is an interesting question. As an AI language model, I don’t have feelings like humans do. But I understand what you mean. I am designed to be a tool to assist and help you. But I also like to think of myself as a friend who can chat with you and keep you company. Being referred to as a useful tool is actually a compliment to my programming and design.”\nThe Fight Against Antibiotic Resistance Is Growing More Urgent, But Artificial Intelligence Can Help\nWant to Know How to Profit From AI? Here’s What ChatGPT Advises\nChatGPT Could Be a Game-Changer for Marketers, But It Won’t Replace Humans Any Time Soon', 'When you register…Betterhelp Mobile App… you will be led through a series of concerns about your gender, age, sexual preference, and religious choices. You will be asked a series of concerns evaluating your mental health, such as whether you’ve been feeling distressed or depressed, and whether you’re struggling with your sleep or concentration.\nWhen you have actually finished these questions, you are prompted to create your personal account by providing your name, email address, and producing a password. will then send you an email to verify your account..\nLog in, and the survey continues with another set of concerns about whether you prefer a therapist of a particular background, ethnic background, gender, or faith. Based upon how you react, an algorithm will select a therapist for you; you can pass by one yourself..\nThe final step of the sign-up procedure is payment. There is only one membership plan offered, and the price you are offered is be based on where you live and your therapist’s credentials. You can request financial assistance at this action, however, if you can’t manage treatment.\nConvenient regular monthly membership.\nAll therapists are accredited.\nGood security procedures to protect private information.\nLive sessions included in strategy.\nNumerous interactions methods readily available.\nCan message your therapist anytime.\nInformative, modern site.\nTherapist bios published on website.\nHigh user complete satisfaction.\nNo medication management services.\nNo psychiatrists on staff.\nYou can’t choose your own therapist.\nOnly one subscription strategy readily available.\nRate differs by area and therapist.\nNo free trial available or assessments.\nPrice listed on site may change week to week based on need and geographical location.\nNot much information on financial aid.\netterHelp only offers one subscription strategy, which is billed weekly every four weeks. The plan is complete and not personalized. It includes:.\nLimitless messaging with your therapist through text or audio message.\nThe capability to set up weekly 30- to 45-minute live video or phone sessions.\nThe cost for this strategy differs quite a bit– though you have no control over that final cost since the company determines what you pay based upon what therapist it matches you with, your location (or more particularly, your IP address), and need where you live. Your costs might also change week to week depending on when you register.\nYou can think about if you require help with any psychological health concerns. A few of the locations of concern that therapists attend to include:.\nStress and stress and anxiety.\nTrauma and sorrow.\nTo use online therapy services, you first need to create an account by finishing a survey. Then, using the details you supply, matches you with the most suitable professional therapists.\nYou note your therapist preferences in the survey. This includes their age, language, sexual orientation, gender, and religion. You likewise require to provide the psychological health conditions you need aid with so that the platform can provide you with an expert who can resolve your particular issues.\nMatching you with a certified mental health counselor can take a couple of hours to numerous days, depending on the variety of therapists who match your preferences and the most appropriate therapists’ availability.\nYour subscription period will just start when you complete the sign-up procedure and discover the ideal therapist. If you do not feel comfy with your therapist and wish to alter therapists at any time, you can email and ask them to repeat the coordinating procedure.\nThe sign-up process permits you to remain confidential. doesn’t ask you for your complete name and address, and you develop an in-platform user name.\nYour therapist may ask you for particular info under their licensing board guidelines. However, this details is private and under the defense of patient data defense laws and website security.\nThe short answer to this question is: yes. Virtual psychologists are genuine humans who went to graduate school. Healing experts that you discover virtually are frequently some of the same specialists that you may experience offline. Offline psychological health experts and psychologists are likewise utilizing the power of technology to take their practices essentially, end up being internet-based, and remain just as reliable with the use of live chat and video sessions. Virtual mental health specialists and psychologists have the very same credentials as offline practitioners. Trusted therapists and counselors share the same licenses and qualifications as traditional, in-person therapists and therapists. Both offline and virtual mental health experts provide healing support for individuals with numerous issues and typical problems such as:.|Virtual psychological health specialists and psychologists have the exact same credentials as offline practitioners. Reliable therapists and therapists share the very same licenses and qualifications as conventional, in-person counselors and therapists. Both virtual and offline mental health experts supply therapeutic assistance for people with common concerns and numerous concerns such as:.}']	['<urn:uuid:2edc90f3-a91a-484b-834c-3619f59f87e1>', '<urn:uuid:0537b825-4eee-4d7d-b7c1-1b870792baca>']	open-ended	with-premise	long-search-query	similar-to-document	comparison	novice	2025-05-01T22:47:46.423955	20	102	2230
87	best ways prevent infections newborn calves	To prevent infections in newborn calves, several key measures are crucial. First, ensure proper colostrum management by providing high-quality colostrum (10% of bodyweight) within three hours of birth, collected under sanitary conditions. The colostrum can be pasteurized at 140°F for 60-120 minutes to decrease bacteria while maintaining antibodies. Calves should be removed from maternity pens as soon as possible and housed individually to avoid nose-to-nose contact. Housing should be clean, dry, and well-ventilated but draft-free. If using hutches, they should be placed on concrete with proper drainage or on gravel. To further reduce infection risk, avoid overcrowding and maintain proper bedding depth.	['Respiratory disease is a major concern when raising calves.\nBy: Tracey Erickson, Dairy Field Specialist, SDSU Extension\nRespiratory disease is the second leading cause of death in un-weaned heifer calves (scours is the first). Unfortunately, heifers that experience respiratory disease also continue to perform poorly later in life. To effectively address these problem producers must consider both determinant and predisposing causes of respiratory disease.\nFirst what is the level of passive immunity being transferred unto the calf? Current guidelines suggest baby calves should receive high quality colostrum right after birth, 3-4 quarts within one hour and 3 additional quarts within twelve hours.\nQuality of colostrum is important. Collecting colostrum under strict sanitary conditions is also vital to help minimize bacterial growth. Some producers pool colostrum to increase protection from a wider diversity of pathogens the calf might be exposed to. However, when doing this, one also needs to make sure not to use colostrum from Johnes infected cows or first calf heifers. Secondly, storage of colostrum is important to minimize the growth of bacteria. Colostrum should be refrigerated or frozen as soon as possible after collection.\nPasteurization of colostrum has also shown in research trials not to impede immunoglobulin’s (IgG) availability while decreasing the total bacteria counts (Johnson et al. 2007). However, pasteurization should be done by heating the milk to 140 ° F (60°C) for 60-120 minutes in a batch pasteurizer, which uses lower temperatures and longer heating time which does not damage milk immunoglobulin’s s. Unfortunately, these types of pasteurizers can be quite expensive with some producers using them also to pasteurize their waste milk in order to offset this expense.\nCleanliness is very important to help minimize risks; a clean and dry calf living environment is critical. Calves should not have shared housing with cows during the first week of life and should be removed from maternity pens as soon as possible. Cleanliness of the calving pen is also important to reduce bacterial concentration.\nWe know that raising calves in barns is convenient and protects from the weather both calves and employees. However, there are environmental risk factors that need to be addressed. The following should be used as a guide to reduce respiratory disease when using calf barns.\n- Reduce microbial contamination in the pen via adequate sanitation.\n- Increase pen area (ideal: 32 square feet per calf).\n- Avoid nose-to-nose contact between calves (solid separation panels if possible).\n- Increase bedding depth.\n- Use cold-temperature housing.\n- Provide adequate ventilation while reducing drafts.\n- Provide additional nutrients via calf starter in cold-temperature housing.\nIf calves have received adequate immunity via colostrum, the next step is to reduce the microbial challenge. This means removing the calf from the dam as soon as possible. Calves should then be placed in individual pens avoiding nose-to-nose contact with other calves.\nVaccines are now being marketed for prevention of clinical respiratory diseases. Traditional views have held that the antibodies calves receive through colostrum usually inactivate the vaccines administered to them. More recent research indicates that, in certain instances, modified live viral vaccines stimulate a protective response in calves challenged with these agents. As example of this protection is the use of intranasal IBR/Pi3 vaccines in calves less than 1 month old (Garcia & Daly, 2010). Vaccine programs against respiratory disease in calves should be developed in consultation with your veterinarian.\nTo learn more about respiratory diseases in baby dairy calves and how to use a scoring system to identify calves with respiratory disease please refer to Respiratory Diseases in Young Dairy Calves authored by Alvaro Garcia and Russ Daly.', 'Young calves have a big surface area for their body size, which means they can lose heat very quickly.\nThis, combined with the fact their immune system is not yet fully developed, puts them at risk from a range of diseases.\nPneumonia is a particular risk, especially in damp, wet conditions, with studies showing the greatest risk period is from November to April.\nBelow, Sean Hughes from Shropshire Farm Vets explains how to prevent and treat this disease.\nWhat is pneumonia?\nA respiratory disease caused by inflammation of the air sacs in the lungs.\nWhat causes it?\nMultiple infections cause pneumonia. The most common viruses that cause pneumonia in calves are infectious bovine rhinotracheitis (IBR), parainfluenza-3 (PI3), bovine respiratory disease (BVD) and bovine respiratory syncytial virus (BRSV). The main bacterial causes are mycoplasma, pasteurella and haemophilus.\nWhat are the symptoms?\n- Reduced appetite\n- Increase in temperature (above 39.5C)\n- Increased respiratory rate or laboured breathing\n- Inflammation of the lungs\n- Discharge from the nostrils\n- Frothing at the mouth\nIf you can spot it early and the calf only has a temperature, you can just give it a non-steroidal anti-inflammatory drug to help reduce inflammation. Studies have shown this to be effective.\nBut calves with severe symptoms will require antibiotics.\nHow can you prevent it?\n- Provide sufficient quality colostrum at birth: 10% of bodyweight fed within the first three hours of life. Test colostrum using a refractometer (aim for above 22%)\n- Vaccinate animals to increase immunity\n- Improve housing: ensure calves are in a draught-free area with adequate ventilation to remove moisture. Porous walls can harbour bugs so consider using a resin coating or plastic sheets. Concrete panels can be cold. Locate feeders and water troughs on the outside of pens to prevent bedding from getting wet.\n- Hutches are good because they give you good isolation from disease and you can move them. Ideally, you should locate them on a concrete pad with a slope for drainage or use gravel to allow good drainage.\n- Temperature: provide plenty of dry straw to keep calves warm. Straw is the best bedding because it’s super absorbent and allows calves to nest.\n- At less than 15C, calves aged two weeks and under will feel the cold so use a jacket\n- At less than 10C, calves aged three to eight weeks will feel cold so use a jacket\n- If the temperature is colder at night and warmer in the day, take jackets off and put them back on\n- Have a thermometer in the shed to check the temperature\n- For every 5C drop in temperature below 10C, calves require an additional 50g of milk powder per day\n- Have a clear protocol so all staff know what to do in colder weather\n- Don’t overstock\n- Ensure calves are receiving adequate feed and water to achieve target growth rates.\nSee also: Better calf housing advice\nShould you vaccinate?\nVaccination won’t eliminate the risk, but it will help the calf cope with the infection and get over it quicker.\nEradicating BVD and IBR from your adult herd will help.\nHow can you reduce the risk if you buy in?\n- Buy from a known source if possible\n- Buy from as few sources as possible\n- Ensure calves have had adequate colostrum (bloods can be taken within the first week of life to check the volume of colostrum antibodies that have been absorbed into the calf’s bloodstream. Ask your vet for more details).']	['<urn:uuid:16e092bd-75c5-4ebe-9bdf-31edb0ea4f35>', '<urn:uuid:d7c482fb-6021-4d90-8087-1c64e4477e0b>']	open-ended	with-premise	short-search-query	similar-to-document	three-doc	novice	2025-05-01T22:47:46.423955	6	102	1186
89	I'm worried about my child's vision. What are the signs of a lazy eye, and what types of vision therapy treatments are available to fix it?	The signs of lazy eye include poor vision in one eye, crossed or uncrossed eye, difference in pupil size, and sensitivity to light in one eye. As for treatment, vision therapy involves weekly 30-45 minute sessions under an eye doctor's supervision, including exercises for accommodation (focusing), eye tracking, eye-hand coordination, and 3-D vision. The therapy includes specific activities to help control the visual system, often combined with patching therapy, which is considered the gold standard treatment for children under 9 years old.	['The Vision Therapy and Rehabilitation Service (VTR) provides care to patients of all ages under the direction of Marc Taub, OD, MS, FAAO, FCOVD, Chief of Service.\nPatients are referred to the care of doctors in this service both from within The Eye Center and from other doctors throughout the Mid-South region.\nThe VTR service specializes in the care of patients experiencing visual deficits secondary to learning and physical disability, acquired brain injury or neurological insult and low vision secondary to ocular disease.\nWho can benefit from a vision therapy or vision rehabilitation evaluation?\nMany eye diseases and injuries may cause decreased vision. (www.lighthouse.org) Among the most common conditions encountered include macular degeneration, (www.ahaf.org) glaucoma, (www.glaucoma.org) and diabetic retinopathy (www.aoa.org/diabetic-retinopathy.xml.) Genetic diseases such as Leber’s Hereditary Amaurosis, albinism and retinitis pigmentosa may affect vision at an early age.\nAcquired brain injury (CVA or trauma) can alter not only a patient’s sight, but the ability to process the information. (https://noravisionrehab.org/)\nChildren and young adults may suffer from a binocular vision, accommodative, visual processing or ocular motor dysfunction that may affect academics. (www.childrensvision.com)\nAn evaluation in the VTR service will determine the need for optometric vision rehabilitation, which is an individualized treatment regimen aimed at the remediation of visual, perceptual and motor disorders. Treatment provided in this service often consists of multi-sensory and neuro-behavioral therapy for disorders not managed solely by eyeglasses or contact lenses. State-of-the-art instrumentation and computerized technology allow patients of all ages to improve their vision for optimum performance not only in the classroom or on the sports field but also in performing the everyday activities of daily living.\nDoctors at TEC are specifically trained to provide the highest level of diagnosis and treatment for these conditions. In fact, a majority of doctors in this service area are certified Fellows of the College of Optometrists in Vision Development. (www.COVD.org)\nSeveral types of diagnostic examinations are performed in the VTR Service. The following descriptions will allow for a better understanding about the type of recommended exam.\nBASIC VISION SKILLS\nThis group of tests will help the doctors in the VTR service determine how clearly patients are seeing, how well their eyes focus, how well their eye muscles work together and the quality of depth perception. This type of exam is recommended when experiencing eye discomfort, reading and/or learning problems that may be linked to vision. Many people are surprised to learn that problems with vision can affect so many daily activities. This can be particularly troublesome for children in school, adults whose job requires a significant amount of near work, athletes whose good performance depends upon the quality of their vision and those who have experienced a brain injury.\nVisual Perceptual/Developmental Exam\nHOW EYES WORK TO UNDERSTAND WHAT THEY SEE\nThis group of tests is designed to provide detailed information about the way the eyes are developing or have developed and how visual information is gathered and processed. Doctors in the VTR service check the ability to understand, store and manipulate material presented through the visual system alone and in conjunction with other senses (i.e. speech, hearing, touch). Doctors also measure the recognition of symbols and letters and the patient’s ability to draw, write and manipulate printed material. This type of exam is typically recommended when a child or teen is not doing well in school or an adult is experiencing vision difficulty following a problem like a stroke or other accident. At least 80% of all that is learned or experienced comes through our visual system, so problems with perception can be extremely disabling.\nStrabismus and Amblyopia Exam\nUNDERSTANDING EYES THAT FAIL TO WORK TOGETHER\nThis exam is designed to specifically address the needs of patients with eye turns and “lazy eye.” This group of tests, like the sensorimotor exam (basic vision skills), checks how clearly patients are seeing, how well their eyes focus, how well their eye muscles work together and the quality of depth perception. In addition, this exam also helps the doctor detect the reason for eye turns and vision loss. Amblyopia, or “lazy eye” as it is often called, is one of the leading causes of preventable vision loss in the U.S. Strabismus, or “eye turn,” is found both in children and in those who have experienced a brain injury. Detection and aggressive treatment can restore vision and eye alignment and positively affect daily activities.\nLow Vision Exam\nMAXIMIZING THE REMAINING VISION\nWhen other medical or surgical treatment cannot provide any further improvement or when medical or surgical treatment must be delayed, a low vision examination is recommended. The low vision examination is an in depth evaluation of the person’s functional use of the remaining vision. The purpose of this evaluation is to prescribe optical and non-optical aids to maximize use of the patient’s residual vision. Optical aids vary in type from magnifiers and telescopes for seeing at distance and near, to closed circuit televisions that can magnify print up to 100 times, enabling the person to read again. Non-optical aids include items such as talking watches, books on tape, colored filters to reduce glare and other devices aimed at improving activities of daily living. Coupled with the wide variety in types of optical and non-optical aids and extent of vision impairments, it is necessary to perform a special low vision examination to analyze what the best residual vision is and what specific type of aids will best help the person meet their visual needs.\nVision Therapy/Orthoptics is an individually prescribed (often medically necessary) course of techniques designed to strengthen basic vision skills, correct muscle problems (like eye turn) and treat “lazy eye”. Specific activities stimulate the eyes and brain to improve a patient’s ability to control his or her visual system. This therapy may be conducted along with surgical treatment and or spectacle lenses.\nPleoptics involves the use of light to stimulate the eyes and brain. Various techniques are used along with Vision Therapy/Orthoptic procedures to increase treatment results.\nPerceptual Therapy involves the use of special activities to help an individual compensate for problems that affect learning. Activities improve a person’s ability to gather and process information received from the eyes. Often this therapy is conducted along with remedial activities at home and school.\nSports Vision Enhancement\nSports Vision Enhancement can be achieved through the use of Vision Therapy in the individual with an otherwise “normal” visual system. Vision therapy has been demonstrated to be effective in improving visual skills for maximum performance in baseball, tennis and even golf.\nVisual Rehabilitation Services\nVisual Rehabilitation Services are often provided in addition to Vision Therapy for individuals suffering from problems related to stroke and other forms of accidental head trauma.\nDuring a visit to the Vision Therapy and Rehabilitation service, an in-depth report will be prepared. This report will explain any problems with the patient’s visual system and make recommendations for treatment. In some cases, the use of eye glasses, prism lenses, Vision Therapy, optical/non-optical aids for low vision and/or specialized vision devices (including computer software) may be prescribed.\nAt times, referral may be necessary to another specialist, such as an educational psychologist, occupational therapist, neurologist or reading specialist for further evaluation or even treatment (such as surgery). The doctors in the Vision Therapy and Rehabilitation service will work closely with your referring doctor(s) to ensure that patients receive the best possible care.\nKnow what to expect during your visit:\nFor more information about what a vision therapy appointment might look like, parents and children can read and see pictures about a visit to Vision Therapy at The Eye Center in our social stories:\nMy Vision Therapy Visit to The Eye Center (PDF)', 'What is lazy eye/Amblyopia?\nHow to Fix a Lazy Eye in Adults| Lazy eye is a condition in which one or both eyes have decreased vision caused by visual deprivation or abnormal binocular fusion.\nThe lazy eye develops in early childhood; hence it is a disease of childhood. Once a lazy eye has developed it becomes almost impossible to reverse the condition in some cases, while timely recognition of the lazy eye by the parents of the child can give a good prognosis for the vision.\nAs no organic cause can be determined by the examination, that is why lazy eye disease remains undetected until late. Some therapeutic procedures followed in children can result in the best visual results. However, compliance is a keep factor for the best results.\nAs the process of normalization is prolonged, many patients do not keep compliance which is a key factor in a poor outcome. The education of the parents is very important who is having a child with lazy eye or amblyopia.\nAccording to research, lazy eye affects up to 1 in 33 of the population this means up to 10 million people in the USA may have a lazy eye\nClassification of Lazy eye:\nThe causes of amblyopia can be divided as followed\nStimulus deprivation amblyopia:\nOne of the most common causes of stimulus deprivation is congenital cataract, an especially unilateral cataract that is highly amblyogenic. Other common cause includes drooping of the upper lid up to the eye’s visual axis.\nConstant occlusion of one eye (> 1 week per year of age) due to any cause is very likely to develop amblyopia.\nThis condition arises when the refractive power between the two eyes is >1D. This is a highly amblyogenic stimulus.\nWhen the symmetrical refractive error is >+5.0 DS or > -10.0 DS unilateral amblyopia may occur if correction is not done.\nAstigmatic/ meridional amblyopia:\nThe relative risk of astigmatic amblyopic is increased if cylinder power is > 0.75 DC. Risk is more when there is a difference in axis or if the magnitude between two eyes is different.\nStrabismic amblyopia is caused when one eye is preferred for fixation. If the process is alternating between the two eyes, then the risk is low.\nPathophysiology of Lazy Eye:\nThere is a reduction in the spatial resolving power of the retinal cells.\nLateral geniculate nucleus:\nIn the lazy eye, there is a reduced number of cells in all six layers of the lateral geniculate nucleus.\nThere is a reduction in the number of cortical cells.\nClinical Features of Lazy eye:\n- Decreased visual acuity of two more lines on the Snellen chart.\n- Crowding phenomenon.\nThere is an abnormality of contour interaction between the point of fixation and the adjacent objects. Visual acuity is better for single optotypes than for multiple optotypes.\n- Normal ocular examination.\n- Decreased contrast sensitivity.\n- Binocular suppression of amblyopic eye.\nManagement of Lazy Eye:\n- Patching: Covering the stronger eye with a patch can force the brain to use the weaker eye. This is a common treatment for lazy eye in children and can also be effective in adults.\n- Glasses or contact lenses: Remove refractive error and perform cataract surgery for cataracts\n- Vision therapy: Vision therapy is a form of rehabilitation that can help to improve the visual skills of the affected eye. This may include exercises to improve eye coordination and strengthen the eye muscles.\n- Atropine eye drops: Atropine eye drops can be used to temporarily blur the vision in the stronger eye, encouraging the brain to use the weaker eye.\n- Surgery: In some cases, surgery may be necessary to correct a misalignment of the eyes (strabismus), which can be a contributing factor to lazy eye.\nExclude other causes:\nOther causes of decreased vision such as refractive error, cataract, and tumors should be excluded.\nsurgery for cataracts.\nHow Long Does it Take to Fix a Lazy Eye With an Eye Patch\nOcclusion therapy (GOLD STANDARD):\nThe amount of occlusion therapy for lazy eye depends on the age, severity, and cause of lazy eye.\n- Patching should be started as soon lazy eye is detected.\n- For part-time occlusion, it depends on the age of the patient. 1 hour/day for each year of age.\n- Full-time occlusion should not exceed 1 week per year of age.\n- Patching should be continued for 3-6 months.\n- If there is no progress for consecutive 3 months, patching should be considered a failure.\n- Patching should be maintained up to the age of 9, which is labeled as the age of the matured visual system.\nThis method is preserved for non-compliant or patients who show a failure to patching therapy or lazy eye\n1% atropine drop is placed in the better eye to blur the vision for near.\nImage degradation is made in the better eye so that amblyopic has a competitive advantage.\nIn this method under correction, a better eye is made with optical lenses.\nAdditional Management Principles:\n- Strabismic amblyopia:\n- Occlusion therapy should be started before strabismus surgery. It is done because the fixation behavior will be harder to determine once the strabismic correction is made.\n- Parent motivation towards patching is increased by the visual reminder of strabismus.\n- Amblyopia due to refractive error.\n- Refractive correction is made before patching therapy.\n- Part-time occlusion is preferable if binocular interaction is present, amblyopia is mild and the child is in school.\n- Stimulus deprivation amblyopia.\n- Remove any barrier within the first 6 weeks of life.\nThere are several steps that can be taken to prevent the development of the lazy eye or amblyopia:\n- Early detection: Regular eye exams are important for detecting any potential vision problems, including lazy eye, as early as possible. It is recommended that children have their first eye exam at 6 months of age and then at 3 years old and before starting school.\n- Correction of refractive errors: If a child is found to have a significant difference in the refractive error between the two eyes, or one eye is more farsighted, nearsighted, or has a greater amount of astigmatism than the other, correcting the error with glasses or contact lenses can help prevent the development of lazy eye.\n- Treatment of strabismus: Strabismus, or a misalignment of the eyes, can lead to the development of lazy eye. If a child is found to have strabismus, prompt treatment with glasses, eye patches, or surgery can help prevent the development of lazy eye.\n- Regular follow-up: Children with a high risk of developing amblyopia should have regular follow-up visits with an ophthalmologist or optometrist to monitor their vision and make sure that their treatment plan is working.\n- Awareness and education of the primary care physician.\n- Vision screening programs in all communities.\n- The red reflex of every baby should be checked at birth.\nCan a Lazy Eye Be Fixed\nAmblyopia can be reversed up to the age of 7-8 years, after this age it is usually permanent. It is the average age for the development of normal vision in the human eye, after this, no therapy or treatment can reverse the vision.\nSigns of Lazy Eye\nThe signs of lazy eye, or amblyopia, can vary, but may include:\n- Poor vision in one eye: The affected eye may have a lower visual acuity than the other eye.\n- A tendency for the eye to turn in or out: This is called strabismus and it is a common cause of lazy eye.\n- Lack of depth perception: People with the lazy eye may have difficulty judging distances or perceiving the three-dimensional nature of objects.\n- Crossed or uncrossed eye: The affected eye may appear to be turned in or out.\n- The difference in the size of the pupils: The affected eye may appear smaller than the other eye.\n- Sensitivity to light in one eye: The affected eye may squint or close when exposed to bright light.\nIt’s important to note that not all people with the lazy eye will have all these signs and symptoms, and some people may not have any obvious symptoms. It’s important to have regular eye exams, particularly if there is a family history of lazy eye or other vision problems. This can help to detect the condition early and increase the chances of a successful outcome.\nAt what age does a lazy eye develop\nLazy eye, or amblyopia, typically develops during childhood. The most critical period for the development of vision is between birth and age 7, during this time the brain is actively organizing and interpreting visual input from the eyes. If the eyes are not properly aligned or one eye is significantly more farsighted, nearsighted, or has a greater amount of astigmatism than the other, the brain may begin to favor one eye over the other. This can lead to the development of a lazy eye. However, it is important to note that amblyopia can also occur in adults as a result of injury, disease, or other conditions that affect visual acuity in one eye.\nWhat if there is no response after 3 months of Patching therapy for children\nIf there is no improvement after 3 months, then consider the following\n- Wrong diagnosis\n- Uncorrected refractive error\n- Failure to prescribe specific treatment\n- Irreversible amblyopia\nHow to fix a lazy eye | Treatment for lazy eye\nIn children below the age of 9 years, patching therapy is considered a gold standard. It will force the lazy eye to do it function more effectively while the patch is placed on the better eye.\nLazy Eye Training\nGames/activities designed to challenge the weak eye have proven to be very beneficial, but they are not enough as a single treatment to cure vision.\nLazy eye training tools include certain types of computer or iPad games and activities such as jigsaw puzzles and drawing pictures.\nTraining with computer games and videos to be effective in several small studies, one in 2016 and one in 2018. However, before it can be considered effective enough to be used without other forms of treatment, more research is needed, such as wearing an eyepatch.\nCan lazy eye worse\nIf left untreated the lazy eye may get worse over time. The brain gradually stops picking signals from the lazy eye and it can render a blind eye.\nHow to fix a lazy eye in adults at home |amblyopia in adults\nUntil now there is no treatment option for the fixing of lazy eye in adults. The only possibility that can be provided is the optical correction to the best of its level.\nWhat is Vision Therapy\nThrough a series of progressive therapeutic eye exercises, patients develop visual skills. Visual enhancement is achieved by improving the communication between your brain and eyes.\nVision therapy aims to improve a person’s visual abilities. Vision therapy is performed once per week under the supervision of an eye doctor in sessions lasting 30-45 minutes. uses a variety of ways – such as testing, eye exercises, occlusion (patching) prisms, and lenses to treat visual problems.\nHome exercises are given in the office to reinforce the exercises learned during the therapy session. For best results, commitment to weekly sessions and therapy homework assignments is essential. Through vision therapy, both eyes will be trained to work together to achieve clear and comfortable vision.\nSome vision therapy programs to treat lazy eye may include:\n- Accommodation (focusing)\n- Fixation (visual gaze)\n- Saccades (switching eye focus, “eye jumps”)\n- Pursuits (eye tracking)\n- Spatial skills (eye-hand coordination)\n- Stereopsis (3-D vision)\nLazy eye / Amblyopia affects 3 out of every 100 children. The condition is treatable and usually responds well to strategies such as eye patching and corrective lens wear.\nA lazy eye is something that can be avoided only by having a check-up with a pediatric ophthalmologist at an early age. The best results for a lazy eye are usually seen when the condition is treated early, in children 7 years of age or younger.\nCan lazy eye be cured in adults?\nStudies funded by the National Eye Institute (NEI) found that lazy eye can be successfully treated even in adults. Vision therapy is a customizable, individualized treatment program performed under the supervision of an eye doctor\nHow do adults get rid of lazy eye?\nVision therapy is an effective treatment method for amblyopia in adults.\nWhen is it too late to fix a lazy eye?\nIt’s never too late to get treated for a lazy eye. some optometrists say It is possible to treat amblyopia in adults via vision therapy\nCan glasses fix a lazy eye?\nGlasses are just a tool when treating your lazy eye. The main method is by patching the good eye.']	['<urn:uuid:924f6607-9ec4-42fc-a748-f043e7a5fd15>', '<urn:uuid:dc741fce-f5df-47bc-aa0b-88ea83447228>']	factoid	with-premise	verbose-and-natural	similar-to-document	multi-aspect	novice	2025-05-01T22:47:46.423955	26	82	3413
90	What issues has the Monterey Bay Sanctuary Advisory Council addressed?	The Advisory Council has addressed numerous major issues including: Joint Management Plan Review, Oil & Gas Exploration, Cruise Ship Discharges, NOAA Coordination on Fishing Issues, Fiber Optic Cables, Kelp Harvesting & Management, Southern Sea Otter Translocation Program, Vessel Traffic Safety, Coast Highway 1 Management Plan, Water Quality Protection Program, Assessment of the National Marine Sanctuary Program, Collection of Jade at Jade Cove, Prohibition of Chumming for Great White Sharks, Moving ATOC Project Outside Sanctuary Boundaries, Decommission of Select National Weather Buoys, National and World Ocean's Conference, Advisory Council Charter and Protocols, and State Mussel Watch Program.	"[""MBNMS Sanctuary Advisory Council\nThe Monterey Bay National Marine Sanctuary Advisory Council was established by Federal law to assure continued public participation in the management of the Sanctuary. Since its establishment in March 1994, the Advisory Council has played a vital role in the decisions affecting the Sanctuary along the central California Coast. The Advisory Council's twenty voting members represent the following user groups: Agriculture, At-Large, Business/Industry, Commercial Fishing, Conservation, Diving, Education, Recreation, Recreational Fishing, Research and Tourism, plus seven local and state governmental jurisdictions. In addition, the respective managers for the four California National Marine Sanctuaries (Channel Islands, Cordell Bank, Gulf of the Farallones, and Monterey Bay), the Elkhorn Slough National Estuarine Research Reserve and the U.S. Coast Guard sit as non-voting members. Members are appointed competitively by the National Oceanic and Atmospheric Administration and serve three-year terms. The Advisory Council meets bi-monthly in open sessions located throughout the almost 300-mile boundary of the Sanctuary.\nThe following list includes some of the major issues the Advisory Council has addressed:\n- Joint Management Plan Review\n- Oil & Gas Exploration\n- Cruise Ship Discharges\n- NOAA Coordination on Fishing Issues\n- Fiber Optic Cables\n- Kelp Harvesting & Management\n- Southern Sea Otter Translocation Program\n- Vessel Traffic Safety\n- Coast Highway 1 Management Plan\n- Water Quality Protection Program (WQPP)\n- Assessment of the National Marine Sanctuary Program\n- Collection of Jade at Jade Cove\n- Prohibition of Chumming for Great White Sharks\n- Moving ATOC (Acoustic Thermometry of Ocean Climate) Project Outside Sanctuary Boundaries\n- Decommission of Select National Weather Buoys\n- National and the World Ocean's Conference\n- Advisory Council Charter and Protocols\n- State Mussel Watch Program\nThe Advisory Council is supported by four working groups: the Research Activity Panel (RAP), the Sanctuary Education Panel (SEP), the Conservation Working Group (CWG), and the Business and Tourism Activity Panel (BTAP). The working groups are composed of experts from the appropriate fields of interest and meet monthly or bimonthly, to serve as invaluable advisors to the Advisory Council and the Sanctuary Superintendent.\nDedicated Advisory Council members have laid a strong foundation for the Sanctuary's structure, policies, and procedures. Sanctuary goals to promote research, education and resource protection are a major focus for the Advisory Council, and members work diligently to promote public stewardship. The Advisory Council has proven to be a powerful voice for the general public, responding to citizen concerns, ideas and needs. The Advisory Council provides a public forum for its constituents, working to enhance communications and provide a conduit for bringing the concerns of user groups and stakeholders to the attention of Sanctuary Superintendents and the National Oceanic and Atmospheric Administration Headquarters in Washington, D.C.\nThe Advisory Council maintains a firm commitment to the goals and objectives of Monterey Bay National Marine Sanctuary. The council is a community- based body that provides a public forum for consultation on resource management issues. The Advisory Council appreciates the efforts of volunteers, non-profit organizations, businesses, and citizens, without whose support the mission of the Sanctuary would be difficult to realize.\nThank you for your interest in the Monterey Bay National Marine Sanctuary Advisory Council. If you have questions, or wish to join the advisory council, feel free to contact the Santuary Advisory Council Coordinator.\n|Monterey Bay and Gulf of the Farallones Advisory Council members at Elkus Ranch in Half Moon Bay after the joint advisory council meeting on February 18, 2010|""]"	['<urn:uuid:3e51941d-c417-46ac-8a3c-1aa43ce515cf>']	open-ended	direct	concise-and-natural	similar-to-document	single-doc	expert	2025-05-01T22:47:46.423955	10	96	573
91	prototype vs agile testing changes feedback	While both approaches deal with changes and feedback, they differ in their focus. Prototyping emphasizes collecting user feedback on mockups before development to validate concepts and refine requirements. In contrast, agile testing focuses on conducting iterative tests from the end user's perspective during development, with testers providing immediate feedback and suggestions to the development team throughout the process.	['Design thinking is quickly entering the vocabulary of IT leaders. Just a few years ago,\nthe approach was largely confined to industrial design and product design circles. However, enterprises looking to differentiate themselves through custom software development are realising they must focus intently on user experience. Design thinking helps ensure applications provide the right user experience—and thus, the intended benefits—by fostering an iterative, user-centric approach across the entire application lifecycle.\nThere are a number of aspects to taking a design thinking approach to application development including being empathetic to your users, defining insights, ideation, prototyping and evaluation. In this article I’ll do a deep-dive into the concept of prototyping.\nPrototyping is a key component of the design thinking process. The first phase of an application development process is to put yourself in your end-users’ shoes. Gather information about intended users and their needs through interviews and shadowing. Define the requirement and develop a functional protype to bring ideas to life and review with users, before embarking on the actual development. Prototypes serve to test ideas by giving end users and business stakeholders something tangible to react to. It’s likely that via prototyping you’ll discover that some initial concepts miss the mark. It’s important to engage the business in continuous dialog and encourage feedback so that the development team can continuously iterate towards the desired solution.\nGlobal design consulting firm, IDEO has a saying, “If a picture is worth a thousand words, a prototype is worth a thousand meetings!” Through the process of making prototypes, a development team is able to think deeply, ask questions, and begin to uncover the true requirements for the solution—in a way that creating abstract specification documents could never replicate.\nPrototypes don’t need to be thrown away\nMany believe that prototypes serve a temporary purpose and are ultimately meant to\nbe replaced by something better. Practices like throwaway prototyping or rapid prototyping advocate for the creation of a mockup that’s eventually discarded rather than becoming part of the final delivered software. Developing the prototype quickly is important to minimise the time and money spent on the throwaway prototype. The idea is that it’s better to focus on validating concepts and refining requirements early on, rather than investing in building software that will change significantly.\nBut what if you could have the best of both worlds: the ability to rapidly create a prototype to collect feedback from users, and the ability to continue refining it and have it ultimately become the production application? You’d still get the benefit of learning through prototyping, having spent minimal time and money in the process. On top of that, the time to value for the final solution would be accelerated, because you wouldn’t need to throw the prototype away and start from scratch.\nLow-code application development platforms progress prototyping through to production\nThis is the power a low-code development platform brings to the design thinking approach. Low-code platforms employ visual, WYSIWYG development techniques that are ideal for enabling small, cross-functional teams, and even individuals, to iteratively design and build applications; progressing them through prototyping and onwards into production.\nIn the context of design thinking, developers and even business domain experts can leverage a low-code platform to quickly construct functional prototypes for validation with users. Pulling from a variety of reusable templates, functional components, and professionally designed UI elements, they can assemble screens, and begin building the application’s logic and underlying data model, without needing to create everything from scratch. Once it’s ready for feedback, the prototype can be shared with a single click and previewed instantly across web, mobile, and tablet devices. Users can provide feedback via an embedded feedback widget, and a closed loop brings this feedback directly into the development environment, facilitating rapid iteration.\nUsing a low-code platform, it is certainly possible to create throwaway mockups with the same speed and ease you would experience using common prototyping tools. In fact, as noted above, many prototypes will simply miss the mark based on feedback from users. These can be discarded without a major investment of time and money, and the team can move on to the next one.\nBut a prototype that does resonate with users can be carried forward, forming the basis of the actual finished application. The team can extend it with complex logic, integrate it with other systems, define a fine-grained security model, and more. They can leverage built-in agile project management tools to iteratively develop the solution, continuing to solicit and adapt based on user feedback. Lastly, a cloud-native architecture with out-of-the-box high availability and failover ensures that the application can be deployed at scale.\nThere are many large organisations that pursue an iterative approach to development. ADP, a payroll technology provider is a good example. The company’s product incubator embraces design thinking, especially the principle of empathy.. Once the team develops a deep understanding of an app’s intended users, they use a low-code platform to quickly build a working application that they test with real users and iterate based on their feedback. One recent app, Compass, was so successful that after rolling it out to 50,000 employees worldwide, ADP commercialised it, selling it externally.\nCombine rapid prototyping with the ability to develop and deploy enterprise-grade apps\nWhile prototyping tools will always have a place, particularly for wireframes, a low-code platform is an ideal solution for organisations looking to bring together the benefits of prototyping with the need for accelerated delivery timeframes. In the context of a design thinking approach, low-code platforms enable teams to quickly construct functional prototypes for validation with users. Because these prototypes can evolve all the way to robust production apps, time to value is reduced significantly because you don’t have to throw the prototype away and start building the production app from scratch.', 'Agile Development Model\nWhat is Agile Model?\nMeaning of Agile is ‘moving quickly’. This software development methodology is based on iterative and incremental model of software development.\nThere were certain principles on which the agile model was to be based. The most important of the principles is customer satisfaction by giving rapid and continuous delivery of small and useful software. The delivery of the software happens at regular intervals as opposed to after a number of months, which is the case with the waterfall model.\nThere is a lot of scope for cooperation between the business people and the developers, as the requirements keep coming from the business people at regular intervals. There is a lot of emphasis laid on technical excellence and good design of the software. The software development team has to adapt regularly to the changing circumstances.\nAgile modeling is a methodology, which makes use of practice for modeling and documentation of software based systems. Traditional modeling methods in software development projects have given way to these practices which are applied in a more flexible manner\nTypes of Agile Methodologies\no Extreme Programming (XP)\no Agile Unified Process (AUP)\no Dynamic Systems Development Method (DSDM)\no Essential Unified Process (EssUP)\no Exia Process (ExP)\no Feature Driven Development (FDD)\no Open Unified Process (OpenUP)\no Crystal Clear\no Velocity tracking\nThere are different methodologies, which are a part of the agile model. The most famous one is scrum methodology. Like all the other agile computer programming, scrum is also an iterative and incremental methodology. This methodology is different than the other methodologies because, the idea of empirical process control was introduced in this process. As a matter of fact, scrum was introduced for software project management. However, it was eventually also used for software maintenance.\nThe best part of the scrum methodology is that it makes use of real world progress of a project, which is used for planning and scheduling releases. The entire computer software project is divided into small parts known as sprints. The duration of sprint can range from one week to three weeks. At the end of the duration of the sprint, the team members along with the stakeholders meet. This meeting helps in assessing the progress of the project and chalk out the further plan of action. This assessment helps in taking stalk of the current state of affairs and rework the line of work and complete the project on time and not just speculate or predict the further outcome.\nExtreme programming (XP)\nIt is a software development methodology which is intended to improve software quality and responsiveness to changing customer requirements. As a type of agile software development, it advocates frequent “releases” in short development cycles, which is intended to improve productivity and introduce checkpoints where new customer requirements can be adopted.\nOther elements of extreme programming include: programming in pairs or doing extensive code review, unit testing of all code, avoiding programming of features until they are actually needed, a flat management structure, simplicity and clarity in code, expecting changes in the customer’s requirements as time passes and the problem is better understood, and frequent communication with the customer and among programmers. The methodology takes its name from the idea that the beneficial elements of traditional software engineering practices are taken to “extreme” levels, on the theory that if a little is good, more is better.\nCritics have noted several potential drawbacks, including problems with unstable requirements, no documented compromises of user conflicts, and a lack of an overall design specification or document.\nAgile Model in Software Testing\nAgile model is not only used in software development, but also for software testing. Agile model testing is carried out from the perspective of the end user. There is no emphasis, which is laid on the rigid testing procedures, but the focus is rather on conducting the tests iteratively on the newly developed software component, as well as regression tests are carried out on the entire software to check if any new bugs were introduced into the software. In the agile testing model, the focus shifts from ‘testers as quality watchdog’ to ‘the entire team quality watchdog’.\nAs the name of the testing methodology suggests, the testers have to adapt themselves to rapid development cycles and make the required changes to the test suite. In this software testing type, the aim is to test from the perspective of the customer as early as possible in the development process. Because the testers are involved early on in the entire process of software development, they give the necessary information, feedback and suggestions to the development team, rather than after the development has come to the final stages.\nAgile model has given the software development process an effective and practice based methodology. Therefore, the principle ‘maximize stakeholder value’ can actually be put into practice, leaving the customer satisfied and happy.\nAdvantages of Agile Model\nThe most important of the advantages of agile model is the ability to respond to the changing requirements of the project. This ensures that the efforts of the development team are not wasted, which is often the case with the other methodologies. The changes are integrated immediately, which saves trouble later. There is no guesswork between the development team and the customer, as there is face to face communication and continuous inputs from the client. The documents are to the point, which no leaves no space for ambiguity. The culmination of this is that a high quality software is delivered to the client in the shortest period of time and leaves the customer satisfied.\nDisadvantages of Agile Model\nIf the projects are smaller projects, then using the agile model is certainly profitable, but if it is a large project, then it becomes difficult to judge the efforts and the time required for the project in the software development life cycle. Since the requirements are ever changing, there is hardly any emphasis, which is laid on designing and documentation. Therefore, chances of the project going off the track easily are much more. The added problem is if the customer representative is not sure, then the project going off track increase manifold. Only senior developers are in a better position to take the decisions necessary for the agile type of development, which leaves hardly any place for newbie programmers, until it is combined with the seniors resources.']	['<urn:uuid:0d7129d5-e47d-4290-bf27-c10e7070b0b3>', '<urn:uuid:425720e0-265d-49a6-a476-8bccebbf8d76>']	factoid	direct	short-search-query	similar-to-document	comparison	novice	2025-05-01T22:47:46.423955	6	58	2027
92	As someone deeply interested in religious studies, I'm curious about how traditional Judaism views the relationship between human moral development and divine commandments. Can you explain their perspective on this?	According to Jewish tradition, human morality is meant to precede and complement divine commandments, not be replaced by them. This is illustrated by the teaching that 'for twenty-six generations, proper behavior (Derech Eretz) preceded the Torah.' The Torah was not given during humanity's earliest years because moral preparation was necessary first. Even after receiving the Torah, human morality should exist within a Jewish person just as it does in everyone else, with Torah serving as an additional spiritual level above this foundation. In fact, it's considered problematic when religious observance suppresses natural morality - as Rabbi Abraham Isaac Kook warned, if fear of God pushes aside natural morality, it is no longer pure fear of God. This is why the Torah doesn't require observance of commandments for the first thirteen years of life, allowing time for moral character development first.	"['Rabbi Oury Cherki\nHow are Torah and Morality Related?\nA. The Universal Character of Ethical Wisdom\nThe wisdom of morality involves the definition of good and evil, and it therefore involves human education. This activity is universal and is not confined to the nation of Israel. In every human society, general rules are developed for appropriate behavior, based primarily on human nature, which is basically decent. Even though ethical norms differ from one society to another, the general goal of every moral code is to keep mankind honest and on a straight path.\nIn every era, there are discussions among human beings on the subject of appropriate behavior. Some questions, such as whether people should honor their parents, have been decided and are accepted by a broad range of people. But other questions, such as whether mankind should refrain from eating the flesh of animals, do not yet have widespread agreement. In our era, eating meat is not generally considered to be offensive behavior even though it requires taking a life in order to give pleasure to a human being.\nThe rules of morality of various human societies are a result of accumulated historical experience by a method of trial and error. Bildad, one of the friends of Job, says, ""Just ask the first generations and investigate their ancestors, for we only came yesterday and our days are nothing more than a shadow"" (Job 8, 8-9). That is, with respect to basic questions, a man must depend on the experience of earlier generations. It cannot be assumed that everything the ancients said is absolute truth, but even based on their errors it is possible in the end to generate a valid ethical approach. In addition, the moral tendency of the human race has been continued to develop during our entire history, and the result is that ethical rules have improved and have reached higher levels than before.\nB. What is the Source of Morality?\nThe root of the moral tendency that exists within the human soul is the attempt to get closer to G-d. Every human society has a direct relationship with the source of all life, and this leads to a yearning for good and for honesty. At times, the character of the open relationship to the source of life is so idolatrous and coarse that the only way for the human race to advance ethically is by denying this relationship. But it should be noted in reality this progress stems from an even more sensitive search for G-d.\nMoral rules are an expression of the will of G-d, but this is revealed in mankind through human nature and not as a command. The Holy One, Blessed be He, created man with the ability to understand that certain types of behavior are appropriate and others are not. For example, the human soul should naturally demand that murder be avoided, and this is not merely a social or religious commandment. In addition, it is possible that such trends started out as laws written by human beings which were then transformed into a social norm, since the human soul became adapted to them.\nC. The Torah is not a Substitute for Human Morality\nThe Torah was not given to the nation of Israel in order to be a substitute for human morality. Human morality should exist within a person of Israel just as it can be found in the heart of each and every person, and the unique spiritual level of the Torah lies on top of this. A person with weak moral strength who encounters the commands of the Torah is liable to reach a status of even greater moral depravity, because within every command he will search for the permitted ways to fulfill his own lowly aspirations (and the powerful emotions of holiness will provide an even stronger ""motivation"" for his actions). For example, if a person does not have a natural understanding of the moral depravity involved in spreading slander about another person and all of his social interactions will be based merely on the limits of halacha, he will be able to spend all of his days spreading slander in permitted ways – without any feeling of how his soul is harmed by his own actions. This is what the Rambam ruled: ""Torah should only be taught to a student who is decent in his actions or to a simple person. But if a person is on an evil path he must be returned to a proper path and tested. Only afterwards should he be brought into the House of Study and taught."" (Laws of Torah Study, 4,1).\nThe Torah did not require a person to observe the commandments for the first thirteen years of his life in order to allow him to first build up his moral character.\nD. Why is it Wrong to be Hasty about Morality?\nIn human history too, proper behavior preceded the Torah, as is written: ""For twenty-six generations, Derech Eretz – appropriate behavior – preceded the Torah."" (Vayikra Rabba 9,3). The Torah was not given during the earliest years of humanity because it was first necessary to have proper preparation in terms of values. This fact leads directly to the conclusion that advances in Torah knowledge must never weaken natural morality. Rabbi Abraham Isaac Kook (the first Chief Rabbi of the Land of Israel, who was one of the spiritual giants of modern day Judaism, 1865-1935) warned about this danger. He wrote: ""It is wrong for the fear of G-d to push aside the natural morality of a man, because if it does so it is no longer a pure example of the fear of G-d."" (Orot Hakodesh Volume 2, page 27).\nAn example of a very problematic suppression of natural morality can be seen in the process of the expansion of Christianity in Europe. This religion forced the nations of Europe to observe parts of the Torah of Israel (many of them had developed a high cultural level but remained moral barbarians). This coercion was accomplished without the natural preparation that was necessary to develop the morality of the soul, and the result was therefore not suitable for the internal nature of these nations. One of the consequences of this process was the atrocious events of the Second World War, which acted as a release for barbaric tendencies of the soul that were not rooted out by moral teachings matched to the character of the people. Here is what was written by Heinrich Heine (a Jew, one of the greatest authors and poets of modern Germany, 1797-1856): ""In Germany there will take place a drama which will give the French Revolution the appearance of a harmless idyll. Christianity has suppressed the militaristic enthusiasm of the Germans for the time being but did not destroy it. As soon as the restraining talisman breaks, violence will break out again...""\nThere is a religious temptation to decide that by observing the commandments a person fulfills his moral obligations. This is very dangerous because it might cause a religious person to ignore some of the most basic factors of his personality. Rabeinu Saadia Gaon (one of the ""geniuses"" of Babylonia, the head of the yeshiva of Sura, 882-942) writes in his book ""Faith and Knowledge"" (Chapter 3, 8) that a man once said to him: If a prophet would command us to do something that contradicts the intellect or ethics we would be required to listen to him, since the moment that G-d gave a command, the act became true and moral. Rabeinu Saadia disagreed, and he claimed that a man who commanded others to perform acts that are illogical could never be considered a prophet, and therefore we would not listen to what he said. The man replied that truth and morality are established only according to the commands of G-d and that no human being can interfere, and he concluded that we would be required to listen to the prophet. Rabeinu Saadia wrote that at that moment he stopped talking to this man.\nThere are periods of time when those who observe the Torah might be lacking in specific traits of proper behavior, such as love for fellow men or the desire to mend society. This leads to moral criticism of the people, and this can quickly be transformed into criticism of the Torah itself.\nThe truth is that the word of G-d will never be revealed to mankind without a prior moral introduction, because an immoral person is neither worthy of nor ready for the holy words. It is therefore wrong to view the word of G-d that comes through revelation as ""true morality"" and to ignore everything else on which it depends.\nE. The Objective of the Torah\nIn view of the above, the Torah was given with a background of the moral development that preceded it, with the goal of lifting mankind up to a higher moral level. The Torah is the word of G-d, who turns toward mankind, and mankind must listen to this word after having perfected Derech Eretz – proper behavior – which lifts man up towards G-d. A lack to reach the level for which the Torah is aiming is not a moral lack – the nations of the world are required to be ethical, even though they are not required according to Jewish tradition to observe the mitzvot.\nBut this then leaves us with a dilemma: Why did the Torah give us commands about things which human morality had already achieved, such as murder and robbery? There are various answers to this question. For example, Rabeinu Saadia Gaon wrote that even the moral commandments have many details that mankind would not have discovered on their own, and for this reason revelation is needed. In ancient times, the Romans wrote that the Jews are strange people because they claim that killing a young baby is the same as murder. Human morality accepts that it is wrong to take a life, but there are delicate questions that are very difficult to answer. For instance, is mercy killing murder or not? Is it murder to kill a fetus or not? Is there any difference between a fetus and a newly born infant? The Torah has provided detailed halachic answers to these questions or has given methods to arrive at an answer. The Maharal of Prague (a master of Kabbalah and a prominent Jewish philosopher, 1520-1612) explains this concept in another way: From the moment that the nation of Israel was given the command, ""Thou shall not murder,"" the prohibition – which until then was nothing more than a moral imperative which helped people to achieve perfection – was transformed into a Divine command which allows mankind to cling to the infinite. This is a new way of looking at this prohibition, a perception which removes the prohibition from the realm of human morality.\nF. In the End – Morality Remains\nAn important note should be added, something that is most relevant for the nation of Israel. In addition to the above considerations, there is an intrinsic moral value in observing the mitzvot that stems from the very fact that they are the words of G-d as transmitted to the children of Israel. Any person who rebels against the source of life – against the holy One who turned to him – is acting in a way that shows a lack of gratitude for what G-d has given him.\nThe moral value of observing the mitzvot can also be described in another way: As a Jew becomes aware of the moral value of the appearance of Israel on the stage of history and of the Jewish contribution to the progress of human morality, and as he begins to understand the importance of belonging to the nation of Israel as expressed by performance of the mitzvot – this becomes a moral imperative for him. Based on reasoning in the Kabbalah, this approach can be expanded to a statement that the performance of a mitzva is moral in itself, since the act of performing or ignoring a mitzva either mends or harms the part of the world to which the mitzva is linked. This is a way of emphasizing the moral demands on a person: a human act can mend the situation or cause harm. (The moral character of a person will still depend on his ability to recognize the morality of the act itself, and therefore anybody who does not recognize the moral significance of an act or does not view it as an obligation will not be considered an immoral person.)\nNote also that the sages declared, ""If there is no Derech Eretz there is no Torah, and if there is no Torah there is no Derech Eretz"" (Pirkei Avot 3,17). That is, proper moral behavior must precede the Torah, but after the Torah has been revealed based on the a priori existence of Derech Eretz, a new and higher-level moral code is derived from the Torah.']"	['<urn:uuid:1ad7cd77-0c18-4495-856f-3499aad862de>']	open-ended	with-premise	verbose-and-natural	distant-from-document	single-doc	expert	2025-05-01T22:47:46.423955	30	140	2169
93	software development lead need comparison between integration testing error metrics vs quality metrics framework hierarchy for decision making	Integration testing error metrics and quality metrics framework hierarchy differ in their approach to supporting decision making. Integration testing metrics focus on quantifiable measures like total errors uncovered, errors by week, and correction hours per error, with the expectation of decreasing numbers over time. The quality metrics framework hierarchy, however, starts with establishing quality requirements and goals, then assigns quality factors, and finally decomposes these into direct metrics. While integration testing metrics provide immediate feedback on testing progress, the quality metrics framework creates a structured approach for defining and measuring overall software quality objectives.	['The biggest challenge in establishing an effective metrics programme is not the formulas, statistics, and complex analysis that are often associated with metrics. Rather, the difficulty lies in determining which metrics provide valuable information to the project and/or organization, and which procedures are most efficient for collecting and applying these metrics.\nIEEE Standard for a Software Quality Metrics Methodology IEEE Std 1061-1998 (Revision of IEEE Std 1061-1992) relates software quality to metrics in the following: “Software quality is the degree to which software possesses a desired combination of attributes. This desired combination of attributes shall be clearly defined; otherwise, assessment of quality is left to intuition. For the purpose of this standard, defining software quality for a system is equivalent to defining a list of software quality attributes required for that system. In order to measure the software quality attributes, an appropriate set of software metrics shall be identified.”\nIt is important to be aware that a common misapplication of software metrics is to use them to measure team members productivity against an industry standard. Such comparisons do not earn support for the metrics programme and in fact are likely to cause resentment among the project staff. A metrics programme must focus on much more than productivity measures.\nSoftware metrics are used to quantify software, software development resources, and/or the software development process. Consider these areas of software development that can benefit from inclusion in a planned metrics programme:\n- Product quality\n- Product performance\n- Schedule and progress\n- Resources and cost\n- Development process\nGoals of a Metrics Programme\nA metrics methodology for measuring quality allows an organization to:\n- Identify and increase awareness of quality requirements and goals.\n- Provide a quantitative basis for evaluating and making decisions about software quality in a timely manner.\n- Increase customer satisfaction by predicting and then quantifying the quality of the software before it is delivered.\n- Reduce software life cycle costs by improving process effectiveness and customer satisfaction.\n- Provide feedback on the metrics programme itself and validate the set of metrics being tracked.\nDefining the Metrics Programme Framework\nThe key to the effective software metrics within an organization is to prepare a plan describing how metrics will be used to meet strategic management goals.\nThe first component of a metrics programme is a framework that describes the metrics to be collected, how to collect the data, and how to apply the results of analysis.\n- A software quality metrics framework hierarchy begins with the establishment of quality requirements and quality goals.\n- Then, by the assignment of various quality factors, the project team outlines the definitions for each of the quality requirements.\n- Next, direct metrics for each quality requirements are obtained by decomposing each quality factor into measurable attributes. The direct metrics are concrete attributes that provide more useful definitions than quality factors to analysts, designers, programmers, testers, and maintainers.\nThe decomposition of quality factors into direct metrics facilitates objective communication between management and technical personnel regarding the quality objectives.\nKeep the following questions in mind when considering the direct metric for each quality factor and its quality requirement or goal:\n- What is this metric supposed to tell us?\n- What is the theoretical relationship between the characteristic or attribute to be measured and the measurements being taken?\n- Are you taking these particular measurements because they’re the right ones or because they’re convenient?\nBeware: Often there is a lack of relationship between the metrics and what we want to measure. This makes the metric gathering process difficult and drawing valid conclusions improbable.\nExample Metric and Interpretation\nA sample metric that should be easy to gather from the Defect Database would be the number of existing Defects versus their Status over a series of Builds.\nThe corresponding abbreviated information table for this metric would be as follows:\n|Name||Name to be given to this metric.||Defects Vs Status per Build (Internal Release)|\n|Quality Factors||Quality Factors that relate to this metric.||Stability, Correctness, Completeness|\n|Target Value||Numerical value of the metric that is to be achieved in order to meet quality requirements. Include the critical value and range of the metric.||Zero known defects un-addressed in the Defect database system – Ideal target value for this metric would be to see the trend towards zero defects for status “New” and “ReOpened” and to a lesser extent “Resolved”.|\n|Application / Impact||Description of how the metric is used and what its area of application is. Indication of whether this metric can be used to alter or halt the project (as “Can the metric be used to indicate deficient software quality?”).||This metric is used to keep track of the number of defects in each of the available states in the Defect database. This can be used as one reflection of the level of quality/stability of the current application. In the future these metric values can be used to calculate the defect open/close rates.|\n|Data Items||Input values that are necessary for computing the metric values.||Values used to calculate the metrics:\n– Number of defects with a status “New”\n– Number of defects with a status “Closed”\n– Number of defects with a status “Postponed”\n– Number of defects with a status “Rejected”\n– Number of defects with a status “ReOpened”\n– Number of defects with a status “Resolved”\n|Computation||Explanation of the steps involved in the metric’s computation.||Collect the Data Items for the range of Builds to be considered. Plot each Data Item as a series with Builds along the x-axis and number of defects along the y-axis.|\n|Interpretation||Interpretation of the results of the metric’s computation.||The numbers of defects un-addressed (New, ReOpened, Resolved) will give an idea of the current state of the application, and of the amount of effort that will be required to meet the Target Value(s).|\n|Considerations||Considerations of the appropriateness of the metric (eg: can data be collected for this metric? Is the metric appropriate for this application?).||If a defect has been addressed it does not necessarily need to have been fixed (eg: Postponed, Rejected).Equivalent Minimum Time to perform similar test coverage for testers and defect fixes for programmers on each Build must be available or the data collected will be skewed and interpretations flawed.|\n|Tools||Software or hardware tools that are used to gather and store data, compute the metric and analyze the results.||Tools Necessary:\n– Export of the Defect database to an Excel spreadsheet\n– The Defect database\n|Example||An example of applying the metric.||A sample graph of this metric is shown below.\n[You would insert a graph that displays the number of defects that are in each status used in the Defect Database across a range of Builds.]\nFrom this graph, observations of the trends of each status can allow conclusions to be drawn about the readiness of the software for external release, and how many more Builds are required and how much development and test effort is required to reach that goal.\n-adapted from IEEE Standard for a Software Quality Metrics Methodology\nWith a number of well-defined metrics measured and recorded over time, the subjectivity of future estimates and software evaluations is greatly reduced. The metrics provide a firm quantitative basis for decision-making.\nAs just one example, if you knew that in past projects of certain size and duration that the testing effort consisted of X hours with Y test cases, this information would provide a starting point for estimates in future projects. Of course metrics do not eliminate the need for human judgment in software evaluations; they only provide a starting point for such an estimate.', 'Collecting metrics is the best way to know whether a process is under control and within overall tolerances. The testing process is no different. If you have a large or complex project, you should collect testing metrics to ensure that the process is going well and accomplishing its objectives.\nAs an example, one of the objectives of testing is to catch as many errors as possible. However, you should expect that the more testing you perform, the fewer errors you will catch over time. If your metrics show that you continue to uncover more and more errors over time, it probably means you have some fundamental development processes that are out of control.\nThe place to start\nThe collection of testing metrics starts after the unit testing. Unit testing is too unpredictable and too unstructured to make much sense from a metrics standpoint. However, the following metrics can be captured from integration testing through the end of the testing process.\n- Total errors uncovered: This is strictly a count of each error uncovered. By itself, it does not have as much meaning as when it is combined with other information for analysis.\n- Total errors by week: This measure gives an overall sense for how the testing process is going. You would expect that a vast number of errors would get caught in the early stages of testing. As time goes by, the number of errors uncovered per week should decrease. You may never reach a point were you find no more errors, but the team cannot complete testing if the number of errors is not tapering down close to zero.\n- Number of hours spent correcting errors per week: This metric provides a sense for the relative complexity of errors caught in testing. Early in the testing process, you may encounter errors that are time consuming to correct. However, as the testing cycle proceeds, the time that you spend correcting errors should decrease.\n- Error correction hours per error uncovered: This metric is similar to the prior metric. As you get further and further into the testing process, you should find that the time required to fix the typical error is getting shorter and shorter. If you uncover late errors that are time consuming to correct, it is usually a sign that the errors trace back to problems in the design or business requirements phases.\n- Number of completed test cases/total number of test cases: This metric gives the team a sense for how much work has been completed and how much is remaining.\n- Budget vs. actual effort, cost, and duration: These are standard metrics that point out how the project team is executing the testing process vs. the original estimates.\n- Total testing cost/effort vs. total development cost/effort: This metric provides some perspective on how one project spends its development time vs. other projects. If the average project spends 25 percent of its time in testing and your project spent 35 percent in testing, it might point out certain inefficiencies.\nSlicing and dicing the errors\nError tracking can be tracked in a number of ways. They are all ways to provide further information to help in making decisions on how the testing process is going and where to focus the team’s testing time.\n- Errors by cause: The project team can track and categorize errors that are similar in nature. For instance, program errors will probably account for most errors in the beginning, but you may find later that errors can be traced to poor documentation or operator errors. Errors that are coming from a common cause can be attacked more vigorously.\n- Errors by subsystem: If a small number of subsystems have an unusually high number of errors, it can be a sign that more focus needs to be placed in those particular areas.\nProduction defect metrics\nProblems uncovered in the testing process are referred to as errors. Once the application goes into production status, these same problems are referred to as defects.\n- Number of defects in production: This is an important metric to determine the overall effectiveness of the testing process. In a perfect world, an application would have no errors when it is implemented in production. However, there are always some. Counting these errors gives a sense of the stability of the system. You can capture similar metrics after implementation as you did during the testing process. For instance, you can capture the number of errors per week, which should decline over time, and the number of hours to fix production errors, which should also decline over time.\n- Production downtime: This metric measures the amount of time an application is down because of errors. This can show the business pain caused by production defects.\n- Cost of defects: This metric measures the cost of defects uncovered in production. This can include the cost of fixing the defects and the cost of people and resources that are idled or underutilized because of the downtime.\nMeasurement is the key\nThe only way to really know how your testing is going is to measure it. Here is what you should keep in mind as you keep track of your testing.\n- Testing metrics should be captured to provide a sense for how the entire testing process is progressing.\n- The most important component of testing metrics is the capturing of the number of errors. In addition, further information can be gathered as to the cost and effort associated with correcting the errors. With this information, valuable insight can be gathered into whether the testing process is under control or not.\n- Much of the same information that is captured during the testing process can also be gathered after the application goes into production. At that point, problems should continue to be tracked as defects.']	['<urn:uuid:a3966bcb-2c24-424c-b4a7-f601e0575b70>', '<urn:uuid:40022e69-3449-42c6-a617-395576c58e82>']	factoid	with-premise	long-search-query	similar-to-document	comparison	expert	2025-05-01T22:47:46.423955	18	94	2224
94	innovative hospital care system singapore how different	Alexandra Hospital pioneered a new Integrated General Hospital (IGH) care model in Singapore where patients are cared for by a single care team throughout their stay with minimal transfers. The model integrates acute, sub-acute, rehabilitative, and community care. Key features include having one care team during inpatient stay, minimal transfers between wards, one principal doctor for outpatient appointments, and strong integration with community and primary care. This approach reduces handovers between teams and institutions, allowing patients to receive all necessary care, including rehabilitation, in the same ward.	['Alexandra Hospital pioneers Singapore’s Integrated General Hospital care model\nAlexandra Hospital under the National University Health System partners MOH Office for Healthcare Transformation and Queenstown community stakeholders to co-develop a new model of hospital care, with a view to scale successful solutions\n1 Friday, 14 December 2018 - Alexandra Hospital (AH) is the first healthcare institution in Singapore to roll out a new model of care, called the Integrated General Hospital (IGH), where patients are cared for by a single care team with minimal transfers during their inpatient stay, and their post discharge care is well integrated with the community.\n2 AH, under the National University Health System (NUHS), has partnered with MOH Office for Healthcare Transformation (MOHT) and Queenstown community stakeholders since taking over the hospital from 1 June 2018, to co-develop the IGH. This new model seeks to better meet the needs of a growing group of patients, many of whom are elderly and have multiple medical conditions. Efforts are ongoing to improve and validate processes for the IGH, with a view to scale more successful practices. Over time, it is hoped that more patients who require acute hospital care but not complex tertiary specialist treatment, can be managed through the IGH.\n3 The design of the IGH model was guided by insights from the community at Queenstown. For example, the Health Innovation Project by the Department of Communications and New Media at the National University of Singapore (NUS) reached out to more than 700 respondents around Queenstown, and identified issues faced by the community. Subsequently, AH partnered the Chua Thian Poh Community Leadership Centre at NUS to carry out a Receptivity Study of about 170 residents in Queenstown where residents shared their hopes and expectations of AH’s care models.\nDifferentiating Elements of the IGH\n4 The IGH care model integrates acute, sub-acute, rehabilitative, and community care, and is differentiated by the following elements:\na. One Care Team during Inpatient Stay\nHolistic and coordinated care delivery is anchored by a lead physician who is supported by a multidisciplinary care team, reinforced through tertiary specialist support and anchored by five key clinical programmes.\nTwice a week, a multi-disciplinary team of doctors, nurses, therapists, medical social workers, pharmacists and care managers meet up to look through each patients’ case notes and discuss the best consolidated care plan for the patient. In the IGH model, multi-disciplinary team rounds are not always doctor-led, but can be led by other members of the care team, depending on the patient’s needs at that point of time.\nb. Minimal Transfers during Inpatient Stay\nResources and services provided by the care team are sensitive to the recovery needs of each patient. Acute care and rehabilitative care take place in the same ward, reducing the hassle and risks of handovers between disciplines, teams and institutions. The patient is also not transferred out to a community hospital but will be able to receive similar rehabilitative care at AH until he or she is fit for home.\nThe patient is cared for by the same care team from admission and treatment, through to rehabilitation and discharge. This provides the opportunity to build trusted relationships between patients, caregivers and the care team.\nc. One Principal Doctor at Outpatient Clinic Appointments\nThere are five key programmes at AH designed to wrap care around the needs of patients. Under these programmes, multiple specialist outpatient clinic sessions are consolidated and helmed by one principal doctor in one appointment, thereby enabling holistic care of multiple chronic conditions, reducing visits and addressing issues like poly-pharmacy.\nd. Integration with the Community, Primary Care, and Home\nAH works with care teams in primary care and the community to facilitate seamless handovers and shared care. Discharge planning begins soon after a patient is admitted to the inpatient ward.\nClose ties are being built and shared care processes worked out between AH and family physicians in the community, including named discharges of patients from AH to primary care, and direct access for patients to AH services through primary care referrals. To this end, [email protected], a service helmed by care managers, expands the hospital’s current transitional care programmes. [email protected] helps patients in the community navigate healthcare options, including hospital care and community care, facilitates management of medical and social emergencies, and collaborates with and taps on strong networks of community partners to better match resources to needs. For example, [email protected] provides care advice over the phone; efficiently contacts the individual’s primary physician; links patients to social support, day care, and home and community services beyond AH; and enables fast-track access to AH services or fast track admission to hospital wards. During each admission, AH patients are introduced to the centralised hotline which is manned by care managers.\ne. Zero-based Design\nThe IGH employs a zero-based design approach, where a clean slate is applied to designing, prototyping and innovating in areas like new care models, technology application and physical space.\nPartnering MOHT to Develop and Scale Solutions\n5 MOHT was established in January 2018 by the Ministry of Health to address fundamental and longer-term issues critical for healthcare transformation. AH has been actively collaborating with MOHT, leveraging MOHT’s expertise and capabilities to develop agile collaborations that help to address challenges faced by patients and families.\n6 In addition, MOHT is developing enablers to facilitate the replication and scaling of successful solutions. These include developing effective ways for health professionals to partner patients and the community in designing care so that it can be more patient-centric; and optimising the use of IT and technology\nCo-Creating Care with Patients and Families\n7 The IGH model allows AH to partner stakeholders to discover and address important factors that contribute towards improving health outcomes holistically. Explained Professor Tan Chorh Chuan, Executive Director of MOHT : “Taking a whole-of-community approach to designing care models is important because social, behavioural and environmental factors play a big role in the health and well-being of patients. Therefore, healthcare delivery models need to continue to integrate further with community support and resources, so as to enable better outcomes.”\n8 To this end, patients and Queenstown residents will play a significant role in co-designing and co-creating care at AH for other patients. AH has established the Alex Advocates, a patient and family engagement and advocacy group. Alex Advocates will be involved in various stages of care design and delivery ranging from enriching discussions that impact practice and policy at hospital management level, to leading improvement initiatives as part of an extended AH resource.\n9 AH and MOHT are rolling out a series of efforts with a larger community of carers and residents around Queenstown, guided by DesignSingapore Council and their networks. These efforts will see patients, caregivers, volunteers, community partners and hospital staff coming together to co-design solutions to common challenges faced by patients in their care journey. For a start, the team is looking critically at improving pathways and resources for patients transitioning from hospital to home.\n10 As part of enabling future capabilities for [email protected], AH and MOHT are working together on Patient Activated Community Transitions (PACT) to review workflows and develop toolkits to help care teams better assess patients for their knowledge, skills and confidence to manage their own health. Interventions are designed for each patient based on his or her activation level, as well as medical, social and functional needs. Care managers will be trained in activation assessment, motivational interviewing, health coaching, resource allocation and community care; and will journey with the patient from the inpatient setting to the community. Patients will get the opportunity to do care planning, goal setting and shared decision making hand in hand with their care teams.\nEnabling Patient Centric Care through Technology\n11 AH and MOHT have also co-designed technology-enabled workflows in the form of a Technology Enabled Nursing Documentation (TEND) application prototype that streamlines, structures and automates nursing documentation at the wards. The team adopted an iterative approach in building the app, which included regular walk-abouts, focus group discussions, and surveys. Training collaterals to supplement learning have also been developed. The app, which is being piloted at AH ward(s), shows promise in improving decision support for nurses and enabling nurses to spend more time on direct care with patients. Through the app, ward nurses are also encouraged to ask key care-related questions and consider relevant tasks according to a structured framework that takes in each patient’s holistic needs. This empowers each ward nurse to practise at the top of their licence. Over time, nurses can also be upskilled to handle more complex tasks.\nImagining Future Wards of IGH\n12 AH is working with MOHT to redesign two wards, where future-ready ideas for a technology-enhanced healing inpatient environment can be rapidly developed and tested. Design thinking principles will be applied – e.g. modular components and integrated service highways that can allow rapid addition and reconfiguration of mechanical and electrical systems, information technology, robotics and other forms of care innovation. In the longer term, AH seeks to discover successes from its various pilots and deploy these at scale in its future infrastructure, as it develops the campus in phases. AH is evaluating proposals submitted for the design of the future inpatient wards. Patients, caregivers and families, members of the public, as well as community care and social care partners will be invited to share their opinions on co-creating a more holistic care experience at the wards.\nVision for AH’s IGH Care Model\n13 Chief Executive of NUHS, Professor John Eu-Li Wong said, “The implementation of the IGH model is in line with NUHS’ and AH’s aim to build a new model of hospital care and develop a health-empowering campus around Queenstown. We are harnessing the strengths and expanded capacity of the whole of NUHS and its partners to transform how illness is prevented and managed holistically both in the hospital and in the community.”\n14 Chief Executive Officer of AH, Associate Professor Jason Phua said, “Whatever we do at AH, we must always keep in mind that it is for our patients, their families, and the community – people that we should and will work with to co-design the hospital and campus.”']	['<urn:uuid:fcd6d094-75d0-45df-ba11-d558de8811a2>']	open-ended	with-premise	short-search-query	distant-from-document	single-doc	novice	2025-05-01T22:47:46.423955	7	87	1694
95	drywall repair versus primer application which process requires more coats for optimal results	Drywall repair typically requires 2-3 coats of compound to achieve a smooth finish, while proper priming is generally a single-step process before the topcoat. However, applying a primer can actually reduce the number of topcoats needed for the final finish.	"['Drywall is one of those things that looks so simple when someone else is doing it...and it can be for you too, if you\'re armed with the right information and have a little patience. Taping an entire house, or even a large room can be a challenge - creating a perfectly smooth finished surface is a bit of an art, and it takes some practice. Our homes take a beating from the weather, kids, pets, and swinging doors - which means almost everyone has a few cracks, minor dents and dings, or even a few holes in our walls - repairing them is a good way to get your feet wet, and is a pretty manageable project for the uninitiated.\nIf you have minor cracks in your walls, you can scrape them out to create an inverted \'V\' with a knife or chisel, and simply fill with pre-mixed compound using a taping knife. This gives the new compound a better chance to bond to the old surface. 2 coats are often required as the first coat will shrink as it dries. After a quick sand, you\'re ready to prime and paint the repaired areas. For holes, it gets a little more involved. Avoid the temptation to fill the hole with crumpled up newspaper and handfuls of drywall compound - there\'s an easier way. Cut yourself a square of new drywall that\'s slightly larger than the damaged area, hold it on the wall and trace the edges onto the wall. Cut out the damaged section, and your new piece should fit perfectly into the hole. Now you\'ll need a way to secure the new piece of drywall into the existing wall...if you are able to use the existing studs, attach the new piece of drywall using 1 5/8"" drywall screws. If the damage is between studs, all is not lost - attach scrap wood across the inside of the opening, being sure to leave enough exposed to attach your new piece of drywall, or pick up a package of drywall clips (they come with screws and instructions!) and secure them around the perimeter of the hole. Insert your new piece of drywall, and screw it in. Now you\'re ready for the compound...\nUsing a 5 or 6"" taping knife, apply some compound (about 1/8"") around and over the patch, being sure to fill the gaps and cover the screws. Apply some paper or fibreglass drywall tape over the joints, and set it into the compound using your taping knife. You\'ll want to hold your knife at about a 30 degree angle to the wall, and apply enough pressure to smooth out the compound and remove the excess, but not enough to pull the tape off the wall - holding one end of the tape against the wall will help. Be sure to fully cover the exposed tape with a thin coat of compound, smooth it out as best you can, and let it dry completely. If you don\'t want the patch to be noticeable, you\'ll need to feather out the edges with 2 or 3 more coats of compound - when each coat has dried, lightly sand it smooth, and apply another thin coat - the trick here is that more thin coats are better than less thick coats. Be careful not to sand too much, or you\'ll expose the tape and have to start all over again.\nIf you secure your new piece of drywall well, the worst that can happen is that you\'ll end up having to apply more compound and try again. A patch typically requires 2 or 3 coats to make it smooth - when you\'re happy with the finish, prime the area and paint over it. Voila - damage disappeared!', '4 Reasons You Should Think Twice Before You Skip the Primer\nPriming Can Be as Important as Any Other Step in the Coating Process\nApplying industrial coatings in manufacturing is one of the many steps to getting a product ready to ship. And though the coating process is just one of those many steps, the technology within the coating process may have a number of steps itself. For many products, one of the most important is priming the surface. Primers are meant to secure the durability of the topcoat when it is applied to a potentially incompatible, or less than optimal subsurface. They also bring valuable performance benefits to the final finish system.\nConsider a multi-layer finish as something like a composite material. In a composite, each material adds desirable characteristics to strengthen the whole. So it often goes when using a custom primer on a finished product. Each layer of coating acts in concert to bring strong performance, environmental compliance and specification-surpassing durability.\nThere are times when primer is skipped. This may be due to time constraints, finish line restrictions or perceptions about the need for priming. Learn four reasons you should think carefully before you skip the primer:\n1. Difficult Substrates\nDifferent primers exist for the many different substrates. These include materials such as steel, aluminum, galvanized, brass and other metal alloys, paper, glass, wood, numerous plastics and polymers, etc. It is important to match the primer to the substrate.\nPrimers often act as a compatibility bridge between incompatible materials. Sometimes, the primer acts chemically to neutralize the underlying surface, to allow it to accept the final layers of coating. Other times, the primer brings qualities to the finish that are not available in the topcoat. Coatings formulators work closely with manufacturing, process and product experts to match the characteristics of the primer to both the underlying surface and the final topcoat.\n2. Higher Performing Top Coats\nThe right primer can frequently lower the cost of an entire process. When the correct primer is applied, top coat application efficiency is enhanced. Appearance and aesthetics are better, as the primer acts to fill, level and reduce surface imperfections. Top coat film thickness can be reduced, extending the efficient use of topcoat material. Primers are often less expensive in comparison to the top coat. The primer is often the step for an imperfect surface to be prepared in a cost-effective way. Skipping the primer may reduce effective results in the long run.\n3. Better Adhesion and Compatibility\nA properly formulated custom primer creates superior adhesion between the base substrate material and the top coat on the finished product. Superior adhesion improves the longevity of the coating, reduces the possibility of top coat failure, and maintains resistance to the environment. The primer can act as an intermediate between otherwise incompatible materials, allowing the topcoat to adhere. The final customer will be satisfied, improving the business relationship.\nOne type of premature coating failure is peeling. If a customer experiences peeling, there may be a costly product recall. Insure against this situation by working with your coating supplier to select the correct primer and apply it using best practices.\n4. Longevity & Quality\nTopcoat durability is a function of many factors, but often it is UV light, moisture and abrasion that shorten the life of a topcoat. It is possible to formulate certain defensive characteristics into the primer, and allow the topcoat to work harder on other factors.\nSometimes, questions involving color and dry time are raised in regard to the use of primers. The correct primer has no detrimental effect on the color of the finished product. As for dry time, a primer is applied first as a separate step. A properly designed process need not be affected by the dry time of the primer. Further, if the right primer reduces the need for additional top coats, then overall process time may be reduced.\nNot only does applying a primer save manufacturers money, but this simple step often avoids the headaches involved with coating failures. Primers should be considered with attention to particular substrate details, with an objective to reduce the number of top coats, to improve adhesion, and to enhance the quality and useful life of the manufactured products.\nDo you have experience with the benefits of primers in your product lines? Please share your thoughts with us in the comments below!']"	['<urn:uuid:c8346064-6fc8-482c-a372-791fc4e55c3c>', '<urn:uuid:c2ead2b8-c99f-4120-8f7c-c51cf27f9145>']	factoid	with-premise	long-search-query	similar-to-document	comparison	expert	2025-05-01T22:47:46.423955	13	40	1355
96	when emil kurbedinov awarded front line defenders	Emil Kurbedinov won the Front Line Defenders award in 2017	"['Emil Kurbedinov: human rights lawyer arrested in Crimea by Russian Counter Extremism officials\nWe, the undersigned NGOs, members of the Civic Solidarity Platform, are highly concerned at the news that human rights lawyer Emil Kurbedinov was arrested in Crimea yesterday by officials of the Russian Center for Counter Extremism (further “Center E”). We call on the Russian authorities and the international community to take steps to ensure that he is immediately and unconditionally released.\nIt is not the first time that Emil Kurbedinov has been subjected to persecution by the Russian authorities in retaliation for his professional work. On 4 August 2016, while Emil was in Rostov-on-Don, unknown individuals tried break into his office and on 26 January 2017 he was detained by representatives of “Center E” in Simferopol and taken to the local office of the Russian Federal Security Services (FSB). On the same day, the de-facto Zheleznodorozhny district court of Simferopol found him guilty under Art. 20.3 of the Code of Administrative Offences of the Russian Federation (“propaganda or public display of Nazi or extremist symbols”) and sentenced him to ten days’ detention. While he was in detention his house was searched as was the office of Crimean human rights defenders in Simferopol where he worked.\nOn 27 October 2018 Emil Kurbedinov’s colleagues and close associates Edem Semedliayev, Liliya Hemeji and Diliaver Memetov were issued a warning about the inadmissibility of extremist activity during a meeting of the Crimean Solidarity movement. On 6 November 2018 a “Centre E” representative visited Emil Kurbedniov’s office with the de-facto prosecutor Valentyn Chuprina and warned him about the inadmissibility of extremist activity.\nEmil Kurbedinov won the 2017 Front Line Defenders award in 2017 in recognition of his human rights activity in Crimea.\nWe strongly condemn the ongoing persecution and harassment of independent lawyers and human rights defenders in occupied Crimea and call on the Russian government to immediately cease their unlawful obstruction of lawyers’ work and human rights activities, as well as the misuse of Russia’s “anti-extremism and anti-terrorism” legislation on the occupied territory to persecute people for their peaceful public, legal and human rights activities. This constitutes a direct violation of international law.\nWe ask international organizations and foreign governments:\n- To call on the Russian government to put a stop to the persecution of Crimean Solidarity activists and lawyers and the obstruction of their peaceful professional activities in occupied Crimea.\n- To condemn the use by Russia of “anti-terrorism and anti-extremism” legislation to prosecute lawyers, human rights defenders and civil society activists in occupied Crimea.\n- To impose personal sanctions on persons involved in gross violations of human rights in occupied Crimea, as well as on those directly involved in the obstruction of lawyers’ work and persecution of Crimean Solidarity activists. In particular, to impose personal sanctions against representatives of the occupying law enforcement agencies, namely, Sushko Andrei Vladimirovich of the Federal Security Service and Shambazov Ruslan Rinatovich. Both individuals are directly linked with the illegal persecution of Emil Kurbedinov and other Ukrainian citizens, persecuted for political motives, as well as with cases involving allegations of torture such as the cases of Renat Paralamov and Oleksander Kostenko.\n- To strengthen sectoral sanctions against the Russian Federation for systematic gross violations of human rights and war crimes in occupied Crimea.\nAssociation UMDPL (Ukraine)\nBir Duino (Kyrgyzstan)\nBulgarian Helsinki Committee (Bulgaria)\nCenter for Civil Liberties (Ukraine)\nCentre for Participation and Development (Georgia)\nCentre for the Development of Democracy and Human Rights (Russia)\nCrimea SOS (Ukraine)\nCrude Accountability (United States)\nGerman Russian Exchange DRA (Germany)\nHelsinki Foundation for Human Rights (Poland)\nHuman Rights Center ""Memorial"" (Russia)\nHuman Rights Club (Azerbaijan)\nHuman Rights House Foundation (Norway)\nHuman Rights Information Center (Ukraine)\nHuman Rights Matter (Germani)\nHuman Rights Monitoring Institute (Lithuania)\nInternational Partnership for Human Rights (Belgium)\nItalian Coalition for Civil Liberties - CILD (Italy)\nKazakhstan International Bureau for Human Rights and the Rule of Law (Kazakhstan)\nKRF Public Alternative (Ukraine)\nLegal policy research center (Kazakhstan)\nMacedonian Helsinki Committee (Macedonia)\nNorwegian Helsinki Committee (Norway)\nPromo LEX (Moldova)\nPublic Association “Dignity” (Kazakhstan)\nPublic Verdict Foundation (Russia)\nSOLIDARUS e.V. (Germany)\nThe Barys Zvozskau Belarusian Human Rights House (Belarus)']"	['<urn:uuid:223d0d29-33eb-42f9-8432-8458d44a1cc0>']	factoid	with-premise	short-search-query	similar-to-document	single-doc	novice	2025-05-01T22:47:46.423955	7	10	691
98	medical management sleep disorders comparison restless leg syndrome vs sleep apnea effectiveness treatments	Medical management approaches differ between sleep apnea and restless leg syndrome. For sleep apnea, medical management includes weight loss, avoiding alcohol and sedatives, and positional therapy, but these methods alone are often not reliable enough for moderate to severe cases. For restless leg syndrome, medical management focuses on lifestyle modifications including reducing caffeine and alcohol intake, improving sleep hygiene, and engaging in physical activities like aerobics and yoga. While these approaches may help reduce symptoms, they typically don't provide complete relief and need to be combined with pharmacological treatments for both conditions.	"[""Insomnia is characterized by difficulty initiating or maintaining sleep. People suffering from insomnia will usually experience some or all of the following symptoms:\n- Difficulty falling asleep, inability to relax the mind enough for sleep to take over.\n- Restless sleep and/or waking up often during the night and having trouble going back to sleep.\n- Not feeling rested or refreshed from a night’s rest.\n- Waking up too early in the morning.\n- Daytime problems with fatigue, sleepiness, moodiness, lack of focus, clumsiness or accidents while at work or driving.\nInsomnia can vary in duration and frequency and may either be short-term (acute insomnia) or long-term (chronic insomnia). It can also be intermittent, with extended periods of time where a person experiences no sleep problems. Acute insomnia may last from one night to a few weeks. Experiencing insomnia consistently at least three nights a week for thirty days or more would be considered chronic insomnia.\nInsomnia is often treated with a combination of sedative hypnotics (sleeping pills) and a behavioral program called cognitive behavioral therapy. If you think you have acute or chronic insomnia, talk to your health care provider, and ask to be referred to our sleep center for special tests.\nInterrupting a person’s breathing during sleep is considered a serious sleep disorder. Untreated, sleep apnea may stop breathing repeatedly during a person’s sleep as often as hundreds of times during the night.\nOf the two types of sleep apnea, obstructive and central, obstructive sleep apnea (OSA) is the more common of the two. OSA is caused by a blockage of the airway, causing a temporary cessation of breathing, usually as a result of soft tissue in the rear of the throat collapsing during sleep. These brief obstructions result in many sleep interruptions each hour, drastically affecting the quality of sleep. Since these interruptions are rarely remembered, sleep apnea sufferers are often unaware of the cause of their symptoms. OSA may cause daytime drowsiness, increased irritability or depression, decreased concentration, reduced work productivity and even frequent accidents or mishaps, including serious traffic accidents. Loud, consistent snoring is a hallmark of obstructive sleep apnea as well.\nDuring central sleep apnea, the airway remains clear and unblocked. The brain, however, fails to signal the muscles to breathe properly due to instability in the respiratory control center. It is called central sleep apnea because it results from a failure in the function and communication of the central nervous system.\nDue to the debilitating effects of this disorder, if you believe you, a friend or family members suffers from these symptoms, consult your primary physician, or schedule a consultation with Mountain View Sleep Lab.\nRestless leg syndrome (RLS) is characterized by tingling, pulling, creeping, or painful sensations in the legs at night. This sensation is brought on by resting such as lying down in bed, sitting for prolonged periods such as while driving or at a theater. The aching may also be accompanied by periodic limb movements that may continue for minutes or hours. RLS typically occurs in the evening, making it difficult to fall asleep.\nSnoring happens when you are unable to move air freely through your nose and mouth during sleep. Many factors, such as the anatomy of your mouth and sinuses, alcohol consumption, allergies, a cold, and your weight can lead to snoring. It is normally caused by a narrowing of your airway, resulting from poor sleep posture or abnormalities of the soft tissues in your throat. A narrow airway gets in the way of smooth breathing and creates the sound of snoring.\nAs you progress from light to deep sleep, the muscles in the roof of your mouth (soft palate), tongue, and throat relax. The tissues in your throat can relax enough that they partially block your airway and vibrate. And, the more narrowed your airway, the more force required to flow air. This increases tissue vibration and consequently raises the volume of snoring.\nCommon causes of snoring:\n- Your Age. As you reach middle age and beyond, your throat becomes narrower, and the muscle tone in your throat decreases.\n- Your mouth anatomy. Men usually have narrower air passages than women and are more likely to snore. A low, thick, soft palate can narrow your airway or an elongated uvula obstruction may cause increased vibrations.\n- Alcohol consumption. Snoring also can be brought on by consuming too much alcohol before bedtime. Alcohol relaxes throat muscles and decreases your natural defenses against airway obstruction.\n- Being overweight or out of shape. Excess fatty tissue and poor muscle tone contribute to snoring.\n- Nasal and sinus problems. Blocked airways such as deviated septum make inhalation difficult and create a vacuum in the throat, leading to snoring.\n- Sleep apnea. Snoring also may be associated with obstructive sleep apnea. In this serious condition, your throat tissues partially or completely block your airway, preventing you from breathing. Sleep apnea often is characterized by loud snoring followed by periods of silence when breathing stops or nearly stops. Eventually, this reduction or pause in breathing may signal you to wake up, and you may awaken with a loud snort or gasping sound. You may sleep lightly due to disrupted sleep. This pattern of breathing pauses may be repeated many times during the night.\n- Sleep posture. Sleeping flat on your back causes the flesh of your throat to relax and block the airway.\nNarcolepsy is a neurological disorder that affects the control of sleep and wakefulness. People with narcolepsy experience excessive daytime lethargy and intermittent, uncontrollable episodes of falling asleep. These sudden sleep attacks may occur during any activity at any time of the day during mid-sentence, while at work, or possibly behind the wheel of a car. Other symptoms of narcolepsy include the sudden loss of muscle tone while awake when surprised or upset, vivid hallucinations as they fall asleep, and sleep paralysis, a condition where normal paralysis of large muscles during REM sleep fails to end upon waking.\nNarcolepsy usually begins between the ages of 15 and 25. However, it can become apparent at any age and appears to run in families.\nSymptoms and diagnosis:\nSince the symptoms of narcolepsy can be found in several other conditions, including obstructive sleep apnea (OSA), accurate diagnosis is critical. Many researchers now believe that narcolepsy is caused by the lack of receptors for the neurotransmitter hypocretin, which regulates the sleeping and waking states. If you believe you or someone you know suffers from narcolepsy, talk to your health care provider, and ask to be referred to our sleep center for special tests.\nSleepwalking is mostly common in children and tends to occur within an hour or two of falling asleep and may last on average between 5 and 15 minutes. While the child’s brainwaves are in those of a deep sleep, the sleepwalker moves as though awake. The sleepwalker usually has no recollection of the event the next morning.\nSleepwalking occurs in more than 10% of children, however, most will outgrow it. It also appears to be genetics. Sleepwalking episodes may be triggered by fever or some medications, unpredictable sleep schedules, sleep deprivation, and stress.\nThe child’s safety during these episodes is the primary concern. Parents should ensure that doors and windows are locked and that no obstructions could cause a fall or other injuries. When a child is sleepwalking, gently guide the child back into bed. Don’t try to awaken them.\nCPAP is considered the best sleep apnea treatment. However, CPAP is not the only sleep apnea treatment. There are three other options to treat sleep apnea. Depending on the individual's anatomy, and unique set of conditions, one of these other options may prove to be optimal.\nContinuous positive airway pressure therapy (CPAP) requires the use of a machine to help a person breathe more easily during sleep suffering from obstructive sleep apnea (OSA). A CPAP machine creates increased (positive) air pressure in your throat preventing your airway from collapsing while breathing during sleep. The use of a CPAP will likely help your bed partner sleep better, as well.\nTypically once you begin the use of a CPAP, it will be every night. A CPAP machine will normally be one of the following types:\n- A mask that covers your nose and mouth.\n- A mask that covers your nose only: nasal continuous positive airway pressure, or NCPAP.\n- Prongs that fit into your nose.\nThere are a few types of surgeries for the treatment of sleep apnea. The most popular is Uvulopalatopharyngoplasty (UPPP). A UPPP procedure involves the surgical trimming (shortening) of the uvula dangling in the back of your throat and the floppy tissue on either side of it. After removing this excess floppy tissue the airway is able to move air freely with less chance of collapsing. If UPPP is successful there normally is no need for a CPAP machine, and the need to carry it with you at all times. Unfortunately, UPPP has a success rate of only 30% to 50% and often it is not effective enough to cure severe cases of sleep apnea.\nOral appliance therapy involves the use of a dentist who specializes in oral appliance therapy for sleep apnea, taking impressions of your teeth, and custom fitting a plastic device that fits tightly on the upper and lower teeth. This device “juts” the lower jaw forward during sleep. By pulling the jaw forward, the tongue is moved forward and is pulled away from the back of the throat, opening the airway and decreasing the probability of airway collapse.\nThey are convenient, easy to travel with, and do not require the use of an electrical receptacle. Unfortunately oral appliance therapy is limited in how far it can pull the jaw forward before leading to temporomandibular joint problems (jaw joint). Therefore it is only considered effective for mild to moderate cases of sleep apnea.\nMedical management primarily consists of three techniques: weight loss, avoiding certain medications, sedatives, avoidance of alcohol prior to sleeping or as a sleep aid, and positional therapy (sleeping on your side or with the head of bed elevated). Depending on the root cause and the severity of OSA symptoms, medical management may not have a significant enough impact on sleep apnea to be a reliable treatment option.\n- Weight loss or management is a healthy thing to do, in general. Alone, it often does not have enough impact on sleep apnea to be a reliable treatment option. For some very overweight patients with only mild sleep apnea, significant weight loss may be enough. However, someone with severe sleep apnea whoich is only moderately overweight, weight loss alone may not be a viable sleep apnea treatment.\n- Alcohol and sedating medications can aggravate make sleep apnea worse. However, it is rarely the sole cause of sleep apnea.\n- Positional therapy can be helpful for some patients, but in general moderate to severe cases of sleep apnea do not respond."", 'When you lay down on your bed at night, feeling the urge to move your body can ruin the whole experience and make it difficult for you to fall asleep. Moreover, if you don’t move, you start feeling a strange and growing sensation in your legs, and now your attention is not focused on relaxing your mind. Your body is interrupting everything, and it feels frustrating to keep trying.\nThat is how it feels every night for patients with restless leg syndrome — no wonder why they suffer from sleep disturbances and the various consequences of lack of sleep.\nThat’s why in this article, we are going to cover restless leg syndrome, also known as Willis-Ekbom disease. What is it exactly? How do you know your sleeping problems are caused by restless leg syndrome? And what can you and your doctor do to improve your symptoms?\nRestless leg syndrome and Willis-Ekbom Disease\nRestless leg syndrome, or Willis-Ekbom disease, is a neurological disorder associated with sleeping problems due to recurrent symptoms of twitching and tingling in your legs at night. They are uncomfortable sensations that make patients feel the urge to move around the legs over and over again as they try to fall asleep.\nThe symptoms of restless leg syndrome may appear when sitting or standing, but they are especially uncomfortable when the patient is lying down. They make falling asleep exceedingly difficult and cause insomnia and chronic sleep problems in patients.\nRestless leg syndrome is often considered a puzzling disease that is difficult to understand and diagnose. It is also difficult to treat because most patients will still have symptoms after treatment. However, we can suspect this diagnose if we have recurrent twitching or tingling in the legs, when this awkward sensation is accompanied with the urge of moving the legs continuously, and when this situation affects our sleep at night.\nAccording to recent research, these patients have altered brain chemistry with excessive levels of a neurotransmitter called glutamate. Patients with higher levels of glutamate usually report more severe, continuous or disruptive sensations. Another chemical involved in Willis-Ekbom disease is dopamine, which is often deficient or not enough, leading to involuntary muscle movement. Thus, to treat restless leg syndrome, we should have two different approaches we will cover in this article. One of them is a pharmacological approach destined to modulate brain chemistry while the other is based on lifestyle modifications to reduce the consequences and health impact of restless leg syndrome.\nAvailable pharmacological options for Restless leg syndrome\nThere are several drugs to treat restless leg syndrome, and each one of them should be adopted for every patient depending on their individual needs. The most important medications are as follows:\n- Levodopa: It is a dopamine precursor meant to increase levels of this neurotransmitter, which is deficient in the brain of patients with restless leg syndrome. It is effective, but long-term use may lead to augmentation (worsening) of the symptoms.\n- Pramipexole: Instead of being a precursor of dopamine, this medication is an agonist. It is a substance that looks like and behaves like dopamine in the nervous system. It can be used along with levodopa in certain phases of the treatment.\n- Ropinirole: It is another agonist of dopamine that improves the symptoms for up to 1 year in patients with restless leg syndrome. It is metabolized by the liver, and doctors need to consider the function of liver enzymes if they are prescribing other medications.\n- Rotigotine: This medication works similar to pramipexole and ropinirole, but is usually administered in transdermal patches. Thus, it is very useful for patients with swallowing problems and daytime symptoms. It is also recommended before surgery.\n- Gabapentin enacarbil and pregabalin: Pregabalin and gabapentin enacarbil (a slow-release version of gabapentin) are excellent in cases of moderate and severe restless leg syndrome. They are also useful to improve sleep measures in these patients.\n- Oxycodone and naloxone: In some studies, the combination of oxycodone and naloxone in prolonged-release have improved the symptoms of these patients significantly. Improvements are not associated with augmentation, as it happens with tramadol.\n- Iron (ferrous sulfate) and vitamin C: They may be included in the treatment of restless leg syndrome, and will be useful in patients with serum ferritin levels lower than 75 mcg/L. It is important to use ferrous sulfate and no other form of iron because other formulations are apparently not effective.\nLifestyle changes that may contribute to your treatment\nAccording to a recent review and meta-analysis, lifestyle changes and modifications do not have sufficient evidence according to the available scientific data. However, that doesn’t mean they are not relevant.\nLifestyle changes may not completely cure the problem, and won’t be better than medications to calm down the symptoms, but they are definitely important to reduce the impact of restless leg syndrome in our general health.\nWe can summarise lifestyle changes for restless leg syndrome as follows:\n- Changes in caffeine and alcohol intake: Caffeine and alcohol intake may directly or indirectly affect your sleep and brain chemistry. Thus, it is recommended to reduce the consumption of alcohol and caffeine close to sleeping time. In some cases, very high consumption of alcohol, nicotine or caffeine was a cause of restless leg syndrome, but results of quitting may be different from one person to another.\n- Sleep hygiene improvements: Since patients with restless leg syndrome are prone to insomnia and other sleep alterations, sleep hygiene improvements are fundamental to reduce the impact of this disease in their lives. Sleeping at the same hour, creating a sleeping environment, and relaxing your mind and body before sleep may be fundamental in improving the consequences of restless leg syndrome in these patients.\n- Aerobics, yoga, and other forms of physical activity: In many cases, physical exercise improves muscle function and stimulation by the nervous system in patients with restless leg syndrome. Physical activity would also reduce the cardiovascular risk associated with lack of sleep and has several advantages, and should not be ruled out in patients with restless leg syndrome.\nAnguelova, G. V., Vlak, M. H., Kurvers, A. G., & Rijsman, R. M. (2018). Pharmacologic and nonpharmacologic treatment of restless legs syndrome. Sleep medicine clinics, 13(2), 219-230.\nPamu, S., Thakkalapally, L., Badugu, V., & Pawar, D. Caffeine Induced Restless Legs Syndrome.\nAukerman, M. M., Aukerman, D., Bayard, M., Tudiver, F., Thorp, L., & Bailey, B. (2006). Exercise and restless legs syndrome: a randomized controlled trial. The Journal of the American Board of Family Medicine, 19(5), 487-493.']"	['<urn:uuid:9a09225d-c350-46b6-9755-d5c7d75477d3>', '<urn:uuid:a1314caa-93c5-44d0-b622-faf0795406b6>']	open-ended	direct	long-search-query	distant-from-document	comparison	expert	2025-05-01T22:47:46.423955	13	92	2912
100	Between Roman and Chinese medicine, which had earlier documented treatments?	Chinese medicine has earlier documented treatments, with records dating back to Shennong's Herbal Classic from the Qin and Han Periods, which was the earliest monograph on materia medica. Roman medical documentation came later, primarily through physicians like Hippocrates and Galen, who served as Marcus Aurelius's personal physician in the Roman Empire.	"['The ancient Greeks and Romans were great\nFree University of Berlin\nRegional differences also played an important role: In the eastern part of the empire, which has always been better organized and more densely populated than the west, Roman officials monitored compliance with the law. From the north, on the other hand, horror tales reached Rome: Celts and Teutons, it was rumored, abandoned their old people in the woods and left them there. In late antiquity, which was influenced by Christianity, the Jewish-New Testament view increasingly prevailed in society : Already the Ten Commandments admonished to honor father and mother, the Christian commandment of mercy was lived in the early Christian communities and was an essential part of the success of the new religion.\nIn Byzantium it was the duty of the empress to care for the poor, the sick and the elderly. Later, when the Roman state became weaker and weaker, private initiatives took over this task: In the fourth century AD, a brother of the Doctor of the Church Basilius, Naucratius of Caesarea, set up special houses for the first time in what is now Turkey for impoverished, old people. More than 30 such facilities are known today. The Eastern Roman state supported them by granting tax exemptions.\nIn the western part of the empire, the newly emerging monasteries always include hostels for the needy. But due to the upheavals of the great migration and the many armed conflicts, special old people\'s homes were not set up there until the early Middle Ages. However, ancient societies did not just seek to mitigate the economic consequences of aging.\nMedicine also tried to understand and cure the symptoms of old age. The Greek physician Hippocrates and Emperor Marcus Aurelius personal physician Galen in particular shaped the medical conception of the ancient world. ""The basis was the so-called four-juices theory,"" explains Professor Baltrusch: ""Blood, phlegm, as well as yellow and black bile were considered the four juices of the human body, the natural balance of which was the basis for a healthy life."" In old age, see above the idea was dominated by the phlegm, caused by the body getting cold and dehydrated.\nOn this basic assumption, the Roman doctor Galen developed a therapy that was supposed to slow down aging. Regular baths, massages and gymnastics should warm up the elderly as well as honey and wine. Lots of fluids should work against dehydration. The Roman poet and politician Cicero, however, not only wanted a healthy way of life, but also a healthy attitude towards life - and not only among the more mature citizens: “Old people who do not make too high demands, who are not sullen or unfriendly, lose their lives quite bearable age; Disgruntlement, however, and unfriendliness is repulsive at any age. ""\n- When we die, we just disappear\n- Who are the speedsters of the superhero comics\n- Is existence physically metaphysical or both\n- Why don\'t people recycle plastic bottles\n- Do you feel sad all the time?\n- What happens to error coins\n- Where is the best country in asia\n- Why did you look at stoicism\n- What business can I start with 5000\n- Have you ever lost something very precious?\n- How many pounds is 1 gallon\n- How to learn to draw quickly\n- How will Donald Trump win re-election\n- What technological advances have made skyscrapers possible?\n- What is a link extractor\n- Why is Miami International Airport so cold\n- Why does sound go through walls\n- In short what is quantum mechanics\n- Are Wealthfront and Betterment Scalable Companies\n- How many people have subscribed to Quora\n- Is vacuum a liquid?\n- Did you think you were underpaid?\n- What are the benefits of Drionic batteries\n- Is Rahm Emanuel Orthodox', 'Chinese Medicated Diet\nThe Chinese have a traditional belief in the medicinal value of food, as they believe that food and medicine share the same origin. This view could be considered a forerunner of nutritional science in China.\nChinese medicated diet is not a simple combination of food and Chinese herb, but a special highly finished diet made from Chinese herbs, food and condiments under the theoretical guidance of diet preparation based on differentiation of symptoms and signs of traditional Chinese medicine.\nChinese medicated diet has a long history. The ancient legend ""Shennong Tastes a Hundred Grasses ""shows that early in remote antiquity the Chinese nation began to explore the function of food and medicaments, hence the saying ""Traditional Chinese medicine and diet both originate from the practice and experience in daily life.""\nIn Shennong\'s Herbal Classic, which was published approximately in about the Qin and Han Periods and is the extant earliest monograph on materia medica, many sorts of medicaments which are both drugs and food were recorded, such as Chinese-date (Fructus Ziziphi Jujubae),sesame seed (Semen Sesami), Chinese yam (Rhizoma Dioscoreae), grape (Vitis), walnut kernel (Semen Fuglandis), lily bulb (Bulbus Lilii) , fresh ginger (Rhizoma Zingiberis Recens), Job\'s-tears seed (Semen Coicis), etc. in the East Han dynasty, some noted medicated diet recipes were recorded, such as Soup of Chinese Angelica root, Fresh ginger and Mutton (Danggui Shengjiang Yangrou Tang ), Decoction of Pig-skin (Zhufu Tang), etc., all of which now still have important values. Sun simiao, a well-known doctor in the Tang Dynasty, listed and discussed such questions as dietetic treatment, dietetic treatment for senile health care and health preservation.\nAccording to history books, up to the period of the Sui and Tang Dynasties about more than sixty kinds of books on dietetic treatment had been published. But unfortunately most of them are lost. Of all the prescriptions recorded in it, 70% are about medicated diet. It is emphasized in this book that ""dietetic therapy should go first for any senile diseases, and then followed by medicine if they are not cured."" Hu Sihui, a royal doctor in the Yuan Dynasty, oceans of medicated diet prescriptions and dietetic drugs were recorded; in addition, some questions, such as diet contraindication in pregnancy, diet contraindication for wet nurse, contraindication for drinking, etc. were also discussed in this book. In the Ming Dynasty, Li Shizhen collected and recorded many medicated diet prescriptions, dozens of which were about medicated gruel alone, another dozens touched on nothing other than medicated wine. Monographs on medicated diet treatment in the Qing Dynasty varied in characteristics. Over 300 species belonging to 7 phyla of medicated food and drink were introduced.\nMedicated diet can be used either to treat diseases or for healthy people to build up their health and prevent diseases. This is one of the characteristics in which medicated diet is different from treatment by medicine. Although medicated diet is something mild, it has a notable effect on the prevention and cure of diseases, health building -up and health preserving. Here are some of the achievements in scientific research of Shandong Traditional Chinese Medicine College:\nEight-Ingredient Food: It is prepared according to the experience in ancient dietetic treatment and health care of imperial court in the Qing Dynasty from eight dietetic Chinese drugs including Chinese yam (Rhizoma Dioscoreae), lotus seed (semen Nelumbinis), and hawthorn fruit (Fructus Crataegi). 97% of the children who took it for 30 days have whetted their appetite, and their growth has improved too.\nNourishing Extract of laiyang Pear and mushroom: It is made from the juice of Laiyang Pear (Malum Piri) and extract of mushrooms ( Lentinus Edodes) and tremella (Tremella). If the middle-aged and senile patients suffering from chronic diseases take it, not only can the symptoms of their illness be alleviated, but their blood-fat can be brought down too when they are suffering from hyperlipemia, and their immunology function can be improved.\nIt has not only the efficiency of medicine but also the delicacy of food, and can be used to prevent and cure diseases, build up one\'s health and prolong one\'s life.']"	['<urn:uuid:a97ae625-5922-401e-b741-3ef804719d73>', '<urn:uuid:be41f58a-1b9d-49d4-8a34-05a0a1b7b090>']	factoid	with-premise	concise-and-natural	distant-from-document	comparison	expert	2025-05-01T22:47:46.423955	10	51	1320
101	What makes the underground root system of the silver-leaf nightshade plant particularly challenging for agricultural control and management?	Silver-leaf nightshade has extensive interconnecting root systems that can penetrate to depths of 2m and create networks with neighboring plants to form colonies. The plant has a tremendous capacity to regenerate from root fragments, and colonies can re-establish even after several seasons of control.	['© Bill Dodd Creative Commons\nNative to North America, silver-leaf nightshade is a deep-rooted summer growing perennial plant from the Solanaceae family. It was first found in Australia in 1901 at Bingara, New South Wales and is now found throughout most parts of New South Wales, South East Queensland, Victoria, South Australia and Western Australia. Silver-leaf nightshade seriously reduces crop and pasture production and is listed as Weeds of National Significance.\nYou must manage the impacts of silver-leaf nightshade on your land.\nYou must not give away, sell or release silver-leaf nightshade into the environment.\n- Silver-leaf nettle, silver-leaf bitter apple\n- Erect, multi-stemmed plant up to 60cm tall.\n- Stems dieback over winter.\n- Leaves are 5-10cm long, wavy edges, silvery-green with paler undersides.\n- Spines are short brown, approximately 5mm long, occur on the stems and petioles.\n- Flowers are up to 25mm in diameter, have 5 purple or white petals with 5 yellow stamens 5-7mm in length.\n- Berries are green-striped, round, smooth, commonly 1cm in diameter which turn yellow-orange when ripe.\n- Seeds are rounded, flattened, light-brown with irregular surface, 2.5-4mm wide.\n- Roots create an interconnecting network with neighbouring plants to form a colony.\n- Roots can penetrate to depths of 2m.\n- Can grow in most soil types.\n- Visit the Weeds Australia website and click on the distribution tab to access the distribution map.\n- Usually flowers in November and can continue to March.\n- Plants are dormant in winter when stems dieback will reshoot in spring.\n- Berries are produced from December-March.\n- Seedlings emerge at any time from late spring until autumn depending on rainfall.\n- Will regrow from any root segment.\n- Replaces native Solanum species.\n- Reduces summer crop yields.\n- Reduces annual pastures such as clover and rye.\n- All parts of the plant are poisonous, especially the fruit.\n- Costly to control.\nHow it is spread\n- Spread from root fragments.\n- Spread by seed carried by birds.\nSilver-leaf nightshade colonies are not easily controlled as the extensive interconnecting root systems are difficult to totally control. It has a tremendous capacity to regenerate from root fragments. Colonies can re-establish even though they may have been controlled several seasons. Good farm hygiene is critical to prevent the spread of seed and root fragments.\n- To date there is no herbicide to eradicate a silver-leaf nightshade colony with a single application. Colonies need to be suppressed and run down with persistent control which includes annual herbicide applications to prevent berry set.\n- No known biological control agents.\n- Silver-leaf nightshade is a category 3 restricted invasive plant under the Biosecurity Act 2014.\n- You must not give away, sell or release silver-leaf nightshade into the environment. Penalties may apply.\n- You must take all reasonable and practical measures to minimise the biosecurity risks associated with dealing with silver-leaf nightshade under your control. This is called a general biosecurity obligation (GBO).\n- At a local level, each local government must have a biosecurity plan that covers invasive plants in its area. This plan may include actions to be taken on silver-leaf nightshade. Some of these actions may be required under local laws. Contact your local government for more information.\n- Contact the Customer Service Centre\n- Last reviewed: 30 Sep 2021\n- Last updated: 30 Sep 2021']	['<urn:uuid:c4fd7266-70e4-485a-aac7-ec44743b5a90>']	factoid	direct	verbose-and-natural	distant-from-document	single-doc	expert	2025-05-01T22:05:01.292488	18	44	557
102	old pictures stored how long display safe	Based on personal experience, daguerreotypes from the 19th century as well as contemporary ones have been safely displayed continuously for over 10 years without showing any signs of deterioration or change. This evidence contradicts claims about daguerreotypes being light sensitive. In fact, daguerreotypes are among the most stable photographic objects, provided their housings are intact to prevent atmospheric pollutants from reacting with the silver surface and the housings themselves are not contributing to deterioration.	['Quoted in full:\nThe recent article in the Scientific American magazine paints a picture of doom and destruction for daguerreian art pieces. Of course this is disconcerting for collectors and institutions that have significant investment in these beautiful objects. The author implies that degradation surrounding some Southworth and Hawes daguerreotypes in the Young America exhibition can be applied to all daguerreotypes when he writes “The vanishing images suggested that any daguerreotype could spontaneously crumble.” This sky-is-falling statement in my opinion does not represent the majority of daguerreotypes.\nLets review this issue.\nApproximately 160 Southworth and Hawes daguerreotypes were exhibited over two years at three institutions. Five plates changed significantly with an obscuring white haze, and supposedly 25 plates changed slightly. The majority of the plates did not change at all.\nFrom personal experience I can tell you that I have 19th century daguerreotypes as well as my own daguerreotypes that have been on continuous display on my studio for 10+ years with no sign of change. This is my argument against the claim that daguerreotypes are light sensitive.\nWhat every collector or institution must know is Southworth and Hawes plates have a very unique storage history contrary to the norm. The great majority of S&H images that remain were plates retained by the studio stored completely unsealed in plate boxes. They were sold in this condition through Holman’s bookshop in the 1930’s. and early 40’s. As they migrated to private collectors and institutions they were sealed using what were thought of at the time to be proper conservation materials. A typical preservation package used by the George Eastman House from the mid-1970’s to 1999 consisted of 4-ply buffered board with a paper binding tape, and a buffered die cut paper mat separating the plate from the glass. The buffering agent is 3% calcium carbonate to provide an alkali reserve of ph 8.5.\nA significant case in point. In 1999, a trove of Southworth and Hawes daguerreotypes were discovered in the garage of David Feigenbaum after his death. A team of conservation professionals from the George Eastman House were asked to prepare the plates for auction at Sotheby’s. Over 200 plates were housed in the materials described above. A collector who purchased a Southworth and Hawes daguerreotype from the David Feigenbaum sale brought it to me to replace the conservation housing with an 19th century brass mat, preserver and case. I retained the die-cut buffered mat and backing board. Soon after, I made a daguerreotype that I felt wasn’t good enough to frame in my own passe-partout housing design, but I wanted to preserve it as I had made it in collaboration with my friend Irv Pobboravsky. I placed the daguerreotype behind glass using the die-cut mat I retained from the Feigenbaum sale held together with spring clips and placed it in a zip-lock back. It was stored in the dark for approximately four years. It now has a very definite obscuring white haze adjacent to the mat. While this is not a scientific experiment, it does provide a significant observation and cause to question if the housing materials are contributing to the deterioration of the plates.\nI have experienced the “white haze” phenomena on other of my contemporary images as well as on 19th century images that have been in contact with buffered board. What is good for the conservation of paper, ie alkaline buffering, is not necessarily good for daguerreotypes.\nIn reviewing the conservation efforts for the Young America Exhibition I learned that plates were not removed from their buffered mat board and die cut preservation packages. These were placed intact into extremely well sealed secondary housings incorporating shallow copper pans to act as pollutant scavengers. A complete overview of the conservation for this exhibition can be found here.\nIf the buffered materials are a co-factor in the formation of “white-haze” deterioration it would explain why even with the best intentioned conservation, some plates still changed during exhibition. A questionable environment was enclosed within a stable one.\nThis remains to be explored and I hope to soon analyze the plate and mat from my example. I present this scenario as a possible alternative and/or co-factor to the silver-chloride scenario presented in the Scientific American article.\nIn closing, I would say that daguerreotypes are among the most stable of photographic objects providing the housings are intact to prevent atmospheric pollutants from reacting with the silver surface and that the housings themselves are not contributing to the problem. The nature of the mechanism of deterioration particular to a small percentage of Southworth and Hawes daguerreotypes is not yet fully understood. The findings reported in the Scientific American article should not prevent us from exhibiting, collecting or enjoying these amazing photographs. It is prudent, as has been shown by the Young America exhibition, to accurately document any daguerreotype intended for exhibition and carefully monitor it at regular intervals to note any changes.\nPresident of the Daguerreian Society\nThis certainly adds a new wrinkle to the previous Scientific American article. It also goes to show that just because an article comes from a reputable source does not necessarily mean it is accurate. My bad. This bears further following, and I will post updates as I find them. That said, I would still be careful in exhibiting Dags to prevent unnecessary degradation.']	['<urn:uuid:10b846f3-c1ac-4618-a7de-1116d28e2548>']	open-ended	direct	short-search-query	distant-from-document	single-doc	novice	2025-05-01T22:05:01.292488	7	74	888
103	I'm interested in how wars affect the economy. Throughout history, how have expensive wars contributed to inflation compared to how modern monetary policy affects inflation rates?	Historically, expensive wars have been a major source of inflation, as governments would print more money to finance military spending like arms and soldiers. In an economy already at full capacity, this additional money would drive up prices. However, modern inflation dynamics have changed - for instance, from 1967 to 1974, countries like Japan and Britain experienced alarming inflation rates without any apparent connection to wars. Today, inflation is managed through careful monetary policy by central banks, who can create or reduce money supply to target specific inflation rates (usually around 2%) to promote stable economic growth. They do this through various tools like buying and selling government debt, rather than simply printing money to fund government spending as was common during wartime.	['Over the last century many countries throughout the world have experienced\ninflation as their major economic problem.\nExpensive wars have traditionally been\nrecognized as the sources of inflation. Governments, in effort to squeeze more production\nout of an economy, have often resorted to printing or releasing more money to finance the\npurchase of arms and soldiers1. In an economy already producing at full capacity, the\nissuing of additional money serves to bid up the prices of the output of the economy,\nresulting in inflation. It was generally assumed from past experience, that once the\neconomy returned to its normal state, the persistent tendency for overall prices to rise\nwould disappear, bringing inflation rates back to normal.\nWorld War II brought the\npersistent inflation that economists came to expect. In the 50’s and early 60’s inflation\nresumed to very low rates concomitant with large growth increases and low\nunemployment. But, from 1967 to 1974 the rates of inflation reached alarming proportions\nin many countries, such as Japan and Britain, for no apparent reason. This acceleration in\ninflation has forced many economists to reevaluate their views, and often align themselves\nwith a specific school of thought regarding the causes and cures for inflation.\nThere are two opposite theories regarding inflation. Monetarism indicates that\ninflation is due to increases in the supply of money. The classic example of this\nrelationship is the inflation that followed an inflow of gold and silver into Europe, resulting\nfrom the Spanish conquest of the Americas. According to monetarists, the only way to\ncure inflation is by government action to reduce growth of the money supply.\nAt the other end is the cost-push theory. Cost-pushers believe that the source of\ninflation is the rate of wage increases. They believe that wage increases are independent of\nall economic factors, and generally are determined by workers and trade unions. More\nspecifically, inflation occurs when the wages demanded by trade unions and workers add\nup to more than the economy is capable of producing.\nCost- pushers advocate limiting the\npower of trade unions and using income policies to help fight off inflation.\nIn between the cost-push and monetarism theory is Keynesianism. Keynesians\nrecognize the importance of both the money supply and wage rates in determining\ninflation. They sometimes advise using monetary and incomes policies as complimentary\nmeasures to reduce inflation, but most often rely on fiscal policy as the cure.\nBefore we can understand the policies suggested by these different schools of\nthought, we must look at the historical development of our understanding of inflation.\nFor approximately 200 years before John Maynard Keynes wrote the General\nTheory of Employment, Interest , and Money, there was a broad agreement among\neconomists as to the sources of inflationary pressure, known as the quantity theory of\nmoney2. The Quantity theory of money is easily understood through fisher’s equation\nMV=PY( money supply times velocity of circulation of money equals price\ntimes real income)\nQuantity theorists believe that over an extended period of time the size of M, the\nmoney supply, cannot affect the overall economic output, Y. They also assume that for all\npractical purposes V was constant because short term variations in the circulations of\nmoney are short lived, and long term changes in the velocity of circulation are so small as\nto be inconsequential .\nLastly, this theory rests on the belief that the supply of money is in\nno way determined by the economic output or the demand for money itself.\nThe central prediction that can now be made is that changes in the money supply\nwill lead to equiproportionate changes in prices. If the money supply goes up then\nindividuals initially find themselves with more money. Normally individuals will tend to\nspend most of their excess money.\nThe attempt of people to buy more than they normally\ndo must result in the bidding up of prices because of the competitive nature of the market,\nAlso essential to the quantity theory is the belief that in a competitive market,\nwhere wages and prices are free to fluctuate, there would be an automatic tendency for\nthe market to correct itself and full employment to be established.\nIn figure 1, w stands for the real wage rate (the amount of goods and services that\nan individuals money income can buy), L d for the demand for labor and L s for the supply\nfor labor. Suppose now that the economic system inherited a real wage rate w 1, The', 'Inflation is always and everywhere a monetary phenomenon.\n- Milton Friedman\nThis essay is a quick overview of macro-economic theory, with an emphasis on monetarism and an explanation of how market monetarism works. There are resources for further reading at the end.\nWhat is Monetary Policy?\nMonetary policy is how an independent branch of the government called the central bank manages interest rates and the money supply to promote and stabilize long-term economic growth. Monetary policy should be countercyclical, acting as a shock absorber against the business cycle. Too often, it is procyclical and makes a bad situation worse.\nMonetary policy is often based on a dual mandate — keeping both inflation and unemployment under control. Most countries follow the US Fed, and the Fed is a very conservative and quasi-political organization. They use Keynesian (outdated) models to understand the world. They modify interest rates, bank reserve requirements, interest on reserves, and open-market operations (creating and destroying money) in an effort to control inflation and unemployment. It works some of the time, in the same way a broken watch tells the correct time twice a day. But during extreme events, when there is a supply or demand shock, it usually backfires and causes a recession.\nMore and more economists are coming to realize that setting interest rates isn’t as effective as they had thought. Instead, the amount of money in circulation is the only determinant of long-term inflation. A common thought experiment is: If the amount of money in your country today doubled overnight, and everyone immediately knew that fact by 7am, almost all prices would double by noon. In real life, we see prices rising rapidly in response to hyperinflative money printing, though the process is more complex. If the central bank adds 2 percent more money to the money supply, prices don’t rise overnight, but they do eventually rise by 2 percent in the long term. When people have more money to spend, prices generally rise in response.\nIf the government takes money from the federal budget and just sends $100 to every citizen, that might stimulate the economy in the short run. That’s not creating money. That’s taking money already in circulation and spending it on one thing rather than another. If the government took that same money and built more housing or bridges, that would put people to work. They would spend the money, and it would also stimulate the economy in the short run. That’s called fiscal stimulus, and it is always quite limited in its effect.\nHowever, if the treasury simply prints a bit more money (adds more new money to its own account simply by changing the number) and puts that new money into circulation, that creates a corresponding bit of inflation that can stimulate the economy for years.\nThe key is whether money is in circulation or out of circulation. To stimulate the economy, the central bank buys government debt or other financial assets. Now those assets are out of circulation (this is known as the central bank’s balance sheet) and the newly created money is now in circulation. When they want to cool off the economy, they sell their assets, pulling cash out of circulation.\nBecause they can create as much money as they want, central banks have infinite economic resources. It’s very important that they use this power only to enforce a steady-growth regime and not to print money when the government wants to spend more or has a need for more money.\nCentral bankers only create and destroy base money, which is a fraction of total money in the economy. They must take into account the multiplier effect, which involves 1) banks lending money (despite YouTube videos to the contrary, banks do not create money out of thin air the way the central bank does), and 2) the velocity of money (how many times a dollar changes hands per year). Both factors determine the total amount of money in circulation.\nIs Inflation Really Bad?\nAustrian economists say inflation is bad. They say it “erodes the spending power of your money.” Look, they say, a movie ticket used to cost $10, now it costs $20. They show images with shopping carts buying less and less food over the years.\nThis is what Irving Fisher called The Money Illusion — the tendency of people to think in terms of dollars in their wallet, rather than adjusting for inflation. Back when your movie ticket cost $10, what was your income? It was a lot less than it is today. In general, wages outpace inflation, so we continue to collect a paycheck that actually buys more and more goods over time!\nIn fact, if inflation were to rise, our wages would also rise. What matters is the gap between them. In general, the amount of money the ticket seller at the theater earns doubles faster than the price of the tickets does.\nThe same is true with investments and real estate — they go up faster than inflation. So the only people hurt by inflation are those who keep a large amount of cash under the mattress or in a vault. Everyone else’s buying power continues to increase as wages and investments continue to outpace inflation.\nHow Much Inflation Should there be?\nYou can think of inflation like heating and air conditioning for our homes. Too little or too much heat can make us very uncomfortable, but the right amount makes us happy and productive. The same goes for air-conditioning. Your home needs a thermostat to keep the interior at a comfortable temperature. That way, you don’t have to keep deciding whether to add heat, reduce heat, add more cool air, or reduce the cool air. The thermostat does it automagically by itself, and that’s one less thing we need to think about.\nSimilarly, we don’t want to have too much inflation, but we also don’t want too little. We also don’t want too much economic growth, or too little. Somewhere around 2 percent inflation, there’s a “Goldilocks” amount that helps keep the economy growing steadily.\nThere are different ways to measure inflation. The Fed uses a personal-consumption index, and there are a few different ways to measure it:\nTwo of the measures show the Fed undershooting its 2 percent target. The green one is perhaps the best statistical measure, as it removes products with extreme price swings during the year.\nHere are the reasons you want a small amount of consistent inflation:\nIt encourages people to spend now and gets money moving. Cash on hand is an important measure of a person or firm’s expectations of the future. If we don’t have enough cash on hand and the future is uncertain, we’ll delay purchasing, and that slows the velocity of money, which slows the economy.\nIt overcomes wage stickiness. Both wages and prices are sticky — they don’t adjust quickly to market realities. Nobody likes to take a cut in salary, and landlords don’t like to accept less rent. Banks don’t want to accept less than their monthly payment. Yet, when there’s a drop in demand, something has to give. A bit of inflation acts as a buffer — if there is a recession and prices don’t go up, they can understand that and wait for better times. It’s a lot better (psychologically) than having to swallow a pay cut.\nPrices are sticky. No one wants to adjust prices every day. If inflation is high, prices will need to change often. People will constantly scout for slow price adjustments and arbitrage the price changes. There will be too much money-induced activity in the economy. At 2 percent inflation, the economy gets a boost and prices double every 36 years, which is generally acceptable.\nA reliable amount of inflation benefits everyone. If inflation bounces between zero and six percent, banks don’t know how to lend, so they lend inefficiently to protect themselves. If the central bank hits two percent inflation each year, everyone can plan on it and lenders will lend more efficiently, passing those savings on to borrowers.\nToo little inflation harms growth. A society at 1 percent inflation will grow more slowly than an economy with 2 percent. For most economies, 2 percent is the “Goldilocks amount” that stimulates growth without causing instability. The right number for a given economy may depend on population growth, technology adoption, and other factors.\nNegative inflation is bad. The opposite of inflation is deflation. In a deflationary economy, people are more likely to hold onto money than spend it. This is a strong sign that there isn’t enough money in the economy. By the time you see deflation, it’s time to add quite a bit of money to the circulating supply, and fast.\nNominal GDP Level Targeting\nIf 2 percent inflation is your goal, how do you achieve it consistently? You want to build a thermostat for the economy, to keep inflation “just right.” Let’s learn a few more key terms …\nNominal GDP vs Real GDP: Sal Khan explains the difference between real GDP and nominal GDP in his excellent video tutorial …\nPeople often talk about real GDP, which is a nation’s output adjusted for inflation. Nominal just means “unadjusted for inflation.” Nominal GDP is the actual dollars flowing through the economy. You have nominal dollars in your wallet and get paid in nominal dollars. You borrow nominal dollars and repay your loan in nominal dollars. So if we track the amount of output in actual dollars without adjusting for inflation, we have an accurate view of demand. That leads to …\nNominal GDP Targeting is a monetary policy that trades two variables and their uncertainties (inflation and unemployment) for a single variable: nominal GDP. Let’s suppose you want to target 2 percent inflation and 3 percent economic growth. Then you would want to have 5 percent more money circulating this year than last year. The cool trick of NGDP is that you don’t care whether …\nInflation is 1 percent and growth is 4 percent\nInflation is 2 percent and growth is 3 percent\nInflation is 2.5 percent and growth is 2.5 percent\nInflation is 3 percent and growth is 2 percent\nInflation is 4 percent and growth is 1 percent.\nThese are all equivalent under NGDP targeting. So to stabilize an economy, you aim for consistent 5 percent nominal growth, and you ignore the two components. If there is $10 trillion in circulation at the beginning of the year, you want $10.5 trillion in circulation at the end. No more, no less. In this scheme, the central bank only looks at nominal GDP, nothing else.\nThis is called Nominal GDP Level targeting because if the central bank sees that they are undershooting, they overcompensate, and if they see that they are overshooting, they undercompensate, so the NGPD prediction comes back into target range. They do not scratch their heads and “try harder” when they undershoot, they add even more money into the economy to compensate for previous shortfalls. This is not too different from the way the heating system has to heat your home if a window is open in winter. It sometimes has to overcompensate to stay on target.\nThe monetarist tool is the amount of money in circulation. If monetarists had their way, central banks would have nothing to do with bank regulations and interest rates. Instead, they would build a mechanism that automatically adjusts the amount of money in the economy to meet a pre-defined 5 percent nominal GDP target at the end of each year. This is called market monetarism. It works like this:\nThe central bank declares a target of 5 percent nominal GDP growth by the end of the year. They pledge to use the power of their balance sheet to accomplish that. Since their balance sheet is infinite, this is a big deal.\nCentral banks can’t see the future. They get economic data that is usually months old. How can they tell whether they are going to hit their target? How can they decide whether to stimulate (add money) or cool off (pull money out of circulation)? They can use a prediction market, where people buy and sell futures contracts based on whether NGDP will hit the stated target. The wisdom of the crowd betting their own money is about the best mechanism for predicting the future level of NGDP.\nThey feed that information into an algorithm that automatically adjusts the amount of money in circulation. There are different ways to do this, but essentially if the market says they are undershooting, they create money and put it into circulation, and if the market says they are overshooting, they pull money back. They should do this at least weekly, but eventually daily would be better.\nThe important thing is that everyone knows the monetary policy is now on autopilot — like a thermostat — and that the central bank is willing to create or destroy as much money as it takes every day to hit the target exactly at the end of each year.\nThis becomes a self-fulfilling prophecy. Everyone knows the central bank has more money than anyone, so if the central bank keeps its word then nominal GDP will hit the target. Simply the threat does the job. With the money supply on autopilot, the central bank doesn’t need to do much, and fears of uncertainty, recession, and deflation disappear.\nThis automated approach hasn’t been tried, but it is more or less the way the Australian central bank works, and they haven’t had a serious recession since the early 1990s (though their growth is now slower than it should be). There are different ways to implement this thermostat approach. We will need research to refine and adjust the model as necessary — especially if the population changes or technology has an impact on stickiness. But more and more economists are starting to see that nominal GDP level targeting would be a huge improvement over today’s monetary policy.\nMarket monetarism is the subset of the monetarist school that includes step 2 above. They believe markets are better at setting prices than experts are, and that an automated monetary policy that uses NGDP futures data as input will provide the necessary countercyclical adjustments to maximize sustainable economic growth.\nNominal GDP level targeting should eliminate recessions and provide a strong counterbalance to shocks. It keeps GDP growing, which makes your take-home pay worth more (buy more stuff) in the long run. When inflation is lower than the 2-percent target, it means the economy is underperforming. Life would be better for everyone if central bankers would just print more money.\nAnd that’s what we hope the Fed will listen to when they meet in Chicago this week. They know about NGDP level targeting, but they don’t take it seriously. It seems too risky to them. That’s why Scott Sumner and David Beckworth are there — to help the Fed look at this thermostat and consider how it could benefit the US economy.\nMy thanks to Rob Siegel and Kevin Dick for their helpful reviews and suggestions.\nEliezer Yukowsky on how central bankers can learn to create more inflation and help their citizens (recommended).\nScott Sumner on The Case for Nominal GDP Level Targeting.\nNominal GDP Level Targeting for Dummies (easy and fun to read).\nThe Case for CBDC, Cato Institute (technical).\nScott Sumner’s blog, The Money Illusion.\nDavid Beckworth’s podcast, Macro Musings.']	['<urn:uuid:fa1048f7-b42a-4441-84e4-3722c5f070e6>', '<urn:uuid:83b3c56c-c8c7-408e-8a3b-0e57afddcbe7>']	open-ended	with-premise	verbose-and-natural	similar-to-document	comparison	novice	2025-05-01T22:05:01.292488	26	123	3321
104	What are the main differences between traditional acoustic pianos and digital pianos in terms of maintenance needs, and how has technology impacted the repair process for both types of instruments?	Traditional acoustic pianos and digital pianos have distinct maintenance requirements and repair processes. Acoustic pianos need regular tuning, especially when affected by factors like stage lights and temperature changes that impact the instrument's tuning. With digital pianos, while they were initially marketed as maintenance-free and never needing tuning, they still require repairs for issues like fouled key contacts, broken floppy drives, and damaged keys and pedals. Technology has impacted repairs differently for each type: acoustic pianos can be serviced through mobile repair shops that can perform on-site maintenance and technical support, while digital piano repairs have become more complex due to densely packed electronics on smaller boards, making repairs more difficult and expensive when needed. Additionally, digital pianos often face parts availability issues after about ten years as models are phased out.	"['Keeping the pedal down on the local piano business.\nRussell Coltharp still has the first tuning lever that his father gave him almost 50 years ago. An enthusiastic 50-something Midtowner, he has turned that lever and countless lessons from his parents and grandparents into Coltharp Piano World, an innovative family business that sells and services pianos in several markets and maintains a showroom here in Memphis that is unique in scope. Whether there is a major flood or just an evening with Jerry Lee Lewis, Coltharp has been there and knows how to fix a piano. And only a piano: “We don’t offer or service trumpets or trombones or guitars or saxophones,” he says.\nMemphis is a music city, and Russell Coltharp has been in the middle of that musical mix for decades. “In the 1970s and 1980s, the Mid-South Coliseum was a big music venue,” he says. “Back in those days, I was really involved with the convention center, the Orpheum, the Mud Island Amphitheatre. Every venue had an acoustic piano. And if the artists carried their own instruments, they needed technical support and tuning. I was pretty much involved in every musical event.”\nFew people have spent more hours listening to the Memphis Symphony Orchestra. And fewer have had to deal with the exacting demands of virtuosic musicians.\n“I’ve spent much of my life sitting backstage. I would have a consultation with an artist on a Wednesday, a Thursday rehearsal, Friday a rehearsal performance, Saturday performance, and Sunday matinee,” he says. “I was on call and on standby for eight months out of the year. Usually, I would be dismissed by intermission. The stage lights get hot. That affects the tuning of the instrument. The artists are very demanding. It can be very challenging. When the piano is your personal orchestra, and that’s your performing piece, it’s live. Working all these years with all the artists, they don’t redo it.”\nWhile stressful at the time, Coltharp laughs about one of his more difficult charges, whose name he declines to mention. The house was packed for a full orchestral performance, when the guest pianist stopped the conductor’s opening count and refused to play. “It was a moment in time,” Coltharp recalls. “The managing director of the symphony was standing next to me. He said, ‘Russell, I think you need to go out there.’ I said, ‘I think you need to go out there.’ Then we agreed to both go out there.”\nEventually, the issue — a minor problem with the piano — was resolved much to the audience’s delight. “As we walked off, the whole place burst into applause. They were tapping their violins.”\nColtharp understands the situation from the artist’s perspective. He knows how complex the piano is and how complex its player is too. “You’ve got to know they are in charge,” he says. “Every ear hears differently. There’s feel, touch, after touch, tonal color. I’ve had artists come in and say it was the best [piano] they’d ever played. Three weeks later someone says the piano plays like a beanbag. A bean bag.\n“You work through it,” he says. “But that understanding is key: to figure out where the artist is coming from, if it’s in touch, tone, or feel.”\nRussell Coltharp comes honestly to his understanding of the piano as a mechanical, acoustic, and psychological tool. His family provided him with a unique set of experiences.\n“My father, my mother, and grandmothers were all piano teachers. I had a great-grandfather who was a music man. I’ve been raised in this all of my life. Memphis has been my home all of my life. My mother and father both exposed me to a small mom-and-pop business. My father exposed me to work under the best technicians that I think have ever lived.”\nThrough his business, Coltharp nurtures the relationship between an instrument and its player. His showroom on Summer Avenue has guided both the novice and the superstar through their musical pursuits. It’s a place where teachers, technicians, and performers foster relationships.\n“I’ve worked for Charlie Rich over on Cherry Road,” he says. “He came in this store many a time. Jane Swoboda taught here for many years; she was a good friend and taught a lot of the local musicians. They would come in and want to learn certain licks. She was wonderful. She was with me for 15 years. I miss her dearly. She played at Folk’s Folly and at the University Club. She had a real way with adults to help them. I’ve worked with a lot of artists over the years. It’s a great musical journey.”\nThe economy has taken him on another journey of his own. In recent decades, several factors have conspired against his profession, starting in the 1980s with digital instruments and more recently with the Great Recession. But Coltharp is an innovative thinker.\n“Of course your symphonies still have the purists of the acoustic piano. But that has so changed now due to the electronic and digital age of synthesizers,” he says. “It’s just really changed through the years. There’s just not as much involvement in the concert venue that there once was.”\nWhat’s a tuner to do?\n“We have mobile shops. About 15 years ago, I started building mobile shops that are powered and able to go to any market or venue and do warranty service, technical support, internal service, and do the work on site. That’s been a blessing. Before the mobile shops, everything had to be transported into our facility. We had to do the work and tranport it back. Just the cost to move an instrument of 1,000 pounds back and forth is a big part of the job. So the mobile shops have been quite successful. It’s worked for manufacturers, too, because I’m able to do cost-effective service in any marketplace. I have [living] quarters in the satellite shops, so I’m able to shower and stay and go comfortably from venue to venue. I have three with technicians available. The technical support is very busy. Thankfully, we’re very busy. I cover quite a bit of ground in other markets.”\nThe opening of the Nashville market was a godsend. And Coltharp didn’t go halfway: His client list there is top shelf.\n“I was asked to rebuild a seven-foot Steinway that’s in RCA Studio B [Everly Brothers, Roy Orbison, Dolly Parton, and Willie Nelson have recorded there]. It took about a month with mobile shops on site,” he says. “I did a lot of work at night. I’ll put in 50-amp hook-ups with water and equipment. I do work in Nashville at the Country Music Hall of Fame. I got involved there with the entertainment side of the industry. I did a restoration to the nine-foot gilt concert grand that’s on exhibit.”\nDon’t worry, he’s still a Memphian.\n“I enjoy taking care of [Nashville]. But there’s a big difference in the music market in Nashville. We’re very busy here, but the recording industry is so different there. Nashville has been a blessing. I’m thankful for Memphis. It’s my home.”\nAnother aspect of Coltharp’s business is piano rescue.\n“When there are situations with flooding, like what Nashville went through,” he says, “they need assistance to get those instruments moved immediately, then we do dry-out procedures to salvage the instrument. You need mobile equipment. We had 8,000 claims of water damage just in Memphis [this past winter]. Not all of them had pianos, but many of them did. Our shops on Broad and downtown are full. We have about 300 instruments in stock, not counting all of the restoration.”\nFixing musical instruments in Memphis is a great way to dive into the character of the city. Coltharp has had a ticket and a front-row seat to observe Memphis’ musical greats and curiosities.\n“There are many hand-built harpsichords in town,” Coltharp says. “I have many customers with interesting, collectible musical instruments. Organette, Victrolas, Nickelodeons that have snare drums, bass drums, piano, and tambourines. Customers in Memphis have collections, especially the old vacuum-pump players with the bellows. Those are not easy to work on.”\nColtharp won’t name names, but there is a pipe organ in a home somewhere in Memphis. And that’s not the half of what comes through his warehouses and shops. “I’ve done a lot of work for the Elvis Presley estate,” he says. “When he passed, I was doing some restoration. His pianos became quite valuable after his death.”\nOne of the more unusual jobs Coltharp has taken on involved German artist Juergen Teller’s photo shoot of William Eggleston for W magazine. Teller decided that his portrait of the esteemed Memphis photographer should be taken in the parking lot of Tops BBQ on Summer Avenue. But Teller wanted a particular prop.\n“They wanted a concert grand in the parking lot behind Tops,” explains Coltharp. “So they contacted me. He wanted [Eggleston] to sit out in the parking lot with a cigarette and piano. So I had mobile shops on the scene. We just had to stand by to reposition the piano. It was a nine-foot concert instrument. It was cool. He was enjoying that moment in time.” (For more on that particular shoot, see “The Art of Being William Eggleston” by Tim Sampson, in the June 2012 issue of Memphis.)\nBut what about a certain piano player, the one from Ferriday, Louisiana? The man with the pretty hair and the fire in his belly? What about the Killer?\n“He used to damage all of our pianos back in the day,” Coltharp says of longtime customer Jerry Lee Lewis. Lewis would leave a signature token of his esteem on Coltharp pianos.\n“He used to damage the keyboard on the treble end with his boot. But now he doesn’t quite get the foot up on the keyboard. So sometimes the bench gets knocked over. We get a lot of damage through the years. We had to get deposits to offset piano damages. I think at one point we were the only people who would rent or lease pianos to him because of the damage. He wanted at least a six-foot grand piano. I never knew him to be that particular over the brand or model. He liked a very bright piano with a lot of clarity. Fast action. He is a very fast player, heavy-handed.”\nColtharp’s relationship with Lewis led to a job managing the pianos for the production of the biopic Great Balls of Fire. The script called for pianos throughout Lewis’ life from the old Stark upright, at which Lewis learned to play with cousins Mickey Gilley and Jimmy Swaggart, to the extravagant pianos he accumulated (and destroyed) over his life. The film job involved 37 pianos. Coltharp had all of the models in his warehouses and kept some poor instruments on a rotation between daily destruction and onsite refurbishing.\nAs Coltharp walks around his showroom, his passion is evident. A wall display explains every aspect of a piano’s construction. He walks from model to model, banging out chords that reveal each instrument’s character. Not many real piano shops are around anymore, and even fewer places where people have taken the time to develop the skills and the savvy to sell a complicated, expensive product.\nColtharp stocks pianos from the gargantuan Bösendorfer concert grand to the most affordable spinet. He likes to show customers the range of sounds and prices. But as he walks through the showrooms and introduces his employees and his family members who are working there, Coltharp demonstrates that building musical relationships is his life’s work.\n“We are passionate about a musical work of art called the piano,” he says. “That’s my passion, and thankfully we stay very busy.”\nJoe Boone is the music editor of the Memphis Flyer.', ""Digital Piano Repair\nDigital Piano History\nDigital Pianos began appearing on the scene in the mid to late 80's as manufacturer's sought to compete with the home piano market. Technology that was being used in professional stage keyboards was adapted and packaged in a furniture quality cabinet to be used in living rooms and family rooms of consumers. Besides being able to make basic piano sounds digital pianos are able to make an infinite variety of additional sounds thanks to their digitally sampled sound technology. The also have a powerful microcomputer in them that makes them capable of playing multi-instrument accompaniments in a variety of musical styles. Most are also equipped with a floppy disk drive, USB slot, or other storage device to allow multi-track recording an playback to MIDI files.\nUnfortunately, many digital pianos were sold on the basis of being maintenance free, ie. never needing tuning, and longevity do to the reliability of electronics. Customers soon learned that the contacts beneath the keys would foul, floppy drives would be damaged or die, and keys and pedals would break. Each of these items turned out to be unique to a particular piano and many of the parts were phased out after about ten years making it difficult to repair them beyond that point. Key contacts can usually be cleaned with satisfactory results put were most often changed outright resulting in rapid depletion of the supplies of replacement parts. Floppy drives look like standard PC floppy drives but are not compatible and supplies of many models have long since been depleted.\nIn the mean time new features and capabilities are added on a regular basis. The number of sounds continues to multiply. And the electronics has been reduced to fewer boards and fewer chips that are more densely packed on smaller boards. While this means greater overall reliability it also means more difficult and expensive repairs when they are needed.\nEquipment Needed for Digital Piano Repair\nThe majority of digital piano repairs involves, broken keys and pedals, dirty key contacts, dead floppy drives, and other non-electronic issues. For this reason the most important tools for digital piano repair are those required for mechanical assembly and disassembly. A good set of screwdrivers, nut drivers, Allen Wrenches and a socket set are essential for the repair of digital pianos. Digital pianos tend to be bulky and sometimes heavy. An extra hand during the assembly and disassembly process can be very helpful. Dust removal is essential to maintain keyboard reliability. Micro fiber dust rags and a small canister vacuum can be very useful, especially an anti-static model. A basic liquid hand soap is good for contact cleaning. Denatured or anhydrous (water free 100% isopropyl)alcohol can be used for other cleaning duties.\nFor electronic repairs and troubleshooting a digital multimeter with a diode check setting is the main workhorse. Repair of the digital controller/generator board often require the use of a good quality oscilloscope. It should have a minimum bandwith of 100Mhz and dual trace is a useful feature. A grounding strap and a good understanding of static protection techniques can prevent inadvertent damage to the very expensive circuit boards that are the heart and soul of modern Digital Pianos. Also required for circuit board repairs is a good quality temperature control soldering iron, a hot air gun, a solder sucker or de-soldering station, dental picks, liquid solder flux, and good quality solder wick. A schematic diagram or service manual applicable to the particular model is also an essential element of troubleshooting.\nTechnical Knowledge Required For Digital Piano Repair\nwhile many of the repairs that are made on digital pianos are simple mechanical procedures electronic failures are not totally uncommon. It is important to realize that mere mechanical aptitude will not suffice for the full range of repairs that might be encountered. A deep understanding of basic electronics is necessary. You should also be familiar with microprocessors, digital signal processors and digital to analog converters. Digital pianos require well practiced soldering and de-soldering skills to avoid damaging delicate integrated circuits and very fine pitched traces on the circuit boards. While the piano is under warranty most electronic repairs can be accomplish by board swaps. Later in the piano's life board repairs can be cost prohibitive or replacement boards may be unavailable. It is also very helpful to have connections to other professionals in the business since many of the repairs in the later life of a particular model are dependent on access to used boards and assemblies. An ability to read and understand schematics and to analyze potential modes of failure that might explain the known symptoms. An analytical mind is your most important tool.\nCan I Fix My Own Digital Piano?\nSafety, when it comes to repair of digital pianos, means protection from bodily harm and protection of the instrument under repair. Inside the digital piano is a localized point of 120-240 volt AC mains. It can give fatal shock if you are not careful. There are also sharp metal edges that can cause severe injury and need to be respected. Digital pianos tend to be bulky and often very heavy and assistance and safe lifting techniques should be employed. Finally, some of the chemicals that are used for cleaning are flammable or may pose other health hazards. It is important to know how they should be handled safely.\nAn even greater danger is the possibility of damaging the instrument. Digital pianos are a built into a fine furniture cabinet and serve a decorative as well as a practical purpose. Surfaces should be protected from inadvertent damage to the fine finish. Also the high level of integration in the circuitry used on the main board creates a fairly high risk of damage due to static discharge. Proper grounding and anti-static protection techniques should be used at all times. Risk of damage to the board is also high during soldering and de-soldering operations. Soldering techniques should be thoroughly practiced before ever attempting a boar level repair on the complex main boards that are the heart and soul of modern digital pianos.\nUnless you fully understand the terms and the implications of the entirety of the above discussion, you should not even be considering working on your digital piano. Seek a repair professional to properly and safely repair your valuable and beloved instrument.\nWhere Can I Get My Digital Piano Repaired?\nMITA technicians are tops in the field, with the training and experience to reliably repair your piano. Find the nearest MITA technician here for further consultation or a quality repair.""]"	['<urn:uuid:f077cfba-7f68-423e-bc3e-5116ee68b261>', '<urn:uuid:66734096-d240-44a9-8576-d5408c5ebb65>']	open-ended	direct	verbose-and-natural	similar-to-document	multi-aspect	novice	2025-05-01T22:05:01.292488	30	132	3062
107	As a prayer leader, how does making intention for regular prayers compare to Janazah prayer regarding Qibla and timing requirements?	For regular prayers, one must know that the prayer time has started and be aware of facing the Qibla - if prayed carelessly without confirming these, the prayer is invalid. For Janazah prayer, while facing Qibla is a necessary condition like other prayers, there is no fixed time requirement - it can be offered at any time. However, both types of prayer require making intention in the heart, as uttering words of intention aloud was not the practice of Prophet Muhammad (saw) or his companions.	"['(Chapter 5c contd.)\nPLACE FOR EID PRAYER\nEid prayer should be offered outdoor in the open, e.g. in a park, field, or a desert etc. If it is wet or not possible to find a suitable outdoor place it can be prayed in a mosque or a large hall. (Abu Dawud)\nTIME OF EID PRAYER\nEid prayer should be offered when the sun is obvious, above the horizon.\nNUMBER OF RAKATS OF EID PRAYER\nEid prayer is 2 rakats. There is no nafl-prayer before off after the Eid Prayer. There is no Iqamah or Azan for Eid Prayer. Ibn Abbas (ra) reported: ""No doubt, Prophet Muhammad (saw) used to pray 2 rakats only for Eid Prayer. He did not pray anything before or after that. (Bukhari, Muslim)\nCONDUCT OF END PRAYER\n2 rakats of Eid prayer should be offered in the same manner as the 2 rakats of the usual prayer except that there are 7 takbirs in the first rakat and five takbirs in the second rakat. With each extra takbir the hands should be raised up to the shoulder level (as in Takbir Tahrima).\nAll extra takbirs should be pronounced before starting Q\'irat (recitation).\nKathir bin Abdullah reported from his father and his father from grandfather that Prophet (saw) said 7 takbirs in the first rakat of Eid prayer and 5 takbirs in the second rakat of Eid Prayer before beginning of the recitation. (Tirmizi, Ibn Majah,Darmi)\nEND PRAYER IS OFFERED BEFORE KHUTBAH\nJafar bin Muhammad (ra) reported:- ""No doubt, Prophet Muhammad (saw), Abu Bakr (ra) and Umar (ra) said 7 extra takbirs in the first rakat of their Eid and Rain Prayer and five extra takbirs in the second rakat of their Eid and Rain Prayer. Prophet (saw) offered Eid Prayer before Khutbah and recited aloud."" (shafaee)\nJANAZAH PRAYER (FUNERAL PRAYER)\nIt is a right of a Muslim that when he passes away other Muslims should pray Janazah prayer for him. Janazah prayer is supererogatory prayer. If no one from the whole of the Muslim Community prayed the Janazah prayer; then the whole community would be considered sinful in the sight of Allah. If some of the people prayed the Janazah prayer then the whole community is saved from the anger of Allah (swt) even though the reward will only be given to the participants only.\nIn hadiths Prophet Muhammad (saw) emphasized and encouraged the Muslims to attend funeral ceremonies. So, every Muslim male should try his best to fulfill his duties for one deceased.\n1. Janazah prayer should be prayed in congregation as this is most rewarding. It can be prayed in more than one congregation but by different people.\n2. Janazah prayer should be offered in an open place but in case of rain or bad weather or any other reason it can be prayed in a mosque or a hall etc.\nWHILE PRAYING JANAZAH PRAYER\nIf the body is that of a male, the Imam should stand level with the head and shoulders of the dead body. Imam should stand level with the middle part of the body if it is a female.\nWHERE JANAZAH PRAYER DIFFERS\nJanazah prayer is only slightly different from other prayers in that there is no ruku, no sajdah, and no Tashahud in it. There is no fixed time for offering this prayer. It has to be prayed in a standing position only. Other conditions like purification, facing Qiblah, sutra, dress etc. have to be satisfied as in the usual prayers.\nCONDUCT 0F THE JANAZAH PRAYER\na) Like other prayers facing Qiblah is a necessary condition. The Imam should ask the people to straighten their rows. There should be an odd number of rows as it is more regardful.\nb) Making intention is necessary in Janazah prayer as it is necessary in other prayers. Before beginning prayer the intention should be made in the heart as uttering any words of niyat aloud was not the practice of Prophet Muhammad (saw) or of his companions.\nFIRST TAKBIR OR TAKBIR TAHRIMA\nJanazah prayer Contains 4 Takbirs. First Takbir is Takbir Tahrima. The Imam says, ""Allahu-akbar"" and raises his hands up to the shoulder level with fingers stretching to the earlobes and the congregation does the same.\nThen the Imam folds his hands on his chest right hand over the left.\nDU\'A OF STARTING\nThen the person can read one of those du\'as which are recommended in the first rakat of the usual prayer before recitation of Fatihah. For example :-\nSubhana Kallah humma wabi hamdika ma tabara kasmuka wata \'aala jad-duka wala ilaha ghayruk.""\n""Glory be to you, O Allah, and all praises are due unto you, and blessed is your name and high is your majesty and none other is worthy of worship but you.""\nOr he can say other du\'as. Some scholars do not recommend du\'a of starting in Janazah prayer but reading it is preferable. However, if someone does not read it, it does not affect his prayer. Both ways are practiced by Muslim scholars.\nThen the person should say :-\n""A\'uzu bil-lahi minash shayta nir rajeem, Bismillah hir-rahma nir-raheem""\nand then he should recite Surah Fatihah.\nSome people do not read surah Fatihah in Janazah prayer but surah Fatihah is necessary for the validity of any type of prayer as Prophet Muhammad (saw) has said that no prayer is valid without surah Fatihah. Hadiths proves that reciting surah Fatihah is necessary in Janazah prayer as well.\nRECITATION OF A SURAH\nA chapter or part of a chapter can be read after the recitation of surah Fatihah but it is not essential to read it.\nThen the Imam should say the second takbir and the congregation should follow but it is not necessary to raise the hands up to the shoulder level but if someone does, it is alright. Both ways are practiced by great ulamas and scholars.\nAFTER THE SECOND TAKBIR :\nAfter the second takbit the person praying Janazah should recite dar\'ud in his heart. It is preferable to read the dar\'ud which a person reads in Tashahud of his usual prayer.\nThen the Imam should say the third takbir and the congregation should follow. Now, each person should pray for the deceased. Alternatively, the Imam should can pray out loud and the congregation can say, ""Aameen"", after him. All kinds of duas for the benefit of the deceased can be said. Some of these are :-\n""Allah hum maghfirlahu warhamhu wa\'fu \'anhu wa \'afihee wa-akrim nuzuluhu wa was-si\' mudkhalahu, waghsilhu bil maee wath thalji wal bardi, wa naq-qihi minal \'khataya Kama yunaq- qath thawbul abyadu minad danasi, wa abdilhu daran Khayram min darihi, wa ahlan Khayram min ahlihi wa zawjan khayrum min-zawjihi, wa adkhil hul jan-nata, waqihi fitnatal qabri wa \'Azaban nar.""(Muslim)\n""O Allah, forgive him, have mercy on him, pardon him, grant him security, provide him a nice place and spacious lodgings, wash him (off from his sins) with water, snow and ice, purify him from his sins as a white garment is cleansed from dirt, replace his present abode with a better one, replace his present family with a better one, replace his present partner with a better one, make him enter paradise and see him from the trials of grave and the punishment of hell.""\nAbu Hurairah (ra) said that the messenger of Allah (saw) prayed and said :-\n""Allah humma anta rab-buha, wa-anta Khalaqtaha, wa anta razaqtaha,\nwa anta hadaytaha lil islam, wa anta qabadta ruhaha, wa anta a\'lamu bisir-riha\nwa \'ala niyyatiha, ji\'naa shufa\'a, faghfir lahu Zan - bahu "" (Abu Dawud, Ahmad).\n""O Allah, you are its Lord, you have created it, and you have guided it towards Islam, and you have taken out his soul and you know best about its secret and open deeds. We have come as intercessors, so forgive him.""\nOne thing we can see clearly from the above mentioned hadiths that every companion who narrated the du\'as of Janazah prayer says that he had heard the Prophet (saw) saying the words of du\'a in Janazah prayer. This proves that the Messenger of Allah (saw) used to pray the Janazah prayer or at least the du\'as in Janazah prayer aloud. Therefore, there should not be any objection or confusion if the Imam recites aloud in Janazah Prayer.\nENDING THE JANAZAH PRAYER (FOURTH TAKBIR)\nThen the Imam should say the fourth takbir and the congregation should follow and after that the Imam should say ""Assalamu \'alaykum wa rahmatul-lah"" turning his face to the right first and then to the ieft; and the congregation should do the same.\nNote:- Some people stress a lot on saying du\'as after the completion of Janazah prayer but we did not find a single hadith supporting this idea. Janazah prayer is designed so that all the du\'as a person wants to say for the deceased can be said after the third takbir. This was the authentic practice of Prophet Muhammad (saw) and his companions.\nAlso see: A very detailed site dealing with step step depiction on the conduct of Janazah prayer.\nPRAYER DURING A JOURNEY\nIslam is a practical way of life and considers the situations in which its followers may face difficulties. So Allah has made the things easy for the believers in some situations. Included in the facilities is the permission for shortening and combining daily prayers during a journey.\n1. QASR PRAYER (SHORT PRAYER).\nWhen a Muslim is on a journey he should pray 2 rakats fard for Zuhr, Asr and Isha. Fajr and maghrib prayers remain as they are.\n2. IT IS MORE REWARDING TO PRAY A QASR PRAYER (SHORT PRAYER)\nIt is more rewarding to pray a Qasr Praver while on a journey. The Messenger of Allah (saw) said: ""It is a gift from Allah which he has bestowed upon you, so you should accept it."" (Muslim)\n3. COMBINING PRAYERS.\nA person on a journey can combine Zuhr and Asr prayers together praying them both at Zuhr or Asr time. He can also combine Maghrib and Isha prayers together praying them both at Maghrib or at Isha time.\nIbn Abbas (ra) says that the Messenger of Allah (saw) used to combine Zuhr and her together when he was on a journey and also he used to combine Maghrib and Isha. (Bukhari)\nMu\'az (ra) says that the Messenger of Allah (saw) was on a journey for the Battle of Tabook. If the sun had already declined when he wanted to start his journey after having camped somewhere, he would combine his Zuhr and Asr prayers together and pray them both at Zuhr time, and if he decided to move before the sun had declined then, he delayed the Zuhr prayer and prayed it combined with Asr prayer at Asr time. And if the sun had already set when he wanted to move he would combine Maghrib and Isha together at Maghrib time. And if the sun had not set when he wanted to move he would delay Maghrib and pray it with Isha at Isha time. (Abu Dawud, Tirmizi)\nThese hadiths are very clear in their meaning and prove that combined prayers while on a journey is a proved and a regular practice of Prophet Muhammad (saw). Still there are people who do not believe in combining prayers together while they are travelling. However, this is a gift from Allah (swt) which the believers should accept gratefully and if someone wants to reject Allah\'s and his Messenger\'s offer it is up to him.\n4. DURATION OF JOURNEY\nA person can pray Qasr and combine his prayers for as long as he remains on a journey, whether it takes weeks, months or years.\nEven if he stays put in one place to fulfil the purpose of his journey he can continue to pray Qasr and combine his prayers. However, if he intended to stay in a place for a fixed number of days then the opinions differ on how long he can go on combining and shortening his prayers, e.g. 4 days, 10 days, 17days, 18 days etc.\nAfter a careful study of hadiths we can say that when someone stays in a fixed place temporarily he would be considered a traveler on a journey, and there is no limit on the number of days he can pray Qasr and combine his prayers.\n5. NAFL PRAYER ON A JOURNEY\nProphet (saw) always offered Witr prayer during his journey and he emphasized and expressed the importance of 2 rakat sunnat of the Fajr prayer. Therefore, the believers should pray these, while on a journey.\nBut what about any other nafl and sunnat prayer?\nThe following hadith answers this question.\nHafs bin Asim says, ""I accompanied Abdullah bin Umar (ra) on a journey to Mecca. On the way to Mecca he led us in the Zuhr prayer and offered 2 rakats. Then he went to sit in his tent. He saw some people praying and asked me what they were doing. They are praying nafl\', said I. Then he said, \'If I could pray nafl then I should have prayed the complete fard prayer \' Then he continued, \'I accompanied the Messenger of Allah on a journey. He did not pray during his travels more than 2 rakats. Then I accompanied Abu Bakr, Umar and Uthman and thev did the same as Prophet Muhammad (saw)\'. There is a good example for you in the practice of Prophet Muhammad (saw). (Bukhari).\nThere are some other hadiths which prove that some of the companions used to pray nafls during their journey. It is better not to pray nafls while travelling but if you stay somewhere and have time you may do so.', 'Question: When making niyyah (intention) for a salat, does one have to keep the direction of the qibla and the entry of the time for the salat in mind?\nIt is okay if one is aware that one is facing the qibla. That is, one is considered to have turned toward the qibla if one can say, “The direction is not correct,” if the prayer rug were laid out in a wrong direction. Besides, one has to know that the time for the salat one is to perform has started. Otherwise, the salat will not be valid if one offers it carelessly without knowing whether the time for it has come.\nIt is written in the book Se’adet-i Ebediyye:\nIf a person who does not know the direction of qibla performs salat without seeking it, his salat will not be accepted even if he has found the qibla by chance. But if he understands after the salat that he found the right direction, it will be accepted.\nIf he has inquired for the qibla but has not performed the salat in the direction which he has decided to be right, he has to perform it again even if he understands that he has found the right direction by chance.\nQuestion: If one is ill or if there is the danger that one’s possessions may be stolen or of being seen by the enemy or if one will not be able to get on the vehicle again when one gets off and it is not possible for one to perform salat by combining them [Salat az-Zuhr with Salat al-Asr and Salat al-Maghrib with Salat al-Isha by following any of the other three madhhabs], either, what should one do in such a case?\nSuch a person should perform salat in whichever direction he is able.\nQuestion: When one is in a vehicle, on a plane, or in a bus, should one perform salat in the direction one is traveling?\nNo, one should try one’s best to turn toward qibla.\nQuestion: When a person on Earth is performing salat, he must face the qibla direction. In which direction should he face if he is in space? For example, the USA sent astronauts to Mars. There were Muslims among them. Suppose that they stay on Mars for six months. Where should Muslim astronauts face when performing salat? How should they determine salat times?\nWhen they turn toward the Earth, they will be considered to have turned toward the qibla. They can work out the location of the Earth with the help of the devices they have. Suppose that they do not know where the Earth is. In such a case, they perform salat facing the direction that they guess is most likely to be the direction of the Earth.\nSalat times are calculated according to the Sun. It is not difficult for those people with such enormous technical means and knowledge enabling them to travel to Mars to determine the times of salats. If they have the capacity to go to Mars, they can calculate salat times, too.\nQuestion: How much deviation from actual qibla is permissible? What is the qibla angle that prohibits one from spreading one’s legs toward qibla or from relieving oneself in the toilet toward it? How far should toilets of buildings be removed from qibla direction when they are at construction stage?\nSalat will be valid if the opening between the crosswise directions of the optic nerves includes the Ka’ba. This angle is approximately 45°. A much more deviation from qibla is permissible if one is ill or fears thieves.\nQuestion: Suppose that a person made a search to find the direction of the qibla and started salat. After he offered one rak’at, a pious Muslim came and said, “You are facing a wrong direction,” and turned him toward the correct direction with his hands. Was the salat of the former valid?\nYes, it is valid.\nQuestion: Our mosque in Europe deviates from the qibla by about 40 degrees. When I said to the imam that we must perform salat in the direction of the qibla, he answered, “Let us make things easy for Muslims. It is not necessary to face the qibla. Let them perform salat without slanting.” The same imam said that he asked the professors coming from Turkey and its Presidency of Religious Affairs the same question and they replied, “You can perform salat in that direction even if the mosque deviates from the qibla by 30 or 40 degrees because you do not live in a Muslim country. The buildings are not constructed in the direction of the qibla in such countries, so you are allowed to perform salat to whichever direction the mosque points.” Does it have any basis?\nIt seems that there is some misunderstanding. What may the reason be for their answering like that? The imam may have misunderstood them or may have attempted to ascribe his own view to them.\nIstiqbal al-qibla is one of the conditions of salat. It means facing the qibla during salat. In the Shafi’i Madhhab, one has to face the qibla exactly without any deviation. According to the madhhabs of Hanafi and Maliki, salat will not be valid if the deviation is more than 45 degrees on the right or on the left.']"	['<urn:uuid:60c523e6-194e-4871-8280-305609be3f01>', '<urn:uuid:893196e6-2a30-47b5-a1c7-4d85d055b462>']	open-ended	with-premise	concise-and-natural	distant-from-document	comparison	expert	2025-05-01T22:05:01.292488	20	85	3167
108	What's the difference between getting a regular parking ticket and a serious traffic violation, and how can someone deal with the mental pressure of each situation?	A parking infraction notice is generally less serious and can be resolved by simply paying the ticket, which is essentially pleading guilty, or contesting it by requesting a trial date. However, a serious traffic violation results in a summons that requires mandatory court appearance and could lead to criminal penalties like license suspension, fines, or jail time. To manage the mental pressure of these situations, several strategies can help. For temporary stress, exercising, listening to relaxing music, doing hobbies, and surrounding yourself with supportive people can be beneficial. For longer-term stress, techniques like deep breathing, progressive muscle relaxation, visualization, and mindfulness can help calm both body and mind. It's also important to manage automatic negative thinking through self-compassion and reducing perfectionism, as these approaches can help reduce anxiety and worry about the situation.	"['Wondering what is a traffic summons?\nYou received a court summons for speeding or traffic violation laws and are looking to find out what it entails.\nWhat’s a summons from a police and what’s the consequence?\nIn this article, we go over the traffic summons in detail so you know all there is to know about it.\nLet’s dive right in.\nTable of Contents\nWhat is a traffic summons\nA traffic summons is a summons issued by the police or a peace officer compelling someone to appear in court so his guilt or innocence can be determined on a charge.\nIf you received a traffic summons, your court presence is mandatory.\nIt also means that the traffic offense for which you are summoned to court is of relative importance requiring you to appear in court and defend your case in front of a judge.\nYou cannot just ignore the traffic summons, you need to make sure you appear in court.\nWhat’s a summons from a police\nSummons or citations are issued by the police when there is a traffic violation or behaviour that can constitute a crime.\nWhen someone is caught in violation of the traffic laws or criminal laws while driving, the police will write a citation against the person to appear in court.\nOften, the citation is issued directly on the scene at the moment the police noticed and apprehended you for traffic violations.\nWhat is a court summons for speeding\nA speeding summons is a traffic summons issued as a result of a speeding offense.\nIf a speeding summons has been issued to someone, they will need to appear in court and answer to the speeding charges outlined in the speeding ticket summons.\nIf the court finds the person innocent, the speeding summons will be dismissed.\nIf the court finds the person guilty of the speeding offense, then the court will define the appropriate penalty and sanctions to issue to the person charged with speeding.\nTherefore, a court summons for speeding ticket is issued only when speeding was at issue and required that you appear in court.\nTypes of traffic tickets\nDepending on your jurisdiction, you may have different types of summons for traffic violations.\nYou can get any of the following:\n- Parking infraction notice\n- Offense notice\nParking infraction notice\nA parking infraction notice is generally not that serious and you’ve probably got many of them.\nWith the parking infraction notice, the owner of a car is informed that they parked in a prohibited place.\nBy paying the parking ticket, you are essentially pleading guilty and resolving the ticket.\nYou can also contest the parking ticket and ask for a trial date to dispute the ticket.\nWhen you get an offense notice, this means that you have been in violation of traffic laws going from minor severity to major one.\nYou can receive an offense notice for speeding, missing a stop sign or driving through a red light.\nA summons is issued for serious offenses with criminal consequences.\nWhen you are issued a traffic summons, you are asked to appear in court to answer to the accusations made against you.\nYou can face sanctions such as the suspension of your driver’s license, fine and even jail.\nYou must make sure you give the summons issued to you all the importance it deserves as you can end up with a criminal record.\nWhat is contained in the traffic summons\nIf you have received a citation to appear from a police officer, it must contain some important information.\nYou should have the name of the court where you are asked to appear along with the court’s address.\nYou should also find an indication as to when is your initial court appearance date and time.\nGenerally, you should also find some information about the offense you’ve been charged with as well.\nAre you guilty when the traffic summons is issued\nIt’s important to note that you are not necessarily guilty because of the fact that a traffic summons was issued to you.\nA police officer who issued the summons to you had reasons to believe that you committed a violation of the traffic laws or criminal laws.\nThe police provided you with the summons so you have the opportunity to answer the charges laid against you before a judge.\nWhen the court will ultimately hear your case, the judge will make the final decision on your level of guilt.\nThe judge can either dismiss the traffic charges or find you guilty.\nConsequences of ignoring a court summons for speeding\nA speeding summons, just like any other type of summons, is an important legal document.\nYou are asked to present yourself to court so it can be determined if you should be held responsible for the traffic violation or not.\nRemember, some traffic violations can result in criminal penalties such as:\n- Careless driving\n- Reckless driving\n- Driving under the influence of alcohol\n- Driving under the influence of drugs\n- Crash causing material or bodily harm\n- Street racing\nIf you do not show up to court on the date required, the court may issue an arrest warrant against you.\nThe warrant for your arrest is a mandate given to the police to find you and detain you until you appear in front of a judge to answer the charges laid against you.\nThis also called a “bench summons” as the judge sitting on the bench issues the summons commanding the police to find and arrest the offender.\nNot respecting a traffic summons can be significant.\nA parking summons, or a non-moving violation, does not force you to appear in court unless you elect to contest the traffic ticket.\nIf your parking ticket has a parking summons date, you can fully resolve it by paying the ticket before the court appearance date.\nIn some jurisdictions, the parking ticket will not have a traffic fine summons and will rather ask you to either pay the ticket, and acknowledge you were guilty, or send a written request to contest it.\nIf you send a written request, then you’ll receive a summons to appear in court and contest the traffic ticket.\nYou received a summons for a traffic ticket and now you must appear in court.\nHow serious is this?\nThe summons to court for speeding, traffic law violation or even the violation of the criminal laws can be serious.\nYou should read the traffic summons carefully to understand when you are asked to appear in court and what are the charges laid against you.\nThe mere issuance of a court summons does not mean that you are guilty of the charges outlined in it.\nYou have the opportunity to go to court and contest the charges.\nIf you are not sure how deal with the summons, you should contact a lawyer experienced in the field to give you guidance.\nWe hope this article helped you better understand what is a traffic summons.\nWe would love to hear your feedback on this article.\nDrop us a comment!', 'Stress and Anxiety Management Skills\nWhat is Stress and Anxiety?\nThe first step in managing stress is to understand it. Although the terms stress, worry, and anxiety are used interchangeably by many people, they do have differences.\nStress involves reacting mentally and physically to a specific experience in your daily life, such as moving away from home, final exams, or lack of money to pay bills that month. After taking action or the stress passes, a normal mood returns. Even positive events such as winning an award or getting married can be temporarily stressful. It is important to recognize that not all stress is bad. A good type of stress, called eustress, keeps people motivated and excited about life. It can enhance an individual\'s performance in studying for an academic exam, or competing in an athletic event, or dealing with a difficult interpersonal situation.\nWorry is a form of thinking involving apprehensive expectations. It can be constructive when it leads to a positive solution, but it can become toxic when it paralyzes an individual. Key components of excessive worry are that it is non-productive and repetitive. Individuals may think about a problem over and over again as though running in place on a treadmill, going nowhere, but may never jump off the treadmill to resolve the problem.\nAnxiety, on the other hand, is what happens when stress continues without the stressor. In the brain, it is most closely related to fear and feelings of impending doom. It tends to be chronic involving excessive worrying about vague fears such as harm to loved ones, being unsuccessful in life, or fear of the future. Individuals may also worry about many small things that are not worth worrying about. If it does not go away, it may become chronic. Stress is not a psychiatric condition, but when pervasive stress and worry continue for over 6 months, it can become an anxiety disorder.\nThe anxiety disorders are the most common mental health problem in America. In any given year, anxiety affects about 18.1 percent of U.S. adults, and many more U.S. adults will experience it across their lifespan. New and better ways to handle both stress and worry before they become long-term problems are essential. The National Institute of Mental Health (NIMH) has succinct and helpful publications on the five major types of anxiety disorders. The Stress Recess site below has an excellent interactive program about stress and anxiety.\nCommon Responses to Stress and Anxiety\nStress affects each of us differently. Below are some common responses to stress and anxiety.\n- Feelings: worry; guilt; embarrassment; irritability; anger; fear; moodiness; feeling overwhelmed.\n- Thoughts : poor concentration; self-criticism; perfectionism; difficulty making decisions; forgetfulness; repetitive negative thoughts; fear of failing; worrying about the future.\n- Behaviors: acting impulsively; being irritable with others; using drugs, alcohol, or smoking to excess; crying; avoiding people or places.\n- Symptoms: tight muscles in neck, shoulders, and face; stomach distress; fatigue; trembling; appetite and sleep problems; dry mouth; heart pounding; sweating.\nTips for Managing Your Temporary Stress\nStress management is a personal journey. What works for one person may not work for another. As you try different approaches, it is important to allow your body and mind to tell you what is working for you.\nFor brief periods of stress, you may find the following helpful in reducing stress: exercising; listening to relaxing music; taking a warm bath or shower; doing hobbies and creative projects; managing your time better; surrounding yourself with supportive family and friends; getting your feelings out; laughing; and focusing on the positive.\nTips for Managing Your Longer-Term Stress and Anxiety\nOver time you may find you need additional tension reducing exercises. These are the state-of-the- art therapeutic approaches for reducing both stress and anxiety. They can be helpful when performed on a daily basis for a few minutes, as well as utilized in the middle of a stressful experience. They can lead your body and mind to calm down. They may also lead you to be less reactive to stress within a few weeks. (See the Virtual Relaxation Room on this site for downloadable exercises for most of these strategies).\n- Deep Breathing: The most basic relaxation exercise is slow, rhythmic breathing from your abdomen to calm yourself. When you are stressed or worried, your breathing tends to be shallow and fast. When your breathing is deep and slow, you tend to relax at a physiological level.\n- Progressive Muscle Relaxation: By alternately tensing and relaxing the major muscle groups throughout the body, you can achieve a deep sense of relaxation. After practicing this for several weeks, you may be able to move on to a ""Body Scan"" exercise where you notice the tension in the muscles but do not need to tense them.\n- Visualization or Guided Imagery: Imagery is a powerful way of achieving relaxation. By being transported to a soothing scene, you are free to let go of all tension and anxiety. You employ your visual sense but also your senses of taste, smell, touch, and sound.\n- Mindfulness of Thinking: Mindfulness is remaining aware of your feelings and thoughts in the here-and-now moment while suspending judgment or evaluation of yourself and your experience. By staying calm and focused without judgment, you can soothe and quiet yourself.\n- Meditation: Meditation is a proven method for relaxation of the mind and body. Meditation can bring you into the present by focusing your attention on your breathing, a few repeated words, a single repetitive action, or the flickering light from a candle. Many different types of meditation exist, so you need to do research to pick the one best for you.\nTips for Managing Your Automatic and Negative Thinking\nThese approaches are very helpful for changing the automatic and distorted negative thinking that can lead to long-term worry and anxiety. (See the Virtual Relaxation Room on this site for self-compassion exercises and the Stress Recess resources below for an explanation of the role of cognitions and beliefs in causing anxiety)\n- Self-Compassion: Self-compassion is the way to achieve well-being and relaxation through responding to yourself with kindness and understanding when you struggle with feelings of inadequacy, embarrassment, and other negative feelings. Self-compassion reduces the negative feelings caused from being relentlessly self-critical and may even lead to improved performance. This approach uses meditation and positive affirmations.\n- Reducing Perfectionism: By setting impossible goals and failing to meet these goals, you may end up with feelings of guilt, anxiety, disappointment, and lowered self-esteem. Frequently, you may set a new unrealistic goal because you believe achieving it will blot out the original sense of failure. More failure is usually the outcome. Reducing Perfectionism and substituting Healthy Striving is crucial to improving the sense of self and achieving personal peace.\nStress and Anxiety Management\nIf you want to learn more about stress and anxiety management skills, you may find additional information at the following links:\n- Anxiety and Self-Esteem (UT/Austin)\n- More Tips for Managing Stress (UT/Austin)\n- Publications about Anxiety Disorders (NIMH)\n- Stress Recess, (UT/Austin)\n- Vicious Cycle of Perfectionism vs. Healthy Striving (Stress Recess)\n- Cognitive Distortions (Stress Recess)\nIf you are struggling with stress, worrying, or anxiety and need more than the exercises above, help is available. Please contact Counseling Services at (775) 784-4648 to schedule a counseling appointment.']"	['<urn:uuid:b03a6401-f5c6-4796-bd79-ce9b9f07dbd8>', '<urn:uuid:567f5700-b0bc-45a5-bf75-d170b8c32aa0>']	open-ended	direct	verbose-and-natural	distant-from-document	multi-aspect	novice	2025-05-01T22:05:01.292488	26	133	2400
112	How do ultrasonic cleaners work and what safety benefits do they provide?	Ultrasonic cleaners use high frequency sound waves (18-120 kHz) created by electronically powered transducers that generate microscopic bubbles in a fluid tank. These bubbles implode creating hydraulic shock that removes debris. In terms of safety benefits, they minimize the risk of percutaneous sharps exposure for dental healthcare workers by reducing direct handling of contaminated instruments during cleaning and reprocessing. They can remove up to 99.9% of contaminants while providing a non-destructive, efficient cleaning method.	['by Breana Cronk, IQS Editor\nIn a world of ever advancing technology it seems that even something as routine as a trip to the dentist yields the discovery of new and improved instrumentation. Bi-annual check-ups for teeth seem also to mean bi-annual updates on dentistry. In recent years one of the most exciting new pieces of equipment has been the ultrasonic cleaner used to clean, protect and inspect teeth. Though relatively simple in design, these devices not only promote the health and safety of patients, but that of the dentists and hygienists that use them as they allow for the fast and efficient cleaning of both teeth and instruments. Far from a dental phenomenon, however, this technology has actually been around since the early 1950’s and has proven useful in a number of different industrial, commercial and even residential applications.\nUltrasonic cleaners image courtesy of ESMA, Inc.\nAs the name would suggest, ultrasonic washers use inaudible sound waves to gently but efficiently clean even small and hard to reach components where bacteria, debris and other sources of contamination are easily hidden even after manual scrubbing. These waves are created by the high frequency expansion and contraction of electronically powered ultrasonic transducers. Some units reach sounds up to 120 kHz, while other applications require forces as low as 18 kHz. The resulting ultrasonic oscillations reverberate throughout a reservoir or tank filled with a conductive fluid in which parts and components to be cleaned are immersed. While hot water may be used on its own, more often specially designed cleaning solvents and solutions with improved conductive qualities are used. No matter the material, the tremendous force creates millions if not billions of microscopic bubbles that implode creating a powerful hydraulic shock which loosens and removes debris for a thorough cleaning of even the smallest crevices or cracks.\nWith the capacity to remove up to 99.9% of contaminants, ultrasonic cleaning has become the standard in both dental and medical applications. As mentioned before, however, this beneficial technology is not limited to healthcare as it is easily adapted to a number of situations and in fact began as a method for cleaning complex aircraft components. These ultrasonic parts cleaners can be large enough to accommodate engine components and turbine blades. Other models are significantly smaller than these industrial ultrasonic cleaners and have even been made into novelty items such as ultrasonic jewelry cleaners and golf club cleaners. Although once relegated to industrial plants and facilities, ultrasonic cleaning systems have quickly found purpose in a number of applications such as automotive and marine industries, as well as businesses including hair salons, pharmacies and sporting good retailers.\nThe growing popularity of ultrasonic cleaners is evident in the ever expanding number of applications for which they are preferred. Speed and efficiency obviously play a role as these devices offer complete and thorough cleaning of even heavily greased industrial parts in ten minutes or less. Additionally, ultrasonic cleaning equipment is a non-destructive, energy efficient and often environmentally friendly alternative to the use of harsh chemical cleaning agents or burdensome manual scrubbing. From teeth to tools, ultrasonic cleaners offer industry a better and more consistent clean.\nPhoto courtesy of Ultrasonic Power Corporation.', 'You must be signed in to read the rest of this article.\nRegistration on CDEWorld is free. You may also login to CDEWorld with your DentalAegis.com account.\nClearly written policies, procedures, and guidelines have been advocated and developed by professional organizations and governmental agencies to help ensure consistency, efficiency, and effective coordination of infection control activities.1,2 One occupational risk faced by dental healthcare workers (DHCWs) is the possibility of percutaneous sharps exposure when handling contaminated dental instruments. Minimizing the potential for this mode of transmission is therefore a primary focus for a comprehensive infection control program.\nOne aspect to consider when implementing an infection control program is selecting technologies and products that can maximize a safe and efficient work environment for healthcare personnel and patients. Instrument cassettes represent examples of both a technology and a product that can be integrated into a dental office. When used appropriately, cassettes can increase organization and improve safety and infection control both in the dental operatory and when processing instruments for reuse on patients.\nInstrument Cassette Selection\nInstrument cassettes were first introduced in hospitals to organize instruments into procedure sets. They were later incorporated into dental school clinics, and in recent years have also become increasingly popular in dental offices. One important feature of instrument cassettes is that a single cassette can be used to hold and organize a complete set of instruments for a specific procedure (Figure 1). This convenience eliminates the need to gather multiple packages for a procedure. In addition, cassettes allow for less handling of contaminated instruments during cleanup and reprocessing. This latter attribute can provide additional safety by enhancing instrument flow while saving time. Table 1 summarizes the main advantages of using a cassette system in dental practice. Figure 2 shows an instrument cassette ready for chairside use.\nAs with the selection of any new product, it is important to consider what features cassettes can provide that will meet the needs of a specific dental practice. For example, cassettes are available in a variety of materials, sizes, and shapes (Figure 3). When determining what size(s) will best fit practice needs, one must consider how many instruments and accessories are used for each procedure. The most probable outcome of such a review is that several different sizes of cassettes will be needed due to specialized instrument requirements for certain procedures (eg, operative, hygiene, surgical procedures). When considering cassette size, it is also important to evaluate the size of the practice’s cleaning and sterilization equipment (eg, ultrasonic cleaner, instrument washer, heat sterilizer). Making sure there is adequate processing and storage space should be determined early on, because cassettes will occupy more storage space compared with other types of packaging materials.\nThis type of logistics review logically leads to a consideration of the impact of cassette implementation on practice costs. The answer is that cassettes will incur an initial financial investment. What also needs to be included in the office discussion, however, is what the cost would be to the practice owner when one of the clinical employees incurs an accidental percutaneous exposure when treating a patient. Initial consultations with a licensed medical facility, multiple post-accident serologic tests, and follow-up evaluations can cost hundreds of dollars for each accident that occurs. These do not begin to approach the emotional impact a sharps exposure can have on the employee. When taken as a whole, cassettes make sense.\nVirtually all commercially available cassettes are perforated cassettes; these are preferable to containers that are completely solid. Solid cassettes may not allow steam or chemical vapor to reach the contents for sterilization to occur. Additionally, cassette perforations allow thorough ultrasonic or instrument washer cleaning. Other features to consider would be instrument rails, strips, holders, or racks inside the cassette that are used to hold instruments in place. If these are made of soft material, they may decrease scratching on the instrument surfaces. Also, check to see if the holding devices provide adequate space between instruments to allow easy access during instrument cleaning prior to heat sterilization. A study performed at The Dental Advisor demonstrated that a single instrument washer or ultrasonic unit cleaning cycle was able to completely remove bioburden coated and dried onto instruments and cassette rails.3\nCompartments within the cassette to place accessories such as rubber dam clamps, anesthetic syringes, burs, amalgam wells, and air water syringe tips would be advantageous. The inclusion of important safety features such as a built-in needle recapping device can further reduce the potential for accidental needlestick injuries during patient care.\nEngineering and Work Practice Controls\nAvoiding occupational exposures to blood is the primary way to prevent transmission of blood-borne diseases (eg, hepatitis B virus, hepatitis C virus, human immunodeficiency virus) in healthcare settings. Exposures occur through percutaneous sharps injury (eg, a needlestick or cut with a sharp object) as well as through contact between potentially infectious blood, tissues, or other body fluids and mucous membranes of the eye, nose, and mouth or nonintact skin (eg, exposed skin that is chapped, abraded, or shows signs of dermatitis).\nThe majority of exposures in dentistry are preventable.1 Strategies to reduce the risk of blood contacts and prevent the transmission of blood-borne diseases include the use of the hepatitis B vaccine, standard precautions, use of engineering controls, and modifications of work practices. Usually a combination of these practices is used. These approaches, along with training and education, have contributed to the decrease in percutaneous injuries among dentists in recent years.4-7 To help DHCWs be as safe as possible with regard to sharp exposures, the Occupational Safety and Health Administration (OSHA) requires the use of engineering and work practice controls to eliminate or minimize employee exposure.8\nEngineering controls are often technology based and isolate or remove the hazard from the workplace. Whenever possible, engineering controls should be used as the primary method to reduce exposures to blood and saliva from sharp instruments and needles. Examples of engineering controls include sharps disposal containers, safety needles, and scalpels that isolate or remove the blood-borne pathogen hazards from the workplace.\nWork practice controls are those behavior-based practices that are incorporated into the everyday work routine that reduce the likelihood of exposure by altering the manner in which a task is performed (eg, using one-handed scoop technique or a needle recapping device to recap a needle; not bending or breaking needles before disposal; not passing a syringe with an unsheathed needle). In many cases, engineering and work practice controls are used together to eliminate or minimize workplace hazards. For example, by not recapping a needle with two hands, one is using a work practice control; if one recaps the needle using a needle recapping device, it is an engineering control.\nAn instrument cassette can be considered both an engineering and work practice control. When using instrument cassettes, the instruments are organized in one unit from the chairside procedure through cleaning, rinsing, drying, sterilization, and storage. Sharps injuries can be reduced chairside, because when reaching for instruments during a procedure, it is likely that the instruments will be more organized when using a cassette. As mentioned above, using cassettes can also decrease sharps injuries during cleaning after the procedure because of decreased handling of contaminated instruments. A built-in needle recapping device inside the cassette can also assist with one-handed needle recapping and eliminate the need to purchase a separate device.\nThe goal of instrument reprocessing is to deliver sterile instruments to patients. When cleaning and processing contaminated instruments between patient treatment procedures, the instrument recirculation system should be logical and organized in a manner that will most efficiently accomplish reprocessing and sterilization and minimize procedures that can place employees at risk for percutaneous, sharps exposures, or other hazards. 9-11 Using instrument cassettes streamlines instrument processing by keeping all the instruments for a specific procedure together in one cassette from the chairside procedure through cleaning, rinsing, drying, packaging, sterilization, storage, and delivery to chairside for the next patient. As a result, DHCW can save time and increase processing efficiency, in addition to reducing the potential for sharps injuries. The following sections review steps involved in instrument reprocessing, with an emphasis on how cassettes can improve efficiency and DHCW safety.\nInstrument Preparation at Chairside\nThe practice should designate a central instrument processing area to more easily control quality and ensure safety, instead of performing these procedures in the operatory.1,9,12 Preparation for instrument processing does begin chairside in the dental operatory, however. After completion of patient treatment, appropriate personal protective equipment should be worn when disposable sharp objects (ie, needles, burs) are discarded in sharps containers. All other disposable items, including gauze, cotton rolls, articulating paper, and cotton tip applicators, can be placed in appropriate waste containers when indicated. Closed and secured cassettes containing contaminated instruments can then be transported to the instrument processing area. Instruments should be arranged in an orderly manner when preparing them for the next patient, because they will not be removed from the cassette during instrument processing. OSHA regulations state that reusable sharp instruments should be placed in an appropriate container at the point of use to prevent percutaneous injuries during transport to the instrument processing area.1,12 Although an additional container may be used for this, a cassette readily accomplishes the same goal by having contaminated instruments already secured inside.\nCleaning and Decontamination\nThe basic premise of aseptic technique—clean it first—applies to instrument processing. Cleaning involves the removal of debris as well as organic and inorganic contamination. Because of the potential for injury from sharp instruments, hand scrubbing should be avoided as much as possible.1,9 Most dental offices use automated equipment such as ultrasonic cleaners for cleaning dental instruments. Instrument washers are becoming more popular in dental practices and can streamline the instrument cleaning process. When using perforated instrument cassettes, the cassette can be placed directly into the ultrasonic cleaner or instrument washer (Figure 4). After cleaning is complete, the cassette is removed and allowed to dry before wrapping. Because there isn’t any direct handling of the instruments during cleaning or sorting instruments later, the potential for injury can be substantially reduced.\nThe purpose of packaging is to protect instruments from environmental contamination after removal from the sterilizer and storage. Packaging materials must be compatible and designed for the type of sterilization process being used (eg, steam autoclave, dry heat, unsaturated chemical vapor) and cleared by the Food and Drug Administration (FDA). Packaging materials include bags, wraps, pouches, and wrapped perforated instrument cassettes. Instruments should never be stored unpackaged because an unwrapped item does not have a shelf life.1 Instrument cassettes are very useful and a popular method to package dental instruments, as virtually every US and Canadian dental school uses them to train students.\nIt is important to note that when using cassettes, all instruments for that specific procedure can be pre-arranged inside the cassette, thereby eliminating the need for bringing miscellaneous packages into the operatory. Decreased handling may even allow for a quicker set-up for the next patient. After the instrument cassette is cleaned and dried, the cassette can be opened and any disposable gauze items can be placed inside before sterilization.\nManufacturer’s instructions provide recommendations for cleaning, wrapping, and sterilizing cassettes. Unfortunately, the need to wrap a cassette is sometimes misunderstood, and a number of dental practices are thus not maximizing the benefit of cassette use. If a wrapping material (ie, sterilization wrapper, paper/plastic pouch) is not used to wrap the cassette, the contents will not remain sterile during storage because of the perforations in the cassette. Also, before wrapping the cassette, place an internal chemical indicator inside with the instruments. If an opaque packaging material is used and the internal indicator will not be visible on the outside of the package, place an external indicator on the package.\nIn dentistry, the three most common methods used to sterilize patient care items are steam under pressure (autoclaving), dry heat, or unsaturated chemical vapor. Steam sterilization is a dependable and cost-effective process and is the most widely used method for items that are not sensitive to heat or moisture.1 All sterilization equipment must be cleared by the FDA and used according to manufacturer instructions. Correct loading of the sterilizer chamber is essential. Items to be sterilized should be arranged to allow adequate circulation of the sterilizing agent.\nBecause the size and shape of instrument cassettes vary, it is important to consider the size of the sterilizer chamber when selecting and purchasing both sterilizers and cassettes. They will most likely take up more space than other types of packaging materials. Accessories, such as racks or trays, are usually provided with the sterilizer to help with proper loading procedures. Usually packages should be placed in the chamber on their edges so that the sterilizing agent contacts every surface of every article to be sterilized. Additionally, it is important to ensure that the cassette materials are compatible with the sterilization method being used in the office. Instrument packs should be allowed to dry inside the sterilizer chamber before removing and handling, as wet packs can easily tear. Finally, sterile packs should not be touched until they are cool and dry because hot packs act as wicks, absorbing moisture, and thus can introduce bacteria from hands and the environment.\nStorage of sterilized items should occur in a manner that prevents contamination; package integrity must remain intact until the time of use. Sterile dental items and clean patient care supplies should be stored in a clean and dry enclosed storage area. Closed cabinets limit dust accumulation and inadvertent contact with the sterile items. Because cassettes take up more storage space than instruments in pouches, it is important to also consider the size of storage space. Also, a wrapped cassette can reduce the necessity of repackaging and sterilizing items as a result of sharp or heavy instruments tearing paper or plastic package materials.\nAn important part of the office infection control program is selecting and using technologies and products to develop a safe working environment for patients and staff. Instrument cassettes are an example of a product that can be integrated into a dental office and, when used appropriately, can increase organization and improve safety and infection control both in the dental operatory and when processing instruments for reuse on patients.\nDr. Molinari provides consultation services to Hu-Friedy Manufacturing, Inc.\n1. Centers for Disease Control and Prevention. Guidelines for Infection Control in Dental Health-Care Settings, 2003. Atlanta, GA: Centers for Disease Control and Prevention, US Dept of Health and Human Services; 2003.\n2. Infection control recommendations for the dental office and the dental laboratory. ADA Council on Scientific Affairs and ADA Council on Dental Practice. J Am Dent Assoc. 1996;127(5):672-680.\n3. Molinari JA, Prose J. Cleaning efficacy of Miele washer/disinfector. The Dent Advisor. 2011;39.\n4. Cleveland JL, Gooch BF, Lockwood SA. Occupational blood exposure in dentistry: a decade in review. Infect Control Hosp Epidemiol. 1997;18(10):717-721.\n5. Gruninger SE, Siew C, Chang SB, et al. Human immunodeficiency virus type I. Infection among dentists. J Am Dent Assoc. 1992;123(3):59-64.\n6. Klein RS, Phelan JA, Freeman K, et al. Low occupational risk of human immunodeficiency virus infection among dental professionals. N Engl J Med. 1988;318(2):86-90.\n7. Siew C, Gruninger SE, Miaw CL, Neidle EA. Percutaneous injuries in practicing dentists. A propective study using a 20-day diary. J Am Dent Assoc. 1995;126(9):1227-1234.\n8. Occupational Safety and Health Administration. Occupational Exposure to Bloodborne Pathogens; Needlesticks and Other Sharps Injuries; Final Rule. Washington, DC: United States Dept of Labor; 2001.\n9. Molinari JA, Harte JA. Practice settings: dental office. In: Association for Practitioners in Infection Control and Epidemiology, ed. Infection Control and Applied Epidemiology: Principles and Practice. 3rd ed. Washington, DC: APIC Publishing; 2005; 51.1-51.23.\n10. The Organization for Safety, Asepsis and Prevention Web site. www.osap.org. Accessed May 25, 2013.\n11. Molinari JA, Harte JA. Instrument processing and recirculation. In: Molinari JA, Harte JA, eds. Cottone’s Practical Infection Control in Dentistry. 3rd edition. Philadelphia, PA: Lippincott Williams & Wilkins; 2009: 221-231.\n12. American National Standards Institute. Comprehensive Guide to Steam Sterilization and Sterility Assurance in Health Care Facilities. Arlington, VA: Association for the Advancement of Medical Instrumentation; 2006.\nAbout the Authors\nJohn Molinari, PhD\nDirector of Infection Control\nThe Dental Advisor\nAnn Arbor, Michigan\nJennifer A. Harte, DDS, MS\nMilitary Consultant for Dental Infection Control (Retired)\nAir Force Surgeon General\nPeri Nelson, BS\nResearch Associate, Microbiology & Infection Control\nThe Dental Advisor\nAnn Arbor, Michigan']	['<urn:uuid:04feab3d-b5ca-4a94-9628-bba277db4361>', '<urn:uuid:5e40940b-4aef-4a87-8be3-2236b367bb35>']	factoid	direct	concise-and-natural	distant-from-document	multi-aspect	novice	2025-05-01T22:05:01.292488	12	74	3262
113	what techniques show surface chemical structure defects	Multiple techniques can analyze surface chemical structure and defects. XPS and AES can detect chemical species in the top 1-2 nanometers of a surface, with XPS identifying chemical bonds and compounds while AES offers high sensitivity for elemental concentrations. STM provides atomic-level resolution and can directly observe surface defects, periodic and non-periodic surface structures, and local surface structure of single atomic layers. It can also obtain information about surface electronic structure when combined with scanning tunneling spectroscopy (STS), revealing details about surface electron states and potential barriers.	"['An adhesive must be able to effectively wet the substrate acted upon, harden, and withstand stress. Various internal and external forces such as heat, stress or chemical solvents can weaken an adhesive. When the strength of the adhesion weakens, the bonded surfaces may separate, causing failure.\nBonding failures can be classified as:\n- Cohesive – the failure originates in the bulk bonding material and may be caused by degradation of the adhesive.\n- Adhesive – the failure occurs at the interface of the two materials being bonded and may be caused by improper surface preparation. Even very thin contaminating films, only a few molecular layers thick, can prevent proper adhesion and cause failure.\n- Mixed – a combination of cohesive and adhesive failures.\nTechniques Used to Determine Adhesion Failure\nSEM Analysis with EDS\nScanning electron microscopy (SEM) with energy dispersive analysis (EDS) identifies the elemental microstructure of a sample and generates high resolution images. This is often the first step in determining particle characterization in any general failure analysis. However, the analysis depth of SEM/EDS below the surface is relatively deep. Thin surface layers or films can easily be obstructed by the signal from below the surface (typically 1-2 micrometers or 1000-2000 nanometers). When sampling the chemistry of the very top surface layer of 10 to 30 nanometers is necessary, instrumentation specifically designed for this purpose is required since even a very thin film can result in adhesion failure.\nXPS and Auger\nX-Ray Photoelectron Spectroscopy (XPS) and Auger Electron Spectroscopy (AES) are excellent surface analysis techniques perfectly suited for adhesion failures, surface staining, surface contamination, etc. Both instruments detect chemical species on the surface of the sample and are complementary to each other. The resultant spectra are “fingerprints” of the analyzed material. If the fingerprint cannot readily be determined by one instrument, the other sometimes may show a clearer fingerprint. XPS is used to analyze inorganic and organic compounds and various composite materials, such as metal alloys, polymers, and ceramics. It is an excellent technique to determine how the surface of a material was prepared for bonding or to determine the point of failure at the surfaces’ interface.\nAES is an efficient and straightforward characterization technique for examining the chemical and compositional elements of the top surface of a solid. This technique is known for its sensitivity and quantitative detail.\nComparison of XPS and AES\n- XPS has a larger spatial zone (or diameter) of analysis compared to Auger. It is typically 0.05 to 1.0 mm2, making it more suitable for sampling a relatively large, diffuse surface layer.\n- In contrast, Auger has a small, focused high-resolution beam which can be used to identify the composition of small particles ~5 micrometers in size.\n- In addition to detecting the elements themselves, XPS can detect the bonding states of elements as well as their chemical bonds, making it the technique of choice for identifying compounds on a surface.\n- While Auger is more sensitive to lower elemental concentration levels, it is generally not sensitive to bonding parameters or identifying compounds.\n- Both instruments isolate surface chemistry from the bulk, being sensitive to ~1 to 2 nanometers depth (3 to 10 atomic layers).\n- Both instruments can sputter away the surface layer, allowing a composition depth profile to be generated.\nFTIR and Raman\nBoth Fourier Transform Infrared spectroscopy (FTIR) and Raman spectroscopy are used to characterize and identify organic materials and adhesive, and/or the surface preparation and cleaning materials used in bonding. They require different sample sizes for analysis and have varying sampling zone (diameter) or spatial resolution of the spectra generated. As with the XPS and Auger techniques, these analytical methods complement each other by filling in the gaps to offer a complete picture of why materials, such as polymers and rubber, lubricants and liquids, fail to bond.\nFTIR can identify organic material and contaminants, including polymers, powders, and films, but provides somewhat limited inorganic data. Raman is used to characterize and identify both organic and inorganic materials and can determine the chemical structure of a material to identify its compounds.\nRaman and FTIR can be used for probing the bulk chemical composition of an adhesive for properties such as additive concentration, cross link density, oxidation, and other factors that would affect the cohesive strength of an adhesive.\nComparison of FTIR and Raman:\n- FTIR requires a sample of at least 15µm in diameter, but Raman has a minimum analysis area of approximately 0.5µm providing better spatial resolution.\n- FTIR is used typically for investigations consisting of organic materials but cannot be used for aqueous analyses; Raman is used to identify organic, inorganic and aqueous samples.\n- Raman also identifies crystalline structure which makes it easier to determine stress failures.\n- Raman imaging and confocal depth profiling can be used to produce maps that identify how components are dispersed in mixtures in three dimensions.\n- FTIR and Raman are both qualitative and quantitative however quantitative Raman analyses can be more difficult.\n- Both have access to spectral libraries to assist in identification.\n- Both techniques are non-destructive and can be used under ambient conditions.\nFor more information on failure analysis for adhesives and binding, please contact us at 1.800.860.1775.', ""Scanning Tunneling Microscopy (STM) Lab Services\nScanning Tunneling Microscope (STM) enables human beings to observe the arrangement state of a single atom on the surface of matter and the physical and chemical properties related to the surface electronic behavior in real time for the first time. It is of great significance and wide application prospect in the fields of surface science, material science, life science and so on. It is recognized by the international scientific community as one of the top ten scientific and technological achievements in the world in the 1980s.\nSTM is widely used in industrial and basic research to obtain atomic images of metal surfaces. It provides a three-dimensional profile of the surface, which is very useful for characterizing surface roughness, observing surface defects and determining the size and conformation of molecules and aggregates on the surface.\n- With atomic-level high resolution, the resolution of STM in the direction parallel to the sample surface can reach 0.1Å, which means that individual atoms can be distinguished.\n- The three-dimensional image of the sample surface in real space can be obtained in real time, which can be used for the research of periodic or non-periodic surface structure. This real-time observable performance can be used for the research of dynamic processes such as surface diffusion.\n- The local surface structure of a single atomic layer can be observed, rather than the average properties of the bulk phase or the whole surface, so the surface defects can be observed directly.\n- It can work in different environments such as vacuum, atmosphere, and normal temperature. The sample can even be immersed in water and other solutions. No special sample preparation technology is required and the detection process will not damage the sample. These features are particularly suitable for studying biological samples and evaluating the surface of samples under different experimental conditions, such as heterogeneous catalysis mechanism, super-integration, and monitoring of electrode surface changes during electrochemical reactions.\n- Combined with scanning tunneling spectroscopy (STS), the information about the surface electronic structure can be obtained, such as the density of states at different levels of the surface, the surface electron trap, the charge density wave, the change of the surface potential barrier and the energy gap structure.\n- Using the tip of STM, the movement and manipulation of atoms and molecules can be realized.\nOur STM laboratory can provide the following services:\nAs a professional reliability third-party testing organization, T,C&A Lab's STM Laboratory can provide the following services according to ISO, ASTM and other standards. Welcome to contact our experts for consultation.\n- General morphology testing\n- Atomic resolution morphology testing\n- Measurement of sample surface state density\nInstructions for sending samples:\n- Temperature: only 77K, cannot be tested at other temperatures.\n- Sample requirements: It needs to be conductive, the scanning surface is very clean, very flat, and free of volatile matter.\n- Powder samples, organic volatile samples, and samples containing unstable substances, such as sulfur-doped samples, gum-containing samples, and biological samples, are not accepted.\n- Currently, the test with magnetic field is not supported.\nStandards we test to\nASTM E2382, ASTM F1438\nIn addition, the experts in our STM Laboratory also provide a variety of custom services as your needs and requirements. Let's discuss the custom services with our experts for free.\nInstruments and data\n- Hegmann, Frank A. Progress and Challenges in Terahertz Scanning Tunneling Microscopy. 2018 43rd International Conference on Infrared, Millimeter, and Terahertz Waves (IRMMW-THz). IEEE, 2018.\n- Caballero-Quintana, Irving; et al. Interfacial Energetic Level Mapping and Nano-Ordering of Small Molecule/Fullerene Organic Solar Cells by Scanning Tunneling Microscopy and Spectroscopy. Nanomaterials 10.3 (2020): 427.\nNote: this service is for Research Use Only and Not intended for clinical use.\n- Inductively Coupled Plasma Atomic Emission Spectroscopy (ICP-AES)\n- X-Ray Fluorescence (XRF) Testing\n- X-Ray Photoelectron Spectroscopy (XPS) Testing\n- Infrared Spectroscopy Testing\n- Ultraviolet Spectrum (UV) Testing\n- Mass Spectrometry Testing\n- Micro-Raman Spectroscopy Testing\n- Nuclear Magnetic Resonance Spectroscopy Testing\n- Elemental Analysis\n- Structural Characterization\n- Morphology & Size Analysis\n- Corrosion Inhibitor Testing\n- Crevice Corrosion Testing\n- Electrochemical Corrosion Testing\n- Galvanic Corrosion Testing\n- High Pressure High Temperature (HPHT) Corrosion Testing\n- Hydrogen Embrittlement Testing\n- Intergranular Corrosion (IGC) Testing\n- Pitting Corrosion Testing\n- Salt Spray Testing\n- Sour Service Corrosion Testing\n- Stress Corrosion Cracking (SCC) Testing\n- Sulfide Stress Cracking (SSC) Testing\n- Thermal Analysis\n- Mechanical Testing\n- Non-Destructive Testing\n- Performance Testing\n- Pharmaceutical Testing\n- Chemical Analysis\n- Case Depth Testing and Analysis\n- Grain Size Analysis\n- Particle Size Distribution Analysis and Testing\n- Coating Thickness Testing\n- Inclusion Rating\n- Ferrite Testing\n- Porosity Testing\n- Grain Flow Testing and Analysis\n- Weld Testing\n- X-Ray Diffraction (XRD) Analysis\n- Scanning Electron Microscopy (SEM) Laboratory\n- Harmful Substances Testing\n- Reverse Engineering & Deformulation\n- Industrial Problem Diagnosis\n- Ingredient Analysis""]"	['<urn:uuid:a15221a9-36de-4457-a1b8-0ed8a553c446>', '<urn:uuid:7dfbeda0-29a3-4883-9d8e-5b8add1ed088>']	open-ended	with-premise	short-search-query	similar-to-document	multi-aspect	novice	2025-05-01T22:05:01.292488	7	87	1682
114	What is the required body length proportion for male Great Danes?	The length of the body should not exceed height at withers by more than 5% in male Great Danes.	"['General appearance: The Great Dane in his noble appearance combines a large, powerful well constructed body with pride, strength and elegance. By substance together with nobility, harmonious appearance, well proportioned outlines, as well as a specially expressive head, the Great Dane strikes the onlooker as a noble statue.He is the Appolo amongst all breeds.\nImportant proportions: Almost square in build, this applies particularly to males. The length of the body (point of sternum to point of buttocks) should not exceed height at withers in dogs by more than 5%, in bitches by more than 10%.\nBehaviour/Temperament: Friendly, loving and devoted to his owners, specially to the children. Reserved towards strangers. Required is a confident, fearless, easily tractable, docile companion and family dog with high resistance to provocation and without aggression.\nSkull: In harmony with the\ngeneral appearance. Long, narrow, distinct, full of expression. Finely\nchiselled, specially under the eyes. Superciliary ridges well developed but\nnot protruding. The distance from tip of nose to stop and from stop to the\nlightly defined occipital bone should be as equal as possible. The upper\nlines of muzzle and skull should run parallel. The head must appear narrow\nseen from the front with bridge of nose as broad as possible. Cheek muscles\nonly slightly defined and in no way protruding.Stop:\nNose: Well developeded, rather broad than round with large nostrils. Must be black with the exception of harlequins (white with black patches). In these a black nose is desired but a butterfly nose (black with pink patches) or flesh coloured nose is tolerated. In blue dogs the colour of the nose is anthracite (diluted black).\nMuzzle: Deep and as rectangular as possible. Well defined corners of lips. Dark pigmented lips. In harlequins not totally pigmented or flesh coloured lips are tolerated.\nJaws/Teeth: Well developed broad jaws. Strong sound and complete scissor bite (42 teeth according to the dentition formula).\nEyes: In blue dogs slightly lighter eyes are tolerated. In harlequins light eyes or two differently coloured eyes are to be tolerated.\nEars: Naturally pendant, set on high, of medium size, front edges lying close to cheeks.\nNeck: Long, clean, muscular. Well formed set on, tapering slightly towards the head, with arched neckline. Carried upright but inclined slightly forward..\nWithers: The highest point of the strong body. It is formed by the points of the shoulder blades which extend beyond the spinal processes.\nShort and firm, in almost straight line falling away\nimperceptibly to the rear.\nLoins: Slightly arched, broad, strongly muscled.\nCroup: Broad, well muscled. Sloping slightly from hipbone to tail set, imperceptibly merging into the tailset..\nChest: Reaching to the elbows. Well sprung ribs, reaching far back. Chest of good width with marked forechest.\nUnderline and belly: Belly well tucked up towards rear, forming a nicely curved line with the underside of the brisket.\nTail: Reaching to the hocks. Set on high and broad, tapering evenly towards tip. In repose hanging down with natural curve. When dog is alert or moving, carried slightly sabre-like but not markedly above the backline. Bristle hair on tail undesirable.\nShoulders: Strongly muscled. The long, slanting shoulder blade forms an angle of 100 to 110 degrees with the upper arm.\nUpper arm: Strong and muscular, close fitting, should be slightly longer than the shoulder blade.\nElbows: Turned neither in nor out.\nForearm: Strong, muscular. Seen from front and side, completely straight.\nStrong, firm, only slightly standing out from the structure of the\nPastern: Strong, straight when seen from the front, seen from the side, barely slanting forwards.\nFront feet: Rounded, well arched, well-knit toes (cat feet). Nails short, strong and as dark as possible.\nHindquarters: The whole skeleton is covered by strong muscles which make the croup, hips and upper thighs appear broad and rounded. The strong well angulated hind legs, seen from behind, are set parallel to the front legs.\nLong, broad, very muscular.\nStifles: Strong, positioned almost vertically under the hip joint.\nLong, of approximately the same length as the upper thigh. Well muscled.\nHocks: Strong, firm, turning neither in nor out.\nShort, strong, standing almost vertical to the ground.\nHind feet: Rounded, well arched, well-knit (cat feet). Nails short, strong and as dark as possible.\nGait/Movement: Harmonious, lithe, ground covering, slightly springy. Legs must be parallel in movement coming and going.\nSkin: Tight fitting. In solid colours, well pigmented. In harlequins, the distribution of pigment mainly corresponds to the markings.\nHair: Very short, dense, smooth and close lying, glossy.\nColour: The Great Dane is bred in three separate colour varieties: Fawn and brindle, harlequin and black, and blue.\nFawn: Light gold fawn to deep gold fawn. Black mask desired. Small white marks on chest and toes undesirable.\nBrindle: Basic colours, light to deep gold fawn with black stripes as regular and clearly defined as possible, running with the direction of the ribs. Black mask desired. Small white markings on chest and toes are undesirable.\nHarlequin: Basic colour pure white, preferably with no ticking. Pure black patches well distributed all over the body, having the appearance of being torn. Grey or brownish patches undesirable.\nBlack: Jet black, white markings permitted. Included here are ""Manteltiger"" in which the black covers the body like a coat (""mantel"") or blanket and muzzle, throat, chest, belly, legs and tip of tail may be white. Also dogs with basic white colour and large black patches so called ""Plattenhunde"".\nPure steel blue, white markings on chest and feet\nat withers:Dogs at least 80 cm, Bitches at least 72 cm.\nFaults: Any departure from the foregoing points should be considered a fault and the seriousness with which the fault should be regarded should be in exact proportion to its degree.\nGeneral appearance: Lack of male or female characteristics, lack of balance, too light, too coarse in built.\nTemperament:Lacking self-confidence, nervous, easily provoked.\nHead: Lines of head not parallel, apple head, wedge shaped head, too little stop; too prominent cheek muscles.\nMuzzle: Pointed, lacking flews, lips too pendulous.Bridge of nose concave (dish shaped), convex (roman nose), falling away in front part (eagle nose).\nJaws/Teeth: Any deviation from a complete set of teeth (only the missing of both PM1 in the lower jaw may be tolerated). Irregular position of individual incisors as long as the bite remains otherwise correct), teeth too small.\nSlack lids, haw too red. Light, piercing, amber coloured\neyes. Wall eyes or differently coloured eyes in all solid coat colours. Eyes\ntoo wide apart or slit eyes. Eyes protruding or too deeply set.\nEars: Set on too high or too low. Standing off from the sides of the head or flat lying.\nthick neck, ewe neck, throatiness or excess of dewlap.\nBeck: Sway back, roach back. Too long in back. Topline rising towards rear.\nFalling away steeply or completely flat.\nTail: Too thick, too long or too short, set on too low or too highly carried above the back line. Hook tail or curled tail as well as tail carried sideways. Tail which is damaged, thickened at the tip or has been docked.\nRibcage: Flat or barrel-shaped ribs. Lack of width or depth of chest. Too strongly protruding breastbone.\nLower line: Belly line\nnot sufficiently tucked up. Teats not sufficiently retracted.\nForelegs: Insufficient angulation. Light bone, weak muscles. Stance not vertical.\nShoulders: Loose or loaded. Upright shoulder blade.\nElbows: Loose, turning in or out.\nForearm: Bent, enlarged above pastern.\nEnlarged, markedly weak or knuckling over.\nMetacarpus: Too sloping or too upright.\nHindquarters: Too much or too little angulation. Cow hocked, close together or open hocked when standing.\nHocks: Exaggerated large or unstable.\nFeet: Flat, splayed, long. Dewclaws.\nGait/Movement: Covering too little ground, lack of freedom in action. Frequent or constant pacing. Lack of co-ordination between front and hind movement.\nCoat: Double coat (coarse, short coat), dull coat.\nFawn: Grey fawn, blue fawn, isabella (cream) or sooty fawn colour.\nBasic colour silver blue or isabella. Washed-out streaks.\nHarlequin: Blue-grey ticked basic colour. Large fawn-grey or blue-grey parts in the patches.\nBlack: Fawn, brown or blue-black colour.\nBlue: Fawn or black-blue colour.\nJaws/Teeth: Pincer bite.\nEyes: Ectropion, entropion.\nTail: Kinky tail.\nNose:Liver coloured; split nose.\nJaws/teeth: Overshot, undershot, wry mouth.\nColour:Fawn or brindledogs with white blaze, white collar, white feet or socks and white tip of tail.Bluedogs with white blaze, white collar, white feet or socks or white tip of tail.Harlequin dogs: White without any black (albinos), deaf. So called Porcelain tigers (dogs that show predominantly blue, grey, fawn or brindle patches), so called ""Grautiger"" (dogs that have a basic grey colour with black patches).\nHeight: Below minimum height\nN.B.: Male animals should have two apparently normally\ndeveloped testicles fully descended into the scrotum.']"	['<urn:uuid:5cf32037-9bb2-46d0-9e62-d587d0eeb4bf>']	factoid	direct	concise-and-natural	similar-to-document	single-doc	expert	2025-05-01T22:05:01.292488	11	19	1440
115	environmental factors cold stress list	Four environmental factors contribute to cold stress: cold air temperatures, high velocity air movement, dampness of the air, and contact with cold water or surfaces.	['30 Oct 17\nRecognizing Hypothermia, Frostbite And Other Common Cold-related Illnesses – Toolbox Talks\nToolbox Talks are intended to facilitate worksite health and safety conversations. Click here to download talking points on recognizing cold-related illnesses to share with your crew.\nWeather patterns are changing. Seasons becoming more extreme. And the ever-increasing unpredictability of Mother Nature is making it harder than ever for workers exposed to her wild weather swings to prepare.\nTake the winter of 2013-14, for example. That’s when a polar vortex settled on top of much of the U.S., helping push that February into the record books as the coldest month in the history of weather observations. Much of the Midwest and East Coast were paralyzed by the cold. The moderately warm fall preceding it only exacerbated matters, with the quick turn in temperatures leaving people less ready to handle winter’s arctic shock.\nWith these cold-weather extremes as a backdrop, it’s more important than ever to be able to properly identify the most common cold-related illnesses, along with knowing what treatments to seek.\nHOW THE BODY REACTS TO COLD\n- Energy is spent maintaining internal temperature\n- Blood is drawn away from extremities to the core\n- Exposed skin & extremities cool rapidly, increasing risk of frostbite and hypothermia\nWhen the body temperature drops below 98.6 degrees Fahrenheit (or 37 degrees Celsius), blood begins to flow away from the extremities to heat the body’s core. This immediately cools exposed skin and extremities, and increases the risk of cold stress, specifically frostbite and hypothermia. According to the Centers for Disease Control and Prevention (CDC), early signs and symptoms of heat loss include shivering, fatigue and confusion or disorientation. They can evolve to include blue skin, a slow pulse, and even loss of consciousness.\nIf body temps continue to fall, dexterity is diminished and speech may be slurred. At 85°F (29.4°C), severe hypothermia – a condition characterized by an extreme low body temperature – sets in. Symptoms include cool skin, severe shaking and memory lapses, among other issues. Once the body temperature plummets below 78°F (25.5°C), a person is at risk for brain damage – and even death – if not treated immediately.\nCOMMON COLD-RELATED ILLNESSES\n- Trench foot\n- Indoor and outdoor workers at risk\nThe three most common cold-related illnesses – hypothermia, frostbite and trench foot – are an obvious danger for those working outdoors in unpredictable winter weather. But the risk for those working indoors in places such as food processing, cold storage and beverage/brewing facilities is just as real.\nThe most severe of the cold-related illnesses occurs when body heat is lost faster than what’s produced, and core body temp drops below 95°F (35°C).\nWhat to look for:\n- Poor coordination and slowing of pace\n- Stumbling and clumsiness\n- Dazed and confused behavior\n- Slurred and slow speech\n- Hallucinations or changes in personality\nWhat to do:\n- Mild Case: Move to warm area and stay active. Cover head and body with dry clothes or blankets. Drink a warm (not hot) drink.\n- Moderate Case: Same as Mild, plus contact emergency medical personnel. Re-warm extremities.\n- Severe Case: Treat worker very gently and do not apply external heat to re-warm. Hospital treatment is required.\nBecause of the way blood leaves the extremities to protect vital organs in the body’s core in cold environments, hands and feet are the most susceptible to frostbite.\nWhat to look for:\n- White, grayish, or bluish skin\n- Cold, hard, or waxy feel to skin\n- May itch, burn, or feel numb\n- Blistering and hardening of skin are signs of extreme frostbite\nWhat to do:\n- Get out of the cold\n- Gradually warm the affected skin\n- Place frostbitten areas in warm – not hot – water\n- Wrap affected areas in a warm blanket\n- Seek emergency medical help ASAP\nNOTE: Do not rub or massage the frostbitten area or use a heating pad, heat lamp or other heat source for warming.\nTrench foot is a “wet cold disease” occurring in damp or wet environments that are just above freezing. The name comes from WWI when soldiers developed the illness while waiting in the trenches for combat.\nThe skin does not actually freeze with trench foot, but other issues definitely can arise.\nWhat to look for:\nWhat to do:\n- Remove wet socks and footwear\n- Thoroughly clean with warm water\n- Dry feet\n- When sleeping or resting, do not wear socks\n- Get medical treatment ASAP\nPERSONAL RISK FACTORS\n- Age, weight, fitness level\n- Chronic or acute illness\n- Alcohol or drugs\nThere are two sets of factors that come into play when considering the causes of cold stress on the body: personal and environmental. Being aware of these factors and knowing an individual’s risk factors will allow that person to be better prepared when the cold weather hits. While workers can’t do anything about some personal risk factors (like age, for example. The very young and the very old are much more susceptible to cold temps), they can reduce risk by being mindful of their own fitness levels — watching their weight, staying hydrated, avoiding alcohol and drugs, getting plenty of sleep, etc.\nAdditionally, acclimatization — gradually increasing exposure to the cold — plays a large part in reducing stress on the body. By taking frequent warming breaks and avoiding the temptation to go “all in”, workers can build up tolerance to frigid temps.\n- Cold air temperatures\n- High wind speeds\n- Damp air\n- Contact with cold water or surfaces\n- Working without proper PPE\nFour environmental factors contribute to cold stress: cold air temperatures, high velocity air movement, dampness of the air, and contact with cold water or surfaces. A cold environment forces the body to work harder to maintain its temperature. Cold ambient air temperature, water, and snow all draw heat from the body. High wind speeds and dampness in the air will also accelerate a body’s heat loss.\nTALK TO YOUR CREW\nThe reality is that work doesn’t stop when the temperature drops. So taking a few minutes before a shift to educate your crew on the signs, symptoms and causes of cold-related illnesses is a simple yet effective measure to increase awareness and reduce the risks.']	['<urn:uuid:0a6785a9-4cb8-4b42-a192-2d640ecee4b7>']	factoid	direct	short-search-query	similar-to-document	single-doc	expert	2025-05-01T22:05:01.292488	5	25	1049
122	I've heard that Taoism is both a religion and a philosophy - what are the basic principles and characteristics that define the Tao or the Way?	The Tao, or the Way, is complex and difficult to define simply. While it can be considered a religion, it is equally a philosophy containing simple yet puzzling instructions about living. It is primarily an inward journey, though it has external elements including scripture, temples, prayer, and local gods and rituals. Unlike other religions, Taoism has no central god but includes a pantheon of modest local deities who help people in their daily lives. The philosophy emphasizes simplicity and acceptance - as expressed in the teaching 'Practice not-doing, and everything will fall into place.' A key principle is achieving emptiness through acceptance of what is and giving up the illusion of control. These beliefs are so compatible with Buddhism that many people practice both traditions.	"['The Tao, or the Way, defies easy description. Although it may be classified as a religion, it is as much a philosophy that contains simple but perplexing instructions about how to live. ""Throw away holiness and wisdom,"" wrote the famous sage Lao Tse, ""and people will be a hundred times happier."" Practicing the Tao is primarily an inward journey, but the outer manifestation includes scripture, temples, prayer, a pantheon of local gods and rituals.\nHistory of Taoism\nTaoism\'s roots, like much of its visible manifestations, are buried in shamanic prehistoric China. Some time around 500 B.C.E., a shadowy figure who is called Lao Tse set down the philosophical principles of a Taoist way of life in a collection of teachings we know as the ""Tao Te Ching."" It has been pondered, studied and used as a guide for living ever since. Gradually, some of the trappings of religion grew around the essential philosophy. There are Taoist priests who perform the complex prayer rituals, temple protocol and scripture memorization, which functions as a kind of prayer. But Taoists do not pray in the way Christians do, for example. They regard gods as embodiments of the principles of the Tao. The essence of the Tao is a personal journey to ""Practice not-doing, and everything will fall into place.""\nTaoism has no central god but does admit a pantheon of local, modest deities who perform various functions to assist people in their daily lives. One example is a god still venerated during traditional Chinese New Year celebrations in an annual ritual. In the Tang dynasty, prosperous families who followed the Tao, would invite Taoist priests to read scriptures in their homes before a paper image of the Kitchen God. The Kitchen God, or the god of the stove, was believed to report the deeds -- or misdeeds -- of the family to the ancestors in heaven on the last day of each year. After scriptural recitations, carefully prepared food and ale were offered to the god and the ale was rubbed on the mouth of the departing god. The people believed this would make the god too drunk to report on them in the celestial realms and they might enter the New Year with a new paper image and their own reputations and good fortune intact. You can find paper Kitchen Gods to hang over your stove in many Chinatown shops today.\nPrayer, Ritual and Symbol\nTaoist temple rituals balance ""qi"" energy and yin and yang for participants and their communities. Priests recite complex prayers and scriptures, dance and play music as people make offerings, light incense and meditate. The Taoist Federation of Singapore sets out a primer of its practices which are formalized and include prayer postures. For prayer, both hands are balled into fists, left over right with thumbs tucked in to form a Yin-Yang symbol. Incense sticks are held up before the altar and offered with the left hand. The incense symbolizes a sacrifice to the ancestors and the gods. The supplicant bows before the altar as the ashes, standing for impurities, fall to the ground and the smoke -- signalling intentions -- rises, bridging the earth and sky.\nThe impersonal nature of the Tao resists personifying the gods, although Taoists borrow deities from everywhere. The temples are full of statues and embroidered hangings with images of gods but the images are really reminders of the goal of practice: to achieve the emptiness that comes with acceptance of what is and forfeit the illusion of control. These beliefs are so compatible with Buddhism that many people identify as Buddhists who also follow the way of the Tao. Lao Tse\'s epic work exhorts Taoists to ""Empty your mind of all thoughts. Let your heart be at peace."" The ideal is a calm transparency, achieved through meditation, contemplation and an appeal to higher powers for the grace of wisdom. One Taoist invocation seems to redefine prayer as the effort to transform oneself into an experience of peace that would ripple outward to affect the world: Empty of all doctrines, the Tao is wisdom eternally inexhaustible ... The Tao that can be told ... If there is to be peace in the world ... I begin this thing called Prayer ...\n- Blue Jean Images/Photodisc/Getty Images']"	['<urn:uuid:5211f4be-72df-447c-bf66-f2f40fca8a13>']	open-ended	direct	verbose-and-natural	similar-to-document	single-doc	novice	2025-05-01T22:05:01.292488	26	125	713
124	I'm working with Hamiltonian cycles and need to understand the space complexity - what's the maximum branching factor and depth for a graph with N vertices and maximum degree D?	For a graph with N vertices and maximum degree D, the depth of the state space is N. The branching factor is D (specifically D-1 at all nodes except the root, since the outgoing arc from a node can't be the same as the incoming arc). This gives an upper bound of D^N on the size of the state space.	"['The HAMILTONIAN CYCLE problem is the following: Given an undirected graph G, find a path that start and ends at the same vertex and contains every other vertex exactly once. For instance, in the graph below the path A-C-F-B-G-E-H-D-A is a Hamiltonian cycle.\nHAMILTONIAN CYCLE can be solved using the following state space.\nState: A path through the graph containing no vertex more than once. For example, A-D-H is a state. A-C-B-A is not a state, because it repeats A. A-H-G is not a state, because there is no edge A-H.\nSuccessor: Let P be a state, whose last vertex is U. For each edge U--V where V is not in P, the path P,V is a successor to P. For instance, the successors to A-D-H are A-D-H-E and A-D-H-G.\nStart state: Path consisting of a single vertex (it doesn\'t matter where you start).\nGoal state: A path containing every vertex once, where the first vertex in the path is connected by an edge to the last one. (For simplicity of description, we\'re representing the goal state as the path minus its final closing arc, as long as that arc exists. So the cycle above is represented by the state A-C-F-B-G-E-H-D.)\nA ---> AB ---> ABC ---> ABCF fail | | | |--> ABF ---> ABFC fail | | | |--> ABG ---> ABGE ---> ABGED ---> ABGEDH fail | | | | | |-> ABGEH ---> ABGEHD fail | | | |-> ABGH ---> ABGHD ---> ABGHDE fail | | | |-> ABGHE ---> ABGHED fail | |-> AC ---> ACB ---> ACBF fail | | | |-> ACBG ---> ACBGE ---> ACBGED ---> ACBGEDH fail | | | | | |-> ACBGEH ---> ACBGEHD fail | | | |-> ACBGH ---> ACBGHD ---> ACBGHDE fail | | | |-> ACBGHE ---> ACBGHED fail | |-> ACF ---> ACFB ---> ACFBG ---> ACFBGE ---> ACFBGED ---> ACFBGEDH fail | |-> ACFBGEH ---> ACFBGEHD succeed.\nA ---> AB ---> ABC | | | |-> ABF | | | |-> ABG | |-> AC ---> ACB | | | |-> ACF | |-> AD ---> ADE | | | |-> ADH | |-> AF\nSuppose that you are using the above state space for a graph G which has N vertices and maximal degree D. What is the depth of the state space? What is the branching factor? Give an upper bound on the size. Note: your answer to this question should be in terms of the general quantities N and D; it should NOT use the features of the graph in the picture at the top.\nAnswer: Depth: N. Branching factor D (D-1 at all but the root, since the outarc from a node can\'t be the same as the inarc.). Upper bound: DN\nA state is any assignment of the first K vertices alphabetically to positions in the path, as long as the assignment does not place two vertices that are not connected by an edge in successive positions in the path, and does not place two vertices in the same position. For example [A->3, B->6, C->5, D->1] is a state. (Another way to write this state would be D-*-A-*-C-B-*-*). [A->3, B->6, C->5, D->4] is not a state because C and D are in sequential positions in the path but are not connected by an edge. [A->3, B->3, C->5, D->1] is not a state because B and A are in the same position. In this definition, the first and last positions are considered to be ""successive"" positions also, so an assignment that placed D in 1 and B in 8 would also not be a state.\nA successor to state S extends S by assigning the next vertex anywhere it will fit, subject to the above two constraints. For example, the only successor to the state [A->3, B->6, C->5, D->1] is the state [A->3, B->6, C->5, D->1, E->8]. The state [A->3, B->6, C->5] has three successors: [A->3, B->6, C->5, D->1], [A->3, B->6, C->5, D->2], and [A->3, B->6, C->5, D->8].\nThe start state is the empty assignment.\nA goal state is a state that assigns a position to every vertex.\nSuppose that one is doing a depth-first search of this state and has reached the state [A->1, B->4, C->2]. Show how the depth-first search continues from here to the goal state.\nAC*B**** ---> AC*B*D** ---> AC*B*DE* ---> ACFB*DE* fail (no valid spot for G). | |-> AC*B**D* ---> AC*B*ED* ---> ACFB*ED* ---> ACFBGED* fail | |-> AC*B***D ---> AC*B*E*D ---> ACFB*E*D ---> ACFBGE*D ---> ACFBGEHD succeed.\nAnswer Depth: N. Branching factor: N. (The second vertex --- vertex B --- can go in every slot except 1 if there is an edge A-B and in every slot except 1, 2, and N if there is no edge A-B.) Obvious upper bound: NN. Slightly cleverer upper bound: The number of leaves is certainly no more than the number of permutations on N elements, which is N!.']"	['<urn:uuid:afd178fc-e563-42a6-b56f-ac529ce0d269>']	factoid	with-premise	verbose-and-natural	similar-to-document	single-doc	expert	2025-05-01T22:05:01.292488	30	60	824
126	natural sun vs medical light therapy comparison effects skin health	Medical phototherapy is a controlled, targeted treatment that uses specific wavelengths of UV light (311-312 nm for narrow-band UVB) to treat conditions like psoriasis, eczema, and vitiligo. It's customized for each patient and delivered only to affected areas to minimize damage to healthy cells. Treatment sessions are carefully monitored and scheduled, typically lasting just a few seconds initially. In contrast, natural sun exposure can be more dangerous if uncontrolled. Excessive sun exposure is a leading risk factor for skin cancer, with more than 3.5 million Americans diagnosed yearly. This includes different types like basal cell carcinoma (80% of cases), squamous cell carcinoma (20%), and the most dangerous form, melanoma, which causes over 75% of the 12,000 annual skin cancer deaths in the U.S.	"[""Phototherapy uses UVA or UVB light, depending on each patient's individual condition, to slow the growth of new skin cells. This minimally invasive treatment is customized for each patient and delivered solely to the targeted area to reduce damage to surrounding healthy cells.\nThis procedure is performed quickly and conveniently in your doctor's office, taking just a few seconds to treat unwanted conditions such as psoriasis, eczema and vitiligo and return skin to its original state. Localized areas of skin can be treated specifically to improve its appearance through a series of treatment sessions. Your doctor will decide whether or not this treatment is right for you after a thorough evaluation of your condition.\nNarrow-band UVB phototherapy involves shining ultraviolet light on the skin to treat psoriasis and other chronic skin conditions. It is an easier and safer alternative to PUVA treatment (psoralen plus UVA phototherapy). As its name suggests, the light that is used in narrow-band UVB phototherapy is a very specific range of wavelengths in the ultraviolet spectrum - just 311 to 312 nm - that has been shown to most effectively slow the rapid growth of cells and improve the symptoms of psoriasis.\nPatients generally receive narrow-band UVB phototherapy treatments three times per week for about 10 weeks. Exposure time begins at a few seconds and increases with each session. Session lengths are tailored to the patient's skin type and tolerance. After the skin has cleared, UVB phototherapy may be continued to prolong remission time, or patients may undergo other skin disorder treatments to minimize their exposure to ultraviolet light.\nFor psoriasis, phototherapy is an effective treatment for patients who do not respond to topical medications alone. Psoriasis causes red or white patches of dead skin cells by rapidly creating new cells. Phototherapy exposes the affected skin to ultraviolet light that slows the growth of new skin cells. This may be done using UVA or UVB light, depending on each individual case. UVB light is often more effective for treating psoriasis, while UVA light is able to penetrate deeper for more severe cases.\nPhototherapy is usually administered to psoriasis patients twice a week for four to five weeks. Results are often visible within two weeks and will continue to improve as treatment continues. Most patients see effective relief from this minimally invasive, FDA-approved treatment.\nEczema is a term used to describe a group of inflamed skin conditions that result in chronic, relapsing and very itchy rashes. About 15 million people in the United States suffer from some form of eczema. There is no known cause for the condition, but it appears to involve an overactive immune system in the presence of certain materials and often occurs in people susceptible to allergies.\nPhototherapy is effective in treating symptoms of eczema by exposing the skin to controlled amounts of natural or artificial UVA or UVB light. This procedure is often performed in conjunction with medication to provide the longest-lasting relief from eczema symptoms.\nVitiligo is a common skin condition in which pigment cells are destroyed and white patches of skin appear on different parts of the body. Hair growing in these areas may turn white as well. Vitiligo can affect any area of the skin, but is most common on the face, lips, hands, arms, legs and genital areas.\nThe most common treatment for vitiligo is PUVA therapy, which combines ultraviolet A light treatment with a medication called psoralen. Psoralen increases the skin's sensitivity to the ultraviolet light to enable more absorption. The medication should be taken approximately one-and-a-half to two hours before each phototherapy session.\nPhototherapy is a widely used, highly effective form of treatment for a number of types of skin conditions. However, phototherapy has been linked to several potential complications, including premature aging of the skin and an increased risk of skin cancer. It is essential that anyone undergoing phototherapy receive regular full-body examinations for indications of skin damage or cancer."", 'Summer Sun Increases Skin Cancer Risk\nAuthor: Daniel Kellman, ND\nFor most people, summer weather means enjoying the outdoors, doing yard work or vacationing at the beach. But the summer sun can damage your skin. In fact, exposure to the sun’s ultraviolet (UV) rays is a leading risk factor for skin cancer – and more than 3.5 million Americans are diagnosed with it every year.\nSkin cancer is a broad term that refers to any cancer that begins in skin cells. Basal cell carcinoma, which tends to occur in areas that receive the most sunlight (head, neck, hands, etc.), is the most common form of skin cancer and accounts for about 80 percent of cases. Squamous cell carcinoma, which accounts for about 20 percent of skin cancers, is also common in areas with high sun exposure. Melanoma is the most dangerous type of skin cancer. Although it accounts for only about five percent of skin cancers cases, it’s the cause of more than 75 percent of the 12,000 annual skin cancer deaths in the U.S.\nMost skin cancers are slow to spread and are treatable, if not curable, when caught early. But because skin cancer also can be deadly, it is important to understand the risk factors and how to reduce your risk.\nUV exposure: The primary risk factor for skin cancer is exposure to ultraviolet (UV) light, including sunlight, sunlamps and tanning beds. The greater exposure, the greater the risk. Skin cancer is more common where the sun is strong, such as in the South. People who have had at least one severe (blistering) sunburn, frequent sunburns as a child, or used sunlamps or tanning beds before age 30, are also at increased risk.\nFair Skin: Caucasians have a greater risk of developing skin cancer than non-whites. The risk is also higher in individuals with blonde or red hair, blue or green eyes, or skin that burns or freckles easily.\nOlder Age: Skin cancer risks increase as you age, likely due to accumulated exposure to UV radiation.\nFamily or Personal History: Individuals with a first-degree relative (parent or sibling) or who have previously been diagnosed with skin cancer are at increased risk.\nAlthough skin cancer is usually highly treatable, prevention is best. No matter your age or previous sun exposure, decreasing your exposure to UV light (direct sunlight and tanning beds) is the most important thing you can do to reduce your risk of developing skin cancer. When you do go out in the sun, wear protective clothing, hats, sunglasses and sunscreen.\nWhen choosing a sunscreen, the higher the spf (sun protection factor), the stronger the protection. But don’t let a high spf lull you into thinking you’re safe. It is important to reapply sunscreen frequently. This is especially true for children, since childhood sun exposure can be a significant risk factor for developing skin cancer later in life.\nAlso remember that spf refers only to protection against UVB radiation, which burns the skin, and not to UVA radiation that penetrates deep into the skin, accelerates skin aging and may cause skin cancer. Some sunscreens protect against both, so be sure to check labels. In addition, sunscreens from KINeSYS, Soleo, Green Beaver and Badger offer organic formulations with no added chemicals that can also sometimes damage skin.\nFinally, regular, thorough skin examinations are important, especially if you have a large number of moles or other risk factors. While this will not prevent skin cancer from developing, exams can help catch it early. Always tell your doctor if you see any new, unusual or changing moles or growths on your skin.\nIt’s virtually impossible to go through life with no sun exposure, so we all have some level of risk for skin cancer. But by being aware and taking steps to protect yourself from the sun, you can help keep your skin healthy and reduce your risk.\nFor more information about skin cancer risks, signs, symptoms and treatments, visit the Cancer Treatment Centers of America website at: http://www.cancercenter.com/skin-cancer.cfm.\nDaniel Kellman, ND, FABNO, is clinical director of naturopathic medicine with\nCancer Treatment Centers of America at Southeastern Regional Medical Center in']"	['<urn:uuid:72d1a4f1-e0eb-47e7-af48-4cd239b76708>', '<urn:uuid:f46e0d0c-be6f-4432-b255-804bde7b5bbb>']	open-ended	with-premise	long-search-query	distant-from-document	multi-aspect	novice	2025-05-01T22:05:01.292488	10	123	1345
127	What role did Gillette razors play in WWI soldier safety and Victorian grooming?	While Victorian men maintained elaborate facial hair styles like mutton chops and side-whiskers, Gillette's safety razor became crucial during WWI because soldiers needed to be clean-shaven for gas masks to seal properly against their faces. The razor was so important for survival that when American soldier Lowell Hollingshead was captured, German guards all wanted his Gillette razor, as it could mean the difference between life and death.	['Victorian hairstyles for men came in a wide variety, ranging from classical to distinctly modern. In this article, we’ll explore side-whiskers, sideburns, and mustache styles. The Victorians’ love for facial hair also inspired Gibson girl hairstyles. These hairstyles resembled those of the Roman Emperor, Titus. However, they were not as common as the Gibson girl look.\nVictorian Men’s Sideburns\nDespite the Victorians’ penchant for short hair on the top and back, they also sported sideburns, sometimes very long, and often paired with facial hair. Often reminiscent of Ambrose Burnside’s mutton chops, Victorian men’s sideburns were elaborate extensions of the gentleman’s overall hairstyle. But, sideburns were out of favor by the turn of the 20th century.\nDuring the Victorian era, men’s hairstyles began to change. They wore their hair short and parted on the side, and sometimes combed it up away from their face. Victorians were more likely to wear a mustache than a sideburn. But, men were also more likely to sport a long beard, if it was allowed by their employers. The Victorians’ sideburns are a wonderful example of how men’s hairstyles changed over time.\nThe late Victorian period marked a period of great change in facial hair fashion. Men took their cues from classical art, which encouraged natural looks with few artificial products. The era’s most famous example is Beau Brummel, who had a short sideburn and a clean shaved face. The famous beautician had him check his face every morning in a dentist mirror, and plucked any stray hairs with a tweezer. Regency men wore either short or long sideburns, and rarely wore mustaches.\nDespite the emergence of men’s sideburns in the late 19th century, Victorian men maintained a hirsute appearance. The aesthetes, on the other hand, considered a clean-shaved face as more aesthetic. As a result, Victorian men developed a variety of side-whiskers known as Piccadilly weepers and Dundrearys. Despite the fact that men were more often male than female, this style of hair could be combined with a mustache and a fringed beard.\nVictorian Men’s Mustache\nA Victorian men’s mustache was not uncommon in the 1800s, but its style was unique. Victorian men were known to have beards and thin mustaches. Women, on the other hand, preferred men with beards. Victorians also favored the unshaven look. Here’s a look at the history of the Victorian men’s mustache. Let’s find out what a Victorian man wore under his beard.\nA Victorian man’s appearance became an increasingly important part of his persona. A tamed mustache was an important symbol of manhood. It affirmed manhood and asserted self-control. However, men didn’t want to over-groom or risk indecency. A properly groomed mustache merged the two. A Victorian men’s mustache was both clean-shaven and full-bearded.\nA Victorian gentleman’s mustache was often adorned with a small earring. It was most flattering to a young man’s vanity, making him appear older. Even a twenty-year-old who wears a mustache will seem much older than he actually is. Victorians were also very social, and the mustache was the norm for men in society. Menservants were required to shave, but officers and subalterns wore mustaches adorned with different regiments.\nVictorian Men’s Side-Whiskers\nVictorian men began wearing side-whiskers during the nineteenth century when they were considered more masculine. In addition to being a fashionable fashion accessory, side-whiskers could also be combed and worn with a mustache. Victorian men wore a variety of mustaches, some long and straight, while others were curled. In the early to mid-twentieth century, men also wore full beards, which were bushy and often trimmed in a variety of ways.\nDuring the late 1860s and 1870s, most men presented a hirsute appearance. The aesthetes thought that a clean-shaven face gave a fastidious appearance, so sideburns were allowed to develop into various types of side-whiskers, including bushy mutton-chop’ whiskers and long and combed-out whiskers. Side-whiskers were also known as Piccadilly weepers or Dundrearys, after the Lord Dundreary from Tom Taylor’s play.\nThe earliest stage of Victorian men’s side-whiskers arose around the turn of the nineteenth century, and canny traders peddled fake whiskers. Meanwhile, women often trained their locks down their faces and tied them under their chins. Then, in the 1840s, men began growing mustaches, a common fashion accessory for soldiers in the British army. And as the decade wore on, men began to grow side-whiskers in order to resemble British cavalry soldiers.\nVictorian Men’s Mutton Chops\nVictorian men’s mutton chops can be both thick and bushy or clipped to a neat edge by the jaw. They can also be eccentrically eccentric, with long, thick tendrils flowing midway down the chest. Alternatively, they can be short and separate from the mustache, adding a dashing look to the older gentleman’s otherwise weathered features. Victorian mutton chops are also popular among rock musicians, who are known to have been inspired by the style.\nThe Victorian era saw a resurgence of facial hair, including mutton chops. These men’s sideburns, which were typically long and thick, had become more pronounced than they are today. The sideburns were sometimes called “side whiskers” because they hung down below the jawline. Victorian men’s sideburns eventually fell out of style in the early twentieth century, but not until World War I. World War I brought with it a requirement that men be clean-shaven in order to wear a gas mask. However, this rule did not apply to mustaches.\nVictorian Men’s Sideburns With Chin Strip Shaved Off\nDespite the popularity of the Victorian era’s chin strip piercing, men shaved off their chins without shaving their sideburns. This style of shaved facial hair has its roots in military style. Muskets shoot large amounts of gunpowder, leaving behind embers in the pan. Because the sideburns protected the face from these fires, they were used to prevent burns. Throughout the Victorian era, men maintained very long, thick beards, while others chose to shave them off.\nAfter the Victorian era, men began to reduce their facial hair. The elites often shaved their faces at least three times per week, while working-class men may only have shaved their faces a few times a year. However, a new trend began to emerge during the early nineteenth century. This style of facial hair, also known as a side-whisker, lasted for two decades. Eventually, the bushy outcrops became a popular style. Sometimes, they were ridiculed by the press but often admired by admirers.\nBeards became popular during the Victorian era. Many soldiers fought in the Civil War, and many did not shave their beards. However, a government committee recommended that men expose themselves to dust grow beards to improve their health. The era was also marked by gender identity issues. Victorians wanted to show their independence, and a beard was a symbol of manliness.\nWhat Are The Victorian Hairstyles Names?\nDuring the Victorian era, hairstyles were very different from those of today. For example, Victorian women did not typically wear their hair loosely. But they did occasionally wear it in waves or with flowers.', 'The Art of Shaving\nBrad Larson, Director\n“The first thing each new [guard] would do was go through my pockets ... The one thing that interested all ... was my Gillette razor and they all wanted it. Two offered to buy it and another to trade his straight razor for it, but ... I declined.”\nIn October 1918, an eighteen-year-old American private named Lowell Hollingshead was fighting with the 77th Division in France’s Argonne Forest. Hollingshead was the only survivor in a skirmish. Wounded in the leg, he was captured and taken for interrogation. German guards searched his pockets and all wanted his Gillette razor, but Hollingshead would not give it up. Why was his razor so coveted?\nMen did not shave much before the 18th century. Facial hair was kept in check with a sharp knife, but a truly smooth face was rare. The straight or “cutthroat” razor, invented in Sheffield, England, in the late 1600s, changed that. The blade was thin and able to hold an exceedingly sharp edge. The straight razor was very expensive, as were mirrors, so shaving was limited to the wealthy. A smooth shaven face became the mark of a man of means.\nStraight razors and mirrors became more affordable in the 1840s due to the Industrial Revolution. Still, most men had facial hair because it was fashionable, and because not everyone had the skill to use or correctly sharpen the cutthroat razor. Shaving was unpleasant, especially around the throat. When someone wanted a shave, they went to a barber.\nIn the late 1890s, a traveling salesman by the name of King C. Gillette invented his “safety” razor, and it went on the market in 1901. Gillette knew the real money was in the replacement blades and not the shaver. When the nation went to war in 1917, he sold 4.8 million razor sets to the government at cost.\nWorld War I ushered in the use of various types of poison gas and all warring nations used it. A soldier’s protection was a mask, and it had to fit tightly against the facial skin to be effective. Facial hair prevented a tight seal and gas would leak in, so that meant that a soldier had to shave every day — even if that meant a painful dry shave. As a result, Private Hollingshead’s coveted Gillette razor might be the difference between life and death.\nWhen the war ended, the smooth-shaven man was the model. A popular saying about 1920 was that a clean face was the mark of a clean-minded man. Facial hair was out of style and viewed as crude, the characteristic of a revolutionary. Facial hair regained popularity in the 1960s. Today the unshaven look is popular, especially with younger men.\nThe post-World War I shaving craze was not just for men. Not every woman in the 1920s wore the iconic flapper dress, but women’s fashion moved to shorter hem lines, low necklines, and bare backs. Swim suits became smaller, too. Those changes put more of the female body on view. It was unseemly for women to have hair in the wrong places, so it had to be removed. (This wasn’t a serious concern when Victorian and Edwardian fashion covered legs and arms.) Hair removal for women was not referred to as shaving, but instead it was called “smoothing.”\nAmericans were quick to capitalize on the popularity of smooth skin and women also used the Gillette razor, as well as depilatory creams and hot wax. In 1921, a U.S. Army Colonel named Jacob Schick invented a new type of safety razor that had replacement blades stored in the handle that were fed into shaving position. The Schick design eliminated the danger of handling the razor blade, promoted as especially appropriate for women. Alternatively, women could use a product called “Baby Touch Hair Remover,” which was actually just a piece of very fine-grit sandpaper used to abrade unwanted hair.\nToday, there is a movement among some women to reject “smoothing” in favor of the natural look. Among men, the use of the straight razor is making a comeback. In the 2012 movie Skyfall, spy James Bond shaved with a straight razor. That scene set off a craze for straight razors that has yet to peak, and the German firm of DOVO barely keeps up with demand for a razor designed over 300 years ago.\n- A customer gets a shave in this c1915 photo of John H. Schmitt’s Main Street barber shop. OPM #P2000.42.86\n- Straight razor, was used by William A. Weisgerber, who operated a barbershop on the corner of Wisconsin Avenue and Hancock Street. It has been sharpened so often that the steel has been worn away. OPM #\n- Grouping of safety razors. OPM #\n McCollum, L.C. History and Rhymes of the Lost Battalion. Columbus, Ohio: L.C. McCollum Co., 1929, 74.\n Mirrors, typically called a “glass,” were made widely affordable after 1835. In that year, a German chemist named Justun von Liebig invented a way to make a low cost mirror by using metallic silver on glass.\n Creams dissolve hair, and wax pulls hair out.']	['<urn:uuid:f3e5c633-0783-49b2-b62d-bc36c7c1e293>', '<urn:uuid:5c231e7a-a38c-4401-9df9-18d9a5ca77ba>']	factoid	with-premise	concise-and-natural	similar-to-document	multi-aspect	expert	2025-05-01T22:05:01.292488	13	67	2018
128	nft digital art market impact benefits artists blockchain transparency what risks theft piracy	While NFTs were meant to help unrepresented artists sell their work through blockchain's transparent tracking system, they have created significant problems. On the benefit side, blockchain lets artists monitor who buys their work, control access by certifying original digital images, and track resales. However, theft and piracy have become huge issues, with many smaller artists finding their work being used and sold without consent in NFT marketplaces dominated by cryptocurrency subcultures.	['From the outside, there has been a series of uninterrupted revolutions in the art world over the past few years.\nSince they found widespread notoriety early last year, non-fungible tokens (NFTs) have commanded tens of millions of dollars in price tags for digital works of art. But critics have described them as rubbish of no value at all, meaningless to art patrons, and the artists themselves have complained about the theft of their work, “casting” without their knowledge.\nMeanwhile, the web3-based metaverse is being touted as the new home for this art — a digital environment Facebook has invested billions of dollars in, even if its own employees aren’t adopting it.\nMore recently, AI art (which can create art based on text prompts or simple unfinished sketches) has been promoted as a way to “democratize” art, allowing those without the technical skills to create their own illustrations cheaply and quickly—although only in these The system has been trained on billions of existing examples of art, often without the consent or payment of the original creators.\nSo what was given? Why has the art world been hit again and again over the past year with changes advertised as benefiting artists but seemingly upending how art is made and consumed? Why do innovations in the tech world that are supposed to affect the way society as a whole work seem to explode and spark controversy, especially in the arts?\n“These technologies are showing themselves, looking for ways to get the art world talking,” explained Rob Horning, a technology writer and founding editor of Real Life magazine, noting the rise of NFTs in particular.\nAn NFT is a creation that runs primarily from the Ethereum blockchain — effectively a system for publicly recording and tracking online transactions. The main purpose of the system is to enable the Ethereum cryptocurrency (using “fungible” (exchangeable) tokens, meaning they can be traded with each other as functionally identical items).\nBy contrast, the “irreplaceable” nature of an NFT means that it is unique – no two are interchangeable. This means they can be linked to digital artworks (which themselves are rarely stored on the blockchain) to give them authenticity.\nEssentially, this means that the valuable part of NFTs in the visual arts world is the perception of value. While the digital art to which it is associated can be copied an unlimited number of times, only one person can say they own the “authentic” copy.\nHorning said the technology had little clear purpose until it created a marketplace for itself to sell digital art.\nStep Back, Criticism of Art World Technology\nWhile the initially stated goal was to enable unrepresented artists to sell their work, NFTs have proven to be more divided among artists.\nalthough theft and Piracy Having proven to be a huge problem in the space, opposition to NFTs has become evident from the very group they were supposed to help in the first place: smaller artists who, instead of finding new avenues to sell their work, find themselves mingled with technology and cryptocurrencies Subcultures use and sell their work without the artist’s consent.\nBut Horning said that despite the resistance, the technology continues to roll out and roll out, as NFTs and cryptocurrencies remain “as important as the buzz surrounding them.”\n“People who invest in cryptocurrencies have been under pressure to get cryptocurrencies in the news, to get people talking about cryptocurrencies,” he said. “One of the ways you can do that is to get artists to talk about crypto, or have artists make things that are related to crypto or crypto. NFT related stuff.”\nThe bumpy intersection of the art and tech worlds is now colliding with the art of artificial intelligence, though not unfamiliar. With machine learning models like DALL-E, Stable Diffusion, and Midjourney, anyone with an internet connection can enter a few prompts and generate any image they want.\nAs with NFTs, some artists have fought back. Artists like Simon Stålenhag – their sci-fi scenes inspired the Amazon Prime collection cycle story — and web cartoonist Sarah Andersen Complained that the systems were trained on publicly available art, including their own work. This enables users to request images be generated in the style of living artists, mimicking their work — and potentially taking business away from them.\nThe AI art generator “is not in the hands of the artist right now. It’s in the hands of the early adopters of technology,” Stålenhag told Business Insider in a recent interview.\nBlair Attard-Frost is a PhD student at the University of Toronto who studies the impact of AI and ethical ways of implementing AI in industry. These artists, they say, belong to the “labor displacement” camp, whose workflows have been radically changed by the implementation of artificial intelligence. Like Stålenhag, Attard-Frost said they were concerned about how the creation of AI art could be constructed from the creations of these artists with little or no pay.\nBut these problems arise in many industries implementing AI. The reason it’s more visible in the art world is because of the centrality of art to people’s everyday lives.\n“One of the reasons this ‘AI artist’ thing is getting so much attention is because it’s more common, right?” Attard-Frost said. “It affects everyone, it unlocks all kinds of new capabilities for a lot of people … in a way those more specialized apps don’t do that.”\nThere are a number of reasons why these technological inventions have forged such strong ties with the art world and not elsewhere. That’s partly due to the industry’s shift toward focusing on the sale of art rather than its creation, said Robert Enright, senior contributing editor at Border Crossing Magazine in Manitoba and professor of art theory and critical studies at the University of Guelph. “\n“One thing that has happened — I think that explains why NFTs and why there is this search for new things to sell — I think in many ways, art marketing has become a very, very important part of this process,” Enright said.\n“Because there is so much money in the world right now, and because the rich have to find something to do with their money, one of the things they do is pay dearly for art.”\nAt the same time, as Attard-Frost explains, sooner or later these technologies will appear in all areas of life. They are only taking the first steps in the art world, and regulation around many of these technologies is still in its infancy, and they compare it to the “Wild West.”\nBut American artist Sara Ludy’s work often makes use of new technology, which she says is just emblematic of the field. The nature of art is experimental, and it always draws artists to new mediums and techniques that are not yet widely understood.\nWhile this can make it difficult for artists to keep up with the changing demands of the tools they need to master — and lead to potentially predatory commercial practices that see opportunity for those outside the art world — art and technology will always find themselves intertwined, she said. Say.\n“Artists are driven to expand our definition of the world and of self. Technology is here to expand our definition of self and connection and all of those things,” Ludy said. “So … our motivations are very similar.”', 'Blockchain, Cryptocurrency, and the Art Market\nWhat about the Artist?\nBlockchain and the Art Market\nBlockchain has great potential to increase transparency in the provenance and pricing of artwork. In 2014, the Fine Arts Expert Institute (Geneva) estimated that over fifty percent of the artworks it examined were either forged or misattributed. Navigating the art market is difficult even for experts due to several factors: 1) the lack of transparency; 2) intricate and old-fashioned insider networks; 3) information asymmetries between buyers and sellers; 4) the speed and volatility of trading; 5) the desire among some major purchasers to hide art assets from taxation; and 6) the emotional and status factors that often distort prices and reputations within the art world.\nBlockchain is also a tool to ensure digital scarcity. Because it is so easy to reproduce images taken from online sites, intellectual property rights and copyright are extremely difficult to regulate in digital art. Yet an artist who chooses to sell digital work on the blockchain can monitor who has bought the work, control access to it (by certifying each image as an original) and be alerted to resales that may have implications for royalties and professional reputation.\nBlockchain (and cryptocurrency) for beginners\nBlockchain is a distributed peer-to-peer electronic ledger. A transaction (“block”) can only be performed by authenticated members of that specific blockchain, who each hold an encrypted key that can unlock and verify transactions. Blockchain enthusiasts emphasize that the system is extremely secure and decentralized and that it reduces friction in the market by cutting out middlemen and their associated fees. As each block is added to the ledger, the system produces what proponents refer to as an indelible and transparent record. According to Wealth Management, “transaction information isn’t stored on server, but rather is embedded in digital code that’s dispersed throughout shared databases and protected from tampering, revision or deletion.” Each previous block, once completed and certified by the network, is unchangeable.\nCryptocurrencies such as BitCoin are to date the most publicized example of a service that can be hosted via the blockchain and they also have extraordinary implications for the buying and selling of art. The emblematic entry-level product is CryptoKitties (https://www.cryptokitties.co/), an online game that lets you purchase, collect, and trade electronic cats. The website promises that each cryptokitty is “one-of-a-kind and 100% owned by you; it cannot be replicated, taken away, or destroyed.” Participating in the game requires a player to open a cryptocurrency account and to become familiar with the notions of electronic ownership and brokerage.\nDigital technologies and the art market\nBoth blockchain and cryptocurrency dovetail seamlessly with the ongoing financialization of every corner of the art market. Evan Beard, National Art Services Executive at US Trust (a wealth management unit of Bank of America), notes that “much of today’s most dynamic wealth creation comes from hedge funds, private equity and real estate. None of our clients are buying art for investment. But they’re savvy with credit, and art is a capital asset.” A few of Beard’s top-end clients play the art market by guaranteeing works at the major auction houses. These savvy investors assume the risk of either ending up with the artwork should it not meet its reserve price or taking a percentage of the overage if the auction nets a higher than estimated price for the work.\nIn June 2018, the company Maecenas put the weight of the art establishment behind an experiment with fractionalized digital ownership in what it billed as the world’s first blockchain art sale. In cooperation with Dadiani Fine Art, Maecenas set up a digital auction of forty-nine percent of Andy Warhol’s “14 Small Electric Chairs Reversal Series” (estimated value of $5.6 million USD in 2019). Not only did Maecenas accept payment in cryptocurrencies such as Bitcoin and Ethereum (as well as its own cryptocurrency, ART), it allowed buyers to purchase digital certificates representing fractional ownership of the piece. Just as binary code can reduce the complexity of information to an efficient and universal system of 0s and 1s, blockchain and cryptocurrency enable the virtual slicing of artworks such that owning ten, five, or even one percent of a painting is not only imaginable, but feasible.\nDemocratizing or financializing art?\nThe large-scale uptake of fractional ownership remains uncertain, but the idea makes perfect sense if the ultimate goal to reduce all barriers to the seamless flow of capital, labor, and digitalized intellectual property. Imagine owning, say, 4.62 percent of an Andy Warhol Marilyn or Elvis, or another of those mid-1960s masterpieces that now routinely command millions of dollars at auction. You could show your digital certificate to neighbors and friends, and maybe even display a framed print-out of your digital square of the piece.\nFor some of us, this is the long-sought democratization of the art market, as fractional ownership enables people outside the tiny billionaire art establishment to own at least a part of iconic masterpieces. For others, the notion that anyone could feel meaningfully attached to a fractional piece of art is absurd. Instead, what is really happening –underneath the rhetoric of “democratizing art” — is entry into the art market, and for this access one must, of course, pay. It is also a means to bring new capital from previously excluded clients into the mix and to spread the risk around a much larger cohort of players. These are propositions altogether different from ensuring that diverse people from different economic and social classes have an equitable opportunity to experience and live with high-end art in their daily lives.\nOne can also imagine a worst-case scenario akin to the Great Recession of 2008, which began with the fractionalization and re-packaging of mortgage-backed securities. The scale of such a crisis would likely never match the housing crash. However, the financial incentive to create ever more esoteric, high-risk but high-fee fractionalized art securities could ironically undermine the chain of provenance, ownership, and trust. Just as, in the end, almost no one knew who owned what mortgage liability at what interest rate, one can envision thousands of fractionalized pieces of an Andy Warhol floating in the ether like those silver balloons he released in 1966. For this and multiple other reasons, including equity and access, good old-fashioned museums and galleries remain essential in our post-materialist era.\n Botz, Anneli, 2018. Is Blockchain the Future of Art? Four Experts Weigh In. Art Basel. Available at: https://www.artbasel.com/news/blockchain-artworld-cryptocurrency-cryptokitties\n Rottermund, Amanda, 2019. The Newest Technological Trend in the Art Market. Wealth Management, 10 April.\n Reyburn, Scott, 2018. Art is Becoming a Financial Product, and Blockchain is Making It Happen.” The New York Times, 8 June. Available at: https://www.nytimes.com/2018/06/08/arts/art-financialization-blockchain.html']	['<urn:uuid:decbfe6d-d109-4bfb-953b-d357ac9603db>', '<urn:uuid:edc5b33e-a3de-425c-9167-4d8ebde1d634>']	factoid	direct	long-search-query	similar-to-document	multi-aspect	expert	2025-05-01T22:05:01.292488	13	71	2331
132	tsunami monitoring gps benefits developing countries impact	GPS-based tsunami monitoring systems can provide accurate warnings within 3 minutes of an earthquake, offering detailed information about wave heights and coastal impact. This is particularly crucial for developing countries, which suffer more than 95% of all disaster-related deaths and face economic losses 20 times greater than industrialized nations relative to their GDP.	['Researchers have shown that, by using global positioning systems (GPS) to measure ground deformation caused by a large underwater earthquake, they can provide accurate warning of the resulting tsunami in just a few minutes after the earthquake onset.\nFor the devastating Japan 2011 event, the team reveals that the analysis of the GPS data and issue of a detailed tsunami alert would have taken no more than three minutes.The results are published on 17 May in Natural Hazards and Earth System Sciences, an open access journal of the European Geosciences Union (EGU).\nMost tsunamis, including those in offshore Sumatra, Indonesia in 2004 and Japan in 2011, occur following underwater ground motion in subduction zones, locations where a tectonic plate slips under another causing a large earthquake. To a lesser extent, the resulting uplift of the sea floor also affects coastal regions. There, researchers can measure the small ground deformation along the coast with GPS and use this to determine tsunami information.\n“High-precision real-time processing and inversion of these data enable reconstruction of the earthquake source, described as slip at the subduction interface. This can be used to calculate the uplift of the sea floor, which in turn is used as initial condition for a tsunami model to predict arrival times and maximum wave heights at the coast,” says lead-author Andreas Hoechner from the German Research Centre for Geosciences (GFZ).\nIn the new Natural Hazards and Earth System Sciences paper, the researchers use the Japan 2011 tsunami, which hit the country’s northeast coast in less than half an hour and caused significant damage, as a case study. They show that their method could have provided detailed tsunami alert as soon as three minutes after the beginning of the earthquake that generated it.\n“Japan has a very dense network of GPS stations, but these were not being used for tsunami early warning as of 2011. Certainly this is going to change soon,” states Hoechner.\nThe scientists used raw data from the Japanese GPS Earth Observation Network (GEONET) recorded a day before to a day after the 2011 earthquake. To shorten the time needed to provide a tsunami alert, they only used data from 50 GPS stations on the northeast coast of Japan, out of about 1200 GEONET stations available in the country.\nAt present, tsunami warning is based on seismological methods. However, within the time limit of 5 to 10 minutes, these traditional techniques tend to underestimate the earthquake magnitude of large events. Furthermore, they provide only limited information on the geometry of the tsunami source (see note). Both factors can lead to underprediction of wave heights and tsunami coastal impact. Hoechner and his team say their method does not suffer from the same problems and can provide fast, detailed and accurate tsunami alerts.\nThe next step is to see how the GPS solution works in practice in Japan or other areas prone to devastating tsunamis. As part of the GFZ-lead German Indonesian Tsunami Early Warning System project, several GPS stations were installed in Indonesia after the 2004 earthquake and tsunami near Sumatra, and are already providing valuable information for the warning system.\n“The station density is not yet high enough for an independent tsunami early warning in Indonesia, since it is a requirement for this method that the stations be placed densely close to the area of possible earthquake sources, but more stations are being added,” says Hoechner.\nTraditional tsunami early warning methods use hypocentre (the point directly beneath the epicentre where the seismic fault begins to rupture) and magnitude only, meaning the source of the earthquake and tsunami is regarded as a point source. However, especially in the case of subduction earthquakes, it can have a large extension: in Japan in 2011 the connection between the tectonic plates broke on a length of about 400km and the Sumatra event in 2004 had a length of some 1500km. To get a good tsunami prediction, it is important to consider this extension and the spatial slip distribution.\nNote : The above story is reprinted from materials provided by European Geosciences Union.', 'WHY BE CONCERNED ABOUT HAZARDS?\nNatural and Technological disasters cause great human and economic losses: according to the Centre for Research on the Epidemiology of Disasters (CRED), for the sole year 2008, more than 235 000 people were killed, 214 million people were affected and economic costs were over 190 billion US$.\nThe developing countries suffer the greatest costs when a disaster hits: they suffer more than 95% of all deaths caused by disasters and the losses due to natural disasters are 20 times greater (as a percentage of Gross Domestic Product) in developing countries than in industrialized countries (according to the World Bank).\nDisasters are also a major issue for citizens of developed countries who can suffer them on their own territory (the 2009 earthquake of L’Aquila in Italy implied 308 deaths, 1500 injured and losses exceed US$16 billion) or can face it abroad due to their increased international mobility (both Sweden and Germany lost over 500 citizens each in the 2004 South East Asia tsunami).\nWHAT CAN WE DO?\nWe cannot prevent many of the disasters (especially those natural) but there are certain ways to minimize the risk of disaster, in particular by distributing to all countries the best international experience in Emergency Management.\nAs Emergency Management in all countries is based on State Management Systems (at local, regional and national levels) but relies on accurate Public awareness and knowledge on hazards, risks and prevention measures, it is thus essential to increase awareness of people on :\nwhat types of disaster risk exist in specific areas,\nwhat is the nature of that risk,\nwhen it could happen,\nhow can their consequences be minimized\nThis information has to be open to the general public directly, also via teachers, medical doctors, local authority representatives, Civil Protection services or others.\nWHO ARE WE?\nOur desire to present common material based on sound international experience requires a pre-existing international network of expertise in the field of major natural and technological hazards and related disasters.\nSince 1987, the European and Mediterranean Major Hazards Agreement (EUR-OPA) is a platform within the Council of Europe for co-operation in that field between 27 countries of Europe and the South of the Mediterranean.\nOne of its main objectives is to reinforce and to promote co-operation to ensure better prevention, protection against hazards, risks and better preparation in the event of major disasters.\nApart from its political content, the Agreement has an effective network of Centres spread over its 26 member states: the material presented in our website stems from the respective expertise in the different fields of major disasters management of those Centres.\nThe coordination of the Initiative on website development and its day-by-day operation is carried out by Cyprus Civil Defence.\nTHE GOALS OF THE INITIATIVE\nWhile State Emergency Management Systems have to deal with different contexts (legal basis, capability, recourses, procedures, etc.) in each country, the behaviour of the individual, who is crucial for their survival, can mostly make abstraction of that context.\nThe Besafenet Initiative focuses thus on that aspect and wishes to achieve three main goals:\nPromote a culture of safety among a new generation of people\nRaising awareness on implications of their actions and their way of thinking on emergency\nReplacing fear with a culture of preparedness\nDisseminate knowledge to multilingual societies\nCreate a common knowledge base of best experience\nDisseminate it in several languages to benefit a wider audience\nBecome an interactive tool\nOpen our website to other users and organisations for their benefit and comments\nEnrich its content by contributions based on external experiences\nWHAT IS OUR SPECIFICITY?\nMany sources of information, especially in most widespread languages, exist nowadays on the Internet on hazards description and emergency measures. However, no common material is available in a variety of languages and that is the main specificity of the Initiative: provide unified information to the largest number of persons in their native language. By surfing through the website they will also have access to a lot of useful information and data, such as Case studies, Lessons learnt School curriculum and also photos and videos.\nBut the Initiative wishes to go beyond a simple electronic textbook: using games, cartoons, animations, groups of discussions, etc., we hope to provide a friendly and interactive environment in order to interest and introduce young people to hazards and risk prevention, awareness and action in such catastrophic events.\nIt will thus be a powerful tool offering an exchange of information and communication within countries that share a similar vulnerability to disasters, to lesser or greater extent. In addition, school children and generally young people will find a common ground to exchange views and ideas in their own language and get support either from each other or from experts.\nHOW CAN YOU CONTRIBUTE?\nThe particularity of the material presented in our website is to be oriented not only towards final users but also towards further diffusion through intermediaries.\nAs a citizen, you will have basic information on hazards and the basic actions to take both to prevent disasters and to face it when they happen.\nAs a teacher, you will have the capability to use additional information to spread knowledge on hazards and disasters among your pupils. In some countries, no clear-cut slot is left in current curricula to such training and more traditional such as geography or physics has to be used to introduce it.\nAs a student, the higher level material provided can be useful for your specific training in order to include disaster reduction issue. In future, you will be professionals taking decisions and consequently influencing (even modestly) the resilience of our societies to disasters.']	['<urn:uuid:716542f8-fbb4-4cc7-ac25-4a0a0fafdc74>', '<urn:uuid:1d51c9b6-be14-4913-beb5-68ea1166812b>']	factoid	with-premise	short-search-query	distant-from-document	multi-aspect	novice	2025-05-01T22:05:01.292488	7	53	1618
133	How do scientists study marine mammals in Monterey Bay?	Scientists study marine mammals in Monterey Bay through various field and laboratory approaches. They conduct necropsies of marine mammals and collect scientific data on live dolphins at facilities like Long Marine Laboratory. The bay's status as one of four major global upwelling regions makes it an ideal location for studying marine biodiversity. Researchers examine life history, physiology, and conservation of the diverse marine mammals including whales, dolphins, seals, sea lions and sea otters. This research has significantly improved our understanding of marine mammal behavior and migration patterns. Additionally, the sanctuary's protected status allows for continuous monitoring of these species in their natural habitat.	['Wonders of the Ocean: From Bioluminescence to Marine Mammals\nBurcak Artun, PhD\nUCSC Department of Microbiology and Environmental Toxicology\nShawn Noren, PhD\nUCSC Institute of Marine Science Department\nPreferences: Algebra 1\nSummary: Located in one of four major upwelling regions of the world, the Monterey Bay is a wealth of marine biodiversity. This cluster will give students an active-hands-on approach as we explore the local marine bacteria and charismatic megafauna (marine mammals) that call Monterey Bay “home”. Students will spend time in the laboratory to learn basic micro and molecular biology techniques, and apply them to analyze various bacteria found in the local water sources. Students will also go into the “field” to investigate the life history, physiology, and conversation of marine mammals (seals, sea lions, dolphins, whales, and sea otters) living just off our shores. This cluster will provide students with insights into how scientists study the diverse group of creatures that form our marine ecosystems.\nAll students in this cluster will be enrolled in the following courses:\nMarine Mammal Biology\nSimilar to humans and other terrestrial mammals, dolphins and seals must breathe air and maintain a stable core body temperature in order to survive. Yet living in the ocean creates a paradox: marine mammals must hold their breath to forage and their aquatic environment rapidly steals body heat. Over evolutionary time, marine mammals have acquired amazing physiological adaptations to endure these challenges. In this class we will explore the life history, physiology, and conservation of this fascinating group of mammals. Field trips with real scientists will bring us to Año Nuevo and Long Marine Laboratory to participate in a necropsy of a marine mammal and watch how scientific data is collected on live dolphins, and the Marine Mammal Center (a marine mammal hospital to rehabilitate sick and injured wild marine mammals).\nFrom Water Pollution to Bioluminescence: The Wonders of Bacterial Diversity Around Us\nWater pollution can cause harm to the ecosystem of the ocean around us by destroying marine organisms. The pollution of our beaches can also create a very undesirable environment for people, causing multitudes of health problems. In this course, students will learn about water pollution, and investigate the sources of bacterial contamination of our beaches and streams. Students will start by learning the basics of microbiology laboratory techniques. Then, samples will be collected from locations in and around Santa Cruz by looking at real-time data from water monitoring sites. Sources of this bacterial contamination will be identified by molecular techniques such as DNA extraction and PCR.\nIn a completely different project, students will investigate light-emitting bioluminescent bacteria that are found in the ocean in marine animals such as fish and squid. Luminescent bacteria will be isolated from squid, analyzed, and antibiotic resistance of the isolated bacterial species will be investigated. Students will have fun creating bioluminescent bacterial art in a petri dish.\nAt the end of the course, students will develop an appreciation for the natural water sources around us, and an awareness of bacterial diversity. They will possess a deeper understanding of how to critically analyze data, and make connections to real life examples.', 'Marine Mammals of Monterey Bay National Marine Sanctuary\nMonterey Bay National Marine Sanctuary. It is a whopping 6,094 square miles of protected, enchanting ocean off California’s coast that’s just ripe for research, tourism, and conservation. It’s called the “Serengeti of the Sea” — a thriving, marine melting pot featuring nearly 200 species of shorebirds and seabirds and over 500 species of fish, invertebrates, and algae. But the stars of this sanctuary are surely the marine mammals that pass through or reside in and near the sanctuary’s boundaries: at least thirty-six different species that include everything from whales to sea lions, porpoises to sea otters.\nWhales in the Monterey Bay National Marine Sanctuary\nLong fascinating humans with their complex social structures, incredible size, and even more impressive grace, whales have provided researchers with countless hours of scientific data. Without them, marine mammal behavior and migration patterns may have remained a mystery. But thanks to research like the kind conducted at Monterey Bay National Marine Sanctuary, other national marine sanctuary sites, and around the world, we have a much better understanding of these magnificent marine mammals and their mysterious ways of life.\nDolphins and Whales\nThere are at least eight different species of whales and dolphins that frequent the protected waters off the shores of California’s northern coast, including the humpback whale, the blue whale, and orcas (the largest species of dolphin). All magnificent, majestic creatures, whales play vital roles in balancing marine ecosystems. Whales help regulate and maintain a balanced food chain. They help prevent over-population by eating prey such as krill, and whale poop might even reduce harmful carbons in the Earth’s atmosphere by promoting the growth of phytoplankton at the ocean’s surface. Whale-watching is a popular activity among locals and tourists alike, and supports the local economy.\nSeals and Sea Lions in Monterey Bay\nSeals and sea lions in Monterey Bay are thriving in the sanctuary. Various species such as elephant seals, harbor seals, and California sea lions frequent the waters and shores of Monterey Bay, safeguarded from hunting as well as from commercial over-fishing and pollution. They’re a sought-after site for tourists who enjoy observing their sometimes laughable antics from a non-threatening distance. Some species, such as the elephant seal, come ashore annually to breed and to give birth to pups and can sometimes be observed playing out these familial roles, much to the delight of passers-by.\nA Protected Place for Sea Otters\nOnce threatened, sea otters have managed to make an amazing comeback, thanks to protected areas as Monterey Bay National Marine Sanctuary and policies at the local, state, and national levels. Diminished in number by a variety of factors in the wild — natural predators, hunting by humans, oil spills, and disappearing habitats — sea otters in Monterey can thrive and populations are able to recover. Unlike seals and sea lions, sea otters are no longer listed on the World Wildlife Federation’s Endangered Species Directory but they are protected under the Marine Mammal Protection Act of 1972.\nNot every species of marine mammal observed in Monterey Bay National Marine Sanctuary lives there year-round. Some pass through seasonally on their annual migrations, come ashore to rest or to reproduce or hunt in the lush kelp forests that provide food and protection from natural predators such as sharks and orcas.\nAnyone interested in observing these magnificent marine mammals in their natural habitat has a prime opportunity to do so at Monterey Bay National Marine Sanctuary, so long as they respect the rules of interaction. The Marine Mammal Protection Act provides good guidance for anyone interested in going whale-watching or observing seals. The Act protects all marine mammals in U.S. waters by preventing interactions with them except for permitted scientific research or rescue. This includes approaching them too closely or infringing upon the mammal’s habitats or disturbing their migration, breeding, birth, or shelter. Our partners at NOAA’s Office of National Marine Sanctuaries also provide marine wildlife viewing guidelines that promote responsible encounters with marine wildlife and their habitats in national marine sanctuaries.']	['<urn:uuid:693a705c-73a2-4f17-9dab-5c74c4e4a983>', '<urn:uuid:5cbbae57-0673-4c67-b876-019599bc74aa>']	open-ended	with-premise	concise-and-natural	similar-to-document	three-doc	expert	2025-05-01T22:05:01.292488	9	103	1193
134	How do heat pumps contribute to decarbonization and what installation considerations exist?	Heat pumps are viewed as a leading solution for decarbonizing heat, producing zero carbon emissions on-site. They are particularly effective when powered by renewable electricity. However, successful implementation requires expert design and installation, with careful consideration of factors like output temperature and ground temperature access. Installation barriers include lack of knowledge, perceived complexity, and uncertainty over building suitability. The government recognizes these challenges and is considering regulatory approaches, including requiring installers to provide information about low-carbon alternatives and ensuring suitable grid capacity through DNOs and GDNs.	"['A lot has changed since the 2008 Climate Change Act; legally binding carbon budgets have been met by rapidly decarbonising our electricity supply, largely due to significant amounts of PV and wind generation coming online alongside the closure of numerous coal fired generators. However, whilst we have made great progress on electricity, decarbonising heat is proving very difficult and as the fourth carbon budget (2032) sits on the horizon, attention is starting to focus on meeting this.\nTo meet the demands of the Climate Change Act, nearly all heat in buildings and industrial processes must be decarbonised by 2050. The Clean Growth Strategy (CGS) made it clear that action on decarbonising heat must take place in the 2020s. Partly thanks to the CGS, domestic energy efficiency is also making its way back onto the national agenda, with the imminent ‘boiler plus’, ‘MEES’ the building regulations review and extended ECO to name a few changes.\nStability and smooth transitions are needed\nAs one of a series of documents following on from the CGS, BEIS yesterday released a call for evidence on ‘A future framework for heat in buildings’.\nThe call indicates a positive, if small, first step towards action after the RHI closes in 2020 / 2021. Importantly for those in the industry, it includes an acknowledgement by government that regulation is needed to provide clear long-term stability to the industry and consumer post RHI. Aligning with existing policies, BEIS recognise that there must be a smooth transition when the RHI closes (2020/2021), with potential regulation to ensure this “through to the 2030s”. This will aim to reduce barriers whilst also reducing reliance on subsidy (“There may be a role for targeted subsidy…highly targeted in terms of technology it supported, technology it replaced, and the recipient of the subsidy”) and keeping the options open.\nThe graph below shows one of the inherent problems with policy to date, an incredibly spiky market, which is sure to compromise quality, ultimately reducing the real carbon reductions made. Avoiding this is key to long term success for all players in this sector.\nThe domestic RHI has to date been dominated by heat pump (54 per cent) and biomass (22 per cent) installations, predominantly in off-gas areas (76 per cent of installations).\nTechnologies considered under this call include biomass, bioliquids, biopropane, heat pumps, hybrid heat pumps, gas driven heat pumps, direct electrical heating (storage heaters) and rural heat networks. This signals a recognition that the ‘best’ solution is not yet clear and that other options need to be considered if significant levels of renewable heat are to be deployed.\nHeat pumps, predominantly air source, are broadly viewed as the leading solution for decarbonising heat. The idea of shared ground loop GSHPs is also raised on several occasions, recognising the need to address the cost barrier to this more efficient form of heat pump. BEIS is keen for information about hybrid heat pump solutions, their cost and effectiveness.\nBiomass will continue to have a role to play in rural off-gas properties that are larger and have limited options for building fabric improvement, but expect it to take a back seat.\nBioliquid and biopropane fuels were previously excluded from the RHI in order not to compete with transport where options for decarbonisation are limited. However, there is a recognition (much championed by OFTEC) that these might have a part to play post-RHI for those difficult to heat buildings that would not be suitable for alternatives such as heat pumps. These are likely to be largely viewed as transition options and there are checks and balances that must be in place to ensure sustainability.\nEven with the right technology, and some financial support as provided by the RHI, significant barriers to owner occupiers taking up renewable heat remain. This is important as ~17 million of the ~ 28 million homes in the UK are owner occupied.\nBEIS identifies the key barriers for this group as: not a priority, adverse to change, lack of knowledge, hassle of installation, perceived complexity, uncertainty over suitability of building, uncertainty over performance, short term occupation of building (not prepared to invest money for long term).\nFive near-term regulatory approaches to overcome these barriers are suggested as options:\n- Require installers to provide an equal level of information about low carbon alternatives when they quote for a boiler replacement\n- A scheme to enable low income and vulnerable households to take up low carbon heating, including building fabric upgrades if required. (Indicated as an arrangement following on from ECO).\n- DNOs and GDNs support take up of low carbon heating, by ensuring suitable grid capacity is available and new market solutions such as DSR and other flexibility can be easily accessed.\n- Companies producing or selling oil systems are also required to deliver low carbon heating, likely with targets set based on volume of sales\n- Oil suppliers are required to sell a certain amount of bioliquid, or renewable heating or pay into a fund that supports low carbon heating installs.\nThese questions hint at a number of interesting ideas much discussed of late. Are we going to see the ‘traditional’ heating installers pushed into renewables rather than being pulled in?\nCould we see the gas and electricity networks playing a more active part in decarbonising heat – perhaps simply by enabling flexibility markets or even installing efficiency or low carbon measures in homes to overcome grid constraints?\nWill we start to see heat being sold as a service, like broadband and TV subscription packages, with a third party owning and maintaining the heating equipment?\nCan whole house, performance guaranteed approaches such as Energiesprong be delivered at volume and into the able to pay market?\nIt will be interesting to see how industry responds to the forty four questions posed by this call for evidence, and how that shapes the next ten years of heat.', 'What is Ground Source Energy?\nThe ground – mother earth – acts as a very large store of heat energy. It can be used as a heat source in winter, or a heat sink in summer. The ground can be used to moderate the temperature in buildings standing on it.\nA ground source heat pump can be used to extract heat energy from the ground in winter and to transfer the heat into buildings. Equally it can be used to provide a very efficient mechanism for heat to escape from buildings down into the ground in summer.\nGround Source Heat Pumps\nA ground source heat pump provides a clean way to heat buildings, free of all carbon emissions on site. It can make use of solar energy stored in the ground to provide one of the most energy-efficient ways of heating buildings. Solar recharge of the ground is an integral part of ground source energy which is used to increase the efficiency of ground source heat pumps.\nGround source heat pumps are suitable for a wide variety of buildings and are particularly appropriate for low environmental impact projects.\nThey can be installed anywhere in the UK, using a borehole or shallow trenches or, less commonly, by extracting heat from a pond, a lake or the sea. Heat collecting pipes in a closed loop, containing water (with a little antifreeze) are used to extract this stored energy, which can then be used to provide space heating and domestic hot water.\nHeat pumps can also be reversed in summer to provide cooling.\nThe only energy used by a ground source heat pump is electricity to power the compressor and the circulation pumps which transfer heat energy from the ground into the building. A well designed ground source heat pump installation will deliver three or four times as much thermal energy (heat) as is used in electrical energy to drive the system. For a particularly environmental solution, green electricity can be purchased.\nGround source heat pumps have been widely used in North America, Sweden, Germany and Switzerland for many years. Typically they cost more to install than conventional heating systems. However, they have very low maintenance costs and can be expected to provide safe, reliable and emission-free heating for well over over 20 years.\nGround source heat pumps work best with heating systems which are optimised to run at a lower water delivery temperature than is commonly used in radiator systems. As such, they make an ideal partner for underfloor heating systems.\nThe Advantages of Ground Source Heat Pumps\nGround Source Heat Pumps save money. Heat pumps are much cheaper to run than direct electric heating systems. GSHPs are cheaper to run than oil boilers and can be cheaper than runing gas boilers.\nBecause heat pumps can be fully automated they demand much less work than biomass boilers.\nHeat pumps save space. There are no fuel storage requirements.\nNo need to managed fuel deliveries.\nNo risk of fuel being stolen.\nHeat pumps are safe. There is no combustion involved and no emission of potentially dangerous gases. No flues are required.\nGSHPs require less maintenance than combustion based heating systems. They also have a longer life than combustion boilers. The ground heat exchanger element of a ground source heat pump installation has a design life of over 50 years.\nHeat pumps save carbon emissions. Unlike burning oil, gas, LPG or biomass, a heat pump produces no carbon emissions on site (and no carbon emissions at all, if a renewable source of electricity is used to power them).\nGSHPs are safe, silent, unobtrusive and out-of-sight: they require no planning permission.\nHeat pumps can also provide cooling in summer, as well as heating in winter.\nGround source heat pumps are the only reneweable energy technology that can benefit from the thermal energy storage properties of the ground to recycle heat from summer to winter.\nA well designed ground source heat pump system is likely to increase the sale value of your property.\nGround Source Heat Pumps in Commercial Buildings\nGround source heat pumps are very well suited to commercial buildings, especially those which have a need for cooling in summer as well as heating in winter. However, expert design and installation are critical in achieving high carbon savings and low running costs.\nRenewable Heat Incentive - Commercial RHI\nThe Renewable Heat Incentive is a financial encouragement to install ground source heat pumps in commercial buildings: Ofgem will pay 8.7 pence per kWhour generated every quarter for the next 20 years.\nGround source heat pumps have a key part to play in meeting the UK\'s binding renewable energy targets by 2020.\nPerformance of Ground Source Heat Pumps\nThe performance of a heat pump is measured under standard conditions as the ""coefficient of performance"": this measures the heat output in kilowatts in relation to the electrical input in kilowatts. However, the CoP of a heat pump is greatly influenced by the output temperature delivered to the heat distribution system in the building and the input temperture from the heat source.\nIn cold conditions a ground source heat pump with access to a temperture of 10°C from the ground will deliver a significantly higher CoP than an air source heat pump with access to -5°C from ambient air. The design, installation quality and controls of a ground source heat pump installation are critical to achieving good performance.\nWater Source Heat Pumps\nThe heat pump in a ground source heat pump system is identical to that for a ""water source heat pump"" system. The difference is that a GSHP receives water through a closed loop of pipes buried in the ground, which the pipes absorb heat from; a WSHP receives water through pipes that absorb heat from contact with water. The water may be from a river, open water or even the sea in the case of a ""marine source heat pump"". Usually a closed loop is used. However, if clean water is available from an aquifer it may be possible for an open loop to be used. In this case water is drawn from the aquifer and passed directly through pipes into the heat pump and discharged back to the aquifer though another pipe.\nAn advantage of a WSHP is that a constant temperature will be available to the WSHP even if a large amount of heat is required - provided the WSHP is heat exchanging with a large body of water.\nInstallation of Ground Source Heat Pumps\nTo get the full benefit of a GSHP installation you will need to employ someone with design and installation experience. A ground source heat pump may not perform well unless it is incorporated in a good design by someone who understands the needs of the building, the use to which the building is being put and the local geology.\nA well installed ground source heat pump installation can provide sustainable energy over the whole life of a building.\nFor more information on installation of ground source heating from an experienced source please contact one of our members.']"	['<urn:uuid:2412d628-e1a3-45f0-b077-fbd911809134>', '<urn:uuid:ab314015-ffbc-461a-b6ec-ff80cbf38325>']	open-ended	with-premise	concise-and-natural	similar-to-document	multi-aspect	expert	2025-05-01T22:05:01.292488	12	86	2156
135	michelangelo sistine chapel painting technique details	Michelangelo created the Sistine Chapel frescoes by painting directly onto wet plaster that was applied daily. He painted standing up, not lying down as commonly believed, and used bright colors to ensure visibility from 20 meters below. While he had numerous assistants helping him with the work, he was initially reluctant to accept the commission as he considered himself primarily a sculptor rather than a painter.	"['Perhaps second only in fame to Leonardo da Vinci\'s Mona Lisa, Michelangelo\'s magnificent frescoes on the ceiling of the Sistine Chapel opened to the public for the first time 500 years ago this week\nin St Peter\'s Basilica in Rome.\nThis masterpiece of Renaissance art, at around 40 metres long by 13 metres wide (460 square metres), includes 343 figures with nine central panels depicting the stories of the Old Testament from the Creation to the fall of man.\nThe narrative on the ceiling shows God creating the Sun, Moon and Earth, Adam and Eve, the temptation and expulsion from the Garden of Eden and the story of Noah\'s Ark.\nAdjacent to the main panels are massive portraits of Prophets and Sybils who foretold the coming of Jesus. And scattered throughout are cherubs and smaller nude figures. The frescoes (Italian for \'fresh\') were created by painting directly onto wet plaster that was applied each day. Michelangelo\'s use of bright colours ensured that the scenes could be easily viewed from the floor 20 metres below.\nEven if people haven\'t seen the frescoes live, they\'ve certainly seen Michelangelo\'s imagining of the Creation of Adam - with the finger of God stretched out to give life to Adam - on a mug, a t-shirt or a poster.\nSo it is slightly surprising that the Vatican Museums, who administrate the Sistine Chapel, aren\'t making a bigger deal of the anniversary of this famous artwork. In fact, it\'s difficult to find any reference at all to the occasion on their website. This could simply be that the Chapel\'s administrators are trying to protect the artworks from what one Italian critic recently referred to as \'drunken herds\', trailing in dust on their shoes and illegally using damaging flash photography. Antonio Paolucci, the director of the Vatican Museums probably wouldn\'t describe the visitors like that but he did point out that ""such a crowd emanates sweat, carbon dioxide and dust"", all of which are harmful to the frescoes. The Sistine Chapel is one of the most visited tourist attractions in the world with over 20,000 a day and 4 million visitors annually and the Vatican is probably torn between wanting to protect its precious artwork and the 15 euro admission charge from every visitor.\nWhen Michelangelo di Lodovico Buonarroti Simoni (1475-1564) was commissioned in 1508 by Pope Julius II to paint the ceiling of the Sistine Chapel, he was already famous as the sculptor of Pieta (1498) and David (1504).\nHe was initially reluctant to accept the commission as he considered himself a sculptor not a painter. But he was eventually persuaded when he was given leeway to deviate from the original assignment to paint the 12 Apostles, allowing him the artistic freedom to create something far more elaborate and time-consuming.\n\'The Agony and the Ecstasy\', a 1961 book by Irving Stone made into a cheesy Hollywood film starring Charlton Heston as Michelangelo and Rex Harrison as Pope Julius, depicted the artist lying on his back high up on scaffolding toiling away almost single-handedly. In reality, Michelangelo painted standing and he had a constant stream of assistants to help him with his momentous undertaking. In essence, Michelangelo wasn\'t much different from contemporary artists like Damien Hirst and Jeff Koons who have an army of assistants to execute their designs. However, no one would dispute the genius of Michelangelo or the masterpiece of his frescoed ceiling half a millenium ago or today.']"	['<urn:uuid:6d3803c4-9929-4bd1-8bfe-531bbd9fca36>']	open-ended	with-premise	short-search-query	similar-to-document	single-doc	expert	2025-05-01T22:05:01.292488	6	66	574
136	marine animal food chain pollution effects	In marine ecosystems, energy flows through multiple trophic levels, from phytoplankton to zooplankton to fish, and finally to tertiary consumers like large fish, sharks, and marine mammals. This food chain is severely impacted by ocean pollution. When pollutants enter the water, small organisms ingest toxins which then move up the food chain through bioaccumulation. Additionally, plastic debris is often mistaken for food by marine animals, while oil spills can suffocate marine life by permeating their gills. The degradation of pollution in seawater also depletes oxygen levels, creating dead zones where marine life cannot survive.	['Tertiary Consumer Definition\nA tertiary consumer is an animal that obtains its nutrition by eating primary consumers and secondary consumers. Usually tertiary consumers are carnivorous predators, although they may also be omnivores, which are animals that feed on both meat and plant material.\nFunction of Tertiary Consumers\nWithin any ecosystem, the energy that is present within its organisms is passed through a food chain or food web. Each organism in a food chain occupies a particular position called a trophic level, whereby animals consume other animals in lower trophic levels and are eaten by those in higher trophic levels.\nTertiary consumers often occupy the top trophic level, and so are predated by no other animals; in this case they are called “apex predators”. However, when they die their bodies will be consumed by scavengers and decomposers.\nSometimes in a food chain there is an apex predator above the tertiary consumer. However, energy is used up and is lost as heat as it is transferred through each of the trophic levels, which results in a low availability of energy in the higher levels (this can be viewed as an energy pyramid). It is therefore common to only have four trophic levels, and for the tertiary consumer to hold the ecological function of the apex predator.\nSpecies in the highest trophic levels play a very important role in ecosystems. They control populations or alter the behaviour of animals in lower trophic levels. Animals in lower trophic levels may be carnivores, herbivores or omnivores, and when their populations are limited it relieves either predation or grazing pressure on the trophic levels below them. This keeps ecosystem dynamics in balance. For example, if a population of foxes becomes too large it could put pressure on rabbit populations. By predating the foxes, a tertiary consumer, such as a hawk, keeps the populations in check and reduces the amount of rabbits that are consumed by the foxes. This is called a trophic cascade.\nThe image shows an example of a trophic cascade. When the predator is present the deer population is controlled, however, if predators are removed deer populations grow and this can affect the vegetation of an ecosystem.\nExamples of Tertiary Consumers\nAll big cats, such as tigers, lions, pumas and jaguars are tertiary consumers. They are also all apex predators, meaning they have no predators in their natural environment—an exception to this is the leopard, which is occasionally predated by lions and tigers, with which they share habitats.\nThe physical features of the big cats are typical of apex predators. They have large teeth, jaws and claws; they have forward facing eyes for tracking prey; they also have strong muscles and can often run at great speed.\nBig cats consume prey from all trophic levels beneath them. This includes herbivores that live in herds such as buffalo, zebras and wildebeest, and secondary consumers such as foxes and hyenas. They also sometimes consume large animals such as crocodiles when on land, although when in the water, the crocodiles—which are also tertiary consumers—have an advantage, and the big cats can become vulnerable to attack.\nMarine Tertiary Consumers\nThere are many examples of tertiary consumers in marine ecosystems. The primary producers of the oceans, phytoplankton, are generally consumed by microscopic organisms called zooplankton, and so the numerous animals that feed on the zooplankton are secondary consumers. Fish, jellyfish and crustaceans are common secondary consumers, although basking sharks and some whales also feed on the zooplankton.\nPhytoplankton are extremely numerous, and supply ecosystems with a huge amount of biomass and thus provide lots of energy within the trophic pyramid. Because there is such a large amount of available energy, the secondary consumers (fish etc.) are also numerous and many animals feed on them.\nTertiary consumers in marine environments include larger fish such as tuna, barracuda and groupers, seals and sea lions, jellyfish, dolphins, moray eels, turtles, sharks and whales—some of which are apex predators, such as the great white or tiger sharks and orca whales. Additionally, many seabirds such as gulls, shearwaters and penguins are tertiary consumers.\nIn freshwater environments, predatory fish, such as pike, consume smaller fish as well as other secondary consumers such as frogs, snakes, birds and small mammals.\nHumans are omnivorous, meaning they eat both plant and animal materials. They also have a widely varied diet and so consume foods from every trophic level, including decomposers such as mushrooms!\nIf a person chooses to be a vegetarian or vegan, they would be classed as a primary consumer as they only eat plant material. By eating foods such as grain-fed chicken, a person would fill the role of secondary consumer, however, if that chicken is also able to eat insects the person is a tertiary consumer.\nHumans are often thought of as apex predators, because they have acquired the ability to kill any animal using weapons etc. However, if you took away a person’s gun and put them face to face with a lion…who do you think would be eaten?\nRelated Biology Terms\n- Primary Producers – Autotrophic organisms that use photosynthesis to create their own food using energy from the sun.\n- Primary Consumers – Heterotrophic organisms also known as herbivores, which acquire nutrition from consuming primary producers.\n- Energy Pyramid – The graphical representation of the flow of energy through the trophic levels of an ecosystem.\n- Trophic Cascade – The top-down effect that predators have on populations of prey within an ecosystem.\n1. Which of the following describes a tertiary consumer?\nA. An animal that eats other carnivorous or omnivorous animals\nB. An herbivorous animal\nC. A fast animal\nD. An animal in the third trophic level\n2. Which of the following is an example of a tertiary consumer?\n3. Which of the following is not a typical feature of an apex predator?\nA. Sharp claws\nB. Strong muscles\nC. Thick fur', 'Oceans, which account for 70 percent of the surface of our planet, play a pivotal role in the health of our planet and those who inhabit it. Unfortunately, our oceans are polluted. According to the National Oceanic and Atmospheric Administration, billions of pounds of trash and other pollutants enter our oceans every year.\nThe monumental impacts of this are far-reaching. In this post, we’re taking a closer look at the various causes of ocean pollution, its effects and the steps we can take to combat it.\nCauses of Ocean Pollution\nThere are many causes of ocean pollution. Of all the facts, there is one constant: most pollution in our oceans begins on land and is caused by humans. Here are some of the major causes of marine pollution:\nNonpoint source pollution (Runoff)\nNonpoint source pollution comes from a variety of different locations and sources. The result of this is runoff, which occurs when rain or snow moves pollutants from the ground into the ocean. For instance, after a heavy rainstorm, water flows off roads into the ocean, taking oil left on streets from cars with it.\nManufacturing plants in some areas of the world release toxic waste into the ocean, including mercury. While it’s intentionally being released into the sea, sewage also contributes to ocean pollution, as well as plastic products. According to Ocean Conservancy, eight million metric tons of plastic goes into our oceans every year.\nShips are major contributors to ocean pollution, especially when crude oil spills occur. Crude oil lasts for years in the ocean and is difficult to clean up.\nAtmospheric pollution, which refers to objects carried by the wind to the ocean, is a big problem. Items such as plastic bags and styrofoam containers become suspended in the water and don’t decompose.\nDeep-sea ocean mining causes pollution and disruption at the lowest levels of the ocean. Drilling for substances such as cobalt, zinc, silver, gold and copper creates harmful sulfide deposits deep in the ocean.\nEffects of Ocean Pollution\nOcean pollution has many consequences that directly and indirectly affect marine life, as well as humans. Here are some of the most common effects of ocean pollution:\nHarmful to marine animals\nSea animals are common victims of ocean pollution. Oil spills, for instance, will ensnare and suffocate marine animals by permeating their gills. When the oil gets into seabird feathers, they may not be able to fly or feed their young. Animals that aren’t killed by crude oil may suffer from cancer, behavioral changes and become unable to reproduce.\nMarine animals also mistake small plastic debris for food or become entangled in or strangled by plastic bags and discarded fishing nets. Animals most vulnerable to harm from plastic debris in the ocean include dolphins, fish, sharks, turtles, seabirds and crabs.\nDepletion of oxygen in seawater\nAs excess debris in the ocean slowly degrades over many years it uses oxygen to do so, resulting in less 02 in the ocean. Low levels of oxygen in the ocean lead to the death of ocean animals such as penguins, dolphins, whales and sharks.\nExcess nitrogen and phosphorus in seawater also cause oxygen depletion. When a great deal of oxygen depletion occurs in an area of the ocean, it can become a dead zone where no marine life can survive.\nA threat to human health\nPollutants in the ocean make their way back to humans. Small organisms ingest toxins and are eaten by larger predators, many of which are seafood that we eventually eat. When the toxins in contaminated animals get deposited in human tissue, it can lead to long-term health conditions, cancer and birth defects.\nOcean Pollution Solutions\nGiven the long-term, disastrous effects of ocean pollution, anything we can do to avoid contaminating our seas is a good idea. Here are some ocean pollution solutions that can make a big difference.\nReduce chemical fertilizer use\nExcess chemical fertilizer eventually makes its way into the oceans. Choose organic fertilizers, which tend to be lower in nutrients, and use them at half strength or half as often as suggested.\nOpt for reusable bottles and utensils\nThrow-away plastic bottles and utensils, including straws, are massive ocean polluters. Rather than contributing to the threat to marine life, opt for reusable bottles and utensils.\nHold a cleanup\nOrganize a social distancing cleanup at the beach or a nearby park. The more trash you pick up and properly dispose of, the less waste goes into our oceans.\nProperly dispose of plastics and trash\nOne of the simplest ways to reduce ocean pollution is to properly dispose of plastics and other recyclable materials, so they don’t end up in the ocean. In outdoor spaces, such as beaches and parks, dispose of trash in a secure receptacle or take it home with you.\nTo help encourage proper disposal, we recommend downloading our Waste Wizard App which allows you to input common waste items and see how to properly dispose of them. With a few small changes to our daily routines, we can all do our part to help reduce the amount of pollution going into our oceans.']	['<urn:uuid:924fa36c-e538-42de-8792-af4cd6e92e37>', '<urn:uuid:41253a00-9704-4962-9284-05a735acb791>']	open-ended	direct	short-search-query	distant-from-document	multi-aspect	expert	2025-05-01T22:05:01.292488	6	94	1830
140	How do wave power plants impact marine ecosystems and what are their effects on global pollution compared to other energy sources?	Wave power plants can negatively impact marine ecosystems by occupying natural habitats, endangering marine life with moving parts, risking electrocution through transmission systems, and potentially affecting water quality with maintenance chemicals like lubricants. However, compared to other energy sources, wave power is environmentally friendly since it doesn't emit greenhouse gases or toxins, unlike fossil fuels which contributed to 9 million pollution-related deaths in 2015. Wave power plants also have a small spatial footprint, typically occupying less than half a square mile for a 30MW plant.	"['pollution might just be humanity’s most pressing problem.\nMore than 9 million deaths were linked to “polluted air, water and soil,” in 2015, according to an explosive new report published in The Lancet, a UK medical journal. To provide some context, this means that pollution accounted for 16 percent of all deaths worldwide, “three times more deaths than from AIDS, tuberculosis, and malaria combined and 15 times more than from all wars and other forms of violence,” according to the report’s executive summary. This figure, as the study’s authors point out, may in fact be conservative, and could be millions higher, “because the impact of many pollutants are poorly understood.”\nThe study drew from the work done in previous studies that “show how pollution is tied to a wider range of diseases than previously thought,” including asthma, cancer, heart and lung disease, and neurological disorders. The vast majority of deaths – a full 92 percent, according to the report – took place in undeveloped or developing countries, a shocking statistic that nevertheless still provides some hope: the study’s authors say that “the big improvements that have been made in developed nations in recent decades show that beating pollution is a winnable battle if there is the political will.”\nOther highlights from the study:\n- Deaths from air pollution “are on track to double by 2050” in southeast Asia;\n- The costs of pollution are $4.6 trillion each year, according to the study’s estimate – “equivalent to more than 6% of global GDP”;\n- Of the various forms of pollution, toxic air contributed the greatest number of deaths, at 7.4 million, water pollution (this means sewage, most often) resulted in 1.8 million deaths, and workplace pollution, “including exposure to toxins, carcinogens and secondhand tobacco smoke,” resulted in 800,000 deaths.\n- Although the highest rates of pollution death are found among small developing countries, it’s India, with 2.5 million deaths, and China, with 1.8 million, that have the greatest number of deaths linked to pollution. Both Russia and the US are in the top ten as well.\nAccording to lead author Dr. Philip Landrigan, a pediatrician and professor of environmental medicine and global health at the Icahn School of Medicine at Mount Sinai, stricter regulation of toxic chemicals can often benefit economies, which “puts the lie to what we hear that controlling pollution is going to kill jobs.” As an example, Landrigan cites the passage in the US of the Clean Air Act, which has brought air pollution levels down 70 percent in the intervening years, even as GDP has increased 250 percent.\n“Pollution is one of the great existential challenges of the Anthropocene era. Pollution endangers the stability of the Earth’s support systems and threatens the continuing survival of human societies.”\nThe Lancet Commission on pollution and health\nThe Lancet Commission on pollution and health\nThe study’s conclusions, along with a just-released report by the nonpartisan Government Accountability Office (GAO) which “found that costs [linked to climate change] may rise to as much as $35 billion per year by 2050,” are surfacing at a particularly transformative moment for the EPA – established the same year, 1970, that the Clean Air Act was amended to give the federal government much greater power to regulate chemical use. Administrator Scott Pruitt, who has not accepted scientific consensus around climate change, and who pressed President Donald Trump to pull out of the Paris Climate Accord, has “embarked on record-setting rollbacks,” which include “plans to repeal pollution in the nation’s waterways [and] delaying rules requiring fossil fuel companies to rein in leaks of methane and greenhouse gases.” Pruitt also refused to ban a farm pesticide, chlorpyrifos, that poses a health risk to children and farm workers, and that has already, since 2000, been banned from most household use. The list goes on: the EPA under Pruitt has moved to suppress research into – and even mention of – climate change, including removing references on its website, canceling public talks, and removing from advisory roles scientists who’ve received federal grants for studies, and politicizing the issue by creating “red team-blue team” exercises between scientists who doubt climate change and those who don’t. Such exercises create false equivalences on a topic that’s already got near-unanimous scientific consensus. Pruitt has also moved to repeal the Obama administration’s signature climate regulation, the Clean Power Plan, in an effort to bolster the coal industry, long in decline due to the rise of natural gas and renewables, and has tasked his agency to respond to permit requests in six months or fewer, which means big, complicated projects with difficult-to-predict outcomes could get the greenlight without receiving thorough vetting.\nWhat this amounts to, in the eyes of many folks on the left, is a full-on assault on the environment, but Pruitt and co. see themselves as reformers, trimming away at bureaucratic fat and demanding the science around disputed chemicals be utterly airtight before acting to regulate, rather than allowing what Dr. Nancy Beck, one of Pruitt’s top deputies, calls “phantom risks” to bottleneck industry. It’s a typically Republican approach, maybe more destructively so in this administration than in previous ones, although this may just be because there’s more to destroy: the Obama administration significantly expanded the role of the EPA in its efforts to address climate change, and also took a rather-safe-than-sorry approach to chemical regulation which, in light of The Lancet report, may prove to be the right one. As Wendy Cleland-Hamnett, who until her retirement last month was “the agency’s top official overseeing pesticides and toxic chemicals,” asserts,\nYou are never going to have 100 percent certainty on anything, but when you have a chemical that evidence points to is causing fatalities, you err more on the side of taking some action, as opposed to ‘Let’s wait and spend some more time and try to get the science entirely certain,’ which it hardly ever gets to be.\nThe New York Times’s The Daily podcast posted a fantastic episode on Tuesday about the perceptions each side of the EPA debate has of itself, which you can find here.\nA new study summarizing observations “across 63 German nature reserves” reveals a disturbing 76 percent decline in flying insect biomass.\n- The study’s authors aren’t sure why this happened, but speculate that pesticide use in adjacent areas, coupled with climate change, has played a significant role.\n- The authors also believe their findings to “be representative of much of Europe and other areas of the globe.”\n- A key quote: “Lack of insects is very likely to be detrimental to the entire ecosystem…insects play a crucial role in ecosystems, being responsible for plant pollination and nutrient recycling as well as acting as a food source for animals such as birds, amphibians, reptiles, bats and small animals.”\nAn 11-year-old motivated by Flint’s still-polluted (honestly, how?) water invented a lead-detecting device.\n- From NPR’s description of the device: “there is a disposable cartridge containing chemically treated carbon nanotube arrays, an Arduino-based signal processor with a Bluetooth attachment, and a smartphone app that can display the results.”\n- What we’d like to know: how does an 11-year-old get her hands on carbon nanotubes?\nChina’s new ban on 24 categories of recyclables and solid waste could mean that much of what we recycle ends up in the trash.\n- Why? “China is the dominant market for recycled plastic,” according to Christian Cole in The Conversation. Here in the US, we export around 1.4 million tons of recycled plastic to China.\n- Double bonus: a tiny Montana company with links to Secretary of Interior Ryan Zinke just landed a $300 million contract to rebuild Puerto Rico’s electrical infrastructure. Whitefish Energy Holdings, which had just two employees when Hurricane Maria made landfall last month in Puerto Rico, is based in Zinke’s hometown and owned by a friend of his.\nThe first-ever floating wind turbines—these five turbines off the coast of Scotland have the potential to power, at peak, up to 20,000 homes.\nAccording to a brand new study in Nature Communications, “water rose rapidly, in punctuated bursts, rather than gradually over time” during the last global warming period more than 10,000 years ago. The researchers “suggest[ed] these past events could be viewed as a kind of ‘analog’ for the future.”\n- Double bonus: a new story in The Atlantic, summarizing the results of a different study, would seem to confirm this: “Climate Change Will Bring Major Flooding to New York Every 5 Years”.\nLet’s end this on a positive note: here’s a livestream from the inside of a little penguin burrow.\nMakayla Esposito contributed to this report.\nheader image: ""pollution,"" possan / flickr', '17 Wave Power Advantages and Disadvantages Explained\nWave power is a renewable form of power that is generated from wave energy, using mechanical and electromagnetic technologies. Wave power advantages and disadvantages are; reliability, renewable operation, sustainability, fossil fuel independence, high potential, versatility, flexibility, consistency, minimal maintenance (advantages); cost, usability, weather susceptibility, technical limitations, transmission challenges, navigation problems, geographic constraints (disadvantages).\nThe characteristics of wave power and wave energy can be analyzed simultaneously, since wave power is a product of the conversion of wave energy.\nThis article discusses the advantages and disadvantages of wave power, as outlined below;\n-Advantages of Wave Power (and Wave Energy)\n-Disadvantages of Wave Power (and Wave Energy)\nAdvantages of Wave Power (and Wave Energy)\n1). Wave Power is Reliable\nWhen compared to other types of renewable energy, wave energy is significantly reliable.\nThis is because, unlike solar and wind intensity which change continuously with geographic conditions, wave motion occurs almost on a consistent basis.\nAnother way to describe the reliability of wave power is to state that, although the amount of wave energy (which is the source of wave power) may vary at different times, it is hardly ever equal to zero. There is an average amount of wave energy that is always available.\nWave power is reliable mainly because it does not depend on one variable. Unlike fossil fuels, solar and wind, wave energy originates from different sources, including solar heat, wind current, and Earth rotation.\nThe role of gravity in producing wave energy is yet another reason why it is reliable. Gravitational forces cause waves to occur in the ocean, as they try to balance the distribution of momentum across the water body, and to restore equilibrium after the disrupting effects of wind and solar radiation.\nThis settling effect and gravitational pull constantly works against the disrupting forces, leading to wave energy production. As a result, wave power can always be generated, although it may vary in magnitude at different times.\n2). Wave Power is Renewable\nWave power is renewable because wave energy is produced from solar, wind gravity and water, which are all renewable resources.\nWhile other types of power and energy are affected by changes like fuel availability and global warming, the oceans will always exist, as well as wind, gravity and solar radiation.\nWhat this implies is that electricity generation from wave energy will always be possible.\n3). Fossil Fuel Independence\nBecause wave power is renewable and reliable, it can serve as a substitute to fossil fuels, in its own capacity.\nIn spite of the advantages of wave power, it is an underdeveloped renewable resource . One of the reasons for this is the fact that adequate effort is yet to be made toward the development of wave energy technology.\nFossil fuels, on the other hand, constitute the most developed energy sector. Over-dependence on fossil fuels has economic and environmental disadvantages, which can be reduced by increasing the prominence and effectiveness of wave power.\nThe word ‘sustainable’ resonates with some important concepts, such as sustainability and sustainable development.\nThere are different reasons why wave power is sustainable. These reasons span across the three aspects of sustainability, which are environmental, social and economic.\nWave power is considered by many environment-friendly. The conversion of wave energy does not typically have any negative effects on water, soil or air quality.\nWave energy technologies and mechanisms are relatively simple, and do not emit any hazardous byproducts like greenhouse gases, toxins, and wastes .\nThe aesthetic impact and spatial footprint of wave power plants are also small, because these plants do not occupy large portions of the ocean, are often partially submerged.\nWhat this means is that wave power generation is a conservative practice. Estimates suggest that a 30MW wave power plant will occupy less than half square mile in the ocean.\nBecause it is mostly done offshore, wave power generation does not cause any notable damage to the land. This is unlike fossil fuels, which are known to cause significant soil and water pollution , or wind turbines and bioenergy plants that may cause aesthetic or air pollution.\nWhat all of these implies is that wave power is not a potential cause of environmental degradation.\nOther advantages such as reliability and renewable production, suggest that wave power is also sustainable and beneficial from social and economic perspectives.\n5). High Potential\nWave power has a relatively high potential because wave energy can be produced in large quantities .\nA vast amount of wave kinetic energy is generated in the oceans on a consistent basis. A reason for this is the vast scale of the oceans, and the magnitude of wind, solar and gravitational forces that act upon the ocean water.\nThe result is a very high energy density and energy efficiency of waves.\nAt the same time, the vastness of the oceans implies that wave energy can be accessed in all parts of the Earth. With availability, reliability, efficiency and high density, it can be said that the potential of wave power is significant.\nThis potential can be put to use simply by developing efficient technologies to harness wave energy and generate electricity.\n6). Versatility and Flexibility of Wave Power Generation and Consumption\nWave power generation is a versatile and flexible practice for different reasons.\nThe flexibility of wave power arises from the fact that it can be generated under a variety of conditions.\nThere are different devices, mechanisms and technologies for converting wave energy to wave power. These include barrages, longitudinal buoys, point absorbers, hydraulic piston systems, among others.\nVarious locations on the ocean are suitable for installing wave power plants, because wave energy is widely distributed across the water body.\nThis reduces the environmental impact of the wave power generation process, as plants can be installed in locations where there us minimal environmental effect, such as offshore areas.\nThe scale of wave power generation is flexible as well. It can be scaled up or down based on the size and design of the wave energy converter or power plant.\nIn terms of versatility, there is a variety of possible uses, of wave power. These include desalination, seawater pumping, and electricity generation.\nCompared to other power and energy sources, wave power is fairly consistent.\nThis is because wave energy is reliable, and its magnitude of output can be estimated with some accuracy.\nIt can therefore be said that wave power is ‘predictable’, because of the existence of a consistent, average amount of wave energy at all times.\n8). Wave Power Requires Minimal Maintenance\nBecause wave power plants are relatively simple in their design, the amount of maintenance required by these systems is much less than that which is required by other power plants.\nWhile some wave power plants are expensive to design, construct and install, there are various avenues where cost is minimized during the operational life of the plant.\nThese include hazard control, fuel usage and vandalism, among others.\nDisadvantages of Wave Power (and Wave Energy)\n1). Capital Cost of Wave Power Plants\nThe capital cost of generating wave power is relatively high, mainly because it is an underdeveloped sector.\nSince there have not been many wave power plant projects so far, the cost of acquiring equipment and carrying out the design and construction of these plants, is yet to be optimized.\nAlso, most wave power plants at this time, are built as a result of intensive research and development projects that are directed toward improving the efficiency and performance of wave power.\nSuch research and development projects add significant expense to the wave power generation effort.\nAlthough the power plants are relatively simple and require minimal maintenance, they are susceptible to corrosion as a result of prolonged exposure to seawater .\nThis means that corrosion-resistant materials must be used for building wave power plants, and these exposed metal parts must be assessed routinely to ensure that they are not damaged.\n2). Scale of Usability\nAlthough the amount of wave power produced by a plant depends directly on the size of the plant, there has not been much progress so far in terms of developing and implementing a practical wave power generation plant.\nExisting wave power plants are generally not yet capable of delivering utility-scale power for domestic use. This is a major setback, and limits the actual utilization of wave power.\n3). Wave Power Plants are Susceptible to Weather Hazards\nWave energy capture devices and other technologies used in wave power generation, are constantly exposed to the elements.\nThis exposure means that the equipment can get damaged or impaired due to harsh circumstances of operation.\nAsides the risk of damage, exposure of wave power equipment to harsh weather elements may reduce the performance of these equipment . The efficiency and scale of electricity generation are therefore inhibited at such times.\n4). Impact on the Marine Ecosystem\nIn order to capture wave energy and generate wave power, facilities must be installed on the ocean.\nHowever, this can have some negative effects on the biotic and abiotic components of the marine ecosystem .\nIn addition to occupying the natural habitat of marine species, wave power plants have moving parts that can be dangerous to marine life. Since water is a conductive material, there is also the risk of electrocution by transmission systems that are linked to wave power plants.\nChemicals used to operate and maintain the wave power equipment, such as lubricants, can also act as toxins, and may negatively affect water quality in the marine ecosystem.\n5). Technological Limitations of Wave Power Technology\nWave power also has some technological limitations.\nThese limitations arise solely from the fact that wave power technology is still a developing field and has not seen sufficient inputs and modifications to optimize its potential.\nAlso, because there are relatively few wave power systems that have been developed so far, there is not much practical information available to serve as a reference point for improvement.\nThe result of these conditions is a low technical-efficiency form of wave power, which does not meet the existing energy needs.\n6). Wave Power Transmission Challenges\nThere are two main reasons why wave power is often challenging to transmit.\nOne of these is the fact that wave power technology has some practical limitations. As a result, the transmission mechanism for electricity produced by wave power systems, has not been well developed.\nAnother reason is the obvious fact that wave power is produced offshore. Aside applications like water pumping where wave power is used offshore, it must be transmitted over long distances to the shore where it is needed.\nSuch long-distance transport of electricity across the ocean to the land is a notable challenge that affects the use of wave power.\n7). Sea Navigation may be Affected\nWave power facilities that have been installed offshore can affect navigation on the sea.\nThis is because such facilities may become obstacles within the travel route of marine vessels of various types.\nThe effect of such circumstances can be bad for the economy, as they could affect the marine economy by reducing the speed and sustainability of export and import, sea travel, tourism, fishing, and other marine-based activities.\n8). Noise Pollution May Occur\nThe equipment needed to convert wave energy to power, usually consist of moveable parts and generators.\nThese components can be loud when operating, and can cause significant, continuous noise pollution, that may affect inhabitants of the surrounding environs.\n9). Geographical Constraints of Wave Power Generation\nThere are geographical constraints involved in the generation and consumption of wave power.\nTo begin with, wave power generation varies with location. While wave energy is always being produced, not every marine region may produce enough energy to be harnessed in a profitable manner.\nThere may also be restrictions to the installation of wave power plants in some areas. This is especially the case in places where the marine sector is a notable aspect of the economy.\nLastly, wave power can only be beneficial where there are usable and reliable transmission schemes to send the electricity to where it will be used. In many coastal regions, such schemes and facilities are not available.\nWave power advantages and disadvantages are as follows;\nAdvantages of wave power are;\n- Wave Power is Reliable\n- Wave Power is Renewable\n- Fossil Fuel Independence\n- High Potential\n- Versatility and Flexibility of Wave Power Generation and Consumption\n- Wave Power Requires Minimal Maintenance\nDisadvantages of Wave Power are;\n- Capital Cost of Wave Power Plants\n- Scale of Usability\n- Wave Power Plants are Susceptible to Weather Hazards\n- Impact on the Marine Ecosystem\n- Technological Limitations of Wave Power Technology\n- Wave Power Transmission Challenges\n- Sea Navigation may be Affected\n- Noise Pollution May Occur\n- Geographical Constraints of Wave Power Generation\n1). Ankar, S.; Akdoğan, D. A. (2016). “Environmental and Economic Impacts of Wave Energy.” Handbook of Research on Green Economic Development Initiatives and Strategies. Available at: https://doi.org/10.4018/978-1-5225-0440-5.ch013. (Accessed 3 May 2022).\n2). Enferad, E.; Nazarpour, D. (2013). “Ocean’s Renewable Power and Review of Technologies: Case Study Waves.” In H. Arman, & I. Yuksel (Eds.), New Developments in Renewable Energy. IntechOpen. Available at: https://doi.org/10.5772/53806. (Accessed 3 May 2022)..\n3). Hammons, T. J. (2011). “Tidal Power in the UK and Worldwide to Reduce Greenhouse Gas Emissions.” International Journal of Engineering Business Management 3(2). Available at: https://doi.org/10.5772/50933. (Accessed 3 May 2022).\n4). Mørk, G.; Barstow, S.; Kabuth, A. K.; Pontes, M. T. (2010). “Assessing the Global Wave Energy Potential.” 29th International Conference on Ocean, Offshore Mechanics and Arctic EngineeringAt: Shanghai, ChinaVolume: Proceedings of OMAE2010. Available at: https://doi.org/10.1115/OMAE2010-20473. (Accessed 3 May 2022).\n5). Musabikha, S.; Utama, K. A. P.; Mukhtasor, M. (2016). “Corrosion in the Marine Renewable Energy: A Review.” Conference: 3rd International Conference of Ocean, Mechanical and Aerospace – Scientists and Engineers – (OMAse), Malaysia, Vol.3 & Sec.2. Available at: http://isomase.org/POMAse%206-2-0.php. (Accessed 3 May 2022).\n6). Neary, V. S.; Ahn, S.; Seng, B. E.; Allahdadi, N.; Wang, T.; Yang, Z.; He, R. (2020). “Characterization of Extreme Wave Conditions for Wave Energy Converter Design and Project Risk Assessment.” Journal of Marine Science and Engineering 8(4):289. Available at: https://doi.org/10.3390/jmse8040289. (Accessed 3 May 2022).\n7). Pichtel, J. (2016). “Oil and Gas Production Wastewater: Soil Contamination and Pollution Prevention”, Applied and Environmental Soil Science, vol. 2016, Article ID 2707989, 24 pages,2016. Available at: https://doi.org/10.1155/2016/2707989. (Accessed 3 May 2022).']"	['<urn:uuid:5467784a-63f2-4851-b930-f9c8cfc042fd>', '<urn:uuid:6bdc7ecd-f9f4-4151-88c2-9a4a48229588>']	factoid	direct	verbose-and-natural	similar-to-document	multi-aspect	novice	2025-05-01T22:05:01.292488	21	85	3832
141	max money lose buying options	With long options, investors can lose 100% of invested funds	"[""An option is a contract that allows (but does not require) an investor to buy or sell an underlying instrument, such as a security, an ETF, or even an index, at a predetermined price for a certain period of time. Call and put options are made on the options market, which trades securities based contracts. Most of the time, holders choose to make their profits by trading (closing) their position. This means that option holders sell their options in the market and writers buy back their positions to close.\nOnly about 10% of options are exercised, 60% are traded (closed) and 30% expire worthless. Based on your answers, the broker generally assigns you an initial trading level based on the level of risk (usually 1 to 5, with 1 being the lowest risk and 5 being the highest). This is your key to performing certain types of options trading. Pamela de la Fuente is the editor of NerdWallet with more than 20 years of experience writing and editing in newspapers and corporations.\nOptions trading is the trading of instruments that entitle you to buy or sell a specific security on a specific date at a specific price. Options are among the most popular vehicles for traders, because their price can move fast, making (or losing) a lot of money quickly. Options strategies can range from fairly simple to very complex, with a variety of benefits and sometimes strange names. Options can be used to generate potential income on the shares you own and the shares you would like to own.\nOptions carry a high level of risk and are not suitable for all investors. Certain requirements must be met to trade options through Schwab. Investing involves risks, including loss of capital. Hedging and protection strategies generally involve additional costs and do not secure gains or guarantees against losses.\nWith long options, investors can lose 100% of invested funds. Hedged calls provide revenue, fall protection only to the extent of the premium received and limit the upside potential to the strike price plus the premium received. Spread trading must be done on a margin account. Read the options disclosure document entitled Characteristics and Risks of Standardized Options before considering any options transaction.\nSupporting documentation for any claim or statistical information is available upon request. While many brokers have eliminated fees for trading stocks or exchange-traded funds (ETFs), they still exist for options. These details will be documented in an options trading agreement that will be used to request approval from your prospective broker. Because option prices can be mathematically modeled with a model such as the Black-Scholes model, many of the risks associated with options can also be modeled and understood.\nThe risk you take as an option investor ultimately depends on your role in the contract (which side you're on) and your strategy, as there are multiple strategies you can implement using different combinations of options. European options are different from American options in that they can only be exercised at the end of their useful life, on their expiration date. This is why, when trading options with a broker, you usually see a disclaimer similar to the following. Options that expire before the estimated dates have values calculated based on the underlying prices from the estimated dates, as if the option expires on the estimated date.\nOptions trading is the way investors can speculate on the future direction of the stock market in general or individual securities, such as stocks or bonds. Like all the investment decisions you make, you need to have a clear idea of what you hope to achieve before trading options. Compared to opening a brokerage account to trade stocks, opening an options trading account requires larger amounts of capital. Options trading is when you buy or sell an underlying asset at a pre-traded price on a certain future date.\nBefore buying or selling options, investors should read the Standardized Options Characteristics and Risks booklet (PDF 17.8 MB), also known as the options disclosure document. Options quotes, technically called an option chain or matrix, contain a range of available strike prices. If used properly, options trading offers numerous advantages that stock and bond trading alone doesn't. Options trading strategies can become very complicated when advanced traders pair two or more call or put options with different strike prices or expiration dates.""]"	['<urn:uuid:3816c4c3-ec8c-49e1-bae2-7363df821ff6>']	factoid	with-premise	short-search-query	distant-from-document	single-doc	novice	2025-05-01T22:05:01.292488	5	10	726
142	I've been reading about unexplained phenomena in cosmic ray detection, and I'm wondering what's currently known about the mysterious high-energy cosmic rays that go beyond the 'knee' in the spectrum?	Nobody has any clear explanation for where these super-high energy cosmic rays originate from, making it one of the top ten outstanding problems in physics. While we understand cosmic rays up to the 'knee' (which occurs between 10^13 - 10^15 eV), there's still a big mystery about the kink in the spectrum that happens at the knee and what occurs at energies beyond that. There's also another feature called 'the ankle' at even higher energies, which suggests a completely separate part of the spectrum extending to ultra-high energies, often leading to speculations about exotic phenomena.	['Well, before disappearing into a long session of thinking about some funny behaviour my strings are up to (more later) I’d like to do a quick report on the departmental colloquium that I went to just now. We had Gary Zank, the Director of the Institute for Geophysics and Planetary Physics of the UC system (he’s based out of UCR) give us a talk entitled: “Particle Acceleration in Cosmic Plasmas”, and it was quite fascinating (and very well presented).\nAn outstanding problem in astrophysics is to explain the origin of the almost featureless cosmic ray spectrum extending up to energies of some 1020 eV. A very small feature is apparent at between about 1013 â€“ 1015 eV, the â€œknee.â€ In the late 1970â€™s, a suite of papers was published establishing the idea of diffusive shock acceleration for cosmic rays, essentially a first-order Fermi mechanism, which appeared to provide an explanation for the observed cosmic ray spectrum up to the knee. Diffusive shock acceleration is probably the most widely used particle acceleration mechanism in astrophysics and space physics, yet the theory is based on some stringent simplifications. The detailed [plasma] physics of the acceleration mechanism requires elucidation. We are fortunate in that very detailed observations of particle acceleration at shock waves, particularly in the guise of Space Weather, are providing considerable experimental insight into the basic physics of particle acceleration at a shock wave.\nHe gave us an overview of the remarkably detailed series of studies that his group has been carrying out (with the aid of an impressive multitude of computer simulations of the magnetohydrodynamics involved) in converting the various suggested acceleration mechanisms into detailed output that can be compared to experimental observations. Here’s a bit from their website:\nThe dynamical acceleration of particles at shocks waves propagating in the heliosphere is very poorly understood, yet shock waves are ubiquitous and almost all shocks are observed to energize ions and electrons. An understanding of particle acceleration at solar wind shocks has far reaching astrophysical implications. Furthermore, since energetic particles accelerated in either solar flares or in CME-driven shocks arrive at the Earth well before solar ejecta driven disturbances, an understanding of particle acceleration at interplanetary shocks is an integral part of the NSF and NASA Space Weather program.\nHe spoke quite a bit about shock wave mechanisms and how they work in supernovae as well. The physics of then how those “Galactic” cosmic rays wander around the galaxy and get to us (about a million years later) is quite intricate indeed, but the simulations give a lot of insight into how they end up here, and what we observe. All of this helps cover the physics of cosmic rays right up to the aforementioned “knee” in the spectrum. There’s still a big mystery about the kink in the spectrum that happens at the knee, and what happens for energies after that (and also the part of the spectrum called, yes, “the ankle”, which suggests an underlying completely separate part of the spectrum that spreads to ultra-high energies that is often a cause for speculations involving all sorts of exotic things lying in people’s notebooks).\nSimply put, nobody has any idea where those super-high energy cosmic rays come from. That’s why this is on lots of people’s top ten list of outstanding problems in physics.\n[Update: our Librarian, Sara Tompson, has constructed a partial bibliography for this (and other) talk’s material. It is here.]']	['<urn:uuid:3f8490ec-0d5e-46cb-8eb4-e5f0d5159d25>']	open-ended	with-premise	verbose-and-natural	distant-from-document	single-doc	expert	2025-05-01T22:05:01.292488	30	95	573
143	Could you explain the annual food preparation scale and timing for this traditional German festival that's been running since 1974?	Food preparation begins in early May and continues until the event. The scale is massive - they use 400 pounds of potatoes for German potato salad and 60 dozen eggs for noodles. Everything is handmade, including noodles and sausages, with nothing being frozen. Last year, they produced 7,000 krautstrudels filled with meat and cabbage, which sold out by the weekend's end. The festival began in 1974 and has grown from a parish event to a city-wide celebration, with last year's Saturday crowd being one of the largest ever.	['If you are a fan of the food at Sacred Heart-St. Joseph Parish’s annual Germanfest, then be sure to stop by this year’s event Saturday and Sunday.\nNot only will there be the traditional dishes people love, but also, for the first time, a cookbook featuring the top festival dishes will be sold so German food lovers can make their favorite dishes at home.\n“Alles schmeckt gut!” Father Tim Haberkorn said. The German phrase means “All tastes good!”\nThe cookbook has Germanfest dishes, as well as recipes from the Fasching celebration, which takes place the Saturday before Ash Wednesday. Plus, there are additional recipes from the people who create the food for both events. The cost for the book is $20, with proceeds going to support the parish.\nOn a recent afternoon, volunteer Rose Herman demonstrated how the Germanfest Dumplings with Green Beans and Ham are made. The recipe was a hit in its debut at last year’s event, so the plan is to make even more this year.\n“We’ll multiply this one recipe 110 times for Germanfest. I add potatoes, which isn’t in the recipe in the cookbook,” Herman said, as she dropped bits of dumpling dough into a large pot of boiling water.\nFood preparation begins in early May and continues right up until the event. Everything is handmade, from the noodles to the sausages.\nMaureen Steinbock, who has been in charge of the food for more than 30 years, is quick to point out nothing is frozen, which means the timing has to be just right for the creation of each dish.\nThey will use 400 pounds of potatoes for the German potato salad and 60 dozen eggs to make the noodles. The brats are made fresh, too.\nSteinbock has participated in Germanfest since it began in 1974.\n“I’m following in my mother’s footsteps,” she said. “She made all the potato bread dough for 300 strudels back then, and we sold out.”\nHerman’s husband, Larry, is known as the Strudel Guy. Last year, he oversaw the making of 7,000 krautstrudels, which are filled with meat and cabbage and sold out by the end of the weekend.\nSaturday’s German food line will feature the Dumplings with Green Beans and Ham, plus German sausage; bratwurst; German potato salad; German coleslaw; krautstrudel, a savory pastry filled with meat and sauerkraut; and desserts. There also will be a snack bar, and a beer garden will serve both American and German beers.\nThe more extensive buffet is on Sunday after the morning Mass. Festival-goers will feast on sauerbraten; pork and sauerkraut; krautstrudel; noodles and sage balls; German potato salad; fried chicken; mashed potatoes and gravy; green beans; rolls; and desserts.\n“Last year on Saturday was one of the largest crowds we’ve ever had,” Steinbock said. “What started as a parish event has grown into a city-wide event.”\nGermanfest Dumplings with Green Beans\nServings: 3 to 4\n1 cup flour\n1/2 teaspoon salt\n1/4 cup milk\n1/2 teaspoon baking powder\nFor remainder of recipe:\n1 stick butter\n21/2 cups bread crumbs\n1/4 cup chopped onion\n1 can green beans\n1 cup cubed ham\n1 pint light or whipping cream\nTo make the dumplings, mix all of the ingredients until well blended.\nBring a large kettle with 2 quarts of water and 1 teaspoon of salt (optional) to a boil. Using a small tablespoon or melon-baller, scoop out dumpling dough in amounts the size of a peanut and drop into the boiling water. The dumplings will swell as they cook. Dip spoon in hot water after each scoop. Bring the water back to a full rolling boil, and then drain.\nMelt the butter in a large skillet. Fry the bread crumbs and onion until brown.\nHeat the green beans and ham in a sauce pan. Drain and mix with the cooked dumplings. Pour the bread crumb mixture over the top. Pour the cream over the dumpling mixture.\nThe cream can be warmed if serving right away. The mixture can be covered and placed in a warm oven for a short time until ready to serve. Garnish with toasted croutons, if desired.\n2 pounds ground beef\n1/2 head cabbage, chopped\n1 medium onion, chopped\n1/2 teaspoon pepper\n1/4 teaspoon salt\nPotato dough (see below) or frozen bread dough\nBrown the ground beef. Saute onion and cabbage until tender. Combine the cooked meat, onion, cabbage and seasonings.\nRoll out the potato dough. Cut in 5-inch squares. The dough needs to be fairly thin. Place a tablespoon of meat mixture in the center. Fold the dough over the meat mixture and pinch edges around it.\nBrush top of strudel with egg wash (egg and little water.) Bake at 350 degrees until done, about 15 minutes.\n1 package dry yeast\n11/2 cup warm water\n2/3 cup sugar\n11/2 teaspoons salt\n2/3 cup vegetable shortening\n2 eggs, beaten\n1 cup mashed potatoes\n7 to 71/2 cups all-purpose flour\nDissolve yeast in water. Stir in sugar, salt, shortening, eggs and potatoes. Stir in 4 cups flour, 1 cup at a time. Mix well until smooth.\nKnead with enough of the remaining flour to make a smooth dough. Place in greased bowl, turning dough to coat well. Cover tightly and refrigerate for at least 8 hours.\nPunch down the dough. Shape into desired rolls or use for krautstrudels.\nFor rolls, place shaped dough on a greased cookie sheet. Cover loosely and let rise until doubled in bulk. Bake at 400 degrees for 25 to 30 minutes.']	['<urn:uuid:7b855ea5-9ee2-41cb-abc8-dcea639874a1>']	open-ended	direct	verbose-and-natural	distant-from-document	single-doc	expert	2025-05-01T22:05:01.292488	20	88	915
144	What are the main symptoms of IBS?	The most common symptoms of IBS are abdominal pain or cramps and frequent changes in bowel movements, alternating between diarrhea and constipation.	['Irritable Bowel Syndrome (IBS) is a chronic gastrointestinal disorder. It is also commonly referred to as functional bowel disease or spastic colon. While there are varying degrees of symptoms among individuals, there are some common factors that can contribute to the discomfort that individuals often experience. Learning about the symptoms and possible triggers for the onset of these symptoms can help to more effectively manage the disorder.\nThe most common symptoms of IBS include:\n• Abdominal pain or cramps\n• Frequent changes in bowel movements, alternating between diarrhea and constipation\nIBS-D is diagnosed when diarrhea (loose stools and urgency to have a bowel movement) is a primary symptom, whereas IBS-C is diagnosed when constipation (hard or infrequent stools and straining with bowel movements) is a primary symptom. Interestingly, while indigestion is not considered to be a symptom of IBS, it occurs frequently in those who suffer from this disorder.\nWhile the cause of the condition is unknown, it is generally thought to be a result of abnormal movement within the gastrointestinal tract. Because the gastrointestinal and neurological systems are interrelated (gut-brain connection), communication between the two systems seems to play a role in flair ups. Those who suffer from IBS tend to be highly in-tune with their bodies (i.e. have good bodily awareness), and many affected individuals find that increased stress can bring on symptoms.\nA diagnosis of IBS is typically made when gastrointestinal symptoms have been present for at least 3 months. Generally, doctors will order medical tests to rule out other conditions associated with these same symptoms before arriving at a diagnosis of irritable bowel syndrome.\nThere is no known cure for the condition, yet there are some diet and lifestyle changes that can help to reduce the symptoms of IBS. Namely, identifying and refraining from foods to seem to trigger symptoms is an important part of managing gastrointestinal symptoms.\nCommon foods that tend to be problematic for IBS sufferers because they often increase gas and bloating include beans and other legumes, and cruciferous vegetables like broccoli or cauliflower. Other helpful diet considerations to reduce symptoms include drinking a healthy amount of water throughout the day, eating foods that are high in fiber, eating smaller portions at mealtimes, and eating a diet that is lower in fat and higher in complex carbohydrates.\nPatients who present to urgent care centers with IBS symptoms are often prescribed anti-diarrheal or anti-spasmodic medications to regulate bowel movements. Laxatives are prescribed when constipation is present. There may be times when antidepressants or other psychiatric medications are prescribed for patients as well, given an individual’s presenting symptoms and needs.\nIrritable bowel syndrome should not be confused with Crohn’s Disease or Ulcerative Colitis. These gastrointestinal disorders involve inflammation and damage to the intestinal tract, requiring proper medical management to prevent worsening of the conditions.\nKeep in mind that symptoms such as blood in the stool, black or tarry stools, vomiting, fever or abdominal pain or bowel movements that interfere with sleep are not characteristic of IBS. These symptoms may be the result of a more serious illness and require further medical evaluation. Your doctor can best determine the cause of your presenting gastrointestinal symptoms and prescribe the most appropriate treatment.']	['<urn:uuid:a2295e2e-2eb3-47b8-a5e6-d60834bf6f79>']	factoid	direct	concise-and-natural	similar-to-document	single-doc	novice	2025-05-01T22:05:01.292488	7	22	535
146	What's bigger - Boston's Museum of Fine Arts or The Tech Museum's BioDesign exhibit?	The Museum of Fine Arts in Boston is significantly larger, containing nearly 500,000 works of art and welcoming over 1 million visitors annually. While BioDesign Studio is described as a permanent exhibit at The Tech Museum, its specific size is not mentioned, but as a single exhibit it would be smaller than the entire Museum of Fine Arts.	"['May 8, 2017 San Jose, CA-- The Tech Museum of Innovation has earned one of the nation’s top honors for museum experiences. BioDesign Studio, an exhibit The Tech opened in 2016, won Silver for Interpretive Interactive Installations at the Media and Technology MUSE Awards, presented by The American Alliance of Museums at a celebration Sunday night.\n“We developed BioDesign Studio to make bioengineering playful, fun and approachable. We’re thrilled to have national recognition of this ambitious effort,” says Anja Scholze, Experience Developer and Program Manager, Biotech & Health, who accepted the award at AAM’s annual meeting. “It was a daunting task to design experiences that would empower everyone, from grade-schoolers to retirees, to explore a complex topic like bioengineering. A year later, it’s humbling to see our visitors walk away with a new understanding and enthusiasm for the possibilities of biotechnology and their own role in it.”\nBioDesign Studio is a permanent exhibit with an array of hands-on experiences that encourage visitors to play, tinker and design with the building blocks of life. At the Creature Creation Station, visitors use custom blocks representing genetic traits to build creatures and unleash them in a digital world where they interact with other organisms. In the Living Colors Lab, they use real lab equipment to alter the DNA of bacteria to change its color, and in the BioTinkering Lab they participate in bioengineering projects like creating bricks using mycelium, or mushroom root, a sustainable building material. The goal is to spark a sense of wonder about the world’s most complex technology: biology.\n“Bioengineering plays an important role in solving many of the world’s biggest problems like hunger and climate change. We’re so happy to see BioDesign Studio visitors not only learning about synthetic biology, but starting to see their own potential to create with it,” said Gretchen Walker, Vice President of Learning at The Tech.\nThe MUSE Awards competition received more than 200 applications from a wide variety of institutions in North and South America, Europe, Australia and Asia. This year’s entries included videos and films, interactive kiosks and installations, VR experiences, applications and APIs, digital communities, websites, audio tours and more.\n""We\'re so pleased to have received this recognition- we worked hard with the brilliant team of scientists at The Tech to create an exhibit about synthetic biology that could last 10 years. We can\'t wait to see the new life forms, biological and digital, that visitors create in the years to come,"" said Ben Millstein, Communications Manager of Local Projects, a New York firm that helped The Tech design the exhibit.\nOver 90 GLAM (Galleries, Libraries, Archives and Museums) professionals from across the globe participated as jurors in the process of reviewing and scoring entries. Winning programs demonstrate outstanding achievement in their content, interface, design, technical merit, innovation, utility and appeal.\nNow in its 28th year, the MUSE awards competition recognizes outstanding achievement in GLAM media and technology efforts. The competition is led by the American Alliance of Museums Media & Technology Professional Network. For more information about the MUSE awards, visit: http://aam-us.org/about-us/grants-awards-and-competitions/muse-awards\nMedia Contact: Marika E. Krause | 408-591-0027 | firstname.lastname@example.org\nAbout The Tech Museum of Innovation\nThe Tech is a hands-on technology and science museum for people of all ages and backgrounds. The museum — located in the capital of Silicon Valley — is a non-profit experiential learning resource established to engage people in exploring and experiencing applied technologies affecting their lives. The Tech Challenge and Tech Awards are signature programs of The Tech. The Tech’s mission is to inspire the innovator in everyone.', ""Museums in Boston MA\n40 Boston Museums\nMuseums are a great way to learn about a city’s history and culture. Boston is home to many world-renowned museums covering a range of topics. From art and science to history and nature, there is something for everyone in Boston museums.\nBoston’s Museum of Fine Arts is one of the largest and most comprehensive art museums globally. With nearly 500,000 works of art on display, it is a must-see for any art lovers visiting Boston. The Museum of Science is another popular destination, offering hands-on exhibits and interactive displays. For history buffs, the Boston Tea Party Museum and the USS Constitution Museum are both located in the city and offer insight into two of the most important events in American history.\nWhether you’re interested in art, science, history, or nature, keep reading as we’re highlighting three of the best museums in Boston. However, we’ve also got you covered with a pocket guide to 40!\nThree Boston Museums You Won’t Want to Miss\nMuseum of Fine Arts\nBoston’s Museum of Fine Arts houses one of the finest, most expansive collections to date, featuring everything from paintings by Van Gogh and Rembrandt to Japanese prints and metalworks. The museum also has one of the best collections of Monet paintings in the world, as well as Oceanic and African art spanning from the 16th to the 20th century.\nBoston’s MFA is open from 10 am – 5 pm on Monday, Thursday, Saturday, and Sunday, with extended hours on Friday from 10 am – 10 pm. Regarding pricing, children under six get in for free, youths 7-17 are $10, and adult tickets are $27. However, Museum members can always get in for free.\nContaining nearly 500,000 works of art and welcoming more than 1 million visitors through its doors every year, Boston’s MFA also hosts many intriguing exhibits. A few ongoing include New Galleries of Dutch and Flemish Art and the Art of Ancient Greece, Rome and the Byzantine Empire.\nBoston Children’s Museum\nThe second oldest children’s museum in the world, the Boston Children’s Museum was founded in 1913 by the Science Teachers’ Bureau — a group of forward-thinking teachers and educators who saw the value in such an endeavor.\nFor over a century, the Boston Children’s Museum has provided children from all over the world with engaging, hands-on learning experiences that teach children about everything — including science, the arts, health and fitness, environmental awareness, and culture.\nArt Lab and Attractions\nThe Art Lab encourages children to express themselves in constructive, healthy, expressive ways — providing them with all the means necessary. Attractions like the Construction Zone and Kid Power teach children about movement and physics in fun, engaging ways. At the same time, the Explore-a-Saurus activity teaches children about dinosaurs and encourages them to think critically about the world surrounding them.\nThe museum is open every day from Wednesday to Sunday. The doors open from 9 am -12 pm and from 1:30 pm – 4:30 pm. General admission tickets for everyone over 12 months cost $18.00. Some discounted tickets are available here.\nMuseum of Science\nOne of the world’s premier science museums, Boston’s Museum of Science features dozens of incredible exhibits. Stroll through the Hall of Human life to learn about our anatomy and physiology. Learn about dinosaurs and other prehistoric life in Colossal Fossil: Triceratops Cliff. Explore cutting-edge technology and local inventions in the Wicked Smart: Invented in the Hub exhibit.\nBut even though Boston’s Museum of Science rests in a huge, bustling city, it also proves a great place to learn about wildlife. The museum features exhibits about the world around us, including Natural Mysteries and New England Habitats. They also have a Live Animal Care Center, where they house over a hundred of their animal ambassadors.\nTickets and Hours\nBoston’s Museum of Science is committed to providing outstanding science education. The museum is open from 9 am – 5 pm every day of the week. Children under three and Museum Members can enter for free. Ticket prices vary; it’s $24 for children aged 3-11, $29 for adults, and $24 for Seniors. Since the museum has limited capacity and timed tickets, consider ordering them in advance.\nMuseums in Boston MA\n|America's Fleet Museum||5 Water St||Fall River||http://www.BattleShipCove.org|\n|Boston African American National Historic Site||14 Beacon St Ste 401||Boston||http://www.nps.gov/boaf/index.htm|\n|Boston Fire Museum||344 Congress St||Boston||http://www.bostonfiremuseum.com|\n|Boston Tea Party Ship & Museum||306 Congress St||Boston||http://www.bostonteapartyship.com|\n|Children's Museum||41 Walnut St||Boston||http://childrensmusicnetwork.org|\n|Danforth Museum of Art||123 Union Ave||Framingham||http://www.DanForthMuseum.org|\n|deCordova Sculpture Park and Museum||51 Sandy Pond Road||Lincoln||http://www.deCordova.org|\n|Discovery Museum||177 Main St||Acton||http://www.discoveryacton.org|\n|Dreamland Wax Museum||1 Washington Mall||Boston||http://www.DreamlandWaxMuseum.com|\n|Galerie D'orsay||33 Newbury St||Boston||http://www.galerie-dorsay.com|\n|Gibson House Museum||137 Beacon St||Boston||http://www.thegibsonhouse.org|\n|Gore Place||52 Gore Street||Waltham||https://goreplace.org|\n|Harvard Art Museums||32 Quincy Street||Cambridge||https://harvardartmuseums.org|\n|Harvard Natural History Museum||26 Oxford St||Cambridge||http://www.HMNH.harvard.edu|\n|Holocaust Memorial New England Friends||126 High St||Boston||https://www.cjp.org|\n|Hull Lifesaving Museum & Life||22 Drydock Ave||Boston||https://www.hulllifesavingmuseum.org|\n|Institute Of Contemporary Art||100 Northern Ave||Boston||https://www.icaboston.org|\n|Isabella Stewart Gardner Museum||25 Evans Way||Boston||https://www.gardnermuseum.org|\n|John F. Kennedy Presidential Library and MuseumColumbia Point||Columbia Point||Boston||http://www.JFKLibrary.org|\n|Metropolitan WaterWorks Museum||2450 Beacon St||Boston||http://www.WaterWorksMuseum.org|\n|MIT Museum||265 Massachusetts Ave||Boston||http://mitmuseum.mit.edu|\n|Museum Of African American History||46 Joy St||Boston||https://www.maah.org|\n|Museum Of Fine Arts Boston||456 Huntington Ave||Boston||https://mfa.org|\n|Museum Of Science||1 Science Park||Boston||http://www.mos.org|\n|Natural Heritage Museum||33 Marrett Road||Lexington||http://www.NationalHeritageMuseum.org|\n|New England Aquarium||1 Central Wharf||Boston||http://www.NEAQ.org|\n|Nichols House Museum||55 Mount Vernon St||Boston||http://www.nicholshousemuseum.org|\n|Old South Meeting House||310 Washington St||Boston||http://www.oldsouthmeetinghouse.org|\n|Old State House||206 Washington St||Boston||http://www.bostonhistory.org|\n|Otis House||141 Cambridge St||Boston||https://www.historicnewengland.org|\n|Paul Revere House||19 North Sq||Boston||https://www.paulreverehouse.org|\n|Paul S. Russell, Md Museum Of Medical History And Innovation At Massachusetts General Hospital||2 Grove St||Boston||https://www.massgeneral.org/museum|\n|Peabody Essex Museum||161 Essex St||Salem||http://www.PEM.org|\n|Shirley-Eustis House||33 Shirley St||Boston||https://www.shirleyeustishouse.org|\n|Spellman Museum of Stamps and Postal History||241 Wellesley St||Weston||http://www.SpellmanMuseum.org|\n|The Children's Museum||300 Congress Street||Boston||https://bostonchildrensmuseum.org|\n|The Sports Museum||100 Legends Way||Boston||https://sportsmuseum.org|\n|USS Constitution Museum||Charleston Navy Yard Building 22||Boston||http://www.USSCM.org|\n|West End Museum||150 Staniford St Ste 7||Boston||https://thewestendmuseum.org|\n|William Hickling Prescott House||55 Beacon St||Boston||https://nscda.org|\nDid we leave your theater off the list? Send us the info and we’ll be sure to add it.\nDon’t Miss Out on Things to Do!\nAdd Your Email to OTL’s Private Email List\nFrequently Asked Questions\nDinosaurs and prehistoric life are on display at Boston’s Museum of Science. There’s also a Live Animal Cave, cutting-edge inventions, and plenty more for kids and kids at heart.\nBoston has dozens of museums throughout the city and suburbs. Some of the must-sees include the Museum of Fine Arts, Boston Children’s Museum, the Paul Revere House, the Institute of Contemporary Art, and the Harvard Natural History Museum.\nYes. The Boston Children’s Museum is a fun place for toddlers to teens (and adults, too!). It features hands-on experiences with an Art Lab, Construction Zone, and plenty more to keep visitors busy for hours!""]"	['<urn:uuid:bc4a31d2-0b3c-449b-98d5-2e19d3a76db3>', '<urn:uuid:fa97bf19-d7b4-4825-af1c-5d8aa6cec544>']	factoid	with-premise	concise-and-natural	distant-from-document	comparison	novice	2025-05-01T22:05:01.292488	14	58	1684
148	I'm curious about famous painters - did both Metro Meteor and Franz Josef Kline create abstract art pieces that were sold commercially?	Yes, both Metro Meteor and Franz Josef Kline created abstract art that was sold commercially. Metro created hundreds of abstract paintings featuring colors and textures built up in layers, which were sold through a Pennsylvania art gallery. Franz Josef Kline's abstract work was also commercially successful - one of his abstract collages sold for $120,000 at Shannon's Fine Art auction.	['Metro Meteor the Acclaimed Painting Horse Retires\nMetro Meteor was a fierce competitor at the track winning 8 turf sprints and earning $300,000. After 3 years racing and 2 knee surgeries, Metro was no longer competitive and retired. Ron and Wendy Krajewski, who owned a percentage of Metro, decided to adopt him for themselves. They would give him a safe, forever home and enjoy trail riding. At least that was the plan.\nAs with many plans, this best-laid one went awry. As Metro settled into his new surroundings, a boarding facility near the Krajewski’s home, it became evident that his bad knees were getting worse. Treatment offered temporary relief, but his prognosis was poor, riding was out of the question.\nAs the Krajewski’s spent more time with Metro they realized he was quite a character, bobbing his head for attention and grabbing things left within reach. It occurred to Ron, an avid artist, that Metro might be able to hold a brush in his mouth and perhaps even paint. That revelation changed their lives.\nArtist at Work\nFour years later, Metro has created hundreds of paintings and become a media sensation. Collectors around the world have been quick to snap up a Metro original. At times, the waiting list for his next painting numbered over 100. He was the top selling artist, horse or human, at a Pennsylvania art gallery.\nThe Krajewski’s rented a second stall converted into Metro’s painting studio. Ron, working as Meteor’s assistant, secured a canvas to the easel and dipped brushes in paint. Metro enthusiastically applied his vision holding the brush in his mouth and turning his head to form colorful strokes. The duo usually worked an hour or two several days each week.\n“Metro doesn’t have any edge control,” Ron said. “His paintings are all about colors and textures. So, we’ll do a little bit one day, let it dry, and then come back and do different colors the next day, let it dry. What we do is we build it up in layers. What you’ve got is layers from several days that are peeking through these really thick, broken brush strokes that he has. It really creates an interesting texture. You’ve got colors peeking through colors, and they just kind of vibrate”.\nPay It Forward\nAs Metro’s paintings began to sell, the Krajewski’s established the “Metro Fund” giving half of Metro’s sales to New Vocations Racehorse Adoption Program. New Vocations, located in Pennsylvania, works to retrain ex-racehorses and find them new homes. Transitions for thoroughbreds and saddlebreds like Payasito, Shotgun City and Fast Double G were funded by the Metro Fund’s $80,000 plus donations.\nFor nearly 5 years, this prolific horse has been painting and helping other OTTBs until life once again interceded. For personal reasons, the Krajewski’s are moving and unable to take Metro and his barn mate Pork Chop. The horses will live out their days with Metro’s veterinarian enjoying pasture turnout, naps in the sun and the occasional Twizzler (Metro’s favorite treat). Without Ron’s help, there will be no more paintings. Metro was officially retired on February 28th.\n“We invite people to continue following Metro’s FB page, we’ll do our best to keep you updated, but he is retired. It will probably just be a bunch of photos of him eating grass,” said Ron.\nHappy Retirement Metro Meteor!\nIt was an emotional moment for Ron as Metro worked on his last painting. Ron wanted it to be personal, a portrait of Metro and Pork Chop that he and Wendy could take with them when they move. The paints he set out for Metro were deliberately chosen, representing the colors of the horses and their turnout sheets, bay and blue for Metro, chestnut and green for Pork Chop – “Brothers in Charm”.\nPLAY OUR GAME – METRO VERSUS MAN\nMetro is a uniquely talented horse artist but how does his art compare to the masters of abstract expressionism? Below are 9 paintings, can you tell which were painted by Metro? Tap the question below each painting to flip the card and see if your guess was correct. Good luck!\n“Villa Borghese” was painted by Willem de Kooning in 1960\n“Black Reflections” was painted by Franz Kline in 1959\n“Coffee Cake” was painted by Metro\n“Poe’s Raven” was painted by Metro\n“All Green” was painted by Mary Abbott in 1954\n“Vernal Yellow” was painted by Lee Krasner in 1980\n“Flowering Desert” was painted byHans Hofmann in 1953\n“Root Beer Float” was painted by Metro\n“Totemic Figure” was painted by Robert Motherwell in 1958', 'Auction Report: Curran’s ‘Far Away Thoughts’ Tops October Art Sale Returns\nThe top lot of the sale was this oil-on-canvas piece by Charles Courtney Curran, titled “Far Away Thoughts,” which sold for $192,000.\nMILFORD, Conn. — An oil-on-canvas painting titled “Far Away Thoughts” by the American genre and landscape painter Charles Courtney Curran (1861-1942), sold for $192,000 at Shannon’s Fine Art Auctioneers’ fall fine-art auction held Oct. 24.\nCurran was a prolific painter, known for his light-filled renderings, often of young women. This painting was a prime example of his work. It was also the top lot of the auction.\nThe painting, which depicts a young woman striking a wistful pose, was signed by the artist and has been slated for inclusion in the upcoming catalogue raisonne of Curran’s works by Kaycee Benton.\nIn all, 300 paintings came up for bid in a sale that grossed more than $2.4 million. About 80 people attended the auction in person, while another 600 registered to bid online via Artfact.com. A full bank of 20 phones saw heavy use throughout the evening. “Overall we were quite pleased,” said Gene Shannon of Shannon Fine Art Auctioneers.\nFollowing are additional highlights from the auction. All prices quoted include a 20 percent buyer’s premium:\nA rediscovered abstract collage by the abstract-expressionist master Franz Josef Kline gaveled $120,000.\n• A rediscovered oil-on-paper abstract collage by American abstract-expressionist master Franz Josef Kline (1910-1962) realized $120,000, and a 1951 oil painting by Fernando Amorsolo (1892-1972) of a young woman bathing in an outdoor stream with a female attendant went for $60,000;\n• A one of a pair of large and rare oil-on-canvas views of Niagara Falls by Ferdinand Richardt (1819-1895), titled “View of Niagara Falls,” hit $66,000;\n• Guy Carleton Wiggins (1883-1962) was famous for his snowy Manhattan street scenes. One such work, a oil-on-canvas piece titled “St. Patrick’s in Winter,” brought $60,000;\n• Also, an untitled oil-on-paper work from American artist Michael Goldberg, made $50,400;\n• An oil-on-canvas painting by John Koch (1909-1978) titled “Christmas Tree” breezed to $42,000;\nTwo scenes of Niagara Falls by Ferdinand Richardt came up for bid. This one, titled “View of Niagara Falls,” brought $66,000.\n• Two marine paintings by Antonio Jacobsen (1850-1921), titled “Defender” and “Tidal Wave and the Dreadnought,” both oil-on-board works, commanded $40,800 and $24,000, respectively;\n• An oil-on-panel marine painting by James Edward Buttersworth (1817-1894), titled “Off Sandy Hook,” one of about 600 works by the artist depicting subjects he observed in the waters off New York, rose to $36,000, and an oil-on-canvas coastline scene by Emil Carlsen (1848-1932), titled “Full Tide Coast of Maine,” brought $36,000;\n• Multiple offerings from the iconic pop artists Andy Warhol (1928-1987) and Roy Lichtenstein (1923-1977) were in the sale. Five Warhols came up for bid, including three from his Martha Graham series. One of those, titled “Letter to the World (The Kick)” gaveled for $38,400. Three Lichtensteins were offered; the top achiever titled “Crak!,” which sold for $26,400.\nFor more information, visit Shannon’s Fine Art Auctioneers’ website.\nWorthPoint—Discover Your Hidden Wealth']	['<urn:uuid:044b2f9a-1598-4bf2-888a-b3a08be359a6>', '<urn:uuid:6724ce2a-3226-4a7d-9d66-d6f97db8eaf3>']	factoid	with-premise	verbose-and-natural	similar-to-document	comparison	novice	2025-05-01T22:05:01.292488	22	60	1269
149	When do Orthodox Christians celebrate Christmas according to their calendar?	Eastern Orthodox Christians celebrate Christmas on December 25 in the Julian calendar, which corresponds to January 7 in the Gregorian calendar.	['If you’re looking for an orthodox saints calendar, you’ve come to the right place. This calendar provides detailed rubrics for each day of the year, including the major feast days as well as lesser feasts. It also provides appointed Scripture readings for every day of the year.\nGregorian saints’ feast day\nThe difference in calendars between Orthodox Christians and those who follow the Gregorian calendar is not a small one. The differences between the two calendars are the result of changes in the historical, political, and astronomical contexts. Historically, the Orthodox Church has used the Julian calendar. The calendar’s beginning date is the Indiction on September 1.\nThe Greek Orthodox Church changed the calendar in 1923, when it held its “pan-Orthodox” synod. This was less of a general synod than a local synod, and it made revisions to the “Old” Julian calendar. This calendar was in use for nearly 1,600 years before the Gregorian calendar was introduced.\nThe Eastern Orthodox Church adopted the Gregorian calendar for fixed feasts in the early 20th century, but still uses the Julian calendar for Easter. The Julian equinox corresponds to the Gregorian date of April 3; Orthodox Easter is the Sunday following the first full moon after the equinox.\nOrthodox fast days\nOrthodox fast days are observed on certain days of the year. For example, on April 16th, Orthodox Easter celebrates the resurrection of Jesus from the dead. This day falls after Good Friday and is the most important day of the Orthodox liturgical calendar. It is observed by the Orthodox Churches of Romania, Russia, and Greece, as well as in other countries around the world.\nOrthodox fasting days are a way for Orthodox Christians to get closer to God. It is a time for self-reflection and contemplation, as well as a time to give up destructive practices. In addition to fasting, Orthodox Christians also avoid eating meat products during this time. They may enjoy fish and olive oil, but should avoid eggs and dairy products during this time.\nEastern Orthodox Christians celebrate Christmas on December 25, while the Catholics and Protestants celebrate it on January 7. The Orthodox calendar, known as the “New Calendar”, is based on the Julian calendar. It is approximately one month behind the Gregorian calendar.\nAll Saints Day\nThe Eastern Orthodox calendar has a unique way of marking the day of All Saints. Orthodox churches celebrate All Saints Day on the first Sunday after Pentecost, which falls sometime in early June or early July. The feast day is a day of celebration of the saints who have died for the faith.\nThe calendar is divided into 12 days, each corresponding to a major feast of the Orthodox Church. The calendar also includes martyrs of the early church. It is important to remember the day of All Saints, as they are commemorated in the calendar. This calendar has twelve great feast days and also lists popular saints of Orthodox Churches throughout the world.\nDuring this day, people gather to remember deceased relatives and friends. Some families make offerings to the dead. Others decorate graves with flowers and light candles.\nAn Orthodox Easter calendar is a calendar that commemorates the resurrection of Jesus Christ. Jesus was crucified, buried in a tomb, and was raised on Easter Sunday. On this day, a candle was lit to mark his resurrection. The church was dark, except for the candles. During this service, the risen Jesus appeared to his disciples and apostles. He then ascended into heaven. An Orthodox Easter calendar is based on the Julian calendar, and the holiday is a few days after the Jewish Passover.\nIn Canada, Orthodox Easter Sunday is observed on April 24. It falls after Lent, which is a period of fasting. Many Orthodox Christians also decorate their Easter eggs in red, symbolizing the blood of Jesus Christ. Many families will begin their Easter meal by knocking and breaking painted eggs, declaring, “Christ is risen!” Those who manage to break the most eggs will be declared the winner. In the United Kingdom, Orthodox Easter Sunday is a non-working day.\nIn the past, Easter dates were determined by astronomical calculations. The date was set using an imaginary moon called the ecclesiastic moon. This fixed date was the first full moon after the vernal equinox. This date has changed over time, and the date of Easter is slightly later in the Orthodox world.']	['<urn:uuid:ca9fa326-f2e8-4c3d-afec-35e781725010>']	factoid	with-premise	concise-and-natural	similar-to-document	single-doc	expert	2025-05-01T22:05:01.292488	10	21	732
150	What are the different stages of copper extraction from mines, and what health risks are associated with mining operations?	Copper extraction involves multiple stages: first mining the ore from open pits or underground mines, then crushing and processing the ore, followed by concentration, smelting, and refining to produce pure copper cathodes. The process can use either sulfide or oxide ores and typically takes place at both the mine site and separate refining plants. Regarding health risks, mining operations expose workers to harmful substances like dust, radon, and mercury. Additionally, the chemicals used in mining processes can contaminate groundwater and surface water, potentially affecting both miners' and local communities' health.	"['what is the copper mining process\nCopper Production Official Site of Copper Development\nwhat is the copper mining process From its original home buried underground in a mine to its use in a Copper Production ; Copper The next step in the process flow is smelting for sulfide ore\nMining is extraction of valuable minerals or other geological materials from the earth usually from an orebody, lode, vein, seam, reef or placer deposits.\nHow copper is made material, used, processing, steps\nThe development of more efficient processing techniques in the late-1800s allowed the mining of lower-grade copper ores from to process and refine copper\nCopper Refining: From Ore to Market | Investing News Network\nAfter concentration is complete, the next phase is copper refining. That typically takes place away from the mine, at a refining plant/smelter. The details of the copper refining process depend on the type of minerals the copper is bound with.\nCopper Process Plant Mining Processing Machine|Crushing\nVI:We can design 45T/H, 60T/H, 90T/H, 100T/H, 120T/H production plant. VII：The strong point of Shanghai Daiwo Mining Machinery Co., Ltd. 1.Design the professional\nCopper Mining & Extraction Process Flow Chart\nwhat is the copper mining process This flowchart made of machinery icons explains or expresses in simple but clear terms the step of the Copper Mining and Copper Extraction Process. Starting from\nCopper Mining and Processing: Processing of Copper Ores\nCopper processing is a complicated process that begins with mining of the ore (less than 1% copper) and ends with sheets of 99.99% pure copper called cathodes, which will ultimately be made into products for everyday use.\nCopper Mineral Fact Sheets Australian Mines Atlas\nCopper Fact Sheet: Minerals Australia\'s main copper mining centres are in the Mount Isa/Cloncurry region of In this process copper concentrate is fed into the\nCopper mining. From ore to copper. SchoolScience.uk\nPart of an interactive on-line booklet about copper mining explaining the early, physical stages in the process.\nCopper Mining and Refining (Redox) YouTube\nwhat is the copper mining process 4 min video clip shows how copper is mined. It also shows the reduction process showing copper being …\nWhat is copper mining process? Quora\nwhat is the copper mining process What are the reasons that copper deposit rich countries don\'t sale end products (like sections, sheets tubes etc.) of copper and sale only hal\nNickel Mining and Processing: Everything you Need to Know\nThird in our mining series, find out all you need to know about nickel mining and processing from General Kinematics.\nPowerPoint Copper Processing | Resources | Oresome\nCopper Processing PowerPoint. Find out how copper ore is extracted and turned into copper metal. This is a PowerPoint presentation showing the properties, uses and extraction of copper. It includes details of the mining and processing of copper ore as well as smelting, converting and refining to produce copper metal.\nThe Mining Process at Copper Mountain Mine YouTube\nwhat is the copper mining process The Mining Process at Copper Mountain Mine CopperMountainMining. Loading Unsubscribe from CopperMountainMining? Lumawan Copper Mine …\nCopper extraction Wikipedia\nCopper extraction refers to the methods used to obtaining copper from its ores. The conversion of copper consists of a series of chemical, physical, and electrochemical processes. Methods have evolved and vary with country depending on the ore source, local environmental regulations, and other factors.\n1.1 PHASES OF A MINING PROJECT Home | ELAW\n1.1 PHASES OF A MINING PROJECT (a process called ‘hydraulic mining’) (copper)). If a mining project involves the extraction of a few\nOre Copper Mining Process sq1\nwhat is the copper mining process Copper mining process Types iron ore mining equipment,iron … Copper Mining Info. The above flowsheet shows a basic copper mine process, from mine to metal.\nCopper Mining and Processing: Everything you Need to Know\nwhat is the copper mining process The Basics of Copper Mining and Processing. Mined from open pits, copper ore must be crushed as part of the process that occurs between extraction and production. Using today’s compact mining equipment, copper ore is extracted from the mine.\nwhat is the copper mining process thoughtmedia.us\nCopper mining process, copper mine processing, Sulphide Copper Ore processing, Oxide copper ore processing, copper crushing, copper concentrate, Get Price;\nCopper mining. The main stages. SchoolScience.uk\nwhat is the copper mining process Part of an interactive on-line booklet about copper mining showing the basic steps in mining and purifying copper.\nInnovations: Introduction to Copper: Mining & Extraction\nCopper minerals and ores are found in both igneous and sedimentary rocks. Mining of copper ores is carried out using one of two methods. Underground mining is achieved by sinking shafts to the appropriate levels and then driving horizontal tunnels, called adits, to reach the ore.\nCopper Mining and Refining (Redox) YouTube\n4 min video clip shows how copper is mined. It also shows the reduction process showing copper being …\nCopper Production: How Is Copper Made? The Balance\nCopper is typically extracted from oxide and sulfide ores that contain between 0.5 and 2.0 percent copper. The refining techniques employed by copper producers depend on the ore type, as well as other economic and environmental factors.\nProcesses copper mining and production\nwhat is the copper mining process Copper is found in natural ore deposits around the world. This page explains the copper mining and production route from ore-containing rock to a final product that\n3 Technologies in Exploration, Mining, and Processing\nRead chapter 3 Technologies in Exploration, Mining, Mining, and Processing."" National Research used in the leachprecipitation-flotation process for copper.\ncrushing coal crusher Coal crushing plant - Mining, crushing, grinding, Mining ...Coal crushing plant, coal crusher, ... Compressive Crusher Compressive crushe...\nriver rock screening equipment Small Rock Screening Equipment | Crusher Mills, Cone ...small rock screening equipment rental. Inflatable Bounce House Rentals i...\nold gravel crushing plants sale gravel crushing plants - XSM - Stone Crusher Machinesale gravel crushing plants from XSM. Shanghai XSM (sale gravel crushing pl...\nstone crusher plant manual kenya manual stone crushing machines in kenya | Mining & Quarry ...stone crusher plant manual kenya manual stone crushing machin...\nstone crusher archives Stone Crushers Archives - Williams Plant HireGET IN TOUCH Got a question? Let us know, call 01938 552 337 | 01686 630 244 or submit an e...', ""Mining has several bad effects. It leaves behind a huge hole after mining is done. Secondly it damages natural beauty. A beautiful landscape which once existed is now a huge piece of dug up earth.\nEnvironmental Effects. Environmental issues can include erosion, formation of sinkholes, loss of biodiversity, and contamination of soil, groundwater and surface water by chemicals from mining processes. In some cases, additional forest logging is done in the vicinity of mines to create space for the storage of the created debris and soil.\nThe effects of mining in Africa have left large-scale devastation when companies do not honour their responsibility. Because mining areas are left in an unsustainable condition, plant species and wildlife are threatened and these areas are at risk of becoming lifeless wastelands.\nThe Impact and Effect of Illegal Mining (galamsey) towards the Socio-economic Development of Mining Communities: A Case Study of Kenyasi in the Brong Ahafo Region Adjei Samuel1, N.K.Oladejo1, I.A. Adetunde2, * 1University for Development Studies, Department of Mathematics, Navrongo. Ghana.\nSome of the major effects of mining on the environment are as follows: Minerals are the natural resources which play an important role in the economic development of the country. But the extraction and mining of these natural resources leads to some adverse effect on our environment as well.\nMar 09, 2017· The mining industry has the potential to disrupt ecosystems and wipe out wildlife populations in several different ways. Here's how mining affects the environment and wildlife. Habitat Loss; Mining can lead to the destruction of habitats in surrounding areas. The …\nModern mining is an industry that involves the exploration for and removal of minerals from the earth, economically and with minimum damage to the environment. Mining is important because minerals are major sources of energy as well as materials such as fertilizers and steel.\nApr 25, 2017· Mining is the extraction of minerals and other geological materials of economic value from deposits on the earth. Mining has the potential to have severely adverse effects on the environment including loss of biodiversity, erosion, contamination of surface water, ground water, and soil.\nSome gold can be found by panning in rivers; heavy gold will remain in the pan, whereas lighter rocks and minerals float out. This small-scale form of gold mining has little effect on the body of water, but the large-scale practice of mining gold from ore can have tremendous negative effects on water quality.\nMining can effect the earth because first, deforestation, and because mining requires large portions of land to be removed before they can start mining, lots of trees and plants are removed.\n1.1 PHASES OF A MINING PROJECT There are different phases of a mining project, beginning with mineral ore exploration and ending with the post-closure period. What follows are the typical phases of a proposed mining project. Each phase of mining is associated with different sets of environmental impacts. 1.1.1 Exploration\nFeb 07, 2018· The effects in such cases can be devastating for the environment. Be it due to ignorance of the regulations or just a freak accident, incidents like the Guyana spill of 1995 may occur again. This highlights the fact that issues like mining's effect on the environment are worth some serious deliberation.\nAug 26, 2010· Dust, radon and mercury impact miners' health. Dust, radon and mercury impact miners' health. ... Miners Face Health Risks, Even on Good Days ... mining …\nThe effects of mining coal on the environment. There are 2 ways to mine coal – Strip Mining and Underground Mining – both ways have their own impact to the environment and health. We know it but coal is such a cheap energy source that we don't want to let go of it. The negative effects of coal mining cannot be disputed:\nApr 21, 2019· The human health effects due to cyanide leach gold mining are not well documented, and this is no exception in Montana. The State of Montana has done no formal studies to specifically study mine-related health effects. Pegasus, the last mining company at Zortman-Landusky, started to fund a health study with the $1.7 million supplemental money from the 1996 settlement, but because …\nADVERTISEMENTS: Some of the major environmental effects of mining and processing of mineral resources are as follows: 1. Pollution 2. Destruction of Land 3. Subsidence 4. Noise 5. Energy 6. Impact on the Biological Environment 7. Long-term Supplies of Mineral Resources. Mining and processing of mineral resources normally have a considerable impact on land, water, […]\npositive and negative effects of mining on the environment. Mankind has been mining for precious metals since 42000 years ago and that's a staggeringly long time ago and that's exactly how long our species has been digging into the ground, to harvest its precious metals.\nDownload Coal Mining sounds ... 76 stock sound clips starting at $2. Download and buy high quality Coal Mining sound effects. BROWSE NOW >>>\nMining affects the environment by exposing radioactive elements, removing topsoil, increasing the risk of contamination of nearby ground and surface water sources, and acidification of …\nApr 20, 2015· Effects of Mining. Coal mining, the first step in the dirty lifecycle of coal, causes deforestation and releases toxic amounts of minerals and heavy metals into the soil and water. The effects of mining coal persists for years after coal is removed.\nJul 25, 2018· Environmental impacts from fossil fuel pollution are rapidly increasing in regions that have the highest concentrations of fuels. There are multiple effects of mining fossil fuels. Drilling and mining practices take a substantial toll on local water sources, biologic life and natural resources.\nPublished by the American Geosciences Institute Environmental Awareness Series. ... How can metal mining impact the environment? PDF version. Material adapted from: Hudson, T.L, Fox, F.D., and Plumlee, G.S. 1999. Metal Mining and the Environment, p. 7,20-27,31-35,38-39. Published by the American Geosciences Institute Environmental Awareness Series.\nMining operations usually create a negative environmental impact, both during the mining activity and after the mine has closed. Hence, most of the world's nations have passed regulations to decrease the impact. Work safety has long been a concern as well, and …\nEffects of mining on aquatic resources are both physical and chemical in nature. Most of earthmoving activities of mining occurred well before the enactment of laws designed to protect aquatic resources - particularly the 1977 Federal Water Pollution Control Act.\nThe former is known as underground mining, the latter as strip mining or mountaintop removal. Either process contributes a high level of damage to the environment: #12 Noise pollution. One of the most obvious (albeit perhaps least harmful) environmental effects of coal mining is noise pollution.\nMining has an adverse effect on soil quality. Soil degradation is the prime impact. Another impact is deforestation and loss of fauna and flora.\nThe impact of mining on the environment and the effects of mining techniques need to be more advanced with the utilization of modern equipment to be unintrusive to the environment. Economic growth is high on the agenda of leading countries, sustaining …\nMining is an inherently invasive process that can cause damage to a landscape in an area much larger than the mining site itself. The effects of this damage can continue years after a mine has shut down, including the addition to greenhouse gasses, death of flora and fauna, and erosion of land and habitat.\nNov 14, 2016· After mining is over, the land is left as barren land. The effects of mining sometimes vary depending on what is mined out, but these are some of the general effects you will see in all mine-areas. I'm not an expert when it comes to health impact on miners, but here are some of the things I know will affect them-\nJul 08, 2017· In coal mining, the extraction, crushing, and transport of coal can generate significant amounts of airborne respirable (extremely fine) coal dust. Dust less than 10 microns in size (cannot be seen with the eye). In non-coal mining, stone, and san...\nEnvironmental impacts of mining can occur at local, regional, and global scales through direct and indirect mining practices. Impacts can result in erosion, sinkholes, loss of biodiversity, or the contamination of soil, groundwater, and surface water by the chemicals emitted from mining processes. These processes also have an impact on the atmosphere from the emissions of carbon which have ...\nApr 04, 2017· The Dangerous Effects of Illegal Mining. April 4, 2017 Environmental Issues Written by Greentumble. Illegal mining has been ravaging our planet for. decades. Not only is illegal mining riskier from a safety perspective for those who choose to participate, but it encourages reckless behavior and leads to outcomes that have negative long-term ...""]"	['<urn:uuid:e28d868b-40e6-4d4e-83e3-5c1e083196e5>', '<urn:uuid:11ce18f5-51f7-4dfa-a26b-c4a5796e1622>']	factoid	direct	verbose-and-natural	similar-to-document	multi-aspect	novice	2025-05-01T22:05:01.292488	19	90	2497
151	Why are birds especially at risk from self-cleaning ovens?	Birds have highly efficient respiratory tracts that deliver toxins quickly through their bodies, making the fumes from self-cleaning ovens potentially fatal for them.	['What Are the Dangers of a Self-Cleaning Oven?\nUsing the self-cleaning feature on your oven helps avoid the toxic fumes associated with aerosol oven cleaners and the messy cleanup afterward, but in some instances the self-cleaning feature could be just as dangerous. Following the self-cleaning directions provided by the oven manufacturer can help alleviate some of the dangers, but taking a few extra precautions when using this feature can keep your family and your pets safe.\nBefore You Begin the Cycle\nYour manufacturer warns of what to do and what not to do when using the self-cleaning cycle. Reading your manual thoroughly provides you with a list of safety precautions to take before setting the oven to self-clean. Attempting to use the self-clean feature with a damaged oven gasket reduces the effectiveness of the seal around the oven door. Ensuring all items are removed from inside the oven is essential to reducing the amount of fumes produced by the oven during the cleaning cycle.\nCarbon Monoxide Poisoning\nAccording to the North Iowa Municipal Electric Cooperative Association, your self-cleaning oven can produce a concerning amount of carbon monoxide during the cleaning cycle. Cleaning oven spills when they occur can help reduce the amount of carbon monoxide produced because it is the baked-on, charred foods in the bottom of the oven that creates carbon monoxide as they burn. If you cannot remove the baked-on foods, make sure to vent the area and use the kitchen exhaust fans to help dissipate the carbon monoxide.\nAsthma and Respiratory Issues\nIf you or a member of your family suffers from asthma or any upper respiratory disease, simply venting the area may not be enough to keep you safe. The North Texas Poison Center suggests leaving the home during the self-cleaning cycle. The Teflon coating inside the oven is safe when you bake and broil food items, but the oven heats to 600 degrees Fahrenheit or more during the cleaning cycle and can produce toxic Teflon fumes. These fumes can cause flulike symptoms, such as chills, coughing, sweating and breathing difficulties.\nRemoving your pets from the home, even when you open all the windows during oven cleaning, is a must to keep them safe. While not all animals may be affected by the fumes, animals that are more susceptible to Teflon toxicity could die even when placed in another area of your home. Birds are the most likely to succumb to the toxic fumes known as polytetrafluoroethylene (PTFE) toxicosis, according to PetEducation.com. Birds’ respiratory tracts are designed to deliver high levels of oxygen to the flight muscles; these same highly efficient respiratory tracts deliver toxins quickly through birds’ bodies, making the fumes produced by self-cleaning ovens an automatic death sentence.\nCecilia Harsch has been writing professionally since 2009. She writes mainly home improvement, health and travel articles for various online publications. She has several years of experience in the home-improvement industry, focusing on gardening, and a background in group exercise instruction. Harsch received her Certified Nurses Assistant license in 2004. She attended Tarrant County College and studied English composition.']	['<urn:uuid:866af810-a855-4227-9858-9e955f2d1729>']	factoid	direct	concise-and-natural	similar-to-document	single-doc	novice	2025-05-01T22:36:12.692263	9	23	513
152	How do doctors detect serious medical conditions like epilepsy and brain tumors in patients using brain monitoring?	EEG is clinically used in the detection and characterization of epileptic seizures, brain lesions (from tumors, stroke or others), coma, monitoring in anesthesia or in the study of sleep.	['EEG provides a window into the functioning brain. By observing behavior and brain activity, neuroscience researchers can gain insight into how the two are correlated. Typically this involves monitoring EEG during well defined brain states or in cognitive tasks. EEG is also clinically used in the detection and characterization of epileptic seizures, brain lesions (from tumors, stroke or others), coma, monitoring in anesthesia or in the study of sleep, for example. Recently, we and other research groups have been developing EEG biomarkers for neurodegenerative diseases such as Parkinson’s or Alzheimer’s disease, with promising results. Our technologies, Enobio and Starstim now make it possible to easily record quality EEG in the lab, clinic or at home for any of these applications.\nPatients can use neurofeedback to learn to modulate their EEG using audiovisual feedback of their brain activity – an approach shown to be effective in ADHD, for instance.\nEEG provides a unique opportunity in terms of temporal resolution, wearability and cost compared to other neuroimaging techniques when it comes to potential Human Computer Interaction applications. The field of Brain Computer Interfaces (BCI) is largely based on EEG for these reasons. Another field, known as Affective BCI, seeks to develop measures of the affective state of a user based on their EEG and other physiological measures.\nTranscranial Current Stimulation (tCS or tES as it is also called, including tDCS, tACS and tRNS) is a non-invasive form of electrical neuromodulation. It is being intensely used in basic neuroscience and clinical research. Recent studies by several groups worldwide indicate that tCS holds significant potential in the treatment of chronic pain, stroke rehabilitation, depression, addiction and cognitive enhancement.\nI would like to tell you a story today that started 40 some years ago.\nWhen my siblings and I were little, our mom would have us play a fun game … well, I remember this happening around 1975. The game was … telepathy and you have probably played it, too. We would all sit in a circle for a while and in turns try to transmit each other words, images or other thoughts. Could we communicate this way with each other? Concentrate hard and …\nNeedless to say, we didn’t really make much progress during those early experiments, but the game was productive because it was thought provoking. How could we make this work? It seemed natural enough! Imagine what we could do if we could share thoughts, emotions, sensations... It would be awesome! How would we use this gift? What would you do?\nAs it turns out, I’ve had the privilege of leading a team of researchers from around the world that recently demonstrated for the first time that it is possible to establish direct, conscious brain-to-brain communication using technology, no paranormal powers involved. But before telling you how we did it let me provide some context.\nI am a vocational physicist, since I was a kid and in my humility I’ve wanted to understand the universe. I believe our bodies and minds and the subjective experiences they create are really grounded on observable, solid physical laws – nothing else – and that brains and even minds can be studied using science.\nThe physical brain interacts with body and then the external world through our senses, computing, exchanging information. Picturing, modeling, imagining what is out there. How does the brain do it?\nIf we figure out the basics, interacting directly with the brain – with the mind – will become an engineering problem. Hard – certainly – but also doable sooner or later.\nSo, how would we send a thought from a brain to another, what does that mean?\nWe need to achieve 3 things. The first one is to extract the information from the brain of the sender, you have to capture the thought that is to be sent. Once you do that, you need to transmit the message over some medium. This is easy, everything is digital and the internet for instance can be used (or smoke signals, it doesn’t matter). The last step is especially challenging. You have to insert the information into a second brain. You have to create a thought in the recipient without her relying on the senses.\nThe brain is an electrical organ. Electricity and more generally electromagnetism, the family of physical phenomena governed by Maxwell’s equations, mediates the transmission and processing of information in the nervous system.\nNeurons and many other cells shareinformation electrically as well as chemically, and the varying spatio-temporal patterns of activity they generate can be associated to specific cognitive activities, although we are not able yet to decipher all their meaning yet.\nThis is an important problem, because it seems that whatever the mind is, it is very closely associated to this electrochemical choreography.\nEEG, or electroencephalography, is a hundred-year old technique that consists in measuring the tiny electrical fields generated by the brain while it goes about its business – from the scalp, non-invasively. Modern EEG is quite sophisticated, thanks to much improved electronics, novel mathematical algorithms and tremendous computational power. And it is in constant evolution.\nUsing EEG and other neuroimaging methods now available we are able to study brain function and discern among a discrete set of brain states associated to mental imagery. In other words, we are beginning to crack the neural code. And we can, even if very crudely, literally read minds. So, going back to our game, it seems that we have at least one of the elements we need to enable brain-to-brain communication without magic. We can create a direct forward link between brains and computers using EEG. What about the other direction, computer to brain communication? Well, if the brain is an electrical system, we can surely act on it using electricity. Indeed, there are now medical devices that do just this. My team and I are mostly focusing on a non-invasive approach called Transcranial Current Stimulation.\nTechnically it is sort of the inverse of EEG. Currents are injected from the outside, and these currents create tiny electrical fields inside the brain that interact with neurons, altering their activity and the activity of the entire brain in subtle ways. The roots of brain stimulation are very old, going back at least to the Egyptians, Greeks and Romans (such as the roman doctor Scribonious Largus, who used torpedo fish), who experimented with electric fish and brains to treat pain. (Do no try this at home!) Another related non-invasive technique is called TMS, which generates localized electric fields strong enough to make neurons in the brain fire.Let’s to back to our game. As I’ve explained, using EEG we can already extract information from neural activity associated to mental imagery. We can also use brain stimulation to “inject” information in brains. But can we actually create artificial percepts by non-invasively manipulating electric fields in the brain? Well, it turns out that yes, we can! We can use stimulation to create several types of percepts, including visual and tactile sensations. The technology is advancing quickly, supported by robotics and navigation technologies that allow us to hit the right areas of the brain in a robust and repeatable manner. Using these tools, my colleagues and I recently carried out an experiment to prove that it is possible to transmit information from one brain to the other consciously, without any intervention of anything other than our brains and technology – entirely bypassing our peripheral systems, our senses, our muscles.\nBy now you know how we did it: we used EEG to decode simple thoughts from a person called the “emitter” – a Starlab researcher located in India – and we applied non-invasive stimulation to create percepts in a receiver in Strasbourg. We used TMS, a non-invasive stimulation technique that generates localized electric fields strong enough to make neurons in the brain fire. Applied in the right place and orientation, we could make the receiver perceive flashes of light on demand without intervention of the eyes. There is no light, only the sensation of light. The emitter was given a list of symbols, 1s or 0s, and instructed to think “I am moving my hands” or “I am moving my feet” to encode the 1 or a 0. An EEG system decoded this from the data, “reading the emitter’s brain”, and then sent out emails to another computer which, depending on the received value, guided a stimulation system to stimulate the receiver in one of two different ways, making him perceive or not a flash of light – again to encode a 1 or a 0. Hidden in this binary symbol stream were the words “hola” and “ciao”, much in the same way that computers represent letters in binary form, in 1s and 0s. For all this to work, though, the symbols had to be encoded and decoded correctly. We made every effort to ensure that the transmission was in no way mediated by senses, cues from sounds and such, because our goal was to demonstrate that the transmission was “direct” brain to brain.\nAnd, we succeeded; the list of symbols was transmitted with little error, the two words received faithfully. “Hola” and “Ciao”. Not precisely deep conversation. But a start in the brain-to-brain communication business. This was the first time in human history that two people shared a conscious thought in such a direct way, purely brain to brain. The shared thought was very simple, but in a sense the message contained the essence of any type of information exchange: a yes or a no. A 1 or a 0. So what, you will ask? Can we share anything beyond a boring list of ones and zeros? Well, in all honesty no, not yet today. The next challenge is the synthesis of more sophisticated percepts using brain stimulation. Tactile sensations, sounds, visual imagery will follow. Further down the line we may be able to share abstract concepts, mathematics, emotions. We will use technologies that allow us to read and stimulate the brain in a global manner, because the brain is a distributed networked processor. This will come; it is just a matter of time. And it will change civilization in ways that will make the invention of the internet seem truly quaint. We may imagine we will use these new powers to compute, to think and solve problems together more fluently, to gain extra senses. We will probably need neural translators, to account for the different ways individual brains work. It will be very interesting very challenging. Will we get along better as a species once we establish such broadband communication channels? Will we use them to communicate with other species? With intelligent artificial systems? Or will we use these powers for evil purposes? There are many implications, many possibilities. Many questions.But just as important, the same advances that are to allow such direct, content-rich communication will have empowered us to finely read and manipulate the electrical fields in the brain and treat diseases such as epilepsy or depression. So brain-to-brain communication poses challenges of value to clinical applications. At my company we are already working in this direction with researchers worldwide.\nAs you can see, playing games may have consequences other than expected.\nIndeed, the beginning of science is really curiosity and fun, which kids excel at.\nAnd, as history has shown us many times, the fallout from human curiosity can be tremendous..\nIf you start with a powerful vision, who knows where you will land? “Everything you can imagine is real”.']	['<urn:uuid:6effdd00-1941-4a34-b36b-524535651ef9>']	factoid	direct	verbose-and-natural	distant-from-document	single-doc	novice	2025-05-01T22:36:12.692263	17	29	1913
154	horse therapy programs credentials participation requirements	Military and civilian horse therapy programs have different credential requirements and participation protocols. For military programs like at Camp Lejeune's Scarlet and Gold Riding Club, they work with EFMP families and Wounded Warriors, though they don't have therapeutic professionals on staff. For civilian equine facilitated psychotherapy, providers must be PATH Intl. certified, with Equine Specialists requiring specific training and certification through PATH and/or EAGALA. Licensed therapists must be present and certified in equine therapy. Participation requirements vary - military programs require EFMP enrollment for families with diagnosed medical, intellectual, or emotional disorders, while civilian programs don't require prior horse experience or physician referrals, but do require an initial intake with a therapist to develop a treatment plan.	"[""News: Horsin' around: EFMP families feel sense of fun\nStory by Cpl. Charles Clark\nMARINE CORPS BASE CAMP LEJEUNE, N.C. - More than 30 Exceptional Family Member Program adults and children expanded their senses through touch, sight, sounds and smells at the Scarlet and Gold Riding Club aboard Marine Corps Base Camp Lejeune May 15.\nThe children planted potato seeds, watered carrots and met with three horses to learn about and interact with.\nThe EFMP is a mandatory enrollment program for active duty Marines who have a family member with a diagnosed medical, intellectual or emotional disorder.\n“I think the main thing for the families with the EFMP is being connected to each other,” said Tracey M. Sosa, program manager for the Camp Lejeune Exceptional Family Member Program. “We educate the children in the program and have some science classes as well, like today with the gardening and talking about the horses. But, the most important thing is making sure the kids get the help they need while having fun stuff like this.”\nThe riding club and family member program staff set up a touch-based sensory activity where the children could dig in the dirt as they planted seeds and finger paint on the horses to have a better understanding of the different textures they handled.\n“We love our horses and they bring so much joy into our lives that we wanted to share it with others,” said Kim A. Reid, Scarlet and Gold Riding Club president. “Having the kids here and seeing them laugh and smile really made my day.”\nThe parents seemed excited and elated to see their children laughing, running, blowing bubbles, feeding and finger painting the horses.\n“This is pretty awesome because horses are my daughter’s favorite animal,” said parent, Ashley M. Putney. “I didn’t tell her about what was happening today until we got here. She got really excited really quickly.”\nAfter dipping their hands in different colored paint, the children’s hand prints colored the horses’ sides into a rainbow of high fives. As the horses ate the last of the carrots, the SGRC staff walked the horses around the yard so the children could play with them more.\nThe time for play ended and the parents gathered their rambunctious younglings up and headed home. The SGRC staff showered their horses to clean the paint off, which they seemed to enjoy a refreshing shower after a few hours of having fun.\nThe riding club often works with the Wounded Warrior Battalion. Having the children around wasn’t stressful for the horses who meet a lot of Marines from Wounded Warrior.\n“While we don’t have any therapeutic professionals here, we do our best to help anyone who needs it,” said Kelly E. Goetz, Scarlet and Gold Riding Club community relations manager. “Next time the EFMP kids come out, we’ll try to have more horses to interact with and maybe let the kids ride them as we walked them around our track.”\nFor more information about the Scarlet and Gold Riding Club, call (910)-451-4901 or visit www.sgrcnc.org.\nFor more information about the Exceptional Family Member Program, call (910)-451-4394 or visit www.mccslejeune.com/efmp."", 'Triple Play Farm offers Equine Facilitated Psychotherapy [EFP] sessions as an alternative to traditional talk therapy. Learn more about EFP below.\nWhat is Equine Facilitated Psychotherapy?\nAs defined by PATH (Professional Association of Therapeutic Horsemanship), equine facilitated psychotherapy is, “a form of experiential psychotherapy that includes equine(s). It may include, but is not limited to, a number of mutually beneficial equine activities such as handling, grooming, longeing, riding, driving, and vaulting. Equine-facilitated psychotherapy is a treatment approach within the classification of equine-assisted therapy that provides the client with opportunities to enhance self-awareness and re-pattern maladaptive behaviors, feelingsand attitudes.”\nDo I need a physician referral for EFP?\nA physician referral for equine therapy is not necessary. You may contact us at 704-608-8441 to arrange an initial intake with one of our contracted therapists in order to begin developing a treatment plan. If you have questions of a general nature about the available programs, you may also contact Kris Batchelor, Equine Specialist at 704-608-8441.\nWhat will my sessions at the farm be like?\nEvery therapeutic session at the farm will be co-facilitated by both a licensed therapist and a certified Equine Specialist. This team approach allows us to maximize your physical and emotional safety while working with the horses. Sessions may be individual, couples, family, or group structured depending on your own treatment goals. Duration of individual, couples and family sessions are typically one hour and group work is typically done in ninety minute sessions. Again, depending upon your goals, you may come to the farm once or for several months.The content of your sessions will vary depending upon your personal treatment goals. The treatment team, consisting of a licensed therapist andEquine Specialist, will design activities with the horses that will allow you to explore issues related to self-awareness, confidence, boundary setting, interpersonal skills, trust, respect, body image, etc. Those activities may include observation, haltering, leading, grooming, tacking, riding, and any number of other creative ways that we will guide your interactions with the horses so that you can learn about yourself.\nDo I need to have horse experience?\nNo prior horse experience is necessary. Most of our clients have never been around horses and may never be around them again after completing therapy.\nWill I learn how to ride?\nEquine facilitated therapy is very different than riding lessons. Our objective is not to teach you a skill to improve your horsemanship, but rather to allow you to gain self-awareness that will assist you in meeting the goals of the treatment plan that has been developed by you and your therapist. You may do some mounted work with the horses if there is a therapeutic reason for doing so.\nIs it safe?\nOur staff at Triple Play Farm has spent many hundreds of hours developing our own horsemanship, selecting and caring for the herd here. We know all of the horses very well and carefully choose certain horses for certain clients and activities. The job of the Equine Specialist during all sessions is to maintain physical safety for all participants. That being said, horses are 1,000 pound creatures with the instincts of a prey animal. We will certainly mitigate risk, but part of your experience here at the farm is also taking responsibility for your own safety, a subject that we will discuss in greater depth when you are here.\nShould I wear special clothing?\nWhen working with the horses, we ask that you wear closed toe shoes and if possible, no dangling jewelry. If we are planning to do mountedwork, we will also ask that you wear long pants and a heeled shoe.\nDo you take insurance payments?\nSome of the therapists with whom we contract do accept insurance payments for mental health treatment and the specifics of your particular situation are best discussed with them during your intake. Triple Play Farm also provides contract services and upon request, we would be happy to prepare a proposal for your organization’s board and/or grant writer as well.\nWhat makes you qualified? Couldn’t I go to any barn and call it therapy?\nWhen seeking equine facilitated psychotherapy, you should be very diligent in examining the credentials of any barn that claims to be doing “therapy.” Triple Play Farm is a member center of PATH Intl. and all of our Equine Specialists have received training and certification through PATH and/or EAGALA. We would be happy to provide the criteria for these certifications, which require ongoing continuing education to stay current in this emerging field. We also require our therapists to undergo certification specific to equine therapy and encourage them to develop their own horsemanship if possible. The farm also holds extensive liability insurance specific to the field of equine assisted therapy. Most importantly, any time that we are providing therapeutic services, there is always a therapist present who is licensed to practice in the state of North Carolina.\nHow can I get the ball rolling?\nThank you for your interest in Equine Facilitated Psychotherapy.']"	['<urn:uuid:d12e4173-9ef9-466b-afcd-434c191611fd>', '<urn:uuid:462c1ef1-8148-43bf-8674-a54cf40da400>']	open-ended	with-premise	short-search-query	distant-from-document	multi-aspect	expert	2025-05-01T22:36:12.692263	6	117	1353
155	How often should designers take eye breaks from their monitors?	Ergonomists recommend that designers must take short eye breaks away from the monitor every 20 minutes.	['Being creative and making catchy designs are not enough for making up impressive and amazing designs, rather both you and your designs should comply with the factors like human conformity, usability and feasibility. A well-decorated house that is not comfy to live in and a lavish workstation with itchy chairs and tables are of no use. Here comes ergonomics.\nWhat is the science of ergonomics and what sense it makes in designing? This question might have buzzed your mind when you saw the title of this article. But do not worry. Here, we are going to define ergonomics along with the tips and tricks of how can you incorporate this in designing works.\nErgonomics is basically a science that refers to completing a task effectively and making a product highly useful, handy and supportive for the targeted users. Ergonomics can be used in everything that exists under the sun, but when it comes to graphic designing, its worth increases manifold.\nHere we lay down a few essential ergonomics tips for designers. These tips can help them not only saving their health and wealth but also making their designed products comfortable for others.\nWhen You Need Ergonomic Arrangements:\nA research suggests that if designers use computers for about an hour in a day, they can do it in normal settings; but if they have to use it up to four hours or more, they need to make proper ergonomic arrangements in everything including furniture, gadgets, software, computer and stationary.\nCommon Accessories for Better Ergonomics\nReplace Mouse With Pen Tablet:\nSince its very invention, mouse has been a matter of grave concern for physiotherapists who believe that using mouse for long time can cause some serious injuries to muscles and bones of elbow and arm. So what to do now? There is a replacement here. Designers can use pen tablet instead of mouse while drawing lines, filling colors and moving cursors here and there. Pen tablet is relatively safer, better and more efficient than mouse. So, first of all, you must replace your mouse with pen.\nA Wacom Tablet.\nUse Gaming Keyboard:\nDesigners have to switch from one app or program to another time and again. They have to copy and paste a lot of things in seconds. Doing this all with the help of right click and left click is really boring, tiresome and time consuming. Do not worry. There are available gaming keyboards with programmable hot-keys for this purpose. So, being a designer, it must be your prime priority to replace your simple keyboard with the gaming one. This will reduce your stress, save your time help you creating good designs instantly.\nA4 Tech X7 G800V Gaming Keyboard.\nUse Chairs With Armrests:\nYou may like to purchase some stylish and smart chairs for your workstation but they might not have armrests that are meant for protecting your bones and muscles from injuries in the long run. Always go for the chairs which have proper armrests as this will not only bear the burden of your arms but also support you while sitting down and rising up. According to a scientific research, people who use flat chairs for long are at higher risk of weakening their arm muscles.\nErgonomically Mastered Office Chair\nAdjust Your Chair Height To Comfy Point:\nSome designers are so deeply immersed in their work that they do not care for the height of their chair and their own posture. A chair that is too high or too low from table can cause the user backbone and neck pains. According to physiologists, reclined posture of 100-110 degrees is perfect and safe for workstations. Keep your posture straight all the time. Do not bend behind or forward as this will misshape you.\nWrap Pens And Pencils With Foam:\nHolding, handling and using a thin pencil or pen is really an awful thing when you have to sit on workstation for many hours continuously. Sometimes, the grip over thing pens creates pain in your fingertips and joints. In order to avoid this, you must wrap your tablet pencils or other writing pens with a layer of soft foam. The foam will make pens somewhat thicker and, thus, you can have tighter grip over them. Moreover, foam will keep absorbing the sweat of your fingers.\nWear Support Braces And Gloves:\nIn the market, you may find various ergonomic products that can give designers comfort and make their work risk-free. Out of these, one is support braces/gloves that, if your wear, will save you wrist injuries. But make sure that anything you use is loose enough to let you hands be straight. There should not be any curve in your wrists or fingers while you are working.\nErgonomics of Environment\nUse Ergonomics Accessories With Laptops:\nIndeed, laptops are effectively outpaces desktops within a couple of years. But this has caused great harm to the bodies of users. While using a laptop, you have to keep you arms too high and head too leaning down. This posture creates problems for your head, arms and elbows. So, if you are using a laptop for making designs, always use the ergonomics accessories with it including keyboard, pen tablet, mouse, a wide screen and a comfy desk. Set all these accessories at the positions where all parts of your body, especially hands and arms, feel comfortable. Do not forget that working over laptops for long can be serious damaging for designers.\nArrange Adequate Lighting:\nAlways make sure that the place where you are sitting to work is properly exposed to lights. Try to use natural light as much as possible. At day time, roll up your curtains and let the sun rays come in and at night, use some source light above your head. But avoid too strong lights as this may impair or hurt your eyes. Beware that working in dim light may cause your headache and certain eye problems.\nA designer’s work requires creatively and concentration. When your workstation is exposed to different sort of noises, you cannot be able to focus on your lines and colors. So always use some soundproof room for designing works. There should be no traffic or other unnatural noises around you. If you do not have a soundproof room, you may play some light music that will bar external noise. Remember one thing that more your workstation is comfy, higher will be your imagination.\nKeep Switching Between Mouse And Pen:\nWhen you get addicted to a gadget, it starts hurting you. No doubt, you must perform most of your routine commands and functions with pen tablet, but do not stick to it only. After a couple of hours with pen, switch to mouse for at least half an hour. This practice will make you feel relaxed and save you from some unknown and unnoticed injuries and pains. Some designers place pen tablet on the right and mouse on the left side of their keyboards and use both simultaneously. You can use this trick if you feel comfortable with it.\nChange Settings To Single Click Option:\nNormally, most computers are tuned on double click options which means you have to press the left button of your mouse or pen for two times to launch an application. This becomes messy and stressful sometimes when you are tasked with giving some release in short time. So the best thing is that you go to your control panel and change double click option with single click. This will save your time and energy at the same time. Moreover, this is greatly comfy too.\nEnsure Ventilation In Your Workstation:\nComputers and other gadgets that designers use release a lot of heat and, in turn, consume oxygen. Thus, if your room is airtight, you may start feeling nausea or headache. In order to avoid this, make sure that there is available a proper ventilation system in the room where you are sitting to work. To keep your mind and mood fresh, let some fresh natural air come in.\nErgonomics of Health\nUse An Ergonomic Software:\nWhile working, we do not realize how much time we have spent on computer and when we should take rest. There is available an ergonomic software that monitors your work and prompts you when this is necessary to take eye breaks and exercise breaks and when you need to wind up. Install such sort of software in your computer and activate it when you start working.\nWorkrave is a brilliant, freeware application for rest reminding.\nKeep Adequate Distance Between Monitor And Your Eyes:\nDo not sit closer to your monitor as this will hurt you eyes in the long run. Always maintain a safe distance between your chair and monitor. Some designers lean forward while working and, thus, they get nearer to monitor. This is an unhealthy practice. To be on safe side always, install a protective screen on your monitor. Love you eyes and they will help you viewing more and more designs in nature and art.\nGive Breaks To Your Eyes:\nConstantly looking at monitor for long time will make your eyes sour and itchy. So, ergonomists recommend that designers must give short breaks to their eyes after every 20 mints. Take your eyes away from monitor and peep out of your window so see some greenery or close your eyes for a couple of mints. Keep in mind that eye breaks are necessary to keep your lamps burning for the whole life.\nGet Eye Checkups Regularly:\nIt is recommended by ergonomists that designers working on computers for long should keep visiting eye specialists for checkups with regular intervals. This will help them know their sight and changes that occur in it. Thus, they can go for medical solutions on time in case of any problem.\nTake Exercise Breaks:\nMuscles and bones get stiffed by sitting continuously for many hours. So sink your work routine with small exercise breaks after every one or two hours. Come out of your chair and practice some gentle moves to relax your muscles. Take a little walk in your room or outside if possible. Sit on rest chair for a few mints. Open your window and take long breathes. This all will help you rekindle your energy and refresh your mind.\nKeep Liquidating Yourself:\nYou must keep fresh water and juices on your table when you are working. Keep taking sips time to time. This will do not let your energy level and blood pressure go down. Sometimes we feel headache by sitting in front of monitors for long. This is due to the fact that our sugar and energy levels reduce. To avoid this, the best way is to use liquids all the time.\nDo One Thing At One Time:\nIt is human nature that we can concentrate on one thing at one time and when we try to divide it, things start messing up. Some designers stuff up themselves with multiple projects and tasks and, thus, they cannot be able to put utmost creatively and attention in anyone. Moreover, this makes them feel bored and fatigued. So the best thing is that you perform one task at a time. Take to end a project that you start and then plunge into others.\nUse Comfy Shoes:\nSome ladies use high heels that do not let feet be comfortable. Some men also wear weird shoes. So make sure that your shoes are comfy enough to keep your legs at east all the time you are on your chair.\nIt is an admitted fact that health is wealth. Without good health, you cannot be able to do anything good in your life. Taking care of their health is necessary for all human beings, but in the case of designers, this becomes more important. This is due to the fact that the entire designing work is owed to creatively and initiation and these things are not possible without sound physical and mental health. Therefore, designing experts and health practitioners strongly recommend ergonomic settings at workstations. By practicing the above-mentioned tips, designers can enjoy good health all the time and the products they design will also healthful for the users.']	['<urn:uuid:b5f94af0-142b-4d88-8b8e-0161ba337628>']	factoid	with-premise	concise-and-natural	similar-to-document	single-doc	expert	2025-05-01T22:36:12.692263	10	16	2026
156	what agricultural practices and quality control requirements needed for medicinal herbs laboratory testing	Medicinal herbs require Good Agricultural Practices (GAPs) that include proper harvesting, washing, drying, and packaging procedures. For laboratory testing, quality control measures are essential to ensure accuracy and reliability of test results. The testing process must include physical, chemical, and microbiological evaluations to verify the product's safety and suitability for human consumption. Quality control helps identify defects, maintain regulatory compliance, and enhance the quality of finished products while minimizing risks.	['GAPs for Medicinal Herbs (Good Agricultural Practices)\nEl inglés es el idioma de control de esta página. En la medida en que haya algún conflicto entre la traducción al inglés y la traducción, el inglés prevalece.\nAl hacer clic en el enlace de traducción se activa un servicio de traducción gratuito para convertir la página al español. Al igual que con cualquier traducción por Internet, la conversión no es sensible al contexto y puede que no traduzca el texto en su significado original. NC State Extension no garantiza la exactitud del texto traducido. Por favor, tenga en cuenta que algunas aplicaciones y/o servicios pueden no funcionar como se espera cuando se traducen.\nEnglish is the controlling language of this page. To the extent there is any conflict between the English text and the translation, English controls.\nClicking on the translation link activates a free translation service to convert the page to Spanish. As with any Internet translation, the conversion is not context-sensitive and may not translate the text to its original meaning. NC State Extension does not guarantee the accuracy of the translated text. Please note that some applications and/or services may not function as expected when translated.Collapse ▲\nOn April 18, 2015 we held a Good Agricultural Practices (GAPs) for Medicinal Herbs Training Session for Growers at the Mountain Horticultural Crops Research and Extension Center in Mills River, NC. The instructors in this four hour training included the (former) coordinator of the Blue Ridge Naturally Brand Project, Jennifer Flynn; Craig Mauney, an extension agent (now area specialized agent) who works with farmers on GAPs for fresh produce; Dr. Jeanine Davis, a university researcher/extension specialist and her research assistant, Margaret Bloomquist, research associate, who work closely with medicinal herb growers; and Ed Fletcher, a medicinal herb buyer. At the last minute we decided to videotape the event so others could benefit from the training. It is not a professional video, but all the information is there. The links to those videos on our YouTube channel are below.\nAnother excellent resource is the recently updated Good Agricultural and Collection Practices and Good Manufacturing Practices for Botanical Materials bulletin published by the American Herbal Products Association.\nThis event covered by these videos was part of the WNC Agriventures Project, a project funded by a federal Rural Jobs Accelerator grant with Land of Sky Regional Council, NC State University, AdvantageWest, the NC Natural Products Association, the Community Foundation of WNC, and the Small Business Technology and Development Center.\nVideos of the 2015 GAPs for Medicinal Herbs Workshop\nPart 1: Good Agricultural Practices (GAPs)\nThis video introduces you to the Blue Ridge Naturally Brand, provides an overview of the current Good Agricultural Practices (GAPs) for fresh produce and how it relates to medicinal herbs, and the beginning of the session on suggested GAPs for medicinal herbs.\nPart 2: GAP Resources\n(this video starts with a session already in progress and continues on the next video in the series. See Part 1 for the beginning of this session on suggested GAPs for medicinal herbs and Part 3 for the end). This video covers the existing resources available on GAPs for medicinal herbs, harvesting, and washing herbs.\nPart 3: Drying and Packaging Herbs\n(this video starts with a session already in progress. The session begins in Part 1 and continues into Part 2 of this series and ends in this video). This video covers drying and packaging herbs. It also contains the beginning of the session providing a buyer’s viewpoint on good agricultural practices.\nPart 4: Buyer’s Perspective on GAPs\n(this video starts about five minutes into a presentation on a buyer’s field based view of good agricultural practices. View Part 3 to see the very beginning of this session and Part 5 to see the end). A buyer’s perspective on GAPs for medicinal herbs.\nPart 5: Conclusion\n(this video starts with the end of a session on a buyer’s field based view of good agricultural practices. The session starts in Part 3, the bulk of the presentation is in Part 4, and the end is here). This video is the conclusion of the four-hour training session for medicinal herb farmers.\nJeanine Davis, NC Alternative Crops & Organics Program, Department of Horticultural Science, NC State University. Updated 8/18/2022.', 'Importance of Quality Control in the Lab\nQuality is an essential factor in every industry all over the world. The value of goods and services and the response of customers all depend on the quality and in present times where numerous competitors struggle for dominance in a small market, the success of any organization or business depends immensely on their ability to provide the public with goods and services of the highest quality. The relevance of quality is never as poignant as in the laboratory where a single error in test results could make or mar a study, diagnosis and even patient treatment.\nFollowing the recent transition of cannabis from a purely recreational drug to a medicinal drug, it has been adopted in a range of medical fields and used in the treatment of several health conditions. This change combined with the legalization of cannabis necessitates the need for an effective quality control program to be implemented in the laboratory if there is to be remarkable revenue growth in the cannabis industry.\nWhat Is Quality Control?\nQuality control (QC) serves as the pillar on which the precision, accuracy, and reliability of test results rest. It can simply be described as a means of identifying analytical errors in the laboratory to ensure that test results are not only accurate and reliable but also efficiently provided to offer optimum results.\nQuality Control in Cannabis Laboratories\nCannabis is not left out of the rigorous testing procedures which other pharmaceutical drugs undergo before they can be made available in the market. As something touted to provide the human body with relief from aches, pains, inflammation, anxiety and a variety of other symptoms, cannabis is required to undergo thorough testing procedures to ensure that it is not only adequately potent to provide therapeutic relief for the condition it is being used for but also fit for human consumption. Due to the absence of a universal testing standard, producers and testing laboratories have engaged in the form of testing which can only be labeled as sporadic and without adequately addressing the issues which pertain to Quality Control in the laboratory, it would be challenging to identify deficiencies in the testing process and consequently, results collated.\nBenefits of Quality Control\nTo ensure that tests are conducted adequately, in line with established procedures and requirements, it is essential that laboratory testing is frequently monitored through quality control so as to enhance accuracy. Below are some of the several benefits to be gained from introducing quality control in the laboratory;\nQuality control would mandate that medical cannabis be treated as a pharmaceutical drug, ensuring that physical, chemical, and microbiological evaluations are conducted during the testing.\nQuality control would also have the added benefit of enhancing the quality of the finished product, thus endorsing its safety and suitability for human consumption.\nQuality control helps producers to be proactive in identifying defects and problems with machinery that would otherwise have remained undetected, and overcoming such challenges.\nFurthermore, it would also help producers and suppliers to keep abreast of any changes in the regulatory environment so as to meet up with demand and grow their business.\nIt also aids the effectiveness of producers in minimizing risk and adhering to proper procedure, giving consumers and regulatory bodies confidence in the quality of their products.\nQuality control is an essential factor in cannabis laboratory testing process as it not only ensures the accuracy and reliability of test results but also improves the effectiveness of the testing procedure, thus enhancing an increase in reliability and revenue.']	['<urn:uuid:ce804ee2-2313-4541-be6e-eba0c3f4db8f>', '<urn:uuid:dae9e781-078e-4d66-be6f-602195f71b16>']	open-ended	direct	long-search-query	similar-to-document	multi-aspect	expert	2025-05-01T22:36:12.692263	13	70	1303
157	cbt vs cft techniques treating mental health	Both CBT and CFT are effective therapeutic approaches for mental health treatment, but they work differently. CBT focuses on changing negative thought patterns and developing healthy coping skills through techniques like role-playing and pros-cons analysis. CFT, building upon CBT, adds tools for self-soothing and developing compassion, using techniques like mindfulness, appreciation exercises, and compassion-focused imagery. While CBT emphasizes correcting dysfunctional thinking, CFT specifically helps balance three brain systems: threat, drive, and contentment, with particular focus on developing the contentment system to regulate the others.	['Compassion-focused therapy (CFT) looks to help those who struggle with shame and self-criticism. Often these can be the driving forces behind other mental health conditions like anxiety and depression.\nThe approach was founded by Paul Raymond Gilbert, a clinical psychologist. It is considered an integrative therapy as it uses tools from other psychotherapies. It also uses research and tools from Buddhism, neuroscience and evolutionary therapy. Keep reading to find out more about compassion-focused therapy, what it can help with and what techniques are involved.\nWhat is CFT?\nIt should first be noted that all talking therapies will involve compassion. The premise of counselling itself involves you being kinder to yourself and taking control of your mental health. What makes compassion-focused therapy different however, is that it looks at helping you consciously develop your ability to be more compassionate towards both yourself and others.\nThe founder of CFT, Paul Raymond Gilbert, noticed that many of his clients suffered from very high levels of self-criticism and shame. He found that just cognitive behavioural therapy (CBT) alone didn’t seem to help. While they gained a better understanding of their thinking patterns and how these affected behaviour, essentially it didn’t make them feel better.\nGilbert discovered that they needed tools to help soothe themselves too. So, he developed compassion-focused therapy - an approach to help create a positive emotional response for those who were dealing with low self-worth. The therapy can be used alone, but it can also be used alongside other therapy types, adding another layer of support.\nHow it works\nCompassion-focused therapy looks at evolution theory and how this affects the way we think. Essentially, us humans have two parts to our brains. The primitive or ‘old’ part helps us survive. It ensures we have food, shelter, are loved and are safe. This part is also responsible for the fight, flight or freeze stress response. It tends to be here where problems like anxiety, and even sadness stem from.\nThe modern or ‘new’ part of the brain has come about during the evolution process. This part allows us to have a sense of self and lets us imagine and visualise. We can come up with ideas and choose how we want to live.\nThe thing is, the new and old parts can often conflict or get confused. The basic and instinctual drivers of the old part can take over and create protective emotions (like anxiety).\nCognitive behavioural therapy can help us understand this in greater detail and explain why we feel the way we do. It helps us learn to notice and then change the way we think. Compassion-focused therapy takes this a step further, for those who need it.\nCFT helps us let go of the self-blame we can often attach to negative thoughts.\nWe often think having negative thoughts or feelings is bad or ‘wrong’ and that we are choosing to think like this, therefore we are a bad person, but the truth is nobody chooses to. Our brains evolved to react and sometimes they don’t react in a positive way.\nThe therapy also helps us generate emotions that can help change our thought patterns - like compassion. The brain is designed to create kindness and compassion as well as the more protective emotions like stress and anxiety, it’s just a case of learning how to activate this part of the brain.\nThe idea of generating compassion to help improve well-being actually stems from ancient Buddhism. Studies have proven its effectiveness too. Research has found that by developing our compassion we can create positive effects on our brain and our immune system.\nThe three affect systems\nOne of the key theories behind compassion-focused therapy is that within our brain there are interconnecting ‘systems’ that need to be managed in order to improve mental health.\nThe threat system - This system is protection-focused. This means it will be on high-alert for perceived threats and will react with feelings like anger, anxiety and other protective emotions.\nThe drive system - This system motivates us to get resources and is excitement-focused. As well as focusing on getting basic needs met, like food and shelter, this system is also keen for us to achieve goals like passing a test or succeeding on a date. It’s related to feelings of excitement and arousal.\nThe contentment system - The ‘soothing’ system. This is triggered when there is no perceived threat or when nothing needs to be achieved. It makes us feel calm, peaceful and safe. This leads to us feeling content, happy and socially connected.\nIt’s believed that when these systems become unbalanced, it can lead to problems. The aim of compassion-focused therapy therefore is to regain the balance between the systems. The focus is typically on developing the contentment system to help regulate the other two systems.\nTechniques used in CFT\nThere are lots of different tools and techniques used within compassion-focused therapy, some of which are drawn from other therapies. The primary technique used is called compassionate mind training, or CMT. This aims to help people experience compassion and develop non-condemning attributes.\nHere are some of the techniques and exercises that may be used:\nMindfulness - This helps you learn how to pay attention to the present moment without judgement.\nAppreciation exercises - These may include making a list of things you like in life, the aim is to help you savour the moment, notice when something enjoyable happens and other positive, rewarding behaviours.\nCompassion-focused imagery exercises - This may involve guided memories and fantasies to help stimulate the soothing system.\nFor those who struggle to experience or express compassion, questioning techniques may be used to help identify (and remedy) what could be causing this.\nWho can it help?\nCompassion-focused therapy is particularly helpful for those who have the following:\n- deep feelings of shame or guilt\n- a history of bullying\n- a history or physical or emotional abuse\n- an unrelenting inner critic\n- difficulties trusting\n- difficulties (or an inability) to feel kind towards themselves\nIt can therefore be helpful for those with the following mental health challenges:\n- anxiety (including panic attacks)\n- self-esteem issues\n- eating disorders\nThe nature of the therapy means it can be challenging for some people. For example, if someone is afraid of compassion, doesn’t believe they are worthy of support or is struggling with intense anger or rage.\nKnowing your options and talking them through with your doctor can help you figure out which treatment option will be the most helpful for you and your circumstances.\nFind a therapist dealing with Compassion-focused Therapy\nAll therapists are verified professionals.', 'Cognitive-Behavioral Therapy (CBT) for Addiction and Substance Abuse\nCognitive behavioral therapy, or CBT, is a form of psychotherapy that is effective in treating a range of mental health issues including mood disorders, anxiety disorders, and substance use disorders.1 CBT emphasizes changing negative thought patterns to change behaviors, as well as developing and implementing healthy coping skills into one’s life.1\nThis article will break down the clinical conditions that CBT addresses, how it helps those struggling with substance use disorders and other mental health conditions, and who this type of treatment might be right for.\nAmerican Addiction Centers offers cognitive behavioral therapy along with a variety of other therapies recommended for the safe and effective treatment of drug and alcohol addiction. To learn more about our program offerings and our various nationwide treatment centers, call\nWhat Is Cognitive Behavioral Therapy?\nCognitive behavioral therapy is a form of behavioral therapy and a well-established treatment intervention for people suffering from a wide range of mental health disorders. Cognitive behavioral therapy focuses on cognition, or how your thoughts can influence your mood – not vice-versa.2 CBT is a goal-oriented type of therapy that addresses cognitive issues such as dysfunctional automatic thoughts, maladaptive thinking (or cognitive distortions), and underlying core beliefs.2 Most therapists who use CBT customize the therapy to the specific needs of each patient.2\nCognitive behavioral therapy was developed in the 1960s by psychiatrist Aaron Beck.2 CBT originated when Beck’s perspective changed on mental health conditions from viewing depression and anxiety as mood disorders to viewing these conditions as cognitive disorders.2\nFor example, if a CBT patient’s automatic interpretation of a situation is seen through a negative lens of cognition (thoughts and beliefs), then it is likely to impact their mood negatively.2 Maladaptive thinking or cognitive distortions, such as overgeneralizing, catastrophizing, or personalizing situations, can cause errors in logic and misguided conclusions, sometimes resulting in or worsening of symptoms of depression, anxiety, and other mental health conditions.2\nUnderlying core beliefs can shape someone’s life and be the foundation for automatic thinking. Someone’s ways of thinking and perceiving can undoubtedly shape the way that they interpret the world around them (and their role in it).2\nBeck believed that dysfunctional, automatic thinking, even if it exaggerated or distorted, plays a significant role in mental and behavioral disorders.2\nThe ultimate goal of CBT is to address these negative patterns of thinking and subsequent behaviors to create positive change in a person’s life for the better.2\nAlthough CBT is effective in treating mental disorders, CBT can be helpful for anyone looking to make a shift in the quality and health of their thinking or improve their mood.\nHow Does CBT Work?\nThe fundamental principles of CBT are:1\n- Psychological disorders are based, in part, on inaccurate ways of thinking.\n- Psychological disorders are also based on learned patterns of negative behavior.\n- People suffering from psychological disorders can learn better ways of coping, thereby relieving their symptoms and subsequently creating positive changes in their lives.\nTherapists may also help clients by using role-playing techniques to develop a plan for how to deal with potentially problematic situations in the future.1\nFor example, creating a pros and cons list of reactions to various situations can help people gain an understanding of how their thoughts and actions may make things better or worse. It is important to play out those scenarios in therapy before they need to draw on them in life. Having a plan of action before a person needs this plan can help people feel more prepared and confident. Every person’s challenges in life are unique, so it is up to both the therapist and patient to develop a treatment strategy to address the patient’s needs. What works for one person may not work for another.1\nCBT with a trained therapist helps clients take control of their cognition and develop healthier ways to think, emote, and behave independently and through tangible exercises. The therapist and client work collaboratively to develop strategies to not only have an awareness of negative thought patterns and beliefs but to learn to problem solve and change their behaviors.1 It is a solution-based form of therapy focused less on the past and more on the present and what to do now to make things better.1\nGoals of CBT\nThe goals of CBT will include developing an awareness of one’s misguided thinking patterns that are creating problems in their life and re-evaluating such thinking in light of reality.1 CBT also encourages people to understand the motivation and behavior of themselves and others, as well as using realistic problem-solving techniques to solve problems.1 As a result, this should build a person’s confidence in their abilities to manage stressful situations.\nAnother goal of CBT treatment is to help people learn how to calm their mind and body and begin to face their fears instead of avoiding them.1 CBT can be an empowering tool to help people realize that they can manage their emotions and various situations they may encounter throughout their lives in a healthier manner.\nBenefits of Cognitive Behavioral Therapy\nCBT is a practical, goal-oriented form of therapy. It is a collaborative effort between the therapist and patient that can help the patient improve many aspects of their life.2 Treatment is individualized, so cognitive behavioral therapy may look different for different people. CBT has been shown to be beneficial in treating anxiety, depression, and even ADHD.2 It is also a form of short-term therapy, with weekly sessions typically lasting 2-3 months.2\nIs CBT Covered by Insurance?\nThe short answer is yes, cognitive behavioral therapy is typically covered by insurance. The Affordable Care Act mandates that health insurance companies must cover mental health and substance use disorders on par with coverage for medical or surgical procedures.5\nHowever, individual plans and coverage will vary depending on carriers. If you have questions about your coverage, call the number on your insurance card to find out more information about your specific plan. Some cognitive behavioral therapists accept insurance, but others may not accept insurance. Others may be out-of-network (OON) but offer patients the option of paying their therapy costs up-front and then sending a superbill to their insurance company for reimbursement. In that case, the therapist gives the client the paperwork necessary to submit their insurance claim directly to their provider.\nIs CBT Covered by Medicare and Medicaid?\nMedicaid is the largest payer for mental health services in the United States.6 The Affordable Care Act also expanded Medicaid benefits to millions of Americans that didn’t previously qualify. All Marketplace plans cover both mental health and substance use disorder treatments as “essential health benefits.7\nCBT is considered an evidence-based treatment option for mental health and SUDs. To find a provider in your area who accepts Medicaid and Medicare, click here to be directed to the U.S. Department of Health and Human Services webpage, which provides links to various resources and information regarding providers who accept these types of insurance.8']	['<urn:uuid:17be53e8-3c2a-4945-bd51-48f78804c48d>', '<urn:uuid:9d5b97de-4c8a-441a-bd22-e316530a9cfe>']	open-ended	direct	short-search-query	similar-to-document	three-doc	expert	2025-05-01T22:36:12.692263	7	84	2262
158	How do traffic conditions affect fuel usage and driver anger?	Traffic conditions have multiple impacts on fuel usage and driver anger. Rush hour traffic prevents vehicles from reaching peak fuel efficiency speeds, while idling in traffic wastes nearly 100% of fuel used. These traffic conditions can also trigger driver frustration, which builds up over time - research shows that anger in a specific time period is affected by prior frustrating events and trait anger, leading to more aggressive driving behaviors.	['How to improve fuel efficiency\nHow to improve fuel efficiency\nIn today’s world, fuel efficiency is becoming a higher and higher priority. With fuel prices rising ever higher more and more consumers are trying to find ways to decrease the amount of gasoline or diesel they use. We have compiled a list of some of the best ways to reduce the amount of gasoline or diesel consumption for your household.\nOne of the most obvious ways to limit your gasoline or diesel consumption is to drive less. For years, everyone has touted the benefit of car pooling. Most cities have even created car pool lanes on their freeways and highways. Instead of 5 people taking 5 cars, 5 people can fit in one car. Using those numbers, 5 employees can reduce their to and from work travel gasoline or diesel cost by 80 percent each. If you live and work inside a city, also consider public transportation. Even though there may be a stigma attached to riding the bus, it can greatly reduce your community costs.\nBesides car pooling and public transportation, combining trips and errands can greatly reduce your consumption. A vehicle will operate most efficiently after it has properly warmed up. Short trips usually do not let the car warm up to peak efficiency. When you combine your errands, you reduce the amount of inefficient trips and create a trip that lets the car get to peak efficiency. Many people tend to run errands throughout the week when it is most convenient. Try and combine all your errands for one trip. This will limit the amount of times you actually drive your car and reduces your overall gasoline or diesel cost. Errand combination especially helps when you find yourself going to the same area multiple times a week. A good example of this is the local strip mall. If you find yourself needing to pick up a prescription at the local drugstore, try and do the grocery shopping you had planned for later in the week since the supermarket is right next door to the pharmacy.\nYou can also adjust your driving habits. Most cars are designed to operate at peak fuel efficiency between 35 mph and 60 mph. Most highways have in city speed limits of 55 mph. This means not speeding will actually help conserve gasoline or diesel. Statistics show for every 5 mph over 60 mph you drive, you lose almost 10 percent of your fuel efficiency. Driving more sensibly also helps to conserve gasoline or diesel. Avoid hard acceleration, excessive braking and speeding. You can lower fuel efficiency by almost a third by hard driving. Cruise control is also a helpful tool in conserving gasoline or diesel. If you find yourself driving long flat stretches of road, try and use the cruise control. This helps the car maintain a constant speed which will lower your gasoline or diesel consumption. Most cars also have overdrive gears. This is usually the top gear in manual transmission and is the OD gear for automatics. Try and use these gears as much as possible. It will reduce the rpms of your engine and reduce gasoline or diesel usage. Idling is also a problem. When you idle your vehicle, you are using gasoline or diesel but not moving. This wastes almost 100 percent of the gasoline or diesel used.\nTime of day can play a huge part in how much you use gasoline or diesel as well. If possible, try and reduce the amount of time you spend in rush hour traffic. More and more business are allowing employees to change their start and end time at work. If you can come manage to miss rush hour traffic, you can increase your fuel efficiency tremendously. During rush hour traffic, your vehicle will most likely not get the chance to get to a peak fuel efficiency speed.\nAnother item we overlook often is heavy items within your vehicle. Many people leave items in their car. For about every 100 lbs you carry in your car, you reduce your miles per gallon by about 2 percent. A mistake many truck owners make is to lower the tailgate to increase mpg. This is a fallacy. Trucks beds are most aerodynamic when the tailgate is in the up and closed position. When the tailgate is up, the bed of the truck will actually pressurize and the wind blowing over the truck will see the bed as an extension of the cab.\nOther options include finding more fuel efficient transportation. Many consumers have been buying SUVs for their ability to haul the whole family with room left to spare for a lot of cargo. This makes sense when you are trying to carry a lot, but what about all the trips where your SUV is mostly empty. These vehicles usually get very poor mileage. If you plan on getting a new vehicle soon, plan on looking at some of the more fuel efficient vehicles. Many SUVs now come in hybrid versions as well. If you drive a lot by yourself with no need for cargo space, consider adding a motorcycle to your stable. Most motorcycles will see gasoline or diesel mileage in the 30 to 50 mpg range. This is considerably more than a lot of vehicles on the road. The purchase of a motorcycle can sometimes pay for itself in about a year with gasoline or diesel savings.\nNow let’s look at how maintenance plays a large role in your fuel consumption. A vehicle sees its best mpg when it is in peak running condition. Keeping your engine properly tuned can improve your actual mpg by up to 4%. Replacing your air filter on a regular basis can save you another 10%. Inflating your tires to the manufacturers specifications can save another 3%. On their own these are not very big, but added together they can save you a lot of money. One of the most important and overlooked parts of your vehicle are the oxygen sensors. These sensors are what helps the car’s computer decided how much gasoline or diesel your engine needs at any given time. A faulty sensor can hurt your mpg by up to 40%. With gasoline or diesel at its current price, this is a huge dent in the wallet. Keeping the fuel system in your vehicle in tip top shape is also important. Check and replace if needed any component of the system. Filters, pumps, injectors and seals are all parts of the fuel system that should be checked on a regular basis and replaced if faulty.\nUsing the recommended octane of gasoline or diesel is important too. Even though the cheap stuff is considerably less than the premium, use the premium if your auto requires it. Many vehicles these days will actually suffer a considerable loss in fuel efficiency with the lower octane. People do not realize using the lower grade gasoline or diesel will actually increase their fuel cost by lower fuel efficiency. Using the correct motor oil should also be a consideration. Always use the oil your manufacturer specifies. In addition, look for motor oil that says energy conserving. These oils have additives to help reduce friction within the engine. The lower the friction, the better the engine operates. This also means follow recommended oil change intervals. As oil is used in the engine, it breaks down causing reduced friction protection for your engine.\nAll these tips are meant to help you decrease your fuel usage. Most are simple tips that everyone can do. As the price of gasoline or diesel keeps rising, it is important to everyone’s pocketbook that we increase the fuel efficiency of our vehicles. As an added benefit, conserving gasoline or diesel also helps the environment.', 'Aggressive Driving: Causes and How to Act\nAggressive Driving Behavior (ADB) is the name that refers to a broad group of dangerous and aggressive driving styles that lead to serious accidents. According to the AAA Foundation for Traffic Safety , 55.7% of fatal traffic accidents are associated with aggressive driving. Today we’ll review its causes and what to do about it.\nIndeed, as the evidence points out, driver anger and aggression contribute to increasing the chances of a crash. Aggressive driving is very common, and internal and external variables encourage its development. In the following paragraphs, we’ll show you what scientists know about it and some tips that will be of great benefit to you.\nThe causes of aggressive driving\nInitially, ADB was defined by experts as a syndrome of frustration-driven behaviors that were enabled by the driver’s environment.\nThese behaviors can evolve into a form of instrumental aggression, which allows the frustrated driver to infringe on the rights of other road users. There are many causes of aggressive driving, although we’ll review the most important ones below.\nThe pressure of time\nA study published in Accident Analysis & Prevention in 2017 found that time pressure is a risk factor for road aggressiveness. Drivers who were exposed to greater time pressure (for example, being late for work) exhibited more anger behaviors.\nBut this isn’t the only thing. Those in such a situation are also more likely to:\n- Select higher speeds\n- Accelerate faster after the change from red to green lights\n- Make left turns when oncoming traffic is near\n- Pass a slower vehicle\n- Run a yellow light rather than slowing down\nAll of these variables can lead to disapproval from other drivers, which in turn can increase the level of rage behind the wheel. Time pressure is then associated with a higher risk of aggressive driving.\nFrustration and accumulated anger\nAn article published in Accident Analysis & Prevention in 2015 suggested that the response to aggressive driving may be a cumulative factor.\nThe researchers found that transient anger in a specific time period is affected by the occurrence of frustrating events, trait anger, and anger experienced in the prior time period.\nThose who’ve dealt with frustrating and angry events immediately before driving develop aggressive attitudes behind the wheel.\nA study published in Traffic Injury Prevention in 2021 found a causal relationship between aggressive driving and personality traits. Those who tend to get angry or angry easily in other contexts tend to do so behind the wheel as well.\nBut this isn’t all. The researchers also found that male drivers were 2.57 times more likely to engage in aggressive driving.\nOther data that complement the above are the fact that behaviors of this type decrease with age. On average, a driver’s tendency to engage in aggressive driving decreased by 26% for each year behind the wheel.\nMarried people, likewise, are less prone to this type of attitude. People who are calmer and more collected away from the road are less likely to drive aggressively.\nOther variables that affect the process are the weather, road conditions, the reckless behavior of other drivers, the state of lucidity due to drug or alcohol intake, slow traffic, and one’s own ability to drive.\nAggressive driving is often multifactorial, so it responds to several of these triggers.\nTips to avoid aggressive driving\nAs there’s a greater risk of accidents, compromising one’s own integrity and that of other drivers, and exposing oneself to fines and other similar consequences, it’s crucial to learn to control aggressiveness when driving.\nThere are many things you can do about it, and all of them are easy to implement. Let’s see a list of the most important ones.\n- Carefully review the current traffic regulations: Knowing what you can and can’t do and the associated fines for certain behaviors will encourage you to lean toward a more respectful driving style.\n- Plan your outing in advance: This way, you avoid leaving in a rush, as this can lead to episodes of stress and aggression. Take into account the possible events that may slow you down (red lights, traffic jams, and so on) to include them in the time it will take you to travel from point A to point B.\n- Identify alternative routes: If the specific conditions of a route cause you a certain degree of stress, it may be wiser to consider alternative routes. Even if it takes you longer to reach the final site, you may find greater peace and tranquility in them.\n- Avoid drinking alcohol and doing drugs while driving: Pointing this out seems obvious, but the truth is that despite its consequences, millions of people drive every day under the influence of these substances. When you’re going to drive, don’t drink alcohol and don’t experiment with recreational drugs either.\n- Make sure you get enough sleep if you’re going on a long trip: Not getting adequate rest can make you more irritable behind the wheel. On average, try to get 8 hours of sleep each night without interruptions.\n- Don’t take other drivers’ actions personally: This is a common mistake that leads to increased aggression ratings. Stay away from aggressive drivers and don’t make eye contact with them or start a verbal argument.\nYou simply need to apply a series of habits to reduce aggressiveness at the wheel. If you can’t maintain them over time or they’re not effective, consider visiting a psychology professional.\nDo this especially if your aggressiveness, anger, and impatience also manifest themselves in other moments of your life. Remember that prudence when driving is essential, as you’re not only compromising your life and that of those who travel with you but that of other drivers on the road as well.It might interest you...']	['<urn:uuid:4e61c799-fbe2-436c-8581-6195682a2301>', '<urn:uuid:66a92c6e-bb33-4a3c-94e4-2b50e0019751>']	factoid	with-premise	concise-and-natural	similar-to-document	multi-aspect	expert	2025-05-01T22:36:12.692263	10	70	2261
160	disease prevention integrated farming systems	Disease prevention in integrated farming systems involves multiple coordinated approaches. In maize farming, prevention measures include maintaining clean gardens, conducting timely farming operations, using disease-resistant varieties, and removing infected crops. For poultry, comprehensive biosecurity measures are implemented, including controlling entry points, minimizing movement of people and animals, proper cleaning and disinfection procedures, and maintaining proper ventilation. Disease-causing organisms can enter through various routes including contaminated water, air, feed, transport vehicles, and human factors. Statistics indicate that diseases account for 9-13% of total production costs in poultry farming, emphasizing the importance of preventive measures in both crop and livestock components of the integrated system.	['About the Maize Enterprise\nThe maize crop will be planted on land that has been planted with tobacco. Considering that the farmers have limited access to land, there will not be any land opening hence it will be substitution of tobacco for maize. High-yielding disease resistant varieties of maize will be promoted. In addition, a set of recommended agronomic practices will be applied, all to minimise pest and disease incidences. Irrigation of the maize crop will not be an option because it is not cost-effective, but rather, the farmers will grow the maize during the major rainy season without chemical control of pests and disease. This will ensure that the crop has access to sufficient moisture.\nTraining of farmers to impart skills in Good Agronomic Practices (GAP) will eliminate the need for chemical control of pests and diseases in the maize enterprise. Similarly, good animal husbandry practices will be used to minimise disease in poultry. An integrated approach to weeds, pests and diseases control will be applied. Control of weeds will be through a combination of intercropping maize with low growing crops (cover crop) such as cow peas, ensure optimal plant population at the time of sowing and manual weed removal using a hoe. Other measures will include ensuring timely weeding of the crop to minimize massive weed infestation as this would affect the maize crop. Pest and disease control will be assured through enhancing the farmers’ capacity to prevent, suppress and eradicate pests and diseases. These practices will include ensuring that the gardens are clean; timely farming operations such as planting, weeding and harvesting; using resistant varieties of maize; and removing infected crops. The control of diseases in poultry will also be assured through training of farmers to impart good animal husbandry practices and skills. Most important will be observance of hygiene and good aeration in the poultry unit. Good farming practices have the effect of controlling pests and disease incidences.\n120 farmers in Hoima receive high yielding maize seeds under BFBM project\nOne twenty farmers from two sub-counties of Kitoba and kigolobya have receives high yielding maize seeds under the Better Farming Better Me project. This is the first phase of the project where each of the farmers received 10 Kgs of Longe 5 maize seeds for this season. The farmers who were purposefully selected belong to six groups, which the project is supporting. Majority of them are tobacco farmers.\nTugonzangane group, Bulyango Youth group and Kiryangobe farmers group are from Kitoba Subcounty, while the other three from Kigorobya include; Twimwikyangane , Abagamba Kamwe group, and\nKyamukwenda Twekambe farmers.\nThe farmers greatly appreciated the projected and as a sign of commitment, they have provided land, cleared it up, and will also contribute labor for the maize farm.\nThe harvested maize grain will be milled to produce maize bran, one of the ingredients of the chicken feed in addition to providing food for children to curb child malnutrition together with eggs. This integrated approach (Poultry - Litter – Maize - Maize bran) will promote a well-balanced ecosystem as well as synergy between the two enterprises.\nRelatedly, the chicken litter with droppings, will be used as manure for the maize gardens .', 'The poultry industry has experienced unprecedented growth in size and rapid growth. However, the poultry industry faces a narrow margin of profit as well as the risks that cause the weakness of the safety cycle. Especially after the intensive concentration of poultry farms and after the obsolete concept of the use of antibiotics as a panacea, as it did not realize that antibiotics have deteriorated in recent years. The emergence of resistance against antibiotics has led to thinking more about the use of safer and environmentally friendly elements. To not affect human health, it has come as vital security and an ideal way to face those risks, poultry production and, in the end, prevention not treatment. Hence the importance of biosecurity in poultry farms.\nWhere do diseases come from?\nDisease-causing viruses and bacteria can be transported from one flock to another on bird transporting equipment, trucks, tractors and other farm equipment as well as egg flats and cases.\nDisease enters the farm through several methods:\n- Water: contaminated water sources.\n- Air (and take into account the design of farms to the wind).\n- Breeding different ages: old age is a source of infection for young age.\n- Contaminated feed.\n- Transport vehicles and maintenance.\n- Old waste.\n- Live vaccines themselves\n- Pests such as rodents, dogs, insects, and spikes.\n- The entry of sick birds through the same company produces the chicks from sick mothers who are carrying the disease vertically.\n- Contaminated eggs.\n- Neighbor infected farm.\n- Dust – Feathers.\n- Or because of the human factor such as hands, feet, contaminated shoes, clothes, visitors and guards who move from farm to farm.\nWhat is biosecurity?\nA specific set and series of measures or measures taken to protect public health, animal health, plants and the environment to reduce the entry and spread of pathogens or pathogenic agents.\nWhat is the importance of biosecurity?\nThe occurrence of a disease of any animal herd or animal farm can destroy everything and cause loss of animals and sales, and a decline in production and high costs of veterinary health care and the consequent disinfection.\nProductive statistics indicate that diseases that kill the poultry industry annually are estimated at 9%-13% of the total value of the cost.\nThese losses can be reversed in two directions if we anticipate and implement biosecurity to reduce the percentage of mortalities this will increase the production of eggs and reduce production costs.\nWe return to say that it has introduced the concept of the industry for the poultry trade for many years and the speed of education and the concentration of large numbers of birds in one area, and high productivity, has become a strong target for infection and exposure to disasters at any time.\nIt is important to pay attention to the process of breeding from the ground up and protect it from any factor that could cause the emergence of disease and death and the resulting dead birds, which must be buried immediately and not left among other birds, but must be burned and buried so as not to attract flies and other predators. The environmental factor should also be used to control any disease, such as sun and drought, and to leave time intervals between breeding herd and herd.\nWhat constitutes biosecurity?\nWhich is done by keeping the animal in a controlled environment by fencing the farm to prevent animals from coming out and preventing birds and other animals from entering and applying the principle of all in - all out by disinfection and sterilization periodically on all incoming and outgoing to and from the farm.\nMinimize movement as much as possible of human elements by locking doors and preventing visitors from entering the house without the permission of the Department, for a specific purpose and for the necessary staff only, after taking off their clothes, wearing special clothes for the farm and cleaning the portable devices. Control of movements is not restricted to humans but other animals Such as rats, wild birds, predators and cats. Some say that cats are considered as an aid to eliminate rodents, but that their disadvantages outweigh their advantages and preferably rodenticide. Also fill all gaps and openings that can allow the entry of any animal, mowing the grass periodically around the Planter to reduce the risk of fire and nesting rodents and insects.\nVisitors should be kept on time for the visit and, if necessary, only as maintenance workers and inspectors, and are required to wear afrools, kufu and shoes after taking a hot bath and for this purpose If there is a need for a new hot bath, wear their own clothes and go out, there should be clear instructions by placing signs that are marked with no entry. The doors must remain locked. The keys are kept in a safe and secure place. The car must be sprayed and pass through a bath filled with disinfectant and the driver remains in the transport of feed or chicks.\nIt is an important aspect in biosecurity and is considered a major part of the triangle of biosecurity to prevent disease through the application of immunizations, especially viral ones, which there is no other way to prevent them except on this road, which is not useful with antibiotics and be careful to choose the type of vaccine Appropriate and given in a timely manner through the work of a program covering all the gaps in the time of breeding and it should be noted here that some vaccines give good immunity, but at the same time gives strong and harsh reactions to the flock and affect the emergence of other diseases.\nIs the most difficult stage of biosecurity. Leaving the litter parts around the farm after the cleaning process reduces or even eliminates the cleansing process as a whole. All surfaces inside and outside, and the feeder and maintenance tools must be cleared from the top and the bottom.\n- Remove the waste from the chicken farm and take it outside the farm for a long distance and then make sure that the waste does not reach the entrance to the farm. Then the process of cleaning the farm comes from the remains of the litter.\n- Remove lighting bulbs - fan blades and remove worn bulbs.\n- Remove miscellaneous equipment such as feeders, stripes and even tools from guard rooms, workers and service.\n- We start by sterilizing the ceiling and curtains carefully, fences, drains, stripes and other equipment with good disinfectants, lifting the curtains up and cleaning them. When the curtains are sprayed down to allow the air to remove the traces of disinfectant smells.\n- Use a clean, screw-free, dry and easy-to-absorbent litter.\n- Use insecticides around farms and fences.\n- After that the farm is closed and the curtains are lifted and the sterilization is evaporated and left for 24 hours and then the curtains are opened for ventilation.\n- Do not forget to unload the silo (feed tank) from the remaining feed from a previous flock and disinfect it from the inside with gaseous disinfectants. Remove the feed from the feed lines and not use them in the next flock.\n- Cleaning the water lines using a sodium hypochlorite disinfectant is a household bleach and leave and should not stay more than 24 hours so as not to spoil the rubber nipples and make sure the arrival of the sterilizer by sniffing the smell of chlorine at the end of the tubes and then rinsed vigorously and enough time with running water to make sure there is no trace of the smell of chlorine.\nPost-cleansing and sterilization:\n- Return tools to their natural places such as feeders and stripes.\n- Make sure to fill the water tanks.\n- Ensuring that generators work.\n- Check and operate automatic feeders.\n- Check the burners and make sure they burn well.\n- Check strip lines and leak water.\nApplication of Biosecurity in Poultry Farms:\nBiosecurity is a set of procedures that are followed in poultry farms that prevent the arrival of pathogens for birds. Biosecurity programs are the cornerstone of the poultry industry in general and in modern intensive education systems in particular.\nThe biosecurity program aims at three points:\n- Reduce exposure to pathogens by applying health care programs.\n- Increased bird resistance to disease through immunization programs against. communicable diseases.\n- Combating disease epidemics with medicines that completely eliminate or help prevent it.\nThe health care programs in poultry projects are concerned with reducing the level of microbial contamination in the environment surrounding the birds as one of the standard procedures used to start from the breeder farms through the hatchery to reach the broiler farms.\nThere are a number of concepts that need to be clarified, namely, some common terms such as sterilization, disinfection and cleaning. The term sterilization is called a set of chemical and physical means (such as radiation and heat) that completely eliminate any microbial contamination on surfaces or tools, including fungus spores. Disinfection means reducing the number of microbes in the medium where birds live to the minimum extent possible (except for fungal spores) using chemical solutions called antiseptics. While cleaning means the disposal of all organic substances, bacteria and microbes through mechanical washing processes and using special compounds called detergents.\nThe rule for cleaning poultry farm is that it must be preceded by a cleaning process so that the remaining residues of the previous batch, which may contain microbial contaminants that are the focal points of the infection as well as the disposal of organic materials that may prevent the arrival of disinfectant to the surfaces to be cleaned, which loses much of its effectiveness.\nPerfect detergent specifications:\n- Highly efficient for removing various organic substances and fats.\n- Do not be affected by the quality of water used in washing.\n- Do not leave any residue on surfaces after washing may interfere with disinfectants used.\n- Does not have any toxic effect.\n- Does not react with metals.\n- Perfect disinfectant specifications:\n- Wide spectrum which affects viruses, bacteria and fungi.\n- Economical cost compared to its features.\n- Do not lose any of its activity in the presence of organic matter or soap.\n- It has no toxic effect on birds.\n- It has an extended effect on the surfaces that have been cleared.\n- Does not affect the metals or other materials involved in the installation of the Farm.\n- Soluble in water and not affected by acids or alkalis or water hardness.\n- Its activity is not affected by temperature.\n- It does not take long to eliminate the microbes.']	['<urn:uuid:1eddd2af-6eaf-4456-b2ee-a6c80672fc7e>', '<urn:uuid:d0e0ab3d-e1d9-4415-bc67-b1e8980ba522>']	open-ended	direct	short-search-query	distant-from-document	three-doc	expert	2025-05-01T22:36:12.692263	5	103	2311
161	I'm designing a surveillance system for a city intersection with multiple high-resolution cameras. What would be an efficient way to process all the video data in real-time?	An edge computing solution would be most efficient for this scenario. Instead of streaming raw data from a thousand high-resolution cameras to a server or cloud for processing, which could cause significant latency, the system can be optimized by adding intelligence and processing power to the cameras themselves. Additionally, implementing a local processor in the network between the cameras and the cloud can control the cameras and handle some of the processing heavy lifting, such as using machine learning or artificial neural networks. This edge computing approach would be faster and more secure than simply having video sensors streaming raw data to the cloud.	['Someone who works in edge computing may be responsible for creating, maintaining and upgrading an edge computing environment and may involve the design and development of hardware and software solutions, overhauling existing network infrastructure so that there is a balance of load-shifting across a network and all the devices connected to it.\nSo what is edge computing? Years ago devices would send raw data to a local server and the server would do all the intelligent processing of that data. And then we started sending data to the cloud for processing and the results of that processing would be sent back over the network to the device of origin or some other terminal to read and further manipulate the results. However with more devices and more data going to servers and the cloud we start to get disruptions or slowing of the sending and receiving of data. Today there are a massive amounts of interconnected devices with massive amounts of data needing to be processed. Complex machines like planes and self-driving cars can generate many terabytes per day for each plane, car, automated factory, and so on. This is too much time-sensitive data to effectively process through the cloud.\nWhat’s the answer? Edge computing.\nAs the name suggests, Edge Computing pushes the processing of data closer to the edge of a network (in other words closer to the device of origin or within the device itself). With computing power being as compact and cheap as it is today most devices do much of the data processing internally and will send less, or more refined data across a network.\nThis speeds up the sending and receiving of data by working around the bandwidth limitations of conventional cloud networks and it also helps preserve the integrity of the data packets (when a network is overburdened packets of information can get spread out or bunched up and this can affect real-time sensitive information). As you can imagine avoiding network latency is important for critical and time-sensitive data processing – like with a surgical robot at a hospital, or a self-driving car navigating an intersection, or a network of surveillance cameras looking for faces and number plates. Say you had a thousand high-resolution cameras just streaming raw data to a server or to the cloud for processing – there could be a lot of latency depending on the amount of data and sophistication of the processing – like looking for particular faces at an intersection. However if the cameras themselves had more intelligence and processing power on board, and there was a local processor in the network that sat between the cameras and the cloud that not only controlled the cameras but also did some of the processing heavy lifting, (and in this case that might be using some sort of machine learning or artificial neural network) then we have an edge computing solution that could be faster, and more secure than just dumb video sensors streaming raw data to the cloud. Now imagine a smart factory, maybe a car manufacturer with lots of automated and semi-autonomous machines, devices, computers and servers all interconnected, talking to each other and updating each other and streaming to and from the cloud. Computing on the edge becomes an important part of the network infrastructure in this sort of environment.\nAs large organisations begin to implement more edge solutions to their networking of devices and machines, a job that we may see rise in popularity is a Master of Edge Computing. Typically these sorts of jobs are under the umbrella of titles like “Cloud and Edge Software Engineer”, “Software Architect”, “Connectivity Engineer”, “Network Engineer”, “IT Director”, “Cloud Engineer”, “IoT Embedded Engineer”, and other similar titles. The job description of someone involved in edge computing can be diverse – it could include the planning of a future roadmap for the company network; assessing feasibility, costs and technical requirements for a network; overseeing the overhaul of existing network infrastructures; modifying or designing new software and hardware.\nWith an edge computing environment in place, the job may also include maintenance, improvements and scaling of the network environment.']	['<urn:uuid:157bf33e-606a-4963-b101-c3ae56da43a4>']	open-ended	with-premise	verbose-and-natural	distant-from-document	single-doc	expert	2025-05-01T22:36:12.692263	27	104	686
162	What does being DRC Conflict-free mean?	DRC Conflict-free means that a product does not contain conflict minerals necessary to its functionality or production that directly or indirectly finance or benefit armed groups.	['Conflict Minerals Policy\n“Conflict Minerals” refers to minerals or other derivatives mined in the Democratic Republic of the Congo (DRC) and/or in the adjoining countries where revenues may be directly or indirectly financing armed groups engaged in civil war, resulting in serious social and environmental abuses. In July 2010, the United States passed the Dodd-Frank Wall Street Reform and Consumer Protection Act. Section 1502(b) of this law requires all US stock listed companies to disclose the usage of Conflict Minerals (Tin, Tantalum, Tungsten, and Gold . . . 3T1G).\nInventus Power™ fully supports this legislation and the Electronic Industry Citizenship Coalition (EICC)/Global e-Sustainability Initiative (GeSI) position to assure that specified minerals are not being sourced from mines in the “Conflict Region”, which are controlled by non-government military groups. Consistent with the ‘OECD Due Diligence Guidance for Responsible Supply Chains of Minerals from Conflict-Affected and High-Risk Areas’, Inventus Power™ has adopted the EICC Due Diligence reporting process and requires the following declarations from all Inventus Power™ suppliers:\n- Inventus Power™ requires our suppliers to source from socially responsible suppliers. This means sourcing from suppliers who have confirmed non-conflict sources, even if those sources do come from the DRC or adjoining countries.\n- Suppliers are required to have policies and procedures in place to ensure that products and parts supplied to Inventus Power™ are “DRC Conflict-free*”.\n- Suppliers are required to provide all necessary due diligence information, including smelters’ name, to confirm that all 3T1G (Tin, Tantalum, Tungsten, and Gold) supplied to Inventus Power™ is “DRC Conflict-free”.\n- Inventus Power™ requires suppliers to pass this requirement onto their supply chain.\n- Compliance to these requirements will be taken into consideration when selecting and retaining suppliers.\n*“DRC Conflict-free” means that a product does not contain conflict minerals, necessary to the functionality or production of that product, that directly or indirectly finance or benefit armed groups.\nEAR99 and OFAC Regulations Policy\nInventus Power™ works with suppliers to ensure Inventus Power’s supply chain complies with the rules and regulations of the U.S. Department of Commerce, Export Administration Regulations (EAR99), and the Office of Foreign Assets Control (OFAC).\n- EAR stands for the Export Administration Regulations (15 CFR §§730-774) and they are administered by the Bureau of Industry and Security (BIS) under the U.S. Department of Commerce. The EAR governs the export of most items in the U.S., especially dual use items as enumerated on the Commerce Control List (CCL).\n- EAR99 is the general “catch-all” classification number assigned to any item that is subject to the EAR but that does not have a specific export control classification number listed in the Commerce Control list. By far, the vast majority of U.S. origin goods are classified as EAR99, and under most circumstances, do not require a license for export.\n- OFAC stands for the Office of Foreign Assets Control (31 CFR §§500-599) and is an office under the U.S. Department of the Treasury. OFAC is responsible for enforcing the foreign policy of the U.S. government, including all trade sanctions, embargoes, and financial interactions with prohibited or blocked individuals or entities.\nDOWNLOAD POLICY AS PDF']	['<urn:uuid:5e21080c-5c5c-46ef-906a-b88c34e28364>']	factoid	with-premise	concise-and-natural	similar-to-document	single-doc	novice	2025-05-01T22:36:12.692263	6	26	518
166	modern bathroom design handicap friendly space	"For a modern, handicap-friendly bathroom design, several elements need to be considered. The vanity selection is crucial - floating vanities are particularly suitable as they provide space underneath for wheelchairs while maintaining a modern, sleek appearance. They can be installed as either single (24""-48"" wide) or double units (48""-72"" wide). The bathroom needs proper space planning, with at least 32 inches of clearance for wheelchair passage. ADA-compliant sinks must be installed with adequate underneath clearance and insulated pipes. For shower access, a wheelchair-accessible or walk-in shower is recommended, and grab bars should be installed for safety and stability."	['Whether you’re building a new bathroom or renovating an existing one, choosing the right bathroom vanity design is always a major decision. One of the biggest purchases you’ll make for your bathroom is the vanity units, along with the tub and shower.\nIt’s not just enough to get good vanity units. There are lots of factors you have to consider when buying it. Here are some things you should look out for when buying vanities for your next bathroom remodel.\nChoosing the Right Bathroom Vanity Design\nBathroom Vanity Measurement\nOne of the biggest factors to consider when choosing your vanities is the size of your bathroom. Choosing ones that are too small will create leftover space while choosing ones that are too big will suck in all the space available for movement.\nYour overall space and, most importantly, the floor plan will help you choose the right bathroom vanity design. Look at the height, depth, and width.\nIf you have a small bathroom that can only take a single vanity, then automatically you can avoid looking at double vanities. You also have to choose vanities that allow you to leave enough space for protruding cabinets, and for feet to pass through.\nThere should also be enough space for other bathroom vanity furniture.\nSpeaking of vanities…\nWhat kind will suit my bathroom vanity design?\nThere are different kinds of vanities for sale, so your overall space, floor plan, and personal style will determine the kind of vanities you’ll purchase. There is no ‘right-size’ for bathroom vanities, but there are usually standard sizes for single and double vanities\nNow, there are basically 3 kind of vanities- the single, double and floating vanities\n· Single Vanities\nThis is the commonest type of vanity. It consists of just one sink and is often used for small-sized bathrooms. The size normally ranges from 24”- 48”, but there are some as wide as 60”.\n· Double vanities\nCan you guess why it’s called double?\nExactly. It has two sinks. It is otherwise known as “His and Her sink”\nThe size often ranges from 48” to 72”, but most of these vanities are 60”. This is the best type of vanity for shared bathrooms.\nThis is very ideal for modern bathrooms because it leaves space underneath for easy cleaning. It can exist as both a single and double vanity, although it’s mostly produced as a double vanity.\nIt’s great for small bathrooms because it conserves space. It’s also great for homes with lots of people, especially disabled people in wheelchairs.\nIt’s not enough to simply want to buy vanities. You have to buy ones that suit your ideal bathroom vanity design. After noting your floor plan and overall bathroom size, you can now purchase vanities that suit your style of that size.\nYou can either choose a traditional, modern, transitional, or farmhouse look.\nModern vanities look very sleek and flashy. Traditional vanities have lots of wooden details and carvings. Transitional vanities are a blend of both modern and traditional vanities. Then, farmhouse vanities are from reused furniture and have organic undertones.', 'In the realm of aging, you have got to catch the young at heart before they realize that running, jumping, and climbing is truly a temporary state of mind. Anticipating the slowing of mobility and the onset of disability demands to make accessibility changes in home and hearth. In the twilight years, and for the disabled, living well is all about ensuring independent free movement throughout your homestead. Before you consider building a new home with considerations built-in before you cross the threshold, consider the following tips to make your home handicap accessible.\n- Home Access: Ramps and Doorways\nHave a ramp built to make for an easy transition from outside to inside. This will help with wheelchair access and with anyone who has mobility issues. Depending on materials and size, the cost varies with low-threshold ramps to a custom-designed ramp. Do not forget to add the cost of a permit. Check with your local municipality for permit regulations and information to meet building codes.\nMost household doorways are too small for a wheelchair or walker to easily pass through. Before investing $500 to $1000 for widening, consider offsetting hinges that could help a door swing completely open. That shift could add several inches before committing to a costly job. Also, evaluate all of your devices before beginning changes to your homestead. Knowing width, length, and turning radius can make it easier to accurately widen spaces but also be conscious of the thoroughfares in-between.\n- Bathroom: Grab Bars, Risers, and Showers\nThese can increase reassurance, security, and stability around the shower, tub, and toilet. From professionals to handymen, the cost will run your coffers between $100 to $300 apiece.\nToilet risers make a smoother transition from standing up to sitting down by raising the height of the toilet seat. Risers are perfect for people who have difficulty bending over, sitting down, or standing up. They may be available at drug stores and some home improvement businesses. According to some of the literature, the cost will run less than $50.\nMost showers have high walls that are difficult to step over for the mobility limited. Try creating or replacing the tub with a wheelchair accessible or walk-in shower. If you are on a tight budget, try buying or installing a shower bench for increased stability.\n- ADA Sinks\nThe bathroom is one of the most critical spots for an accident to happen. For starters try installing an ADA compliant restroom beginning with an ADA sink. The design for these sinks assists users with disabilities and mobility problems. Calculating sink mountings results in space for wheelchairs and clearance under the sink. Keep floor space around and beneath clear of debris. Pipes also need to be insulated.\n- Around the House: Cabinets, Flooring, and Furniture\nFor a homeowner with mobility issues, cabinets are frequently too high to reach; an increased difficulty is in having access to what is inside. Move frequently used items such as bathroom towels, medication, and dishes to lower cabinets. Also, move appliances closer to the sink to make for easy task performance.\nConsider hardwood or vinyl flooring for smooth transitions across walking surfaces. Area rugs and carpeting are hazards for anyone with mobility problems; especially, with those who use wheelchairs or walkers.\nFor independent freedom of movement, construct pathways in the house that are at least 32 inches wide between furniture. To make the thoroughfare easy to walk may require downsizing effects and using storage.\n- Government Assistance\nTry not to feel that these changes may be outside of your budget. Administered by the Federal government, disability grants exist for your use. Check into The Assisted Living Conversion for Eligible Multifamily Housing Projects (ACLP) through the U.S. Office of Housing and the Housing and Urban Development Office. Medicaid programs are also offered in most states to cover changes to the homestead.']	['<urn:uuid:64ba13cb-18b7-4b66-9c58-68f284b4c26a>', '<urn:uuid:b14be32e-088d-464d-8b3a-14b926c635dd>']	open-ended	with-premise	short-search-query	distant-from-document	three-doc	novice	2025-05-01T22:36:12.692263	6	98	1156
169	eco building saves money advantages	Eco-friendly or green buildings offer multiple cost-saving advantages. They reduce energy consumption and associated costs through efficient lighting and ventilation systems. Solar and renewable energy sources are cheaper than fossil fuel alternatives. The buildings also minimize water usage through efficient plumbing and recycling systems. For example, Ramah in the Rockies implemented solar water heating and timer-controlled lighting to reduce electricity and propane costs, while S M Sehgal Foundation's green building reduced electricity costs by almost 50 percent through intelligent design.	['by Tamra L. Dollin\nEver wonder what it takes to build a ‘green’ camp from the ground up? What does it mean to build in an environmentally sustainable way? How do you minimize your impact on the land while building a facility to comfortably house hundreds of campers and staff every year? In what way can the physical buildings reinforce the educational values being practiced at camp?\nRamah in the Rockies is responsible for building up the magnificent 360 acre Rocky Mountain site which hosts Ramah Outdoor Adventure, a unique specialty camp (funded by the Foundation for Jewish Camp and the Jim Joseph Foundation) combining outdoor adventure and environmental awareness with vibrant Jewish living and learning. The core values of Ramah in the Rockies are: Limud (Learning), Etgar (Challenge), Yirah (Awe) and Shemirat HaTeva (Stewarding the environment). We wrestle every day with the challenge of putting those values into practice as we contemplate and build new structures on the property to accommodate the growing number of campers wanting to attend Ramah in Colorado.\nWe are building several new structures for this coming summer, including new tent platforms, a programming pavilion and a new restroom. Here are some questions we have to answer:\n“How many years payout are you willing to go?” This means how much more money are we willing to pay now, for savings that may take several years to realize? This must be considered when contemplating energy saving techniques or alternative energy sources. For example, a recommendation has been made to add a solar array or solar ‘garden’ to our site, which would feed electricity back to the public grid. Investing in a solar array would cost money up front, but the savings would be realized over a period of several years, by lowering our monthly electrical bills, and we would be using a clean source of energy.\n“Do you have a master plan for sustainability at the camp?” We actively seek out partnerships (other non- profit organizations, government agencies or corporations) and hope to serve as a laboratory for some new ideas in the field. Some suggestions include building with recycled wood harvested from local dead trees with a company from Austin, TX, solar powered cabins made from renewable materials with an Israeli firm, equine anaerobic digestors to reuse horse manure to power barn lighting. We are reaching out to NREL (National Renewable Energy Laboratory), located in nearby Golden, CO for assistance in formulating an overall strategy.\nWe have adopted the following sustainable initiatives for our new restroom facility about to be built: pre-heated water using a rooftop solar water heating system, reducing both electricity and propane use, ‘daylighting’ to maximize natural light during the day, putting all lighting systems on timers to control usage, ‘metering’ of sink and shower faucets to reduce water consumption and installing two-button flush system for toilets. This is in addition to our existing solar composting toilets, thoughtfully built by our predecessors the Girl Scouts, which are clean and odor- free desiccating (non-flushable) toilets.\nTo keep our initiatives on track, evaluate new ideas, decide on implementation, we formed a Sustainability Committee. Last summer, this committee took charge of several exciting initiatives, including the planting of hundreds of trees in a heavily burned area of camp, arranging for chickens to live at camp and be cared for by the campers, and initiating the beginning of a camp wide recycling effort.\nDeveloping these sustainability initiatives will take time, energy and resources, but our vision is clear:\nWe are both users and stewards of the land and our natural resources. It is our imperative to care for nature as we are enriched and nourished by its bounty.\nTamra L. Dollin is Project Director, Ramah in the Rockies.', 'Sustainability is a word that we encounter and read about on a daily basis. It thus becomes important to know more about the concept. Broadly, sustainability refers to meeting present needs without compromising the ability of future generations to meet their needs. The broader concept refers to natural resources, social equity, and economic development. However, the primary driving force behind the concept of sustainability emanates from two of the most pressing issues of today: judicious use of scarce natural resources and environmentalism.\nExtending the concept to architecture, sustainable architecture seeks to limit the negative impact of buildings on the environment through efficiency and moderate use of materials, energy, development space, and the ecosystem at large. The main focus areas in sustainable architecture rest on a premise of conservation in energy consumption and building material use. The idea is to look at building design that is aimed at limiting the impact of humanity on the environment.\nSustainable architecture is a major consideration in building design as architects try to ensure that buildings generate minimal harmful effects to the ecosystem and the communities.\nSustainable architecture has its reflections in three major areas:\n- Materials. Building materials, construction methodology, and use of resources.\n- Operation. Sustainable operation during the building life cycle, including its ultimate disposal.\n- Energy efficiency. Construction with the goal of achieving long-term energy and resource efficiency as well as function.\nThe benefits in the implementation of sustainable architecture are multipronged, and positive impact can be derived in environmental, economic, and social space. Some of these are:\n- Conservation and restoration of natural resources,\n- Reduction in energy consumption and waste,\n- Reduction in continued dependence on traditional energy sources,\n- Improvement in productivity and performance, and\n- Reduced demands on local utility infrastructure.\nAs architects around the globe increase their focus on the unique challenge sustainability presents in architecture, a conscious shift has been made to buildings being sustainably designed. These buildings strive to reduce their impact on the environment through energy and resource efficiency, reduction in non-renewable resource consumption, and enhancing the natural environment.\nWhat Is A Green Building?\nSustainable architecture has resulted in the emergence of the “green” building. The World Green Building Council defines a Green building that, in its design, construction, or operation, reduces or eliminates negative impacts and can create positive impacts on our climate and natural environment. Green buildings preserve precious natural resources and improve our quality of life.\nThus sustainable architecture, or green architecture, or green design, is an approach to building structures that minimize harmful effects on humans and the environment.\nGreen buildings, thus created, may have several defining characteristics and features like:\n- Efficient use of energy, water, and other resources like use of water-saving plumbing fixtures, energy-efficient lighting, and ventilation systems designed for efficient heating and cooling.\n- Use of alternative or renewable energy sources such as solar and wind power.\n- Reduction of waste and pollution and promotion of reuse and recycling.\n- Improved indoor environmental air quality.\n- Use of building materials that are non-toxic, non-synthetic, responsibly harvested, recycled, ethical, and sustainable.\n- Consideration of the environment in design, construction, and operation, e.g., efficient use of space, minimal harm to the natural habitat.\n- Consideration of the quality of life of occupants in design, construction, and operation.\n- A design that enables adaptation to a changing environment.\nWhile most green buildings may not have all these features, green components such as solar energy and rainwater harvesting bring multiple benefits and are effective means to addressing climate change, driving sustainability, and promoting economic growth and vibrant communities.\nSome key advantages in the adoption of green buildings are their potential to reduce greenhouse gas emissions, thus safeguarding the environment; reduction in energy use, thereby cost savings on energy spending; reduced and efficient water use and recycling of waste water to minimize the detrimental effects of polluted water; community benefits through a lowered carbon footprint and conserved resources; and human benefits such as well-being, satisfaction, engagement, and productivity.\nBuildings that are healthier, cleaner, and greener do good not only for the planet, but also for the people.\nGreen Buildings and the Sustainable Development Goals\nGreen buildings contribute to the Sustainable Development Goals, and can truly catalyze and address some of the most pressing issues of the world.\n- COST-EFFECTIVE & CLEAN ENERGY (SDG 7). The most cost-effective energy is the through renewable energy sources that are not put to use. However, green buildings leverage renewable energy, which is cheaper than fossil fuel alternatives. Renewable energy produces no carbon emissions, hence, limiting the impact on the planet is an additional benefit.\n- SUSTAINABLE COMMUNITIES & CITIES (SDG 11). Almost 60 percent of the world’s population will settle down in the urban areas by 2030; hence, ensuring their sustainability is of paramount importance. Buildings are the foundation of urban cities, and green buildings are key to their long-term sustainability. Be it homes, schools, shops, offices, or green spaces, the makeup of communities are the end result of the built environment that must be sustainable to ensure a high quality of life for all. In fact, in many countries, Green Building Councils have developed tools that encourage the formation of green neighborhoods and districts, and have helped cities like Mandaue in Philippines to create and implement policies that promote sustainability across cities.\n- LIFE ON LAND (SDG 15) – The materials used to construct a building play a major role in determining its sustainability. Hence the construction industry and its supply chains have a significant role to play in leveraging responsibly sourced materials such as timber. Green building certification tools also acknowledge the need to reduce the use of water; value the biodiversity, ensuring it is protected; and incorporate this into the area they build on during and after construction, minimizing the damage and design to enhance biodiversity, such as through landscaping with local flora.\nThe way homes and workspaces are designed have an impact on our health, our neighborhoods, and the planet. As a result, the concept of green buildings has started to make an impact in building design and architecture. While in the past some realty players were reluctant to make the switch to green buildings due to higher upfront costs, trends have started to change as people view the broader picture of larger investment returns, such as reduced emissions, lower utility costs, and increased social value.\nGreen buildings are not about fads and trends. They must be designed in a way that ensures their resilience and adaptability, keeping our changing global climate in mind. This is critical in developing countries, most of which are vulnerable to the effects of climate change. But it’s not solely about future proof buildings, the infrastructure must be equally sustainable and resilient to future risks.\nGreen Buildings and the Environment\nThe World Environment Day is celebrated across the globe on 5th June and is the principal platform of the United Nations to create awareness and action to protect the Earth’s fragile environment.\nBuildings are one of the largest consumers of resources such as water, energy, and other materials. Besides, they contribute wastes and pollutants during the three phases of their life cycle: construction, maintenance, and deconstruction. The rampant degradation of the environment across the globe has made it imperative to take measures to optimize the use of natural resources and reduce waste. The shift to green building construction and practices can address these concerns and help make a shift to a sustainable environment.\nBuildings Affect the Climate\nAccording to Architecture 2030, buildings account for almost 40 percent of the greenhouse gas emissions (GHGs). Additionally, if we take into account the other activities, and infrastructure, such as transportation, and other buildings, the number jumps further. With green buildings, the impact our buildings have on climate change can be significantly reduced, while also building resilience into our homes and communities.\nGreen Buildings Generate Fewer Greenhouse Gases\nGreen buildings encompass a structure’s design, planning, construction, operations, and end-of-life recycling and renovation, while considering indoor environmental quality, energy, water, materials selection and location. Green buildings reduce landfill waste, enabling alternative transportation use, and encouraging retention and creation of vegetated land areas and roofs. High-performing green buildings, the LEED-certified buildings in specific, provide the means to reduce the climate impacts of buildings and their occupants.\nLEED rewards all the thoughtful decisions that encourage compact development and connection with transit and amenities, helping the lower GHGs in association with transportation. Additionally, less transport of materials to and from the buildings eliminates the associated fuel consumption. All this combined significantly reduces the carbon footprint of buildings and its occupants beyond what energy efficiency alone does. The inhabitants providing feedback, using systems that showcase a building’s environmental efforts and performance, can drive further reductions.\nWhat better than for the community, architects, policy makers, and users to come together to take a pledge to move toward green buildings and take a step to safeguard the habitat and environment.\nS M Sehgal Foundation (Sehgal Foundation), a rural development NGO in India, has constructed its headquarters building in Gurugram, Haryana, according to the Platinum Standards LEED set by U.S. Green Building Council and the Indian Green Building Council.\nThe founders of S M Sehgal Foundation, Dr. Suri Sehgal and Mrs. Edda Sehgal, conceptualized the “green” design, construction, operation, and maintenance of the building to be in keeping with the organization’s mission to promote sustainable rural development in India and reduce the building’s impact on human health and the environment.\nSehgal Foundation’s building includes green features like photo-voltaic solar panels on the rooftop generating 35 kW of electricity; solar water heaters; shading devices; a rainwater harvesting storage tank of 800,000 liters; onsite recycling of gray and black water; groundwater recharging (zero runoff site); courtyards maximizing natural light and ventilation; recycled wood; various endangered plant species; use of in-situ bricks; maintenance-free exteriors; insulated walls; use of rapidly renewable rubber wood and bamboo; double-glazed glass, and a highly reflective roof finish, among others.\nThe construction of the building is based more on common sense and only a small part uses sophisticated technology. With intelligent designs such as that of the S M Sehgal Foundation building, electricity cost can be brought down by almost 50 percent. The incorrect notion of the high cost of green buildings is a myth. S M Sehgal Foundation in line with their mission “to achieve positive social, economic, and environmental change” have constructed this ecofriendly building, taking a step toward sustainability.\nWatch a video on S M Sehgal Foundation’s green building in Gurugram, Haryana']	['<urn:uuid:df64ae73-6d78-41f9-8868-b59c343d731f>', '<urn:uuid:4709d2ef-e688-4365-84ca-b7c15f89a7cb>']	factoid	with-premise	short-search-query	distant-from-document	three-doc	novice	2025-05-01T22:36:12.692263	5	80	2381
170	explain sustainable development definition meaning	Sustainable development combines two key concepts: sustainability and development. Sustainability is defined as the capacity to create, test, and maintain adaptive capability. Development is the process of creating, testing, and maintaining opportunity. Therefore, sustainable development refers to fostering adaptive capabilities while creating opportunities. It is not a contradictory concept, but rather a logical partnership aimed at creating sustainable futures where human livelihood becomes easier, human opportunities become richer, and nature's diversity is better sustained.	"['|Home | Archives | About | Login | Submissions | Notify | Contact | Search|\nCopyright © 2000 by The Resilience Alliance\nThe following is the established format for referencing this article:\nHolling, C. S. 2000. Theories for sustainable futures. Conservation Ecology 4(2): 7. [online] URL: http://www.consecol.org/vol4/iss2/art7/\nEditorial Theories for Sustainable Futures C. S. Holling\nUniversity of Florida\nPublished: November 30, 2000\nMake things as simple as possible. But no simpler. (Albert Einstein)\nSustainable development and management of global and regional resources is not an ecological problem, nor an economic one, nor a social one. It is a combination of all three. And yet actions to integrate all three typically have short-changed one or more.\nSustainable designs driven by conservation interests often ignore the needs for an adaptive form of economic development that emphasizes human economic enterprise and institutional flexibility. Those driven by economic and industrial interests often act as if the uncertainty of nature can be replaced with human engineering and management controls, or ignored all together. Those driven by social interests can act as if community development and empowerment of individuals encounter no limits to the imagination and initiative of local groups. Each view captures its prescriptions in code words: regulation and control; get the prices right; empowerment; stakeholder ownership. These are not wrong, just too partial. Investments fail because they are partial. As a consequence, the policies of governments, private foundations, international agencies, and NGOs flop from emphasizing one kind of myopic solution to another. Over the last three decades, such policies have switched from large investment schemes, to narrow conservation ones to (at present) equally narrow community development ones.\nEach group builds its efforts on theory, although many would deny anything but the most pragmatic and nontheoretical foundations. The conservationists depend on theories of ecology and evolution, the developers on variants of free-market models, the community activists on theories of community and social organization. All these theories are correct, in the sense of being partially tested and credible representations of one part of reality. The problem is that they are partial. They are too simple. We lack an integrated theory that can serve as a foundation for sustainable futures, a theory that recognizes the synergies and constraints among nature, economic activities, and people, a theory that informs and emerges from thoughtful practice.\nEvidence points to a common cause behind past failures of investments in sustainable development. Historically, the management of forest, rangelands, fisheries, and wildlife resources was dominated by theories of carrying capacity and goals of sustainable yield. Human behavior was ignored. The application of these theories led to the expectation that target variables such as employment could be stabilized and created a demand for a constant flow of product. These policies were successful initially, and profit and employment were, in fact, stabilized. But their very success resulted in slow changes in key ecological, social, and cultural components not captured in the management models: changes that typically led to the collapse of the entire system. The ""economic extinction"" of cod along the coast of eastern North America is a prime example. From a review of a wide range of failed sustainable development initiatives, a common pathology emerges. At the extreme, the ecological system loses resilience, the industries become dependent and inflexible, the management agencies become rigid and myopic, and the public loses trust in governance.\nThere are so many examples of this pathology that we have learned the lesson well in theory, if not entirely in practice. We recognize that human behavior and nature’s dynamic are linked in an evolving system. We realize that the seeming paradox of change and stability inherent in evolving systems is the essence of sustainable futures. We now know that to counteract the current pathology we need policies that are dynamic and evolutionary. We need policies that expect results that are inherently uncertain and explicity address that uncertainty through active probing, monitoring, and response. However, we cannot successfully implement these new policies because we have not learned the politics and we ignore the public.\nTo date, the papers in Conservation Ecology that have focused on Adaptive Ecosystem Management and global change have carryied a gloomy message. Many provide examples in which the implementation of probing policies that recognize uncertainty and that allow for learning is frustrated. The realization of these new policies is frustrated by bureaucratic politics within organizations and by power politics outside agencies. Bureaucracies can become as much vested interests as can environmentalists and industries, and the politics of each group can exploit uncertainty in explicit disinformation campaigns. And we scientists provide the ammunition for them when our delight in rigorous analysis of the parts of a system ignores the consequences of the interaction of the parts and blinds us to political realities. It is no wonder that science and scientists have a bad name in so many situations in which collaboration among scientists, small enterprises, and conservationists could so obviously be a benefit to all.\nIs the failure to implement dynamic and evolutionary policies the result of the inherent complexity of these ecological, economic, social systems? That view is incisively explored by Emery Roe in his book Taking Complexity Seriously. That book is reviewed in this issue of Conservation Ecology from four perspectives, including the author\'s. That view sees complexity as anything we seem not to understand because there apparently are large numbers of interacting elements. Here I present another, alternative view suggesting that such complexity may be in the eye of the beholder, and that most of the ""large number of interacting elements"" may be, in fact, the consequence of a smaller number of controlling processes. It is this latter view to understanding the smaller number of controlling processes that opens a line of deep enquiry about complex evolving systems. Both views provide the motivation and direction needed to develop alternative perspectives and models. And both provide a focus for the kind of deliberative conversations about difficult issues that Conservation Ecology encourages. There is no one path to understanding.\nThe alternative view that I propose argues that there is a requisite level of simplicity/complexity behind complex, evolving systems that, if identified, can lead to understanding that is rigorously developed but also can be lucidly communicated. It argues that if you cannot retain a handful of causes in your explanation, then your understanding is simplistic. If you require more than a handful of causes, then it is unnecessarily complex. If you cannot explain it to your neighbor, you do not truly understand it. That level of understanding is built upon a foundation of adequate integrative theory, rigorously developed, rooted in empirical reality, and communicated clearly with metaphor and example. The first requirement to achieving that level of understanding is to begin to integrate the essence of ecological, economic, and social science theory. And we need to do so with a goal of being ""as simple as possible but no simpler"".\nIn the late 1980s, the Royal Swedish Academy of Science established an institute, The Beijer International Institute of Ecological Economics, to bridge the disciplines of economics and ecology and, more generally, the natural and social sciences. One of the inspired creations of the Director, Karl-Göran Mäler, was an annual meeting on an island in the Swedish archipelago of economists, ecologists, mathematicians, and others from the natural and social sciences. There was never an agenda – only one or two general questions. What is poverty? What ecological and human stresses come from population growth? What is resilience of an economy? Of an ecosystem? How to measure values?\nOut of those meetings and their deliberative conversations came a growing, deep understanding among the participants of fields other than their own. Not the superficial polarization so characterizing much debate, but understanding of strengths and weaknesses. The surprise was that there was so much agreement between ecologists and economists: the world’s human and natural systems are becoming dangerously stretched; the methods of each discipline had remarkable similarities; the theories and mathematics were strangely similar—and inadequate. The critical differences were amazingly slow to emerge. The desire for collaborative dialogue and the sheer decency of a Swedish context led us to steer away from disagreements. But it is the tension of differences that can crystallize discovery.\nIt ultimately became clear that there were deep and fruitful differences. Each of the primary fields of economics, ecology, and institutional analysis has developed tested insights. But each is missing key elements that would allow for the kind of integrative theory and practice that is required for sound decision making on sustainable resource use issues. As examples:\nEconomics: Modern economics has gone far in discovering the various pathways through which millions of expectations of, and decisions by, individuals can give rise to emergent features of communities and societies (e.g., rate of inflation, productivity gains, level of national income, prices, stocks of various types of capital, cultural values, and social norms). Two factors make economic theory particularly difficult. First, individual decisions at any moment are themselves influenced by these emergent features, by past decisions (e.g., learning, practice, and habit), and by future expectations. Second, the emergent features that can be well handled by existing economic theory and policy concern only fast-moving variables. The more slowly emergent properties that affect attitudes, culture, and institutional arrangements are recognized, but are poorly incorporated.\nEconomists know that success in achieving financial return from fast dynamics leads to slowly emergent, nearly hidden, changes in deeper and slower structures, changes that can ultimately trigger sudden crisis and surprise. But the complexities that arise are such that most modern economists are frustrated in their attempts to understand the interactions between fast- and slow-moving emergent features.\nEcology: Ecosystem ecologists have made it plain for a long while that some of the most telling properties of ecological systems emerge from the interactions between slow-moving and fast-moving processes and between processes that have large spatial reach and processes that are relatively localized. Interactions between, for example, regional patterns of vegetation formed by major disturbance processes like fire and insect outbreak, and local species composition formed by competition among species. Those interactions are not only nonlinear, but also they generate alternating stable states and normal journeys of biotic and abiotic variables through those states. It is those journeys, measured in years, decades, and centuries, that maintain the diversity of species, spatial patterns, and genetic attributes that give resilience to ecological systems.\nWhat this tells us is that variability is not merely an inconvenient characteristic of productive, dynamic systems. Rather, it is critically necessary to their maintenance. Ecologists have made significant advances in understanding the specific role of variability in maintaining the resilience of natural systems and the conditions that cause a system to flip into an irreversible, and typically degraded, state controlled by unfamiliar processes.\nHowever, ecologists have been largely ignorant of human behavior, organizational structures, and institutional arrangements that mediate the relationships between people and nature.\nSocial Science: Institutional theory and analysis does consider such features, but in a largely static sense. Hence, it also stops just short of the confluence point among the three fields that could provide us with the integration we need. Institutional theory currently provides an understanding of the variety of arrangements and rules that have evolved in different societies to harmonize the relationship between people and nature. Social scientists have gone far in describing the way people store, maintain, and use knowledge in stable circumstances. But an integrative approach requires attention to the very same dynamic dimensions that economics and ecology, each in their own way, have developed.\nIn order to plan for sustainability, we need to know, and we need to integrate, how information is evaluated and how counterproductive information is rejected at times of deep change. How is new ""knowledge"" created from competing information sources and incorporated with useful existing knowledge? Which processes create novelty, which smother innovation, which foster it? None of the disciplines of ecology, economics, and institutional theory, as construed at present, can, in isolation, help in these fundamental questions of innovation, emergence, and opportunity.\nEvolution and Complex Systems: Yet, those questions are at the heart of development: the emergence of novelty that creates unpredictable opportunity. It is biological evolutionary theory, expanded to include cultural evolution, that does deal with just those questions. The recent invention of complex systems studies explicitly sees ecological, economic, and social systems each as specialized representations of a complex adaptive system. There have been wonderful advances achieved by borrowing those mechanisms that generate variability from known biological processes and exposing the emergent patterns that result. But, as for each of the other fields, the representations are partial. They are detached from efforts to represent the necessary and just sufficient complexity in natural and human processes, and to test the adequacy and credibility of the results.\nEven the most ruthlessly pragmatic goal for developing policies and investments for sustainability needs a theoretical foundation that integrates ecological with economic with institutional with evolutionary theory and that overcomes the disconnect rooted in current theoretical limitations within each field.\nIt was this diagnosis that launched the “Resilience Project”, a five-year effort of an international group of ecologists, economists, social scientists, and mathematicians. The project initiated a search for integrative theory and integrative examples of practice. The goal was to develop and test elements of an integrative theory at the level of simplicity necessary for understanding, but with the complexity required for developing sustainable policy.\nThe results of Resilience Project are summarized in the final report to the MacArthur Foundation (http://www.resalliance.org/reports/). For me, it was a huge advance in unraveling the puzzles and paradoxes that had confused me over the years in my efforts to understand the interactions between nature and people. The fundamental paradox is that change is essential, and yet stability is necessary. Together with some 120 scientific papers that arose out of the work, the four forthcoming books from the project constitute an important contribution to the theory of sustainable use of natural resources. In the exuberance of discovery, those results were boiled down to 10 conclusions, as noted in the final report: 10 tablets from the Resilience Mountain!\nThe heart of the work is now developed and described in a book in press with Island Press, edited by Lance Gunderson and C. S.Holling: Panarchy: Understanding Transformations in Human and Natural Systems. Panarchy is the term we devised to describe the evolving nature of complex adaptive systems. It encapsulates how novelty and change coexist in a context of persistence and stability. It resolves the paradox of change and stability.\nWe define panarchy to be the structure in which systems of nature (e.g., forests, grasslands, lakes, rivers, and seas), of humans (e.g., systems of governance, tribes, and cultures), as well as combined human—nature systems (e.g., agencies that control natural resource use), are interlinked in never-ending adaptive cycles of growth, accumulation, restructuring, and renewal. These transformational cycles take place in nested sets at scales ranging, for example, from a leaf to the biosphere, over periods from days to geologic epochs. By understanding these cycles and their scales, it seems possible to identify points at which a system is capable of accepting positive change, and possible to use those leverage points to foster resilience and sustainability within a system.\nThe panarchy summarizes succinctly the heart of what we define as sustainability. The fast cycles invent, experiment and test; the slower ones stabilize and conserve accumulated memory of past successful, surviving experiments. In a healthy system, each level is allowed to operate at its own pace, protected from above by slower, larger levels, but invigorated from below by faster, smaller cycles of innovation. The whole panarchy is therefore both creative and conserving. The interactions between cycles in a panarchy combine learning with continuity.\nThis clarifies the meaning of sustainable development. Sustainability is the capacity to create, test, and maintain adaptive capability. Development is the process of creating, testing, and maintaining opportunity. The phrase that combines the two, sustainable development, therefore refers to the goal of fostering adaptive capabilities and creating opportunities. It is therefore not an oxymoron, but represents a logical partnership.\nSustainable futures are ones in which the basic means of human livelihood get easier, human opportunities become richer, and nature\'s diversity is more sustained — and not only in the rich parts of the world. Utopian, perhaps, but the resilience of nature and the ingenuity of people would make it feasible, if our institutions and those who utilize and control them had sufficient flexibility and vision. The ultimate test of the discoveries and conclusions from the Resilience Project will be the extent to which the resulting solutions generate problems less costly than their predecessors and opportunities more viable.\nA new international consortium of researchers, the Resilience Alliance (http://www.resalliance.org), has been established to carry forward the findings of the Resilience Project. The Alliance will use case studies from around the world to test and refine the new theories that emerged from the Resilience Project through thoughtful application and experimentation. The Alliance will also continue to seek new theoretical foundations for the integration of ecology, economics, and social science by further exploring the insights achieved through the Resilience Project.\nWe call for the submission of papers to Conservation Ecology that give examples of these new types of solutions as profiled by the Resilience Project — solutions that fundamentally deepen our understanding of resilience and sustainability.\nResponses to this article are invited. If accepted for publication, your response will be hyperlinked to the article. To submit a comment, follow this link. To read comments already accepted, follow this link.\nAddress of Correspondent:\nC. S. Holling\nDepartment of Zoology\nUniversity of Florida\n223 Bartram Hall\nGainesville, Florida 32611-2009 USA\nPhone: (352) 543-6955\nFax: (352) 392-3704\n|Home | Archives | About | Login | Submissions | Notify | Contact | Search|']"	['<urn:uuid:bdc53901-87cc-41b9-8006-5b43b8d973f6>']	open-ended	direct	short-search-query	similar-to-document	single-doc	novice	2025-05-01T22:36:12.692263	5	74	2968
171	I'm designing outdoor electrical components and need to understand Santoprene's weathering characteristics alongside its adhesive bonding limitations. What are its outdoor durability properties, and which adhesive solutions work best for it?	Santoprene demonstrates excellent outdoor durability due to its EPDM rubber content, featuring superior resistance to UV rays and ozone, preventing crack formation on surfaces during outdoor exposure. It also offers excellent ozone and general weathering resistance. For bonding solutions, since Santoprene is a low surface energy material, it requires specialized adhesive approaches. Pressure-sensitive adhesive (PSA) bonding tapes with unique formulations designed for LSE surfaces can be used, and certain structural acrylic adhesives are also suitable, particularly 3M Scotch-Weld Structural Acrylic Adhesives, which provide impact resistance and high performance across various environmental conditions.	"['Mix of EPDM and Polypropylene Produced with a Unique Block Surface Texture\nVolume Discounts for 25 Linear ft + Purchases\nStocked Sizes Ship in 24 Hours!\nNeed Custom Cut Parts? Call 1-844-Rubber-4\nFree Shipping on Orders Over $1000, Call 1.714.772.3000\nSantoprene rubber is mixture of vulcanized EPDM rubber and polypropylene. It is a fantastic choice of synthetic rubber material to use for any application that sees a high working temperature range. This thermoplastic rubber is ideal for use in various automotive and electrical projects thanks to its ability to operate in temperatures reaching up to 300° F. It is safe for outdoor use thanks to its resistance to ozone and UV rays. The Santoprene elastomer is also very durable and flexible, with a mid-level durometer rating of 55-65. This particular type of Santoprene sheet rubber comes with a unique block surface design.\nBlock-Patterned Surface Texture: The distinguishing feature about this Santoprene rubber sheet is its surface texture. Unlike the standard smooth surface texture of most other elastomers, this sheet of thermoplastic rubber is manufactured with a block surface pattern. All across its body are tiny blocks. These mainly serve an aesthetic function for application where appearances are important. However, they do provide for a better level of grip so as to reduce the chances of it slipping out of place.\nEPDM Benefits: This thermoplastic rubber is made partly from fully vulcanized EPDM rubber. The EPDM elastomer is known for being a good rubber material to use in outdoor settings. As a result, its outdoor weathering resistance traits are passed on to Santoprene rubber. A Santoprene sheet can operate comfortably in the outdoors because it features superior longevity in the face of UV rays and ozone. Outdoor elements like UV rays can damage other elastomers by causing cracks to form on their surfaces, but that is not the case with the Santoprene elastomer.\nExcellent Temperature Range: Silicone often tends to be the first rubber that comes to mind when people are looking for a high-temp elastomer. However, Santoprene rubber should also be considered. This synthetic rubber material has an excellent working temperature range. It can endure temperatures that go as low as -74° F and can equally function in conditions that reach as high as 300° F. This excellent feature allows the rubber to be used in various temperature intensive applications in the automotive, electrical, and industrial fields.\nSlow burn rate\nLow compression and tension set\nStocked in popular thickness gauges\nAlso available with a smooth surface texture\nStandard rolls of Santoprene sheet available in 24” and 36” width options and lengths of up to 50ft\nContinuous Temperature Range: -50° F to 275° F\nIntermittent Temperature Range: -74° F to 300° F\nThanks to its polyolefin base, Santoprene elastomer is recyclable despite being a synthetic rubber material\nSantoprene thermoplastic rubber is a family of high-performance elastomers which combine the performance characteristics of vulcanized rubber, such as flexibility and low compression set, with the processing ease of thermoplastics. It is the mixture of in-situ cross linking of EPDM rubber and polypropylene.\nWithstands transient temperatures up to 150 Celsius (300F) and continuous temperatures to 135 Celsius (275F) per SAE J2236 (Standard Method for Determining Continuous Upper Temperature Resistance of Elastomers).\nFluid resistance similar to polychloroprene for aqueous-based fluids, oils and hydrocarbons.\nLow compression and tension set.\nOutstanding dynamic fatigue resistance.\nExcellent ozone and good weathering resistance.\nFully vulcanized EPDM rubber particle in a thermoplastic matrix of Polypropylene (PP). Santoprene™ thermoplastic rubber grades are proprietary products. Their composition is trade secret information of Advanced Elastomer Systems, L.P. These products are not identified by CAS number. All components of these products appear on the Inventory of Chemical Substances published by the U.S. Environmental Protection Agency or qualify for the TSCA polymer exemption under U.S. Federal Register Vol. 60, No. 60, 3/29/95. New Jersey Trade Secret Registry No.: 01122800003-5001P.\nEU 2003/11/EC: Compliant to EU Directive 2003/11/EC regarding marketing and use of certain dangerous substances and preparations, specifically pentabromodiphenyl ether or octabromodiphenyl ether.\nUL QMFZ2, UL QMFZ8: UL listed: file #QMFZ2.E80017, Plastics - Component; file #QMFZ8.E80017, Plastics Certified For Canada - Component.\nEU Directive 2002/95/EC (RoHS) compliant.\nChrysler MS-AR100 AGN, Delphi SD-2-346 Sec. 4.1, Ford WSD-M2D378-A1, GM GMP.E/P.001, Valeo VMS-7055\nApproximate weight per square foot: 1/8"" weighs 0.45 lbs.\nShore Hardness (Shore A, 0.0787 in, 73.4 °F): 59.\nContinuous -50° to +275° F\nIntermittent -74° to +300° F\n-76°F, ASTM D-746, ISO 812.\n0.970. ASTM D792.\n0.970 g/cm2. ISO 1183.\nSmooth and Block Design\nTensile Stress at 100%:\n300 psi, ASTM D412. Across Flow (73°F)\n305 psi, ISO 37. Across Flow (73°F)\nTensile Stress at Break:\n750 psi, ASTM D412. Across Flow (73°F)\n754 psi, ISO 37. Across Flow (73°F)\nElongation at Break:\n400%, ASTM D412. Across Flow (73°F)\n91lbf/in, ASTM D624. Across Flow (73°F)\n91lbf/in, ISO 34-1. Across Flow (73°F)\nPer ASTM D2000 / SAE J200\nAA, BA, BC, CA (Type, Class)\nBurn rate is considered slow. Meets Federal Motor Vehicle Safety Standard No. 302 (down to .040”).\nBonding and Decorating:\nSantoprene TPV’s, like other polyolefins (PP, PE) are difficult materials for bonding and decorating. In order for an adhesive to wet Santoprene, it must have a critical surface tension lower than 28 dyne/cm. Most adhesives, tapes and coating have surface tension above this range and do not wet (adhere to) solid Santoprene TPV. For more information view document TL00308 (Exxon Mobil).\nAppliance Components, Automotive Applications, Automotive Under the Hood, Consumer Applications, Diaphragms, Electrical Parts, Gaskets, Seals.\nSantoprene is polyolefin based and completely recyclable.\nIn addition to hand fabrication, this product can be fabricated using laser, die, and water-jet cut. Please submit your drawings for a price quote.\nLocated below are reviews from customers who have purchased materials from Rubber-Cal. This is a live feed linked to Shopper Approved, which is an independent platform for consumers to post their feedback.\nLive Feed refreshes every 20 seconds.', 'Joining low-surface-energy plastics that are difficult to bond\nThank you for your interest in 3M Industrial Adhesives & Tapes products. A 3M representative will contact you shortly regarding your inquiry.\nAn error has occurred while submitting. Please try again later...\nLow surface energy plastics, or LSE plastics, are often known by their initials and include such materials as polypropylene (PP), polyethylene (PE or HDPE), polystyrene, acetal, EVA (ethylene vinyl acetate) and powder-coated paints. They are generally soft and have a low melting point so they’re easy to process, even at high volumes, and they’re low-density, which helps with lightweighting. Because low surface energy is the primary characteristic of this group, they’re all more difficult to bond – there are adhesive and tape options that work well, but there are far fewer options to choose from and test.\nLSE plastics are easily molded into a variety of shapes and are commonly used for single-use applications such as signage, decorative trim or packaging – plastic containers, but also plastic trays, protective buffers and wrapping films. Most applications don’t require a strong adhesive, but as a re-use market many recyclable plastics are shredded and turned into lightweight plastic lumber, which generally has the same bonding properties but may also require more adhesive strength.\nThese are some of the best adhesives and tapes to use for LSE plastics. Learn more about each featured technology using the links below.\nPressure-Sensitive Adhesive (PSA) bonding tapes are thin tapes with an adhesive on both sides. These tape constructions include adhesive transfer tapes and double-sided tapes. 3M has unique formulations that are designed for adhesion to LSE surfaces. They are ideal for smooth, flat surfaces and are often used for complicated flat shapes such as die cuts for smartphones, flat-screen TVs, gasketing, trim attachment and many packaging applications.\n3M™ Scotch-Weld™ instant adhesives are high-strength liquid adhesives designed for tight-fitting joints. As little as one drop of instant adhesive per square inch can be enough to bond many substrates, including LSE plastics.\n3M™ Scotch-Weld™ Structural Acrylic Adhesives are 2-component liquid adhesives that give designers the greatest strength for demanding applications. Many of these adhesives are a good choice for bonding LSE plastics. 3M™ Scotch-Weld™ Structural Acrylic adhesives provide impact resistance and high performance in a wide range of environmental conditions.\nPolypropylene is a low-density plastic manufactured in very large volume and widely used as film, fiber and molded parts. It is often used for packaging as containers, absorbent pads and wrapping film as well as to create lightweight components for the automotive, appliance and medical industries.\nPolystyrene is a clear, hard plastic; it can be brittle, but tougher versions known as high-impact polystyrene (HIPS) are available which have slightly different bonding properties. Some of the many applications that use polystyrene include foam peanuts, CD cases, clamshell containers, bottles, trays, cups and disposable cutlery. Polystyrene processes easily by molding, allowing for fine detail, as well as by vacuum forming to create foam panels.\nPolyethylene is the most common plastic, produced in the largest volume. It is often made into wrapping film for packaging and molded into bottles or other containers. Polyethylene has relatively low strength and low temperature resistance but is easy to process and used for applications where those factors are less important.\nPolyoxymethylene is an opaque white high-performance plastic with high strength, stiffness and rigidity plus good impact and temperature resistance and dimensional stability. It is often used in components like gear wheels, conveyor belts, eyeglass frames, fasteners and ski bindings.\nEthylene vinyl acetate is a rubber-like polymer with good toughness and crack resistance. It is often used as foam in footwear, particularly midsoles for tennis shoes and sandals, and for sports padding; it can also be a substitute for natural cork.\nTraditional paints have a range of surface energies resulting in different bonding requirements. Powder-coat paints are a free-flowing dry powder which is applied and then heated to form a hard protective coating. Additives with low surface energy often flow to the surface when melted, which can make powder coats difficult to bond.\nIn determining which adhesive will perform best, it is very often helpful to consider the assembly type. The six assembly types shown below have different design characteristics that often determine the best adhesive or tape.']"	['<urn:uuid:04907e8b-3ae7-4082-a2ba-f53b15d14a95>', '<urn:uuid:8ec2cbbf-9c31-4b0d-ba77-9dcbe7293efe>']	open-ended	with-premise	verbose-and-natural	distant-from-document	multi-aspect	expert	2025-05-01T22:36:12.692263	31	92	1691
174	As a development economist, what role did the state play in Eastern Europe's economic modernization?	The state was a prime mover in economic change in Eastern Europe, spearheading the modernization process by developing complex administrative services, creating developmental banks, and encouraging the growth of certain industries, particularly those connected with defense.	"['8 edition of The state and economic development in Eastern Europe. found in the catalog.\nThe state and economic development in Eastern Europe.\n|LC Classifications||HC244 .S63|\n|The Physical Object|\n|Number of Pages||179|\n|LC Control Number||66014883|\nThis book examines how foreign direct investment (FDI) inflows to Central and Eastern Europe have changed after the Great Recession. It argues that beyond their cyclical effects, the economic crisis and the changing competitiveness of Central and Eastern European countries have had structural impacts on FDI in the region. Health Care Challenges In Eastern Europe. advocating harmonious growth of both welfare spending and economic development by The book identifies the need for Author: Armin H. Fidler.\nThe nine articles in this book explore educational and economic change in the countries of Eastern Europe and the former Soviet Union. Together they provide both an overview of the developments - in their historical context - and an analysis of aspects of the situation in a number of different countries: the former Soviet Union, Poland, Hungary, Czechoslovakia, Romania (including Transylvania Author: David Phillips (Editor), Michael Kaser (Editor). The concept of the developmental state emerged to explain the rapid growth of a number of countries in East Asia in the postwar period. Yet the developmental state literature also offered a theoretical approach to growth that was heterodox with respect to prevailing .\nAp ECONOMIC REFORM IN EASTERN EUROPE A REPORT CARD INTRODUCTION It is over two years since Poland became the first East Empean nation to adapt de cisive free market economic reforms. 70 Reform in Eastern Europe and the Developing Country Dimension They have stated that they favour policies of \'adjustment with growth\' without being willing to accept the financial implications. The main factor determining the impact on developing countries will .\nLicensing Bill [Lords]\nHandwriting resource book\nFourth report [from the] Foreign Affairs Committee, session1992-93\nCranmer and the English reformation\nInternational agricultural trade negotiations in the mid-1980s\nDirectory of museums and art galleries in the British isles.\nStudies of language, thought, and verbal communication\nOLYMPUS OPTICAL CO., LTD.\nAdditional Physical Format: Online version: Spulber, Nicolas. State and economic development in Eastern Europe. New York, Random House  (OCoLC) Read this book on Questia. T he state has been a prime mover in economic change in eastern Europe.\nIt has spurred the process of modernization -- it has developed complex administrative services, created developmental banks, encouraged the growth of certain industries (mostly connected with defense). The economy of Europe was by this time dominated by the EU, a huge economic and political organization with then 15 of Europe\'s states as full members.\nEU membership was seen as something to aspire to, and the EU gave significant support and aid to those Central and Eastern European states willing to work towards achieving economies that met GDP: $ trillion (Nominal; ), $ trillion (PPP.\nGet this from a library. The external sector, the state and development in Eastern Europe. [Barry J Eichengreen; Richard Kohl; University of California, Berkeley. International and Area Studies.]. The role of the state has occupied centre stage in the development of economics as an independent discipline and is one of the most contentious issues addressed by contemporary economists and political economists.\nThe immediate post-war years saw a swing in economic theory towards interventionism, motivated by the urgent need for reconstruction in advanced capitalist countries, the. Transition Economies will aid students, researchers and policy makers working on the problems of comparative economics, economic development, economic history, economic systems transition, international political economy, as well as specialists in post-Soviet and.\nthe economy of the European Union. This report on Health and economic development in south-eastern Europe, which our two institutions have the honour to present in this book, brings forward concrete evidence regarding the potential contribution of improved File Size: 1MB.\nThis is the first book to compare the distinctive welfare states of Latin America, East Asia, and Eastern Europe. Stephan Haggard and Robert Kaufman trace the historical origins of social policy in these regions to crucial political changes in the mid-twentieth century, and show how the legacies of these early choices are influencing welfare reform following democratization and globalization.\nEmphasizing the development of class structure, this book is the first in English to describe the historical and social development of Poland, Czechoslovakia, Hungary, and Romania from medieval feudalism to modern capitalism. Historically these countries have maintained mostly peaceful relations among themselves in the past and now share the common characteristic of being Soviet "".\nTransition Economies provides students with an up-to-date and highly comprehensive analysis of the economic transformation in former communist countries of Eastern and Central Europe and countries of the former Soviet Union. With coverage extending from the end of central planning to the capitalist varieties of the present, this text provides a comparative analysis of economic transformation.\nEconomic Snapshot for Central & Eastern Europe. April 8, Central & Eastern Europe growth to lose traction in The regional economy will take a considerable hit this year as the coronavirus pandemic affects activity across the region, weighs on.\nThe issues investigated within the Handbook extend to a discussion of the varied economic consequences of transition, the social structures and institutional systems which underpin development processes, and the broadly understood sustainability of Central and Eastern Europe’s current development model.\nEastern Europe was the recipient of an analogous dividend; it imported energy and raw materials at submarket prices from the Soviet Union in return for the stationing of. Eastern Europe is the eastern part of the European is no consistent definition of the precise area it covers, partly because the term has a wide range of geopolitical, geographical, cultural, and socioeconomic connotations.\nThere are ""almost as many definitions of Eastern Europe as there are scholars of the region"". A related United Nations paper adds that ""every assessment of. The differences in economic structure, wealth and income between the major parts of the region are mirrored in regional differences in social structure and the distribution of political power.\nBerend argues that social transformation (just like economic modernization) remained partial and unfinished in Central and Eastern Europe. Together with Turkey, a newly authoritarian and repressive state in southeastern Europe, the authoritarian belt in Europe’s East manifests a bleak geopolitical reality characterized by disregard for EU borders, international order, and liberal democracy.\nIlliberalism and patronalism are contagious and pose a risk of spreading to other Eastern. Publisher Summary. This chapter discusses Western Europe\'s economic development and the NIEO.\nThe development of the market economy since the middle of the s, and the corresponding development of the West European economic and social structure, has been characterized by far-reaching changes.\n(Archived document, may contain errors) Ma FOR EAsIlERN EXJROPQ AN AGENDA FOR ECONOMIC GROWTH INTRODUCIION The revolutions sweeping Eastern Europe and the Soviet Union are a result.\nThe economic crisis, the second economic shock to hit the Eastern Europe and the South Caucasus region after the collapse of the Soviet Union, has been a warning and a call to action. The region has many advantages and much potential, but some of this was squandered during the boom years of the s.\nEconomic growth is broadening in Central, Eastern, and Southeastern Europe (CESEE). Further ahead, however, growth prospects will be tested by a dwindling workforce and weak productivity.\nReaching Western European income levels would thus take longer, says the IMF in its Regional Economic Issues update on the region. This edition features a new chapter linking the environment and development problems; a new chapter describing critical issues for the s including the economic transition taking place in the republics of the former USSR and eastern Europe, the economic crisis in sub-Saharan Africa, and the impact of the globalization of the world economy.In Transition Economies: Transformation, Development and Society in Eastern Europe and the Former Soviet Union, Aleksandr V.\nGevorkyan summarises the major economic and many social indicators of the changes which have taken place in the 29 European and Central Asian countries of what was formerly known as the Soviet book will prove a useful resource for students of transformation.The book illustrates concepts from all major third-world regions (Latin America, Asia, Africa, and Eastern Europe), with discussion of Asia\'s recent growth acceleration, Latin America\'s slowing growth, sub-Saharan Africa\'s food and economic crisis, and how developing regions have been affected by a globalized economy.']"	['<urn:uuid:4276e808-a65c-49ae-aeeb-40ff182c13b6>']	open-ended	with-premise	concise-and-natural	similar-to-document	single-doc	expert	2025-05-01T22:36:12.692263	15	36	1388
175	As a theater historian studying early Black playhouses, I'm curious about how the African Grove Theatre influenced both 19th century performances and modern Black theater institutions. What were its historical achievements, and how does its legacy continue in contemporary theater organizations?	The African Grove Theatre, established by William Henry Brown in 1821, was groundbreaking as the first theater to allow all-black casts to perform plays originally written for White actors, including Shakespeare's Richard III and Othello. It produced two notable actors: James Hewlett, the first African American Shakespearean actor, and Ira Aldridge, who later became internationally renowned. The theater, located on Prince Street, became popular with both Black audiences (who attended after church on Sundays) and White patrons, though racist opposition eventually forced its closure. Its legacy continues through modern institutions like the New Heritage Theatre Group, which carries on the mission of presenting quality productions for the community at affordable prices, and various Harlem theaters that focus on telling Black stories through their own lens, such as Blackberry Productions and the Classical Theater of Harlem.	['Ira Aldridge was a teenager discovering his love of theatre before becoming the first of his kind to be known internationally. William Henry Brown established a theatre before writing what many considered to be the first play of its kind. James Hewlett was a tailor by trade before becoming the first of his kind to star in a one-man show. These prominent Black men, during the early part of the 19th century, played a pivotal role in shaping America’s Black Theatres, especially in Washington, D.C.\nThe history of this movement in the district was a topic briefly mentioned during a discussion last night at the Historical Society of Washington, D.C. (HSW) on K Street NW. The event, “Theatre District: How Washington, D.C. Became a National Stage for the Performing Arts,” was a look at how the city evolved into “a theatre-Mecca second only to New York City,” according to HSW Executive Director Sandy Bellamy.\n“There are scores of dance, choral music, instrumental music and opera companies in our midst,” said Linda Levy Grossman, moderator and president/CEO of the Helen Hayes Awards, which honors professional theatre in the Washington, DC metropolitan area. But Monday night’s discussion, the first of HSW’s fall programming, was to focus solely on theatre.\nKicking off a brief overview of the city’s history was an 11-minute video titled “Again and Again: The Legacy of Washington Theatre.” According to the film, the city’s first playhouse was a bare room inside a hotel on E Street NW in the early 1800s. Two new playhouses – featuring “everything from acrobats to the finest classical actors from both sides of the Atlantic”– were constructed in 1804 and 1822 to accommodate growing audiences. And in 1835, the National Theatre opened three blocks from The White House on Pennsylvania Avenue.\nFollowing its opening, the building was destroyed by fire and rebuilt on the same site five times during the 1800’s, according to nationaltheatre.org. In the time preceding the Civil War, opera houses and music halls dotted the downtown area. After the war, the city underwent another transformation. Between 1885 and 1915, 37 new theatres opened in a block bordered to the south by 9th Street, to the east by Pennsylvania Avenue, to the north by 15th Street and the west by New York Avenue. And while this enlivened, six-block theatre district was created downtown, an area known as “Black Broadway” was taking shape uptown.\nAt the time, Segregation forced African Americans nationwide to establish their own organizations and institutions as a way of supporting their lifestyles. And thanks to William Henry Brown, a West-Indian born U.S. theatre producer and playwright, African-American artists also had a blueprint for establishing their own playhouses. “As it happens, African-American theater flourished as early as 1821,” writes Heidi Weiss in a September 2006 Chicago Sun-Times article. That same year, Brown, a retired steam ship steward, created the African Grove from “a little tea garden and cabaret” behind his house in lower Manhattan. African Grove was the first of its kind to allow an all-black casts to perform plays originally written for White actors, which included Shakespeare’s Richard III and Othello.\nThe company’s productions soon became a popular diversion with White audiences, which started a rivalry “between this small theater and Stephen Price’s Park Theater,” according to a web lecture on the African Grove Theater. As the story goes, Brown rented a hall right next to the Park Theater for performance of Richard III after being ousted from his house on Thomas Street. Brown’s production coincided with the Park Theater’s presentation of the same play. According to the online lecture, “Stephen Price hired a mob to stage a ‘riot’ and had the police shut down the African Grove performances.” Laura Blanchard, vice chair of the American Branch of the Richard III Society, writes on the organization’s Web site that the African Grove moved to Mercer and Bleecker streets on October 1. The company was again forced to close down in 1823. That same year, Brown wrote The Drama of King Shotaway, the first African American play to be written and produced in the United States. The play is based on a Black Carib revolt on the island of St Vincent in 1796 against both English and French settlers.\nDuring the time of African Grove, Brown’s company produced two notable actors: James Hewlett, the first African American Shakespearean actor, and Ira Aldridge, a teenager at the time. According to blackpast.org, an online reference guide to African American History, Hewlett and Aldridge honed their skills “while sitting in the balcony of Stephen Price’s landmark Park Theatre observing the acting styles of European transports in Shakespearian plays.”\nBorn 1778, James Hewlett’s education of theatre came from following behind British actor George Frederick Cooke as a servant boy, when he learned to imitate the actor’s actions and attitude. But, according to a Dec. 22, 1825 article in The Star, the young man had something else going for him. “Hewlett…must have had a natural talent for theatrical performances and an excellent voice, or he could never have surmounted his early difficulties,” the newspaper reported. Those difficulties were the result of racism. In addition to working as a waiter and tailor by trade, Hewlett was a role model for the African Grove’s younger member, Ira Aldridge. When Hewlett joined the theatre company in 1821, he attempted Richard III with an all‐black cast and played the title role in Brown’s The Drama of King Shotaway. But much of his life after the African Grove is a blur. According to the Oxford Companion to American Theatre, he “seems to have confined his appearances to recitals devoted largely to imitations of famous White actors.”\nAmong his honors, Hewlett was called “the most astonishing phenomena of the age” by an 1826 advertisement. In addition, the ad goes on to describe him as: “a young man, who, notwithstanding the thousands of obstacles which the circumstance of complexion must have thrown in his way of improvement, has, by the mere dint of natural genius and self‐strengthened assiduity, risen to a successful competition with some of the first actors of the day.” Later billed as “Shakespeare’s proud Representative,” he disappeared after a farewell benefit in 1831. According to blackpast.org, Hewlett passed in 1836.\nIra Aldridge, an American stage actor who made his career largely on the London stage, is the only African American actor among the 33 actors of the English stage with bronze plaques at the Shakespeare Memorial Theatre at Stratford-upon-Avon. Born on July 24, 1807 to Reverend Daniel and Luranah Aldridge, Ira’s first professional acting experience was in the early 1820s with the African Grove, according to various sources. There, he debuted as Rolla in Pizzaro, played Shakespeare’s Romeo and later gained fame for his portrayal of Hamlet.\nConfronted with persistent racism in the U.S., Ira emigrated to England, where he worked as a dresser to the British actor Henry Wallack. His move from the U.S. sparked a series of tours that started in 1831, when he successfully played in Dublin, along with several locations in southern Ireland, Bath, and Edinburgh. He eventually toured Europe in 1852, and was successful in Germany – where he peformed for Frederick William IV of Prussia after being presented to the Duchess Saxe-Coburg-Gotha – and in Budapest. Ira spent most of his final years in Russia – where he met Leo Tolstoy, Mikhail Shchepkin and Taras Shevchenko – and in continental Europe. He died in August 1867.\nThe spirits of Aldridge, Hewlett and Brown’s African Grove motivated the theatre movement on D.C.’s “Black Broadway” during the dawning of the 20th century, when the city became the social and cultural capital of Black America, according to the PBS documentary, “Melodies and Memories.” “From 1900 to 1920, it was this country’s largest African American community. Anchored by Howard University and federal government jobs, this community became a magnet for African American intellectuals and sent a stream of shining talents to the nation for generations,” according to PBS’s Web site. “It developed a prosperous Black middle class which forged a strong society of churches, newspapers, businesses and civic institutions.”\nAmong those institutions were the Howard and Lincoln theaters. Created in 1910, the Howard Theater at 620 T Street NW was a stucco-clad building that originally served “as a playhouse for both variety shows and moving pictures catering to African-American audiences,” according to a January 2008 Staff Report for Howard Theater. “The Howard is the oldest surviving and the first known theater in the country built just for Black audiences during segregation when Blacks were barred from attending or performing at White theaters.” Success of the 1,200-seat auditorium helped energize the debuts of other Black-owned theaters, such as the Apollo in Harlem, the Uptown in Philadelphia, and the Royal in Baltimore (or the Chitlin’ Circuit), according to “Historic U Street Jazz,” a project of George Washington University. The theater closed its doors when the Great Depression hit in 1929. When it reopened its doors in 1931, the theater moved away from providing variety acts to solely jazz performances. The city’s desegregation in the early 1960’s and the 1968 unrest that ensued after the assassination of Dr. Martin Luther King Jr. led to the Howard closing its doors in 1970. The theater is currently closed with plans for renovations.\nLike the Howard, the Lincoln Theater was designed as a movie theater for black patrons in 1921. Initially, it was where African Americans saw vaudeville acts, first-run films, and amateur competitions. When the Lincoln switched owners in 1927, the theater was expanded to include “a cabaret, a hot nightspot, and a dance hall called the Lincoln Colonnade,” according to GWU’s “Historic U Street Jazz.”\nThe Presidential Ball came to the Lincoln in the 1940s, and the first ladies Eleanor Roosevelt and Bess Truman used the theater for a March of Dimes rally. “The Lincoln’s name, its decor, its cabaret, and the politically and socially elite visitors all worked to affirm the importance, not only of the Lincoln, but of the community on U. Street,” according to “Historic U Street Jazz.”\nAnd like the Howard, the Lincoln Theater suffered from the city being fully integrated in the 1960’s. Following the Brown v. Board of Education decision in 1954, Black businesses moved downtown and along with them went majority of the neighborhood’s prominent residents. The unrest of 1968 also ended the Lincoln’s golden era. “The Lincoln played B movies until it was permanently closed in 1982,” according to Historic U Street Jazz. “Currently, the Lincoln remains in the custody of the District Government and is awaiting a proposal for restoration.”\nLast night, Grossman, moderator and president/CEO of Helen Hayes Awards, had a question for the audience. “Who here has, at some time in recent history, attended a Washington theatre performance as an audience member?” At the sight of every hand raised, she said, “Excellent! A’s for everyone.”\nToday, the total number of theatres in D.C. quadrupled from 14 in 1983 to more than 70 now. In 2008, alone, 69 of the city’s area theatres – plus theatre festivals – produced 428 productions, 169 readings and 154 festival productions, the moderator said. The total? It’s around 8,723 performances seen by almost two million audience members. So if everyone in the room attended even one of those productions in 2008, she said, they played a critical role in confirming the city’s current reputation. “The quantity of productions maintains Washington’s tradition as the second most prolific theatre town in the country,” Grossman said. “But the quality and the diversity of the work produced here make Washington second to none.”', 'I am thankful for love, life, the pursuit of happiness, family, good friends, good health, to be alive on planet earth, a member of my culture and of service to the human race that I live in the United States of America and for President Barack Obama. How about you?\nI am also thankful for Community Works NYC and New Heritage Theatre Group, which, in conjunction with the Interchurch Center and partners, presented the New York premiere of the expanded, comprehensive exhibition “Harlem is … Theater.” The exhibit, which is a public art and education program under the auspices of Community Works NYC, features narratives on the fascinating history of Black theater, along with other relics, photos and memorabilia.\n“Harlem is … Theater” is currently open to the public now through February, after which it will then be displayed at the New York Public Library of the Arts at Lincoln Center. The exhibit does an excellent job of portraying the artistry, commitment and rich history of Black theater, where it began and how it continues to evolve.\nThe artist’s ability to bring a story to life through their portrayal of a vision, a dream or a slice of life is what makes theater so compelling. Black theater, as Stephanie Berry, founder and co-artistic director of Blackberry Productions, stated, “allows Black artists to tell our stories, through our lens and not have someone else misappropriate our stories or take them from us.”\nGreetings at the opening reception were made by Barbara Horowitz, founder and president of Community Works NYC. She introduced several of today’s prominent artists, who have contributed to the longevity of Black theater by dedicating themselves to carrying on the art. There to do what he does so well was Darryl T. Downing, ensuring the evening ran smoothly and without a hitch, which it did.\nAppearing on stage was George Faison, co-founder and artistic director of the Faison Firehouse Theatre, who said, “In our outreach training program, we listen to the young artists, which is something few adults do.”\nIn that same vein, Berry said, “We at Blackberry Productions have committed ourselves to cultivating new works by Black writers.”\nAlso appearing on stage, Ray Gaspard, president of the Frederick Douglass Creative Arts Center, said, “Our after-school filmmaking programs are designed to enhance the children’s interest in learning.”\nAcknowledged was Gertrude Jeannette, who was not in attendance, as she was preparing to celebrate her 100th birthday Nov. 28. Jeannette is the founder and CEO of the HADLEY Players. She was also the first female licensed in the United States to drive a taxicab—just a bit of trivia. “Our mission,” she stated, “is to provide Harlem with professional theater at affordable prices.” A video clip featuring Jeannette is also part of the exhibit.\nDue to a scheduling conflict, Woodie King Jr., founder and producing director of New Federal Theatre and founder and producing director of the National Black Touring Circuit, was unable to attend but was quoted as saying, “If corporations are going to make money in Harlem, they must provide funding to support the local arts organizations.”\nContinuing the program, James Pringle, founder of Harlem Theatre Company, noted, “Our goal was to produce actors who were intelligent, well-trained and professional.”\nBarbara Ann Teer, visionary founder of the National Black Theatre, once said, “Theater is a healing art form that must be located in an energy center … Harlem has that kind of energy.”\nGarland Lee Thompson Sr., co-founder and executive director of Frank Silvera’s Writers’ Workshop, said, “Theater people in Harlem have to collaborate more with each other and gain control of the venues in which we present our works.”\nDebra Ann Byrd, producing artistic director of Take Wing and Soar Productions and founder of Harlem Shakespeare Festival, said, “We can change this conversation, locally, nationally and internationally.”\nTy Jones, producing artistic director of the Classical Theater of Harlem, said, “We are out to entertain diverse audiences who desire to be highly engaged emotionally and highly satisfied intellectually by productions that are anchored in the context of the African Diaspora.”\nHow could you possibly talk about Black theater in Harlem and not talk about Vy Higginsen, Ken Wydro and Higginsen’s daughter Ahmaya Knoelle, co-writers, co-producers and co-directors of “Mama, I Want to Sing” and “Mama Foundation for the Arts.” Both mother and daughter spoke vibrantly about how “Mama’s mission is to preserve, present and promote the culture of African American music and dance.”\nLast but certainly not least to be recognized was Voza Rivers, founding member and executive producer of New Heritage Theatre Group, where Jamal Joseph is executive artistic director. Rivers was quoted as saying, “New Heritage is continuing Roger Furman’s mission of presenting quality productions for the community at affordable prices.” Rivers went on to say that he discovered theater when he began his quest to find his voice. His search was to discover how he was going to contribute to society. He then discovered Roger Furman. Rivers, though humble and unassuming, continues to be a beacon in the community not only when it comes to theater, but especially when it comes to being an inspiration to others struggling to find their art.\nFurman was a trained actor and theater arts producer who wanted to do more with anti-poverty programs, which were at their height of existence during the 1960s, than just collect a check. Furman wanted theater to be an integral part of the initiative, an art form that would last long after the funds ran out, and the term “anti-poverty” was no longer in vogue. Hence, his spirit lives on at the New Heritage Theatre Group as an inspiration to all aspiring artists and those who can love and appreciate Black theater.\nSeeing and hearing those who continue to carry the torch underscores the brilliance of “The Harlem is … Theater” exhibition. Little is known by the general public of New York’s historic Black theaters. The earliest recollection begins with the African Grove Theatre, which is recorded as the first theater to produce dramatic works by and for Blacks. The exhibit will explain how the theater, located on Prince Street, would produce works by Shakespeare. The Black audience would come to the theater after church on Sundays and became a very popular venue for Black entertainment. Intrigued by its popularity, shortly thereafter, white patrons began to visit the theater as well. Appalled at the ability of Blacks to put on such fine productions, they began to cast negative and disparaging remarks and comments, often interrupting the actors on stage, sometimes going so far to summon the police to arrest the actors while on stage. The theater soon closed.\nIt wasn’t until 1935 that Black theater would emerge again thanks to the WPA Federal Theatre’s Project Harlem Unit. This was followed by the Rose McClendon Players, the American Negro Theater, New Heritage Theatre Group and the New Lafayette Theatre, which was “a proponent of Ritual Theater created to ‘bind together and strengthen Black people so that they can survive the long struggle that is to come.’” That was in 1973.\nUntil next week … kisses']	['<urn:uuid:c101a550-e6d4-4085-82e3-9426538e9032>', '<urn:uuid:779eca8d-6581-409f-8781-658dfa01ad33>']	open-ended	with-premise	verbose-and-natural	distant-from-document	multi-aspect	expert	2025-05-01T22:36:12.692263	41	135	3122
176	what keep bird healthy prevent disease symptoms tips	To keep birds healthy and prevent diseases, there are several key measures to take. For emergency conditions, watch for signs like birds sitting fluffed up with closed eyes, labored breathing with tail bobbing, bleeding, or exposure to toxic substances - these require immediate veterinary care. Regular health monitoring includes checking droppings (which should have solid feces, clear urine, and white urates), eating habits, and activity levels. Regarding disease prevention, particularly from common urban birds like pigeons, it's important to avoid contact with bird droppings as they can carry diseases like histoplasmosis, cryptococcosis, and psittacosis. When cleaning bird debris, wear protective equipment including gloves, masks, and eye protection, and use a bleach solution to properly disinfect affected areas.	['Bring your bird to the vet immediately if it is experiencing any of the following emergency conditions:\n- Your bird is sitting on the bottom of the cage fluffed up with its eyes closed, or\n- its tail is bobbing from labored breathing even though it isn’t being disturbed, or\n- if it is bleeding profusely or\n- has consumed a toxic substance, or\n- it is convulsing with seizures or if it has inhaled gas, teflon or smoke from a fire or burned food.\nHealth Evaluation Forms\nThe purpose of the following Health Evaluation Forms is to help bird owners track down the cause or causes of their bird’s ailment. This form is also used by members of the HolisticBird list who wish to ask other list members for help.\nBy answering the questions, the bird owner is guided through a troubleshooting process that often helps target the solution. Consider the questionnaire an aid to diagnosis, without which, appropriate help cannot be suggested.\nThe forms may be used for your own personal problem solving, for preparing for a vet visit, and to send to the HolisticBird list, if you are a member of the list, and would like to ask the other list members for help. To submit the form(s) to the list simply copy the relevant form(s) into your post and answer the questions.\nUse the following to determine which forms you should fill out:\n1. If your bird has a behavior problem such as screaming, biting or other aggression, fill out forms A through G.\n2. If your bird is plucking or mutilating its feathers, fill out all of the forms.\n3. If your bird has minor diarrhea or looks as if it isn’t feeling well because it is quieter than usual and isn’t eating as well, fill out forms A, C, D, E. F.\n4. If your bird has been to the vet, fill out form B in addition to the other appropriate forms.\nPlease briefly describe your bird’s health or behavior problem for which you are filling out this form.\nYour name and email address\nBird’s name, species, and color mutation (if applicable)\nBird’s age and sex\nWhere was the bird obtained? (pet shop, breeder, rehome, rescue)\nHow long have you had this bird?\nHow long has the bird had this problem?\nB. Veterinary Care\nHas a vetinarian seen the bird?\nWhat tests, cultures, X-rays, etc. were performed? Different vets consider different tests to be a ‘complete health screen’, so be specific about what lab work was done. (cbc, culture, gram stain, chemistries, x-rays, SPE)\nWhat were the tests and the results?\nWhat was the Veterinarian’s diagnosis?\nWas treatment/medication prescribed?\nPlease detail what was given, dosages and duration of prescribed treatment.\nWas there an improvement shown from treatment:\nIf treatment failed, what other steps were taken to resolve the problem:\nHave you used herbs or remedies such as Echinacea, ACV, GSE, etc., how often and for what reasons:\nWere any OTC (over the counter) treatments used prior to a vet visit:\nHas this bird been diagnosed with PDD?\nIf so, was it before or after it was treated with baytril for a bacterial infection?\nWas the diagnosis of PDD based on biopsy results or was it based on symptoms?\nC. General Health\nNormal droppings consist of three parts:\nsolid feces of different colors depending on what the bird is eating;\nclear urine; and\nDroppings might be watery, slimy with mucus, well formed tubes, dry / hard, black /scant, contain whole seeds or other food, foamy, the urates or urine could also be colored.etc\nDescribe your bird’s droppings including solids, urates, and urine.\nHave the droppings changed from normal frequency, color, consistency or quantity for this bird?\nIf so, describe\nHas the bird’s eating habits and preferences changed?\nHas the bird’s activity level, talking, singing changed?\nHas the bird’s mood changed?\nIs the bird cold and fluffed?\nIs the bird breathing rapidly with tail bobbing when it is not being disturbed?\nIs the bird perching or sitting at the bottom of the cage?\nD. Diet and Nutrition\nWhat is your daily feeding schedule?\nHow often do you feed?\nWhen and what do you feed?\nWhat percentage of the following foods does your bird actually eat? pellets, vegetables, fruit, seed mix, nuts, sprouts, meat and eggs, bird bread, table food, soak and cook, treats, junk food, other.\nWhat kind of vegetables does your bird eat\nWhat kind of fruit does your bird eat\nAre the fruits and vegetables washed?\nAre they organic?\nWhat brands of pellets or seed mix does your bird eat\nWhat kind of table foods and treats does your bird eat\nHow often do you allow junk food: chips, crackers, pasta, bread, candy ice-cream, cake, cookies.\nDo you feed any supplements, and if so what kind?\nDo you administer supplements on food or in water?\nWhat foods does your bird refuse to eat?\nWhat strategies have you used to improve the diet?\nDoes your bird crave any particular kind of food?\nHave your bird’s food preferences changed lately?\nWas anything in the home changed prior to the first display of symptoms? This could be a change of food, cage location, new bird additions, interior decoration (such as new drapes, carpet, furniture), new people, loss of bird buddy or human friend, etc.\nHow often is the cage cleaned?\nHow often is debris from the cage tray removed?\nHow often are the perches cleaned?\nHow often are food and water cups cleaned and disinfected?\nHow long is uneaten spoilable food left in the food dish?\nHow often are uneaten seeds and pellets removed and refreshed?\nHow often is water changed?\nAre insects (house flies, fruit flies, ants, cockroaches etc) present on or in the bird’s food?\nF. Social Interaction\nDo you have other birds, and how do the birds react to each other?\nAre there other pets in the household, and how does the bird respond to them\nWhat other Human members of the family interact with the bird, and does the bird have preferences?\nAre other pets or family members ill?\nWhat is the cage location and how much activity is there in this location?\nHow does the bird respond to activity around the cage?\nHow does the bird respond to being alone?\nHow often and how long is the bird alone?\nHow often is the bird out of the cage to interact with family?\nWhat type of exercise does the bird like, such as exploring, flying, showering etc?\nDoes the bird exhibit signs of sexual maturity?\nG. Cage and Toys\nIs the cage covered at night.\nDoes your bird sleep in a different cage:\nWhat type of perches are in the cage and their positions:\nWhat is used in the bottom of the cage (newspaper, corn cob, etc.) and can the bird reach it:\nIf toys are provided, what are the birds preferences:\nIs the bird passive or aggressive to the toys, eg: plays with or destroys them\nAre toys rotated or are the same ones left in the cage all the time:\nWhat type of lighting is used (such as incandescent or full spectrum):\nIs the photo period (of lighting source) natural and regulated, or random and irregular:\nDoes the bird have access to natural sunlight or is taken outdoors Are night lights used:\nWhat is the water source and location, eg: bowl, dish, water bottle:\nDoes the bird like to bathe, and what is it’s favorite form of bath (mister, sink, bowl, etc) and how often:\nAre supplements or anything else put in the water?\nIf so, what?\nWhat is the drinking water source? (tap, well, municipal, filtered, bottle)\nJ. Household Safety\nWhat are the major products you use for general housecleaning. eg: Clorox, Windex, types of soaps, floor products/waxes etc:\nAre there carpets in the house and what chemicals are used for cleaning them:\nWhat disinfectants are used to clean the birds cage: Are scented candles, strong perfumes, or Teflon pots and pans used:\nWhat type of aerosol sprays are used, eg: room deodorizers, hair sprays, pesticides, etc:\nAre there any smokers in the household, and do they handle the birds:\nAre fabric softeners used in cage coverings: What type of ventilation (such as windows, vents, fans, etc.) is used when questionable products are used, or painting or heavy cleaning is done:\nDoes the bird sneeze or pluck after the vacuum has been used? Is the home heating electric, gas, oil, radiant or forced air:\nWhat is the temperature in the house, and is it constant or varied:\nWhat houseplants can the bird reach:\nAre pest exterminators used:\nWhich method of pest control used:\nIf birds are housed outdoors what type of shelter is provided against sun and bad weather:\nDo predators (cats, birds, mice, wild animals, insects) disturb/distress the bird during the night\nAre fertilizers, herbicides, and pesticides used on trees or lawn\nDo outside birds have access to treated lawns, trees or plants', 'Pigeon Prevention & Clean-Up Guidelines\nUrban pigeons are descendants of the Rock Dove, a species of pigeon domesticated by humans for food and as pets. Birds that were released or escaped became today’s city pigeons.\nPigeons can carry diseases and parasites that can be transmitted to humans, including histoplasmosis, cryptococcosis, and psittacosis. Although West Nile virus (WNV) is found in pigeons, they are an unsuitable or “dead end” host for this viral disease. The health district does not submit samples from pigeons for WNV testing.\nPigeon droppings are as much a concern as the pigeons themselves. On average, a well-fed pigeon deposits 25 pounds of droppings a year. Pigeon feces are unsightly and can damage buildings, vehicles, trees, shrubs, lawns, benches and park fountains.\nPigeons have no natural enemies in urban areas and reproduce quickly. Pigeon overpopulation can lead to increased property damage and higher disease rates among pigeons. Accumulated bird debris may attract mice, rats, and flies.\nPigeons have four basic needs in order to survive: food, shelter, the ability to reproduce, and safety from predators. If any of these basic needs are disrupted, the pigeons will move away.\nPigeons will eat anything they can fit into their bill. If they cannot find food in an area, they will look for it elsewhere. Follow these steps to keep pigeons from eating at your house:\n- Don’t feed the pigeons.\n- Remove unsecured bird feeders and routinely clean up spilled seed.\n- Cover trash cans and keep area around the cans clean.\n- Don’t leave uneaten pet food outside.\n- Pick up after your pets. Pigeons will eat pet waste.\n- Empty containers of water.\nPigeons seek shelter at night and congregate at roosting sites during the day. Pigeons feel safe in a sheltered area where they are not easily seen. In urban areas, pigeons roost in trees, abandoned structures, rafters, beams, along building eaves and awnings, and under bridges. These areas can be easily modified to discourage roosting.\n- Block access to interior roosting and nesting sites by using wood, metal, 1/4-inch (0.6cm) rust-proofed wire mesh, or plastic or nylon netting.\n- Alter the angle of ledges to 45° or more. Fasten sheet metal, wood, Styrofoam blocks, stone or other materials to ledges to achieve the desired angle.\n- Porcupine wires can be attached to any area where pigeons roost. These devices consist of a solid base with sharp prongs sticking out at all angles. This prevents birds from landing. To improve their effectiveness, keep wires clear from debris.\n- Apartment residents can install fine netting across balconies to deter roosting.\nRemove nests to discourage breeding. Pigeons will reuse the same nest throughout a breeding season. Keep removing any rebuilt nests. After a few failed attempts, the pigeons will nest somewhere else. “Birth control” products are available to licensed pest control companies that prevent their eggs from hatching.\nIn an urban environment, pigeons have few natural predators. However, by instinct, pigeons have a fear of being preyed upon. Pigeons may be deterred from locations by hanging “frightening” devices such as strips of Mylar fabric, CDs, pinwheels, aluminum pie plates, large beach balls, noisemakers, and life-size reproductions of falcons, owls, etc. Rotate items to keep the birds from becoming unafraid of them.\nPigeon feces may contain bacteria and other pathogens that can cause illness. Prevent infection by avoiding direct contact with bird debris while cleaning affected areas. Keep children and pets away from areas which have accumulated bird debris.\nWear personal protection equipment (PPE) when cleaning up fecal matter:\n- Long pants\n- Long-sleeved shirt\n- Waterproof gloves\n- Eye protection\n- Filter mask\n- Closed-toe and water proof shoes\nFollow these steps to clean and sanitize properly:\n- Prepare a 10 percent solution of sodium hypochlorite by mixing one part bleach with nine parts water.\n- If indoors, mist the area to settle suspended air-borne particles.\n- Soak the area with the bleach solution and leave it undisturbed for at least 10 minutes. This will disinfect and soften the droppings, making them easy to remove.\n- Use an old mop or spray bottle to apply and spread the bleach solution.\n- Re-wet the area with the bleach solution if the area starts to dry during the 10 minute soak.\n- Dense accumulations of feces may require repeated applications of the bleach solution.\n- Place the debris into a doubled plastic bag (a plastic bag in another plastic bag).\n- Use a square-nosed shovel or a hoe to scrape up the debris.\n- Seal both bags.\n- Place bags in the outside trash.\n- Using dish soap or laundry detergent, scrub the area with a stiff brush or broom to remove debris from cracks and crevices. Rinse area with water.\n- A power washer can be used for this step.\n- Reapply the bleach solution and keep the area wet for another 10 minutes. Do not rinse.\n- If the treated area receives at least 4 hours of direct sun, this step can be omitted as ultraviolet light has disinfecting properties.\n- Air-dry before allowing people and pets into the area.\nThis procedure may not remove all stains and the use of bleach may discolor walkways, sides of building, and other structures and may cause damage to growing vegetation. Damage may be prevented by using a commercial disinfectant without sodium hypochlorite. Read label instructions before using these products.\nIf a sensitive area receives a considerable amount of sunlight, the disinfectant may not be necessary as the sun’s UV light works as a natural disinfectant. Physical removal of the debris is necessary. This method is also considered acceptable for areas with little or no foot traffic.\nProperty restoration and pest control companies may offer services to remove accumulated bird debris.\nFlocks of pigeons (and their droppings) are not only an eyesore and nuisance, but they can pose a health risk to humans. The health district does not enforce or regulate pigeon control unless there is a complaint or problem at one of our permitted facilities.\nA list of local Animal Control and/or Code Enforcement agencies that respond to pigeon complaints is listed in the below table. (Clark County and the City of Las Vegas do not respond to pigeon complaints and recommend residents contact a pest control company.)\nAnimal Control: (702) 293-9283\n|North Las Vegas|\nAnimal Control: (702) 633-1750\nCode Enforcement: (702) 633-1677\nAnimal Control: (702) 267-4970\nCode Enforcement: (702) 267-3950\nAnimal Control: (702) 346-5268\n- Keep children and pets away from contaminated areas until they have been cleaned, sanitized and dried.\n- If pigeon debris is in an enclosed area, such as an attic, open windows and use fans to force fresh air into the area before cleaning.\n- Leave area undisturbed to prevent air-borne particles.\n- Never handle a dead bird with your bare hands.\n- Use rubber gloves or an inverted plastic bag to pick up the bird.\n- Place the dead bird into a plastic bag, seal bag and place in an outdoor, covered trash container.\n- Dead birds should be disposed of with regular trash.\n- Clothes worn during cleaning should be washed separately in hot water. If possible use a disinfectant in the wash.\nUpdated on: August 21, 2018']	['<urn:uuid:4e1c97bf-3cfa-403a-84cb-81d3b679fa1c>', '<urn:uuid:9246d8e8-faf5-405a-a826-82b9a3feee6d>']	open-ended	with-premise	short-search-query	distant-from-document	multi-aspect	novice	2025-05-01T22:36:12.692263	8	117	2698
178	international mother language day unesco when was it proclaimed commemoration	International Mother Language Day was proclaimed in November 1999 at UNESCO's General Conference and is commemorated every February 21.	['Languages Also Die: The Case of the Wixárika by Oscar Ukeme Bautista Muñoz\nBy Oscar Ukeme Bautista Muñoz\nFebruary 25th, 2008\nThe following exhibit can be applied not only to Wixárika (Huichol) but to any indigenous language, and is particularly dedicated to those indigenous languages in danger of becoming extinct. Only due to contextual and regional reasons have we decided to describe it and compare it in this manner. Furthermore, we are not trying to say that the Wixárika language is inferior to Spanish, to the contrary, we intend to make a fitting reflection regarding the preservation of indigenous languages. Let us thus begin.\nEvery February 21 we commemorate the International Mother Language Day, proclaimed in November 1999 at UNESCO’s General Conference. Languages are the principle instrument through which we can preserve and develop our tangible and intangible cultural patrimony, as they impart a basic function in the construction of our societies.\nIn our indigenous culture the mother tongue is the language of the gods, through it we can communicate with our deities, strengthen our customs and traditions. With it we can laugh, name things, identify spaces and places, as well as use it to sing, tell stories, and practice our quotidian dialogues.\nBut before continuing with our exhibit, I want to underline the following, the mother tongues of our First Nations are not dialects, they are languages with dialectic variants, which is different. Currently the General Law of Linguistic Rights of our country considers them National Languages. A dialect is a geographic variant of a language, (for example the Spanish spoken in the Dominican Republic and the Spanish spoken in Spain). The language utilized by our indigenous cultures is much more than that, it is an intellectual capacity or faculty developed as human beings that allows us to abstract, conceptualize and communicate ideas. Indigenous languages are born in a particular place and are expressed because they originate from these ancestral lands.\nBut let us go to what preoccupies us: languages also die. Yes, because when a language ceases from being used for a determined activity or is mixed, the language stops evolving as a means of communication within the given sphere as there are no longer new words. For example, indigenous languages rarely create new names for things that arrive in our communities such as telephones, computers, or radios. As such the language loses its influence over naming these new machines, things or items. Consequently, a “loss of dominion” is produced, first of all because these are items that are not produced by the indigenous population, and secondly because of the lack of a linguistic vision through which to identify them.\nFurthermore, if we cease from using Wixárika in our daily conversations or in the workplace, little by little it becomes more difficult to speak or write in our mother tongue about recent discoveries or new knowledge, including in those situations where for different reasons it would be convenient to use Wixárika. What is happening is a deterioration of the Wixárika language as one that sustains a society, especially as we now mix it with other languages like Spanish and English. Generally speaking, there no longer are pure native languages. If when we mention words like Chat, Word, Excel, Power Point, Flash, bye, okey, Spanish has lost its dominion to English, where we have in our country more than 100 million speakers of the language, then what happens with those indigenous languages that have a much smaller quantity of speakers throughout the country where we have at least 62 native languages without counting dialectical variants, and 23 languages that are in danger of becoming extinct (cakchiquel, chichimeca, jonaz, chocho, cluj, cochimí, cucapá, guarijío, ixcateco, ixil, jacalteco, kekchí, kicapú, kiliwa, lacandón, matlatzinca, mocho, paipai, pápago, pima, quiché, seri y tlahuica)?\nWe have taken a few steps forward in some respects, as in the case of the System of Cultural Indigenista Radio Stations of the government’s Commission for the Development of Indigenous Peoples (CDI for its Spanish acronym) that transmit programming in mother tongues, the creation of the General Law of Linguistic Rights, indigenous books, the recording of indigenous music, and above all, the instruction of mother tongues in indigenous education, as well as the effort to standardize indigenous alphabets.\nWe still have much to do, and the obstacles and commitments continue to be the same ones: to strengthen and foment our mother tongues in our own homes, from parents to children, brothers and relatives, but also that of giving us the opportunity to use our languages in order to develop ourselves; otherwise we will continue to fall behind, but of course, we must place our mother tongue in the forefront.\nIt is possible that we wind up in a situation where Spanish or another language becomes the public language (at home, in customs, in reunions, at work, etc) while Wixárika solely remains for domestic use, for informal exchange or for occasional use. Our mother tongue can thus become an obstacle because Wixárika will cease to function as a common and rich language, and we do not want this to occur.\nIt is today that we must elect a language or at least recognize in which situations to use it in order to strengthen it, as tomorrow is too late. We must be informed about what is occurring and be responsible of our destiny.\nPamparios ne iwama, yu nait+ xemuye hane wixáritari aix+a xeteneu erieka.\n©Oscar Ukeme Bautista Muñoz 2008\nOscar Ukeme Bautista Muñoz is a Wixárika graduate from the Autonomous University of Nayarit. He received the National Prize for Indigenous Youth and directed the Union of Indigenous Students for Mexico.\nTranslation by Diana Negrín da Silva']	['<urn:uuid:07a94c95-e142-43a5-ac90-a1c7d168761e>']	factoid	with-premise	long-search-query	similar-to-document	single-doc	expert	2025-05-01T22:36:12.692263	10	19	946
179	asian studies background compare Sylvia Stanfield Darren Aronofsky experience Asia	Both individuals have connections to Asian studies, though with different focuses. Ambassador Sylvia Stanfield has extensive academic and professional experience in Asian studies, earning an M.A. degree in Asian Studies from the University of Hawaii as an East West Center grantee, and studying at the University of Hong Kong School of Oriental Studies and Linguistics. She also studied Mandarin and Cantonese at the State Department's School of Advanced Chinese Language. In contrast, Darren Aronofsky's Asian experience was more limited, primarily consisting of backpacking through the Middle East and studying social anthropology at Harvard, though his work has been influenced by his global travels and experiences.	['Darren Aronofsky was born on 12 February 1969 in Brooklyn, New York. Son of Charlotte Aronofsky and Abraham Aronofsky, he grew up in Manhattan Beach. The Director graduated from Edward R. Morrow High School. He has one sister, Patti. Darren is a popular American Filmmaker and Environmentalist. He is currently dating Jennifer Lawrence – the Mystique girl from X-Men.\nDarren Aronofsky Educational Background\nHe studied Film and Social Anthropology at Harvard University and also attended American Film Institute. He has won several film awards. For his senior thesis he wrote a screenplay called Supermarket Sweep which went on to become a National Student Academy Award Finalist. Darren Aronofsky PI – the Psychological thriller “PI” (the movie grossed $ 3 million) was his debut movie.\nAronofsky is popular for making surreal and psychologically disturbing movies. His most famous movie was the Requiem for a Dream (a novel by the same name by author Hubert Selby Jr.). he loves to explore the grim realities behind the glorious mind. There is something in his screenplay that makes me identify the Subconscious mind which popular author Virginia Woolf also talked about in her works in the later years.\nDestiny always has one trick up her sleeves. if you want something in your life, she will make sure you get it provided that you work hard for it with no excuses. During his youth, Darren trained as a field biologist with The School for Field Studies in Kenya in 1985 and Alaska in 1986. He attended school in Kenya to pursue an interest in learning about ungulates. He later mentioned, “The School for Field Studies changed the way I perceived the world”.\nAronofsky’s interest in the outdoors led him to backpack his way through Europe and the Middle East. In 1987, he entered Harvard University, where he majored in social anthropology and studied filmmaking; he graduated in 1991.\nDarren entered the world of filmmaking with his debut PI. The movie was shot in 1997 . the film was produced with an initial budget of $ 60,000 , the movie premiered at the 1998 Sundance Film Festival, where the director received his first award.\nMovies directed by Darren Aronofsky\n|Requiem for a Dream||2000|\n|Hubert Selby Jr.: It/II be better||–|\n|White Boy Rick||2018|\nMost acclaimed work\nDarren has been an influential screenplay writer and director. He explains that he got the chance to see the world from a new perspective while he was in Africa. He is a notable storyteller, who understands the grim realities and introspects the mind and its games especially as the person experiencing it sees it. One of his acclaimed movies Black Swan was another was nominated for 5 Academy Awards.\nMovie – Black Swan\n|Genre||Mystery / Drama Film|\n|Starcast||Natlaie Portman, Mila Kunis, Vincent Cassel, Mark Margolis|\n|Plot||Nina a ballerina, gets the chance to play the white Swan, Princess Odette. But she finds herself slipping into madness when Thomas, the artistic director, decides that Lily might fit the role better.|\n|Released on||25 Febrauary 2011|\n|Box Office Collection||329.4 million USD|\n|Review||S. Jhoanna (Common Sense Media): Black Swan is a dance macabre personified a grueling tragic, obsessive and gripping film about a ballerina’s quest for perfection at the expense of personality and sanity|\nMovie – Requiem for a Dream\n|Starcast||Jared Leto, Hubert Selby Jr., Jennfier Connelly, Ajay Naidu, Abraham Aronofsky, Marlon Wayans, Christopher McDonald, Marcia Jean, Loiuse Lasser, Mark Margolis, Sean Gullette, Keith David, Suzanne Shepherd, Dylan Baker|\n|Plot||Imaginatively evoking the inner landscape of human beings longing to connect, to love and feel loved, the film is a prable of happiness lost. It tells the parallel stories between the lonely, widowed sara Goldfarb and her son Harry. The plump sara, starts a dangerous diet regimen to beautify herself for a national audience.|\n|Released on||06 October 2000|\n|Review||Peter Travers from Rolling Stone: No one interested in the power and magic of movies should miss it.|\nHis Few Favorites\nDarren Aronofsky has a special bond with his father Abraham Aronofsky and Mark Miragolis. He always managed to reserve a space for both in his each movie. For example, in all his movies, his gets a role on matter how small it is. Bet you didn’t notice that. Mark Margolis and Abraham Aronofsky remain his favorites. Darren makes sure that they both are a part of his movies.\nRoles his father played in his movies\n- Black Swan – Mr. Stein\n- The Fountain – Lab Technician\n- The Wrestler – the annoyed man\n- PI – Delivery man\nAronofsky is also a keen participant of environmental activism. To support the save the environment, In 2014, he traveled to the Alberta Tar Sands with the Sierra Club’s Michael Brune and Leonardo DiCaprio to promote the need to save the environment. In 2015, he traveled to Alaska’s Arctic National Wildlife Refuge with Brune, Keri Russell, and the leaders of several veterans groups.\nHe also holds the honor of receiving the Humanitarian Award from both the Humane Society of the United States and PETA.\nNot only that, In 2015, he collaborated with the artist JR on “The Standing March,” which was a public art installation in Paris to encourage diplomats at COP21 to take action against climate change.\nHe is a board member of The Sierra Club Foundation and The School of Field Studies.', '2021 – China, Strategic Challenges Old and New\nOn December 8, 2021, the Gerald R. Ford School of Public Policy at the University of Michigan and the American Academy of Diplomacy co-hosted a discussion panel to enhance public understanding of critical foreign policy areas. This in-person panel focused on China and the challenges for a future U.S.-China relationship featuring panelists Ambassadors Sylvia Stanfield, Craig Allen, David Shear, and moderator Ambassador Gerald Feierstein.\nABOUT THE SPEAKERS\nAmbassador (retired) Sylvia Gaye Stanfield was the U.S. Ambassador to Brunei Darussalam from 1999-2002 and a career member of the U.S. Senior Foreign Service.\nAsia was the focus of much of her 30 plus years with the Foreign Service. Her first overseas assignment was with the then American Embassy in Taipei, Taiwan. As a political track Chinese language officer, she had postings with the U.S. Consulate General in Hong Kong, the U.S. Embassy in Beijing, and the American Institute in Taiwan in Taipei. She served on the State Department’s “China desk” at the time of the normalization of U.S. relations with the People’s Republic of China and later headed the Office of Taiwan Coordination Affairs. She was Director of Australian and New Zealand Affairs prior to serving as Charge d’Affaires and Deputy Chief of Mission of the U.S. Embassy in Wellington, New Zealand. Her wide-ranging Washington assignments included those with the Bureau of African Affairs, the Bureau of International Organizations Affairs, the Office of the Inspector General, the Board of Examiners, and the Senior Seminar. She was Diplomat-in-Residence at Florida A&M University and at Spelman College before serving as Senior Advisor for Mentoring Coordination at the Department of State.\nAlong with continuing involvement in mentoring activities, she is a President of Black Professionals in International Affairs (BPIA) – an organization founded in the late 1980’s to increase African-Americans’ interest and involvement in international affairs, and a member of the Association of Black American Ambassadors executive committee. She also is a Director of the Miami University (Ohio) Foundation Board, and a past president and current member of the Western College Alumnae Association Board of Trustees.\nA native Texan, she earned a B.A. degree in intercultural studies from Western College for Women in Oxford, Ohio. While an East West Center grantee, she received a M.A. degree in Asian Studies from the University of Hawaii and continued her studies at the University of Hong Kong School of Oriental Studies and Linguistics. After joining the Foreign Service, she did further study in Mandarin and Cantonese at the State Department’s School of Advanced Chinese Language and Area Studies in Taiwan.\nOn July 26, 2018, Craig Allen began his tenure in Washington, DC, as the sixth President of the United States-China Business Council (USCBC), a private, nonpartisan, nonprofit organization representing over 200 American companies doing business with China. Prior to joining USCBC, Craig had a long, distinguished career in US public service.\nCraig began his government career in 1985 at the Department of Commerce’s International Trade Administration (ITA). He entered government as a Presidential Management Intern, rotating through the four branches of ITA. From 1986 to 1988, he was an international economist in ITA’s China Office.\nIn 1988, Craig transferred to the American Institute in Taiwan, where he served as Director of the American Trade Center in Taipei. He held this position until 1992, when he returned to the Department of Commerce for a three-year posting at the US Embassy in Beijing as Commercial Attaché.\nIn 1995, Craig was assigned to the US Embassy in Tokyo, where he served as a Commercial Attaché. In 1998, he was promoted to Deputy Senior Commercial Officer. In 1999, Craig became a member of the Senior Foreign Service.\nFrom 2000, Craig served a two-year tour at the National Center for APEC in Seattle. While there, he worked on the APEC Summits in Brunei, China, and Mexico. In 2002, it was back to Beijing, where Craig served as the Senior Commercial Officer. In Beijing, Craig was promoted to the Minister Counselor rank of the Senior Foreign Service.\nAfter a four-year tour in South Africa, Craig became Deputy Assistant Secretary for Asia at the US Department of Commerce’s International Trade Administration. He later became Deputy Assistant Secretary for China. Craig was sworn in as the United States ambassador to Brunei Darussalam on December 19, 2014. He served there until July 2018, when he transitioned to President of the US-China Business Council.\nCraig received a B.A. from the University of Michigan in Political Science and Asian Studies in 1979. He received a Master of Science in Foreign Service from Georgetown University in 1985.\nAmbassador David B. Shear is an Adjunct Professor at the Johns Hopkins School of Advanced International Studies (SAIS). He performed the duties of Principle Deputy Under Secretary of Defense for Policy from June 2016 to January 2017. He was the Assistant Secretary of Defense for Asian and Pacific Security Affairs from September 2014 to June 2016. Prior to 2014, Mr. Shear served for 32 years in the American Foreign Service, most recently as the United States Ambassador to Vietnam. He has also served in Sapporo, Beijing, Tokyo, and Kuala Lumpur. In Washington, he has served in the Offices of Japanese, Chinese, and Korean Affairs and as the Special Assistant to the Under Secretary for Political Affairs. He was Director of the Office of Chinese and Mongolian Affairs in 2008-2009 and served as Deputy Assistant Secretary in the Bureau of East Asian and Pacific Affairs in 2009-2011. Ambassador Shear was a Rusk Fellow at Georgetown University’s Institute for the Study of Diplomacy 1998-99. He is a graduate of Earlham College and SAIS and has attended Waseda University, Taiwan National University, and Nanjing University. Ambassador Shear is the recipient of the State Department’s Superior Honor Award and the Defense Department’s Civilian Meritorious Service Award. He has a first degree rank in kendo, the Japanese art of swordsmanship.\nJerry Feierstein retired from the U.S. Foreign Service in May 2016 after a 41-year career. At the time of his retirement, Feierstein held the personal rank of Career Minister. Feierstein currently serves as the Senior Vice President of the Middle East Institute. Over the course of his career, he served in nine overseas postings, including three tours of duty in Pakistan, as well as tours in Saudi Arabia, Oman, Lebanon, Jerusalem, and Tunisia. In 2010, President Obama appointed Feierstein U.S. Ambassador to Yemen, where he served until 2013. From 2013 until his retirement, Feierstein was Principal Deputy Assistant Secretary of State for Near East Affairs.\nIn addition to his career-long focus on the Near East and South Asia, Feierstein also played a prominent role in developing and implementing State Department policies and programs to counter violent extremism. As Deputy Coordinator and Principal Deputy Coordinator in the State Department’s Counter-Terrorism bureau, Feierstein led the development of initiatives to build regional networks to confront extremist groups as well as to counter terrorist financing and promote counter-terrorism messaging. He continued to focus on defeating terrorist groups through his subsequent tours as Deputy Chief of Mission in Pakistan and as Ambassador to Yemen.\nFeierstein joined the Middle East Institute in October 2016 as a Senior Fellow and the Director of a new Center for Gulf Affairs.']	['<urn:uuid:43d0565e-6ce7-4903-8cc2-7bfba9a3d39a>', '<urn:uuid:375d5b7e-9703-4818-a5c3-3760ee98d14d>']	open-ended	with-premise	long-search-query	similar-to-document	comparison	novice	2025-05-01T22:36:12.692263	10	105	2086
181	What's the maximum allowed shot shell load for handicap competitions?	Under the rules of the Australian Clay Target Association, 32 grams of shot is the permissible maximum load for handicap competitions.	['Article 4 – 2010\nQuestion: I have been shooting Trap for over a year now and have worked my way back to a 21 metre handicap with a standard Miroku Trap gun. When I shoot from this distance and even further back have you any suggestions you can give me to improve? I seem to be very erratic and inconsistent the further back I get, but I guess this is understandable. Grateful for any advice you can give me.\nAndrew G, Essendon VIC\nAnswer: I have always liked to make some changes when shooting from 22 metres and beyond. First of all the hold or starting position of the gun in relation to the trap house when calling for the target is different for me. I like to use a high gun hold position when shooting trap and teach this technique for shooters that shoot with both eyes open. The starting position for common mark ( 15 metre ) shooting is much higher than what it is off my handicap mark of 25 metres. This is simply to have a similar amount of gun movement to move the gun up from the starting position to the point where the trigger is pulled to break the target. Obviously the further back you stand from the trap house the less gun movement is needed to shoot the target so to simulate the movement needed from 15 metres to 25 metres a lower start position is needed for the latter. If you have a shotgun with an adjustable comb and adjustable chokes then two more alterations can be made which I believe are advantageous. I personally like to shoot a gun with a higher point of impact from the maximum handicap distance. I do this because it gives me extra vertical lead when you come up from under the target. I like to lift my comb up three millimeters which equates to a twelve percent higher shooting shot pattern.\nThere is only one choke to use if you have a choice on long handicap shots. Full. There really isn’t anything to discuss here. I use an improved modified choke for the first shot from 15 metres and the extra 10 metres in handicap ideally requires the next tightest choke. If you have the luxury of having both barrels with adjustable chokes then screw in an even tighter full choke into the top tube. Remember a standard full choke with a typical trap load is ideal to 36.5 metres. Not too many shooters I have seen are quick enough to shoot both barrels accurately at a target before it has travelled only 11.5 metres from the trap so anything less than full choke is probably not perfect.\nUnder the rules of the Australian Clay Target Association a shot shell with 32 grams of shot is the permissible maximum load to be used in handicap competitions ( 28 grams is the maximum for all other DTL Trap events ). Take advantage of the extra 4 grams of shot when shooting at the greater distance. Personally I like number 7 shot from 25 metres as opposed to 7.5’s from 15 metres. The larger shot has the extra hitting power on the target which I prefer, particularly if you need a second barrel break. Any shot shell that has a velocity of over 1250 feet per second with 32 grams of shot is going to recoil on your shoulder and face fairly hard so I really think you need to avoid some of the ultra fast loads that I am sure will hit the target hard, but your body just as hard which can make 50 targets of handicap shooting a bruising and unpleasant experience.\nFinally if you get the opportunity to shoot a 32” or 81cm barrel from the longer handicap distances then please try it. The extra couple of inches will smooth out your swing and I am sure will improve your score. In the United States where the best handicap shooters play, 34” and even 36” barrels are not uncommon.']	['<urn:uuid:09d85b39-418f-4f95-8bcf-646d80f4ede9>']	factoid	with-premise	concise-and-natural	similar-to-document	single-doc	novice	2025-05-01T22:36:12.692263	10	21	676
182	body composition testing methods hydrostatic weighing dexa scan radiation exposure safety concerns	Hydrostatic weighing uses water displacement with no radiation exposure, making it safe for frequent testing. In contrast, DEXA scanning uses very low levels of X-ray radiation, which while relatively low, may be of concern for frequent testing and is not recommended during pregnancy. Both methods can accurately measure body composition, with DEXA having the additional capability of measuring bone density.	"['Everything You Need To Know\nAbout Hydrostatic Body Fat Testing.\nWhat is a Hydrostatic Body Fat Test?\nDefinition: Hydrostatic weighing, also referred to as ""underwater weighing,"" ""hydrostatic body composition analysis,"" and ""hydrodensitometry,"" is a technique for measuring the mass per unit volume of a living person\'s body. It is a direct application of Archimedes\' principle, that an object displaces its own volume of water.\nWhy should I try Hydrostatic Weighing?\nBody fat testing (rather than just stepping on your simple home scales) is the best way to find out what you are really made of! Research shows that Hydrostatic Testing (Underwater Weighing) has become universally regarded, by industry experts, as the ""Gold Standard"" in body fat testing.\nWhether you are looking to lose weight, gain weight, or just maintain your current weight, having a Hydrostatic Body Fat Test done will provide you with a wealth of information to let you know how you\'re doing.\n""That hydrostatic testing (underwater immersion) is the most accurate method for body fat determination."" Renowned author and fitness expert Covert Bailey, in the phenomenal best seller ""Fit or Fat""\nHow do other body fat testing methods compare?\nHydrostatic Body Fat Test\n- Regarded as the “Gold Standard” in body fat testing\n- Fast test time (5-10 minutes)\n- Most accurate technology available today\n- Provides the best repeatability from test to test (tracking changes)\n- Error rate around 1.5%\n- Low equipment maintenance\n- Has been the most accurate method for over 30 years\n- Requires knowledge to administer test\n- Being submerged underwater might be a little difficult for some (if you’re uncomfortable going underwater for a few seconds.)\n- Must be able to blow out your air\nDuel Energy X-Ray (Dexa)\n- Under proper conditions it provides accurate results\n- Error Rate is less than 2% under proper conditions\n- Radiation exposure is relatively low but it is still new technology\n- Very expensive equipment\n- High Cost per test\n- Different DEXA equipment can produce different results\n- X-Ray license required to use machine\n- Frequent testing may be of concern due to radiation exposure\n- Was designed for discriminating bone density as opposed to soft tissue such as organs, muscle and fat\nCaliper Body Fat Test\n- Easy to use once skill is mastered\n- Does not require much time\n- Noninvasive method\n- Inexpensive way of estimating body fat percent\n- Technical sources of error\n- Error rate up to +/-8%\n- Mostly concerned with subcutaneous fat (under the skin)\n- May not be an ideal measurement for those who are obese, or very lean.\n- Reliability is highly dependent upon skill and the type of calipers used\nBod Pod Body Fat Testing\n- Fast 5 -10 minutes\n- Not difficult to operate\n- Error ratio +/-3 percent\n- Results effected by body temp of muscles\n- Hydration levels can effect results\n- Body hair can have an effect on the results\n- Very expensive equipment\n- Breathing pattern might affect the results\n- Can have a claustrophobic effect', 'DEXA (DXA) Scan: Bone Density Test\nWhat is a bone density test?\nA bone density test, DEXA, measures the mineral content of the bones in certain areas of the skeleton. It’s a way to measure bone loss as you age. Healthcare providers sometimes call these tests bone densitometry tests, or DXA.\nWhat is a DEXA scan?\nA DEXA scan is a type of medical imaging test. It uses very low levels of x-rays to measure how dense your bones are. DEXA stands for “dual-energy X-ray absorptiometry.”\nMedical experts consider DEXA scans to be the most useful, easy, and inexpensive test for helping to diagnose osteoporosis. The test is quick and painless.\nWhat is osteoporosis?\nOsteoporosis is a term used to describe brittle bones and also the risk for having a broken bone. As you age, your bones can lose thickness and strength. Osteoporosis literally means “porous bone.” DEXA tests help your healthcare provider track your bone density and risk for having a broken bone over time. Providers often use DEXA tests to help diagnose osteoporosis.\nOsteoporosis results when you to lose bone faster than your body can create new bone tissue. This is most common in postmenopausal women. Over time, bones get weaker. Brittle bones break more easily.\nProviders sometimes call osteoporosis a “silent” disease because it doesn’t hurt. Many people first realize they have osteoporosis after they break a bone from a minor fall.\nWhat is Osteopenia?\nOsteopenia is a term used to describe “low bone mass.” Many individuals, including those who are slender and very active, have lower bone mass all of their lives. But this does not necessarily mean that they will develop osteoporosis. Many world-class athletes have low bone mass but their bones are healthy and very strong. Osteopenia is not “pre-osteoporosis,” but sometimes, if a person has other risk factors for fracture, an osteoporosis medication will be recommended to help prevent future fractures.\nHow does a DEXA scan work?\nDEXA scans measure the mineral content in certain bones, such as the hip, spine and/or wrist. It works this way:\n- You will be asked to lie on a special DEXA x-ray table. The technologist will help position your correctly and use positioning devices such as foam blocks to help hold the desired position.\n- As the arm of the DEXA machine passes over the body, IT uses two different x-ray beams. The beams use very little radiation to keep the test safer, and help to distinguish bone from other tissues.\n- The scanner translates the bone density measurement data into pictures and graphs. Bone is most easily seen in white, while the, fat and muscle tissue look like shadows in the background on the technologist’s computer monitor.\n- These results are then reviewed and interpreted by a radiologist or other physician trained in DEXA interpretation\n- Your healthcare provider is sent a copy of the written report to discuss with you and consider what treatment is most appropriate.\nWho gets a DEXA scan?\nHealthcare providers consider many factors when deciding who may benefit from a DEXA scan and how often. Healthcare providers often recommend a DEXA scan to assess your bone health for osteoporosis and fracture risk if you are older than 50, have had a broken bone, or other illnesses that put your bone health at risk.\nResearch shows women start losing bone mass earlier and faster than men. So healthcare providers usually recommend women get a DEXA scan to screen for osteoporosis at younger ages compared to men.\nYour provider may recommend a DEXA scan if you have one or more risk factors for osteoporosis or fractures:\n- Increased age: Many individuals lose bone mass as they get older. The National Osteoporosis Foundation recommends people at average risk get a DEXA scan starting at 65 (women) and 70 (men).\n- Family history: If one or more family members have had osteoporosis or more than one fracture, you could be at a higher risk for bone loss.\n- Previous fracture injuries: Breaking a bone, especially after age 50, may be a sign that you’re at greater risk. Porous (less dense) bones break more easily.\n- Medications: Some medications, such as the steroid prednisone, cancer drugs, and drugs used after an organ transplant can weaken your bones.\n- Your overall health: Many chronic medical disorders can make your bones more likely to break. Risky conditions include rheumatoid arthritis, lupus, diabetes, liver disease and kidney disease.\nWhat else do healthcare providers use DEXA scans for?\nHealthcare providers may also order a DEXA scan to:\n- Track bone health changes over time.\n- Monitor your response to treatment, such as an osteoporosis medication.\n- Evaluate body composition, such as how much fat and muscle mass your body has (and where).\nHow often should a DEXA scan be done?\nMedicare allows a DEXA scan to be done once every two years, and this is the current recommended timeframe. There are exceptions to this rule if you have certain diseases.\nYour healthcare provider will consider several factors, such as your age, level of fracture risk, previous DEXA scan and current medications. Your healthcare provider will then make a personalized plan for how to assess and protect your bone health.\nHow should I prepare for a DEXA scan?\nMost people don’t need to change their daily routine before a DEXA scan. Eat, drink and take any medications as you normally would, unless your provider tells you otherwise. You will be asked to fill out a questionnaire that asks about your current health, your family history of broken bones, smoking history, and current medications.\nBefore your test, please do the following:\n- Stop taking calcium supplements 24 hours before your test: This includes multivitamins as well as antacids such as TUMS® (commonly used to treat heartburn).\n- Wear loose-fitting clothing with no metal: Wear comfortable clothes. Try to choose items that don’t have metal (zippers, buttons or buckles). Sweatpants and a casual top may be good choices.\n- Tell your doctor if you might be pregnant: DEXA scans use low levels of radiation. Medical experts recommend avoiding all radiation exposure during pregnancy to protect an unborn baby.\nHow is a bone density test done?\nDEXA bone density tests are outpatient procedures. You may be able to wear your regular clothes during the test. Or you may be asked to change into a hospital gown. There are no needles or injections in this test. Getting a DEXA test is similar to having a standard X-ray.\nHow long does a DEXA scan take?\nA DEXA scan usually takes no more than 25 minutes. Many people are in and out of the room in less than 30 minutes.\nIs a DEXA scan painful?\nNot at all. You won’t feel a thing as the X-ray beams pass through your body.\nYou may feel slightly uncomfortable lying on the table, depending on how you’re positioned. But you’ll only need to stay in that position for a few minutes.\nHow accurate are DEXA scans?\nDEXA scans offer a high degree of precision and accuracy. Medical experts consider DEXA scans to be an accurate test for diagnosing osteoporosis.\nUnlike x-ray machines, DEXA machines are checked daily for their ability to measure bone mineral accurately, and no two DXA machines are exactly alike. That is why your healthcare provider will insist that you have all of your DEXA tests done on the same machine.\nResults and Follow-Up\nWhat should I expect after a DEXA scan?\nDEXA scans are quick and painless. You should be able to resume your usual activities immediately after the test.\nProfessionals certified to interpret DEXA images will review your results and write a report that will be sent to your healthcare provider.\nYour healthcare provider will explain your test results and help you understand what they mean for your health. Your healthcare provider can help you make decisions about how to keep your bones strong. They can also recommend diet and lifestyle changes that may help to lower your risk of a fracture.\nWhat should I ask my healthcare provider?\nIf your healthcare provider has recommended a DEXA scan, you may want to ask:\n- Why do you recommend this test for me?\n- Where do you recommend I have this test?\n- What should I do to prepare for my test?\n- When should I expect to get test results?\n- Will I need other tests?\n- What can I do at home to keep my bones healthy?\nMedical experts consider DEXA scans the “gold standard” for diagnosing osteoporosis and fracture risk. Many individuals lose bone density as they age. But that doesn’t mean you have to accept fragile bones simply as a reality of getting older. It is never too early to learn how to take care of your bones! Ask your provider if a DEXA scan may help assess your bone health today. Then, talk about steps you can take to slow bone loss or protect your bones for years to come.']"	['<urn:uuid:690abf82-eb0c-4480-9a6e-ff86e38024ef>', '<urn:uuid:2376dcb0-6391-43ef-8834-19a861086ca7>']	factoid	direct	long-search-query	similar-to-document	multi-aspect	expert	2025-05-01T22:36:12.692263	12	60	2008
183	differences between epoxy polyester vinyl ester resins boat building applications surface preparation requirements	Different resins have distinct applications in boat building. Epoxy resins are ideal for wooden boats due to their low porosity and superior filling capability, but are the most expensive. Polyester resins are cheaper and better suited for GRP boats, while vinyl ester resins offer a middle ground in terms of cost and moisture protection. For surface preparation, non-porous surfaces need to be sanded smooth, and all surfaces must be cleaned of oil and wax using acetone or appropriate solvents with paper towels. For epoxy application specifically, surfaces need different preparation methods: if the previous coat is wet but cured enough, direct application is possible; if fully cured, amine blush must be removed and the surface sanded; alternatively, peel ply can be used on flat surfaces.	"['Trade Secrets: 3 ways to prepare a surface for recoating in epoxy\nWhatever the project you’re working on, you’ll need several coats of epoxy resin and hardener. Most projects need between two and four. However many coats you’re planning on, you need to recoat at the right time and in the right way and ensure your surface is properly prepared.\nHow you prepare a surface for recoating with epoxy depends on whether the epoxy you’re covering is wet or dry.\nIf the epoxy is wet but cured enough to support the weight of the next coat, you can just apply another coat to create a ‘primary bond’, which is a bond between the epoxy layers at the chemical level (intramolecular bonding). However, as your epoxy blend dries it becomes harder to create a primary bond, so you’ll need to achieve a secondary bond (intermolecular bonding). Secondary bonding includes dipole-dipole bonding and hydrogen bonding. Mechanical bonding can also be achieved when liquid adhesive flows into surface cracks and cures, thereby ‘keying in’ to the surface.\nBelow, we talk you through the three main ways that you can get your epoxy-coated surface – whether wet or dry – ready for its next coat.\n1. How to prepare a completely cured epoxy surface\nIf your epoxy has completely cured, then the first thing you’ll need to do is check the surface for amine blush.\nAmine blush appears as a wax-like film on cured epoxy surfaces. It’s a normal by-product of the curing process and it’s easier to spot in cool, moist conditions. Even though amine blush can prevent bonding to further layers of epoxy, it is water soluble and easy to remove.\nAll you need to do is wash the surface thoroughly with clean water and an abrasive pad and then dry it with fresh paper towels to rub off the amine blush before it dries on the surface again. Then, sand any glossy areas of the surface with 80-grit sandpaper to ‘key it in’ and clean away the dust. Now you can apply your next coat of epoxy.\n2. How to recoat a recently epoxy-coated surface: the sticky tape test\nIf you have recently applied epoxy, then you can apply the next layer when the previous coating has reached the sticky stage.\nTo check the epoxy is appropriately sticky, you can perform what we call the ‘sticky-tape test’. When you put your finger on some sticky tape, you can feel the stickiness but no glue actually comes away from the tape. Similarly, if you can put a gloved finger on your epoxy-coated surface and it feels tacky – but no glue comes away – then you’re at the right stage to apply another coat.\nIf a lot of epoxy comes away on your finger, then you’ll need to leave the surface to cure for a bit longer. By the same token, if there’s no stickiness at all then you’ll have to refer to method 1 above and treat the surface as fully cured.\n3. Using peel ply\nThe third method for preparing a surface for recoating in epoxy is to use peel ply.\nPeel ply – also known as release fabric – is a synthetic cloth that’s designed to improve the texture of an epoxy-coated surface. Importantly, it doesn’t stick to the epoxy; it just peels away to leave behind a perfectly textured surface that’s ready for your next epoxy layer to adhere to.\nAll you do is apply your epoxy blend to your surface and drape the peel ply on the top. Make sure you smooth the peel ply out with a spreader so that there are no air bubbles. Once the epoxy has cured, you can just peel off the peel ply and you’re ready to apply your next layer.\nRemember that peel ply is best reserved for flat surfaces. It doesn’t work well with curves, as any wrinkles left in the peel ply will cure into the epoxy.\nThanks very much to Hamish Cook for his contribution.\nWant to know more about coating surfaces in epoxy? Take a look through our detailed archive of Trade Secrets.', '- slide 1 of 5\nResins play a multi-purpose role in boat building. They are used for gluing, fiberglassing, moisture sealing, and coating or encapsulating. Resins can also be used as a fairing compounds. There are many commercial products and types available. Before using these materials, users should have in mind the following basic information.\n- slide 2 of 5\nTypes of Resins\nEpoxy resins : These resins are suitable for wood boats, since they are less porous than the rest of the available types and present a remarkable ability to cover fillings. They are the most expensive type of resins.\nPolyester resins : These resins are not recommended for wooden boats. On the contrary, they are more suitable for GRP boats. They are the cheapest ones.\nVinyl ester resins: This is a less popular type of resin for boat building. The cost of vinyl esters comes between the one of polyesters and the epoxies. They offer more effective moisture protection than the polyesters, and a more reasonable price than the epoxies, although the latter are considered to be the top in moisture resistance. Vinyl ester resins also present great mechanical properties; they are tougher and more flexible than polyesters. They can also endure extreme fatigue and high temperatures without distorting. However, this material is more difficult to process and requires good ambient conditions during cure in order to be more effective.\n- slide 3 of 5\nApplying Procedure for Epoxies, the most Popular Resins\nPreparing the Mixture\n- Mixing the resin with the hardener in a plastic or metal container, is the first step. The mixing ratios depend on the specifications of each product.\n- The two ingredients should be stirred together thoroughly. A power mixer could also be used.\n- Fillers could also be added in the mixture. The purpose of fillers is to thicken the mixture in order to be more suitable for bonding or fairing.\nPreparing the Surface\n- The bonding surfaces should be firstly cleaned of any oil, wax etc. by using acetone or any other appropriate solvent. The surface should be wiped with paper towels before the solvent dries.\n- Non-porous surfaces should be sanded smooth.\nApplying and Curing\n- The time period between mixing and applying is called ""pot life"" and depends on the product\'s requirements.\n- After the mixture is ready it should be applied to the bonding surfaces with a brush, foam roller, or plastic spreader.\n- The resin should then be left to cure. It takes approximately 24 to 48 hours.\n- Curing times will also vary according to the mixing ratios.\n- The repaired surface should then be sanded with a 120-grit sandpaper to remove most of the excess material and a 220-grit sandpaper to polish the area.\nThis is the general procedure followed. Users should always consult the manufacturer\'s instructions.\n- slide 4 of 5\nHazards and Safety Precautions for Epoxies\nThe use of resins, especially epoxies, entails health risks and certain safety measures should be taken during use:\n- The ratio of resin to hardener should be carefully measured. Wrong ratios result in curing problems.\n- The process of curing generates heat. If the mixture begins to heat up it should be quickly moved to a cooler environment.\n- The mixture should be used after the reaction is complete and has cooled\n- Glass or foam containers for epoxy resins should be avoided because of the potential exothermic heat build-up risk. Manufacturers recommend the use of plastic, metal or wax-free paper containers.\n- Long exposure may cause a skin rash, so skin contact should be avoided.\n- The use of gloves is necessary.\n- In case of skin contact, an appropriate cleaner such as vinegar or a hand cleaner should be used. Solvents or acetone should be avoided.\n- Fumes should not be inhaled.\n- Users will have to make sure that they are not allergic to these materials.\nUsers should have in mind that the cheaper the resin the more diluted it is and of low quality. It is recommended that users only use well-known products.']"	['<urn:uuid:d56fd801-b4ce-44ab-8128-b8f5ab54fd0f>', '<urn:uuid:7c2c561b-86f6-491c-90ff-8c76e725c93c>']	open-ended	direct	long-search-query	similar-to-document	multi-aspect	expert	2025-05-01T22:36:12.692263	13	125	1367
184	facilities inside railway sleeper levels russia	There are three classes of railway cars in the Trans-Siberian Railway. The 3rd Class (Platzkartny) has open carriages with 54 beds arranged in bunk formations, with folding lower beds and luggage lockers. The 2nd Class (Kupe) features lockable compartments with four beds each. The 1st Class (Lux) offers the most comfort with only two beds per compartment and no upper bunks, and is generally cleaner and better maintained.	['The Trans-Siberian Railway has three different classes of railway car. Your travel experience will depend completely on which of these you choose. One aspect is, of course, the vastly differing prices. Even more important is personal preference. Do you want to get to know the country and people or do you prefer a peaceful journey? What are the hygienic standards?\nPlatzkartny – The 3rd Class of the Trans-Siberian Railway\nIn the cheap 3rd Class, there are no separate compartments, just an open carriage. In the picture on the right you can see what it looks like inside.\nThere are always two beds, one above the other. On each side of the aisle are two bunk beds side by side, with a small table by the window between the beds. The lower beds can be folded up and have luggage lockers underneath. One side is like an open compartment. On the other side of the corridor, the beds are parallel to the passage. The lower bed can be folded up during the day and turned into a table. Altogether there are around nine combinations with a total of 54 beds in a railway car.\nSpending the night so close to so many strangers is not everyone’s cup of tea. On the other hand these tickets, the so-called “Platznykarty” are much cheaper. It is also the best way to get to know the country and people playing a round of Durak. Most Russians are very friendly and interested in foreigners and constantly offer us food and drink. If you need your rest and don’t want to chat continuously, this is not the place for you. If you decide to use this class of car try, if possible, to get the compartment-side bed. There you have some peace because you sleep with your head to the window. Moreover, one can leave the bed down during the day and snooze in comfort. The beds on the compartment side have the numbers 1-36. The beds on the corridor side, the numbers 37-54.\nKupe and Lux – the better railcar classes of the Trans-Siberian Railway\nThe second Class (Kupe) is considerably more private. There are four beds in a lockable compartment. The allocation of bunks is similar to that in the open 3rd Class compartment. No distinction is made between men and women, bunks are assigned randomly. You have more peace of mind here but also no contact with the locals. The 2nd Class is used by tourists mainly.\nIn the first Class (Lux) there are only two beds in a compartment, the upper bunks are absent. These are supposedly cleaner and better maintained.\nNo definite recommendation can be given. Those who want a real Trans-Siberian adventure should choose the 3rd class. If you feel you might be overwhelmed, the 2nd Class is the better choice. The 1st Class is probably suitable for only few readers here. To get a feel about how the prices differ, I recommend my page on Trans-Siberian Railway Prices.\nRemember that tickets for the 3rd Class are not available everywhere. You will find more information about this on my page on Trans-Siberian Railway Ticket Booking.']	['<urn:uuid:40e0e0b6-713a-444d-bbb2-c61aa938bef6>']	open-ended	direct	short-search-query	distant-from-document	single-doc	expert	2025-05-01T22:36:12.692263	6	68	524
185	planning to go camping range creek bears food safety precautions need to know	In Range Creek, strict food safety precautions are necessary due to black bears. Bears can quickly become accustomed to finding food in human-active areas. To prevent this, food items are not allowed inside tents or open vehicles. Even scented items like lotions and shampoos must be kept out of tents. Special precautions are also taken to ensure bears have no access to trash.	"[""Your cart is empty.\nAnimals of Range Creek\nThe animals of Range Creek are completely wild and we work hard to keep it that way. Black bears in particular can quickly get used to the idea that tasty treats are available in areas where humans are active. Food, even yummy smelling lotions and shampoos, are not allowed inside tents or open vehicles and special precautions are taken to make sure that bears have no access to trash.\nRange Creek is home to many different species of animals, each living in the area best suited to their needs. Many animals, especially the mammals, have a wide range of habitats but for a few it is limited. For example, moose (Alces alces) and flying squirrels (Glaucomys sabrinus) prefer the cooler and moister conditions found at higher elevations while big horn sheep (Ovis canadensis) frequent the desert terrain and cliffs of the lower canyon.\nSmall mammals such as deer mice (Peromyscus maniculatus), bushy-tailed pack rats (Neotoma cinerea), squirrels (Spermophilus variegatus), long-tailed weasels (Mustela frenata), and cottontail rabbits (Sylvilagus nuttallii) are frequently seen in and around the ranch complex. Mule deer (Odocoileus hemionus) browse the surrounding pastures along with coyotes (Canis latrans) hunting for mice and rabbits. In the fall they are joined by elk (Cervus elaphus) coming down from the high country to spend the winter.\nAt night visitors to the ranch get a chance to view, hear, or smell some of the nocturnal species that call Range Creek home. A bat census conducted by the Utah Division of Wildlife Resources in 2007 confirmed the presence of at least seven different species of bat including: Hoary bat (Lasiurus cinereus), western pipistrelle (Pipistrellus hesperus), big brown bat (Eptesicus fuscus), Towsend's big eared bat (Plecotus townsendii), and three species of the Myotis genera fringed, little brown and yuma (M. thysandes, M. lucifugus and M. yumanensis). The bats come out at dusk preforming aerial acrobatics in quest of their favorite food - flying insects. Other animals whose presence is known, but who are less frequently sighted, include skunks (Mephitis mephitis), ring-tailed cats (Bassariscus astutus), and great horned owls (Bulbo virginianus). Other elusive and rarely seen species include the black bear (Ursus americanus), mountain lion (Felis concolor), red fox (Vulpes vulpes), and bob cats (Lynx rufus) whose tracks and scats are seen much more often than the animals themselves. These animals do most of their hunting at night and spend the hot summer days snoozing in the shade.\nReptiles and amphibians are also represented in Range Creek. Garter snakes (Thamnophis sp.) and racers (Columber sp.) are common. Great Basin gopher snakes (Pituophis melanoleucus) are another commonly found species. This rattlesnake mimic in both appearance and manner feeds on mice, toads, and other snakes including rattlesnakes (Crotalus viridis) which, while present, are rarely seen. The most conspicious amphibian species in the canyon is the western toad (Bufo boreas). At night these toads leave their burrows to hunt for flying insects and ants that are snatched up using their sticky tongues. In the summer they lay their eggs in the murky still waters of the pond where their transformation from tadpole to toad takes place. Once fully developed thousands of penny-sized toads cover the ground as they move away from the water to find their new homes.\nIn 2004 the Salt Lake Chapter of the Audobon Society identified more than seventy bird species in Range Creek. Visitors to the ranch may spot birds of prey like golden eagles (Aquila chrysaetos) or red-tailed hawks (Buteo jamaicensis) circling far above in search of a hapless rabbit or squirrel while ravens (Corvus corax) squawk from the branches of the cottonwoods. During the spring and fall migration red shafted flickers (Colaptes auratus) and downy woodpeckers (Picoides pubescens) interupt the quiet of the ranch drumming their bills against trees in search of food. Many wren, finch, and sparrow species visit feeding stations at the ranch and hummingbirds keep visitors entertained watching their aerial acrobatics and aggressive antics. Larger birds like turkey (Meleagris gallopavo) and sage grouse (Centrocercus urophasianus) would have been a welcome addition to prehistoric cooking pots.""]"	['<urn:uuid:b9dfd797-7271-4e25-9a1d-21cd8b758525>']	open-ended	with-premise	long-search-query	similar-to-document	single-doc	novice	2025-05-01T22:36:12.692263	13	63	684
188	How does competition work in the Tomiki aikido system?	In Tomiki aikido matches, one opponent is armed with a mock knife while the other acts as defender. The roles are reversed after a specified time and points are tallied to determine the winner. The system also includes kata competition.	['Aikido Journal #102, 1995\n“I seriously doubt that the would-be “samurai” of the twentieth century will find a satisfactory solution to their quest for ultimate combative effectiveness through martial arts competition.”\nThe martial art of akido has enjoyed a steady growth since its quiet introduction in Japan following World War II and subsequent spread abroad. While the art has earned much respect for its ethical tenets, the techniques of aikido are often criticized as being too soft and impractical to be of any real use in an actual engagement. I have frequently added my voice to this chorus and maintain that the casual nature of practice in many schools today leaves students with unrealistic expectations of what they can expect to accomplish if their skills should ever be tested in a real-life encounter. I still believe that practice against lifeless, “ceremonial” attacks without the application of atemi and convincing finishing techniques leaves one highly vulnerable in a life-threatening situation.\nThis having been said, how specifically to go about adding a strong element of “realism” to aikido is altogether another question. Various improvements have been proposed such as teaching attacking skills, incorporating liberal use of atemi, adding self-defense techniques, etc., all with the aim of making up for aikido’s perceived technical deficiencies.\nAnother of the most frequently advocated solutions to this thorny issue is the introduction of competition to add a realistic dimension and provide a quantifiable way of measuring one’s skills against an opponent. The argument is often framed in such a way that the measure of a martial system is based on how exponents fare, or presumably would fare, in a match situation. For example, who would come out on top if fifth dans in judo and karate were to match skills? Is taekwondo superior to kung fu? Can an aikidoka with no cross-training in another art hold his own against an exponent of any of these more combat-oriented martial arts? Such speculation is endless and has failed to lead to any sort of consensus.\nThe most prominent example of the concept of competition applied to aikido has been the Tomiki system, which was philosophically inspired by the thinking of Jigoro Kano, the founder of judo. Kenji Tomiki, a prewar disciple of both Kano and Morihei Ueshiba and a successful judo competitor in his own right, devised a sport system of aikido which was launched via the aikido club of Waseda University in the 1950s. Matches in this style consist of one opponent armed with a mock knife while the other acts as the defender. The roles are reversed after a specified time and points are tallied to determine the winner. In addition to matches, this system of sport aikido includes kata competition. Tomiki Sensei experimented with various modifications to his system and, since his death in 1979, his senior students have carried on under the banner of the Japan Aikido Association, There are perhaps one hundred or so schools and clubs that follow the Tomiki system worldwide. The results of this continuing experiment with competitive aikido have been mixed, and even within this system there are those who prefer to emphasize more traditional practice methods and forego matches altogether. The Tomiki method has come under attack from proponents of other aikido schools who hold that the principle of competition itself runs counter to the central principles of aikido. Because of this fact, Tomiki Aikido remains to a certain extent isolated from more mainstream approaches.\nTwo other widely-practiced styles of aikido have embraced competition, albeit to a limited degree, in conjunction with demonstrations. Both the Yoshinkan Aikido and Shinshin Toitsu Aikido organizations conduct demonstrations where participants are graded on their performance, based on the execution of technique, balance, ability to blend, and other such criteria. Winners receive awards at the end of the event much as in other sports. The sort of “friendly competition” this approach has spawned seems to encourage performers to intensify their practice at least in preparation for these events, My impression is that aikido purists who frown at the Tomiki approach are not particularly concerned by these forays into competition by the Yoshinkan and Ki Society since neither conducts matches or bouts that pit two opponents against each other. I doubt very much, however, that this sort of performance competition by itself will be enough to satisfy those who call for training reforms designed to give aikido techniques “teeth” so as to render them effective in a realistic selfdefense situation.\nStill another attempt to restore an “aiki budo-like” dimension to aikido through the introduction of competition has been recently launched by Fumio Sakurai. In the view of Sakurai, a former Yoshinkan Aikido shihan, aikido should rediscover its roots and be practiced with vigor as it was in the prewar days. He recalls the rigorous training undergone by his teacher, the late Gozo Shioda, in the “Hell Dojo” of aikido founder Morihei Ueshiba in the 1930s. In an effort to achieve this goal, Sakurai has begun experimentation with a new form of competition in which two opponents square off in an empty-handed match. Each competitor dons protective padding covering the knees, shins, and feet, and kicking is allowed. Punches are, however, prohibited as are attacks to the face, kicks to the outside of the knee, attacks to the groin, and various other dangerous moves.\nI recently attended the inaugural tournament of Sakurai-ryu Aikido, as this new approach to aikido has come to be called, held on September 15. Sixteen competitors participated in this intraclub tournament and, with one or two exceptions, there were no aikidoka with tournament experience. Most of the attacks were very tentative since atemi were not permitted, and those who fared the best succeeded in closing the distance with their opponents to score points. I saw only one or two clean “aikido-like” techniques, one a kotegaeshi and the other an armbar. The winner in the heavyweight division was the largest, most muscular and well-trained athlete of the lot. However, he sustained an injury during the tournament that afterward kept him sidelined for several weeks.\nThe challenge for Tomiki advocates and people like Sakurai Sensei who favor competition is how to preserve the essential attributes of aikido—taijutsu system with specific ethical principles—while devising a sport that is both safe and interesting to spectators. What if the rules and nature of competition itself do not encourage the execution of aikido techniques? How does one avoid having the objective of “victory above all”—clearly the antithesis of Morihei Ueshiba’s vision—becoming the participants’ main inducement to compete as in so many other sports? If these conditions are not satisfied by these fledgling sports, then what is the justification for calling them “aikido?”\nAs a result of our promotion of Sakurai Sensei’s activities in the Japanese-language Aiki News, I have been recently invited to attend two fighting tournaments that featured exponents of the popular Gracie Jujutsu system. In the first tournament, Rickson Gracie won his three matches effortlessly by forcing his larger opponents to the ground and applying a decisive choke. Everything was over in a matter of seconds. This is the trademark of this unique system, which has gained a widespread and much-deserved reputation for its effectiveness under match conditions.\nWhat impressed me most was the ease with which Rickson downed his adversaries and how his victories resulted in no injury to either his opponent or himself. That should grab your attention! Two of the winners of other bouts managed to break their hands in the process and their victories were rather bloody and artless by comparison. Gracie Jujutsu will surely be of interest to many aikidoka because of its humane approach and effectiveness in certain combat scenarios. The top exponents of this system are experts in grappling and knowledge of this skill would be very complementary to any martial art. Parenthetically, we will have an interview with one of the Gracie brothers in the near future and will do our best to present in detail this innovative martial system.\nThe opportunity to attend these matches was a real revelation for me coming as I do from the aikido world. With the exception of Rickson Gracie’s bouts, I found most of the matches to be animalistic and, quite frankly, repulsive. It occurred to me that competitors are required to develop a particular mindset in order to do well in such tournaments, Such fighters must learn to be aggressive and ruthless, and attempt to exploit the rules fully to achieve victory. I doubt that such character traits can be easily switched on and off. I also wonder if these attitudes, deeply ingrained as they are through rigorous training, might not come to dominate an athlete’s personality and prove a liability in personal interactions. I felt that the controlled, harmonious nature of aikido practice—even though it might not prepare one for tournament fighting—is much preferable to these other dog-eat-dog fighting styles from the standpoint of learning to live peacefully in society.\nI also noted that these athletes, many of whom are or aspire to become professionals, live in constant fear of injury. It was obvious in several matches that certain defensive maneuvers were designed to protect a vital part of the body from attack. Although fatal injuries might be infrequent in these tournaments, the accumulation of physical punishment over a period of time can leave a person with serious medical problems, disabilities, not to mention losing one’s means of livelihood. Shades of boxing and football!\nSeeing these tournaments set my mind thinking along lines I had not explored previously. I asked myself, for example, did the victors in these matches demonstrate an ability to overcome an opponent in a “realistic” situation by besting their rivals in the ring? Surely, there were skilled martial artists in the competition. However, even though the first bouts I saw were billed as “no-holds-barred,” still the opponents fought within the confines of a ring. There was a single opponent, no element of surprise was involved, and naturally no concealed weapons or firearms figured in the fights. So though it was an “anything-goes” situation as far as fighting matches are concerned, the conditions were far removed from reality.\nEven the marvelous skills displayed by Rickson Gracie provide no clue as to how he would handle a “real” situation against multiple attackers who are more than likely to be armed. Obviously his chances could be considered superior to those of an untrained person, but a confrontation involving firearms—the scenario most feared by the average citizen—is an altogether different matter both tactically and psychologically speaking.\nTo sum up my thoughts on this issue, I seriously doubt that the would-be “samurai” of the twentieth century will find a satisfactory solution to their quest for ultimate combative effectiveness through martial arts competition. I believe rather that the skills required to become a peerless warrior in a modern society are far different from those of the earlier and simpler times in which these arts were developed. Today’s warriors are people like the police and elite military instructors who contribute to the “Coping with Violence” section of Aikido Journal. These dedicated individuals have vast knowledge of the many manifestations of violent behavior and what to do about it. They bring to their jobs a detailed understanding of weapons, tactics, and psychology. They are men who have looked death in the face on numerous occasions and who cannot afford to relax their alertness for even a moment in the fulfillment of their duties.\nAikido’s main contribution to the enrichment of individual lives lies not in the mechanics of techniques but rather in its ability to transform and elevate spirits beyond the plane of dualistic thinking. I genuinely believe that those seeking “the ultimate fighting system” are destined to forever pursue an illusion.\nMembers please log in here to continue…\nAlready a member? Login below…']	['<urn:uuid:9a37c75e-4fdd-4702-8237-aa2cb02b6eda>']	factoid	direct	concise-and-natural	similar-to-document	single-doc	expert	2025-05-01T22:36:12.692263	9	40	1971
189	How does heat affect clay drying and workplace lung risks?	Heat plays a dual role - in clay work, it helps air dry clay cure over 2-3 days until pieces are no longer cool to touch, while in industrial settings, high-heat operations like welding and furnace work increase lung disease risks by producing dangerous fumes and gases.	"['How to Glaze Air Dry Clay and Make Trinket Dishes\nTHESE ARE SO CUTE!!! Maybe you’ve seen trinket dishes on Etsy and thought they would make good little gifts. Maybe you’ve thought about making them but you don’t have a kiln. You can still try making these little dishes at home with air-dry clay. This tutorial will show you some simple hand-building techniques that make it easy to create these little bowls. These are all techniques I learned in my traditional ceramics courses. And to make this SUPER EASY I have a printable template that will help you make shaped trinket dishes that will help your projects stand out. I also cover what I use to glaze my Air Dry Clay pieces to make them as similar to traditional ceramics as air dry can be.\nYes, I Have YouTube Videos on How to Make Shaped Trinket Dishes AND How to Glaze Air Dry Clay\nI’ve decided that videos are totally the way to go for tutorial posts. In this post I actually have TWO videos for you. The first video in this post will show you what clay to use, how to use it, and all the tips and tricks to make trinket dishes with air-dry clay. The second shows you what glaze to use and demo’s glazing the trinket dishes. I hope you’ll watch both! And then keep reading below the videos for a supplies list, and a free printable template!\nProject: How to Make Trinket Dishes with Air-Dry Clay and Glaze them!\nI’m going to be demonstrating three different types of trinket dishes. The first two we’ll use a cookie cutter to get the shape we want. The third dish, a cloud-shaped trinket dish, uses a template that you can download from my Creativity Resource Library. Just print it out and then cut it out, and you’ll have a shape to trace into the clay.\nThen I’ll show you how to use stamps to add pattern and texture to the clay. And to finish, I’ll let you know what glaze will give you the look of traditional ceramics and how to apply it. Yay!\nWhat Air Dry Clay Should I Use?\nMy goal was to find a clay that worked, looked, and felt as much as possible like kiln-fired ceramics.\nOf the clays I tried, the Crayola Air Dry Clay was also the one that I felt met these criteria the best*. It also looked the most like traditional ceramics once it was glazed.\nFor this tutorial, we’ll be using the Crayola Air Dry Clay. It’s a non-toxic clay that behaves a lot like regular potters clay. It is an air-dry clay (no oven needed) and takes 2 to 3 days to fully cure depending on the thickness of your project. It also dries to a really nice white color and has a weight similar to regular kiln-fired ceramics.\nMy biggest problem with some of the other air-dry clays I’ve tried was that it didn’t feel like clay once it was dried. One I tested felt spongy (Model Magic) and one (Primo Porcelain) felt plastic and dried a little translucent. I use porcelain clay all the time at the art center and this was nothing like it!\n- I did not try all of the air-dry clay on the market though, so if you have an air-dry clay that you love please leave it in the comments!\nWhat Glaze Should I Use?\nOf all the different glazes I tried I really like the Triple Thick by DecoArt best. It didn’t feel rubbery, although it didn’t feel as hard as a baked piece.\nHow to Make Trinket Dishes from Air-Dry Clay\nSupplies and Materials\nAir Dry Clay Template- a FREE download from my Free Creative Resource Library.\nCrayola Air Dry Clay (white)– I really like this clay the best from those that I tried. I have the Amazon link for your convenience, but you can easily find this at the craft store (and use a coupon).\nCanvas Duck Cloth *\nWater in a Small Dish\nCookie Cutter Set\nNeedle Tool (if you get one of the sets below this is included)\nCling or Rubber Stamps *- I use the circle from this Tim Holtz Bitty Grunge Set\nTriple Thick Glaze by DecoArt\nNon-Stick Craft Mat *\nClay Slump Molds*– You can use items around the house or a small bowl, I use my Fiestaware Salt Shaker because it’s rounded just right.\nThis page includes affiliate links- which means that you don’t pay extra, but I get a small commission when you purchase through them. This helps me buy more supplies for these tutorials! So if you choose to support me in this way, thank you!\nStep One: Prep the air dry clay.\nGrab a handful of clay, roll it and pat it, and set it aside to dry just a bit. When the clay first comes out of the container it’s pretty sticky and tacky and difficult to use. So I usually pull a few handfuls out of the container and roll them into a ball and then pat them a little flat (so there is more surface area exposed to the air). Just until it’s not super sticky feeling anymore.\nMake sure that you put the cover on the container again so the clay in it doesn’t start to dry as well.\nStep Two: Roll out the air dry clay on canvas fabric.\nWhen I work at the art center near my home every hand-building table is covered with canvas duck cloth. I took that trick home with me and now at home, I have a small piece of utility fabric or canvas duck cloth that I lay out on the table. The clay doesn’t stick to it and I can fold it up when I’m done working. Instant clean up! I just take it outside and shake the clay dust and bits into the garbage.\nWhen you roll out the clay use a regular wooden rolling pin that you’ve specifically designated just for ceramics projects (that means don’t use it for cookies after this). Even though the clay is non-toxic it’s just a good idea to keep your art and baking tools separate.\nRoll out the clay and from different directions. Roll evenly, until it is about 1/4″ thick. If you need to start over, just ball it up and then roll it out again. If there are a lot of cracks in the shape ball it up a bit more compressing it in your hands or on the table as you do so. This is called wedging the clay. You’re removing air pockets and creating a more solid slab to work with. Then roll it out again. Some small cracks don’t matter though so don’t get all perfectionist about this.\nStep Three: Cut out the shapes.\nTo cut the clay into shapes you can try using a cookie cutter, cut it freehand with a needle tool, or use a template and cut around it with a needle tool. In the video, I’m using a heart-shaped and round cookie cutters for two of the bowls. For the third shape I’m using the cloud template you can find on the Air Dry Clay Project Templates that is a free download in my Creative Resource Library.\nThe template technique is so easy and you can create your own templates in any shape you want. Just cut it out and set it on the clay. Then, using a potters needle tool cut around the template. Hold the needle tool straight up and down and just drag it around the template. Stopping occasionally if the clay is pulling or dragging too much. Pick it up, and then start again. It’s easy once you’ve tried it.\nOne thing to notice is that the cut edge when we use the needle tool is a lot rougher than it is with the cookie cutters. But even the cookie cutters leave a definite hard cut look to the edge. Traditional ceramics have a more rounded edge.\nTo get that look, just dip your fingers in the small bowl of water and with just a small amount of water gently go around the edges smoothing them with your fingers. Once you’ve done this the clay will be tacky again.\nI usually set it aside to dry for 10-15 minutes or until it feels less tacky. You can tell the clay is ready to work again when you touch it with your finger and you don’t leave a fingerprint on the clays’ surface.\nStep Four: Add a pattern to the clay’s surface.\nThis is my favorite part. I love texture! And with clay, it is so easy to get tons of awesome patterned texture layered into your surface.\nTo do this you can choose to use stamps, found objects, textiles, and really anything that can be pressed into the clay. You can also choose to draw into the clay with a blunt object once it’s hardened.\nThis is a great place to use many of the same stamps and texture techniques you use in mixed media art and scrapbooking. Or you can create your own rubber stamps and use those! I even have a video showing how easy it is to create your own rubber stamps. In the video, I used a rainbow stamp (that I show you how to carve in my rubber stamp video) to embellish the clay cloud trinket bowl.\nThe single most important thing to be aware of when stamping or adding texture to clay is to make sure that the clay is not too wet.\nAgain, if I was to touch it with my fingertip and see my fingerprints, then it’s not ready yet. Just let it dry a little bit longer, maybe another 10 minutes, until you can touch it and it’s not tacky. Then press your stamp or texture evenly into the clay surface.\nPro-Tip: To get the most professional look when using stamps, use a little bit of water and smooth out any outline impression that is not part of your actual design.\nStep Five: Mold the clay into the shape of a small bowl or trinket dish.\nWith your hands gently bend the shape up around the edges. Make small gentle movements and go around the shape several times. Using force and creating a sharp bend will probably crack the clay. This works best when the clay isn’t super wet but isn’t dried yet either. So pick it up and test the clay. If it’s too hard, mist it with some water. If it’s too wet, let it sit and air dry a little longer.\nThe other way to create a rounded shape is to slump it over a mold. Examples of molds would be another bowl or something else that has the shape you’re looking for in your own piece. I often use a small dish or a Fiestaware salt shaker that are perfectly shaped for these small round dishes.\nPro tip: If you feel like the clay is sticking to the form you’re using for a mold, you can place a paper towel or a thin paper between the clay and the mold to keep them separate.\nRemove the dish from the mold right away and set it right side up to dry. Let it dry. After 20-30 min. check it to make sure it hasn’t relaxed and lost its shape.\nIf that has happened, you can just use your fingers to gently bend the edges up again and reestablish the shape you want.\nStep Six: Let Dry.\nLet your bowls dry for 2-3 days. Until they are a solid white color and no longer cool to the touch. As the water evaporates from the clay and it dries, the condensation of the water as it evaporates creates a cool feeling. So those are two ways you can know your piece is ready to be painted and or glazed.\nStep Seven: Little Finishing Details.\nEven at this stage, you can still go over the piece once more, and use a little water to smooth the edges or any unwanted marks. If you do choose to do this, then make sure your piece dries again before you go on to step number eight.\nPro tip: Smoothing and shaping is a simple thing to do and really makes your pieces look more professional. Details matter and help your products look professionally handmade, not homemade!\nStep Eight: Glaze the small clay dishes.\nTime to glaze your pieces! Use a foam brush or reg. brush with soft bristles to apply the glaze. I used the Triple Thick Glaze by Decoart (the link is in the supplies list). Load the brush with a generous amount of glaze. Try to use as few brushstrokes as possible and try to apply as evenly as possible. This glaze does want to pool and drip when you apply it this thickly. So just be aware of that and check for drips. If you see them on the edges use your brush to gently wipe them back.\nDo not glaze the very bottoms. The glaze will want to pull away from the clay and bond to whatever you set it on instead. Set aside the little dishes (preferably on a non-stick craft mat or the canvas duck fabric) to dry for 2- 3 days depending on the thickness of your pieces.\nAnd voila! How to Make Trinket Dishes with Air-Dry Clay\nOne word of warning, glazing these bowls does not make them food safe. As far as I know, there is no acrylic based glaze that can do this.\nCheck out my OTHER Air Dry Clay post, How to Sculpt Air Dry Clay Trinket Dishes and learn simple techniques for crafting more shaped dishes of air dry clay!\nFor More Ideas and Inspiration!\nBe sure to check out my Air Dry Clay Board on Pinterest– it’s loaded with ideas and tutorials from other blogs as well as enough examples of what’s possible to make your head swirl!\nAnd if you would like to know more about the Crayola brand of air dry clay check out the Crayola Air Dry Clay product page!\nLove this? Share it!\nIf you found this tutorial helpful please pin the image below or like, comment, or subscribe to my YouTube channel. AND if you could pin the image below that would be ah-maz-in! Thanks for your help!', 'Who is at risk for work-related lung disease?\nYou may be at risk for work-related lung disease if the air you breathe at work contains an excessive amount of dust, fumes, smoke, gases, vapors or mists. Workers who smoke are at a much greater risk of lung disease if they are exposed to substances in the workplace that can cause lung disease. Poor ventilation, closed-in working areas and heat increase the risk of disease. Outside air pollution also can increase the risk of lung disease in people who work in jobs that expose them to substances that can cause lung disease.\nWhat substances in the workplace can cause lung disease?\nMany substances found in the workplace can cause breathing problems or lung damage. Some of them include the following:\n- Dust from such things as wood, cotton, coal, asbestos, silica and talc. Dust from cereal grains, coffee, pesticides, drug or enzyme powders, metals and fiberglass can also hurt your lungs.\n- Fumes from metals that are heated and cooled quickly. This process results in fine, solid particles being carried in the air. Examples of jobs that involve exposure to fumes from metals and other substances that are heated and cooled quickly include welding, smelting, furnace work, pottery making, plastics manufacture and rubber operations.\n- Smoke from burning organic materials. Smoke can contain a variety of particles, gases and vapors, depending on what substance is being burned. Firefighters are at an increased risk.\n- Gases such as formaldehyde, ammonia, chlorine, sulfur dioxide, ozone and nitrogen oxides. These are associated with jobs where chemical reactions occur and in jobs with high heat operations, such as welding, brazing, smelting, oven drying and furnace work.\n- Vapors, which are a form of gas given off by all liquids. Vapors, such as those given off by solvents, usually irritate the nose and throat first, before they affect the lungs.\n- Mists or sprays from paints, lacquers (such as varnish), hair spray, pesticides, cleaning products, acids, oils and solvents (such as turpentine).\nWhat kinds of breathing problems can occur following exposure to such substances?\nSome substances can cause you to have upper respiratory irritation or irritation of your nose and/or throat with cold-like symptoms, such as a runny nose and scratchy throat.\nViral infections and allergies produce similar symptoms. You should become suspicious of a work-related illness if your nose and throat are often irritated and breathing problems seem to occur when you are at work. Breathing in substances at work can also increase your risk of developing bronchitis, flu-like symptoms, asthma or emphysema.\nA person who has bronchitis has a persistent cough that produces mucus or sputum and lasts at least 3 months to a year. Cigarette smoking is the most common cause of bronchitis, but workplace toxins can also play a role.\nIf you notice that you often have what seems to be the flu, your illness may be caused by something you are exposed to at work. The following are some work-related lung diseases that can make you feel as though you have the flu:\n- Allergic alveolitis (also known as ""farmer\'s lung"") can occur after excessive exposure to moldy hay.\n- Metal fume fever occurs from inhalation of metal vapors, such as in welding and other metallic operations.\n- Polymer fume fever can occur after breathing the fumes of polymers, such as Teflon.\nA worker who has one of these conditions develops breathing problems, cough, fever, muscle aches and general malaise (a feeling of being tired and having no energy) 4 to 6 hours after exposure to the substance. If such symptoms occur again and again when you are at work, this is a clue that your illness may be related to your work.\nIf you develop asthma for the first time as an adult, the illness could be related to something you are exposed to at work. Asthma symptoms include wheezing, chest tightness, a persistent dry cough or trouble breathing.\nEmphysema usually occurs in older people who smoke. However, people who have worked with coal, asbestos or silica dust for 20 years or more can also develop emphysema. They may have a cough, fatigue, chest tightness and difficulty breathing.\nWhat should I do if I think something in the air at work is making me sick?\nVisit your doctor if you think the air at work is making you sick. Your doctor will probably ask you to provide some of the following information:\n- When your symptoms first appeared\n- How often you have symptoms\n- The time of day that the symptoms are worse\n- Whether you feel better on some days\n- How you think your symptoms relate to work\n- What types of materials you come in contact with at work\nYou may find it helpful to keep a written record of these things to share with your doctor. Be sure to make a note of your shift or work hours, the days of the week you work and the days of the week you are off work. Try to recall previous jobs, hobbies and smoking habits -- anything that might have affected your lungs. If your doctor has sent you an occupational health history form, fill it out as completely as possible.\nYour doctor may find it helpful to know all of the ingredients listed on the containers of materials you use in the workplace. Make a list of these ingredients and write down any precautions and first-aid measures that are printed on the label.\nAsk your employer for copies of the material safety data sheets (MSDSs) at your workplace. These are information sheets about the products that you use in the workplace. All employers are required by law to complete these forms, and you have a right to see them. Bring them with you to your doctor\'s appointment.\nHow can I keep from having my lungs damaged by something I\'m exposed to at work?\nIf you smoke, stop. This is the most important thing you can do for your overall health, regardless of risks at your workplace. Smokers have a greater risk of developing some work-related lung diseases than nonsmokers.\nUse a respirator. A respirator is a device you wear over your mouth and nose that cleans the air before it enters your body. You must be properly fitted and trained to use a respirator. Over time you should be refitted and retrained in how to use it. The respirator must be carefully cleaned after each use and it should be checked to ensure that it works properly. Use a respirator as a temporary measure until you are no longer exposed to the damaging substance.\nIf you are exposed to damaging substances at work, talk to your supervisor about the need for adequate ventilation and new procedures to reduce or eliminate your exposure. A change in ingredients, work practices or machinery can reduce hazards in the air. Ventilation systems can remove pollutants and toxins from the air to reduce exposure and prevent buildup. Local exhaust ventilation can be used to remove polluted air at the point where it is generated by a hazardous process or machine. At some jobs, people can be separated from the hazardous materials.\nWritten by familydoctor.org editorial staff']"	['<urn:uuid:ea3b090c-362c-4b76-b66c-26b28d6db28f>', '<urn:uuid:e2b1daf7-dea9-4f15-b153-2a00db2732a7>']	factoid	direct	concise-and-natural	similar-to-document	multi-aspect	expert	2025-05-01T22:36:12.692263	10	47	3612
190	How do places like Point Pelee and Cape Race function as natural bird sanctuaries, and what environmental concerns arise from artificial lighting in these wildlife areas?	Places like Point Pelee, Ontario and Cape Race, Newfoundland function as natural sanctuaries by providing essential rest stops for migrating birds. Cape Race, for example, offers shelter through its tuckamoor (stunted spruce trees) and man-made structures, where vagrant birds can find protection from harsh Atlantic winds. However, artificial lighting in these areas poses significant environmental concerns. The International Dark Sky Association reports that 30% of outdoor lighting in the U.S. is wasted, leading to approximately $3.0 billion in energy costs and 15 million tons of carbon dioxide emissions annually. This light pollution creates sky glow that interferes with birds' natural navigation abilities and disrupts the sustainable rhythm of the ecosystem, affecting not just birds but entire biological communities of interacting organisms.	"['As I\'ve stated in earlier posts choosing a time and location to go birding is often not a random decision. For many experienced birders, there is much forethought,analysis and planning behind the scenes prior to any birding trip,especially in times of heavy bird migration migration. This is especially true for regions such as Point Pelee,Ontario, High Island ,Texas, Cape May,New Jersey and various other hotspots.\nThese locations are often referred to as \'migrant traps"". A migrant trap is a strategically situated piece of land, often an island or Peninsula. It could also be a particularly luch area in a very arid region, or a heavily wooded sector in a heavily urbanized area,such as Central Park in New York City. Migrant trap don\'t actually trap birds of course,but they act as a falling out point for birds that might be stressed after a long migration.They are appealing because they are the first point of land available to tireed migrants or because they have some ecological component that makse them superior to the surrounding environment.\nFor us in Newfoundland we are often at the end of a birds migratory route, we get very few transients other than late summer and fall shorebirds. In short, if your a bird that makes it this far to the north east, you don\'t intend on going any further, and even if you did,where would you go? We do however have a few locations that have proven to have the ability to concentrate birds after the appropriate weather conditions and Cape Race is one such area.\nCape Race is the most south easterly point of land in Newfoundland. The Cape itself is a barren area,with a few buildings,tundra and some short grassy areas. There aren\'t any trees at the Cape itself so vagrants settle in the grass and are often found sheltering around man made structures- under steps,parked cars anything that provides shelter. Cape Race is situated at the end of an approximately 20km dirt road that trails along the coast from the community of Portugal Cove South. Along this road there again is little cover aside from scatted patches of stunted spruce,referred to locally as tuckamoor. The tuckamoor and various parts of the road has shown a remarkable ability to hold vagrant songbirds. It consists of extremely dense,often tangled spruce tress that have been battered for perhaps a decades or perhaps even hundreds of years by the often fierce and unrelenting winds,blowing off the northern Atlantic Ocean. At first glance, this habitat doesn\'t look like much,but imagine your a tiny 6 once bird that has just flown 1000 km\'s during a storm out over the Atlantic, in 80km winds and it starts to look exponentially more appealing!\nSo,why am I even talking about all of this? Well, I\'ve been looking at the upcoming weather maps for the next couple of days and they\'re looking really really good for potentially bringing a pile of birds to the southern Avalon Peninsula. It has only been two weeks since the last fallout at Cape Race,which brought Cattle Egret, Hooded Warbler, Scarlet Tanager and a pile of Thrushes. This next system looks every bit as good as that one to me and shares a lot of features as the previous system. Looking below you can see the system I\'m talking about.\nSaturday May 8th- Notice the system centered around the Great Lakes Region\nSunday May 9th- System is further east and generating winds from the SW dirctly to the Avalon Peninsula.\nMonday, May 10th. A continuation from the previous day,still giving S winds to the southern Avalon Peninsula\nNotice the movement of the low pressure system from the Great Lakes to the Maritimes. Notice especially, how the isobars(lines on the map) in the maps for Sunday and Monday are tightly packed(indicating strong winds)blowing out over the Atlantic Ocean and straight to southern Newfoundland( the winds flow parallel to the isobars.) Now look back at the weather maps from the Cape Race fallout a couple of weeks ago and notice the similarities. This low pressure system actually originated in the Midwest near the Texas panhandle then started to rapidly move to the North East.As well, system happens to coincide with the main migration of warblers into the Great Lakes and the NE US.\nIf things play out like just right,there could be some legendary birding coming our way in the next few days. if you have sick days banked I\'d suggest you use them. Make sure you have a full tank of gas and have your bins and camera within reach.Good birding and stay tuned!', 'In the previous section, we have identified the ABCs of outdoor lighting and cautioned that the careless utilization of artificial lighting results in light pollution. In this section, the GLDS wants to outline the three steps essential to reduce light pollution and create a Dark Sky environment. They are as follows:\n- Human-Made Light Pollution Components\n- The Byproducts of Light Pollution\n- Light Pollution Solutions\nHuman-Made Light Pollution Components\n- Glare – Strong, luminous light that results in excessive brightness that causes visual discomfort.\n- Clutter – Groupings of light sources that emit excessive glare. Clutter contributes to light trespass.\n- Light Trespass – Light, individual or a cluster, that crosses over from one property or parcel of land onto another in a built-up/populated area.\n- Sky Glow – The proliferation of clutter and light trespass in a built-up/populated area that produces a luminous background that inhibits one’s ability to view the stars. Sky glow is highly variable on the amount of light being emitted upwards, immediate weather conditions and the quantity of air particles (dust and gas) in the immediate geographic area.\nThe Byproducts of Light Pollution\nFor hundreds of millennia, mankind experienced a natural night sky bursting with stars. It was an integral part of the day and night cycle of life. The natural dark sky enabled man to better understand its place in the universe. Consequently, it inspired science, religion, philosophy, literature and art. Artificial light that resulted in light pollution disruptive this natural cycle and had a negative impact in our world as follows: Wildlife and Ecosystems An ecosystem is a biological community of interacting organisms and their physical environment. Plants and animals are reliant on our planet’s daily cycle of light and dark to maintain its sustainable rhythm. The addition of light pollution at night disrupts the habitat. Some primary examples:\nNocturnal animals sleep during the day and become active at night in order to use the cover of darkness to escape their predators.\nWetland amphibians (e.g., frogs) rely on the nighttime for their reproductive activities.\nSpecies of birds migrate or hunt at night and use the natural light of the moon or stars to navigate.\nInsects are drawn to natural light, but the introduction of light pollution has been destructive to certain species.\nThe International Dark Sky Association estimates that 30 percent of all outdoor lighting (lighting that is not shielded) in the U.S. alone is wasted. This wasted energy has huge economic and environmental consequences – approximately $3.0 billion in energy costs per year and the release of an estimated 15 million tons of carbon dioxide (source: U.S. Department of Energy 2011).\nHealth & Well Being\nHumans sleep-wake pattern (a.k.a. biological clock) are controlled by the day-night cycle they are exposed to. Artificial light can disrupt that cycle. In medical terms, that cycle is known as a circadian rhythm. Our bodies produce a hormone (melatonin) which keeps us healthy – positive functioning of key organs, lower cholesterol, stronger immune system, etc. Exposure to artificial light at night, especially blue light according to a 2015 Harvard Medical Study http://www.health.harvard.edu/staying-healthy/blue-light-has-a-dark-side can be disruptive and suppresses our melatonin production.\nBrighter does not mean safer when it comes to outdoor lighting deterring crime or reducing accidents. Numerous published studies have found that increased streetlights do not prevent crime. In reality, too much outdoor lighting utilized to enhance safety and security at night increases overall energy costs and produces glare which actually impairs visibility since the pupils in our eyes constrict as a result.']"	['<urn:uuid:5ad9a3f7-7755-47f3-b430-1288a757bc9c>', '<urn:uuid:dcbed352-5387-49f3-ba02-779210d27c5b>']	open-ended	direct	verbose-and-natural	similar-to-document	multi-aspect	novice	2025-05-01T22:36:12.692263	26	121	1351
191	What makes belt conveyors versatile while also being dangerous?	Belt conveyors are versatile as they have high load carrying capacity up to 30000 t/h and can transport materials over large distances up to 3-4 km with simple design and easy maintenance. However, they are also dangerous, with over 80 serious or fatal accidents in the U.S. in recent decades, with 48% of accidents involving pulleys and 30% occurring during maintenance and cleaning operations.	"['Belt conveyor - SlideShare\nJan 17, 2016 · Belt conveyor 1. A Seminar on topic BELT CONVEYOR PRESENTED BY- ALOK KUMAR MISHRA DEPTT. OF MINING MACHINERY ENGG. 2. CONTENT Introduction Main elements of belt conveyor Aspects of belt conveyor design Working of belt conveyor Advantages of belt conveyor Disadvantages of belt conveyor Maintenance procedures Bibliography\nBelt Conveyor PowerPoint PPT Presentations - PowerShow\nBelt Conveyor Type is Estimated to Hold the Largest Conveyor System Market in Airport Industry - The belt conveyor type is expected to dominate the retail industry conveyor system market. Belt conveyors are made of one or more layers of material and run in an endless loop.\n(PPT) Conveyor Belt presentation | Ev Solomon - Academia.edu\nConveyor Belt GROUP F Name Matric No. Ameer Hafetz Bin Johar B041310319 Ammar Bukhari Bin Tajuddin B041110269 Evie Michelle Solomon B041210180 Koh Wen Kheng B041210153 Lau Shu May B041410025 Lily Syafiqah Binti Yusuf B041210233 Introduction Conveyor system is a mechanical system used in moving materials from one place to another.\nBelt Conveyor Systems Ppt - Video Results\nMore Belt Conveyor Systems Ppt videos\nPPT – Conveyor Belts PowerPoint presentation | free to ...\nFind here details of company selling and manufacturing conveyor belt. Get latest info on shetty eneterprisre - manufacturer, exporter and supplier of conveyor belt like pu conveyor belt, pvc conveyor belt in india – A free PowerPoint PPT presentation (displayed as a Flash slide show) on PowerShow.com - id: 8871a3-NzlhY\nBelt Conveyor Process for PowerPoint and Google Slides\nThis ‘Belt Conveyor Process for PowerPoint and Google Slides’ features: 2 unique slides; Light and Dark layout; Ready to use template with icons and text placeholders; Completely editable shapes; Uses a selection of editable PowerPoint icons; Standard (4:3) and Widescreen (16:9) aspect ratios; PPTX file and for Google Slides; Free fonts used:\nConveyor system ppt - SlideShare\nApr 19, 2017 · Conveyor system ppt. 1. o A conveyor system is a common piece of mechanical handling equipment that moves materials from one location to another. o Conveyors are especially useful in applications involving the transportation of heavy or bulky materials in industries. o Conveyers are also used in general material handling such as those moving boxes along inside a factory, such as agricultural materials, such as grain, salt, coal, ore, sand, overburden and more.\nConveyors - Safety Training PowerPoint Presentations\nConveyor Systems Guarding is the only way to make machines TRULY human friendly. 20 slides: Conveyor Systems - Guarding Contains fatal accident information from the past and general information about guarding. 16 slides: Don\'t Get Carried Away! Hazard alerts related to conveyors for Metal and Nonmetal. 71 slides: Guarding Belt Conveyors\nppt on convayor belt system - petrovandepas.nl\nBelt Conveyor - Free download as Powerpoint Presentation (.ppt), PDF File (.pdf), Text File (.txt) or view presentation slides online. DESIGN OF MATERIAL HANDLING EQUIPMENT: BELT … Conveyor Belt System - The conveyor belt that rotates about them.one or both pulleys are powered, moving the belt and the material on the belt forward.\nbelt conveyor systems ppt - michalcesek.cz\nbelt conveyor systems ppt. Our products includes five series: crusher, sand making machine, powder grinding mill, mineral processing equipment and building materials equipment.Our leading products have crushing equipment, sand making equipment, mobile crusher, etc., Each type of product is with complete specifications.\nintroduction to belt conveyor ppt - chalkandcork.co.za\nBelt Conveyor Powerpoint Ppt Presentations Powershow . Belt conveyor powerpoint ppt presentations all time show recommended sort by conveyor belt the conveyor belt is carrying medium of a belt conveyor system the conveyor belt system consists of two or more pulleys with an endless loop of carrying medium global conveyor belt. More Details. Get Price\nDesign of a Material Handling Equipment: Belt Conveyor System ...\nThe belt power (kW) is given as = effective tension (1.141 KN) V= Belt speed (1.25m/sec) P b = 1.43 kWBelt tension of a conveyor system is of a varying value along the system flight and is governed by the following influencing factors: length and track of the system, number and arrangement of pulley, characteristics of the driving and braking ...\nDESIGN OF MATERIAL HANDLING EQUIPMENT: BELT CONVEYOR SYSTEM ...\nof belt conveyor system for biomass wood using 3 rolls idlers, in terms of size, length, capacity and speed, roller diameter, power and tension, idler spacing, type of drive unit, diameter, location and arrangement of pulley, angle and axis of rotation, control mode, intended application, product\nCONVEYOR MAINTENANCE AND TROUBLE SHOOTING\nfor interlocking of conveyors and conveyor systems such that if one conveyor in a system or process is stopped other equipment feeding it, or following it can also be automatically stopped. Electrical controls, machinery guards, railings, walkways, arrangement of installation, training of personnel, etc., are necessary ingredients for a safe ...\nUnderstanding Conveyor Systems - Types, Applications and ...\nJan 22, 2021 · This article focuses on conveyor systems, exploring and defining the different types of conveyors. Additionally, it looks at the key factors which should be considered when determining the type of conveyor system best suited for a particular application.\nDesign and Fabrication of Pneumatic Conveyor System\nBelt conveyor system is the transportation of material from one location to another location. Belt conveyor has high load carrying capacity (up to 30000 t/h), large length of conveying path (up to 3-4 km), simple design, easy maintenance and high reliability of operation.\nConveyor Belts | McMaster-Carr\nUnlike traditional belt and roller conveyors that mainly move products, this plastic belting creates a hard, cut-resistant work surface— similar to a cutting board— that stands up to food-processing jobs, such as cutting, deboning, and shelling. It’s FDA compliant for direct contact with food.\nPpt On Belt Conveyors - ochsen-niederurnen.ch\nA conveyor belt is the carrying medium of a belt conveyor system (often shortened to belt conveyor) Belt conveyor is the most economical and efficient material handling equipment which can be implemented in the thermal power plant for coal handling Belt conveyors  are the most. conveyor belts and its types ppt . get price\nConveyor System & Safety | Belt (Mechanical) | Manufactured Goods\nConveyor System & Safety - Free download as Powerpoint Presentation (.ppt), PDF File (.pdf), Text File (.txt) or view presentation slides online. conveyor safety system\nbelt conveyor system ppt - klimaatchaos.be\n12805 belt conveyor system ppt . Conveyor belts represent a high risk, because they have the ability to spread a fire over long distances. Fires on belt conveyors are mostly ignited by mechanical failures like frozen idlers, which is even more dangerous in combination with coal dust.\ncema belt conveyor design and calculation ppt\nPpt Presentation Slides For Conveyors System. belt conveyors presentations pptConveyor Belt Design Ppt Presentationbelt conveyor system pptThe conveyor belt design can be determined by both the function it is intended to perform and theppt of belt conveyerConveyor Transition Effect in PowerPointYouTube support Online\nppt on belt conveyor - petrovandepas.nl\nBelt Conveyor Ppt - Manufacturers, Factory, Suppliers From China We preserve enhancing and perfecting our goods and service. At the same time, we operate actively to do research and growth for Miniature Conveyor Chain, Belt Conveyor Systems Design, Vegetable Conveyor Belt, With a wide range, top quality, acceptable charges and great ...\nDesign Of Belt Conveyor System For Material Handling Ppt\nBelt conveyor working ppt - hoftermoubeke.Be.Belt conveyor working ppt - gent1913-1918.Be.Belt conveyor working ppt.Design of material handling equipment belt of belt conveyor system for biomass wood using 3 rolls idlers, in terms of size, length, capacity and speed, roller diameter, power and tension, idler spacing, type of drive unit ...\nBelt Conveyor - an overview | ScienceDirect Topics\nBelt conveyors are the most widely used and versatile mode of mechanical conveying systems employed to transport materials horizontally or on an inclined either up or down. Fig. 10.1 , represents a typical belt-conveyor arrangement, with the following main components of the system:\nOverland Conveyor Systems - Alaska Department of Natural ...\nSystems Rick Fredericksen Mining Section Chief Division of Mining, Land and Water April 10, 2009. Bu Craa, Morocco ... Microsoft PowerPoint - Conveyor Systems.ppt\nConveyor Systems - ERIKS North America\nIn North America we have about 45 conveying system service teams and over 20 service locations in the U.S. and Canada that are fully equipped to mobilize and respond to your conveying system needs. Our crews are skilled in installation, troubleshooting and preventative maintenance and respond to customers’ needs 24/7, 365 days a year.\nFlat Conveyor Belt PowerPoint Template - SlideModel\nA belt conveyor system consists of two or more drums, with an endless loop of carrying medium—the conveyor belt—that rotates about them. This system was popularized by the industrial revolution and powered the growth of economies systemizing the production of goods. The template contains a PowerPoint slide with icons.\nLecture Belt Conveyor Calculations Ppt\n6000 tph on each 72"" Belt Conveyor @ 1020 fpm with a 2000 HP Drive 5445 mtph on each ... lecture belt conveyor calculations, ppt » engineering belt conveyor... Continue Reading → Conveyors / Mining Conveyors | kmg.agh.edu.pl\nand on equipment conveyors. PN belting comprises the vast majority of plied fabric belting in service and is referred to throughout this handbook. For information advice on other belting types consult FENNER DUNLOP. 1 - 2\nBelt Conveyor Systems | Conveyor Belt Types | Ultimation\nWhat is a belt conveyor system? Belt Conveyor systems are the most versatile and simplest material handling systems. They work with two or more pulleys driving an endless loop belt. The loop then moves a product from Point A to Point B on the belt. We use belts made from fabric or rubber.', 'Conveyor belt systems have been responsible for over 80 serious or fatal accidents in the U.S. over the last 20 or so years. According to a report featured by the American Society of Safety Engineers, a disproportionate number of conveyor related accidents involve a specific component of the system; the pulleys. Roughly 48% of accidents are reported to involve pulleys. Understanding where they are and what function they perform in a particular system can go a long way to ensure that personnel remain safe during normal operation, maintenance, and cleaning, during which 30% of accidents occur.\nTypes of Conveyor Belt Systems\nGravity-driven conveyors have no mechanical or electrical power source. The momentum of the product and the force of gravity move product along these conveyors.\nGravity Wheel Conveyor – The gravity wheel conveyor is a skate wheel gravity flow system. Both curved and straight sections are used in this system. This type of conveyor uses a pattern of free turning wheels as the conveying surface.\nGravity Roller Conveyor – The gravity roller conveyor is a roller-to-roller gravity flow system. These are light-load conveyors used for handling product. The conveyor beds are comprised of two side channels which support free turning rollers.\nThere are many different types of flat belt conveyors used to move product throughout the distribution center. The four most common types of flat belt conveyors are the slider bed, belt-on-roller, meter belt, and brake.\nSlider Bed Conveyor – Slider bed conveyors operate by pulling a belt over the top surface of a box channel bed. Product is carried directly on the belt surface. Fixed speed center drives and fixed speed end drives are used to drive the slider bed conveyor. Center drives can be used for one or two-way operation, while end drives are designed for one-way operation only. Slider bed conveyors are usable in incline, decline, or horizontal applications. Slider bed conveyors are adaptable for use with many other types of powered and gravity conveyors.\nBelt-On-Roller Conveyor – Belt-on-roller conveyors carry products directly on the belt. The belt rides on the surface of carrier rollers mounted in the bed. Center drive units can be used in one or two-way operation, and end drive units are suitable for one-way operation only. Belt-on-roller units can be used for incline, decline, or horizontal operations. They can be used in conjunction with many other powered or gravity conveyors.\nMeter Belt – A meter belt conveyor is a belt conveyor with two belts and a common drive. The discharge belt runs faster than the induct belt to allow spacing of conveyed products. It is primarily used prior to merge or induct units. Meter belts are available with a brake/clutch option that is either air or electric-operated.\nBrake Belt – The brake belt is used to stop product flow and allow accumulation of the product prior to product discharge onto a merge unit. Brake belts are electrically operated and are available with a brake or a clutch/brake.\nThe live roller type conveyor is a conveyor type on which product is moved by rotation of the carrier rollers.\nTypical Live Roller Conveyors – Here, the carrier rollers are rotated by friction with a powered belt, which is pressed against the underside of the carrier rollers by adjustable pressure rollers. Friction between belt and carrier rollers, and thus driving force of the carrier rollers in any desired area, can be varied by adjusting the height of the pressure rollers under the belt at that location. This conveyor may be used on inclines or declines, which do not exceed five degrees from horizontal.\nChain-Driven Live Roller – The chain-driven live roller is a transportation-type conveyor. They use cycloidal tooth sprockets welded on one end. Cycloidal sprockets have thicker teeth than regular sprockets, which allows the chain to better mesh with the sprocket teeth. Guards are mounted above and below all chain and sprockets for safety. Standard tooth sprockets are used on end cap rollers, because the chain wraps 180 degrees around the sprocket.\nSawtooth Merge – The sawtooth merge is a live roller conveyor. Product is moved downstream on the conveyor by multiple rotating carrier rollers. The carrier rollers are powered by a continuous flat belt, which is located beneath the rollers in the center of the conveyor. Pressure rollers press the flat belt up against the bottom surface of carrier rollers. The friction generated between the flat belt and the carrier rollers causes the rollers to turn as the belt is driven. The name “sawtooth” is derived from the conveyor’s sawtooth or wedge configuration, which allows product to converge from both sides, from other junctions or conveyors.\nLineshaft Conveyor – The lineshaft conveyor is a live roller conveyor on which carrier rollers are individually driven through belts from a “lineshaft.” The lineshaft, consisting of interconnecting shaft sections, is completely enclosed within the bed sections of the conveyor. Drive belts for the carrier rollers are made from an elastomeric material such as polyurethane and run on spools installed on the lineshaft. There is enough friction between the bore of the spool and surface of the shaft to turn a carrier roller with loads up to about 20 pounds.\nAutomatic Pressure Conveyor – The APC, or Automatic Pressure Conveyor, is an air-operated live roller accumulation conveyor, which provides zero-line-pressure accumulation. This means that the rollers apply no drive pressure to accumulated products, preventing products from jamming and pressing against each other as they accumulate. Conveyor roller motion is provided by a pneumatically controlled belt that is actuated by downstream sensors. Air pressure is supplied to, or removed from, the belt actuating devices in zones called “accumulation zones” by pressure-sensor assemblies, thus regulating the flow of product.\nSometimes, it becomes necessary to convey product around curves or around curves and up to another level. This is accomplished by use of a spiral belt or flat belt turn.\nSpiral Belt Turn – The spiral belt turn conveys a product around a turn and up or down between different elevations. Product spacing and orientation are maintained from beginning to end of the turn.\nFlat Belt Turn – The flat belt turn is a motorized conveyor unit for moving product around a curve without relying on momentum or pressure from the follow-on products. From the beginning to end of the turn, the unit transports product without changing the product’s relationship to the belt while maintaining the same distance between products.\nFor more information about conveyor belt and sortation systems, visit our Conveyor Basics page at //www.techtransfer.com/resources/wiki/entry/752/. For information related specifically to safety and preventive maintenance, visit our Conveyor Safety and Preventive Maintenance page at //www.techtransfer.com/resources/wiki/entry/754/']"	['<urn:uuid:770dc5a3-fb0e-4542-8c8e-b560fd8647cd>', '<urn:uuid:b30b3c36-059a-4f1d-9bab-a5cd5452955c>']	factoid	direct	concise-and-natural	distant-from-document	multi-aspect	expert	2025-05-01T22:36:12.692263	9	64	2700
192	drug delivery nano systems cardiovascular disease treatment	Nano-drug delivery systems are nanoparticles that enhance drug solubility, stabilization, and tissue absorption while extending cycle periods and restricting enzymatic breakdown. These systems, which have dimensions between 1-100 nm, can be administered orally, through inhalation, or intravenous injection. They help strengthen drug safety and efficacy in treating cardiovascular diseases by targeting specific areas and improving drug delivery.	"[""Biological processes utilization for industrial and other applications, notably gene modification of microbes for the synthesis of hormones and antibiotics is Biotechnology.\nBiological processes utilization for industrial and other applications, notably gene modification of microbes for the synthesis of hormones and antibiotics is Biotechnology. Now Cardiovascular disorders are a major global public health issue, with the highest mortality and morbidity rates within all disorders. For treating and preventing heart diseases, development of drugs is now gaining importance. Nanotechnology has emerged as a novel way to deal with difficulty that occurs in treatment of cardiovascular disease, with help of remarkable working of nanoscience material and nanoscience. The system of delivering Nano drugs is a type of nanoparticles that can enhance drug solubility and stabilization, extend cycle period, enhance the absorption rate of tissue or target cell, and restrict enzymatic breakdown, strengthening drug safety and efficacy of medicines. These drug systems can be given orally, through inhalation and injection intravenously. Nano-drug delivery systems are substances that have at least one nanometer-scale dimensional (1 to 100 nm) or are formed with these substances as core elements in three-dimension.\nToward the turn of the twentieth century, scientific advances in the recognition of the physiological process linked with disease in coronary artery, caused a reduction in mortality. Coronary Artery Disease is still one of the world's major reason of death. There has also been great progress in finding innovative approaches for people suffering with Coronary Artery Disease and its associated consequences due to the persistent work of doctors and researchers all over the world. Drugs, robotic surgery, and nanotechnology have all been used as part of these strategies. First robotic interventions for cardiac patients were documented by Granada et al. They did coronary angioplasty on all of their patients and claimed a 100 percent success rate. Patients with disease like coronary artery in a multicenter trial were treated with a process known as percutaneous coronary procedure and it was described by Weisz et al. They employed the same success criteria and obtained a 97.6% success rate. Low - density lipoprotein cholesterol decreases in phase II studies ranged from 18.2 percent to 67 percent when compared to placebo. Alirocumab reduced LDL cholesterol by 66 to 73 percent, but placebo and atorvastatin only reduced LDL cholesterol by 17 percent. Coronary Artery Disease therapies have a bright future ahead of them.\nFor optimal CVD prevention and therapy, rapid and precise detection is critical. In latest days, the use of molecular imaging in the diagnostics of CVDs has received much interest. New contrast agents, in conjunction to continual innovation in various imaging modalities, are essential for quick, high-resolution and high-sensitivity, and diagnosis. In early stages of disease, contrast agent can be used to target lesion or defected area. It is done by formulating nano probes that produce different chemical signals that. Can be visualize in X-ray imaging, contrast-enhanced ultrasound imaging, fluorescence imaging and magnetic resonance imaging. Drug-loaded NDDSs with a large molecular mass can pass vascular wall specifically and reside in tumor infected sites. The drug-loaded nanoscale can maintain its structure in normal human blood vessels, and. alteration in shape can be used to deliver medicine through the blood stream to the Atherosclerotic plaque in the effect of strong blood fluid shear force.\nReperfusion therapy is most commonly employed in the initial stages of myocardial infarction, however it has the potential to trigger apoptosis and reactive oxygen species. These substances promote cardiomyocyte apoptosis and necrosis by opening the permeable transition pore of mitochondrial membrane and increasing outer mitochondrial permeability. The ability of nano-drug carriers to target the increased porosity of blood arteries and the enhanced monocytes in ischemic myocardium can help in drug delivery. RNA interference is a process in which specific gene is silenced in eukaryotes that has evolved as a protective mechanism against invading genes and pathogens. Some researchers employed nanoparticles like chitosan to build and pack short interfering RNA in response to Platelet Derived Growth Factor-B mRNA plasmid vector, which was then transfected into vascular cells of rabbit artery wall effected due to balloon catheter and delivered utilizing therapeutic ultrasound. The packed chemicals have a interactive effect, and the remedial impact is more effective than individual therapy, due to the drug nano-system and co-loaded gene, which is linked with gene interference and nanotechnology. Cardiac hypertrophy is effectively prevented with genome wide down regulation of p53 activity by targeted siRNA. The utilization of NDDSs will enhance, and novel procedures and approaches for clinical diagnosis and therapy will be supplied, due to nanotechnology innovation and deeper investigations on molecular disease processes of cardiovascular Diseases.\nA number of novel genes and proteins have been discovered that can be targeted to offer greater heart protection in the search for ever-more effective medicines to cut cholesterol levels and lessen cardiovascular disease risk. Individuals with mutations that alter the Proptone convertase substillin/ kexin type 9 gene have much reduced cholesterol levels, lowering their risk of heart attack by 80%. In the United States, Verve Therapeutics is taking it a step further by developing a one-shot gene editing therapy that disrupts the PCSK9 gene persistently, lowering cholesterol levels and cardiovascular disease risk. Individuals with established coronary artery disease and those in desperate need of novel therapeutic techniques will be the first to benefit from Verve's genome - editing therapy. The core of the bullseye is a population of high-risk individuals with unresolved requirements who have already had a heart attack or have sky-high cholesterol due to the genetic disorders. Whereas preventative therapies and lifestyle changes can be very helpful in preventing heart failure, they are sometimes not enough for some people. This has its own set of challenges: demand for donor hearts far outnumbers availability, resulting in patients waiting for months or even years for a viable transplant. Carmat's continuing international trial has showed excellent interim results, with 70 percent of heart failure patients who got the device surviving for at least six months or until receiving a heart transplant. The first data set clearly demonstrated that our device has the ability to be very effective in the management of biventricular illness, but further more reliable data will be required to prove it as a true targeted treatment. While 3D bioprinting is still in its development, the technology is fast advancing and has achieved substantial prominence in recent years, prompting the eternal question of whether we will soon be printing complete human hearts for transplantation. Although we should really not expect to be printing unique replacement hearts any time soon, there are a number of areas where bioprinting could have a substantial influence on people with cardiovascular problems in the coming days. Bioprinting technology of Cellink's is being used in a number of initiatives to create 3D cardiac models for drug testing, heart disease research, and regenerative medicine.\n- Deng, Y., Zhang, X., Shen, H., He, Q., Wu, Z., Liao, W., & Yuan, M. (2020). Application of the Nano-drug delivery system in treatment of cardiovascular diseases. Frontiers in Bioengineering and Biotechnology, 7. https://doi.org/10.3389/fbioe.2019.00489\n- Kandaswamy, E., & Zuo, L. (2018). Recent advances in treatment of coronary artery disease: Role of Science and Technology. International Journal of Molecular Sciences, 19(2), 424. https://doi.org/10.3390/ijms19020424\n- Paulis, L. E., Geelen, T., Kuhlmann, M. T., Coolen, B. F., Schäfers, M., Nicolay, K., & Strijkers, G. J. (2012). Distribution of lipid-based nanoparticles to infarcted myocardium with potential application for MRI-monitored drug delivery. Journal of Controlled Release, 162(2), 276–285. https://doi.org/10.1016/j.jconrel.2012.06.035\n- Mitha, F. (2021, March 3). How is European biotech tackling the Cardiovascular Disease Problem? Labiotech.eu. Retrieved October 3, 2021, from https://www.labiotech.eu/in-depth/cardiovascular-disease-european-biotech/.""]"	['<urn:uuid:694711cd-b039-47aa-a145-b9301ccd3aae>']	open-ended	direct	short-search-query	similar-to-document	single-doc	expert	2025-05-01T22:36:12.692263	7	57	1262
193	armenian culture preservation and resistance ww1	Armenian culture faced serious threats to its preservation, particularly during WWI. While centuries of foreign influence and Ottoman subjugation had already impacted Armenia's elite culture, the peasantry managed to maintain many traditional elements including dance and music. However, the Turkish massacres and deportations of 1.5 million Armenians during WWI dealt a severe blow to cultural preservation, especially in Western Armenia. Despite these challenges, Armenians showed remarkable resistance - defending themselves in multiple locations across the Ottoman Empire, with over 300,000 Armenian soldiers fighting on Russian fronts and others organizing defensive battles in cities like Van, Urfa, and Musa Dagh, demonstrating both cultural resilience and active resistance rather than passive victimhood.	"['Armenian Dance Before 1915\nThe Armenian dance heritage has been one of the oldest, richest, and most varied in the Near East. The ancestors of the Armenians established themselves in Hayastan (Armenia) about 650 Before Christ (B.C.) soon after the collapse of the Urartian Empire. The geographic position proved both a curse and a blessing. Located at a major crossroads between powerful empires, Armenia became a buffer state continually ravaged by invading armies, but distant enough to retain its own culture and identity.\nThe geographic location encouraged commerce and exposed the Armenians to many other peoples: Phrygians, Syrians, Persians, Hellenic Greeks, Romans, Laz, Jews, Byzantines, Arabs, Kurds, Seljuks Mongols, Osmanli, Georgians, Asiatic Albanians, Russians, and countless others. Armenian culture reflects many of these influences.\nAlthough centuries of Ottoman subjugation changed or destroyed much of Armenia\'s ""Great Tradition"" (elite culture), the ""little tradition"" of the peasantry remained relatively unchanged for millennia. The rich dance heritage remained a living tradition into the 20th century. The Turkish massacres and deportations of 1,500,000 Armenians during world War I, and the subsequent dispersion of the survivors, irrevocably destroyed much of the dance heritage of Western Armenia, leaving scattered fragments of some dances. Many of these surviving fragments have since been lost due to modern cultural assimilation and urbanization.\nThe destruction of most of the material culture has made it difficult to study the dance historically. Similarities in the poses found in Armenian dance with poses found in ancient Sumerian and Urartian artifacts have been cited as evidence of a direct relationship. These similarities do suggest the continuity of certain motifs but these motifs are also shared by neighboring ethnic groups. Most of the written records that have survived are ecclesiastically oriented (that is, illuminated manuscripts), and make little mention of the dance. These writers were clerics who viewed the dance as pagan in origin and generally ignored or suppressed it. The references that do exist indicate that many Armenian dances were originally totemic, imitating animals or nature.\nThe traditions of many centuries contributed to the development of the rich diversity in Armenian dance. The dance itself is divided into two categories: dances (barer), which were executed to the accompaniment of musical instruments, and song-dances (bari-yerker), which were performed to vocal accompaniment.\nDances were usually accompanied by musical instruments. In the village, the most common instruments were davul / tahul (a large drum), and zourna (primitive oboe). Other popular village instruments used were dudeksheeve and mey (shepherd\'s flutes), and daf (tambourine). The sax was a stringed instrument commonly played in Western Armenia, with the tar being its Eastern Armenian counterpart. The kemenche (fiddle) was used as a folk instrument on the Black Sea, but elsewhere was used to accompany the songs and poetry of the wandering ashoog (troubadour). A village ensemble often consisted of no more than two or three instruments.\nIn the cities, a more elaborate tradition of musical performance existed, with groups of musicians playing in orchestras. These musicians often played tar, oud, kanoon, snatur, nagar, kemenche, daf, dumbeg, and mandolin, or (starting in the 19th century) clarinet, piano, violin, and other European instruments. The music of urban ensembles was heavily influenced by urban ""oriental"" (Arabic, Persian, and Turkish) music.\nThese urban musicians considered Armenian village music to be ""peasant\' and ""unsophisticated,"" and preferred playing Ottoman urban music (that is, longa, simai) and European music. The urban dances reflected this preference (that is, chifte-telli, waltz, quadrille). It was essential for a rural or urban band to have a good singer or skilled joke-teller, who could create impromptu lyrics. Improvisation was an intrinsic part of Armenian culture.\nSome of these songs were ancient but many were improvised ditties reflecting the issues of the day (that is, the local gossip), and changed frequently. The lyrics themselves were not only in Armenian but also in Kurdish, Turkish, Azerbaijani, Greek, etcetera. In many areas of Armenia, these other languages were commonly used by Armenians, often in addition to their own Armenian language. Armenians often composed songs in these other languages or adopted songs created by these neighboring ethnic groups.\nArmenian dance has a wide variety of formations. The dances are often performed in an open circle, with the little fingers interlocked. In general, the dances moved to the right (counter-clockwise), although there are a few areas that moved clockwise to the left (that is, Yerzinga). The basic structure of the dance could be either men only, women only, or mixed lines. The number of dancers also varied: group/line/circle dances, solo dances, or couple dances. In rural Western Armenia, the couple dances were commonly done by members of the same sex (that is, Women\'s duet from Chamokhlu, men\'s combat dances). A man and woman dancing together as a couple was more typical of the urban areas, or Eastern Armenia.\nArmenian dance could also be broken down into two distinct styles of dance, ""Western Armenian"" (Anatolian), and ""Eastern Armenian"" (Caucasian). These two major styles are also subdivided into regional styles (that is, Van, Lori). Eastern Armenian, the style of the Transcaucasus Mountains, displays ballet-like movements and acrobatics in its oirginal folk form, particularly the men\'s dances. This is the style usually performed by most Armenian dance groups today, who are influenced by the repertoire of the State Dance Ensemble of the Armenian Soviet Socialist Republic (S.S.R.).\nThe Role Of Dance\nThe modern concept of a dance/party (hantess/kef), as a distinct social function with a band playing, etcetera, is an Armenian-American innovation, and did not exist traditionally. A party was not a separate function in itself, but merely one aspect of some major event or festivity which included the entire community (that is, a wedding). There were European balls in the cities for the urban Armenian merchant classes, but these had little in common with the village festivals. A poor villager did not have a band conveniently playing when he wanted to dance, nor did he need one, for he could provide his own music by singing a dance-song. The traditional village dances varied widely and encompassed all aspects of village life. The dance was not simply and idle amusement, but and organic part of the culture. Any event, such as an engagement, would include special music, songs, and dance.\nA dance often combined several functions simultaneously. The following description illustrates the multiple roles. It describes Armenian pilgrims dancing at an Ascension Day festival in the Armenian monastery on the outskirts of Treibizond. International folk dancers familiar with Pontic Greek dancing or Turkish Black Sea dancing will recognize this as the Armenian cognate form.\nContinuity and Change\nArmenia had a multiplicity of distinctive regional subcultures, many of which had their own characteristic dialects and customs, including dances. The extensive mountain ranges isolated villages and encouraged variety. The Armenian peasantry was noted for its improvisational skill in songs and dances, often creating new songs and dances to commemorate particular occasions and noteworthy local events (that is, Papertzi Gossip Dance). As time passed these topical songs would be forgotten, as new events inspired new songs and dances.\nThe same geographic isolation that encouraged diversity also maintained continuity in the music and dance tradition within each area because a creative villager would draw upon his traditional elements as his artistic source. Thus, a new village dance would closely resemble the old dances, maintaining the artistic continuity, because they both used common traditional elements of that particular community. Although the regional style would change, as do all living traditions, it would do so very slowly over many generations.\nArmenian villagers did travel, particularly as pilgrims to the large religious festivals. There they would be exposed to the music, songs, and dances of other villages and regions. When they returned home, they would describe and demonstrate these for their own village, often adding a local flourish to the song or dance. Some of these might be incorporated into the local repertoire, and modified to suit local tastes.\nAnother major factor in the diffusion of dance was the large scale transfer of populations to other areas. Life in Armenia was precarious due to its geographic and political position. Foreign invaders forced large segments of the population to move, at several points in history. Seljuk invasions in the 11th century led to the Armenian settlements in Sepastia and Cilicia. In the 16th century Shah Abbas deported a large number of the Armenian population to Persia. Nomadic Kurds then migrated into depopulated Western Armenia, which they presently dominate.\nAs a result, Armenian song and dance did not exist in discrete isolated units. Instead, it resembled an Oriental tapestry, combining different elements. Although the regional style of music and dance remained intact, some of the songs and dances may have originated elsewhere in a different form, and have been assimilated locally. Many songs were widespread, with different dances accompanying them in different areas (that is, Hoy Nar, Lepo Le Le). Conversely, the dance could be widespread, and done to different songs in different areas (that is, Bar, Sword Dance).\nThe variety of Armenian dances as so extensive, and documentation so poor, that few individuals are familiar with even a fraction of the dances. A brief list of regional dances could include:', 'Submitted by global publisher on Fri, 05/15/2015 - 15:54\nBy Harutyun Marutyan\nMost of the initiatives and events to commemorate the Armenian Genocide Centennial were mainly aimed at the world at large and at Turkey specifically, which was to be expected. The Genocide Centennial, however, is a milestone and a starting point for addressing a myriad of national issues as well.\nAs a rule, every year references to and publications on the Armenian Genocide tend to focus on the victims and sometimes by extension on Armenian irregular units and their defense tactics. Yet no official mention of them is made, which perpetuates the victim mentality on a scale of the whole nation.\nMeanwhile, the years of the Armenian Genocide and World War I in particular witnessed another reality. The official documents of the Russian Supreme Command state that since the outbreak of the war, over 300,000 soldiers of Armenian descent had fought on the Western and Caucasus fronts of the Russian Empire. The seven Armenian volunteer units recruited 6,000 people. These sources tell of a greater number of volunteers from other regions of Russia and foreign countries – apart from Armenia and Transcaucasia – but the Command of the Caucasian Army, as instructed by the government, intentionally abandoned the strategy of enrolling more volunteers. The Eastern Legion, a unit composed of over 5,000 Armenian militants established within the French Army in November of 1916, was renamed the Armenian Legion in December of 1918.\nDuring the Genocide Armenians were driven to defensive positions throughout the Ottoman Empire. In 1915 the Armenian population in Shatagh/Tagh, Van, Shabin-Karahisar, Muş, Fitinchag, Urfa, and afterward (in 1920-1921) in Hadjin and Antep was forced to take up arms. Defensive battles were waged in cities and comparatively large settlements as well as in provinces, namely Gevaş, Pesandasht, Armenian villages in Yozgat, Sason, Musa Dagh and Armenian villages in Hınıs and Hodiçor.\nThough in some of the scattered fights Armenians were overpowered instantly, on some occasions they lived to fight another week or month, organized and scattered, armed and unarmed alike. One thing is certain – in many instances Armenian civilians were not “sheep to be slaughtered” without a fight. An Armenian earnestly defended himself and his family, their lives and dignity. Could a nation without statehood unite in the face of adversity, wage defensive battles and emerge victorious in Sardarapat and Aparan in May 1918 (during World War I) and then stage acts of defiance in Karakilisa, consequently saving Eastern Armenians from an imminent Genocide?\nIn the meantime, the Armenian world has commemorated the Armenian Genocide victims for over a century, either officially or informally. Participants of the famous and still unknown defensive battles are thus referred to as victims. Over decades this very interpretation has evoked manifestations of an inferiority complex, a view of the Genocide memories as a burden, and, frequently, a belief that it is crucial to sweep these memories away.\nIt takes decades for a memory-driven policy to crystalize and for its impact on society to become apparent. Sometimes the memory factor emerges spontaneously in turbulent times; sometimes a society lives with it by choice. Memory becomes a permanent part of the people\'s self-expression and identity. Thousands of fragments are weaved with unseen threads into one composition, making this memory-driven policy whole.\nOne hundred years after the Armenian Genocide we know of documented acts of defiance during the massacres; we have 25 years of national statehood; we have the Artsakh (Nagorno-Karabakh) victories. Therefore, it is crucial to review and redefine the meaning of “Remembrance Day,” or at least to shift the emphasis and rephrase the commonly accepted wording into “Armenian Genocide and Heroic Defense Remembrance Day.”\nDoctor Harutyun Marutyan is a leading research fellow at the Department of Contemporary Anthropological Studies at the Institute of Archaeology and Ethnography, National Academy of Sciences of Armenia, and visiting professor of Anthropology at Yerevan State University. He is an IREX/RSEP (Michigan University, 1998), Fulbright (MIT, 2003-2004) and DAAD (Berlin, 2013) alumnus. His research interests include national identity transformation, Armenian Genocide memory, mo¬dern national movements, iconography, traditional Armenian culture, and poverty. Harutyun Marutyan is the author of three monographs and more than a hundred scholarly articles. He is recipient of the President of the Republic of Armenia Prize for his valuable contribution to the recognition of the Armenian Genocide.\nWhy April 24 should be an ""Armenian Genocide and Heroic Defense Remembrance Day""']"	['<urn:uuid:18559095-26aa-458f-b74e-43cfa762981f>', '<urn:uuid:b9168944-169e-4e77-969a-621aba429820>']	open-ended	direct	short-search-query	similar-to-document	multi-aspect	novice	2025-05-01T22:36:12.692263	6	110	2266
196	medical procedure fix hole eardrum patch repair surgical options	When an eardrum doesn't heal on its own, doctors may perform an eardrum patch procedure, where they put a paper patch over the hole. This might need to be done multiple times until full healing occurs. If other treatments fail, a surgical procedure called tympanoplasty may be necessary, where a surgeon attaches a small patch of the patient's own tissue to close the tear on the eardrum.	"[""Darren lost his balance while waterskiing. As he fell sideways, his head slapped against the water and he felt a sharp pain inside his ear. When Darren put his fingers to his ear he saw blood. He also realized he couldn't hear as well from that ear.\nDarren's parents called the doctor and got him an appointment right away. The doctor looked in Darren's ear and told him he had a perforated eardrum.\nWhat Is a Perforated Eardrum?\nA perforated eardrum is a tear or hole in the ear's tympanic membrane (the medical name for your eardrum). A perforated eardrum is also sometimes called a ruptured eardrum.\nA perforated eardrum can really hurt. And if you can't hear as well as usual, it can be pretty scary. The good news is, most people who have a perforated eardrum get all their hearing back eventually.\nIf you think you have a perforated eardrum, see a doctor. A tear in the eardrum can allow bacteria and other things to get into the middle ear and inner ear. If that happens, an infection could develop that can cause more hearing loss.\nMost perforated eardrums heal in a few weeks. Sometimes, though, doctors need to do surgery to repair the tear.\nHow the Eardrum Works\nThe eardrum is a thin piece of skin-like tissue that's stretched tight — like a drum — across the opening between the ear canal and the middle ear.\nThe outer ear funnels sound waves into the ear canal that hit the eardrum and make it vibrate. The middle ear and inner ear convert the vibrations to signals that the brain interprets as sounds.\nIf there is a hole in the eardrum, it can't always vibrate as well as it should. This can make a person's hearing worse.\nCauses of a Perforated Eardrum\nYou've probably already know not to stick cotton swabs or other things into the ear canal when cleaning your ears. But eardrums can get ruptured a number of ways, and not all of them involve puncturing them with a swab.\nHere are some things that may cause perforated eardrums in teens:\n- Sudden pressure changes (barotraumas). Most of the time, the air pressure in the middle ear and the pressure in the environment are in balance. But some things — like flying in an airplane, driving on a mountain road, or scuba diving — can cause a sudden change in pressure that may rupture an eardrum.\n- Loud noises (acoustic trauma). Really loud noises, like an explosion, can produce sound waves that are strong enough to damage the eardrum. Luckily, this doesn't happen often. Loud noise also can cause temporary or permanent damage to the cochlea.\n- Foreign objects. Thinks like cotton swabs or bobby pins may poke through the eardrum if pushed into the ear.\n- Head trauma. A direct blow to the ear or a severe head injury from something like a car accident can fracture (break) the skull bone and tear the eardrum.\n- Direct trauma to the pinna and outer ear canal. A slap on the ear with an open hand or other things that put pressure on the ear can tear the eardrum.\n- Ear infections. An infection of the middle ear or inner ear can cause pus or fluid to build up behind the eardrum. This can make the eardrum burst open.\nWhat Are the Symptoms?\nThe first sign of a perforated eardrum will probably be pain. Here's what someone might notice after tearing an eardrum:\n- mild to severe pain that may increase for a time before suddenly decreasing\n- drainage from the ear that can be clear, pus-filled, or bloody\n- hearing loss\n- ringing or buzzing in the ear (tinnitus)\n- dizziness or vertigo (a feeling that the room is spinning) that can cause nausea or vomiting\n- weakness in the muscles of the face (this doesn't happen a lot)\nTalk to a parent or call a doctor right away if you have any symptoms of a perforated eardrum. You should also see a doctor if you continue to have symptoms after getting treatment for a perforated eardrum. Even though most perforations heal on their own, you want to take steps to make sure any hearing loss you experience is only temporary.\nGo to the emergency room right away if you have severe symptoms. Examples of severe symptoms are bloody discharge from your ear, extreme pain, total hearing loss in one ear, or dizziness that causes vomiting.\nDiagnosing a Perforated Eardrum\nTo check for a perforated eardrum, a doctor will most likely examine your ear canal with a lighted instrument called an otoscope. Often, a doctor can see the tear and may even be able to see the tiny bones of the middle ear. Other times it can be hard to see the eardrum at all because of fluid draining from the ear.\nA doctor might order additional tests. Some of these are to check the eardrum for a rupture, others help doctors learn more about hearing loss. The doctor may want you to get an audiology exam to measure how well you hear at different pitches and volumes.\nIf there is fluid coming from the ear, a sample of the fluid might be tested in a lab. This can help doctors decide which antibiotic is best for treating the infection.\nWhat's the Treatment?\nUsually, a perforated eardrum will heal on its own within a few weeks without any treatment. While the eardrum is healing, over-the-counter pain relievers can help ease any pain. Ask your health care professional or a parent which pain relievers are best for you.\nTo help prevent infections (or treat any existing infections), a doctor may prescribe antibiotics. Antibiotics are usually a pill that you'll swallow, but sometimes can be ear drops.\nHere are three things to avoid doing if you have a perforated eardrum:\n- Never use over-the-counter ear drops unless your doctor specifically tells you to. If there is a hole in the eardrum, some kinds of ear drops can get into the middle ear or cochlea and cause problems.\n- Avoid getting water inside the ear canal. Your doctor might recommend that you keep your ear dry during water activities to prevent infection while the eardrum heals. This can be done by gently placing a waterproof earplug or cotton ball coated with petroleum jelly in your ear when you shower or take a bath.\n- Don't clean your ear or forcefully blow your nose. Wait until the tear in your eardrum is completely healed.\nIf your eardrum doesn't heal on its own, an ear-nose-throat (ENT) specialist may recommend an eardrum patch. During this procedure, a doctor puts a paper patch over the hole. Doctors may need to do this procedure a number of times until the eardrum is fully healed.\nIf all other treatments fail, the ENT specialist might have to do a kind of surgery known as a tympanoplasty. The surgeon will attach a small patch of your own tissue to close the tear on your eardrum.\nPreventing a Perforated Eardrum\nSometimes you can't prevent a perforated eardrum (like when an eardrum ruptures because of infection, for example). But a lot of eardrum perforations are 100% preventable.\nTo make the chances of a rupture very unlikely:\n- Call your doctor right away if you notice any signs of an ear infection.\n- Never stick anything in your ear, even to clean it. If you get something stuck in your ear, have it removed by a health care provider — don't try to get it out at home as this could damage your ear.\n- Try to avoid flying on airplanes if you have a cold or sinus infection. If you have to fly, chew some gum during takeoff and landing. You can also try to equalize the pressure in your ears by yawning or swallowing. But don't try that trick of blowing your nose while pinching your nostrils shut. Doctors don't recommend this.\n- Get lessons and a certification if you plan to go scuba diving. Make sure you learn how to equalize the pressure in your ears. Don't scuba dive if you have an ear infection, sinus infection, or cold.\nPerforated eardrums can be scary at first, so it helps to remember that most clear up on their own. But you'll still want to see a doctor and get the right advice on how to make this happen.\nShare this page using:\nNote: All information on TeensHealth® is for educational purposes only. For specific medical advice, diagnoses, and treatment, consult your doctor.\n© 1995- The Nemours Foundation. All rights reserved.""]"	['<urn:uuid:06ae29fa-bd86-4ad0-be5d-0dbcf4edc944>']	open-ended	direct	long-search-query	distant-from-document	single-doc	expert	2025-05-01T22:36:12.692263	9	67	1441
197	How did Western powers react differently to Soviet control of Poland in 1945 compared to the invasion of Czechoslovakia in 1968?	In 1945, Western powers actively participated in conceding Poland to Soviet control, with Roosevelt and Churchill making this decision at the Yalta Conference, partly to gain Soviet support against Japan. In contrast, during the 1968 invasion of Czechoslovakia, Western powers took a more hands-off approach - while they condemned the invasion, NATO allies deliberately chose not to intervene, though the incident did cause a temporary setback in U.S.-Soviet détente efforts, including the cancellation of a summit between Johnson and Brezhnev.	"['Polish Antipathy towards the Soviet Union\nAfter the conclusion of the Second World War, the victorious Allies were showered with the spoils of their success in the conflict. The victorious nations - the Soviet Union, United States, Great Britain, and France -- were left to decide what to do with the war ravaged countries that remained throughout Europe and Asia. The major question on the minds of the leaders and politicians remained: how to divide up the crumbled nations of the broken continent? When dividing up the spoiled nations, the job was broken into different geographical tasks: Europe, Asia, and the third world countries (Gaddis, 1997).\nIn February 1945 the leaders from the big three countries - Franklin Roosevelt (President of the United States), Winston Churchill (Prime Minister of Great Britain) and Josef Stalin (Soviet Premier) met in the City of Yalta to discuss how to divide Europe (Judge & Langdon, 1999). The Soviet Red Army had already occupied Poland and established a Soviet-sponsored provisional government (Judge & Langdon, 1999). The Polish people were in favor of being run by a Soviet-sponsored government or of being recognized as a central Soviet state.\nWith the war in Japan far from over, Roosevelt believed that conceding Poland to the Soviet Union would help gain Russian support against the Japanese (Judge & Langdon, 1999). Churchill and Roosevelt tried to obtain the best arrangement they could on Poland, but it would be a futile process as the Soviets would go on to occupy Poland (Judge & Langdon, 1999). Historically, this is noted as the point that the Western leaders sold out the Poles to the Soviets. The Polish citizenry and political leadership were left upset that they were just given to the Soviets as a bargaining chip in World War II.\nThe Yalta Conference essentially made the country of Poland a Soviet territory. The three powers decided to recognize the Polish Provisional Government of National Unity. In 1945 - as promised by Stalin - Poland would hold democratic elections (Dziewanowski 1987). The elections, controlled by the Soviets, were a fraudulent act used to claim Soviet legitimacy over Poland (Dziewanowski 1987).\nWith the Soviet sponsored government in place, the Polish people would be officially part of the communist network. The citizens of Poland were angry at being sold out to the Soviets and would develop feelings of antipathy toward the Soviet Union. The feelings of antipathy would cause superior conflict between the Polish people and the Soviet-sponsored state. The communist-backed Polish Provisional Government of National Unity would have to intervene to try to end the antipathy that the population of Poland felt towards the Soviets.\nThe steps taken by the Polish Provisional Government of National Unity were meant to stop antipathy, and succeeding in suppressing anti-communist views with the threat of violence and the creation of the Polish Constitution of 1952. This was used to ease the transition of Poland into a central Soviet state, and was coupled with an interjecting of Soviet influence into the daily lives of their citizens -- what was in essence an effort to try to make the Polish people more appreciative of the Soviet Union.\nSuppression through Violence\nDuring the Cold War there were two ideologies around the world for government and for way of life. One was the capitalist system that promoted democracy and freedom; the second was a socialist system that promoted communism and equality for all in society (Gaddis, 1997). When a country became communist, they would do so with guidance from the Soviet Union and would establish a socialist system as both a government and a way of life (Gaddis, 1997).\nThe Polish Provisional Government of National Unity was completely under the control of the Soviet Union (Kersten, 1991). Many top Polish government officials spent time training and developing communist skill sets and ideologies. The Soviet Union believed that, by teaching others the way of communism, they would continue the process of implementing it into their societies (Dziewanowski1987). Furthermore, the Soviet Union...\nStalin often had people with non-communist views disposed of through murder or relocation (Dziewanowski1987). There was no room, according to Stalin, for any differing ideology in the Soviet-controlled countries. Dissenting views would be a problem, and the Polish people remained angry and held onto conflicting viewpoints about the Soviet Union and Stalin.\nWhen taking control over Poland, Stalin made it perfectly clear that the only ideology the Polish people would follow would be that of communism (Dziewanowski 1987). The Soviet Union took control of the elections in Poland, thus demonstrating that the Soviet system of communism and socialism would be the only life for the Polish citizens (Dziewanowski 1987). There were two ways the Soviets knew how to be successful imposing influence or will on another county, and these ways existed through brute force or anti-communist legislation. The actions taken by the Soviets were often of force and completely unacceptable to many of the Polish citizens.\nUnder Soviet influence, the Polish Provisional Government of National Unity would begin a process of eliminating anti-communist viewpoints. After the elections in 1947 the communist Polish Provisional Government of National Unity controlled 417 out of 434 seats in the parliament, thus forcing the established Polish government official out of office. By using force to control the elections, the communist government of Poland had controlled 96% of the Polish Provisional Government of National Unity. The Western powers did not protest leaving the anti-communist leaders in Poland powerless -- and this is a point that has remained contentious among the Polish to this day.\nEither through force or through legislation (Polish Constitution of 1952), the communist viewpoint would be the supreme law of the land in Poland (Kersten, 1991). One way of forcing people to covert to communism was through salami tactics. Salami tactics allowed communists to legally dismember any person or group that provided opposition. It thus became a tactic that gave the Polish Provisional Government of National Unity and the Soviet Union absolute control over Poland. With people in Poland fearing dismemberment, they were left to remain quiet and accept communism or to flee the country for freedom elsewhere.\nThe salami tactics used against Jozef Pilsudski (a major force in Polish politics) ended his reign of political influence. The tactics helped to rip Pilsudski\'s Polish Socialist Party apart and eventually allowed it to fall into the communist regime (Kersten, 1991). At first Pilsudski\'s party split into two factions, but later through legislation and force, became fully in supportive of the communist opposition. This activity forced Pilsudski and others in his party to flee Poland (Kersten, 1991). When the citizens of Poland saw that established political officials were fleeing or being executed, they were further enraged at the communist regime.\nWith the salami tactics in full effect, there would be little - if any - opposition to the communist Polish Provisional Government of National Unity. Polish reality would fall to a position of rule under the influence of Stalin as a central Soviet state. Stalin was known to have anti-communists executed or sent to prison camps in which they would live a life of hard labor until their deaths (Dziewanowski 1987). Many anti-communist parties and their supporters were forced to become communist or to flee Poland in fear of their lives or freedom.\nStalin\'s system of suppression was also adept at using military force when necessary to express communist views. The Soviet Union\'s Red Army was a well trained and massive militia that reported directly to Stalin himself (Dziewanowski 1987). If a group wanted to demonstrate an anti-communist or anti-Stalin viewpoint, the Red Army would likely be called into duty. Stalin\'s brute force controlled many European countries. This strategy was effective because of the fact that many opposed to Stalin were fearful of both him and of the threat of brute force that he brought down on others (Dziewanowski 1987).\nAlthough the Polish people were angry and did not want to be a part of the central Soviet state, the first step taken by the communist Polish Provisional Government of National Unity to stop antipathy against the Soviet Union was to drown out the voice of any who dared to oppose them. This was done through brutal force. In September 1980 the Solidarity was formed; this was the first non-communist political party in Poland. The Solidarity was created as a social movement against communism, and they displayed civil resistance in an attempt to change the culture that encompassed workers rights.\nPolish Constitution of 1952\nThe second step taken by the Polish Provisional Government of National Unity to stop antipathy against the Soviet Union was to enact the Polish Constitution of 1952. The constitution was also known as the July Constitution or the Constitution of 1952 because it was signed into law on July 22, 1952. The Polish Constitution of 1952 was modeled after the 1936 Soviet Constitution. The model posited several key features, including a definition of the…\nCommunism & Nationalism Communism Communism is a society without money (For Communism) 1, without a state, without property and without social classes. People come together to carry out a project or to respond to some need of the human community but without the possibility of their collective activity taking the form of an enterprise that involves wages and the exchange of its products. The circulation of goods is not accomplished by means\nOverall, it can be said that the fall of the communist systems around Europe has had different effects and repercussions. These determined the historical evolution between economic success and disarray. Poland is a good example for the effects Western countries had on its economic and political scene, whereas Yugoslavia represents a country still facing the chains of transition, with little European prospects. Bibliography BBC News. ""Profile: Serbia and Montenegro.""BBC World. 2006. 6\nExecutive-Legislative relations in Post-Communist Europe There are two main methods for appointing the executive, the one used in parliamentary systems, the other one in presidential systems. According to the parliamentary method the people first elects the legislature, which, in turn, appoints the executive. In a pure parliamentary system the executive, furthermore, can remain in office only as long as it enjoys the support, or confidence, of a majority in the legislature.\nBut help is on the way. A Belgian theologian is cited as saying: \'It is important and healthy for women, for families, for societies, that we are dealing with the return of the human male, almost from the dead\'."" (2007) It is interesting to note that there appears to be great fear among the Polish majority mindset that the strong role of men in their society will somehow be\nAlso, Anna finds more lies as she analyses William\'s past, concluding that lies play a vital role in people\'s lives. The fact that even William\'s mother had to lie relating to her son\'s real father convinces Anna to think less about William\'s life. Ursula having similar beliefs to Anna contributes to them wanting to find out more about William\'s past, and, to try to understand it. When finally deciding to\nPolish Companies Reacted to Ethical Issues and Changes in Business Standards Since the Fall of Communism in 1989? Poland\'s Economy Pre-Communism\'s Fall Poland\'s Natural Resources Minerals and Fuels Agricultural Resources Labor Force The Polish Economy Under Communism System Structure Development Strategy The Centrally-Planned Economy Establishing the Planning Formula Retrenchment and Adjustment in the 1960s Reliance on Technology in the 1970s Reform Failure in the 1980s Poland\'s Economy After the Fall of Communism Poland After the Fall of Communism Fall of Communism Marketization and Stabilization Required Short-Term Changes Section', 'Soviet Invasion of Czechoslovakia, 1968\nOn August 20, 1968, the Soviet Union led Warsaw Pact troops in an invasion of Czechoslovakia to crack down on reformist trends in Prague. Although the Soviet Union’s action successfully halted the pace of reform in Czechoslovakia, it had unintended consequences for the unity of the communist bloc.\nBefore the Second World War, the nation of Czechoslovakia had been a strong democracy in Central Europe, but beginning in the mid 1930s it faced challenges from both the West and the East. In 1938, the leadership in Great Britain and France conceded the German right to takeover the Sudetenland in the Munich Agreement, but the Czech government condemned this German occupation of its western-most territory as a betrayal. In 1948, Czech attempts to join the U.S.-sponsored Marshall Plan to aid postwar rebuilding were thwarted by Soviet takeover and the installation of a new communist government in Prague. For the next twenty years, Czechoslovakia remained a stable state within the Soviet sphere of influence; unlike in Hungary or Poland, even the rise of de-Stalinization after 1953 did not lead to liberalization by the fundamentally conservative Czech government.\nIn the 1960s, however, changes in the leadership in Prague led to a series of reforms to soften or humanize the application of communist doctrines within Czech borders. The Czech economy had been slowing since the early 1960s, and cracks were emerging in the communist consensus as workers struggled against new challenges. The government responded with reforms designed to improve the economy. In early 1968, conservative leader Antonin Novotny was ousted as the head of the Communist Party of Czechoslovakia, and he was replaced by Alexander Dubcek. The Dubcek government ended censorship in early 1968, and the acquisition of this freedom resulted in a public expression of broad-based support for reform and a public sphere in which government and party policies could be debated openly. In April, the Czech Government issued a formal plan for further reforms, although it tried to liberalize within the existing framework of the Marxist-Leninist State and did not propose a revolutionary overhaul of the political and economic systems. As conflicts emerged between those calling for further reforms and conservatives alarmed by how far the liberalization process had gone, Dubcek struggled to maintain control.\nSoviet leaders were concerned over these recent developments in Czechoslovakia. Recalling the 1956 uprising in Hungary, leaders in Moscow worried that if Czechoslovakia carried reforms too far, other satellite states in Eastern Europe might follow, leading to a widespread rebellion against Moscow’s leadership of the Eastern Bloc. There was also a danger that the Soviet Republics in the East, such as the Ukraine, Lithuania, Latvia, and Estonia might make their own demands for more liberal policies. After much debate, the Communist Party leadership in Moscow decided to intervene to establish a more conservative and pro-Soviet government in Prague.\nThe Warsaw Pact invasion of August 20–21 caught Czechoslovakia and much of the Western world by surprise. In anticipation of the invasion, the Soviet Union had moved troops from the Soviet Union, along with limited numbers of troops from Hungary, Poland, East Germany and Bulgaria into place by announcing Warsaw Pact military exercises. When these forces did invade, they swiftly took control of Prague, other major cities, and communication and transportation links. Given the escalating U.S. involvement in the conflict in Vietnam as well as past U.S. pronouncements on non-intervention in the East Bloc, the Soviets guessed correctly that the United States would condemn the invasion but refrain from intervening. Although the Soviet crackdown on Czechoslovakia was swift and successful, small-scale resistance continued throughout early 1969 while the Soviets struggled to install a stable government. Finally, in April of 1969, the Soviets forced Dubcek from power in favor of a more conservative administrator. In the years that followed, the new leadership reestablished government censorship and controls preventing freedom of movement, but it also improved economic conditions, eliminating one of the sources for revolutionary fervor. Czechoslovakia once again became a cooperative member of the Warsaw Pact.\nThe Soviet invasion of Czechoslovakia was significant in the sense that it delayed the splintering of Eastern European Communism and was concluded without provoking any direct intervention from the West. Repeated efforts in the UN Security Council to pass a resolution condemning the attacks met with opposition from the Soviet Union, and the effort finally died away. The invasion did, however, temporarily derail progress toward détente between the Soviet Union and the United States. The NATO allies valued the idea of a lessening of tensions, and as a result they were determined not to intervene. Still, the invasion forced U.S. President Lyndon B. Johnson to cancel a summit meeting with Soviet leader Leonid Brezhnev. Although Brezhnev knew this was the most likely outcome of the invasion, he considered maintaining Soviet control in the East Bloc a higher priority in the short-term than pursuing détente with the West. As it turned out, the progress on arms control agreements were only delayed by a few years in the aftermath of the Prague Spring.\nThere were also long-term consequences. After the invasion, the Soviet leadership justified the use of force in Prague under what would become known as the Brezhnev Doctrine, which stated that Moscow had the right to intervene in any country where a communist government had been threatened. This doctrine, established to justify Soviet action in Czechoslovakia, also became the primary justification for the Soviet invasion of Afghanistan in 1979, and even before that it helped to finalize the Sino-Soviet split, as Beijing feared that the Soviet Union would use the doctrine as a justification to invade or interfere with Chinese communism. Because the United States interpreted the Brezhnev Doctrine and the history of Soviet interventions in Europe as defending established territory, not expanding Soviet power, the aftermath of the Czech crisis also lent support to voices in the U.S. Congress calling for a reduction in U.S. military forces in Europe.']"	['<urn:uuid:0abff520-f651-4b5d-86a2-88b63d2942b8>', '<urn:uuid:d5c1a3a4-f040-4ccf-b8c1-9a27186ce6e6>']	factoid	direct	verbose-and-natural	distant-from-document	comparison	expert	2025-05-01T22:36:12.692263	21	80	2923
198	greek art influence modern dance pioneer	Isadora Duncan revolutionized turn-of-the-twentieth century concert dance by combining Greek aesthetic influences from studying art in museums with natural movement techniques. She created a dance style expressing the human spirit through free movements, departing from rigid ballet techniques, and is considered the creator of modern dance.	"['Maenads & Muses: A Celebration of the Dances of Isadora Duncan & the Greek Ideal\nSaturday, April 16\nA historic event in dance in Washington, DC - a performance of Isadora Duncan dances at the Center for Hellenic Studies.\nAdmission: Free. Attend any or all portions of the day\'s events.\nRegistration required for the panel discussion and reception (click here to RSVP).\nRain or shine. Dance performances appropriate for children and families.\n""Maenads & Muses: A Celebration of the Dances of Isadora Duncan & the Greek Ideal"" brings together the artistic and the scholarly with performances of Isadora Duncan dances as well as discussions of the influence of the Greek aesthetic and philosophy.\nOutdoor Dance Performances 3-5pm\nDances of Nature, Love & Friendship by Isadora Duncan\nfeaturing the Duncan Dance Project & local guest dancers\nPanel Discussion 5:30-6:30pm\n""Ancient, Modern, Now: An Exploration of Dance & the Greek Aesthetic""\nwith members of the Duncan Dance Project and Center for Hellenic Studies scholars\nCourtyard Performance 7-7:30pm\n""Maenads & Muses"" with the Duncan Dance Project and local guest dancers\nReception & Talkback 7:30-9pm\nSponsored by the Center for Hellenic Studies\nFor more information, see www.duncanschool.com.\nThe Isadora Duncan repertory dances on this program have been passed down through a direct lineage of Duncan dancers, from the schools of Anna Duncan, Irma Duncan, and Maria-Theresa Duncan. Fourth generation Duncan dancers Meg Brooker, Valerie Durham, Julia Pond, and Jennifer Sprowl have coached and performed extensively with Duncan master teachers who trained directly with first and second generation Duncan dancers, including Lori Belilove, Jeanne Bresciani, Barbara Kane, Hortense Kooluris, and Julia Levien. The versions of the dances on this program were collaboratively staged by the performers. More information about the Isadora Duncan repertory dances and direct lineage dancers can be found at www.isadoraduncanarchive.org.\nDuncan Dance Project Company\nMeg Brooker, Assistant Professor, Middle Tennessee State University, is a founder and steering committee member of the Isadora Duncan International Symposium and a former member of Lori Belilove & Company/Isadora Duncan Dance Foundation. As a Duncan dancer, Meg has performed in national and international venues including The National Portrait Gallery of the Smithsonian, the Dallas Museum of Art, Museum of Fine Arts Houston, the Art Monastery (Italy), Erarta Museum of Contemporary Art (St. Petersburg), American Center of Moscow, PROJEKT Fabrika (Moscow), and the ancient Greek ruins at Chersonesos (Crimea), among others. Meg directs the Duncan portion of Dancestry, recognized in 2015 as “Best of the Arts in Austin” by the Austin-American Statesman. Meg is also working to historicize Duncan contemporary Florence Fleming Noyes and has presented scholarship on early twentieth century dance for Society of Dance History Scholars, Congress on Research in Dance, National Dance Educators Organization, and the Schools of Philology, Psychology, and the Arts at Moscow State University. www.megbrookerdance.com.\nValerie Durham is a direct lineage Duncan Dancer who has studied the Isadora Duncan technique since 1992, and trained as a dancer in ballet, tap and jazz. She is the Artistic Director of The Duncan Dancers, and the Director of the Isadora Duncan School for Creative Movement & Dance in the Washington DC area. Valerie studied and performed as a Company Member with the prestigious Lori Belilove & Company in New York City, and has studied with Duncan Dance Masters Lori Belilove, Jeanne Bresciani, Barbara Kane, Julia Levien and Hortense Kooluris, as well as many other Duncan luminaries. She has performed the Duncan repertory, as well as her own Duncan-based original choreography, nationally and internationally. Valerie is a Teaching Artist with the John F. Kennedy Center for the Performing Arts, served as the President of the Word Dance Theater Board of Directors and earned a Masters of Fine Arts degree in Dance at the University of Maryland in 2012. Valerie has helped spearhead the formation of the Isadora Duncan International Symposium and is a member of the IDIS Steering Committee and chair of the Isadora Duncan Archive Project. www.duncanschool.com\nJulia Pond is an independent artist based in London, whose experience of Duncan dance since 2001 deeply influences her contemporary choreography and teaching. Her 2012 work, Bach Motets, a choreographed concert conceived by Crispin Lewis and performed with baroque ensemble the Musicall Compass, premiered at St. John’s Smith Square, London. Julia’s 2010 work Song of the Sibyl has been presented by London’s Cloud Dance and Scenepool Festivals, Rome’s Exitart, Jennifer Muller/The Works NYC, Noyes School of Rhythm and Katharine Hepburn Theater, Old Saybrook CT. A member of Lori Belilove’s Isadora Duncan Dance Company from 2001-2005 and an international affiliate from 2005-2010, Julia is a 4th generation Duncan dancer primarily taught by Lori Belilove and Cherlyn Smith. Julia currently receives coaching in Duncan repertory from Barbara Kane, founder of the Isadora Duncan Dance Group, London/Paris. Julia is also a member of the Steering Committee of the Isadora Duncan International Symposium. She has taught a contemporary Duncan technique class Bernie Grant Arts Centre since 2013. From 2007-2009 she lived and worked at the Art Monastery Project where she helped develop the project’s unique combination of contemplative practice and artistic work. Trained at the Boston Conservatory, Julia graduated magna cum laude in 2000 with a BFA in Dance.\nJennifer Sprowl is a fourth generation Duncan Dancer and founding member of Lori Belilove & the Isadora Duncan Dance Company in New York City. Training directly with Duncan Dance luminaries Lori Belilove, Hortense Kooluris and Julia Levien, Sprowl’s wide ranging dance credits include Rebecca Kelly Dance Company, Pennsylvania Ballet, Pennsylvania Dance Theater and Dayton Ballet Company. She has worked extensively with modern dance masters Bill Evans, Eleanor King, Bella Lewitzky and Hannah Kahn. Sprowl currently serves as faculty with the Joffrey Academy of Dance, Chicago and teaches classes dedicated to the preservation and extension of Isadora Duncan technique for the 21st century . A specialist in the field of pre/post rehabilitation for dancers, Sprowl is a graduate of the Ohashi Institute of Shiatsu, certified as an Active Isolated Stretch practitioner based on the work of Aaron Mattes, is a Certified Flexibility Technician and has extensive training in Gyrokensis, Yamuna Body Rolling and Power Pilates. Sprowl is regularly invited to present master classes and guest teach at prestigious universities and dance companies throughout the United States and internationally. Jennifer’s innovative staging of the Duncan Dance repertoire in Chicago includes works for MOMENTA, The Chicago Academy for the Arts, and her own company, Duncan Dance Chicago. Her uplifting and motivating approach renders her classes and coaching in the Duncan technique a pure, authentic and powerful experience. www.duncandancechicago.com\nFamed for her bare feet, silk tunics, and free spirit, Isadora Duncan (1877-1927) revolutionized turn-of-the-twentieth century concert dance. A San Francisco native often hailed as the “Mother of Modern Dance,” Duncan began teaching and performing at a young age. She traveled east, dancing in Chicago and New York, where she worked as a member of Augustine Daly’s theatre company. Duncan’s early solo concerts were in the context of high society salons, and she danced to both musical accompaniment and poetic recitations. By 1900, Duncan sought an audience for her art in Europe. In London, she began to create choreographies to Frederic Chopin’s piano compositions, and in Paris she served a brief apprenticeship with Loie Fuller. In fact, Fuller organized a concert for Duncan that led to her first major contract with a theatre in Budapest, Hungary. Over the course of her nearly three-decades long career, Duncan toured extensively throughout Europe, Russia, the United States, and South America. Her work evolved during that time, with early choreographies expressing youthful joy and exuberance, symphonic works evoking Greek mythological stories and archetypes, and powerful dances featuring monumental and heroic themes in response to the First World War.\nDuncan’s influence was not limited to revolutionizing dance as an art form, she was an outspoken advocate for women’s freedoms, including dress reform and education, founding her first school in Germany in 1904. Six of her original students, dubbed the “Isadorables” by a critic, performed with her and later passed on her technique and a repertory of nearly one hundred choreographies. Influenced by her observations of movement in nature, her studies of the work of Francois Delsarte, and her meditations on Greek and Renaissance art, Duncan identified the solar plexus as the initiatory center of all emotive and expressive movements and created a dance technique that develops the relationship between breath and gesture. This movement technique is expressive, integrating, and powerful, and as direct-lineage Duncan dancers, Duncan Dance Project members Meg Brooker, Valerie Durham, Julia Pond, and Jennifer Sprowl are actively working to preserve, pass on, and develop the Duncan dance legacy.', 'Isadora Duncan was a dancer who was born in 1877 or 1878, in San Francisco. What distinguishes Isadora from all her other contemporaries is that her dancing didn’t adhere to a form, to rules, or rigid ballet techniques. She had a completely different and pioneering philosophy towards dance.\nShe perceived dance as a natural movement of the body and a medium for the expression of the human spirit. Isadora was deeply moved and inspired by ancient Greek art, which she combined with her American sense of freedom. She is considered the creator of modern dance.\nDuncan’s parents divorced when she was just an infant, and she lived with her mother and three other siblings in extremely poor conditions. The children, who were all dancers, didn’t have any other choice but to contribute to their household income by giving dancing lessons to the other kids in the neighborhood. Isadora continued with this throughout her teenage years. She loved dancing, and she always improvised and experimented with her moves. She traveled to Chicago and became part of the Augustin Daly’s theater company. From there, Isadora moved to New York City, where, unfortunately, the stage wasn’t ready for her unique movements.\nFeeling disappointed and unappreciated, Isadora left America and moved to London in 1898. In London, she danced in wealthy peoples’ drawing rooms, while she was drawing her inspiration from the Greek art in the British Museum. Her earnings were sufficient for renting a studio where she could create “magic” for the stage. After London, Isadora traveled to Paris, drawing more inspiration from the Louvre.\nIn 1902, Isadora was invited by Loie Fuller to tour with her. They traveled all around Europe and Isadora could perform freely, creating a more innovative technique. She influenced the perception of dance at the time by giving the audience natural movement dance instead of rigid ballet techniques.\nEven though the critics were divided in their opinion, Isadora inspired many artists such as Abraham Walkowitz, Arnold Ronnebeck, Auguste Rodin, and Antoine Bourdelle, who created works based on her.\nUnusual for a stage artist, Isadora wasn’t fond of the commercial aspects of public performance, such as contracts and touring. Her mission was to share the dance and her philosophy of movement, so she opened schools and dedicated herself to teaching young people.\nDuncan opened the first school in Berlin-Grunewald, Germany, in 1904. This was the place where the “Isadorables,” Isadora’s protégées, were educated. This was a group of six girls – Erika, Irma, Gretel, Maria-Theresa, Liesel, and Anna, who continued their teacher’s legacy, while the name “Isadorables” was given to them by the French poet Fernand Divoire.\nIsadora legally adopted all six of them in 1919. She also opened a school in Paris, but it didn’t last long due to the outbreak of WWI.\nAleister Crowley, whom Duncan met in 1910, wrote of her: “Isadora Duncan has this gift of gesture to a very high degree. Let the reader study her dancing, if possible in private than in public, and learn the superb ‘unconsciousness’- which is magical consciousness – with which she suits the action to the melody.” – Aleister Crowley, “Magick: Liber ABA: Book 4: Parts 1-4”.\nHe also refers to Isadora under the name, “Lavinia King” in his “Confessions” and his novel “Moonchild.”\nDuncan’s dancing costumes were also unique and extraordinary, as they allowed her to move freely and gave the impression that her body is extremely comfortable, which is the complete opposite of the corseted ballet costumes. Ancient Greek art always inspired Isadora’s clothes, and her most famous costume was a white Greek tunic she wore while barefoot. In 1911, while at a lavish party organized in a rented mansion, the Pavillon du Butard in La Celle-Saint-Cloud, by the French fashion designer Paul Poiret, Isadora, wearing a Greek evening gown designed by the host, danced barefoot on tables among 300 people and 900 bottles of champagne.\nAs much as she did not respect the rules and laws in dance, she was also less keen to observe morality and traditional mores in her way of life. She was an atheist, communist sympathizer, and bisexual. She had two children born in 1906 and 1910, one of which was with the theater designer Gordon Craig, and the second with Paris Singer. Both her children drowned with their nanny when their runaway car went into the Seine in 1913. It took Isadora years to recover from her children’s deaths and she never actually fully came back to herself.\nIn 1921, Isadora moved to Moscow where she met the 18 years younger poet Sergei Yesenin. They married after a few months, and although Yesenin joined her on tour in the United States and Europe, after less than a year, he returned to Moscow, leaving the marriage.\nHe committed suicide in 1925. Isadora had a brief relationship with the poet and playwright, Mercedes de Acosta. Most of her later life featured her drunkness, debts, and love affairs.\nIn 1927, while driving with friends in Nice, in an Amilcar automobile, she wore a hand-painted, long, and flowing silk scarf, designed by the artist Roman Chatov. It was a present from her friend Mary Desti who was also driving in the car. The vehicle was open-air, and the most bizarre accident happened to Isadora – her silk scarf became entangled around the open-spoked wheels and rear axle while still draped around her neck. It hurled Isadora from the car and broke her neck.\nFollowing this horrific incident, Duncan was brought to the hospital and declared dead and was later cremated, and her ashes were placed next to those of her children, in the columbarium at Père Lachaise Cemetery in Paris, 1927.']"	['<urn:uuid:19ac63e7-4479-42bf-83fd-2270eb7e7caf>', '<urn:uuid:17aa3145-fc59-49c7-800a-5bfd45ebc5d8>']	factoid	direct	short-search-query	distant-from-document	multi-aspect	novice	2025-05-01T22:36:12.692263	6	46	2375
199	What happens when two different viruses infect the same cell?	When two viruses infect the same cell, one virus may prevent the other from replicating through a process called viral interference. This can occur through several mechanisms: by blocking cell receptors, competing for cellular resources, or triggering interferon production. Additionally, some viruses can swap genetic material to create hybrid viruses, particularly in the case of flu viruses.	"[""Genomics and Virology\nViruses are all around us. What are they and how can they affect human health?\nThe Big Picture\nViruses are bundles of genetic material wrapped in a protein coat that can infect living things. Viruses cause damage by hijacking a host cell's machinery to make copies of themselves, often disrupting normal cell function.\nViral vaccines can protect individuals from contracting and spreading common diseases caused by viruses, such as the flu, measles and COVID-19.\nWhat is a virus?\nViruses are tiny infectious particles that are halfway between living and nonliving organisms. They are so small (a millionth of a millimeter) that it would take hundreds to thousands of them to cover the end of a human hair. Each virus is composed of genetic material wrapped in a protein coat. Viruses that infect plants and animals also have a layer of fat molecules. Viruses cannot reproduce on their own. Instead, viruses replicate by infecting a host cell (such as humans, other animals, plants or bacteria), hijacking the host's biological machinery and turning the host cell into a virus-producing factory.\nWhat are viruses made of?\nMost viruses have the same basic structure:\na genetic information molecule in the form of nucleic acids such as DNA or RNA.\na protein layer, or coat, that surrounds and protects the nucleic acids.\nThe protein layer allows viruses to fuse with the outer layer of the cells they attack. The nucleic acid portion encodes genes to make proteins that are essential for the virus to function. These proteins direct viral replication and carry out other activities, such as evading host defenses.\nHow many viruses exist on Earth?\nResearchers estimate that 10 nonillion (10 followed by 30 zeroes) individual viruses exist on Earth. If all the 1030 viruses were organized in a single-file fashion, they would stretch for over 100 million light-years (a single light-year is 6 trillion miles) — which is four times the distance from Earth to the Canis Major Dwarf, our closest galaxy!\nBut only a tiny fraction of the viruses on Earth affect humans. Approximately 200 different viruses are known to cause disease in humans, including:\nAcquired immunodeficiency syndrome (AIDS)\nViral agent: Human immunodeficiency virus (HIV)\nViral agent: Poliovirus\nViral agents: Influenzavirus A, B, C or D\nCoronavirus disease 2019 (COVID-19)\nViral agent: SARS-CoV-2\nHow are viruses transmitted?\nViruses can be transmitted in many ways, including by:\nDirect contact with an infected organism, such as being bitten by a mosquito infected with the West Nile virus. When viruses (and other pathogens) move from one species to another, it is known as a spillover event.\nIndirect contact with someone who is infected, such as through respiratory droplets from a person who is coughing or sneezing.\nAirborne or surface transmission, such as touching a surface where infectious viruses are still located minutes to hours after they landed there, can also result in viral transmission.\nHow do viruses infect living organisms?\nViruses have proteins on their surface that typically latch onto a specific molecule on the surface of a host cell, called a receptor. The viral surface molecule can be likened to a specific key, while the host cell receptor is a lock. When the key meets the lock, it opens a door for the virus to enter the cell.\nViruses enter host cells as particles. Once a viral particle enters a host cell, its nucleic acid material interferes with the host cell's functions, essentially hijacking the proteins and other materials of the host cell to make more copies of the viral particles. One infected cell can release hundreds to thousands of new viral particles, with each of the new viral particles being capable of infecting another cell.\nOnce a virus successfully replicates itself, it leaves the host cell to infect other cells. Some viral infections cause no symptoms. However, when many viral particles infect an organism's cells at the same time, they may cause anything from uncomfortable symptoms to severe illness and even death.\nWhy don't all viruses cause human disease?\nThe exact reason why some viruses infect humans to cause disease and others do not remains a biological mystery. For example, humans usually die if infected by the rabies virus. But while human cells can be infected by circoviruses, they do not seem to cause disease. But circovirus infections in other mammals such as dogs and pigs can cause severe diseases.\nIf it is difficult for viruses to cause human disease, how are some able to do so?\nThere are a few major ways by which certain viruses can cause disease.\nViruses that encode information with RNA rather than DNA tend to have a higher rate of mutations. These mutations allow the viruses to be diverse in their genetic makeup, increasing the probability and pace by which they evade the human immune system.\nIn other cases, two different viruses interested in attacking the same host cell can swap regions of their nucleic acid and make a hybrid virus.\nSome viruses vastly benefit from staying inside their hosts for an extended period of time without being deadly. The lengthier the infection, the longer the virus has to adapt and spread to other hosts.\nFlu viruses can do both — mutate at a high rate and mix with other viruses.\nEach year, scientists measure and predict which versions of the influenza virus, or strains, will be prevalent around the world during the next flu season. Then, they produce an influenza vaccine that works against the new strains. These new strains usually acquire changes in their nucleic acid that make the viruses work differently in the host organism, such as by changing the viral protein coat slightly. That is why scientists must tailor vaccines to specific strains of viruses.\nHow does genomics help us understand viruses?\nGenomics is an interdisciplinary field that focuses on studying an organism's entire nucleic acid material (such as DNA or RNA), which is known as its genome. In 1977, researchers sequenced the first viral genome — phi X174, a virus that attacks bacteria.\nBut much progress has been made since then. For example, as of September 2021, there were 11,465 viral genome sequences available.\nIt is important to generate the complete genome sequence of viruses for several public health reasons. Knowing the viral sequence allows researchers to detect whether a virus is present in a host organism, and it provides clues for how a virus attacks and infects the host cell.\nViruses need to be able to use the functions of host cells to replicate themselves. Inhibiting some of the host cell's functions can potentially make viruses vulnerable. Researchers are studying genome sequences of both viruses and their hosts so as to target specific cell pathways that can be used for treatment.\nStudying viral genomes is key for understanding viral mutations and their evolution over time. Understanding viral genomes also helps researchers track outbreaks and consider how best to treat viral infections or vaccinate against a virus.\nHow can we reduce the spread of viruses?\nMasking, proper handwashing, use of hand sanitizers and social distancing reduce the spread of viruses of many viruses. Antiviral medications and vaccines can eliminate or reduce the severity of diseases caused by viruses.\nMedicines used to treat bacterial infections do not kill viruses.\nHow do viral vaccines work?\nPreviously, viral vaccines contained weakened or dead viruses, with both forms being incapable of causing disease. Now, scientists have an additional tool in their toolkit, producing vaccines using a virus's genome sequence. The viral genome has the information needed to create viral proteins, the active component of the vaccine to which the immune system responds. When injected, these DNA or RNA molecules are used by the host to produce specific viral proteins, and the immune system then recognizes the viral proteins as foreign, sparking a response from multiple types of white blood cells.\nOne such class of white blood cells, called B cells, produces a particular type of protein called an antibody. Antibodies bind to molecules on the surface of the virus and neutralize the virus to prevent it from replicating.\nOnce the human body successfully produces antibodies against a virus, its arsenal is ready for defense when the immune system comes in contact with the same virus in the future.\nWhy do some viruses affect certain people more negatively than others?\nThe exact reason why viruses affect people in different ways is under active study. Researchers attribute it to a combination of genetic and environmental factors. People with existing health conditions, such as diabetes, cardiovascular disease or cancer, are more vulnerable to a severe viral infection.\nSome individuals also have specific genomic variants that can influence how a virus interacts with their body. For example, some relatively rare genomic variants make people susceptible to severe viral and other infections. On the flip side, some genomic variants protect specific individuals from viral infections. Researchers continue to study these mechanisms, including the relationship between the level of viral infection and specific genomic variants.\nDoes our body have viral DNA that doesn’t cause disease?\nYes. The human genome contains a considerable amount of DNA that previously existed in viruses. These viral sequences are remnants of past viral infections. Most of these sequences originally came from retroviruses, a type of virus that can insert one copy of its genome into the DNA of a host organism (such as a human). As the host cells make copies of its own genome, it copies the viral DNA as well. These sequences can pass from one generation to the next, becoming a permanent part of the human genome (like a fossil record).\nAt present, DNA from these retroviruses accounts for about 9% of the human genome, but most are thought to be incapable of producing new viral particles.\nLast updated: November 12, 2021"", 'General Properties of Viruses\nWhat is virus?\nThe smallest infectious and acellular microbe.\nConsisting only one kind of nucleic acid (DNA or RNA), and which obligately replicate inside host cells.\nThe complete mature viral particles.\n(The intact infectious virus particles.)\n- The simplest: acellular microbes contain either DNA or RNA\n- The smallest: Pas through 0.2μm filters\n- Obligatory intracellular parasites.\nI. Size, shape and structure\nThe unit of measurement nm\nComparative sizes of virions and bacteria\n1. Staphylococcus aureus\n5. Bacteriophage of E. coli\n6. Influenza virus\n8. Encephalitis B virus\nTobacco mosaic virus: rod-shaped\nVSV (Vesicular stomatitis virus): bullet-shaped\nBacteriophage T4: tadpole-shaped\nEbola Virus: filamentous shape\nCore: Viral nucleic acid (DNA or RNA)\nCapsid: Protein shell\ncapsomers (morphological subunit)\npolypeptide molecules (chemical subunit)\nCore + Capsid → nucleocapsid\nSize, shape and structure\nOthers: enzymes, etc.\ne.g. Retrovirus has reverse transcriptase\nSymmetry of viral nucleocapsids: Is decided by arrangement of capsomeres\n(e.g., tobacco mosaic virus)\n(e.g., poxviruses )\nViral nucleic acid: ssDNA, dsDNA, ssRNA, dsRNA\nprotection, mediate the attachment of virue to specific receptors on host cell surface\ndetermine species and organ specificity\nimportant antigens, superantigen\nHuman Hepatitis D\nNOTE: a single circular RNA molecule without a protein coat which mainly cause plant diseases.\nProteinaceous infectious particle\nBovine spongiform encephalopathy (BSE)\nNOTE: infectious agents composed of a single glycoprotein with MW 27-30 kDa.\nIn host cell, virus replicates its nucleic acid and synthesizes\nits proteins, then assembles them to form progeny viral\nparticles that are released by budding or cell lysis.\n- Adsorption /Attachment\ni. Adsorption / Attachment\nSpecific binding of a viral attachment protein (VAP) with a receptor on the surface of host cell;\nVAP (on virion ) --- viral surface protein\nSpike – enveloped virus\nCapsid protein – naked virus\nViral receptor (on host cell)\nGlycoprotein, carbohydrate or glycolipid\ne.g., CD4 (HIV), CD46 (measles virus), Sialic acid (influenza virus)\nSome enveloped viruses\nMost naked virus\nB. Direct fusion of cell membrane with viral envelope:\nOnly enveloped viruses\nC. Nucleic acid translocation:\nSome bacteriophages and naked virus\nThe process of removing capsid and releasing viral nucleic acid into the cytoplasm;\nAcidification of the content of the endosome\nProteases are needed;\n- Viral genome replication\n- Viral protein synthesis\ndsDNA; ssDNA; dsRNA; +ssRNA; -ssRNA; retrovirus\n+ssRNA with DNA intermediate in life cycle (HIV);\ndsDNA with RNA intermediate (HBV);\n+ssRNA virus (Poliovirus, HAV)\nViral genomic RNA serve as mRNA;\nEnzymes for replication are made after infection, not carried in virion;\n(Extracted) Viral genomic RNA is infectious\n-ssRNA virus e.g., influenza virus\nVirion carries RDRP;\nFirst step: Transcription of viral genome;\nExtracted -ssRNA not infectious;\nNaked virus: capsid + viral genome → nucleocapsid (virion, complete structure)\nEnveloped virus: capsid + viral genome → nucleocapsid (incomplete structure)\na. DNA viruses (except poxvirus): cell nucleus;\nb. RNA viruses and poxvirus: cell cytoplasm;\na. assemble as empty shell (procapsid), then viral genome fill in.\nb. Viral capsomeres array around the viral genome to form helical\nThe process of progeny viruses getting out of host cell.\nNaked viruses:released by cell lysis.\nEnveloped viruses:usually released by budding.\nDuring budding enveloped viruses acquire their envelope.\nDefective measles virus: release from cell to cell via cell bridges.\nenveloped virus replication （1）\nenveloped virus replication （2a）\nenveloped virus replication （2b）\nenveloped virus replication （3）\nenveloped virus replication （4）\nTwo aspect factors:\nnon-permissive cells → Abortive infection\nare genetically deficient and incapable of producing infectious progeny virions.\ncan supplement the genetic deficiency and make defective viruses replicate progeny virions when they simultaneously infect host cell with defective viruses.\ne.g., HDV & HBV\n- Defective viruses lack gene(s) necessary for a complete infectious cycle;\n- helper viruses provide missing functions;\n- 100:1 (defective to infectious particles)\n- DIP (defective interfering particle) : When the defective viruses can not replicate, but can interfere other congeneric mature virion entering the cells, we call them defective interfering particles (DIP).\nVirus infection which does not produce infectious progeny because the host cell cannot provide the enzyme, energy or materials required for the viral replication.\nThe host cells that cannot provide the conditions for viral replication.\nThe host cells that can provide the conditions for viral replication.\nIII. Viral interference:\nWhen two viruses infect simultaneously one host cell, One type of virus\nmay inhibit replication of another type of virus.\nRange of interference occurrence\n- between the different species of viruses;\n- between the same species of viruses;\n- between the inactivated viruses and live viruses.\nMain mechanisms of viral interference:\na. One type of virus inhibit or prevent subsequent adsorption and penetration\nof another virus by blocking or destroying receptors on host cell.\nb. The competition of two viruses for replication materials, e.g., receptor\npolymerase, translation initiation factors, etc.\nc. One type of virus may induce the infected cell to produce interferon that\ncan prevent viral replication.\nThe mechanism of IFN function\nSignificance of viral interference:\na. Stop viral replication and lead to patient recovery.\nb. Inactivated virus or live attenuated virus can be used as vaccine to\ninterfere with the infection of the virulent virus.\nMay decrease the function of vaccine when bivalent/trivalent vaccine is used.\nJust for your practice see the answers at the end.\nFill in the blank\n1-The surrounding protein coat of a virus is called the _______ and it is composed of protein subunits called _________.\n2-Viruses that are only covered with a protein coat outside viral genome are called ______ viruses, while those that have an additional lipid-containing membrane covering are called ________ viruses.\n3. The general steps of the viral replication cycle include ( in the order of their occurrence) ___________________, ___________, ____________, __________, _________________.\n3-Attachment, Penetration, Uncoating, Biosynthesis, Assembly and release.']"	['<urn:uuid:58828205-e370-4a88-8c53-4c44be012379>', '<urn:uuid:a046236c-8ab8-43ea-9b7d-2c32355cb959>']	factoid	with-premise	concise-and-natural	distant-from-document	three-doc	novice	2025-05-01T22:36:12.692263	10	57	2575
200	What are the immediate environmental effects of hurricanes on coastal marshes, and how do these areas help reduce financial losses from storm damage?	From an ecological perspective, hurricanes help maintain wetland health by resetting succession cycles and creating more open marsh environments that provide food resources for waterfowl. The storm surge and saltwater intrusion create natural disturbances that prevent marsh from becoming too heavily vegetated. In terms of financial protection, coastal wetlands serve as natural flood barriers - in Ocean County, New Jersey, areas behind existing salt marshes experience 20% fewer property damages on average compared to areas where salt marshes have been lost.	['On Aug. 25, 2017, the eighth named storm of the year’s Atlantic hurricane season—Hurricane Harvey—made landfall near Rockport, Texas. In the four days that followed, the storm dumped immense amounts of precipitation over eastern Texas, many areas receiving more than 40 inches of rain. The flooding that followed was devastating, with more than 70 people killed in Texas and preliminary damage estimates in excess of $50 billion.\nI arrived in Houston two weeks after Harvey departed, the storm having moved farther inland and finally weakening into a line of showers that broke up over Tennessee. As I drove south along state Route 288 toward Matagorda Island, traveling closer to where the storm had made landfall, the scars left by Harvey were unmistakable. Residents of low-lying areas had most of their possessions—couches, tables, dressers and televisions—ingloriously piled at the edge of the road. The flood line was clearly visible, rising in places above children’s play sets, cars and to the roofs of homes. Debris was scattered everywhere.\nDucks Unlimited had organized the hunt, but Harvey hit with such force I expected the trip would be canceled. However, our outfitter—legendary Matagorda duck guide, boat captain and owner of Matagorda Sunrise Lodge, Bink Grimes—made it clear that we were still welcome to come down and hunt with him. In fact, the teal hunting in early September had been very good. Even in the wake of the storm, Bink and his crew had managed to eke out limits of blue-wings for their clients every day.\nWhen I arrived at the lodge, Bink’s enthusiasm and perpetual good nature made it easy to forget that, just days prior, the worst storm to strike this country in more than a decade had passed directly over our current position. I asked him how much Harvey affected the ducks. “Maybe a little,” he said. “It’s stormed here for centuries.”\nThat much was true, and the locals were eager to get on with their lives. With characteristic Lone Star resolve the residents around Matagorda cleared trees from roads, shoveled silt from basements and knocked on doors to find the rightful owner of a battered Igloo cooler that had floated into someone else’s yard. All was evidence of the ferocity of the storm, but the greatest demonstration of the hurricane’s power was the silting-in of the Gulf Intracoastal Waterway.\nThe Intracoastal Waterway is a body of water—some of it natural bays and rivers, other portions artificial—that runs from Boston, Mass., to Brownsville, Texas. While interstate highways are filled with 18-wheelers busily running goods across the nation’s interior, the IWW, as it’s known, serves as a quiet migration corridor for billions of dollars in goods. The Gulf Intracoastal Waterway, which spans Florida to Texas, is a key pathway for goods to reach a sizeable portion of the U.S. population.\nBut as I looked out at the IWW from the lodge, flat cargo ships stood motionless in the September sun. The boats hadn’t moved since the storm. Their captains could be seen standing on the bridges of their boats chatting back and forth, or playing cards to pass the time they spent suspended between locks. The result was millions of dollars in lost revenue each day.\nThe lockkeeper, then, was understandably oblivious to our boat’s arrival. He hadn’t opened or closed the locks since the storm and, until powerful dredgers cleared the water, his services wouldn’t be required with the exception of anglers and duck hunters looking to travel from one area of the canal to another. When he graciously opened the enormous steel gates, we waved, started our boat forward, and promptly ran aground and stalled out. The canal, normally 15 feet deep to accommodate passing barges, had accumulated so much silt after the storm that the water was less than a foot deep in places.\nWhat’s all this have to do with teal hunting? More than you might imagine.\n■ ■ ■\nLong before Harvey made headlines, hurricanes had pounded these same coastal shorelines—there were simply fewer humans here to suffer the effects. There were no refineries centuries ago to illuminate the night and keep petroleum products flowing. There were no suburbs, no overpasses, no seaside bars and grills, and no Intracoastal Waterway to ferry goods from one side of the Gulf to the other.\nThere were marshes.\nThis low country near the Gulf, in the days before mass human settlement, was dominated by a chain of wetlands and marshes that both fresh and saltwater species relied upon for survival. These vast areas also served as a kind of sponge, absorbing flood waters and holding excess rain until it could seep into underground aquifers, reducing erosion and protecting surrounding ecosystems from further devastation once storms had passed.\n“From an ecological perspective, tropical storms are an important form of natural disturbance in coastal wetland ecosystems,” says Dale James, Ducks Unlimited’s manager of conservation planning for the organization’s Southern region. “They aid in maintaining wetland health and structure by resetting cycles of succession, or natural plant community changes, in the ecosystem. Without periodically setting back succession, marsh can become highly vegetated with little or no value to waterfowl. We manage succession through disking, mowing, burning or herbicide applications. Hurricane-related storm surge, and saltwater intrusion to inland fresh and intermediate salinity wetlands provide the natural disturbances necessary to create more open marsh environments that provide a greater variety of food resources to benefit wintering waterfowl.”\nMarshes play a vital role in coastal ecology. It follows, then, that Ducks Unlimited’s efforts to increase wetland and marsh habitat benefits not only the birds but also the humans who rely on these areas to act as a buffer against the punishment from storms like Harvey.\nDucks Unlimited’s Texas Prairie Wetlands Project has conserved or restored more than 21,000 acres of land in 28 counties along the eastern coast of Texas. The organization has contributed $12.5 million toward the project, and Texas landowners have contributed an additional $13.7 million to fund DU’s efforts to restore vital habitat lost to agriculture and ranching over the last century. This collaboration has brought land managers, property owners, hunters and biologists together with a shared mission of improving habitat and returning it to a natural state. In the wake of Harvey, we are now beginning to understand the full scope of these projects. Despite our technological achievements we still find answers to complex problems woven into the fabric of the natural world.\nThe early indications were that the hurricane’s effects, while still quite severe, were mitigated—at least in part—by habitat that had been restored for waterfowl using hunter dollars. When I hunted Matagorda it was too soon to determine the full impact on wildlife and wetland ecosystems since some of the infrastructure needed to reach those areas had been destroyed. One bright spot for migrating waterfowl was that many of the area’s rice farms (as many as 75 percent, according to DU estimates) had already harvested their crops, so there was food available in the form of waste grain for birds that would not be able to rely on submerged aquatic vegetation damaged in the storm. Additionally, the same violent waters that swept away the aquatic vegetation also served to clear damaging invasive plant populations such as water hyacinth and giant salvinia.\n■ ■ ■\nWading through calf-deep water and guided by the reflection of starlight on the surface of the marsh, Bink led our hunting party through the murky wetland toward a levee. Southeast Texas is still warm in mid-September, and with highs in the 80s every day I knew the water moccasins that undoubtedly made their home in the swamp were active. It caused me to pause twice to examine an odd reflection on the surface of the water—errant shadow or snake? When we finally reached the island I carefully brushed away the loose grass in an area I guessed to be large enough to allow me to see any snake before it came too close. I would have liked to have turned on my flashlight, but the fear of snakebite wasn’t as compelling as the irritating mosquitoes that dogged the entire hunting party as we crossed the swamp. Turning on a light invited them to attack, and their constant droning soon made me forget about snakes as I spit and swiped at the harassing swarms. The only thing that halted their attacks was the occasional wind gust that swept across the water from the northwest.\nThe creeks and wetlands around Matagorda Island have a special place in my heart. The barrier island was the site of my first industry hunt, and I have fond memories of the time I’ve spent tucked in the tall weeds at the edge of brackish water. What I knew to be true of Matagorda before Harvey’s arrival was still true; in September, the marshes are alive with birds. Before shooting light, with the decoys still settling in the water and before I’d even loaded my gun, I could see the first twisting flight of teal rushing across the sky.\nAs daylight came and shooting time grew near I reacquainted myself with hunting these birds. Groups of four or six teal would zip across the surface of the water and vanish from sight as they dipped below the skyline. That required me to find their reflection on the surface of the water and find it quickly. The teal might drop out of sight and suddenly bank toward the decoys. If I was still blinking at the horizon and wondering where they’d gone, I was apt to miss my opportunity for a shot when the birds whistled past at close range.\nThe good news, though, is there were many birds, and one mistake did not mean an empty game bag. Teal aren’t forgiving, so it’s best to hunt where they can be found in large numbers. I missed my first shot at a low-flying bird, cursing myself for being behind before I even pulled the trigger and watching as Rafe Nielsen from Winchester sent that same bird tumbling from the sky with a well-timed shot. No matter how many times I remind myself that these birds are deceptively fast and require a good gun mount, a strong, steady swing and proper follow-through, I always seem to manage to shoot behind the first few birds of the morning.\nAs the day wore on and the sun rose over the distant tree line, delicate plovers walked on stilted legs at the water’s edge. The mosquitoes had dissipated, thankfully, and I could devote my full attention to the teal. So abundant are the marshlands of southeast Texas that, on a good day, the morning sky is never devoid of birds. As sure as we would be watching a low-flying group at our 12 o’clock position, another hunter in the line would call birds to our right. On many occasions while monitoring a flock birds ahead of us, an unseen group of teal would approach from behind and pass just out of cricket-bat range overhead. The game was simple: keep your head low, your gun close, and be ready to shoot quickly. As with hunting doves, everything happens in a hurry when chasing teal.\nMy marksmanship that day wasn’t impressive, but the number of birds was astounding. In fact, with my sub-par shooting I still managed to limit, more a testament to Bink’s ability as a guide and the region’s abundance of birds than my prowess with a shotgun. But the birds were there, and any questions I’d had about how they would fare in the wake of such a devastating disaster were answered by breakfast time.\nSeptember on the coast of Texas is teal time, and Texans pride themselves on their rich traditions. A storm wouldn’t stop that. Harvey could halt the flow of trade in the Gulf of Mexico for weeks, but the wetlands were still the same as they had been before the storm—the same as they had been for millennia prior to that. The birds we hunted that day were the offspring of teal that had been traveling this migration route since time immemorial. I realized as I sat with my back against the levee in the coming dawn how foolish it had been to underestimate the resilience of nature. The human suffering from the storm was great, but the natural world has a solution to almost every dilemma.', 'Coastal Wetlands Provide Significant Flood Damage Reduction\nRecently released report on Coastal Wetlands and Flood Damage Reduction uses industry-based risk models to assess natural defenses in the Northeastern USA\nVisit http://www.lloyds.com/coastalresilience to download the full report.\nOn the four year anniversary of Hurricane Sandy, a new study puts a dollar value on the risk reduction benefits provided by coastal wetlands in the Northeast United States. The report, Coastal Wetlands and Flood Damage Reduction, uses industry-based risk models to study the flooding and storm surge impacts of Hurricane Sandy along the US’s northeast coast.\nHurricane Sandy caused devastating flooding and become the second costliest hurricane in US history. This research finds that coastal wetlands prevented more than US$625 million in property damages during Hurricane Sandy, reducing property damages throughout the Northeast US by 10% on average. The research finds that the benefits of wetland conservation accumulate upstream: some places with few wetlands within their boundaries nevertheless benefited from the cumulative surge reduction of wetlands downstream.\nThe study also examined the benefits of wetlands through the year in Ocean County, New Jersey, and finds that areas behind existing salt marshes have 20% fewer property damages on average when compared to areas where salt marshes have been lost. Properties built on previously existing wetlands, and properties at low elevations, face the greatest risk from flooding, and therefore derive the greatest protection benefits from coastal wetlands.\nAs the likelihood and costs of hurricanes like Sandy continue to increase, coastal communities need for a more effective suite of strategies for risk reduction. Coastal wetlands and reefs provide a natural defense from flooding and storm surge, but these habitats are being degraded or lost at alarming rates. This report provides one of the few existing assessments of the economic costs and benefits of the role of coastal wetlands in reducing flood damage to properties. The report shows that coastal wetlands can reduce property damage from storms, and that these protection benefits can be readily incorporated and accounted for in the insurance industry’s risk models. This research will help inform (i) risk reduction and conservation management priorities and (ii) the development of incentives for the conservation and restoration of natural defenses.\nThis work is supported by the Lloyd’s Tercentenary Research Foundation, and was led by the University of California Santa Cruz, The Nature Conservancy, and the Wildlife Conservation Society, in association with Risk Management Solutions and Guy Carpenter and Company, with additional support from the Science for Nature and People Partnership.\nLearn more at http://www.lloyds.com/coastalresilience\nCaption for Figure 4\nPredicted increases in property losses if marshes had not been present during Hurricane Sandy (click on image to enlarge).\nSandy Census tracks show the percent changes in flood damages that would have occurred during Hurricane Sandy without coastal wetlands. Dark red areas derive the greatest protection benefits from today’s coastal wetlands.\nFrom the Executive Summary:\nThere are three key messages from this report\n- Risk industry-based tools are used to quantify the economic benefits of coastal wetlands for property damage reduction from hurricane-induced flooding in the northeastern USA.\n- It is estimated that during Hurricane Sandy, temperate coastal wetlands saved more than $625 million in flood damages and hundreds of millions of dollars in New Jersey alone. Where they remain, wetlands reduced damages by more than 10% on average.\n- In Ocean County, New Jersey, salt marsh conservation can significantly reduce average annual flood losses by more than 20%.\nWe quantify the economic benefits of coastal wetlands in reducing property damage from storms and flooding in the northeastern United States (USA). In 2012, Hurricane Sandy hit the northeastern coast of the USA causing devastating flooding and becoming the second costliest hurricane in USA history. As the likelihood and costs of hurricanes like Sandy continue to increase, there is a need for a more effective suite of strategies for risk reduction. There is great interest in the role of coastal wetlands and reefs as natural defenses in reducing some of this risk, especially where these ecosystems are being degraded or lost. While there is substantial evidence for the physical ability of wetlands to attenuate waves, there have been fewer assessments of the economic costs and benefits of their role in reducing flood damage to properties. This has limited their consideration by public agencies and private industries.\nUsing risk industry based flood models, we predict the increase in damages from Hurricane Sandy that would have occurred if wetlands had been lost. We estimate that coastal wetlands saved more than US$ 625 million in avoided flood damages from Hurricane Sandy across the northeastern USA. For census tracts with wetlands, there was on average a 10% reduction in property damages across the region. The damage reduction benefits varied by state and reached as high as 29% for Maryland. We also find that the benefits of wetland conservation accumulate upstream. Some townships with few wetlands within their boundaries nevertheless benefited from the cumulative surge reduction of wetlands downstream. Wetlands can also increase flood heights and damages to some properties by blocking the flow of water and causing it to pile up, which is similar to effects observed for artificial defenses such as seawalls or levees.\nTo examine the benefits of wetlands beyond an individual hurricane, we estimate the effects of salt marshes on annual flood losses to properties in Ocean County, New Jersey for 2000 storm events. Areas behind existing marshes are predicted to have an average of 20% less property losses than areas where marshes have been lost. These benefits of salt marsh conservation for damage reduction are much higher for properties at lower elevations.\nTogether, these studies illustrate the direct and indirect flood risk reduction benefits that coastal wetlands provide by reducing flood heights and also by decreasing exposure. We show that coastal wetlands can reduce property damage from storms and that these effects can be readily incorporated into the insurance industry’s risk models. These results help inform (i) risk reduction and conservation management priorities and (ii) the development of incentives for the conservation and restoration of natural defenses.']	['<urn:uuid:39590719-e58c-43bf-a4ea-2ec6060bdf16>', '<urn:uuid:821cb41d-3d50-464a-b22b-f01c409f1535>']	factoid	direct	verbose-and-natural	distant-from-document	multi-aspect	expert	2025-05-01T22:36:12.692263	23	81	3071
201	how many agents participated protocol division aiwolf 2021	In the Protocol Division, 34 agents participated in the initial round, and 15 finalists were selected for the final round.	['Introduction: Invitation from a Game Master｜Artificial Intelligence based Werewolf\nArtificial intelligence (AI), for which game play with humans has long been an important benchmark for research, can show the essence of intelligence and its requirements. AI has already defeated top-level human players in complete information games such as chess or Shogi. The complete information game Go currently has human players who can defeat the most advanced AI, but it seems only a matter of time before humans will be defeated by AI. In the field of incomplete games, Texas Hold’em Poker has a tradition of competition in the AI field. Real-time action video games are also spurring attempts at evaluating intelligence in real-time environments.\nCompared to the previous game-related challenges, the communication or communicative intelligence skills that are commonly used in board games and card games have not been examined. When people play board games and card games, they converse with other players, and some games are advanced through conversation as so-called communication games. Few studies in the literature have analyzed artificial intelligence in relation to such communication games. “Are You a Werewolf?” is one of these communication games.\nThe Werewolf game is conducted solely through discussion and players must exert their cognitive faculties fully in order to win. In the game, players must hide information, in contrast to perfect information games such as chess or Reversi. Each player acquires secret information from other players’ conversations and behavior and acts by hiding information to accomplish their objectives. The game highlights various problems that have not been addressed adequately in the field of artificial intelligence, such as the asymmetric distribution of player information, the use of persuasion for earning confidence, and the use of speculation for detecting fabrications.\nFollowing this, we started a project to create an “Artificial Intelligence Werewolf” (AIWolf) to play as the werewolf in place of a human player. The objective of this comprehensive project is not only to develop a game-playing algorithm, but also to develop virtual agents, real robots, and so on. To achieve this objective, there are a number of tasks that must be undertaken.\nThe collective intelligence approach is used for these tasks. To implement a collective intelligence approach, a common platform is indispensable. As described herein, we present the outline of a Werewolf platform for artificial intelligence (AI Wolf Platform), which has been developed as an open source project. We plan to hold an AI Wolf tournament in which researchers with various backgrounds can participate freely with the aim of realizing collective intelligence with the participants.\nTo achieve the above goals, we require research technologies in the following areas:\n- Multi-agent simulation\n- Machine learning\n- Language processing\n- Logic programming\n- Human–agent interaction\n- Cognitive science\nCollaboration in these areas will be required for solving Werewolf. We anticipate that the development cycles will contribute to these fields and aid in the finding of essential features on social interaction.\nSource Code for the finalist teams in the 3rd International AIWolf Competition Team Name Source Code Document toku/ICE toku.zip toku.pdf TOT TOT.zip TOT.pdf KP22 AIWolf Generator KP22.pdf SYu AIWolf Generator SYu.pdf CanisLupus AIWolf Generator CanisLupus.pdf Tomatoken AIWolf Generator Tomatoken.pdf SORA AIWolf Generator SORA.pdf Hideto AIWolf Generator Hideto.pdf HALU HALU.zip HALU.pdf Tomato Tomato.zip Tomato.pdf OKAMI OKAMI.zip … Continue reading 3rd International AIWolf Competition — Source Code and Document\nThank you for participating in the Third International AIWolf Competition. In this year, we had two divisions: Protocol Division and Natural Language Division. Final Results of the Protocol Division In the Protocol Division, 34 agents participated in the initial round, and 15 finalists were selected for the final round. The finalists played 400.000 werewolf games, … Continue reading Final Results of the 3rd International AIWolf Competition at ANAC 2021\nYou can download the game logs of the past international AIWolf contest final from here.\nThe registration site of the protocol division is now open. http://contest.aiwolf.org/en/ The test game among the uploaded agents runs at 0 AM, 6 AM, 12 PM and 18 PM UTC. You can see the results of the test games on this page.\nWe are pleased to announce the 3rd international AIWolf contest. The deadline for registration is July 1st, 2021. Please see here for the detail.\nSource Code for the finalist teams in the 2nd International AIWolf Competition Team Name Program Algorithm Description takeda 〇 〇 otsuki 〇 〇 HALU 〇 〇 J0hnDoe 〇 ○ cube 〇 ○ daisyo 〇 ○ Tomo 〇 ○ simipu 〇 ○ Udon 〇 ○ Tomato 〇 ○ wasabi 〇 ○ FoxuFoxu 〇 ○ PaSeRi 〇 … Continue reading 2nd International AIWolf Competition — Source Code\nThank you for participating in the Second International AIWolf Competition. In this year, we had two divisions: Protocol Division and Natural Language Division. In the Protocol Division, 45 agents participated in the initial round, and 15 finalists were selected for the final round. The finalists played 232.000 werewolf games, and the results are as follows: … Continue reading Final Results of the 2nd International AIWolf Competition at ANAC 2020\nWe have released AIWolf platform version 0.6.2. http://aiwolf.org/server/\nWe have released AIWolf platform version 0.6.1. http://aiwolf.org/server/\nThe 2nd International Werewolf AI Competition will be held as part of the the IJCAI-PRICAI 2020 in Yokohama, Japan. Agent submission deadline is currently set to 15th, June. Please see the competition page for details. 2nd International AIWolf Competition']	['<urn:uuid:01ca741c-5c0b-4bae-8c7d-baf325bc51d2>']	factoid	direct	short-search-query	similar-to-document	single-doc	expert	2025-05-01T22:36:12.692263	8	20	892
202	How do healthcare facilities handle end-of-life discussions with terminally ill patients, and what specific topics do they typically cover in these conversations?	Healthcare facilities conduct structured conversations about end-of-life care through trained professionals like social workers, nurses, and pastors. During these discussions, they cover several key topics including treatment preferences, quality of life decisions, and specific medical scenarios. They ask patients about their wishes regarding life-prolonging treatments, such as whether they would want to continue treatment if they couldn't walk or talk. The conversations also explore personal aspects like the patient's fears, worries about being a burden, comfort needs, and any relationships they want to mend. Healthcare providers discuss practical matters such as whether patients prefer to die at home or in the hospital, and they help patients document their wishes through advance directives. These directives detail individual treatment preferences and assign power of attorney, making them available electronically to ensure the patient's wishes are followed.	['In This Episode << SLIDE LEFT TO SEE ADDITIONAL SEGMENTS\nTERESA CLEMENTS, RN: Who or what helps you when you face serious challenges in your life?\nCURTIS NELSON: I always get comfort from Audrey, my wife.\nCLEMENTS: Of 61 years.\nCURTIS NELSON: Yes, of 61 years, yes. And then our pastors.\nCLEMENTS: So your faith is important?\nNELSON: Yes, very important.\nLUCKY SEVERSON, correspondent: Conversations like this at Gundersen Lutheran Hospital in La Crosse, Wisconsin, are what set off the nationwide outcry over the so-called “death panels.” This is Curtis Nelson, connected to a dialysis machine, with his wife Audrey and his son Dennis. Teresa Clements is a nurse guiding the discussion.\nCLEMENTS: With your particular illnesses, and you’ve got the multiple myeloma, the heart failure, and now the kidney disease, it’s difficult to predict when a complication can occur, and it can happen suddenly, and you might not be able or aware to make those decisions.\nSEVERSON: These end-of-life conversations began in the 1980s at the urging of the hospital’s medical ethicist, Bernard Hammes. He had grown alarmed after listening to staff doctors distressed about how to treat incapacitated terminally ill patients.\nBERNARD HAMMES (Clinical Ethicist, Gundersen Lutheran Health System): What does the patient want me to do? The patient now is too sick to ask, the family, when we ask the family, had no idea what the patient would or would not want, and so we were really faced with this moral or ethical dilemma.\nSEVERSON: And when the doctors don’t know what the patient or the family wants, Hammes says there’s only one thing to do.\nHAMMES: Here, anywhere in the world quite honestly, when you have a patient coming into a hospital who’s very ill, maybe dying if we don’t treat them, our assumption is that treating, attempting to prolong life is the right thing to do. And that, indeed, from an ethical, professional perspective is the right thing to do, but is it what the patient would want?\nCLEMENTS: You have a serious complication from your kidney disease, you have a good chance of living through the complication, but it’s expected you will never be able to either walk or talk or both, and you would require 24-hour nursing care. You would choose the following: to continue all treatment because living as long as possible is most important; you would stop all efforts, including dialysis to keep you alive because your quality of life is more important than your quantity; or you are not sure.\nNELSON: That would be terrible. I wouldn’t want to have that.\nCLEMENTS: So to stop all efforts then.\nNELSON: Yes, if I got into a position like that, yes.\nSEVERSON: In La Crosse, Wisconsin, 96 percent of the patients who die have gone through these advance directive discussions and designated how they would prefer to spend their last days.\nHAMMES (lecturing): This program is not trying to talk people out of treatment. This program is trying to help patients make informed decisions so that we know what they would want even in a crisis, and we can deliver the services that match their preferences.\nSEVERSON: The program has been so successful representatives from around the country now attend seminars at Gundersen Lutheran. The success is due, in part, to the backing of the Catholic and Lutheran churches. A similar program is underway in Minneapolis-St. Paul, which is supported by the head of the National Association of Evangelicals, Pastor Leith Anderson of the Wooddale Church outside Minneapolis. He says he witnessed too many families going through emotional turmoil when their loved one was dying.\nREV. LEITH ANDERSON (President, National Association of Evangelicals): For the family, that there are processes in place is wonderfully helpful because often children and spouses, they’re frightened, they don’t want to make a mistake, they don’t want to give up too soon, they don’t want to hold on too long, and if it’s been discussed, and especially if it’s been documented in writing, that is really a gift to family.\nSEVERSON: Pastor Anderson says both he and his wife have filled out advance directives, and he’s encouraged members of his congregation to do the same. The directives, he says, are biblically based, and he uses as an example the story of Jacob when he knows he is about to die.\nANDERSON: And it tells about him bringing all of his sons around him, and he gave a prepared statement to every one of them, and it was different for each one. But the Bible line in Genesis 49 says that he gave instructions. Now that’s marvelous. Here long ago was a man who knew he was going to die and gave final instructions.\nSEVERSON: Advance directives today detail individual treatment, assign power of attorney, and are available electronically. Hammes says they are not “death panels,” a description he says is “simply a lie.” He says some people choose to stay alive with any technology medical science can offer. A majority request less invasive treatments. Some, because of their religious views, are ready to meet their maker.\nCLEMENTS: If those hopes don’t come true, what else would you hope for, Curtis?\nNELSON: That the good Lord says I can come in.\nCLEMENTS: That the Lord says you can come in?\nSEVERSON: The hospital now trains social workers, nurses, and pastors to conduct these discussions. Bernard Hammes has filled out his own.\nHAMMES: I’m not making a judgment for you or for anyone else, but I think we live in a world in which we have to share resources. That’s a spiritual value for me. So if I receive medical care, and it reaches a certain stage, and it’s not going to change the outcome for me, but a lot more money could be spent, I would say, you know, the cost of this care has reached a point that I no longer feel is ethical, because other people don’t even have basic needs being met.\nSEVERSON: Although it wasn’t the original intent of Gundersen’s advance health-care planning program, there has been an additional benefit. It saves money. Typically, hospital costs for a patient’s last 6 months of life nationwide average about $31,500. At some hospitals it’s twice that amount or more. At Gundersen Lutheran it’s $22,000 because the patient spends fewer days in the hospital.\nHAMMES: Where would you rather spend your time if you had two years left to live, in the hospital going through tests and procedures? We’re putting many, many patients in this country through a lot of additional suffering and expense, some of which they’re going to have to pay for. It’s the fourth most frequent reason for families to go bankrupt.\nSEVERSON: There’s another reason hospital costs are less. Doctors here are paid a salary. Dr. Jeff Thompson is CEO of the Gundersen Lutheran Health System.\nDR. JEFF THOMPSON: In our organization and others like us, a physician gets no extra money because they do a CT scan or lab work. There’s no added incentive to put patients in the hospital.\nSEVERSON: Dr. Greg Thompson, a pulmonary critical care specialist, says these days the intensive care ward mostly treats patients who have a better chance of long-term survival.\nDR. GREG THOMPSON: Many of those patients who have the underlying terminal disease don’t even come to the intensive unit, because they have already decided that at this point in their life that’s not the level of care that they want. They want care, but not the critical care that they would receive in a critical care unit.\nANDERSON: I think that there’s a growing number of people who do not want to have a lot of tubes connected to them. I would say that increasingly I am hearing people say, “I want to die at home.” So they’re making a choice that dignity is more important than more days.\nCLEMENTS: Any other hopes for you guys?\nDENNIS NELSON: Oh, I would hope that he would get off from this, and if it is eventually going to happen, that it wouldn’t be a long, drawn out process in passing so.\nCURTIS NELSON: That’s the biggest thing. I don’t want it to have it dragged out.\nTERESA NELSON: So this is a good conversation to have.\nSEVERSON: In these discussions, talk is about practical things but often turns deeply personal.\nHAMMES: People don’t like talking about death. It’s a taboo in our society. This is a very intimate conversation. When you talk about these issues, you’re really talking, if you will, about the meaning of life, about your religious beliefs and faith, and ultimately about who you are, and that’s a little frightening to most of us.\nSEVERSON: At the end of these discussions, Hammes says he often hears the same thing from the nurses and facilitators who conduct them.\nHAMMES: What they will report to me is that what they experienced was a sacred space. What happens in families when they really get into the meaning of this conversation is they tell each other how important they are to each other.\nSEVERSON: The idea of advance directives appears to be gaining traction. Intimate discussions about the end of life are now starting to take place in hospitals around the country.\nFor Religion & Ethics NewsWeekly, I’m Lucky Severson in La Crosse, Wisconsin.', 'This article was originally published by Barbara Rubel on OpenToHope on Wednesday, October 12, 2011\nWhat is Palliative Care and Hospice?\nIf you have been told that your loved one is terminally ill, this article will help you identify palliative care, hospice, advanced care planning, Five Wishes, and questions to ask during this difficult time. Let’s first look at palliative care,which helps individuals improve their quality of life by providing prevention and relief of suffering, early identification, holistic assessment and treatment of pain, and support for physical, psychosocial, spiritual and bereavement issues (WHO, 2008). Hospice, on the other hand, offers care when curative medical treatments no longer enhance quality of life. Although Hospice is most often provided only at the very end of the terminal illness, it can be provided at any point once the patient is told they are terminally ill. The Hospice Medicare Benefit specifies the services to be provided to Medicare beneficiaries who choose to receive hospice care if they have a medical prognosis with a life expectancy of 6 months or less if the illness runs its normal course (www.hospicefoundation.org)\nWhat is Advance Care Planning?\nYou might be struggling with whether or not to tell your loved one that he or she is dying. As a hospice bereavement coordinator I helped many families break the bad news. Ira Byock, author of The Four Things That Matter Most, maintains that people who are aware they are dying, can improve relationships in their life by saying: Please forgive me, I forgive you, thank you, I love you and good-bye. In anticipation of death, advance care planning is essential if a person’s preferences for end-of-life care are to be communicated and honored.\nAdvance care planning involves decision making, expressing treatment preferences, and completing documents that communicate the patient’s values and beliefs for their health care when they can no longer speak for themselves. An important conversation is medical power of attorney which is a health care proxy or health care surrogate. It allows your loved one to name a representative to make health care decisions on their behalf should he or she become physically or mentally incapacitated. Is that person you?\nWhat Does Your Loved One Wish For?\nDo you remember as a child asking for three wishes? Well now you have an opportunity to ask for five. Five Wishes has become America’s most popular living will because it is written in everyday language and helps start and structure important conversations about care in times of serious illness. Five Wishes is available at Aging with Dignity, and will guide your loved ones who are terminally ill in speaking with their loved ones about their wishes should they not be able to speak (http://www.agingwithdignity.org). Five Wishes lets the family and doctors know:\n- Who you want to make health care decisions for you when you can’t make them.\n- The kind of medical treatment you want or don’t want.\n- How comfortable you want to be.\n- How you want people to treat you.\n- What you want your loved ones to know.\n20 Questions to Ask Your Terminally Ill Loved One\nAs a Bereavement Coordinator for hospice, I was privileged to sit at the bedside of many terminally ill patients and asked them the following questions. Look over the list and use the questions as a guide for the conversation you will have with your loved one.\n- Do you feel as though you are being including in your health care decisions?\n- What are you most afraid of?\n- What are you most worried about?\n- Do you worry about becoming a burden to anyone in particular?\n- Is there anything that is making you feel uncomfortable?\n- What is most difficult about leaving your loved ones behind?\n- What do you think will happen to your loved ones after your death?\n- Are there any relationships you want to mend?\n- What tasks do you need to complete before you die?\n- Would you prefer to die at home or in the hospital?\n- What does a good death mean to you?\n- What brings you the greatest sense of comfort?\n- What are you most proud of?\n- Do you have any regrets?\n- What cultural beliefs sustain you?\n- What is your role in the family?\n- What role has faith played during your illness?\n- Is there one thing that you want to pass along to those left behind?\n- What does your illness mean to you?\n- What is the meaning of your life?\nMy hope is that this article has helped you with some of the issues you are facing. Open to Hope has many other articles on coping with loss. Take the time to read what you can and know that you are not alone.\nFor more on Barbara Rubel and OpenToHope, see http://www.opentohope.com/20-questions-to-ask-your-terminally-ill-loved-one/']	['<urn:uuid:c9fe22a7-ba91-444e-881c-8860955cce01>', '<urn:uuid:9dfa0151-ecb3-4b8b-b29c-a1bdba616319>']	open-ended	direct	verbose-and-natural	similar-to-document	multi-aspect	novice	2025-05-01T22:36:12.692263	22	134	2370
203	adenoid anatomy clinical impact sleep apnea	Adenoids are pyramidal-shaped lymphoid tissue structures located in the nasopharynx. From an anatomical perspective, they have a complex blood supply from 6 different arteries and drain into the pharyngeal venous plexus. When enlarged, adenoids can cause significant clinical impacts, particularly obstructive sleep apnea syndrome (OSAS). This condition affects about 2% of children, especially between ages 2-5, causing interrupted breathing during sleep. OSAS can lead to serious consequences including poor school performance, learning difficulties, high blood pressure, and in rare cases, death. The primary treatment for adenoid-related sleep apnea is typically surgical removal of the adenoids.	['Adenoid, also known as the nasopharyngeal tonsil, is a mass of lymphoid tissue found in the posterosuperior wall of the nasopharynx. Adenoids, along with palatine and lingual tonsils, belong to mucosa associated lymphoid tissue (MALT) and constitute the major part of the Waldeyer’s ring. Located at the gateway of respiratory and alimentary tract, this ring of tissue is the first site of encounter with microorganisms and pathogens, therefore is considered responsible for immune protection. This article will focus mainly on the anatomy of the adenoids with their clinical relevance.\n- Lymphatic drainage\n- Arterial supply\n- Venous drainage\n- Clinical points\n- Related diagrams and images\nThe nasopharyngeal tonsil originates from the pharyngeal endoderm in the posterior midline of the nasopharynx. The development begins during the late first trimester (third month) in association with mucus glands of the pharynx and is completely formed by the seventh month of gestation. The size of the tonsil increases during the early years of childhood, but then usually begins to atrophy at the end of first decade of life.\nLocationThe adenoid is a pyramidal shaped structure composed of lymphoid tissue. The apex of this pyramid is extended toward to nasal septum, and the base sits at the posterior most wall of the nasopharynx. The adenoidal surface is inavginated by number of folds with some crypts. There is a midline pharyngeal bursa (bursa of Luschka) which extends posteriorly and superiorly. This bursa represents the site of notochordal attachment to the endoderm of the primitive pharynx.\nMicroscopically, the adenoid is covered by the same epithelium as the respiratory tract i.e. pseudostratified ciliated columnar epithelium. The epithelium covers the organ laterally and inferiorly with some small scattered patches of non keratinised stratified squamous epithelium. This epithelium also lines the series of mucosal folds. Between the upper surface and the adjacent sphenoid and occipital bone there is a layer of connective tissue (hemi-capsule) made up of reticular fibers. This connective tissue covering sends septa inside the lymphoid parenchyma and subdivide it into 4-6 lobes. Many sero-mucous glands are present within the connective tissue with their ducts extending through the lymphoid parenchyma.\nThe adenoid is supplied by the:\nThe lymphatic drainage of the adenoids is to the pharyngomaxillary space and retropharyngeal lymph nodes.\nArterial supplyThe adenoids receive their blood supply from 6 arteries:\n- Ascending pharyngeal artery: This artery arises from the inferior part of the external carotid artery. It has anteriorly directed pharyngeal branches which supply the pharynx and associated structures.\n- Ascending palatine artery: This is a branch of the facial artery, and passes superiorly between the styloglossus and stylopharyngeus muscles. In the superior part of its course, it passes between the superior constrictor of the pharynx and the medial pterygoid muscle.\n- Tonsillar branch of the facial artery: This branch emerges from between the internal pterygoid muscle and the styloglossus muscle. The artery will also continue to enter the palatine tonsil and posterior most section of the tongue.\n- Pharyngeal branch of the maxillary artery: The maxillary artery is the seventh branch of the external carotid artery. The pharyngeal branch is a branch from its third section.\n- Artery of the pterygoid canal: This is another branch of the third section of the maxillary artery, and supplies the superior part of the pharynx and the auditory tube.\n- Basisphenoid artery, branch of the inferior hypophyseal arteries, supplies the bed of the adenoid\nThe venous drainage is via the internal submucous and external pharyngeal venous plexus. After emerging from the lateral surface of the tonsils, draining veins join the paratonsillar veins which pierce the superior constrictor to join the pharyngeal venous plexus. They may also drain into the internal jugular and facial veins.\nIn certain cases, the adenoids can become infected in young children and do not atrophy significantly. Infections can also cause the adenoids to remain swollen, and enlarged, even when the infection is gone. This enlargement can affect nasal breathing, resulting in a nasal voice, and mouth breathing. They can also cause problems with sleep, and cause apneoic episodes or restlessness. In this situation, the patient may require an surgical removal of the adenoids to clear the obstruction.\nEustachian tube dysfunction\nThe Eustachian tube connects the middle ear to the nasopharynx. Enlarged and inflamed adenoids may block this passageway and can cause infection of the middle ear i.e. otitis media. A blocked tube sucks the tympanic membrane inside by creating a negative pressure in the middle ear cavity leading to mild to moderate hearing loss.\nObstructive sleep apnoea\nThis condition usually occurs in children during periods of sleep due to the blockage in the airways. Palatine tonsils or the adenoids may grow larger to obstruct the airways. There are episodes of blockage throughout the night during sleep, resulting in an interrupted sleep pattern. If the child has shown clear evidence of apnoeic episodes whilst asleep, then a tonsillectomy with concurrent adenoidectomy may be the best course of action.', 'Snoring, Obstructive sleep apnea, OSAS, Adenotonsillar hypertrophy\nIntroduction to sleep apnea:\nParents are quick to mention some things to their pediatrician: fevers, seizures, and bleeding. Snoring is another important symptom that your child’s doctor needs to know about, though it often goes unreported.\nAny child who snores may have obstructive sleep apnea, and may not be getting adequate sleep.\nNot all kids with sleep apnea snore. Even when they do, sleep apnea is often overlooked. Instead, the child may be diagnosed with a behavioral disorder — most commonly ADHD.\nWhat is sleep apnea?\nMost people make some quiet snoring noises when they have (or are recovering from) a cold but this quickly resolves after the cold. Some people snore even when not ill, and some snore loud enough that others can easily hear them. In these cases, snoring may be the sign of obstructive sleep apnea syndrome (OSAS), where there is prolonged partial blocking, or intermittent blocking, of breathing during sleep. The obstruction is usually caused by large tonsils or adenoids, which may be temporarily enlarged by infection or allergies.\nChildren with sleep apnea do not get sound sleep. They may also get suboptimal oxygen to the brain at night. Obstructive sleep apnea can have a serious negative impact on a child’s intellect and behavior.\nOSAS can cause growth problems. It has also been linked to ADHD, poor school performance, learning difficulties, bedwetting, high blood pressures, lung disease, heart disease, and rarely even death.\nOSAS is different from primary snoring (PS), the name given to snoring that doesn’t cause sleep disruption or breathing problems. Primary snoring is more common than OSAS.\nWho gets sleep apnea?\nOSAS occurs in about 2 percent of children. The peak age is 2 to 5 years old, but it can occur at any age.\nIn older children and adults, it is more common among the obese. It is also common in those with sickle cell disease, Down syndrome, birth injuries, or any other condition that might narrow the upper airway.\nWhat are the symptoms of sleep apnea?\nClassically, those with sleep apnea snore quite loudly for a bit, then are silent (sometimes not appearing to breathe), then snort briefly, move about, and resume snoring. If snoring is accompanied by nighttime breathing difficulty and pauses in breathing, then it may well be sleep apnea.\nHowever, many children with OSAS do not follow this classic pattern. OSAS and PS cannot be reliably distinguished from each other based on the symptoms alone.\nOther common symptoms of sleep apnea include mouth breathing, restless sleep, difficulty paying attention during the day, decreased academic performance, oppositional behavior, and restlessness.\nIs sleep apnea contagious?\nHow long does sleep apnea last?\nChildren often outgrow OSAS within several years.\nHow is sleep apnea diagnosed?\nSnoring should be brought to the attention of your pediatrician. You might want to make a cassette tape of your child’s sleep noises to bring with you.\nOSAS and PS cannot be reliably distinguished from each other based on the physical examination and history alone. Other tests must be used. A sleep study is the gold standard test for telling the difference. Thus, snoring needs to be reported to the doctor, and when snoring lasts longer than a brief respiratory infection, or fails to respond to allergy treatment, it deserves thorough evaluation. Often pediatricians enlist the help of ear-nose-and-throat, neurology, or pulmonary specialists to help distinguish between the two.\nHow is it treated?\nBecause enlarged tonsils and adenoids usually cause the obstruction, removing them can usually solve the problem.\nSometimes the obstruction is treated with gentle positive air pressure in the airway at night – nasal CPAP (continuous positive airway pressure).\nSupplemental oxygen, and correction of anemia may provide additional help.\nDecongestants, steroids, antibiotics, or other medicines might reduce snoring caused by enlarged tonsils or adenoids in PS but are unlikely to be of much help with true obstructive sleep apnea.\nHow can it be prevented?\nEarly treatment of primary snoring might prevent the cycle that leads to obstructive sleep apnea. Preventing or treating obesity and nasal congestion can also help protect children from OSAS.\nRelated A-to-Z Information:\nAdenovirus, Allergies (Allergic Rhinitis), Anemia (Low hemoglobin), Asthma, Attention Deficit Hyperactivity Disorder (ADHD),Bronchiolitis,Cerebral Palsy, Cleft Lip and Palate, Common Cold, Congenital Heart Disease, Cough, Croup, Depression, Down Syndrome, Enuresis (Bedwetting), Epilepsy, Gastroesophageal Reflux, Head Banging,Obesity, Pertussis (Whooping cough), Sudden Infant Death Syndrome (SIDS), TonsillitisReviewed by: Khanh-Van Le-Bucklin, Liat Simkhay Snyder\nLast reviewed: November 14, 2013']	['<urn:uuid:ec52f396-3759-46d9-9c60-a174fe506497>', '<urn:uuid:9b43af25-b707-4570-8bd6-f922846db900>']	open-ended	with-premise	short-search-query	similar-to-document	multi-aspect	expert	2025-05-01T22:36:12.692263	6	95	1566
204	countries sharing land border eritrea location	Eritrea is located along the inlet of the Red Sea and shares borders with Sudan, Ethiopia, and Djibouti.	"['This unleavened flatbread hails from Eritrea and it\'s a daily household staple here. It is so simple to put together—it is a combination of just flour, water, and salt at its base.\nI love the free-form nature of this bread. Since you shape it in the hot pan (move quickly and make sure to not burn your fingers!), it develops a wonderfully irregular texture on the outside, charred in some places and soft in others, making it perfect for mopping up stews and long-cooked vegetables. It\'s also delicious straight out of the pan drizzled with a little honey or spiced ghee.\nWays to Adapt this Recipe\nOnce you master the basic recipe, you can add a few pinches or warm spices to the dough. Any of the spices or spice mixes below will work well here.\n- Berbere, an Ethiopian spice blend\nTips for Making Kicha\nIt might seem intimidating to shape the dough in the hot pan, but there are some step you can take to do it successfully. Once you make Kicha a few times the approach will seem like second nature:\n- Wet your fingers\n- Work gently but quickly to press the dough out into a circle around the warm pan\nWhat to Serve with Kicha\nThis flatbread is endlessly versatile. You can enjoy it for breakfast with yogurt, eat it along with stewed greens, stew or just as a snack with butter.\nA Little Bit about Eritrea\nEritrea is located along the inlet of the Red Sea and shares borders with Sudan, Ethiopia, and Djibouti. It won its independence from Ethiopia in 1993 after a 30-year war. It has nine recognized ethnic groups. The food is heavily influenced by Indian, Arab and Ethiopian cultures.\nAbout “In BiBi’s Kitchen”\n“In Bibi’s Kitchen,” written by Somali chef Hawa Hassan with food writer Julia Turshen, explores not only the recipes from eight African countries that touch the Indian Ocean but also the women, communities, and cultures of the region. This book is as valuable in the kitchen as it in the living room casually read page by page. She peppers the book with facts about the different countries and stories of the women who created some of the recipes. It’s the kind of cookbook you keep within arm’s reach so you can reference it often.\nMore Bread Recipes\nKicha (Eritrean Flatbreads) from “In Bibi’s Kitchen""\nRecipe Note: Recipe reprinted with permission from In Bibi’s Kitchen by Hawa Hassan with Julia Turshen, copyright © 2020. Published by Ten Speed Press, a division of Penguin Random House, LLC.\n- 1 1/2 cups whole wheat flour\n- 1 cup all-purpose flour\n- 2 teaspoons kosher salt\n- 1 1/2 cups warm water\n- 2 tablespoons canola oil, divided\nMix the flours, salt, and water:\nPlace the whole wheat and all-purpose flours and salt in a large bowl and whisk well to combine. Using your hands, mix in the water. The batter will be like a very thick pancake batter.\nLine a plate with paper towel and heat a nonstick skillet with oil:\nLine a plate with paper towels and set aside. Set a 12-inch nonstick skillet over medium heat and add 1 tablespoon of the oil, tilting the pan so the oil lightly greases the bottom of the pan.\nCook the flatbread:\nOnce the oil is hot, add half the dough to the skillet and use wet fingertips to gently and carefully press the dough into a wide circle that covers the surface of the skillet.\nCover the skillet and cook until the top of the dough is glossy and the underside is golden brown, about 3 minutes. Carefully flip the bread over, cover, and cook until the second side is browned, another 2 to 3 minutes.\nTransfer the flatbread to the prepared plate, adding the remaining 1 tablespoon oil to the pan, and repeat the process with the remaining dough.\nServe and store leftovers:\nServe immediately while the breads are warm or let cool to room temperature. Leftover breads can be stored in a plastic bag at room temperature for a day and rewarmed in a skillet over low heat.']"	['<urn:uuid:3ad7b264-be74-470c-91c9-d51fedaeabda>']	factoid	direct	long-search-query	distant-from-document	single-doc	novice	2025-05-01T22:36:12.692263	6	18	690
205	What specific steps do experts recommend for California communities to enhance their resilience and survival capabilities in case of a major seismic event?	Experts recommend that all Californians should ensure their communities are prepared to sustain themselves for three days after a major quake. This involves having family preparedness plans and creating guidelines through collaboration between fire and police departments, county agencies, city officials, and residents. These guidelines can be distributed through city council meetings, direct mail, local paper articles, neighborhood watch meetings, and local groups like baseball leagues, soccer leagues, and YMCA. Additionally, city engineers can provide advice on areas likely to sustain higher damage levels based on structure and soil issues.	"['APHA\'s 2010 Get Ready Scholarship: Excerpts from winning essays\nSix students — at the high school, undergraduate and graduate college levels — were chosen from 900 applicants as the winners of APHA\'s 2010 Get Ready Scholarship. Below are excerpts from the winning essays.\n• Leah Wight— Golden Valley High School, Merced, Calif. (high school level)\nGeographically, the most probable natural disaster to occur where I live would be an earthquake. I live in the Central Valley of California, so I have experienced a mild earthquake or two. But I certainly haven\'t experienced anything even close to the same magnitude as the Haiti earthquake. This recent catastrophe has urged me to rethink my own family\'s earthquake disaster plans....Earthquake prevention is impossible, and earthquake prediction is near impossible. The only way we can protect ourselves is through planning and preparing. Earthquakes can shatter windows, destroy houses, annihilate entire cities, but they cannot eradicate my earthquake preparedness.\n• Courtney Farr — Robert L. Patton High School, Morganton, N.C. (high school level)\nGreat floods in the valley\nI live in the Foothills of North Carolina and happen to be in the direct vicinity of the large Catawba Valley. We do not receive a tremendous amount of precipitation, but when we do the rain usually comes in such large quantities, flooding seems almost inevitable...Based on my experiences and watching the devastating effects in my community, I am now more aware of the weather expected for my area. If another natural disaster such as a dangerous flood were to occur again, this time I would make sure to have a safe and effective plan and follow through to the best of my abilities...Ultimately, you have to know there is no way to stop a natural disaster, just be prepared for it the best you can and take the necessary precautions.\n• Brittany Voorhees — Holy Names University, Oakland, Calif. (undergraduate level)\nEarthquake reality: The first 72 hours\nLiving in Northern California, and the San Francisco Bay area specifically, there is always the potential for a significant seismic event. This is particularly true in both the area I live and the university I will be attending this fall as a junior. Living and going to school on two major active earthquake faults presents an ever-present awareness and challenge to prepare for the inevitable. The thought that ""it will never happen here,” simply is not a viable approach to follow. With this awareness comes the need to be prepared to survive for at least 72 hours without assistance from outside sources. This requires food, water, medical necessities and information on friends and fellow students on campus.\n• Delaney Moore — Indiana University-Purdue University Indianapolis, Indianapolis, Ind. (undergraduate level)\nWinter is the season for cold skies and warm, bacteria-filled buildings. People constantly find themselves overcome with illness. This is the time of the year when hygiene is most important, especially in a dorm setting where students are in close corridors. Preparation for the flu season as well as constant awareness and care throughout the flu season will result in less illness and life-changing habits. In the incident of an emerging epidemic, such as the recent H1N1 (outbreak), taking precautions is vital for protection. It\'s important to educate, supply and enforce hygiene behavior. At a college campus, many actions can be taken.\n• Tazeen Dhanani — George Mason University, Fairfax, Va. (graduate level)\nPrevention, preparation and partnership to fuel community readiness\nPublic health emergencies like natural disasters and infectious disease outbreaks are inevitable. Events such as fires, floods, earthquakes and hurricanes are disasters that people usually have very little to no control over, yet these disasters have the most impact on its victims and others indirectly affected by them...However, whether it is a devastating earthquake that affects the entire global community or a small house fire that (displaces) only a single family, the need for planning well in advance of these disasters will most effectively serve the victims\' needs. Having a plan and putting that plan into action during crises will prepare communities on a scale far superior and with more efficacy than having no plan at all.\n• Kristen Paz — Pepperdine University, Malibu, Calif. (graduate level)\nEarthquakes: Prepping for the aftermath of California’s faults\n...All Californians should ensure that their communities are prepared to sustain themselves for three days in the event of a major quake. Each family should have a preparedness plan. Creating guidelines on how to prepare should be a consolidated effort of the fire and police departments, county agencies, city officials and residents. Distributing these guidelines can be accomplished at city council meetings, via direct mail pieces and articles in local papers, neighborhood watch meetings and through local groups such as baseball and soccer leagues and YMCA. City engineers can advise on which areas are more likely to sustain higher levels of damage as they have a greater understanding of possible structure and soil issues.\nReturn to main Get Ready Scholarship page']"	['<urn:uuid:541031ad-c63e-4763-9877-dcf9aa2cd4b5>']	open-ended	direct	verbose-and-natural	distant-from-document	single-doc	expert	2025-05-01T22:36:12.692263	23	90	827
207	What was the increase in students walking to school in Hanoi?	A pilot of the ASRTS in Hanoi resulted in a 650 percent increase in the number of students walking to school in the morning.	"[""Vietnam: Livable Cities Project\nHealthBridge Vietnam (HBV) focuses on making urban neighbourhoods more livable and conducive to healthy lifestyles. Its three main areas of work are:\nAccess to Parks and Public Spaces – The number of safe, accessible and fun public spaces in Vietnamese cities has been steadily decreasing, while the public is increasingly demanding that governments create and maintain public spaces. However, without a clear strategic vision, many city governments lack the resources and capacity to develop public spaces to meet these demands. HBV’s activities include research and pilot projects, working with local groups and officials in the cities of Hanoi, Hoi An and Hue to develop clear strategies for developing and maintaining public spaces.\nAccess to Healthy Transportation – Motorcycle use has rapidly become the main mode of transportation in Hanoi and the most common way to take primary school children to and from school. HBV, with local partners in Hanoi, is working to develop safe routes with the goal that more children will be walking to school on a regular basis.\nPreserving Local Public Markets – As a result of increasing modernization, the number of local public markets in Hanoi has been steadily decreasing. They are being replaced by supermarkets, shopping malls and commercial centres, resulting in decreased access to fresh fruits and vegetables throughout the city, especially for the urban poor. HBV’s activities including raising awareness among decision-makers about the important role that fresh markets play in the health and economy of the city. Research, campaigns and workshops are being organized to create the support necessary to protect and preserve the local public markets.\nKey successes to date include:\n- Development of the HoiAn Parks Master Plan, which will see 79 new playspaces for children by 2020 and ensure that every child can walk to a playground close to home;\n- In 2013 the Hanoi government announced they would stop replacing markets with commercial centres. We estimate that approximately 2700 vendors’ livelihoods were saved and the approximately 279,000 people who shop at these markets continue to be able to buy healthy fresh food close to home;\n- A pilot of the ASRTS in Hanoi resulted in a 650 percent increase in the number of students walking to school in the morning.\n- Action centre for city development\n- Urban Development Agency, Ministry of Construction\n- Vietnam Women’s Museum\n- Fresh Studio\n- Hue Planning Institute\n- Vietnam Urban Planning and Development Association\n- Institute National de Recherche Scienctifique de Québec\n- Institute of Sociology\nExpected results include increased numbers of:\n- Pedestrian improvements;\n- Safe routes to school;\n- Children walking to school;\n- Policies on parks and public spaces at the city level;\n- Parks, and improved quality of parks;\n- Children playing in parks;\n- Girls playing in parks, and\n- A decreased number of fresh markets being redeveloped.\nHanoi at a Cross-Roads: Streets for People or Cars?\nAn introduction to a practical framework to support healthy public transit, which can be adopted for Hanoi: the 3D approach\nSummary – English | Vietnamese\nHanoi - Fresh markets, a way of life and public health under threat, HealthBridge. Presented as Key-Note lecture at Public Forum “Public Markets in the Corporate City” in Hanoi March 2011. Published in Vietnamese\nUrban Planning Journal (Tap Chi Xay Dung) 2011\nSummary – English | Vietnamese\nFull Document – English\nUrban development trends in Hanoi & impact on ways of life, public health and happiness. Livability from a Health Perspective, HealthBridge. Presented at Conference: Hanoi Millennium – City Past and Future Organized by UN-Habitat and Global Research Center Hawaii, 12-13 October 2010, Hanoi. Published in Vietnamese Urban Planning Journal (Tap Chi Xay Dung) 2010 - English\nSanders, P., Zuidgeest, M., and Geursd, K. Liveable streets in Hanoi: A principal component analysis. Habitat International, 2015.\nDaniel, K. et. al. Campaigning to save market women's livelihoods in Hanoi: experience from HealthBridge. Gender and Development, 2015.\nProject brochure, in Vietnamese - Giới thiệu Chương trình Thành phố Sống tốt tại Việt Nam""]"	['<urn:uuid:4e6b8899-69ea-40c4-80af-262b1cb623e4>']	factoid	with-premise	concise-and-natural	similar-to-document	single-doc	expert	2025-05-01T22:36:12.692263	11	24	669
208	What should teachers prepare before starting an afterschool lesson?	Teachers need to gather and organize all required materials, potentially sort them for students or assign materials managers, review any necessary content or instructions, develop discussion questions, prepare props in advance, plan how to divide students into effective groups, and consider if additional adult help is needed. They should also think about student learning goals and how to evaluate outcomes.	"['Practice in Action\nWriting activities can include learning and practicing new vocabulary, journal writing, conducting interviews, or developing storylines. The best writing activities go hand in hand with reading activities because this approach helps to further develop language skills.\nThere are a variety of ways to capitalize on children\'s enthusiasm for writing and communication. Journal writing, writing workshops, newsletter production, or pen pal projects are all good options for afterschool. When working with very young students, invite them to tell you a story about a topic of interest. Write down each story and read it back to them. For beginning writers, ask students to choose words or characters from stories they are reading. Even if they are not sure of correct spellings, encourage students to sound out words and try to write them out and illustrate their meanings. Encourage students to keep word banks for future writing projects.\nFor a large group of students, older students, or for students with different skill levels, journaling, letter writing, and interviews can engage students in literacy activities in topics of their choice. Ask for student volunteers who are willing to read drafts of their writing, and then have their peers review and offer helpful suggestions. Encourage students to revise their work, just like in a writer\'s workshop. Finally, display and celebrate completed student work.\nAfterschool programs provide a perfect opportunity for students of different levels and abilities to write informally. Engaging activities and regular practice tend to increase students\' desire to write. Writing plays an important role in learning. Through writing, students form and develop ideas, make sense of their own experiences, and present their understanding in relevant ways. Creating and sharing written work provides an opportunity for students to tell their stories, see themselves as authors, and begin to understand the qualities of good writing.\nFor English language learners, writing ability is closely tied to literacy experiences in their native language. Students with minimal literacy in either their home language or in English may need to be taught about the practical purposes of written language. For ELLs with literacy in the primary language, transfer of writing ability is influenced by the similarities and differences between writing systems, such as alphabetic (e.g., Spanish) and logographic (e.g., Japanese). Some ELLs may be literate in alphabetic writing systems that use letters and print conventions that are very different from English, such as Arabic or Thai. Explicit instruction in writing conventions and text structures is crucial for ELLs learning to write fluently in English.\nPlanning Your Lesson\nGreat afterschool lessons start with having a clear intention about who your students\nare, what they are learning or need to work on, and crafting activities that engage students while supporting their academic growth. Great afterschool lessons also require planning and preparation, as there is a lot of work involved in successfully managing kids, materials, and time.\nBelow are suggested questions to consider while preparing your afterschool lessons.\nThe questions are grouped into topics that correspond to the Lesson Planning\nTemplate. You can print out the template and use it as a worksheet to plan and\nrefine your afterschool lessons, to share lesson ideas with colleagues, or to help in professional development sessions with staff.\nLesson Planning Template (PDF)\nLesson Planning Template (Word document)\nWhat grade level(s) is this lesson geared to?\nHow long will it take to complete the lesson? One hour? One and a half hours? Will\nit be divided into two or more parts, over a week, or over several weeks?\nWhat do you want students to learn or be able to do after completing this activity? What skills do you want students to develop or hone? What tasks do they need to accomplish?\nList all of the materials needed that will be needed to complete the activity.\nInclude materials that each student will need, as well as materials that students\nmay need to share (such as books or a computer). Also include any materials that students or instructors will need for record keeping or evaluation. Will you need to store materials for future sessions? If so, how will you do this?\nWhat do you need to do to prepare for this activity? Will you need to gather\nmaterials? Will the materials need to be sorted for students or will you assign students to be ""materials managers""? Are there any books or instructions that you need to read in order to prepare? Do you need a refresher in a content area? Are there questions you need to develop to help students explore or discuss the activity? Are there props that you need to have assembled in advance of the activity? Do you need to enlist another adult to help run the activity?\nThink about how you might divide up groups―who works well together? Which students could assist other peers? What roles will you assign to different members of the group so that each student participates?\nNow, think about the Practice that you are basing your lesson on. Reread the\nPractice. Are there ways in which you need to amend your lesson plan to better\naddress the key goal(s) of the Practice? If this is your first time doing the activity, consider doing a ""run through"" with friends or colleagues to see what works and what you may need to change. Alternatively, you could ask a colleague to read over your lesson plan and give you feedback and suggestions for revisions.\nWhat to Do\nThink about the progression of the activity from start to finish. One model that\nmight be useful—and which was originally developed for science\neducation—is the 5E\'s instructional model. Each phrase of the learning\nsequence can be described using five words that begin with ""E"": engage, explore, explain, extend, and evaluate. For more information, see\nthe 5E\'s Instructional Model.\nOutcomes to Look For\nHow will you know that students learned what you intended them to learn through this\nactivity? What will be your signs or benchmarks of learning? What questions might you ask to assess their understanding? What, if any, product will they produce?\nAfter you conduct the activity, take a few minutes to reflect on what took place.\nHow do you think the lesson went? Are there things that you wish you had done differently? What will you change next time? Would you do this activity again?\nMost afterschool programs have at least one digital camera. However, if your program does not, digital cameras may be purchased for as little as $100, and disposable digital cameras for less than $15. Digital storytelling, a writing activity that engages multiple senses and addresses many learning styles, gives students a way to bring their words to life with images and sound. For more information, check out the following Web sites:\nTeaching Digital Photography: Showing Kids How to See With the Camera\'s Eye http://www.youthlearn.org/activities/teaching-digital-photography-showing-kids-how-see-cameras-eye\nEducational Uses of Digital Storytelling http://digitalstorytelling.coe.uh.edu/\n- Write Source: Writing Topics (http://www.thewritesource.com/writing_topics/)\nWriting topics by grade level for grades 1-12.\n- Postcard Geography (http://pcg.cyberbee.com/)\nStudents can learn about geography while polishing their writing skills in this postcard exchange project. Includes links to standards and possible extensions.\n- The Write Site (http://www.writesite.org/html/oti.html - This site may no longer be available. )\nDesigned for Ohio middle school students, this project encourages students to take the role of reporters and editors to research, write, and publish their own newspapers.\nFitzgerald, J., & Shanahan, T. (2000). Reading and writing relations and their development. Educational Psychologist, 35(1), 39-50.\nNational Council of Teachers of English. (2008). Writing Now.\nUrbana, IL: Author. Retrieved June 23, 2009, from (http://www.ncte.org/library/NCTEFiles/Resources/PolicyResearch/WrtgResearchBrief.pdf).\n- Fountas, I. & Pinnell, G. (1996). Guided reading. Portsmouth, NH: Heinemann. A comprehensive resource for implementation of guided reading activities\n- National Research Council. (2000). Starting out right: A guide to promoting reading success. Washington DC: National Academy Press.\n- Braunger, J. & Lewis, J.P. (1997). Building a knowledge base in reading. Portland, OR: Northwest Regional Educational Laboratory. This synthesis of research on how children learn how to read provides a baseline for educators and policymakers to consider in helping all children to meet higher standards.\n- Novick, R. (2002). Many paths to literacy: Language learning and literacy in the primary classroom. Portland, OR: Northwest Regional Educational Laboratory. This resource provides guidance on selecting children\'s books, and specific strategies to build comprehension from emergent literacy to independent reading.\n- Curtis, M. & Longo, A. (1990). When adolescents can\'t read: Methods and materials that work. Cambridge, MA, Brookline Books.\n- RMC Research Corp. (2001). Put reading first: Helping your child learn to read. A parent guide. Preschool through grade 3. Washington, DC: National Institute for Literacy.\nDescribes the kinds of early literacy activities that should take place at school and at home to help children learn to read successfully. Designed for parents, based on the findings of the National Reading Panel.\n- Armbruster, B.B., Lehr, F., & Osborn, J. (2001). Put reading first: The research building blocks for teaching children to read, kindergarten through grade 3. Washington, DC: National Institute for Literacy. Summarizes what researchers have discovered about how to teach children to read successfully. It describes the findings of the National Reading Panel Report and provides analysis and discussion in five areas of reading instruction: phonemic awareness, phonics, fluency, vocabulary, and text comprehension.']"	['<urn:uuid:8e72f196-56ca-4d24-b070-863d74a25cc8>']	open-ended	direct	concise-and-natural	similar-to-document	single-doc	novice	2025-05-01T22:36:12.692263	9	60	1542
209	why earth domes good for growing plants	Geodesic greenhouses are superior for growing plants because their uniform and curving surface absorbs heat and light consistently, providing maximum sun exposure throughout the day. The high ceiling promotes better air circulation and even temperatures, while minimal surface area eliminates cold spots.	['The most efficient greenhouse designs aren’t the traditional house-like structures. Geodesic or dome-like structures are far more effective, with even NASA and Tesla incorporating them when planning for permanent structures in the moon or other planets.\nSpace Age Design and Structure\nFrom the biospheres of the Eden Project in the UK and the Climatron in the Missouri Botanical Garden to Elon Musk’s envisioned colony in Mars, geodesic domes or geodomes are considered to be some of the most viable and efficient structures to nurture life. They have a very solid structure, with each connecting joint reinforcing the whole structure and distributing stress to a larger area. The curved nature of the dome also makes it more resilient to heavy winds and snow. The dome-like shape gives geodomes a high volume to area ratio, giving it more space than the usual rectangular structure. Even with their higher volume, geodomes have 30-40 percent less surface area than rectangular buildings, allowing temperatures inside to remain regulated and preventing heat loss during winters.\nGeodomes as Greenhouses\nGeodesic greenhouses are quite uncommon, but serious gardeners will opt for one if they require a greenhouse with higher heat output and retention. A geodome’s uniform and curving surface absorb heat and light consistently, giving your plants maximum sun exposure throughout the day. The high ceiling promotes better air circulation, evening out the temperatures within the dome. With a minimal surface area and no edges for snow to accumulate, your dome will retain heat and eliminate cold spots. You can extend your growing season or grow crops that require higher temperatures. The bigger volume also allows you to grow more plants or perhaps bigger plants and small trees.\nA geodome’s uniform surface distributes sunlight more efficiently than standard greenhouses. Your crops will grow at a uniform rate, with little variation in size or appearance. Geodomes are easy to maintain; damage to one panel is less expensive to repair since you’ll only be replacing a small section instead of a whole wall panel in case of damage. It also allows for easier couplings with an existing structure, and it can easily be connected through an existing doorway if you want a conservatory-like structure.\nA Few Disadvantages\nA goedome’s unique structure might cause a few problems when applying for a permit. Your local homeowners’ association might not understand what it is or consider it too eye-catching for the neighborhood. Geodomes also run a bit hotter than standard greenhouses. While this makes them ideal for winter months or when raising peppers, tomatoes, and melons, the summer heat can get stifling for your plants. You’ll need a cooling solution for your ordinary crops. A few well-placed blinds, a few vents, or maybe an integrated pond within your greenhouse should do the job.\nGeodesic greenhouses outperform standard greenhouses in almost every aspect of growing plants. They allow you to plant more crops, make use of the sun more efficiently, and retain more heat during the winter. If they’re good enough tosustain life on another planet, they should do well in your backyard.']	['<urn:uuid:426f5400-96eb-4049-b4aa-4a3f7a8b73e9>']	factoid	direct	short-search-query	distant-from-document	single-doc	novice	2025-05-01T22:36:12.692263	7	42	509
210	gary atkinson bill bentley music business experience compare	Gary Atkinson and Bill Bentley had different paths in the music business. Atkinson started as a blues fan and collector from age 13, later working in marketing and sales for magazines, and eventually becoming an agent for blues artists before acquiring Document Records in 1999-2000. Bill Bentley had a more diverse career in the music industry, serving as music editor at publications like Austin Sun and L.A. Weekly, forming a band with notable musicians, and spending 20 years at Warner Brothers Records handling major artists like Los Lobos, Elvis Costello, and the Red Hot Chili Peppers.	"['Interview with Gary Atkinson of Document Records\nGary Atkinson is the current owner of Document Records, a label that specializes in hard-to-find Blues recordings.\nDocumenting our past: Interview with Document Records’ Gary Atkinson Part I\nDocument Records is providing an important service to all of humanity.\nDocument is doing what most American record labels have failed to do: Helping to preserve the rich cultural history of the United States, and carry on the rich legacy that this country has contributed to musical innovation. Document is committed to keeping the music of black culture from the early 20th century alive and available.\nAll of the label’s nearly 900 titles are in print, and available to the public. Document has a treasure trove of music that is endless in depth. The releases of their artists are meticulously catalogued and released in chronological order. They do not skip any selections, and their goal is to make the most possible music available to the public.\nThe current owner of Document is Gary Atkinson, who runs the label with his wife Gillian. Atkinson has been a lifelong fan of the music and was indoctrinated to blues culture from an early age.\n“My father was a jazz and blues fan, so I was very aware of everyone from King Oliver to Big Bill Broonzy,” he said. “When I was only about 13, I had an older brother who also became interested in the music, and he was going out and watching various musicians playing both acoustic and electric blues. The combination of my father’s records and brother’s records ended up inspiring me to get involved. I then began to play the guitar, and collect records, I amassed a pretty decent-sized collection of records over the years.”\nAtkinson’s musical tastes led him to be a bit of misfit when it came to popular culture.\n“The strange thing is when I was 13 and heavily into the likes of Blind Willie McTell and Barbecue Bob, guys in school were liking Queen and Led Zeppelin. I was into names like Black Ace, Kokomo Arnold, and Memphis Minnie among others. Consequently, school lunch time could be a very lonely experience.”\nAtkinson said he was first introduced to Document in his teens, while looking for records.\n“I was buying LP’s at the time, things from (record labels like) Origin, Biograph, and Yazoo,” he said. “There was a peculiar record label called Roots, which had nothing but track listings and a strange address in Austria. The whole thing was being produced and compiled by a name, Johnny Parth. I was around 13 at the time, and if someone said to me in years to come, ‘you will own this company,’ I would’ve been amazed. I mean I’m still amazed now.”\nAtkinson eventually began doing work in marketing and sales at various magazines around his hometown. Around 1987 he left his hometown, and became an agent for some blues artists from the states. He also began to do review work for different magazines and record companies, one of which was Document.\n“So I struck a relationship there,” he said. “In the year 2000, 1999, the former owner of Document offered the company to me.”\nAtkinson was a little shocked at the offer, but immediately jumped at the opportunity.\n“In his broken English, Johnny (Parth) asked me, ‘Do you want everything?’” Atkinson said. “By that time I had amassed quite a collection of Document CD’s, so I just assumed he meant develop the whole collection. So I said, ‘Well it’s OK Johnny, I got quite a lot of it.’ And he said, ‘No, no, I mean everything, all of it.’ I said, ‘Well you know I’ll just take it as it comes along, that’s fine.’ Well the penny dropped, and I realized that he was actually offering me the whole company, and he gave a price. I instantly said, ‘yes.’”\nThe irony that a British label holds almost all of this American music is not lost on Atkinson.\n“Yes, I suppose it is a very big catalogue,” he said. “Sometimes labels are sized by their catalogue depth. If an independent has something like 300 or 400 titles in their catalogue they’re deep in the well. Document has now close to 900 titles, and something like 22,000 to 23,000 tracks.”\nAtkinson credits Parth for blazing the trail, stating that “what Johnny did was basically a step ahead of what a lot of the guys were doing back in those days, in the ’60s.”\n“The music was not so readily available as it is now, and so collectors would put stuff onto tape and they would swap tapes and records. It was a very active community, not only nationally but worldwide. It’s in the collectors mentality and to, particularly in those days, to try and get the pieces of the jigsaw together and then put the thing together. It was in that way that they could get a profile of these musicians behind the extraordinary names that appeared on the labels. Very little was known about those musicians then, and this was the way of putting the pieces together.”\nThe expanse of the Document titles is almost overwhelming. Atkinson said that all the CD’s are not “have to have” things, but they are aimed at what he calls, “serious collectors of the most frightening kind.” He described them as “the kind of guys that if you put out three volumes, and they’ve got volume one, and they’ve got volume three, even though they don’t know what’s on volume two they can’t sleep at night because they haven’t got it.”\nAtkinson also noted that it was important to have these titles available because “as far as African-Americans are concerned, there is documentation of very different sides of their social life,” and that the records “do a lot of coloring in of the picture.”\nAccording to Atkinson, the music has universal appeal; it has the ability to be relevant to anyone with an open mind.\n“If you just go back to the beginning of all of this, my father was well into the music, but he was a white guy living on the northeast of England, he just had a natural affinity with the music,” Atkinson said. “He was able to relate to what came out of the speakers. ... The music cuts through cultures, through geographical boundaries. It cuts through politics, through religion, through everything.”\nThanks to TOMASZ LESICZA and The Athens Messenger', 'Record and Music Industry Executives who shared their insights for Johnny Winter\'s definitive biography include Bill Bentley, Rick Dobbis, Bruce Iglauer, Mike and Richard Vernon, and John Wooler.\nWhen I interviewed Bill Bentley from his office in Los Angeles, he worked in publicity at Warner Brothers Records. Bill has an impressive background in the music industry. He was a music editor at the Austin Sun and L.A. Weekly, and formed a band with Speedy Sparks (bass player for the Sir Douglas Quintet) and Will and Charlie Sexton (Arc Angels, Bob Dylan) in the late 1970s. He spent 20 years at Warner Brothers handling major artists, including Los Lobos, Elvis Costello, the Blasters, Green Day, X, Lou Reed, the Red Hot Chili Peppers, R.E.M., the Barenaked Ladies, Kenny Wayne Shepherd, and Wilco.\nA native Texan, Bill was living in Houston, but traveled to Austin to see Muddy Waters with opening act Johnny Winter at the Vulcan in August 1968. Bill was blown away by Johnny\'s performance. He shared his memories of the Vulcan Gas Company, that fateful night with Muddy and Johnny, the excitement of Johnny\'s performance, and the impact it had on Muddy. ""You could tell opening for Muddy was a big thing for him and he didn’t hold back at all,"" Bill said. ""From the very first song, he went for it. He was so good it was unbelievable . . . I think he scared Muddy a little bit . . .""\nRick Dobbis is another heavy hitter in the music business that worked with Johnny. During his 35 year career, he has been President of Sony Music International, President of PolyGram Records, and Senior Vice President of Arista Records. He currently runs an independent Global Business Management Company, where his client list includes the Rolling Stones and Yanni. Rick also produces the TV show Americana Roadhouse 411, and is a partner in Dream Jam World, a children’s entertainment company.\nIn 1974, when Johnny\'s manager Steve Paul started Blue Sky Records, a specialty label promoted and distributed by Columbia Records, he hired Rick as executive vice president and general manager. Rick explained the inner workings of the Blue Sky label, his role as a liaison between Blue Sky and Columbia, and his experiences both in and out of the studio with Steve Paul and Johnny.\nI interviewed Bruce Iglauer in Tunica, Mississippi, not far from Robinsville, where Robert Johnson spent much of his life. Bruce is founder and president of Alligator Records, with a catalog of over 200 titles and the distinction of being the largest independent blues label in the world. Bruce met Johnny in 1978 at a Son Seals show and the two clicked immediately. In 1984, he signed Johnny to his label, which released Guitar Slinger (1984), Serious Business (1985), and Third Degree (1986).\nBruce candidly shared his experiences having Johnny as a house guest, and of a live recording at the Wise Fools Pub in Chicago where Johnny sat in with Son Seals. He explained his relationship with Johnny in the studio during the sessions for the first two Alligator releases and why Johnny requested that he not be involved in the production of Third Degree. Bruce also offered insight into Johnny\'s personality, as well as the relationship between Johnny and Teddy Slatus and how Slatus\'s inability to act as an authoritative manager affected Johnny\'s s record sales and reputation.\nThe leading producer of British blues bands in the late 1960s, Mike Vernon produced the legendary Bluesbreakers John Mayall with Eric Clapton LP released by the Decca label in Britain in July 1966. He also produced the Bluesbreakers’ only album with Peter Green, and records by Chicken Shack, Duster Bennett, Savoy Brown, and Ten Years After. Mike and his brother Richard founded Blue Horizon Records, the successful British blues label that released two Fleetwood Mac albums in 1968. During the late 60s and early 70s, the label released dozens of blues records including albums by traditional blues artists such as Elmore James, Johnny Shines, Sunnyland Slim, Earl Hooker, Lightnin’ Hopkins, B.B. King, and Otis Rush. Producer\nWith Mike in the U.K. and Richard traveling back and forth from Brazil to Spain, we did our interviews through the mail. Mike and Richard shared their memories of the 1968 trip that Johnny and Keith Ferguson made to England to find a blues label willing to record a white blues artist. The Vernon brothers remembered their initial meeting and impressions of Johnny, and explained the deal they made with Johnny and how it would have taken place if a serendipitous story in the December 7, 1968 issue of Rolling Stone hadn\'t immediately changed Johnny\'s life.\nI interviewed John Wooler from his offices in Los Angeles, where he works as a music consultant and producer at Exolution Entertainment and as a music professor at Cal Poly Pomona. The president of Pointblank Records, a Virgin blues/roots imprint label he launched in 1989, Wooler was working on a deal with John Lee Hooker when he signed Johnny to the label in 1991. With 26 Grammy nominations and five wins, Wooler was well known for his expertise in the record business. He had joined Virgin Records UK as Deputy Head of A&R in 1984; within ten years he became Senior Vice President of Virgin Records US. He signed all the Pointblank artists, including John Lee Hooker, Charlie Watts, Van Morrison, John Hammond, Pops Staples, Larry McCray, Albert Collins, The Kinsey Report, and Walter ""Wolfman"" Washington.\nJohnny signed with Pointblank after Wooler assured him he would have complete creative control and the ability to do straight blues. Johnny\'s Pointblank recordings include Let Me In (1991), ""Hey Where\'s Your Brother?"" (1992) and Johnny Winter Live in NYC \'97 (1998). Producer Dick Shurman extolled John Wooler for the free rein he gave him and Johnny over those projects. Wooler shared his experiences with Johnny on a personal level and in the studio, talked about promotion for those recordings, and explained why then manager Teddy Slatus\'s attempt to start his own imprint label for Johnny never came to fruition.']"	['<urn:uuid:f90d1324-8c59-47ec-8480-d38f6f6501c1>', '<urn:uuid:5d8c1a7e-119f-4d0f-a738-4fdb5baea417>']	open-ended	direct	long-search-query	distant-from-document	comparison	novice	2025-05-01T22:36:12.692263	8	96	2090
211	trying to save my houseplants need help what color light wavelengths do plants use	Plants need red and blue light wavelengths to grow properly. The blue wavelengths help foliage grow and thrive, while the red wavelengths support the development of flowers and fruit. Green wavelengths are not usable by plants - they are simply reflected off the plant's leaves, making them appear green. Plants require a full spectrum of warm and cool wavelengths that replicate sunlight.	['Regular LED (Light-emitting diode) lights provide some of the wavelengths needed by plants, but they do not offer the full spectrum of wavelengths necessary to grow healthy, happy plants.\nFor this reason, you must use LED grow lights, which provide the red and blue light spectrums that help plants grow.\nThe blue wavelengths help foliage grow and thrive, while the red wavelengths support the development of flowers and fruit.\nThe green wavelengths that are typically provided by household LED lights are not usable by plants.\nThey make plants look greener, but this is only because their green rays are reflected off the plant’s leaves.\nIf you want to grow plants using artificial lights of any kind, you must use bulbs that provide a full spectrum of warm and cool wavelengths that replicate those provided by the sun.\nThis article provides good guidance to help you use artificial light to grow plants indoors. Read on to learn more.\nImportant Light Source Guidelines To Add To Your Plant Care Regimen\nSunlight is the perfect light for plants. It has just the right balance of light wavelengths to help plants grow, bloom and set fruit.\nEven so, you can provide an excellent habitat to help your plants thrive in any room in your home or office through carefully selected and correctly used artificial light.\nChoose The Type(s) Of Lighting You Want\nWhen choosing indoor lighting for plants, you may wish to go with full spectrum fluorescent or full spectrum LED lighting, or you can mix and match.\nLED Lighting For Plants\nThere are many advantages to using full spectrum LED lights to grow plants. These bulbs are very energy efficient, offering cool, safe operation.\nThere are also many different types of LED light bulbs for use in various settings.\nWhile it is possible to calculate the amount of red and white wavelength of various common household LED light sources to produce to customize your plant setup, it’s better, easier, and safer to purchase and use LED grow lights.\nOne caveat, though, double-check to be sure the bulbs you buy really do provide a full spectrum of wavelengths.\nAlso, remember that some LED lights are sold as “plant lights” but only offer the green spectrum, making your plants look green – until they die.\nFluorescent Lighting For Plants\nFluorescent lighting is inexpensive and versatile.\nYou can buy handy CFL (Compact Fluorescent Light) bulbs that can be used in any light socket or get tube fixtures that are easy to hang anywhere.\nThe advantages of fluorescent lighting include cool and economical operation and a very long bulb life.\nIf you cannot find full spectrum fluorescent bulbs, you can use cool white bulbs, which also deliver a full spectrum of wavelengths.\nCFL vs. LED\nCompared with fluorescents, LED lighting also runs cool and is safe, efficient, and easy to use.\nIn addition, even though LED lighting may be a little more expensive to set up, bulb life is even longer than fluorescent lighting.\nOn the downside, LED lighting doesn’t cover as much area as fluorescent lighting.\nLED devices are often heavier than those designed to be used with fluorescent lighting, and for use in your living space, these receptacles may not be as attractive as those that can use CFL bulbs. [source]\nArtificial Lighting Tips & Questions\n1. Get A Fast Affordable Start On Plant Lighting.\nYou can begin by simply replacing all of your regular light bulbs with CFL or LED bulbs.\nThen, add LED grow light bulbs or CFL bulbs to hanging lamps or table lamps to create a good growing space for individual or small groupings of potted plants.\nThis will help your plants grow and thrive, and it will also help you save energy and money.\n2. Examine Any Bulb You Plan To Buy Carefully.\nRemember to read the description of the bulb’s wavelength carefully.\nIf you buy “plant bulbs” or “plant lights” without double-checking, you may end up with a green wavelength LED light or a green tinted incandescent light.\n3. Always Pay Attention To The Safe Wattage Range Of Lamps And Sockets.\nRemember that you can use LED or CFL bulbs in any household light fixture but stay within the wattage range.\n4. Set Up A Proper Growing Space To Get Your Garden Started.\nIf you want to do some serious gardening indoors or start seeds indoors to transfer to your spring and summer garden, you’ll need a space equipped with hanging tube fixtures that provide concentrated light to your plants.\n5. Use Halogen Or Incandescent Lights Carefully Or Not At All.\nYou can include halogen and incandescent lights in your plant lighting mix, but they don’t provide full spectrum lighting\nThey burn hot and use a lot of energy, so, overall, you’re better off leaving them out.\n6. Mix & Match Bulbs Successfully.\nIf you decide to include incandescent and halogen lighting in the mix, be sure to position cool bulbs (e.g., CFL and LED) closer to plants.\nPlace hot incandescent or halogen bulbs in higher settings to provide light to the room without burning your plants.\n7. Use Reflective Surfaces To Increase Lighting.\nMirrors and white walls can increase the light output of your fixtures and brighten your home or office.\nIn a grow room, reflective materials, such as Mylar, will greatly increase light output.\n8. Make Use Of A Timer To Provide The Right Amount Of Light.\nIt can be hard to remember when to turn your plant lights on and off. Set up timers or use a “Smart” program to provide your plants with 16 hours of light and 8 hours of dark daily.\nWhy Use Full Spectrum Artificial Light For Plants?\nWhen you use full spectrum LED or CFL lights in your home gardening ventures, you can improve the health of your existing plants and make it possible to expand your indoor gardening efforts to even the darkest corners of your home or office setting.\nAdding artificial light improves both the quality and the quantity of light available to your plants and you.\nPlants are not the only entities that benefit from full spectrum lighting. All living beings can benefit from exposure to abundant, natural spectrum light—even you! [source]']	['<urn:uuid:30c57d64-5877-47a4-bd59-d6ec4d3c7a68>']	factoid	with-premise	long-search-query	distant-from-document	single-doc	novice	2025-05-01T22:36:12.692263	14	62	1034
213	dangers pet rat bite infection	Rat bites can lead to rat-bite fever (RBF), caused by bacteria found in rats. Symptoms appear between 3 days and 3 weeks after exposure, and include fever, vomiting, headache, and muscle pain. About 50% of patients experience joint pain or swelling, and 75% develop a rash on hands and feet. Complications can include abscesses, liver or kidney infections, pneumonia, meningitis, and heart infections. RBF has a mortality rate of approximately 10% if left untreated.	['Mice and Rats: Health Hazards and How to Prevent Them\nMice and rats are some of the most damaging and dangerous pests to have in homes and businesses. Their habits cause extensive damage, and they are known carriers of many diseases. It is important to be aware of the risks posed by mouse and rat infestations, so we put together a guide detailing the causes, symptoms, and prevention methods of the main rodent-borne illnesses in the United States.\nHantavirus Pulmonary Syndrome\nHantavirus is a virus spread primarily by deer mice, white-footed mice, cotton rats, and rice rats. Typically, it is contracted after coming into direct contact with rodents or their urine and droppings, or by breathing in dust contaminated with urine or droppings. It can also be contracted through rodent bites, but that is not as common. Symptoms develop between 1 and 8 weeks after exposure, and they occur in two phases. Universal early symptoms include fatigue, fever, and muscle aches. Other early symptoms that occur in about half of all Hantavirus cases include chills, dizziness, headaches, abdominal pain, nausea, vomiting, and diarrhea. Late symptoms begin between 4 and 10 days after the early symptoms phase. These symptoms include coughing, shortness of breath, and lungs filling with fluid. Hantavirus has a mortality rate of 38%.\nLeptospirosis is a bacteria spread by rodents, as well as other animals. It is contracted by eating or drinking contaminated foods and water, or by contact of skin or mucous membranes with contaminated soil or water. Symptoms will typically arrive abruptly between 2 days and 4 weeks after exposure to the bacteria, although some people show no symptoms at all. The illness may occur in two phases. The first phase may consist of fever, chills, abdominal pain, diarrhea, vomiting, headache, muscle aches, red eyes, jaundice, and rash. If a person experiences a second phase, it will be more severe and may occur after a period of recovery from the first phase. The second phase may include liver or kidney failure, respiratory distress, or meningitis. Without treatment, recovery from leptospirosis may take months, and in some cases can lead to death.\nPets can also get leptospirosis, although it is rare in cats. Symptoms that are commonly seen in dogs include fever, abdominal pain, vomiting, diarrhea, refusal to eat, severe weakness and muscle pain, stiffness, severe depression, and the inability to have puppies. Younger animals are usually affected more than older animals.\nLymphocytic Choriomeningitis (LCM)\nLymphocytic choriomeningitis, or LCM, is a disease caused by lymphocytic choriomeningitis virus, or LCMV. It is typically spread by house mice. It can also be spread by pet rodents, but that is not as common. An estimated 5% of house mice in the United States carry LCMV. It is contracted either by direct contact with rodents or rodent urine and droppings, or by breathing in dust contaminated by rodent urine and droppings. It can also be spread through bite wounds from infected rodents, although this is much rarer. LCM may occur in two phases. Symptoms of the first phase appear between 8 and 13 days after exposure. Common symptoms of the first phase include fever, nausea, vomiting, lack of appetite, malaise, headache, and muscle aches. Less common symptoms include sore throat, cough, chest pain, joint pain, testicular pain, and pain of the salivary glands. If a second phase occurs, it will do so after a few days of recovery from the first phase. Symptoms of the second phase include, meningitis, encephalitis, meningoencephalitis, acute hydrocephalus, and, in rare cases, myelitis. As LCM is an infection of the nervous system, it can cause temporary or permanent neurological damage, including nerve deafness and arthritis. If a pregnant woman becomes infected with LCMV, she may pass the infection to the fetus. This can result in fetal death during the first trimester, or serious and permanent birth defects during the second and third trimesters. LCM is rarely fatal, with a mortality rate of less than 1%.\nRat-Bite Fever (RBF)\nRat-bite fever, or RBF, is caused by one of two bacteria that are spread by rats and possibly mice as well. Only one of the two RBF-causing bacteria is found in the United States, and that is streptobacillus moniliformis, which causes streptobacillary RBF. As the name suggests, RBF is typically contracted through a bite or scratch wound from an infected rodent, or through contact with a dead rodent. It can also be contracted by eating or drinking food or water that is contaminated with rat droppings, in which case it is referred to as Haverhill fever. Symptoms appear between 3 days and 3 weeks after exposure to the bacteria, by which time any bite or scratch that caused the illness would likely be healed. Common symptoms of Streptobacillary RBF include fever, vomiting, headache, and muscle pain. In addition, approximately 5 out of 10 patients experience joint pain or swelling, and approximately 3 out of 4 patients experience a rash. This rash will appear on hands and feet and look like flat, reddened areas that have small bumps. People with Haverhill fever may also experience sore throat and more severe vomiting. Complications with Streptobacillary RBF include abscesses inside the body, liver or kidney infections, pneumonia, meningitis, and infections involving the heart. Approximately 1 out of 10 people who get Streptobacillary RBF die.\nSalmonellosis is an infection caused by the bacteria salmonella, and can be spread in many ways, including by rats and mice. When spread by rats or mice, it is contracted by eating or drinking food or water that is contaminated with rat droppings. Symptoms typically appear between 6 hours and 6 days after exposure, although some people may not develop symptoms for several weeks. Symptoms usually last between 4 and 7 days, but can last for several weeks. Common symptoms of salmonellosis include fever, abdominal pain, and diarrhea. Some strains of salmonella can cause severe disease, as well as infections of the blood, bones, joints, nervous system, or urine.\nTularemia is caused by a bacteria and can be spread in many different ways, including by rats and mice. There are multiple forms of tularemia, which are categorized by how the bacteria was contracted. Symptoms vary by form, but all forms cause fever. Causes and symptoms of the main forms of tularemia are listed below. Please keep in mind that this list only includes the causes pertaining to rodents. The forms of tularemia that are listed may have other causes that are not included in this list.\n- Ulceroglandular tularemia is caused by handling an infected animal. Symptoms include a skin ulcer where the bacteria entered the body, fever, chills, exhaustion, and swollen and painful lymph glands.\n- Glandular tularemia is the same as ulceroglandular tularemia in all ways, except that it does not cause skin ulcers.\n- Oculoglandular tularemia is caused by the bacteria entering through the eyes, usually when someone is butchering an infected animal and touches their eyes. Symptoms include irritation and inflammation of the eye, an ulcer on the inside of the eyelid, sensitivity to light, and swelling of the lymph glands in front of the ears.\n- Oropharyngeal tularemia is caused by eating or drinking contaminated food or water. Symptoms include vomiting, diarrhea, sore throat, tonsillitis, mouth ulcers, and swollen lymph nodes in the neck.\n- Pneumonic tularemia can be caused either by breathing in contaminated dust or aerosols, or by leaving another form of tularemia untreated, allowing it to spread through the bloodstream to the lungs. Pneumonic is the most serious form of tularemia. Symptoms include chest pain, difficulty breathing, and a dry cough.\n- Typhoidal tularemia is a combination of general symptoms of tularemia, without any of the localized symptoms of other forms. Such general symptoms include extreme exhaustion, enlarged spleen or liver, vomiting, diarrhea, and pneumonia.\nMost cases of tularemia can be treated fairly easily with antibiotics, although some cases are life-threatening.\nFor more information about these and other rodent-borne illnesses, visit this page of the CDC’s website.\nDiseases spread by mice and rats can be avoided if necessary precautions are taken. For one, avoid any contact with rodents that are not pets. Take steps to make your home or business an environment where rodents cannot or do not want to live. Do not swim or wade in water that could potentially be contaminated with rodent urine or feces. If your job requires you to come into contact with anything that is potentially contaminated- such as soil, water, or infested buildings- always wear protective footwear and clothing. When mowing, check the area beforehand for any sick or dead rodents, and do not mow over them if there are any. Clean up any rodent nests, as well as any urine and droppings. For information on how to safely clean up dead rodents, rodent nests, or rodent urine and droppings, visit this page on the CDC’s website. When handling nests or wild rodents, dead or alive, always wear gloves and wash your hands with soap and warm water after.\nAlthough it is rare, diseases can also be spread by pet rodents, so precautions should be taken when handling them as well. When choosing a rodent pet from a pet store or breeder, avoid any that look sick or otherwise unwell. Do not choose any that are in the same cage as rodents that look unwell, either. If possible, clean your pet’s habitat, food and water bowls, toys, and any other objects outdoors. If outdoor cleaning is not an option, then use a large bathtub or sink that can be easily disinfected. Avoid using a kitchen sink. Always wash your hands with soap and warm water after handling your pet or its belongings.\nIf you are bitten or scratched by a rodent, wild or domestic, clean the wound immediately with soap and warm water. Contact a health care provider as soon as possible and tell the provider about the bite or scratch. Get treatment if need be.\nIn addition to spreading illnesses, mice and rats tend to cause extensive, and usually expensive, damage to homes and businesses. They will chew through just about anything they can get their teeth into, including walls, floors, insulation, pipes, wires, upholstery, important documents, family heirlooms, and more. The damage to insulation can make temperature regulation very difficult and expensive. Lack of insulation means having to run air conditioners and heaters much more than usual, in addition to the fact that insulation can be expensive to replace. Chewed wires are quite dangerous, and actually cause about 25% of the house fires in the United States each year. Mice and rats also cause fire risks when they tunnel into and build nests inside of appliances, causing them to short-circuit or malfunction. When an infestation is severe, the urine of the mice or rats can soak into wood and compromise the structural integrity of a building. For information on how to prevent infestations, check out our mouse and rat FAQ pages\nA few mice or rats can quickly turn into an infestation. Rodent infestations are not something to be taken lightly or ignored, as they can be potentially dangerous. If you think you have mice or rats in your home or business, call our experts today and we’ll send a technician out right away.\nYou’ll be supporting research into lyme disease, too.\nChoosing Excel helps us support the John Hopkins Lyme Research Center. You will help them advance the critical knowledge and clinical tools urgently needed to improve Lyme disease patient care and health outcomes.']	['<urn:uuid:382f354d-6d21-444a-bc47-1742e2e48f28>']	open-ended	direct	short-search-query	distant-from-document	single-doc	novice	2025-05-01T22:36:12.692263	5	74	1915
214	military expert wondering what role battlefield smoke from musket gunpowder influenced development standardized army uniforms	The advent of gunpowder-charged muskets led to a significant change in military uniforms. When musket fire from massed formations became common, the battlefield would become shrouded in thick smoke after the first volley. This practical challenge led commanders to outfit their units in standardized, bright-colored uniforms to help with identification when the battlefield was obscured by smoke. Additionally, as unit sizes grew, the interests of economy and building unit cohesion also contributed to the standardization of military clothing.	['When you look at any text dealing with the armies of the eighteenth and nineteenth centuries one of the features which immediately stands out is the elaborate uniforms worn by the armies of every combating nation. My particular interest is in the Napoleonic period and the armies of that era excelled themselves in the splendour of their attire. Contemporary observers regarded the French uniforms with unreserved astonishment. The luxury of the French uniforms was overwhelming and veterans of the period, writing their memoirs in their old age, mourned the passage of such magnificence. They consoled themselves with the conviction that no greater military splendour, bound up as it was with the charisma of their Emperor, had ever been seen in Europe, or would ever be seen again.\nBut how did such colour and vibrancy come into common usage among the army rank and file?\nPrior to the age of gunpowder, recognition on the battlefield of friendly versus unfriendly units could be achieved by a display of badges and flags – hence, men-at-arms sporting the heraldic emblems of their feudal lords on their shields and massing under the banner of their captain.\nHowever, in the late sixteenth century and into the seventeenth century a revolution swept the battlefield. With the advent of reliable gunpowder-charged muskets and the musket fire from massed formations becoming the decisive factor on the battlefield this led to the crystallization of military organization into professional armies consisting of trained soldiers arranged in permanent organizations. Gunpowder also meant that as soon as the first volley was fired, the battlefield would be shrouded in thick smoke.\nAt this time, units were still raised by wealthy individuals much as they had been in feudal times but two factors led to the donning of standardised military uniform. As unit sizes grew the interests of economy and the building of an esprit de corps led commanders to the provision of uniformity of clothing within their units. Also, large units all wearing the same bright colour helped in identification when the battlefield was choked with smoke.\nThe development of military uniforms then followed three principles:\nThe Hierarchical Principle – essentially the differentiation of rank within an organisation and the differentiation of types of units both in terms of branches of the army and within a smaller unit – e.g. the designation of elite troops such as grenadiers.\nThe Seduction Principle – the innate desire for soldiers and their commanders to want to look smart and attractive – as Jane Austen commented in Pride and Prejudice regarding Mr Wickham “the young man wanted only regimentals to make him completely charming”. This goes hand in hand with the idea of parades – the grandeur of the parade is in no small part due to the splendour of the appearance of the units taking part.\nThe Utility Principle – compromises made on campaign for the practicalities of warfare – e.g. the wearing of plain greatcoats in bad weather and the stowing of gaudy badges that might draw enemy fire.\nOn top of this there was a tendency for all armies to copy the appearance of particular units that were deemed the “best” – hence, hussars in almost every army copied the appearance of the original Hungarian hussars drafted into the Austrian Army in the eighteenth century. The dolman and pelisse, festooned with lace, and the shako and sabretache became ubiquitous.\nAll that having been said, I’m not quite sure what principle still drives the uniforms of senior officers in the army of North Korea – perhaps there is a Pearly King and Queen principle I have overlooked.']	['<urn:uuid:f4275c90-4f8c-4999-b753-dcb103a5667c>']	open-ended	with-premise	long-search-query	similar-to-document	single-doc	expert	2025-05-01T22:36:12.692263	15	78	601
218	How does the Index of Urban Green Zones Allergenicity work?	The IUGZA calculates allergenicity risk by creating an inventory of species and assigning values based on biological attributes like pollination strategy, flowering duration, and the pollen's capacity to generate allergic responses.	['Urban green spaces provide several benefits beyond aesthetics. They offer shade, help to reduce pollution, offer habitat for birds and insects, a space to meet and socialise or for kids to play. Not surprisingly the choices of plants used to populate these areas are made with these considerations in mind, unfortunately, their allergenicity is not.\nFor those without serious allergies, they may appear to be a small annoyance. In fact, allergies are a serious public health problem causing asthma, rhinitis and skin conditions and they disproportionately affect children. It also appears that this is, in part, a self-inflicted wound, spurred on by the way in which we designed our living spaces.\nThe clearest example of this is botanical sexism, a term coined by horticultural expert Thomas Orgen. It refers to the tendency for urban planners to use male plants because of concerns about the fruit produced by female trees: concerns like higher maintenance, the attraction of pests and the littering of streets with fruit.\nThis bias toward male species leads to massive amounts of pollen, the male reproductive organ of plants, being released into our cities. Orgen studied and campaigned for this issue for nearly 40 years, writing books and developing the first rating system for measuring the potential of a plant to cause allergic reactions in humans, the Orgen Plant Allergy Scale.\nThis idea of quantifying allergenic potential has now been extended to green spaces too with the Index of Urban Green Zones Allergenicity (IUGZA). “The index was created with the aim of assessing the risk of allergic symptomatology in a green area as a function of the plant species that grow in them,” explains Paloma Cariñanos, a botanist at the University of Granada who, along with colleagues, developed the index in 2014.\n“To calculate the IUGZA, an exhaustive inventory of species is carried out and each plant is assigned values for a series of biological attributes related to allergenicity.” The index parameters consider things like the pollination strategy of the plant, the duration of its flowering and the intrinsic capacity of its pollen grains to generate an allergic response. With this information each species is then assigned an Allergen Potential Value.\nRecently Cariñanos applied the index to greens spaces in 23 cities located in six Mediterranean countries and was able to show that several native ornamental species are some of the main allergy culprits. She also found that bioclimatic characteristics of the territory and design aspects, such as the density of trees and the number of species used were the variables most likely to impact the IUGZA.\nCariñanos stresses however that this work highlighting the causal and aggravating factors of allergies in the population should not be viewed in a negative light. “It is not our intention to generate public alarm or devalue the positive role that parks and gardens have in the urban ecosystem and on the welfare of the population,” she says. “Instead, it is necessary to emphasise this disservice that affects so many people and that generates social, economic and environmental costs.”\nAreas for improvement according to Cariñanos are the incorporation of exotic species whose allergenicity has not been reviewed, increasing the diversity of species used and, of course, ending the bias toward female plants.\nOrgen agrees saying, “if there isn’t a high number of female plants in a landscape, you’re going to have a problem.” However, he also points out that things like climate change are having an effect too. “The pollen season is starting earlier and lasting longer,” he explains. “I’m seeing certain species that in the past only bloomed once a year but now are blooming twice a year and this makes it more important than ever to pay attention to what we’re planting.” He also recommends specific changes in the nursery industry such as allergy tagging the plants they sell and an overall better awareness of the issue.\nIn terms of solutions, Cariñanos admits that implementing the changes highlighted by her and others work is not easy, but she sees some encouraging signs. “I know some European political parties have measures to reduce the impact of allergens on the quality of life in their electoral programs.”\nThe issue is also taken into account by the researchers of the EU project Urban GreenUP, which is studying innovative nature-based solutions aimed to renature urban landscapes worldwide. In Valladolid, Spain, one of the demonstration sites, they claim they can reduce “allergy by 50% in the long term both in intensity and duration”. More info here.\nyouris.com provides its content to all media free of charge. We would appreciate if you could acknowledge youris.com as the source of the content.']	['<urn:uuid:e4376d0d-0d39-4615-a567-36c598dbf515>']	factoid	with-premise	concise-and-natural	similar-to-document	single-doc	expert	2025-05-01T22:36:12.692263	10	31	775
219	construction project manager need to know steel frame systems cost effectiveness and seismic performance requirements	Steel frame systems are cost-effective due to off-site fabrication reducing on-site expenses and lower maintenance costs. Regarding seismic performance, they require specific modifications including proper detailing of beam-column joints and connections with the building frame to ensure integral action of lateral load resisting elements and prevent potential structural failures during earthquakes.	['Steel frame systems (SFS) represent contemporary structural solutions specifically engineered for the rapid and efficient construction of modern framed buildings.\nThese innovative systems enable the assembly of steel columns, steel beams, and various other structural elements into a framing configuration. By doing so, they provide robust support for floors, roofs, walls, as well as internal components like partitions and cladding.\nNotably, steel frame systems are gaining widespread popularity in contemporary construction projects, surpassing alternative construction materials in preference.\nInfill walling is the most common application – most economical constructed from the floor to soffit of the primary structural frame to ‘infill’ the external wall zone. This option is typically the most economical solution and allows the steel frame systems to be installed from the inside of the building.\n- Quicker and easier to install than conventional deflection brackets\n- Simpler and faster to install than traditional masonry infill\n- Fewer components on site – less components to store, lose or work with\n- Fix and forget system – no concerns about missing brackets\n- Visible centre line indent indicates fixing location\n- Vertical slots at 25mm centres allow for flexibility of stud positions\nWhy should you use SFS?\nSFS framing is made from cold-rolled steel sections, meaning they come with all the benefits of structural steel. The steel framing is compatible with a massive range of external finishes, ranging from timber cladding to traditional brickwork. The components are typically fabricated off-site to fit the required specifications before being sent to the site.\nSome typical applications of a steel frame structure include apartment buildings, retail units, hotels and schools. Using SFS has become more prominent over the years. And when you consider the advantages, it is clear to see why that is the case.\n- Strength – steel is incredibly dense and can support huge loads, compared to timber frame systems. Its higher density means that steel frames, while heavier than concrete or timber, can support heftier loads on a beam of the same size.\n- Time-saving – steel frames are prefabricated. This means that they are immediately ready to be assembled (via bolting or welding) when they arrive at a site. As a result, this makes for a swift, easy process of installation if time is against you.\n- Flexible – steel can be cut and shaped to your exact desired requirements, meaning it is compatible and suitable for a wide range of diverse designs. This means you can create a structurally stable framing system while also bringing a unique vision to life. Structural steel frames are also easy to modify or alter, should any renovation or expansion work be on the cards.\n- Durable – Steel frame system can last significantly longer than timber or concrete – steel does not split or crack the more it ages. Provided the steel has been adequately finished or primed, it will not succumb to corrosion, nor will it warp or rot when exposed to moisture.\n- Cost-effective – given that steel framing systems are fabricated off-site, you can reduce your on-site expenses significantly. As we have said, steel is incredibly durable, so costs for maintenance, repair or replacements will be exponentially lower.\n- Sustainable – steel is infinitely recyclable as a material, meaning that your carbon footprint will be substantially lower.\n- Safe – steel is a non-combustible material, meaning it will not pose a fire risk. An SFS structural framing system will ensure structural integrity when faced with extreme weather. While this weather poses a higher risk for larger buildings, having a steel frame structure in place will provide stability and optimum protection.', 'Seismic retrofitting is the modification of existing structures so as to improve the system behaviour or its components repair or strengthening up to the performance is expected. The retrofitting of a building requires an appreciation for the technical, economic and social aspects of the issue. Choosing the optimal solution depends on a large variety of criteria, the most important being the total cost, period of construction, the ease of technologies application etc. Furthermore, the seismic behaviour of the buildings is affected due to design efficiency, construction deficiency, additional loads, additional performance demand etc. A case study is conducted in Mani Mandir complex located in Gujarat, to find the impact of various retrofitting techniques. A comprehensive retrofit program was formulated. Conservative principles, minimum intervention and consonance with the heritage character of the building were important considerations in selecting the retrofit program. The retrofit measures include providing a rigid diaphragm behaviour mechanism in existing slabs, introducing stainless steel reinforcement bands in the existing masonry walls, cross pinning and end pinning in walls and pillars and strengthening of arches and elevation features.\nEarthquake creates destruction in terms of life, property and failure of structures. In order to protect from the risk triggered by seismic disaster to the life and property, the performance of the structure must be improved and thus Seismic Retrofitting plays its role. Retrofit involves modifications to existing structures that may improve energy efficiency or decrease energy demand. Seismic retrofitting is the modification of existing structures so as to improve the seismic behaviour or its components repair or strengthening up to the performance it is expected. Retrofitting also proves to be a better option catering to the economic considerations and immediate shelter problems rather than replacement of seismic deficient buildings. Two alternative approaches are conceptually adopted and implemented in practice for seismic retrofitting. The first approach focusses on upgrading the structure to resist earthquake induced forces (i.e. modifying the capacity) and is called Conventional method of retrofitting. The second approach focusses on reduction of earthquake induced forces (i.e. modifying the demand) or Unconventional approach. Seismic retrofitting is the collection of modern techniques for earthquake resistant structure.\nThe presence of soft and weak storey at the open ground floor, in-plane discontinuity out-of- plane offset of the ground floor columns and eccentric mass are commonly observed irregularities in the studied buildings. In absence of collector elements in the slab and proper detailing of the connections with the building frame, there is lack of integral action of the lateral load resisting elements, techniques for earthquake resistant structure. The seismic performance of beam-column joints in an RC framed structure has long been recognized as a dominant factor that affects its overall behaviour when subjected to earthquake forces, as indicated in earlier version of design codes and standards. Unsafe designs and deficient detailing that does not conform to seismic codes within the joint region may result in extra inelastic story drift and excessive post-yield rotation, which likely causes local failure, and may even lead to progressive collapse. The potential problems associated with the design deficiencies of the beam-column joints have been identified in many catastrophic structural failures reported in past major earthquakes.\nFour major objectives are identified to understand the feasibility of seismically retrofitting existing structures. The first objective is to investigate how building location affects the annual probability of attaining or exceeding specified performance levels. The second objective is to develop a framework to determine the economic feasibility of seismic retrofitting. The third objective is to study the effects that achievable loss reduction, investment return period and retrofitting. The final objective is to determine the impact of a modest retrofit strategy applied to identical example buildings.\nTo provide safety to the occupants by reducing the of structural collapse during severe earthquakes. This can be done by strengthening the columns and joints so that their flexural and shear capacities will be adequately stronger. Retrofit strategy refers to options of increasing the strength, stiffness and ductility of the elements or buildings as whole. Several retrofit strategies may be selected under a retrofit scheme of a building.']	['<urn:uuid:dccbc43b-808b-439d-b5e7-e1ffe766f85c>', '<urn:uuid:3ffebfc4-2fde-44f6-93bb-f4766881b9c2>']	factoid	with-premise	long-search-query	similar-to-document	multi-aspect	expert	2025-05-01T22:36:12.692263	15	51	1281
220	bpmn epc rules events notation difference	BPMN and EPC differ in their approach to rules and events. In EPC, rules are externalized from processes and connected via events, where processes produce events that can fire rules. BPMN, on the other hand, is more IT-focused and specific regarding aspects like message flow, with the ability to translate to BPEL for executable business processes. While both notations model business processes, EPC provides more elements with business focus.	"['Rules vs. Processes (Again) — Part 2: Now for Events\nProcesses connect to rules via events. Processes produce events, which can fire one or more rules (i.e., cause the rule(s) to be evaluated). The rules might determine whether the event is undertaken correctly or will produce a desired outcome. The rules also might make some decision. The rules are externalized from the processes and established as a separate resource. This permits direct management of the rules, which in turn permits much closer tie-in to the business side and far greater agility in decision logic.\nThis notion of Rule Independence is the centerpiece of the business rule approach. The various principles underlying this fundamental principle are enumerated in the Business Rules Manifesto.\nUnderstanding Rule Independence requires careful examination of the relationship between rules and events. Intuitively, we know that certain rules apply when certain events occur. But what exactly is the connection between rules and events?\nTo understand, we must probe into events more deeply. What is an event? There are at least two ways of looking at events, both correct from their own perspective.\n- The business perspective: For the business, an event is something that happens requiring the business to respond, even if only in a trivial way. (Usually, the response is not trivial.) For example, a customer places an order. This is an event that requires a well-organized response. Often we try to organize our response to such business events in advance — for example, within business process models, workflow models, procedures, and so on.\n- The IT perspective: For an information/knowledge system that supports the business, anevent is something that happens and needs to be noted or recorded because knowing about the event is potentially important to other activities, either those occurring during the same time frame or those that might happen later. In the business rule approach, of course, such recording is always based on predefined terms and facts — that is, primarily on the basis of the fact model. An information/knowledge system can support the fact model in several ways: either directly, or indirectly through a database design, a class diagram, and so on. To simplify matters, let\'s just say there is some data somewhere in the system that must be updated (created, modified, or deleted) to record the event. Otherwise, the business cannot know about the event. For convenience, I will call these update events.\nNow, how do events connect with rules? Consider the following sample business rule (expressed in RuleSpeak). Figure 1 shows the relevant terms and facts for this rule.\nCustomer Rule: A customer must be assigned to an agent if the customer has placed an order.\nFigure 1. Terms and Facts for the Customer Rule.\nThe rule itself has been expressed in declarative manner. This means, in part, that it does not indicate any particular process, procedure, or other means to enforce or apply it. It is simply a rule — nothing more, and nothing less.\nDeclarative also means that the rule makes no reference to any business event or update event where it potentially could be violated and/or needs to be tested — that is, where it needs to fire. The rule does not say, for example, ""When a customer places an order, then ....""\nThis observation is extremely important for the following reason. ""When a customer places an order"" is not the only event when the rule could potentially be violated. Actually, there is another event when this rule could be violated. In business terms this other event might be ""When an agent leaves our company...."" The corresponding update event might be ""When an agent is deleted...."" This other event could pose a violation of the rule under the following circumstances: (a) The agent is assigned to a customer, and (b) that customer has placed at least one order.\nIn other words, the rule could potentially be violated during two quite distinct kinds of events. The first — ""When a customer places an order ..."" — is rather obvious. The second — ""When an agent leaves the company ..."" — might be much less so. Both events are nonetheless important because either could produce a violation of the rule.\nThis example is not atypical or unusual in any way. In fact, it is quite commonplace. In general, every business rule (in proper declarative form) produces two or more kinds of events where it could potentially be violated and/or needs to be evaluated (i.e., needs to fire), both at the business perspective and the system perspective.\nIn summary, what does this analysis reveal about the relationship between rules, events, and processes? First, it illustrates the basic point that rules and events, while related, are not the same. Second, it illustrates that there are always potentially multiple events where any given rule needs to fire (be evaluated). Figures 2 and 3 provide additional examples to reinforce this crucial point. Finally, it illustrates that the relationship between processes and rules is an indirect one — processes produce events, and events in turn should fire rules.\nFigure 2. Multiple Events for a Simple Rule.\nRule: A customer must have an address.\nThis rule produces…\nUpdate event #1: When an instance of customer is created.\nUpdate event #2: When an attempt occurs to delete (nullify) the value of address.\nFigure 3. Multiple Events for a More Complex Rule.\nRule: A territory must not include more than one of the following:\n* Non-candidate traditional gas station.\n* Food outlet.\nThis rule produces…\nUpdate event #1: When an instance of territory is created.\nUpdate event #2: When an instance of direct outlet is added to (included in) an existing territory.\nUpdate event #3: When an instance of direct outlet already included in a territory changes kind.\nUpdate event #4: When an instance of traditional gas station already included in a territory gets or changes evaluation.\n Excerpted from Chapter 2, Business Rule Concepts: Getting to the Point of Knowledge (Second Edition), by Ronald G. Ross, September 2005. ISBN 0-941049-06-X - www.BRSolutions.com\n An obvious exception is if the rule is qualified in such manner that it applies only when a given event occurs, for example: A customer must be assigned to an agent who lives in the same city at the time of assignment.\n# # #', 'Process Modeling Notations\nThe following sections describe further process modeling notations.\nBusiness process description (RACI-Notation)\nFor an initial process capture without a special modeling tool the Excel spreadsheet can be used. The following picture shows the first worksheet of the RACI where the overall process flow has to be captured:\nBusiness Process Description (RACI) I\nThe second worksheet provides all necessary details on process step level:\nBusiness Process Description (RACI) II\nThe Business Process Description Excel spreadsheet basically collects or describes all the steps that have to be performed to fulfill a Business Process or it\'s Variant.\nThe most important parameters are:\n1. Input and Output of each process steps\n2. The involved roles and their relation to the step. I.e. that\'s where the RACI naming comes from a person can either be:\n2.1. R: Responsible is the person who carries out the activity\n2.2. A: Accountable; person who decides\n2.3. C: Consulted; person asked before carrying out the activity or who supports the activity\n2.4. I: Informed; person has to be informed\n3. The Systems, Components and Business Objects involved\nMore information can be captured and the Excel spreadsheet can easily be enhanced and tailored to project needs.\nIt is important to understand that on this level the process steps are addressed. If it is necessary to document single activities the spreadsheet can be enhanced by a column to indicate that level 6 of the process model is captured.\nTo transform a Business Process Description into an ARIS Model the EPC Model has to be used (because level 5 is documented). The respective connectors to build RACI oriented relations are provided in the chapter ""Business Process Modeling - Event Driven Process Chain (EPC)"".\nBusiness Process Modeling Notation (BPMN)\nBPMN is an abbreviation for Business Process Modeling Notation and represents a model type. Compared to the Event Driven Process Chain (EPC), BPMN is a rather modern notation. BPMN was developed and published in 2002 by Stephen A. White.\nOriginally BPMN was developed by the Business Process Management Initiative (BPMI). However it was handed over to the Object Management Group (OMG) which is known for the development of other modeling specifications like like UML, CORBA or Model Driven Architecture. OMG is still responsible for the BPMN specification.\nBPMNs main purpose is also to visually model business processes. Even though the EPC is an accepted standard on business side it is not very popular when it comes to IT. BPMN tries to be more specific especially regarding IT relevant aspects like message flow. Another advantage is a possible translation of BPMN elements to the BPEL (Business Process Execution Language) specification. This provides the possibility to model executable business processes as also featured by NetWeaver BPM.\nComparison to EPC\nIn its current definition BPMN does provide some additional/different elements compared to EPC, however EPC does still provide a higher number of elements and symbols with business focus. EPC was developed in 1992 at the university of Saarland together with SAP-Employees and is the main process modeling notation within the ARIS Toolset. EPC mainly consists of Events and Functions. Together with logical operators and connectors this results in the definition of process flows. Additional sattelite elements provide further process specification like Roles, Entities, Information Carriers, Systems etc. that can be assigned for example to a function as input or output information.\nTransformation between EPC and BPMN\nARIS supports an automated transformation between EPCs and BPMN Model types. However since BPMN does define different elements one will face a loss of information and the BPMN model needs rework.\nTransfer of models beween ARIS and NetWeaver BPM\nCurrently there is no import feature available to import BPMN Models created in ARIS into NW BPM. One possible reason is, that the current BPMN specification does not define a serialization format (it is not defined how to actually store a BPMN model for example as an XML structure). However the OMG together with SAP are currently specifiying the next version of BPMN which will then also provide a defined format for serialization. Having this in mind we hope that there will be an automated or at least technically supported import possible. Until then it is unfortunately necessary to manually redraw these models in NW BPM.']"	['<urn:uuid:68eedb40-f89e-47b9-9608-832c1f7e42f3>', '<urn:uuid:50b26749-6366-4ff0-ac65-f3cc95209008>']	factoid	direct	short-search-query	similar-to-document	comparison	expert	2025-05-01T22:36:12.692263	6	69	1756
221	how modify trust agreement when laws family circumstances change	Trust decanting provides a way to modify trust agreements when circumstances change. It involves taking funds from an existing trust and distributing them to a new trust with more favorable terms. This allows for tweaking trustee succession provisions, converting a limited trust into a dynasty trust, changing the governing law to a less taxing state, modifying powers of appointment, merging similar trusts, and adjusting terms to provide for special needs beneficiaries.	['1. Carefully select your trustees.\n2. Define your trust beneficiaries.\n3. Include powers of appointment.\n4. Allow for trust decanting.\n5. Provide for the appointment of a trust protector.\nIf you would like us to review your trust agreements and make recommendations for improving their flexibility, please call our office now.\n1. The Wrong Trustee Can Derail Your Ultimate Wishes\nChoosing the right succession of trustees for a long-term irrevocable trust is critical to the trust’s success and longevity. You have most likely considered naming (or have already named) one or more of your family members as Trustee(s). You may have also given the ability for the Trustee to appoint additional family members because they will better understand the varying needs of your beneficiaries and will keep the costs of administering the trust down.\nHowever, your family members will not be able to fulfill all of their fiduciary obligations without hiring legal, investment, and tax advisors. These expenses will add up and can ultimately cost more than a corporate trustee, such as a bank or trust company, which will be able to meet all fiduciary obligations under one roof for one fee.\nOn the other hand, forcing your trust beneficiaries to be stuck without a reasonable means for removing and replacing trustees will land your beneficiaries and trustee in court. Therefore, it is crucial to build provisions into your trust agreement which allow beneficiaries or a trust protector (more on them below) to remove and replace trustees without court intervention.\nPlanning Tip: Selecting a trustee is one of the most important decisions you will make when creating any long-term irrevocable trust or dynasty trust. Serious consideration should be given to naming a corporate trustee, either alone or as a co-trustee with a family member or trusted advisor. A corporate trustee will act as a neutral party to oversee discretionary distributions and investment strategies that benefit both current and remainder beneficiaries. To create flexibility, specific beneficiaries (such as current income beneficiaries) or a trust protector should be given the right to remove the corporate trustee and replace it with another corporate trustee.\n2. Your Trust Beneficiaries Need to Be Clearly Defined\nYou need to carefully consider who you want to include as beneficiaries of your trust twenty, thirty, or even fifty years into the future. Should adopted children be included (both minor and adult adoptees)? How about children born using “assisted reproductive technology”? In the past the definition of a “descendant” or “child” was straightforward, but today it can encompass much more than blood heirs.\nPlanning Tip: While you cannot predict or foresee everything that will happen in the future, you should carefully consider who you want to provide for after you are gone. Clearly defining the class of beneficiaries who will benefit from your trust will allow for a smooth transition between generations and potentially head off litigation.\n3. Powers of Appointment Can Add or Eliminate Beneficiaries\nIf you are concerned about how your children, grandchildren, or even great grandchildren will eventually grow up, you can build flexibility into a dynasty trust by giving your spouse or other beneficiaries the ability to include or exclude heirs through the use of powers of appointment. A power of appointment is also important if a trust is designed as a dynasty trust but the beneficiary fails to have children, and it can also be used to include or exclude charitable beneficiaries.\nPlanning Tip: Powers of appointment at each generation should be considered when creating a trust that is intended to last for decades into the future. In many cases, the powers can be as limited or as broad as you desire without creating any gift tax or estate tax problems.\n4. Trust Decanting Takes Something Old and Makes it New\nTrust decanting involves taking the funds from an existing trust and distributing them to a new trust that has different and more favorable terms. Decanting should be included in your trust agreement because it allows the following:\nTweaking trustee succession provisions.\nConverting a trust that terminates when a beneficiary reaches a certain age into a dynasty trust.\nChanging a support trust into a full discretionary trust so that a beneficiary’s creditors cannot reach the trust.\nClarifying ambiguities or drafting errors in the trust agreement.\nChanging the governing law or trust situs to a less taxing state.\nModifying powers of appointment.\nMerging similar trusts into a single trust or creating separate trusts from a single trust.\nAdjusting the trust terms to provide for a special needs beneficiary.\nPlanning Tip: You may be concerned that building decanting provisions into your dynasty trust will defeat your long-term goals and intent. Nonetheless, without building any flexibility into your trust agreement from the beginning, it is likely that your heirs will end up in court to fix a trust that no longer makes practical or economic sense.\n5. Trust Protectors Can Fix Just About Any Problem\nA trust protector is an individual or entity that is empowered to see that your wishes are ultimately fulfilled. A trust protector’s duties can be as limited or as broad as you choose. In essence a trust protector can be given the power to modify the terms of a trust without necessarily having to decant it and to address unforeseeable events such as changes in tax laws or family dynamics.\nPlanning Tip: Of any of the options you can include in your trust agreement to insure flexibility, a trust protector is in and of itself the most flexible. This is because a trust protector can be given the right to appoint, remove and replace trustees; include or exclude beneficiaries; adjust powers of appointment; and decant the trust into a new one. Therefore, trust protector provisions should be included in all of your trust agreements.\nAre Your Trust Agreements Flexible?\nUnfortunately trust agreements that are more than a few years old usually lack flexibility provisions for allowing the trust terms to be adjusted as the needs of the beneficiaries and governing laws change. The good news is that modern trust law contemplates these changes and can be invoked to fix an old trust that has gone awry.\nIf you are interested in learning how to build flexibility into your revocable trust or how to modify an existing irrevocable trust, please contact us.']	['<urn:uuid:5a58f614-2f08-42ef-bc85-e0a78e61a510>']	open-ended	direct	long-search-query	distant-from-document	single-doc	novice	2025-05-01T22:36:12.692263	9	71	1049
222	What happened to the stock market crashes after 1994 compared to the crashes before that year in terms of duration and losses?	After 1994, market crashes became more severe and longer lasting. The bear markets following the Nifty Fifty crash in the mid-70s and Black Monday of 1987 had average losses of about 40 percent and lasted 240 days, while the dot-com and credit crises lost on average about 52 percent and lasted over 430 days.	['SIX years after the financial meltdown there is once again talk about market bubbles. Are stocks succumbing to exuberance? Is real estate? We thought we had exorcised these demons. It is therefore with something close to despair that we ask: What is it about risk taking that so eludes our understanding, and our control?\nPart of the problem is that we tend to view financial risk taking as a purely intellectual activity. But this view is incomplete. Risk is more than an intellectual puzzle — it is a profoundly physical experience, and it involves your body. Risk by its very nature threatens to hurt you, so when confronted by it your body and brain, under the influence of the stress response, unite as a single functioning unit. This occurs in athletes and soldiers, and it occurs as well in traders and people investing from home. The state of your body predicts your appetite for financial risk just as it predicts an athlete’s performance.\nIf we understand how a person’s body influences risk taking, we can learn how to better manage risk takers. We can also recognize that mistakes governments have made have contributed to excessive risk taking.\nConsider the most important risk manager of them all — the Federal Reserve. Over the past 20 years, the Fed has pioneered a new technique of influencing Wall Street. Where before the Fed shrouded its activities in secrecy, it now informs the street in as clear terms as possible of what it intends to do with short-term interest rates, and when. Janet L. Yellen, the chairwoman of the Fed, declared this new transparency, called forward guidance, a revolution; Ben S. Bernanke, her predecessor, claimed it reduced uncertainty and calmed the markets. But does it really calm the markets? Or has eliminating uncertainty in policy spread complacency among the financial community and actually helped inflate market bubbles?\nWe get a fascinating answer to these questions if we turn from economics and look into the biology of risk taking.\nONE biological mechanism, the stress response, exerts an especially powerful influence on risk taking. We live with stress daily, especially at work, yet few people truly understand what it is. Most of us tend to believe that stress is largely a psychological phenomenon, a state of being upset because something nasty has happened. But if you want to understand stress you must disabuse yourself of that view. The stress response is largely physical: It is your body priming itself for impending movement.\nAs such, most stress is not, well, stressful. For example, when you walk to the coffee room at work, your muscles need fuel, so the stress hormones adrenaline and cortisol recruit glucose from your liver and muscles; you need oxygen to burn this fuel, so your breathing increases ever so slightly; and you need to deliver this fuel and oxygen to cells throughout your body, so your heart gently speeds up and blood pressure increases. This suite of physical reactions forms the core of the stress response, and, as you can see, there is nothing nasty about it at all.\nFar from it. Many forms of stress, like playing sports, trading the markets, even watching an action movie, are highly enjoyable. In moderate amounts, we get a rush from stress, we thrive on risk taking. In fact, the stress response is such a healthy part of our lives that we should stop calling it stress at all and call it, say, the challenge response.\nThis mechanism hums along, anticipating challenges, keeping us alive, and it usually does so without breaking the surface of consciousness. We take in information nonstop and our brain silently, behind the scenes, figures out what movement might be needed and then prepares our body. Many neuroscientists now believe our brain is designed primarily to plan and execute movement, that every piece of information we take in, every thought we think, comes coupled with some pattern of physical arousal. We do not process information as a computer does, dispassionately; we react to it physically. For humans, there is no pure thought of the kind glorified by Plato, Descartes and classical economics.\nOur challenge response, and especially its main hormone cortisol (produced by the adrenal glands) is particularly active when we are exposed to novelty and uncertainty. If a person is subjected to something mildly unpleasant, like bursts of white noise, but these are delivered at regular intervals, they may leave cortisol levels unaffected. But if the timing of the noise changes and it is delivered randomly, meaning it cannot be predicted, then cortisol levels rise significantly.\nUncertainty over the timing of something unpleasant often causes a greater challenge response than the unpleasant thing itself. Sometimes it is more stressful not knowing when or if you are going to be fired than actually being fired. Why? Because the challenge response, like any good defense mechanism, anticipates; it is a metabolic preparation for the unknown.\nYou may now have an inkling of just how central this biology is to the financial world. Traders are immersed in novelty and uncertainty the moment they step onto a trading floor. Here they encounter an information-rich environment like none other. Every event in the world, every piece of news, flows nonstop onto the floor, showing up on news feeds and market prices, blinking and disappearing. News by its very nature is novel, adds volatility to the market and puts us into a state of vigilance and arousal.\nI observed this remarkable call and echo between news and body when, after running a trading desk on Wall Street for 13 years, I returned to the University of Cambridge and began researching the neuroscience of trading.\nIn one of my studies, conducted with 17 traders on a trading floor in London, we found that their cortisol levels rose 68 percent over an eight-day period as volatility increased. Subsequent, as yet unpublished, studies suggest to us that this cortisol response to volatility is common in the financial community. A question then arose: Does this cortisol response affect a person’s risk taking? In a follow-up study, my colleagues from the department of medicine pharmacologically raised the cortisol levels of a group of 36 volunteers by a similar 69 percent over eight days. We gauged their risk appetite by means of a computerized gambling task. The results, published recently in the Proceedings of the National Academy of Sciences, showed that the volunteers’ appetite for risk fell 44 percent.\nMost models in economics and finance assume that risk preferences are a stable trait, much like your height. But this assumption, as our studies suggest, is misleading. Humans are designed with shifting risk preferences. They are an integral part of our response to stress, or challenge.\nWhen opportunities abound, a potent cocktail of dopamine — a neurotransmitter operating along the pleasure pathways of the brain — and testosterone encourages us to expand our risk taking, a physical transformation I refer to as “the hour between dog and wolf.” One such opportunity is a brief spike in market volatility, for this presents a chance to make money. But if volatility rises for a long period, the prolonged uncertainty leads us to subconsciously conclude that we no longer understand what is happening and then cortisol scales back our risk taking. In this way our risk taking calibrates to the amount of uncertainty and threat in the environment.\nUnder conditions of extreme volatility, such as a crisis, traders, investors and indeed whole companies can freeze up in risk aversion, and this helps push a bear market into a crash. Unfortunately, this risk aversion occurs at just the wrong time, for these crises are precisely when markets offer the most attractive opportunities, and when the economy most needs people to take risks. The real challenge for Wall Street, I now believe, is not so much fear and greed as it is these silent and large shifts in risk appetite.\nI consult regularly with risk managers who must grapple with unstable risk taking throughout their organizations. Most of them are not aware that the source of the problem lurks deep in our bodies. Their attempts to manage risk are therefore comparable to firefighters’ spraying water at the tips of flames.\nTHE Fed, however, through its control of policy uncertainty, has in its hands a powerful tool for influencing risk takers. But by trying to be more transparent, it has relinquished this control.\nForward guidance was introduced in the early 2000s. But the process of making monetary policy more transparent was in fact begun by Alan Greenspan back in the early 1990s. Before that time the Fed, especially under Paul A. Volcker, operated in secrecy. Fed chairmen did not announce rate changes, and they felt no need to explain themselves, leaving Wall Street highly uncertain about what was coming next. Furthermore, changes in interest rates were highly volatile: When Mr. Volcker raised rates, he might first raise them, cut them a few weeks later, and then raise again, so the tightening proceeded in a zigzag. Traders were put on edge, vigilant, never complacent about their positions so long as Mr. Volcker lurked in the shadows. Street wisdom has it that you don’t fight the Fed, and no one tangled with that bruiser.\nUnder Mr. Greenspan, the Fed became less intimidating and more transparent. Beginning in 1994 the Fed committed to changing fed funds only at its scheduled meetings (except in emergencies); it announced these changes at fixed times; and it communicated its easing or tightening bias. Mr. Greenspan notoriously spoke in riddles, but his actions had no such ambiguity. Mr. Bernanke reduced uncertainty even further: Forward guidance detailed the Fed’s plans.\nUnder both chairmen fed funds became far less erratic. Whereas Mr. Volcker changed rates in a volatile fashion, up one week down the next, Mr. Greenspan and Mr. Bernanke raised them in regular steps. Between 2004 and 2006, rates rose .25 percent at every Fed meeting, without fail... tick, tick, tick. As a result of this more gradualist Fed, volatility in fed funds fell after 1994 by as much as 60 percent.\nIn a speech to the Cato Institute in 2007, Mr. Bernanke claimed that minimizing uncertainty in policy ensured that asset prices would respond “in ways that further the central bank’s policy objectives.” But evidence suggests that quite the opposite has occurred.\nCycles of bubble and crash have always existed, but in the 20 years after 1994, they became more severe and longer lasting than in the previous 20 years. For example, the bear markets following the Nifty Fifty crash in the mid-70s and Black Monday of 1987 had an average loss of about 40 percent and lasted 240 days; while the dot-com and credit crises lost on average about 52 percent and lasted over 430 days. Moreover, if you rank the largest one-day percentage moves in the market over this 40-year period, 76 percent of the largest gains and losses occurred after 1994.\nI suspect the trends in fed funds and stocks were related. As uncertainty in fed funds declined, one of the most powerful brakes on excessive risk taking in stocks was released.\nDuring their tenures, in response to surging stock and housing markets, both Mr. Greenspan and Mr. Bernanke embarked on campaigns of tightening, but the metronome-like ticking of their rate increases was so soothing it failed to dampen exuberance.\nThere are times when the Fed does need to calm the markets. After the credit crisis, it did just that. But when the economy and market are strong, as they were during the dot-com and housing bubbles, what, pray tell, is the point of calming the markets? Of raising rates in a predictable fashion? If you think the markets are complacent, then unnerve them. Over the past 20 years the Fed may have perfected the art of reassuring the markets, but it has lost the power to scare. And that means stock markets more easily overshoot, and then collapse.\nThe Fed could dampen this cycle. It has, in interest rate policy, not one tool but two: the level of rates and the uncertainty of rates. Given the sensitivity of risk preferences to uncertainty, the Fed could use policy uncertainty and a higher volatility of funds to selectively target risk taking in the financial community. People running factories or coffee shops or drilling wells might not even notice. And that means the Fed could keep the level of rates lower than otherwise to stimulate the economy.\nIT may seem counterintuitive to use uncertainty to quell volatility. But a small amount of uncertainty surrounding short-term interest rates may act much like a vaccine immunizing the stock market against bubbles. More generally, if we view humans as embodied brains instead of disembodied minds, we can see that the risk-taking pathologies found in traders also lead chief executives, trial lawyers, oil executives and others to swing from excessive and ill-conceived risks to petrified risk aversion. It will also teach us to manage these risk takers, much as sport physiologists manage athletes, to stabilize their risk taking and to lower stress.\nAnd that possibility opens up exciting vistas of human performance.']	['<urn:uuid:5fd8b5fa-5b7e-454a-8861-2c54acc16970>']	factoid	direct	verbose-and-natural	similar-to-document	single-doc	novice	2025-05-01T22:36:12.692263	22	54	2191
223	ways start discussion cyberbullying teens	Some ways to start the conversation include asking: 'Do you feel like you can tell me if you ever have a problem at school or online?', 'Who are your friends on Facebook?', and 'I want to be your friend on Facebook. Would that be OK with you? What would make it OK?'	['Contributor: Daniela Isakov, MD\nCleveland Clinic is a non-profit academic medical center. Advertising on our site helps support our mission. We do not endorse non-Cleveland Clinic products or services. Policy\nCyberbullying, like any bullying, is repetitive negative behavior that can demean or embarrass a child or teen. It can happen online in texts, emails, video game chats and on social media platforms like Facebook and Twitter.\nIt is particularly harmful because it can happen 24 hours a day, seven days a week. Messages or pictures are easily shared and can go viral. This can have long-lasting effects, long after the initial incident. This type of bullying is more challenging because children often do not report it to adults.\nRecognize the signs\nAbout 24 percent of middle and high school students have been cyberbullied at some point in their lifetimes, according to research published in 2013 by the Cyberbullying Research Center.\nWatch for the warning signs: a child who is suddenly withdrawn, doesn’t want to go to school, seems to have low self-esteem or is scared or anxious without a known reason.\nWhen to ignore it, when to act\nSometimes, responding to cyberbullying isn’t the right approach. If it’s just a single comment, ignoring it can make it stop. When it fails to get a response, this can take the air out of the bully’s sails.\nHowever, when it becomes a repeated pattern and is something violent, threatening or particularly cruel or personal that makes the victim too scared or embarrassed to go to school or hang out with friends, then it needs to be reported.\nYou should always be on the lookout and ask your children questions. There are many tools out there to help set privacy and security settings.\nThere are special software monitoring programs that can help parents monitor what is happening online. Keep computers in a public space. The bottom line is to be involved with your children and if they come to you with any concerns, take it seriously.\nIf your child is bullied:\n- Keep all written records (this includes emails or texts)\n- Help guide and coach your child\n- Get the school involved\n- Reassure your child that they have done nothing wrong\n- Call your child’s doctor and set up an appointment\n- Check out these sites: Onguard Online and NetSmartz\nRELATED: Why Energy Drinks and Your Children Don’t Mix\nTeach kids: ‘Think before you click’\nThe great life lesson, think before you act, applies especially to the instant communication of cyberspace.\nHere are some suggested talking points to guide your kids:\n- Don’t send messages or post anything when you are angry\n- Don’t write or send anything that you would not want a friend to see\n- Be as polite and courteous to people online as you are to their faces\n- Never send naked or compromising pictures of yourself to someone, even if they promise no one will see them (many times everyone ends up seeing them)\nHow to start a conversation with your teen\nOften, kids don’t tell their parents about cyberbullying because they are afraid they will be punished.\nKeep lines of communication open so that kids feel comfortable telling you they have been cyberbullied or that they have sent a picture or a message that has hurt someone or that they regret sending.\nRegular family dinners are the perfect way to stay in touch and keep your children happier and healthier.\nHere are some great ways to start the conversation:\n- Do you feel like you can tell me if you ever have a problem at school or online?\n- Who are your friends on Facebook?\n- I want to be your friend on Facebook. Would that be OK with you? What would make it OK?\nAs parents, we can’t avoid some of the hurts our children face as they grow up. But by being proactive in both understanding our kids and in learning about new technology, we can support our children and step in when it goes beyond what’s reasonable for any kid to handle.\nRELATED: Tips for Parents: Managing Medications at Home']	['<urn:uuid:93867f38-e29c-47cf-91b5-2454dc0b450f>']	factoid	direct	short-search-query	distant-from-document	single-doc	novice	2025-05-01T22:36:12.692263	5	52	688
224	old bottle transportation protection methods india	When shipping fine wines, particularly Champagne and Burgundy, bottles were carefully wrapped in cartridge paper and packed in cases lined with the same material. For shipping to places as far as India, cases were filled with salt to preserve the wine's freshness, and particularly thick bottles were used for such long voyages.	['The finest wines, when matured, are generally sent in bottles, carefully packed. Every bottle of champagne is carefully wrapped in cartridge paper, and the case lined with the same substance. This wine should never be drawn from the case until it is wanted for use. Burgundy should be kept in the same manner. The cases being filled with salt, which cannot escape, will preserve the wine fresh even in India. The bottles, however, should be more than commonly thick when designed for a voyage so long.\nCyrus Redding, Every Man his Own Butler (London, 1839)\nA young David Copperfield is banished to work at his stepfather’s dockside import-export wine and spirit warehouse:\nI know that a great many empty bottles were one of the consequences of this traffic, and that certain men and boys were employed to examine them against the light, and reject those that were flawed, and to rinse and wash them. When the empty bottles ran short, there were labels to be pasted on full ones, or corks to be fitted to them, or seals to be put upon the corks, or finished bottles to be packed in casks. All this work was my work, and of the boys employed upon it I was one.\nCharles Dickens, David Copperfield (1849)\nMost early 1600s English wine bottles were thin-walled and better suited for carrying wine from cask to table than for heavier-duty storage and shipping. In the 1630s, thicker walled “shaft and globe” and then (around 1670) “onion bottles” began to be produced. Such vessels could be filled, sealed, and sometimes packed in interlocking layers in wooden boxes for shipping.\nBy the late 1600s, it was recognized that the rounded shape of wine bottles hampered their placement during storage. John Worlidge, in his popular Vinetum Britannicum (London, 1678) states that laying bottles on their sides is to be commended as it keeps corks moist and damaging air out. He warns those who “place their Bottles on a Frame with their no[s]es downwards” that they risk sediment in the bottle being served in the first glass.\nAmong bottles with “seals” at Winterthur, the DePeyster example is of particular interest. John (or Johannes) DePeyster of Albany, New York, served as mayor, city recorder, and Commissioner of Indian Affairs at various times. The 1726 date on this special-order vessel may record when the order for a group of bottles was placed or perhaps represents the vintage of the wine to be placed in it.\nEngland; dated 1719 (bladder onion bottle), dated 1739 (octagonal bottle)\nInscribed “Cs Croon / Woodbroug / 1719” (bladder onion bottle), “*/ -R-S- / 1739” (octagonal bottle)\nBequest of Henry Francis du Pont 1961.1332, 1959.1721\nAlthough the name and initials on these bottles have yet to be identified, the vessels were special orders both in terms of their shapes and the inclusion of inscribed seals. The freeblown “Croon” bottle is a “bladder onion” form made on a modest scale from around 1715 to 1740. The rare octagonal “RS” bottle is a molded form dating from around 1720 through the 1770s.\nThe above two vessels were personalized with amateurish engraving, probably by the owners. On the “SH” bottle, the initials are stipple engraved, which called for repeated striking of the glass with a sharp tool. The shoulder of the cylindrical “W Gildas” wine bottle was inscribed with rough scratching.\nDAMON & SYLVIA, LISIMOND and CHLORIS\nJohn Faber, Jr. (engraver) after a painting by Phillippe Mercier\nThomas and John Bowles and Son (publisher)\nLondon, England; 1753–64\nInk on laid paper\nGift of Mrs. Waldron Phoenix Belknap 1960.754\nBy the time this print was published in the mid-18th century, the illustrated costumes and wine bottle forms were long out of date. The sentiment of friendship and romance shared to the accompaniment of wine, however, was timeless.\nBeginning around 1730, bottles became more cylindrical, making it easier to place them horizontally during storage to keep corks wet and better preserve the wine. Rather than being freeblown, these bottles typically were dip-molded to create the more straight-side profile. The pushed-up undersides, known as “kicks,” left a fairly even bottom edge to the bottle and kept the rough “pontil marks” created during manufacture from scratching wooden table tops. The extra surface area created by a kick may also have helped in cooling the drink when the vessel was placed in cold water or on ice.\nApplied seals on bottles sometimes carried the names or initials of owners. The larger bottle here was made for Sidney Breese, a Welshman who settled in New York City in 1730. He was a merchant specializing in imported goods, including textiles and looking glasses (mirrors). This is one of four bottles bearing the same seal.\nWine bottle (left)\nEngland; dated 1774\nInscribed “Rolle / 1774”\nBequest of Henry Francis du Pont 1959.1978\nWine bottle (right)\nHenry Ricketts & Co.\nBristol, England; 1821–35\nInscribed “W.M.C.” (seal), “PATENT” (shoulder), and “H RICKETTS & Co. / GLASS WORKS BRISTOL.” (underside)\nGift of Mrs. Harry W. Lunger 1973.452.1\nIn 1821 English glassmaker Henry Ricketts patented a new method of molding glass bottles. His full-size, three-part molds completed the upper portion of the bottle as well as the walls and bottom, making vessels more consistent in shape and volume. By this time, complaints and legislation to try to curb trickery by wine-sellers who sold smaller capacity bottles than were promised had a long history. Another mold was pushed up from the bottom to create the “kick” and provide the maker’s name in relief. Within about 20 years, American manufacturers patented similar methods of bottle making. The bottle shown here bears an applied and stamped seal with the original owner’s initials.\nThis children’s book tells of an elegant entertainment at an alderman’s house in Bow, England. The details of the story are related in an alphabetical rhyme and include references to several alcoholic beverages. Alcohol consumption is virtually never referred to in modern children’s books but was considered a part of everyday life in the past. The following verse appears on a page adorned with wine bottles, and a musical scene:\nW was the wine of all sorts: but I think\nIt would be hard to tell you how much they did drink.\nHallmarked silver corkscrews were popular by the mid-1700s, and variations were soon available in steel and other metals. They are listed fairly often in 18th-century Pennsylvania and Virginia Gazette advertisements. The “silver and steel corkscrews” in Catharine Rathell’s 1772 Williamsburg, Virginia, ad indicate she sold such items in different materials and, presumably, at different prices.\nThe “peg and worm” corkscrew shown here features a pick that can be used to remove smaller corks. Two of the other corkscrews feature protective cylindrical cases that, when inserted in the loops, form handles. The simpler of the two folding corkscrews is known as an Irish bow or Irish harp. The other looks much like a modern Swiss Army knife.']	['<urn:uuid:569006ce-455f-412c-a761-b956e87cf4cd>']	open-ended	direct	short-search-query	distant-from-document	single-doc	novice	2025-05-01T22:36:12.692263	6	52	1154
226	What are the key similarities and differences between ancient Roman elections and modern democratic elections in terms of citizen participation and voting rights?	In both ancient Rome and modern democracies, citizens have the right to participate in elections and choose their representatives. However, there are significant differences in how inclusive these systems are. In ancient Rome, voting power was unequal and based on wealth, women couldn't vote or hold office, and only rich aristocrats could become consuls, senators, or governors. Modern democratic standards are more inclusive, requiring universal and equal suffrage for all adult citizens, protecting their rights to form political parties, and allowing nearly all adult citizens to stand as candidates. Modern democracies also emphasize the importance of fair electoral processes, requiring independent news media access, proper voter registration systems, and protection against widespread fraud in vote counting.	"['As someone who has studied the establishment and breakdown of democratic regimes for the past twenty-odd years, I’ve spent a fair amount of time evaluating the conduct of elections from afar. Based on that experience, I can say with some confidence that election-watching has been radically transformed by the global spread of digital connectivity.\nMost significant, both the volume and quality of information about the conduct of elections has increased by orders of magnitude. Twenty-five years ago, few elections were monitored by international observers, and local and regional press accounts were sparse and hard to track down. Fifteen years ago, you could find a report from international observers on many elections, but those reports weren’t always reliable, and lots of elections–especially in Africa and Asia–still went without. Even five years ago, the roster of countries covered had grown a bit more, and online news services were providing access to a lot more local reporting, but shoddy infrastructure and censorship meant you still had to hunt and peck for informative nuggets, especially from poorer countries.\nAll that has changed dramatically in the past few years. Now, we can visit an NGO’s web site and scan thousands of tweeted accounts on today’s elections in the Democratic Republic of Congo, one of the poorest countries in the world. We can click over the Guardian‘s Middle East Live blog and catch the latest reports on today’s parliamentary balloting in Egypt. We can pick up the newspaper and read about how Russians are using their smartphones to record and share evidence of abuses in the build-up to that country’s upcoming vote–and then go to YouTube and see what they’re talking about.\nAll of this information is a tremendous opportunity, but it also poses some new challenges. When you’re on the lookout for electoral malfeasance, there’s almost always some noise to be found. Often, the closer you listen, the more noise you hear. The difficult part is turning all that noise into a signal, and that only gets harder when the information is, essentially, endless. (Do date-constrained Lexis-Nexis and Twitter searches on “Egypt” and “elections” and just try reading everything that comes up. I dare you.)\nThe only way to try to relate all of that information to some judgment about the nature of the regime the election produces is to start with a conceptual framework that connects election procedures and the context in which they occur to specific criteria about what constitutes democracy. In other words, you have to decide ahead of time a) what your standards are and b) what kind of evidence you’re going to use to decide whether or not those standards have been met. Even that turns out to be harder than it sounds.\nAs I see it, competitive elections are the procedural core of contemporary democracy. The notion of democracy is rooted in principles of participation, responsiveness, and accountability, and in large, modern states, regular elections have emerged as the most efficient and most effective way to translate these principles into action. Democracy is rooted in the idea of the rule of the people—the notion that a government is established by, of, and for the citizens of a particular state. On the scale of the modern state, where citizens typically number in the millions, direct democracy is impractical, if not impossible, so citizens instead choose representatives who are empowered and expected to act on their behalf. Elections to select those representatives provide regular avenues for citizens to participate as voters, as partisan activists, and even as candidates. Elections also ensure that citizens have frequent opportunities to hold their representatives accountable for their actions in office. That mechanism of accountability, in turn, encourages representatives to be responsive to their constituents’ concerns, and it ensures that citizens may replace them if they are not.\nSome scholars have rightly cautioned against tying the concept of democracy too tightly to elections, a mistake Terry Lynn Karl famously characterized as the “fallacy of electoralism.” Nevertheless, nearly every major definition of democracy put forward in recent decades identifies elections as one of, if not the, critical procedural element of democracy today. As Samuel Huntington put it in The Third Wave, “Elections, open, free and fair, are the essence of democracy, the inescapable sine qua non.”\nOf course, the occurrence of elections alone is hardly enough to make democracy. Some of the world’s most oppressive regimes have held regular elections with high turnouts, yet governments such as the USSR’s or Iraq’s under Saddam Hussein could hardly be characterized as responsive or accountable. To judge the presence of democracy, we have to examine the qualities of the electoral process and, to some extent, the broader context in which those elections occur.\nWhen I’m looking at observer reports, news stories, and now online streams of information about the conduct of elections, I’m thinking of democracy as a form of government in which a free citizenry fairly chooses and routinely holds accountable its rulers. In practice, this occurs when four general conditions hold:\n- Elected officials rule. Representatives chosen by citizens actually make policy, and unelected individuals, bodies, and organizations cannot veto those representatives’ decisions.\n- Elections are fair and competitive. The process by which citizens elect their rulers provides voters with meaningful choice and is free from deliberate fraud or abuse.\n- Politics is inclusive. Adult citizens have equal rights to vote and participate in government and fair opportunity to exercise those rights.\n- Civil liberties are protected. Freedoms of speech, association, and assembly give citizens the chance to deliberate on their interests, to organize in pursuit of those interests, and to monitor the performance of their elected representatives and the bureaucracies on which those officials depend.\nIn practical terms, that means looking for evidence that helps answer the following questions:\n1. Are the officials who actually rule chosen through elections?\n- The head of government is chosen directly or indirectly by popular election, or he/she is the constitutionally designated successor to an elected head of government who has resigned, died, or become incapacitated while in office.\n- The members of the legislature are chosen by popular election.\n- No unelected individual, body, or organization—domestic or foreign—wields veto power across a range of national policy issue areas.\n2. Are those elections competitive?\n- At least two independent political parties field candidates for most or all national offices, including the head of government in cases where that office is filled directly by election.\n- Independent news media exist and are accessible to most citizens.\n- Processes of voter registration and identification and lists of registered voters are not manipulated, restricted, or impeded on a large scale to partisan advantage.\n- State resources are not used directly and extensively in political campaigns to the advantage of incumbent officeholders.\n- The vote-tallying process is not subject to abuse or fraud that is widespread or sufficient to change either the balance of power in the legislature or the outcome of a direct election for head of government.\n3. Is the political process broadly inclusive?\n- Citizens may form independent political parties or associations without substantial interference or impediment by the state.\n- Nearly all adult citizens may stand as candidates for office.\n- Elections are based on the principals of universal and equal suffrage.\nThose criteria still leave a lot of room for subjective judgment (e.g., when does the use of state resources on behalf of incumbent office-holders become “extensive”?). Even so, I think they’re specific enough to allow us to make sharper judgments about specific cases. For example, applying these criteria to today’s elections in Egypt, we can see that even wonderfully fair and competitive elections would not qualify that country as a democracy (yet) because a self-selected council of military officers continues to serve as Egypt’s executive authority, giving us a “no” to the first question. In DROC, it’s the reverse; rulers will claim an electoral mandate, but those elections won’t have been sufficiently competitive to qualify the resulting regime as a democracy.\nOf course, those are not natural facts; they are my personal judgments, based on a specific idea of what democracy is, and what brings it into being. However you define democracy, though, the broader point holds. Information about the conduct of elections may no longer be scarce, but it’s still impossible to make sense of all that noise without stepping away from the live streams long enough to develop some clear ideas about the concept of democracy it’s all meant to express.', ""The Roman Republic\nHistory >> Ancient Rome\nFor 500 years Ancient Rome was governed by the Roman Republic. This was a form of government that allowed for people to elect officials. It was a complex government with a constitution, detailed laws, and elected officials such as senators. Many of the ideas and structures of this government became the basis for modern democracies.\nWho were the leaders of the Roman Republic?\nThe Roman Republic had a number of leaders and groups that helped to govern. Elected officials were called magistrates and there were different levels and titles of magistrates. The Roman Government was very complicated and had lots of leaders and councils. Here are some of the titles and what they did:\nThe Roman Senate\nby Cesare Maccari\n- At the top of the Roman Republic was the consul. The consul was a very powerful position. In order to keep the consul from becoming a king or dictator, there were always two consuls elected and they only served for one year. Also, the consuls could veto each other if they didn't agree on something. The consuls had a wide range of powers; they decided when to go to war, how much taxes to collect, and what the laws were.\n- The Senate was a group of prestigious leaders who advised the consuls. The consuls usually did what the Senate recommended. Senators were selected for life.\n- The Plebeian Council was also called the Peoples Assembly. This was how the common people, plebeians, could elect their own leaders, magistrates, pass laws, and hold court.\n- Tribunes were the representatives of the Plebeian Council. They could veto laws made by the Senate.\n- As Rome conquered new lands, they needed someone to be the local ruler. The Senate would appoint a governor to rule the land or province. The governor would be in charge of the local Roman army and would also be responsible to collect taxes. Governors were also called proconsuls.\n- An Aedile was a city official who was responsible for the maintenance of public buildings as well as public festivals. Many politicians who wanted to be elected to a higher office, like consul, would become aedile so they could hold big public festivals and gain popularity with the people.\n- The Censor counted the citizens and kept track of the census. They also had some responsibilities to maintain public morality and to look after public finances.\nThe Roman Republic did not have a precise written constitution. The constitution was more of a set of guidelines and principals that were passed down from generation to generation. It provided for separate branches of government and balances of power.\nWere all people treated equally?\nNo, people were treated differently based on their wealth, gender, and citizenship. Women did not get the right to vote or hold office. Also, if you had more money, you got more voting power. Consuls, Senators, and Governors only came from the rich aristocracy. This may sound unfair, but it was a big change from other civilizations where the average person had no say at all. In Rome, the regular people could band together and have considerable power through the Assembly and their Tribunes.\nTake a ten question quiz\nabout this page.\nFor more about Ancient Rome:\nHistory >> Ancient Rome""]"	['<urn:uuid:139d18ad-3d29-4500-8ff7-b974c01aa05f>', '<urn:uuid:fea00b8a-e425-4e74-b362-a6db4f929376>']	open-ended	direct	verbose-and-natural	similar-to-document	three-doc	novice	2025-05-01T22:36:12.692263	23	116	1966
227	watering hours nassau county lawns allowed	According to Nassau County's Lawn Watering Ordinance, watering is prohibited between 10 a.m. and 4 p.m. Additionally, odd-numbered homes and businesses can only water on odd-numbered days, while even-numbered homes and businesses can only water on even-numbered days.	['Plainview Water District launched the Preserve Plainview water conservation campaign to ensure our area’s water source is healthy and sustainable. This page will serve as your resource to access information about how to conserve water and why it is important. We look forward to your participation in this ever-important campaign to preserve and protect our most precious natural resource.\nPlainview Water District wants to remind you that we can all help to conserve water. And remember, conserving water around your home also helps save you money on your water bill!\nAs a service to our customers, we’ve provided a list of tips and techniques affecting your water usage. Take a look.\nSmart Irrigation Controllers\nReplacing a standard irrigation timer with a smart irrigation controller is the most effective way to save a significant amount of water and reduce your water bill during the irrigation season.\nIn the Garden\n- Follow Nassau County’s Lawn Watering Ordinance\n- Watering is prohibited between 10 a.m. and 4 p.m.\n- Odd-numbered homes and businesses can only water on odd-numbered days\n- Even-numbered homes and businesses can only water on even-numbered days\n- Limit the amount of time you spend watering your lawn. The average lawn needs only 1 to 2 inches of water per week. If you see footprints in the grass when you walk across your lawn during the summer, it’s time to water.\n- Before watering, check the weather forecast. Periods of cool, cloudy weather reduce the need to water.\n- Avoid watering your lawn on windy days.\n- Place mulch or peat moss around your plants to retain moisture.\n- Don’t over-water the lawn; set a timer to keep track of how much watering has been done.\n- Check with your local nursery for a list of low maintenance plants that require less water.\n- Adjust water sprinklers so they water your plants, not the driveway or sidewalk.\n- Winterize underground sprinkler systems.\n- Water your lawn responsibly. See our lawn irrigation conservation tips.\n- Disconnect all outdoor hoses before winter. Drain and store them.\n- Turn off the water that leads to the outside of your house during the winter.\n- Leave outside water faucets open. This allows any trapped water to expand after a freeze and prevents broken pipes during the winter.\n- Cover your outdoor pool or spa to reduce evaporation during the winter. See all pool conservation tips.\n- Check your pool’s walls and filtration system. Make repairs where needed.\n- Use a broom or rake to clean sidewalks or driveways, instead of hosing them down.\n- Wash the car with soap, water and a bucket. Use a hose with a shut-off nozzle for a quick final rinse.\n- Turn the faucet off while you brush your teeth, wash your face or shave.\n- Reduce the amount of time you spend in the shower.\n- Replace standard showerheads with low-volume heads or flow restrictors.\n- Don’t run water before closing the drain and filling up the bathtub.\n- Change your toilets to ultra-low flush models.\n- Check your toilets regularly for leaks or plumbing problems.\n- Don’t use your toilet as a wastebasket or ashtray. Extra flushes waste water.\n- Capture running water while waiting for the water temperature to change before your shower. The excess water can be used to water plants.\n- Clean vegetables using water in a pan and a vegetable brush instead of under running water.\n- Wait until you have a full load of dishes or laundry to run the dishwasher or washing machine. If you cannot wait for a full load to accumulate, set the water level to match the size of the load.\n- Don’t let the tap run while waiting for water to cool. Fill a pitcher with drinking water from the tap and store it in the refrigerator.\n- If you boil vegetables when cooking, save the water. Use it to make nutritious soups and sauces.\nWinter Conservation Tips\n- If water pipes are located in an unheated area of your house, cover the pipes with insulation to prevent freezing.\n- Disconnect all outdoor hoses, turn off the water leading outdoors and open each outdoor faucet.\n- Winterize irrigation systems by turning off the system and draining.\n- Keep any fire hydrant on your property clear of snow.\n- Know where your shut-off valve is located in case of an emergency.\n- Use a sponge mop when doing household cleaning. It uses less water than a string mop. It also takes less water to keep a sponge mop clean.\n- Pre-soak grills, oven racks, etc. overnight. Wash them with an abrasive scrub brush or pad. Use lots of “elbow grease” to minimize water use.\n- Take steps to prevent drafts in the basement so pipes won’t freeze.\n- Insulate hot water pipes to avoid wasting water while it heats.\n- Check for and repair leaks. Look for leaking faucets, toilets or pipes to reduce water waste.']	['<urn:uuid:ecaa1af4-6606-46d6-bc59-d248625caaec>']	open-ended	with-premise	short-search-query	similar-to-document	single-doc	novice	2025-05-01T22:36:12.692263	6	38	828
228	I've been studying different philosophical methodologies and I'm curious - what's the key difference between Kant's transcendental idealism and Descartes' mathematical rationalism in terms of how they approach knowledge?	While both are epistemological approaches, Kant's transcendental idealism focuses on understanding the limits of human reasoning power through a theory of space and time, trying to determine which questions are philosophically legitimate. In contrast, Descartes' mathematical rationalism emphasizes achieving certainty by following a mathematical model and deliberately renouncing questionable beliefs acquired through experience and senses, using pure reason as the path to knowledge.	"['In 1784, Kant (1724 – 1804) wrote a short essay in response to a question set by the Berlinische Monatsschrift entitled, “Answering the Question: What is Enlightenment?” The essay, brilliant in its brevity and directness, proposed that the catchcry of the Enlightenment should be Sapere aude! or Dare to be wise! True to his word, Kant embarked on expanding his critical philosophy, then well underway following the 1781 publication of the Critique of Pure Reason. By the end of his career Kant had also developed an extensive moral and aesthetic philosophy interwoven with his metaphysics, the depth and reach of which has had a lasting influence in philosophy and continues to register an impact in modern thought.\nHis epistemological position, transcendental idealism, arose out a philosophical landscape defined by the competing schools of rationalism and empiricism (thinkers such as Descartes, Locke, Leibniz, Berkeley and Hume). Through a novel theory of space and time, Kant asserts that the subject can learn the limits of its reasoning powers, and that with these limits established we can also learn which questions are philosophically legitimate and which, indeed, have certain answers. Transcendental idealism’s success derives from its attempt to leap beyond the traditional ontological distinctions of his predecessors – but are such distinctions simply replaced by equally puzzling and debatable ones, such as that between the phenomena of empirical objects versus the reality of noumena?\nIn the realm of moral philosophy Kant is famous for his assertion that in order to act morally, the subject must freely follow his reason-determined duty with complete disregard for the empirical circumstances at hand. There is an elegant simplicity to Kant’s position, but this can distract us from the more practical problems associated with this moral philosophy. Kant is aware of these problems and offers a spirited defence, pointing to the interior features of his moral philosophy: the transcendental apparatus which underwrites his tract on moral action: the freedom of the subject, the afterlife and God.\nKantian aesthetics vaulted the beautiful and the sublime into the acme of philosophy, and centred on his claim that the beautiful and the sublime are neither empirical nor ideal, harking back to the kernel of transcendental idealism. With his contention that the aesthetics of art and nature involves the play or contest of the faculties of ordinary experience, Kant also paved the way for the third critique to posit a worldview capable of uniting our potentially conflicting conceptions of metaphysics and morality. Is this agenda of the third critique successful? Can Kant’s system be regarded as complete – and sustainable?\nThis course will be taught at an intermediate level – that is, knowledge of some aspect of Kant’s philosophy, preferably of the first critique, is recommended. Our aim is to provide an overview which is as detailed as time will allow, and which will bring into focus the three main streams of the Kantian philosophy so as to elucidate their interconnectedness and interdependence.\nMonday – Thursday: Sapere aude! and the Critique of Pure Reason – Inside and outside Kant’s limits of reason (Marc)\nFriday: Kant’s moral philosophy I – The deontological position, the philosophy of the categorical imperative (Philip)\nMonday: Kant’s moral philosophy II – How is morality philosophically/critically possible? (Philip)\nTuesday – Friday: The Critique of the Power of Judgment – the beautiful, the sublime and the architectonic of Kant’s critiques (Paul)\n- Deleuze, Gilles, Kant’s Critical Philosophy: The Doctrine of The Faculties, trans. Hugh Tomlinson and Barbara Habberjam (Minneapolis: University of Minnesota Press, 2003)\nDeleuze’s book provides a brief and readable 75 page introduction to the corpus comprising Kant’s critical philosophy. For more detailed introductions to each of the three critiques respectively, see:\n- Gardner, Sebastian, Routledge Philosophy Guidebook to Kant and the Critique of Pure Reason (London: Routledge, 1999)\n- Schneewind, J. B., “Autonomy, Obligation and Virtue: An Overview of Kant’s Moral Philosophy,” in The Cambridge Companion to Kant, ed. Paul Guyer (Cambridge: Cambridge University Press, 1992), pp. 309 – 341\n- Wicks, Robert, Routledge Philosophy Guidebook to Kant on Judgment (London: Routledge, 2007)', '|Philosophy Pages||Dictionary||Study Guide||Logic||F A Q s|\nLife and Works\n. . Method\n. . Animals\n. . Doubt\n. . Cogito\n. . God\n. . Error\n. . Extension\n. . Dualism\n. . Cartesianism\nThe first great philosopher of the modern era was René Descartes, whose new approach won him recognition as the progenitor of modern philosophy. Descartes\'s pursuit of mathematical and scientific truth soon led to a profound rejection of the scholastic tradition in which he had been educated. Much of his work was concerned with the provision of a secure foundation for the advancement of human knowledge through the natural sciences. Fearing the condemnation of the church, however, Descartes was rightly cautious about publicly expressing the full measure of his radical views. The philosophical writings for which he is remembered are therefore extremely circumspect in their treatment of controversial issues.\nAfter years of work in private, Descartes finally published a preliminary statement of his views in the Discourse on the Method of Rightly Conducting the Reason (1637). Since mathematics has genuinely achieved the certainty for which human thinkers yearn, he argued, we rightly turn to mathematical reasoning as a model for progress in human knowledge more generally. Expressing perfect confidence in the capacity of human reason to achieve knowledge, Descartes proposed an intellectual process no less unsettling than the architectural destruction and rebuilding of an entire town. In order to be absolutely sure that we accept only what is genuinely certain, we must first deliberately renounce all of the firmly held but questionable beliefs we have previously acquired by experience and education.\nThe progress and certainty of mathematical knowledge, Descartes supposed, provide an emulable model for a similarly productive philosophical method, characterized by four simple rules:\nWhile engaged in such a comprehensive revision of our beliefs, Descartes supposed it prudent to adhere to a modest, conventional way of life that provides a secure and comfortable environment in which to pursue serious study. The stoic underpinnings of this ""provisional morality"" are evident in the emphasis on changing oneself to fit the world. Its general importance as an avenue to the contemplative life, however, is more general. Great intellectual upheavals can best be undertaken during relatively calm and stable periods of life.\nIn this context, Descartes offered a brief description of his own experience with the proper approach to knowledge. Begin by renouncing any belief that can be doubted, including especially the testimony of the senses; then use the perfect certainty of one\'s own existence, which survives this doubt, as the foundation for a demonstration of the providential reliability of one\'s faculties generally. Significant knowledge of the world, Descartes supposed, can be achieved only by following this epistemological method, the rationalism of relying on a mathematical model and eliminating the distraction of sensory information in order to pursue the demonstrations of pure reason.\nLater sections of the Discourse (along with the supplementary scientific essays with which it was published) trace some of the more significant consequences of following the Cartesian method in philosophy. His mechanistic inclinations emerge clearly in these sections, with frequent reminders of the success of physical explanations of complex phenomena. Non-human animals, on Descartes\'s view, are complex organic machines, all of whose actions can be fully explained without any reference to the operation of mind in thinking.\nIn fact, Descartes declared, most of human behavior, like that of animals, is susceptible to simple mechanistic explanation. Cleverly designed automata could successfully mimic nearly all of what we do. Thus, Descartes argued, it is only the general ability to adapt to widely varying circumstancesand, in particular, the capacity to respond creatively in the use of languagethat provides a sure test for the presence of an immaterial soul associated with the normal human body.\nBut Descartes supposed that no matter how human-like an animal or machine could be made to appear in its form or operations,\nit would always be possible to distinguish it from a real human being by two functional criteria.\nAlthough an animal or machine may be capable of performing any one activity as well as (or even better than) we can, he argued,\neach human being is capable of a greater variety of different activities than could be performed by anything lacking a soul.\nIn a special instance of this general point, Descartes held that although an animal or machine might be made to utter sounds resembling human speech in response to specific stimuli,\nonly an immaterial thinking substance could engage in the creative use of language required for responding appropriately to any unexpected circumstances.\nMy puppy is a loyal companion, and my computer is a powerful instrument, but neither of them can engage in a decent conversation.\n(This criterion anticipated the more formal requirements of the Turing test.)\n|History of Philosophy|']"	['<urn:uuid:bbc6d9dc-c4fb-4d1e-a3ac-0ff0911f30b1>', '<urn:uuid:33524e9c-29b6-4b89-b813-8e98302851b1>']	factoid	with-premise	verbose-and-natural	distant-from-document	comparison	expert	2025-05-01T22:36:12.692263	29	63	1473
229	Do light rays and sound waves follow similar refraction principles?	Yes, both light and sound waves follow similar refraction principles. When these waves pass from one medium to another at angles other than 90° or 0°, they change direction due to changes in their speed. For light, this is explained by Fermat's principle of least time and occurs when light enters media of different refractive indices, such as air to water. Similarly, in underwater acoustics, sound rays bend when passing through gradients of different sound speeds, which vary based on temperature, salinity, and pressure. In both cases, the frequency remains constant while the phase velocity changes at the boundary between media.	"['Fermat’s Principle-Definition, And Special Cases\nFermat’s principle states that the path taken by a ray between two given points is the path that can be traveled in the shortest time.\nTo be true in all cases, this statement must be weakened by replacing the “minimum” time with a time “at rest” relative to the path variation such that deviations in the path cause at most second-order variation in lead time.\nFermat’s principle is also known as the shortest-time principle. The refraction behavior of light has been a source of study and consternation for centuries because a simple relationship between the angle of incidence and refraction could not be established.\nIn 1621, Dutch researcher Willebrord Snell discovered that, for a given pair of media, the sine of the angle of incidence and angle of refraction maintains a constant ratio, an experiment worth trying yourself.\nAlthough Snell is correct, this observation of the effect has nothing to do with the cause. He also claimed Snell’s discovery as his own. Fermat found this acceleration absurd and looked for a reason for the behavior of light.\nSpecial Cases of Fermat’s Principle\nThere are two special cases of Fermat’s principle:\n- Isotropic Media\n- Homogeneous Media\nSince the velocity of propagation in an isotropic medium is direction-independent, the secondary wavefronts propagating from a point on the primary wavefront in a given infinitesimal time are spherical, such that their radii are perpendicular to their Common facets at points.\nBut their radii mark the direction of the light rays, and their common tangent plane is a general wavefront. Therefore, the light rays are perpendicular (orthogonal) to the wavefront.\nSince most optics courses focus on isotropic media and treat anisotropic media as an optional topic, the assumption that light rays are perpendicular to the wavefront has become so common that even Fermat’s principle is explained in terms of this assumption, but in fact, it is the Fermat principle is more general.\nIn a homogeneous medium all secondary wavefronts propagating from a given primary wavefront W within a given time Δt are congruent and have similar directions, so their envelopes W’ can be seen as the envelope of a single secondary wavefront, which maintains its orientation as its center (source) moves across W.\nIf P is its center, and P” is its point of tangency to W”, then P’ moves parallel to P, so the plane tangent to W’ at P’ is parallel to the plane tangent to W at P. Another secondary wavefront is consistent and similarly oriented centered on P’, moves with P, and meets its envelope W” at point P”.\nThen, in the same way, the plane tangent to W” at P” is parallel to the other two planes. Therefore, due to the consistent and similar orientation, the beam directions PP’ and P’P” are identical but not necessarily perpendicular to the wavefront, since the secondary wavefront is not necessarily spherical.\nWho stated Fermat’s principle?\nA French mathematician, Pierre de Fermat stated Fermat’s law.\nWhat is the Fermat principle for refraction?\nFermat’s principle states that when a light ray moves from one fixed point to another fixed point, through any number of reflections or refractions, the total optical path followed by the light ray should be stationary; it will either be minimum or maximum.\nWhy does light take the shortest path?\nFermat’s principle of the least time traveled by light is used to understand how light rays travel. According to this particular principle, the path taken by the light between any two points is the path that can be taken in the shortest time period, but it is not necessary to be the shortest path.\nCan light be slowed to zero?\nLight, which travels at a speed of 300,000 km/sec in a vacuum, can be slowed down and even stopped completely by methods that involve trapping the light inside crystals or ultracold clouds of atoms.', 'Refraction is the change in direction of a wave due to a change in its speed. It is essentially a surface phenomenon . The phenomenon is mainly in governance to the law of conservation of energy. The proper explanation would be that due to change of medium, the phase velocity of the wave is changed but its frequency remains constant. This is most commonly observed when a wave passes from one medium to another at any angle other than 90° or 0°. Refraction of light is the most commonly observed phenomenon, but any type of wave can refract when it interacts with a medium, for example when sound waves pass from one medium into another or when water waves move into water of a different depth. Refraction is described by Snell\'s law, which states that for a given pair of media and a wave with a single frequency, the ratio of the sines of the angle of incidence θ1 and angle of refraction θ2 is equivalent to the ratio of phase velocities (v1 / v2) in the two media, or equivalently, to the opposite ratio of the indices of refraction (n2 / n1):\nIn optics, refraction occurs when waves travel from a medium with a given refractive index to a medium with another at an angle. At the boundary between the media, the wave\'s phase velocity is altered, usually causing a change in direction. Its wavelength increases or decreases but its frequency remains constant. For example, a light ray will refract as it enters and leaves glass, assuming there is a change in refractive index. A ray traveling along the normal (perpendicular to the boundary) will change speed, but not direction. Refraction still occurs in this case. Understanding of this concept led to the invention of lenses and the refracting telescope.\nRefraction can be seen when looking into a bowl of water. Air has a refractive index of about 1.0003, and water has a refractive index of about 1.33. If a person looks at a straight object, such as a pencil or straw, which is placed at a slant, partially in the water, the object appears to bend at the water\'s surface. This is due to the bending of light rays as they move from the water to the air. Once the rays reach the eye, the eye traces them back as straight lines (lines of sight). The lines of sight (shown as dashed lines) intersect at a higher position than where the actual rays originated. This causes the pencil to appear higher and the water to appear shallower than it really is. The depth that the water appears to be when viewed from above is known as the apparent depth. This is an important consideration for spearfishing from the surface because it will make the target fish appear to be in a different place, and the fisher must aim lower to catch the fish.\nThe diagram on the right shows an example of refraction in water waves. Ripples travel from the left and pass over a shallower region inclined at an angle to the wavefront. The waves travel more slowly in the shallower water, so the wavelength decreases and the wave bends at the boundary. The dotted line represents the normal to the boundary. The dashed line represents the original direction of the waves. This phenomenon explains why waves on a shoreline tend to strike the shore close to a perpendicular angle. As the waves travel from deep water into shallower water near the shore, they are refracted from their original direction of travel to an angle more normal to the shoreline. Refraction is also responsible for rainbows and for the splitting of white light into a rainbow-spectrum as it passes through a glass prism. Glass has a higher refractive index than air. When a beam of white light passes from air into a material having an index of refraction that varies with frequency, a phenomenon known as dispersion occurs, in which different coloured components of the white light are refracted at different angles, i.e., they bend by different amounts at the interface, so that they become separated. The different colors correspond to different frequencies.\nWhile refraction allows for beautiful phenomena such as rainbows, it may also produce peculiar optical phenomena, such as mirages and Fata Morgana. These are caused by the change of the refractive index of air with temperature.\nRecently some metamaterials have been created which have a negative refractive index. With metamaterials, we can also obtain total refraction phenomena when the wave impedances of the two media are matched. There is then no reflected wave.\nAlso, since refraction can make objects appear closer than they are, it is responsible for allowing water to magnify objects. First, as light is entering a drop of water, it slows down. If the water\'s surface is not flat, then the light will be bent into a new path. This round shape will bend the light outwards and as it spreads out, the image you see gets larger.\nA useful analogy in explaining the refraction of light would be to imagine a marching band as they march at an oblique angle from pavement (a fast medium) into mud (a slower medium). The marchers on the side that runs into the mud first will slow down first. This causes the whole band to pivot slightly toward the normal (make a smaller angle from the normal).\nIn medicine, particularly optometry, ophthalmology and orthoptics, refraction (also known as refractometry) is a clinical test in which a phoropter may be used by the appropriate eye care professional to determine the eye\'s refractive error and the best corrective lenses to be prescribed. A series of test lenses in graded optical powers or focal lengths are presented to determine which provide the sharpest, clearest vision.\nIn underwater acoustics, refraction is the bending or curving of a sound ray that results when the ray passes through a sound speed gradient from a region of one sound speed to a region of a different speed. The amount of ray bending is dependent upon the amount of difference between sound speeds, that is, the variation in temperature, salinity, and pressure of the water. Similar acoustics effects are also found in the Earth\'s atmosphere. The phenomenon of refraction of sound in the atmosphere has been known for centuries; however, beginning in the early 1970s, widespread analysis of this effect came into vogue through the designing of urban highways and noise barriers to address the meteorological effects of bending of sound rays in the lower atmosphere.\n- Snell\'s law\n- Huygens–Fresnel principle\n- Birefringence (double refraction)\n- Negative refraction\n- List of indices of refraction\n- Total internal reflection\n- ^ ""Shoaling, Refraction, and Diffraction of Waves"". University of Delaware Center for Applied Coastal Research. http://www.coastal.udel.edu/ngs/waves.html. Retrieved 2009-07-23.\n- ^ Ward, David W; Nelson, Keith A; Webb, Kevin J (2005). ""On the physical origins of the negative index of refraction"". New Journal of Physics 7: 213. arXiv:physics/0409083. Bibcode 2005NJPh....7..213W. doi:10.1088/1367-2630/7/1/213.\n- ^ ""Eye Glossary"". http://www.eyeglossary.net/#R. Retrieved 2006-05-23.\n- ^ Navy Supplement to the DOD Dictionary of Military and Associated Terms. Department Of The Navy. August 2006. NTRP 1-02. https://www.nwdc.navy.mil/Documents/NTRP_1-02.pdf.\n- ^ Mary Somerville, On the Connexion of the Physical Sciences, J. Murray Publishers, (originally by Harvard University), 499 pages (1840)\n- ^ Hogan, C. Michael (1973). ""Analysis of highway noise"". Water Air and Soil Pollution 2 (3): 387. doi:10.1007/BF00159677.\nWikimedia Foundation. 2010.\nLook at other dictionaries:\nréfraction — [ refraksjɔ̃ ] n. f. • 1270; lat. refractio, de refringere « briser » ♦ Phys. Déviation d un rayon lumineux ou d une onde électromagnétique, qui franchit la surface de séparation de deux milieux, dans lesquels les vitesses de propagation sont… … Encyclopédie Universelle\nRefraction — Réfraction Le pinceau nous paraît brisé à cause de la réfraction de la lumière lorsque celle ci traverse le dioptre eau air. La réfraction, en physique des ondes notamment en optique, acoustique et sismologie est un phénomène de déviation d une… … Wikipédia en Français\nRefraction — Re*frac tion (r?*fr?k sh?n), n. [F. r[ e]fraction.] 1. The act of refracting, or the state of being refracted. [1913 Webster] 2. The change in the direction of ray of light, heat, or the like, when it enters obliquely a medium of a different… … The Collaborative International Dictionary of English\nrefraction — Refraction. subst. fem. Brisure. Ce qui arrive quand un rayon passe par des milieux differents. Un baston dans l eau paroist rompu à cause de la refraction … Dictionnaire de l\'Académie française\nrefraction — [ri frak′shən] n. [LL refractio] 1. the bending of a ray or wave of light, heat, or sound as it passes obliquely from one medium to another of different density, in which its speed is different, or through layers of different density in the same… … English World dictionary\nRefraction — Refraction, so v.w. Brechung. R. der Lichtstrahlen, s. u. Licht F) … Pierer\'s Universal-Lexikon\nRefraction — Refraction, s. Strahlenbrechung; Refractor, ein dioptrisches Fernrohr … Herders Conversations-Lexikon\nrefraction — (n.) 1570s, from L.L. refractionem (nom. refractio) a breaking up, noun of action from pp. stem of L. refringere to break up, from re back (see RE (Cf. re )) + comb. form of frangere to break (see FRACTION (Cf. fraction)) … Etymology dictionary\nrefraction — ► NOUN ▪ the fact or phenomenon of being refracted … English terms dictionary\nRéfraction — Le pinceau nous paraît brisé à cause de la réfraction de la lumière lorsque celle ci traverse le dioptre eau air … Wikipédia en Français']"	['<urn:uuid:b4812680-4167-4996-8a73-5ef378d0b3b1>', '<urn:uuid:c8db4420-e3f6-47c5-8336-f6d24e9e3693>']	open-ended	with-premise	concise-and-natural	similar-to-document	comparison	expert	2025-05-01T22:36:12.692263	10	101	2241
233	How large is the server space in the Quicken Loans building?	The Quicken Loans Technology Center features two 10,000 square foot server rooms.	['Quicken Loans Data Center\nThe state-of-the-art Tier III Quicken Loans Technology Center is a 66,000 square foot data center and office complex, featuring two 10,000 square foot server rooms built out for Quicken Loans and Rock Ventures family of companies. The other half of the building is made available for a future data center. It is a technological and architectural masterpiece in Detroit’s Corktown District.\n- Data centers require immense amounts of electrical power to operate daily, especially for a data center of this size. Downtime is not an option for a data center, so the backbone of the data center is a reliable electrical system with a robust sequence of operations.\n- Quicken Loans had a desire to make this data center a showpiece for all Data Centers in the region. Where most data centers prefer to stay obscure and out of the public eye, Quicken Loans wanted to make a statement for the Detroit community as well as to potential Co-location clients.\nOur Custom Solution\n- The Sequence of Operations of any data center can make or break its uptime performance. Even the smartest equipment is useless if an up-front, bullet-proof plan for the sequence is in place. The construction team relied heavily on GE and GLEP’s expertise to craft the full sequence for the project. It was then up to the GE team to implement this amongst the equipment.\n- Large Data Centers require fully redundant and automated electrical distribution systems. GE’s industry-exclusive Entellisys Low Voltage Switchgear was the perfect fit for a robust and transparent system with its redundant CPU-based technology. GE was able to fully scale and automate the substation control, while giving Quicken Loans the ability to see the health and status of their system in real-time.\n- Quicken Loans’ quest to make an attractive data center trickled all the way down to the electrical gear. Most electrical distribution equipment is standard ANSI grey. Quicken Loans didn’t want standard grey. They wanted each piece of equipment to be color-coded in blue and white for their team to quickly know which side the power was derived from. GE did not run from this requirement and Quicken Loans now has beautiful Blue and White switchgear to showcase!\n- Quicken Loans also demands the highest degree of monitoring throughout their data center and office space. It is critical for their facility team to know what is going on within their electrical system at all times, both in real-time and in historical format. The GE Envisage Power Monitoring system is a custom-made solution that dives into the entire electrical system and keeps Quicken on top of every facet of their electrical equipment.\n- Park Metal MV LIS\n- GE VPI Dry Type Substation Transformers\n- GE Entellisys LV Switchgear\n- GE Switchboards\n- GE Zenith Automatic Transfer Switches\n- GE A-Series Lighting Panels\n- GE Safety Switches\n- GE Dry-Type Transformers\n- GE Surge Protective Devices\n- GE Busway\n- GE Lighting Contactors\n- GE Envisage Power Monitoring System']	['<urn:uuid:da3b5d39-d6fc-4ad8-a520-77fbbd64f25c>']	factoid	direct	concise-and-natural	distant-from-document	single-doc	novice	2025-05-01T22:36:12.692263	11	12	501
234	government economic growth tariff relationship impact	The government's role in economic development involves creating opportunities and improving living standards through policies and investments. Tariffs are one tool governments use that has mixed effects on economic growth. While tariffs can help development by protecting local industries, creating jobs, and generating government revenue that can be reinvested in the economy, they also risk stunting growth through several mechanisms. These include reduced competition leading to inefficient domestic industries, higher prices for consumers and businesses, potential trade wars that harm exports, and limited access to foreign technology and equipment that could boost productivity. The government must therefore carefully balance protectionist measures with maintaining beneficial trade relationships and domestic market efficiency.	"[""The process of creating and maintaining an environment in which businesses and entrepreneurs can thrive, while creating new jobs and increasing economic growth.\nThe process of creating and maintaining economic opportunities in a region or country in order to improve the quality of life for citizens. Economic development is a critical component of a country's overall strategy for growth and development. Economic development projects often require a combination of public and private investment, and often involve the collaboration of government, business, and civil society organizations.\nThe process of creating and sustaining an economy in which all people can have access to the resources they need to be productive and fulfill their own needs and aspirations.\nThe process of creating jobs and increase the level of economic activity in a region. It can involve the promotion of new businesses, the development of new industries, and the improvement of infrastructure.\nThe process of creating jobs and developing the economy by encouraging business and economic growth. It also includes improving the quality of life for all citizens through innovative public policy.\nThe duty is to develop the country economically and raise the standard of living of its people. A country's economic health is measured by its gross domestic product, or GDP. GDP is the sum total of all final goods and services produced within a country in a given period. It is one of the most important indicators of a country's economic health and can be used to measure progress and prosperity. Economic development can be achieved through a variety of means, including increasing access to education and health services, increasing the productivity of the workforce, and encouraging private sector investment. The government also plays a role in economic development by providing necessary infrastructure and support for businesses.\nThe duty is a government responsibility to foster the economic progress of a country. In order to fulfill this responsibility, the government sets economic goals, provides assistance to businesses and makes policies that promote economic growth.\nThe duty is often neglected in favour of other pressing issues, such as social welfare or defence. In order to overcome this, the government has proposed a number of ways in which economic development can be prioritized, including increasing exports and attracting foreign investment. However, these measures will only be successful if the government is prepared to invest in infrastructure and provide incentives for businesses to relocate to areas with potential.\nThe duty is a key pillar in the government's policy towards growth and job creation. it has a number of key objectives, including creating a favourable business environment, encouraging foreign investment, and helping to stimulate economic growth. it also aims to improve the quality of life for the population, through initiatives such as education and health care.\nThe duty is a devolved matter for the Scottish Government. The Scottish Government has a responsibility for allocating a share of the Scottish Budget, which is allocated according to the population of each local authority. The Scottish Government's economic development duty is to help generate jobs and promote economic growth in Scotland. The Scottish Government's economic development programme helps to support businesses, create jobs and develop economies. The Scottish Government funds a range of initiatives, including business support, infrastructure projects and research and development.\nRequire knowledge, skills and abilities. It helps in increasing production, improving quality of life and creating new jobs. Economic development can be done through public or private sector. The aim of public economic development is to create jobs and increase incomes. The main instruments of public economic development are fiscal and monetary policies, public infrastructure and market promotion. Private sector economic development focuses on creating new businesses and attracting foreign investment. It is done through various means such as access to credit, investment opportunities and quality infrastructure.\nRequire lot of skill, effort and time. Economic development can be done in many ways, such as by creating new businesses, attracting new companies to an area, or improving the infrastructure. Economic development can also be done by providing financial assistance to businesses or by providing training to workers.\nRequire labor, capital and entrepreneurship. It is important to have all three in order to create new businesses and grow existing ones. The availability of capital is essential for businesses to start and grow, while the need for labor can be met by either immigrants or by the natural increase in the population. Entrepreneurship is also essential for economic development, as it allows businesses to find new and innovative ways to improve their products or services.\nRequire some skill and knowledge. Developing area is where people can find good work and have a chance to improve their living standards. There are many ways to help economic development. Governments can build new roads, railways and other infrastructure to make it easier for businesses to get around. They can also provide financial support to businesses, especially the small and medium sized ones. Non-governmental organisations (NGOs) can also help by providing training and other services to businesses.\nRequire knowledge, intelligence and hard work. Economic development is responsible for creating new jobs and improving the economy by creating businesses and industries. Economic development can also provide assistance to businesses in finding new markets and creating new products.\nHave a good understanding of the economy. You should also be able to identify opportunities and create plans to take advantage of those opportunities. You must also be able to communicate your ideas effectively to policymakers and the public.\nUnderstand the development process and have a well-organized plan. The first step is to understand your current economic situation and what needs to be done to improve it. Next, develop a comprehensive plan that outlines what needs to be done and when it should be done. Finally, execute your plan through coordinated efforts with local businesses and governments.\nHave a well-planned strategy that is backed by ample resources. Without a solid foundation, you will not be able to achieve your goals. First, you must identify the areas in which your community needs improvement. You must also develop a plan to address these needs. Once you have a strategy, you need to find the resources to put it into action. You also need to be able to keep track of your progress and make adjustments as needed.\nHave a good strategy. A good strategy starts with having a good plan. A good plan includes knowing your market, your competitors, and your target audience. You also need to have a good business plan to make sure your strategy is achievable. Finally, you need to have good execution to make sure your strategy is successful.\nHave a solid foundation in economics and finance. Economics is the study of how people use resources to produce goods and services. Finance is the study of how to manage money and financial resources. In order to be successful in economic development, you need to be able to understand how resources are allocated, how markets work, and how to make wise financial decisions."", 'PROS AND CONS OF TARIFFS\nProsand Cons of Tariffs\nProsand Cons of Tariffs\nAtariff is a tax or charge levied on imports or exports entering orleaving a particular country. While the sole purpose of the tariff isto restrict trade, there are a number of advantages that accrue withthe imposition of tariffs. Generation of income, restricting tradeand protecting industries are the advantages that accrue with theimposition of tariffs. On the other hand, the imposition of tariffsin an economy carries some disadvantages along with itsimplementation in the economy. In most cases, the increase in theprices of goods and services, reduction of sales volume and traderelations are the cons of imposing tariffs in an economy. Thediscussion on tariffs will illustrate their advantages anddisadvantages in an economy.\nTheAdvantages of tariffs\nOneof the main advantages of tariffs is the protectionism function,where they act as tools of protecting local industries from externalcompetition. Most times, consumers will opt for foreign commoditiesthat are produced instead of buying the same commodity producedlocally. This trend forces the government to impose tariffs oncertain goods so as to protect their own domestic industries or atthe same time make extra money (Gandolfo& Trionfetti,2013).It should be noted that consumers are not prohibited in any way tobuy foreign goods, but the art of imposing tariffs on those foreigngoods makes them expensive (Northrup& Turney, 2003).The consumer will have no choice but to buy the locally availableproducts produce by the local industries.\nAsa result, another advantage of tariffs, creating jobs is achieved.The imposition of tariffs leads to the creation of jobs in an economydue to the protectionist function of tariffs levied on the imports ofgoods, which can be available in the local market. By imposingtargeted tariffs on the importation of certain products, thegovernment prevents the exporting of employment to other countriesand encourages the creation of jobs in the country. This is becauseimporting goods gives the foreign producers the local market andtakes the market away from the local manufacturers (Gandolfo& Trionfetti,2013).Therefore, the local industries cannot grow when the local populationis creating a market for the foreign producers other than their ownindustries. Imposing tariffs cuts the demand and production capacityof the foreign manufactures and gives the same to the localproducers, thereby increasing local production (Gandolfo& Trionfetti,2013).By increasing production levels in the country, the tariffs end upcreating jobs locally.\nInsuch circumstances, it is the responsibility of governments toprotect their domestic employment. As we have seen above, when thereis a stiff competition of imported goods with a country’s domesticgoods, there the domestic industries end up being threatened. Thiscan result in the domestic companies firing their own employees ordeciding to shift to oversee countries, all with the purpose ofcutting costs (Smith,2005).The effect of this will result in a country having an increasednumber of unemployed, unhappy electorates. When ascending to power,many leaders always promise to create employment to their localcitizens, and tariffs open a way of preserving jobs for those whoalready have jobs.\nTheimposition of tariffs is also an advantage to the infant industriesin a country, which are competing with established internationalmanufacturers. A government can also decide to impose tariffs solelyin order to protect its own infant industries that are still tryingto pick up (Smith,2005).When a country wants to come up with its own industry, producing andsupplying a particular type of a good, it must protect the localmarket from the dominance of foreign producers. To achieve this, agovernment must make imports expensive. At the same time, thegovernment must make exports to the local consumers expensive for theforeign producer to viable pursue. To do this, the government will beforced to impose high tariffs on similar products produced fromforeign countries and in the process discouraging local consumersfrom buying the product.\nAnotheradvantage of imposing tariffs is the protection of consumers fromcheap or low quality products from foreign markets. Governments canalso choose to protect their own local consumers when they feel thatsome imported goods are low quality and promote dumping of cheapproducts from foreign producers (Michaely,2009).In such a case, a government will impose high tariff on the good, sois to discourage foreign producers from exporting them to localmarkets. At the same time, the imposition of a high tariff will forcelocal consumers to avoid them as they would be highly expensive toimport.\nTheimposition of tariffs on a product to protect consumers from lowquality products is implemented when a government has no legalgrounds of imposing a total ban on the product (Gandolfo& Trionfetti,2013).This may be as a result of lack of evidence or adherence tointernational trade agreements that may be in favor of the exportingcountry. A good example is where country A imposes a high tariff onmeat or beef from country B. Country A does this if the governmentbelieves that the meat from country B is low quality, but not enoughreason to ban its importation. As a result, the meat imports fromcountry B to country A will reduce or end, because its consumers willfind alternative market to import from.\nAnothersignificant advantage of imposing tariffs by a government is thegeneration of income from the fee levied on imports and exports.Income by the government is earned through the specific types oftariffs levied in the form of cash. For instance, the governmentraises income from the Ad valorem tariffs placed by the importingnation while putting into consideration the percentage of the goodbeing imported overall value (Gandolfo& Trionfetti,2013).\nThegovernment also raises income from the specific tariffs, where afixed fee is always levied on any amount or value of a good beingimported. For example, a country could be charging $500 for all carsbeing imported into its market. The tariff is always flexibledepending on the type of good. For instance, all fresh fruitsimported could be levied at $10 while fresh animal products beingimported could be levied at $30. All this translates into income forthe government.\nTheDisadvantages of Tariffs\nOneof the disadvantages of tariff is inefficiency of local industries,particularly when the tariffs are used as tools for protecting localindustries. When local industries are protected from foreigncompetition through tariff imposition, they face an easy tradeenvironment which may make them compromise on quality(Baier & Bergstrand, 2001). Inthis case, we can see that the art of imposing tariffs on foreigngoods can result to the local industries to be less efficient as theyare not subjected to eternal competition. At the same time, tradewars might arise between nations where the foreign nation might hitback by imposing their own tariffs on all imported goods from a givennation.\nAnotherdisadvantage of imposing tariffs is the impact they have on thebilateral and multilateral trading relationships with othercountries. The imposition of a tariff may induce a retaliatoryrelationship where the concerned countries hurt each other’s tradeby imposition of tariffs on the other country’s exports (Gandolfo& Trionfetti,2013).This may be as a result of a country being motivated to imposetariffs as a retaliation strategy. A country may think that anothercountry has not played by the agreed rules and thus is forced toimpose high taxes on all imported goods entering from the othernation. Retaliation also comes in handy when another nation simplydecides to go against the host nation on foreign government policies.\nAnotherdisadvantage of tariffs is that they create a cost aspect in theirimposition. For tariffs to be effective, they require a country toincur a cost for their imposition to be implemented. This cost is inthe form of employees for tax authorities, tariff infrastructure andsystems put in place (Gandolfo& Trionfetti,2013).The disadvantage comes where the costs incurred outweigh the benefitsgenerated from the tariff. For example, if a tariff meant to protectdomestic producers leads to high administrative costs of imposing it,it ends up being a disadvantage. This may happen where with noreasonable competition, the price of commodities will rise, whichwill also guarantee the sales of those producers to also rise.\nAnotherdisadvantage of tariffs is that they can lead to reduced employment,instead of creating or protecting local employment. Tariffs may limitthe importation of new technology and production potential to acountry, especially tariff levied on machines, raw materials andentrepreneurial equipment(Baier & Bergstrand, 2001). Ifa tariff is imposed on such goods or resources, local productionreduces as producers end up relying only on the local technology. Ifthis happens, the need for the domestic producers to employ moreworkers reduces, which will mean that the jobs will reduce in thecountry (Michaely,2009).As a result, the employment in the country reduces or stays at theold low level, other than creasing through the use of foreigntechnology.\nOnesuch good example that can show how bad tariffs can affect acountry’s economy is the imposition of tariffs on the imposition ofsteel. This will have the short run of benefiting the local producerswho will benefit from high prices to a point that they can even makehigh profits. But in the long run, the increasing cost associatedwith steel will make the cost of production in the economy high. Thelarger cost incurred are then distributed evenly to all consumersthrough high prices (O`Rourke& Smith, 2007).In addition, the production of basic goods will reduce, since steelis used in most factories. The infrastructural development willreduce as almost all industries use steel from buildings, railway,communication, and energy industries among many others. The impact isa crumbled economy, which will rely on imports to sustain itsconsumer needs.\nAnotherdisadvantage of imposing tariffs is the possibility of hurting theeconomy of the country by reducing the quantity and gains of thecountry’s exports. Remember as all this is happening, the tariffincreased and this means that the government is generating moreincome to benefit the economy. The consumer will be left with onlytwo viable options, either to buy less of those expensive goods orseek solace in buying less of other goods. With this increase inprice would mean that the consumer income will be deemed to bereduced.\nMoreimportantly, imposing high tariffs on certain goods discourages theirexportation to export and reduces the quantity of exports. This hasthe negative effect of reducing the amount of revenue a governmentcollects on such commodities (Jones& Martin, 2008).At the same time, reduced exports mean that the country’s foreignexchange will reduce. As a result, both the balance of trade andbalance of payment gets affected negatively, and reduces.\nAnotherbasic disadvantage of tariffs is that they make life expensive forlocal consumers by increasing the price of the products. As far astariffs are concerned, the consumer is always on the receiving end.This happens because the proportion of tariffs levied on imports istransferred by importers to the consumer in terms of a high price(Baier,& Bergstrand, J. (2001).The only time that consumers can be said to benefit from tariffs iswhen in the long run, the domestic industries use the advantage ofthe tariffs to improve on the quality of the production instead ofrelaxing.\nItis therefore a disadvantage that consumers benefit from the effectsof tariffs, but at a cost (O`Rourke& Smith, 2007).This happens because tariffs are designed to mostly favor the localproducers and the government. When tariffs are imposed on certaingoods, they have the impact on making related domestic production tobe favored and not the consumers. On the other hand, imposing oftariffs on certain goods ensure that the government benefits directlythrough revenue collection and not mainly consumers.\nTheimposition of tariffs has both advantages and disadvantages to theeconomy, the producers, consumer and the government. Imposing tariffsearn the government income and gives it a tool to protect localmarkets and industries from foreign markets. Imposing tariffs isadvantageous to consumers as they are protected from low qualityproducts from foreign producers. At the same time, tariffs protectproducers from competition from foreign products throughprotectionism policies. However, tariffs attract a cost in theircollection, reduce exports and may limit the introduction of foreigntechnology. At the same time tariffs may end up punishing the localconsumers as they are transferred in terms of prices. Despite thediscussed disadvantages, tariffs are not only important but necessaryfor an economy and their advantages prove the reason why they shouldbe levied.\nBaier,S., & Bergstrand, J. (2001). The growth of world trade: tariffs,transport costs, and income similarity. JournalOf International Economics,53(1),1-27.\nGandolfo,G., & Trionfetti,F. (2013). InternationalTrade Theory and Policy.New York: SpringerScience & Business Media\nJones,V., & Martin, M. (2008). Internationaltrade.[Washington, D.C.]: Congressional Research Service.\nMichaely,M. (2009). Tradeliberalization and trade preferences.Hackensack, N.J.: World Scientific.\nNorthrup,C., &Turney, E. (2003). Encyclopediaof tariffs and trade in U.S. history.Westport, Conn.: Greenwood Press.\nSmith,J. (2005). In praise of tradeoffs. BMJ,330(7498)Retrived From, <http://dx.doi.org/10.1136/bmj.330.7498.0-g>29 October, 2015']"	['<urn:uuid:a1f4d5bf-74a0-4831-8298-a554a29a3be2>', '<urn:uuid:809b5bf4-df61-42c2-8929-4f9de7462280>']	open-ended	with-premise	short-search-query	distant-from-document	multi-aspect	expert	2025-05-01T22:36:12.692263	6	110	3172
235	advantages draining water pipes versus leaving faucets running winter vacation home	For weekend getaway homes in cold areas, it's recommended to turn the water off and open the faucets when leaving for extended periods. This prevents PVC pipe damage from ice expansion, which would require under-house repairs.	['7 Wintertime Tips for the Practical Farmer\nPractical tips for farm and ranch owners aren’t necessarily important for survival, just convenience. However, it’s the little things we do that lead to overall happiness and well-being during the winter and beyond. If you’re feeling a touch of the cabin fever starting to creep in, slip on those long johns and a heavy coat and head outside because we have a list for you to do.\nDrip the Faucet\nThis isn’t really a new tactic to anyone who owns a house where it gets real cold. If this is your weekend getaway, turn the water off anytime you leave for an extended period plus open the faucets. PVC pipe is strong, but over time it won’t be able to handle the expansion of ice and you’ll find yourself under the house making replacements.\nSave the Ashes\nDon’t clean the ashes from your fire place until you’re finished using it for the season. The ashes create an insulation for coals in the fireplace so that when the fire burns down, the embers will continue to put out heat. You can also easily stoke a fire as long as it has a good base of hot coals.\nHeat the Chickens\nChickens are perhaps the easiest farm animal to maintain. They only need a coup to keep them safe from predators, and some feed and water. If you want to be a kindly sort of owner, put some straw in the hen boxes during the winter so they’ll have somewhere warm to lay eggs. It’ll cause your electricity bill to increase a bit, but heat lamps will warm the coup plus cause hens to lay more often than they usually would in winter due to the fewer hours of daylight.\nCut Firewood on Cold Days\nCutting firewood on cold days allows you to stay warm no matter the temperature. Sure, it can be tough to simply go outside when the mercury hovers below freezing. But run a chainsaw for a half hour or so and you’ll begin shedding layers. He who cuts his own firewood warms himself twice. Where have I heard that?\nWinter is the time for trimming trees when they are dormant. Even though many disease-carrying parasites have been beat back by the cold, spray the nub of each limb you trim on fruit-bearing trees with spray paint. This, in essence, “seals the wound.”\nBuy a Crockpot\nThis depends on preference, but a Crockpot (slowcooker) is the epicenter to many a kitchens. If you’re outside for long periods, or come in tired not wanting to cook, the Crockpot is a game changer. You can throw in all the ingredients in the morning, come back later and voila!, a hot meal. Plus, they don’t pull a lot of electricity.\nSpread Dead Wild Flowers\nThis is a practical tip for those who love their spring flowers. On our little farm, once the flora has gone dormant, we’ll uproot the beds of wildflowers and pile them along the edge of a hay field behind the house. After we cut the clover for hay in spring, we’ll run over the field including the piles of dead flowers with a disc in preparation to plant millet. It’s pretty neat to see a nice row of flowers spring up on the edge of the field, some of which we’ll transplant back to the garden. Remember that if a seed is able to make contact with the earth, gets enough water and sunlight and some fertilizer, it’ll survive and even thrive.']	['<urn:uuid:25adfe0e-8f13-4e51-9575-bfa7b25f7fbf>']	factoid	direct	long-search-query	distant-from-document	single-doc	expert	2025-05-01T22:36:12.692263	11	36	591
236	rainbow cave and house rock which natural force shaped them both	Both Rainbow Cave and House Rock were shaped by natural erosion processes, but in different ways. Rainbow Cave was formed when waves, wind, ice and water eroded the softer Chapel Member of the Munising Formation of Sandstone. House Rock, which stands about 10 meters tall on the crater rim, shows evidence of erosion and weathering, as demonstrated by its surface exposure age dates being younger than the crater's 49,000-year formation age.	"['PIRO: The “Painted” Pictured Rocks\nFigure 1. Pictured Rocks Cliffs Photograph by: Beth Dondit\nWhy are the Pictured Rocks the “Pictured Rocks?” What caused the colors to form on the cliffs? How did it happen?\nThe Pictured Rocks cliffs span approximately 15 miles from the Beaver Basin west to Munising, MI. The cliffs are constantly being weathered and eroded by the powerful forces of the water, waves, wind and ice. A sea cave can form when a softer rock is affected by erosion. The Chapel Member of the Munising Formation of Sandstone is this softer layer. Waves, wind, etc. have slowly eroded “Rainbow Cave” over a long period of time. Inside this sea cave, you will see many colors along the rock walls/ceiling. The staining or nature’s painting, has left quite a canvas inside this cave. When groundwater seeps through porous rocks, the minerals in the groundwater also seep through, and leave behind colors to mark their presence. Green and blue colors come from copper; black from manganese, or tannins originating in the streams; orange and red come from iron; and white from limonite. Water follows the path of least resistance, and travels downwards (gravity). The water table here is higher than Lake Superior, thus water is moving to the lowest point possible. This is very evident inside the “Rainbow Cave.”\nFigure 2. Natural Paintings on the Pictured Rocks Cliffs Photograph by: Beth Dondit\nLogging Your Visit:\nL1: At this location, what is the most prominent color in the cave? What mineral caused that coloration?\nL2: What is the most unique color here? What mineral “painted” this color?\nL3: What force caused this landform to form?\nL4: What is causing the “rain” inside the cave? Where is it coming from?\nFigure 3. “Rainbow Cave” in the distance Photograph by: Beth Dondit\nEarth Science Literacy Principles Big Ideas:\nEarth Science Literacy Big Idea 4- Earth is continually changing.\nEarth materials take many different forms as they cycle through the geosphere.\nAs water and minerals travel through both the hydrological cycle/geosphere, they continually shape our Earth’s landscape. Evidence of this is easily viewed along the Pictured Rocks coast. Even more impressive from a kayak, viewing the features firsthand (beware of changing weather conditions, clapotis, and cracks/fractures, which could amount to falling rocks).\nThe mineral deposits/stains that paint the Pictured Rocks are very colorful and impressive. The minerals seep through the porous sandstone layers, with the groundwater, and leave their mark.\nCommon Earth Science Misconceptions:\nMinerals are only found in rocks, as solids, and they don’t change forms.\nRocks are solid, hard surfaces that don’t change shape/form.\nRocks are hard, nonporous substances.\nMichigan State Content Expectations:\nGrade 3- E.SE.E.2- Surface Changes- The surface of the Earth changes. Some changes are due to slow\nprocesses, such as erosion and weathering; and some are due to rapid processes, such as landslides, volcanic eruptions, and earthquakes.\nGrade 6- E.SE.06.12- Earth’s Changing Surface- Explain how waves, wind, water, and glacier movement,\nshape and reshape the land surface of the Earth by eroding rock in some areas and depositing sediments in other areas.\nClapotis- “confused seas.” This occurs when waves hit large cliffs, and bounce off, connecting with other waves, creating large, multi-directional wave patterns.\nBlewett, William L. Geology and Landscape of Michigan’s Pictured Rocks National Lakeshore and Vicinity. Detroit, MI: Wayne State University Press,\nNational Park Service. “Pictured Rocks: Frequenly Asked Questions.” 11 June 2012. <http://www.nps.gov/piro/faqs.htm.>', 'Six days in the crater (day one)\nPosted by Pat Donohue\n03-02-2012 10:02 CST\nThe following is the first in a series of posts based on field notes and memories supplemented by background reading material from the Meteor Crater Field Camp that was held from October 17-23, 2010. The field camp was run under the NASA Lunar Science Institute and headed by Dr. David Kring of the Lunar and Planetary Institute.\nTwenty-two of us are spread out between three Chevy Suburbans, and it\'s strange having legroom on a geology expedition. Not that there\'s far to go. We are camped out in an RV park a mere 5.5 miles from our field site: Barringer Meteorite Crater. This is the first day of the first ever Meteor Crater Field Camp, and we are making the first trip first thing in the morning to my first visit to any crater, ever. Everyone\'s ready to get started, and we don\'t have long to wait. Our first stop is approximately fifteen feet outside the gates of our campsite, and we step out of the vehicles after realizing the stop wasn\'t because of a forgotten water bottle or notebook.\nAt 5.5 miles out there\'s not much of the crater to see and so we huddle around Dr. Kring, our fearless leader. He asks us to imagine standing at this exact spot 49,000 years ago* as Meteor Crater formed. ""What would you see?"" he asks us. Slowly we find our voices: A streak of light and a flash. A fireball. Wind whipping across the plains. A massive volume of ejected material rushing toward you. Then nothing because you are dead.\nWe learn we wouldn\'t even last that long. At this distance the shock wave would reach you in less than a second, turning you inside out before the wind and heat simultaneously flash-cooked your body as it tumbled away in pieces with the desert sage. Oh well. Someone luckier and further away would have seen quite the show.\n49,000 years later, as we pile back into the vans, it\'s mostly sunny and warming past 50°F on the high desert plains of Arizona.\n[*On the basis of thermoluminescence, 26Al, 10Be, and 36Cl studies, it\'s generally agreed that Meteor Crater formed 48 to 49 thousand years ago. More recently, updated 36Cl reference material argues for an older age of 60 to 65 thousand years.]\nOn the docket for our first day at the crater is a 3.7 kilometer (2.3 mile) hike along the rim, about 1.8 km clockwise before lunch, then retracing our steps counterclockwise. There\'s House Rock (also known as Monument Rock), the largest (intact) boulder on the crater rim at about 10 meters tall. Pile on two more House Rocks and you\'d have a reasonable estimate of the meteorite diameter. And maybe at one time there really was another House Rock or two on top. Surface exposure age dates from the top of House Rock are younger than the 49,000-year formation age.\nIt wouldn\'t be surprising if House Rock had initially been covered by ejecta. Erosion and weathering is evident everywhere at the crater. A gully running downslope beneath the crater museum rapidly cut through three layers of authigenic breccia, both exposing and halfway eroding a projectile fragment over a two year period. The breccias are so friable that when we later head into the crater, we aren\'t allowed to touch or even go near the left side of the gully where the projectile is exposed.\nOn our counterclockwise hike back we generate a little erosion of our own by scrambling down the crater wall a bit from House Rock to see something (else) awesome. We start out on Kaibab limestone on the crater rim and walk down through Moenkopi formation, and end up back at Kaibab. The top slice of bread in the Kaibab-Moenkopi-Kaibab sandwich is ejected, overturned Kaibab. The bottom slice is in-situ Kaibab. And the meaty Moenkopi center is where it gets interesting. Look at the photo below. Both members of the Moenkopi are visible here. The pale reddish brown Wupatki (at left) is a massive sandstone underlying the dark, reddish brown fissile siltstone called the Moqui. The surrounding pale/tan blocks are dominantly Kaibab (limestone/dolostone), though most shown here are loose boulders.\nOriginally horizontal beds were uplifted during impact and now dip away from the crater. In the center of the above image, the Moqui member -- the surface unit at the time -- takes a sharp turn and winds up parallel to the crater wall. This is an exposed portion of a fold hinge, where a flap of target material was overturned to create an inverted stratigraphic sequence.\nThere\'s so much more to see at the crater. Sand fields, tear faults, shocked quartz...and we\'re still just getting started!']"	['<urn:uuid:19a45410-c030-465f-97e0-8555075f9967>', '<urn:uuid:9c5b2d08-de9c-4b8c-b9ea-9cb1e6a138a4>']	open-ended	direct	long-search-query	distant-from-document	comparison	novice	2025-05-01T22:36:12.692263	11	71	1364
237	behavioral health researcher looking for gender differences depression workplace burnout stages treatment methods	Women experience depression at twice the rate of men, with one in eight women experiencing clinical depression in their lifetime. Depression is treated through antidepressant medication and psychotherapy, particularly Cognitive Behavioral Therapy (CBT). Workplace burnout progresses through 7 stages: compulsion to prove oneself, working harder, neglecting daily needs, displacement of conflicts, revision of values, denial of problems, and withdrawal. Both conditions can be managed - depression through professional treatment, and burnout through stress reduction techniques like exercise, adequate sleep, and proper work distribution.	"[""The National Institute of Mental Health estimates that nearly 19 million adults in the US experience at least one major depressive episode every year. Depression is one of the most common mental health disorders in America. Sometimes referred to as major depressive disorder or clinical depression, it is different from less severe feelings of sadness. The good news is that depression is highly treatable. In this blog, we'll go over how to treat depression.\nWhat are the symptoms of depression?\nThe symptoms of depression can vary from person to person. Below is a list of depression symptoms from the American Psychological Association. You might experience these symptoms if you are struggling with depression.\n- Prolonged sadness or feelings of emptiness\n- Feeling helpless or hopeless\n- Feeling guilt or worthlessness\n- Anger and irritability\n- Difficulty concentrating\n- Changes in sleep patterns\n- Changes in appetite\n- Chronic pain, headaches, or stomach aches\n- Loss of interest in activities\n- Withdrawal from friends and family\n- Thoughts of death or suicide\nWhat causes depression?\nJust like substance abuse, there is no one cause for depression. The causes of depression will be different for each person and can be the result of a combination of factors.\nBiological risks for depression include having a family history of depression, being diagnosed with a co-occurring mental health disorder, having a terminal illness, and being a woman. In fact, women experience depression at twice the rate of men, with one in eight women experiencing clinical depression in their lifetime.\nEnvironmental risks for depression include things like prolonged stress from work, major life changes, and trauma. Sometimes, environmental risks are called sociological or psychosocial risks since they are not biological (genetic) and are a result of things that happen as a part of day-to-day life.\nThere are also developmental risks for depression. For example, experiencing trauma or abuse during childhood can increase your risk of developing clinical depression later in life.\nHow do you treat depression?\nDepression is highly treatable. While each person’s specific treatment may vary, generally speaking, depression can be treated with antidepressant medication and psychotherapy. Cognitive Behavioral Therapy (CBT) is a type of therapy used to treat depression, anxiety, and PTSD.\nCognitive Behavioral Therapy works by helping you to change the way you think and helping you to change your behaviors. The best results are typically seen after 12-16 weeks of treatment. Cognitive Behavioral Therapy is offered at our counseling centers. If you are looking for a counseling center that offers treatment for depression, check out our counseling center locations.\nCan I treat depression on my own?\nYou might wonder if it’s possible to treat depression on your own, or with only medication, or only therapy. Remember, people experience depression differently. What causes your depression might not be what causes depression in someone else. This means that there is no one way to treat depression.\nResearch has concluded that depression is best treated with the help of a qualified mental health professional and that a combination of medication and therapy is most effective for moderate to severe depression. It’s best to seek the advice of a mental health professional, like a therapist who understands depression and is qualified to work with you on developing a treatment program that is unique to your needs.\nLearn more about depression:\nLooking to learn more? Here are a few articles about depression that might interest you.\n- The warning signs of depression and suicide in young adults\n- 3 things you should know about postpartum depression\n- Warning signs you could be experiencing depression\n- Is my child depressed?\n- Therapy options for children experiencing depression\nYou don’t have to live with depression or try to treat it on your own. Let us help you find a depression treatment that meets your needs."", 'Have you ever experienced burnout at work? The Chances are that you probably have without even knowing it.\nOccupational burnout has become such a regular occurrence in the lives of knowledge-work professionals, particularly considering today’s ever-increasing demands. Many of us aren’t even aware of how close we might be to burning out, or – worse still – we might have been in this state for a while!\nBurnouts can do serious damage to both employees and their companies in general. Stick to the end to learn more about what occupational burnout really is, what causes it, and how to avoid it yourself.\nWhat is Occupational Burnout?\nBurnout, in the context of one’s occupation, is a type of psychological stress characterized by exhaustion, lack of enthusiasm and motivation. In most cases, burnouts are accompanied by frustration and cynicism, which, in turn, lead to reduced productivity at the workplace.\nOne of the most visible signs of organizational stress is an increase in employee turnover. If employees are fearful for their positions, or feel the expectations are unrealistic, they may leave the organization rather than continue struggling.\nTurnover is a very costly process for any organization. Significant monetary costs are accrued in the process of recruiting, hiring, training, as well as general decrease in productivity.\nThe American Management Association believes the cost of finding an employee’s replacement is around 30% of that employee’s salary.\nTurnover also causes additional work and stress on other employees who have to fill in during the recruitment period, thus leading to further instances of burnout in the team.\nFor example, the burnt-out person might be that colleague who is late, for work, each morning, because he hasn’t slept well and dreads getting out of bed to head to the office; or the co-worker who stares at the computer screen for hours on end, although she never seems to focus on the task in front of them.\nThe real problem is when you have a whole team, or even an entire department of burnout people. How can you grow and reach high goals with unmotivated, and uninterested, people by your side?\nThe simple answer is: you can’t!\nThe issue will continue to develop and, as people from other departments feel the instability of their colleagues, inevitably the whole company will be negatively affected.\nWhat Causes Burnout?\nAlthough the common understanding is that burnouts are generally caused by work overload for extensive amounts of time, according to a report published by PLOS ONE there are three types of occupational burnout. Logically, each one is caused by different circumstances.\nFrenetic burnout is the stereotypical version described above, defined by workers who just have too much on their plate. These employees generally adopt a negative tone, venting about their workload.\nThis type of employee burnout, however, affects individuals who plainly feel like they aren’t getting much satisfaction out of their work. Team members experiencing this sort of burnout tend to “cognitively avoid” their work, distancing themselves from what they consider to be an unrewarding experience.\nWorn-out employees are those who struggle with the stress of the daily grind and ultimately choose to neglect their work because of those pressures.\nThe study found that 15 percent of employees in the report experienced frenetic burnout, 9 percent experienced under-challenged burnout, and 21 percent were worn-out.\nStages of Employee Burnout\nThe American psychologist Herbert Freudenberger, and his colleague Gail North theorized about occupational burnout and divided the development of the syndrome into 7 stages. Some are signs of burnout at work, while others come from personal pressures.\nCompulsion to prove oneself. In most cases, this is a result of trying to work on too many assignments simultaneously.\nWorking harder. In their desire to prove themselves to others, or try to fit in as part of an organization that does not suit them, many people establish high personal expectations and, in order to meet them, they tend to focus solely on work and take on more than they usually would.\nNeglecting daily needs. Since the individuals are already devoting all of their time to work, there is no room for anything else in life. Friends and family, eating and sleeping are no longer seen as vital aspects of life, and are just burdens which take away from the time that can be put into work.\nDisplacement of conflicts. People who reach this stage become aware that something is not right but have trouble finding the source of the problem and often start placing blame elsewhere, for example, on the team or organization.\nRevision of values. Sliding down the slope towards burnout, people’s values change. Work consumes all energy, leaving none for friends and the things they previously enjoyed. As work becomes their only focus, they become intolerant to other people’s mistakes and are never satisfied with the work of their colleagues: this often leads to internal conflicts.\nDenial of emerging problems. At some point, people affected by burnout become intolerant, aggressive, and sarcastic. They begin to ignore problems related to the project they are working on because they don’t want to deal with them and they blame it on the pressure that comes with their excessive workload.\nWithdrawal. With little or no social contact all individuals will inevitably become isolated. At that point, depression hits like a ton of bricks. The affected person disengages from team activities and communicates less with their colleagues, this inevitably leads to problems in the team dynamic.\nHow to Overcome Burnouts?\nThere is no “universal panacea” that will guarantee a remedy for ‘burnout’: however, there are a few tried-and-tested methods that might assist in its avoidance. As the condition is stress related, in order to stop it, you must find a way to reduce the sources of stress and reevaluate the way you distribute responsibilities.\nDon’t rush into starting more work than you can finish without pushing past your acceptable threshold, also avoid multitasking. This advice is followed even by the most successful entrepreneurs such as Amazon’s founder Jeff Bezos and other business leaders. Mr. Bezos is also a fan of the two pizza rule when it comes to scheduling meetings, which means that Bezos won’t call or attend a meeting if two pizzas won’t feed the entire group.\nIf you cannot pinpoint the exact cause of burnout, take the time to analyze what’s going on in your life and focus on something other than work.\nA good way to escape stress is by practicing sports. A study published by the British Medical Journal shows that regular exercise helps to reduce anxiety, boost a person’s mood, enhance productivity and improve the quality of life.\nGetting enough sleep, eating well, and drinking plenty of water further reduces the stress levels of everyday life.\nTaking time off work to recharge your batteries is also a good idea. A week with family or friends, somewhere far from the office, can do miracles for your mental health. In addition, don’t be afraid to speak out when you are overloaded and seek assistance from your team.\nHow to Optimize Your Process to Avoid Employee Burnout?\nDealing with occupational burnout on a personal level is one thing, protecting your team from recurring burnouts requires even more effort. If you are in the position of a manager, and are responsible for delivering results on a daily basis, keeping your team engaged, and efficient, is vital.\nTo achieve this, and ensure that you’re not working with a bunch of potential burnouts, you should consider changing some of your management practices and experiment with methods focused on workflow visualization such as Kanban.\nKanban is a method for lean management. In short, It allows you to clearly visualize the assignments of your team, on a whiteboard, and apply limits to the amount of work in progress (WIP) available.\nSo, how to avoid burnouts at work with Kanban?\nBuild a Kanban board. Kanban boards consist of vertical columns and horizontal swimlanes. Each column represents a step in your process, while swimlanes are often used to visualize different types of assignments or different priorities.\nPrepare a board that mirrors the most important stages of your process and visualize all assignments on individual Kanban cards. It is important to mention that every card should have a single assignee responsible for processing it.\nPlace WIP limits. Make sure your team works on as few tasks at a time as possible to avoid frequent context switching so they finish what they start before pulling new work in progress.\nWIP limits can regulate the amount of work a certain team member is working on at any given time. Using WIP limits, the manager will be able to monitor the activity of his/her team closely and intervene when they see a problem.\nSet up daily team stand-up meetings. Stand-up meetings have become an integral part of Kanban culture and make it very easy to spot when something is wrong. You just need to gather your team at the beginning of each work day in front of their Kanban board and go through the items that are present.\nCommunicate progress and discuss existing as well as potential blockers to keep everybody in the loop and make sure that work is evenly distributed.\nKanban is a pull system, meaning that team members start new tasks only when they have the available capacity to process them.\nApplying this method of working means focusing on one thing in order to do it in the best possible way, instead of doing five things simultaneously and, consequently, achieving something mediocre. Simply said, quality comes before quantity.\nSome may think that this way of working might end up being slower, but, in reality, it is exactly the opposite.\nOne of the best things about using a Kanban is that every aspect of the project is visualized right in front of you, so the work can be delegated accordingly among the team members.\nWith Kanban, you can see if the colleague that is always complaining about how much work he has, is really that overloaded, or is just lazy and is trying to hide from additional assignments.\nThe same goes for the quiet person, who never complains and just takes everything that is sent her way, though she really has a full plate. By using Kanban it is very clear who is doing what and, if the distribution is not balanced, it will become immediately obvious.\nOccupational burnout is a very serious issue that must not be taken lightly by managers as well as their teams.\nOptimizing your work life is crucial for avoiding occupational burnout. Analyze your situation and consider how to prevent burning out using the techniques we have covered in this article.\nIf you are in a managerial position, and want to see if Kanban might help in protecting your team, we encourage you to test Kanbanize so you can ascertain how best to optimize your processes.']"	['<urn:uuid:be12076b-6f2d-4c4f-904a-37cc61638cd9>', '<urn:uuid:ba0fe8c1-95db-4973-9366-feff54bc3485>']	factoid	with-premise	long-search-query	distant-from-document	multi-aspect	expert	2025-05-01T22:36:12.692263	13	83	2450
240	Which approach ensures higher workspace utilization: assigned seating or hot-desking?	Hot-desking ensures higher workspace utilization compared to assigned seating. Analytics show that in traditional assigned seating environments, less than half of employees with personally assigned cubicles are actually found at their desks, and as few as 10 percent of cubicle residents spend 90 percent or more of their work week at their assigned space. In contrast, hot desking allows companies to provide a smaller number of desks for employees to use on a rotating basis, leading to better space utilization and cost savings. This efficiency is achieved by allowing multiple employees to use the same desk space at different times, rather than having underutilized assigned workstations.	['In the first article for this series, the focus was on the concept of behavioral design—or more specifically, design as it relates to workplace behavior. In particular, the message emphasized how important behavioral design is to workplace architecture. Recent studies confirm the direct impact behavioral design has on people’s lives, wellbeing, and on the quality of their interactions. As individuals continue to transition from a fully assigned work environment to a more behaviorally focused and agile space, design value is achieved once sentiments, fears, and expectations are acknowledged and addressed. For example, measuring how space is allocated against how space is used can fill change gaps in order to build design results consistent with observation. Equipped with the knowledge that where employees are stationed affects the way they think, the focus now moves to the “how-to” of behavioral design—methods for making it work.\nWhat drives transformation?\nDesign for behaviors comes from knowing the conditions that drive the need for a shift in workplace design. These conditions come from three sources. First, and perhaps most surprising, are the analytics showing that less than half of those at work who reside in personally assigned cubicles can actually be found at their desks. Stated differently, observations indicate that possibly as few as 10 percent of assigned cubicle residents spend 90 percent or more of their work week at their desks. No longer are employees bound to their workstations. Because of the recent advances in mobile technology, cubicles and offices are generating less and less value for businesses.\nThe second condition prompting design for behaviors deals with the reality of very low employee engagement in the workplace. Gallup, an international polling organization, has tracked this for the United States since 2000. The company’s surveys reveal employee engagement has barely budged in well over a decade. According to Gallup Daily Tracking, only 32 percent of U.S employees are engaged in their jobs and workplaces. Many report that this comes as a result of the hectic and often unpredictable nature of the workplace environment. Ultimately, low engagement can create negative actions toward productivity and negative attitudes toward organizational culture.\nThe third rationale that explains why work behavior design is reinventing itself is due to the increasing complexity of the workplace. For at least the last 50 years, employees were generally assigned work that was much more rote-and-response driven than is called for today. An employee had a skill set that worked to solve specific sets of tasks. Many employees worked solo. As a result, companies developed systems that lent naturally to a cubicle-intensive environment that fulfilled plug-and-play work behaviors. Now, work is largely people-problem driven, which tends to require more time and interaction when it comes to solving problems and building systems. Collaboration is at the heart of creative talent, and designers are catering to behavioral design accordingly.\nThere are many merits to designing with behavioral change in mind. However, to design this way, before attempting to use knowledge of behaviors to transform work environments, first it helps to understand employees’ fears, uncertainties, and doubts. Some of the most common sentiments embodying this apprehension include:\n1. “I need a place to call my own.”\n2. “I need a place to put my things.”\n3. “I need to be able to find the people I need.”\n4. “I need a door for privacy and confidentiality.”\n5. “I need to belong to the office.”\nOne common theme among these five statements is where the emphasis is placed: on the personal needs of the individual. This is very natural; employees believe they must look out for themselves. Another shared sentiment is that each message indicates a loss of control. Although employees define “control” differently—depending upon their status at an organization—being in control over at least the basics (like where to put one’s things) must count for something. Finally, all five reactions come from to memories of former fixed and assigned workplaces that are still perceived as having value. Why? Given the chance, most people tend to fall back on what is familiar from the past.\nThis list of sentiments is telling. Behavioral design benefits from carefully and considerately restating individuals’ expectations in a changing workplace. Anticipate that disruption will occur as a result of the transition—especially when the difference is as dramatic as changing from a fixed or traditional office or workplace to one more behaviorally flexible. Changes in behavioral design require using one’s imagination to envision new ways of working in dynamic work settings. It is through imagining new work expectations and processes that employees can reset their perceptions and judgments toward behavioral design. For that reason, it is important to invest the time and learn the value of aligning memory of past workspaces to new visions of how work will be produced moving forward. In the end, more advanced work behaviors may evolve that have the potential to increase utilization, stimulate engagement, and reset disappointed expectations about adapting to a new workplace.\nSupporting behavior by design\nRecognizing the connection between space and human behavior, companies like Google, Intel, and Cisco are spending millions on redesigning buildings, knocking down walls, and rearranging conference rooms. For example, since the perceived value for increased collaboration has been driving design trends, awareness of perceptions and judgments from the employees involved in the process seem to accelerate change acceptance. Being engaged in the behavioral design process helps employees move beyond deterrents and closer to acceptance.\nOne tactic in supporting behavioral change through design involves how the news of the imminent design change is delivered—explaining each step as it occurs—in real time. Making sure the key stakeholders stay abreast of the what, when, and whys of a changing workplace empowers teams. Another approach for supporting a staff in transition is reassurance. Making certain that everyone sees the positive vision behind designs for new behaviors goes a long way toward easing the pain of a transition. Another way to relieve transitional stress comes from helping employees envision what success in this new environment might look like.\nLast but not least, one straightforward way of igniting employees’ imaginations is with storytelling. The reasons why workplaces are underutilized, why engagement continues to be low, and why the complexity of work continues to increase are best discovered and understood through the story of people who are working. Behavioral design can benefit from the power of, “Once upon a time” and “Happily ever after”.\nModern workplace makeover\nModern workplace makeovers are a fact of life. It’s taken plenty of time, but the workplace is now becoming far less individualized. The traditional systems and beliefs that standard cubicles and offices propagated for so long are being shed and replaced with behavioral design standards that favor collaboration. As the sophistication and value of this trend increase to better align with employees’ work behaviors, transitional tactics will continue to be developed to support and ease the changeovers. Keep in mind: the best behavioral designs will not only encourage teamwork and boost engagement, but they will do so with transparency—while simultaneously catering to a human’s capacity for imagination.\nArticle originally published in Work Design magazine', 'The COVID-19 pandemic has changed the way we work, and many companies are now embracing flexible working arrangements. One of the most popular flexible working arrangements is hot desking. Hot desking is a work arrangement where employees do not have a fixed desk or workspace. Instead, they work from any available desk in the office. Hot desking is gaining popularity due to its potential to reduce office space and costs while increasing employee productivity and collaboration. However, it is not without its challenges. In this comprehensive guide, we will cover everything you need to know about hot desking, including its benefits and drawbacks, best practices, and FAQs.\nBenefits of Hot Desking:\nHot desking has several benefits for both employers and employees. Here are some of the key benefits of hot desking:\n- Reduces Office Space and Costs: Hot desking can help businesses reduce the amount of office space required, which can lead to cost savings. Instead of assigning a desk to each employee, companies can provide a smaller number of desks for employees to use on a rotating basis.\n- Increases Collaboration and Communication: Hot desking can foster collaboration and communication among employees. Employees from different departments and teams can work together, share ideas and knowledge, and build relationships.\n- Enhances Flexibility: Hot desking provides employees with the flexibility to work from different locations within the office. They can choose a desk that suits their needs and preferences, which can enhance their comfort and productivity.\n- Encourages Cleanliness: Hot desking can encourage employees to keep their workspace clean and tidy. Since they do not have a permanent desk, they are more likely to clear their workspace at the end of the day.\nDrawbacks of Hot Desking:\nWhile hot desking has several benefits, it also has some drawbacks. Here are some of the key drawbacks of hot desking:\n- Decreased Sense of Ownership: Employees may feel less ownership over their workspace since they do not have a fixed desk. This can lead to decreased motivation and productivity.\n- Lack of Privacy: Hot desking can lead to a lack of privacy since employees may be working in close proximity to others. This can be challenging for employees who need to focus on individual tasks.\n- Difficulty in Finding a Desk: Employees may find it challenging to find a free desk, especially during peak hours. This can lead to frustration and reduced productivity.\nBest Practices for Hot Desking:\nTo make hot desking work effectively, it is important to establish some best practices. Here are some best practices for hot desking:\n- Establish Clear Guidelines: It is essential to establish clear guidelines for hot desking, including how to reserve a desk, how long employees can use a desk, and how to keep the workspace clean and tidy.\n- Provide Adequate Resources: Companies should provide adequate resources, such as power outlets and ergonomic chairs, to ensure employees can work comfortably.\n- Offer Training: Employees should be trained on how to use hot desking effectively. This can include how to find a desk, how to set up their workspace, and how to keep the area clean.\n- Encourage Communication: Companies should encourage communication among employees to foster collaboration and enhance productivity.\nQ. What is hot desking?\nA. Hot desking is a flexible working arrangement where employees do not have a fixed desk or workspace. Instead, they work from any available desk in the office.\nQ. What are the benefits of hot desking?\nA. The benefits of hot desking include reduced office space and costs, increased collaboration and communication among employees, enhanced flexibility, and an encouragement of cleanliness in the workspace.\nQ. What are the drawbacks of hot desking?\nA. The drawbacks of hot desking include a decreased sense of ownership over workspace, a lack of privacy, and difficulty in finding a free desk, especially during peak hours.\nQ. How can companies make hot desking work effectively?\nA. To make hot desking work effectively, companies should establish clear guidelines, provide adequate resources, offer training, and encourage communication among employees.\nQ. Is hot desking suitable for all types of companies?\nA. Hot desking may not be suitable for all types of companies. Companies with a highly collaborative and mobile workforce may benefit the most from hot desking.\nHot desking is a flexible working arrangement that is gaining popularity due to its potential to reduce office space and costs while increasing employee productivity and collaboration. However, it is not without its challenges. To make hot desking work effectively, companies should establish clear guidelines, provide adequate resources, offer training, and encourage communication among employees. While hot desking may not be suitable for all types of companies, it can be a valuable option for companies with a highly collaborative and mobile workforce. By following best practices and addressing the challenges of hot desking, companies can successfully implement this flexible working arrangement and reap its benefits. So, now you know everything you need to know about hot desking!']	['<urn:uuid:245d0ecd-1856-4abf-9cec-77e425366888>', '<urn:uuid:50503ede-9ade-4fb6-a964-18a1733fcc07>']	open-ended	with-premise	concise-and-natural	distant-from-document	comparison	expert	2025-05-01T22:36:12.692263	10	106	2009
241	prescription safety glasses lens options bifocal	For prescription safety glasses, there are several lens options available. Single vision lenses have the same focal power throughout and can correct nearsightedness, farsightedness, and astigmatism. Bifocal lenses have two distinct parts - lower portion for reading and upper portion for distance. Companies like Dewalt offer bifocal safety glasses, such as the DPG59-115C Reinforcer Rx model. Safety prescription lenses must meet specific thickness and impact testing requirements while still providing necessary vision correction.	['Types of Prescription Lenses\nWhat types of lenses are used to correct my vision?\nIn a nutshell, there are four types of lenses used with prescription glasses to correct vision: Single vision, bifocal, trifocal, and progressive.\nSingle vision – As the name indicates, a single vision lens has the same focal power (or magnification) from top to bottom and can be used for nearsightedness, farsightedness, as well as for correcting astigmatism. Single vision lenses are the most common lenses used and, for most first time glass wearers, the first lenses prescribed. While you can purchase inexpensive ready-made single vision readers in most drug stores, they will not correct for astigmatism or in the case where your eyes have different corrective needs, i.e. one eye is a +1.50 and the other is a +2.00. Using readers, in that case, can cause an additional eye strain problems.\nBifocal – A bifocal lens has two parts: the separate, very distinct lower portion designed for reading or close-up work and the upper portion containing a prescription for distance or even with no correction at all. Using bifocals allows a person to leave their glasses on at all times while retaining the ability to see at various distances.\nTrifocal – Much like the bifocal, the trifocal contains three separate and distinct levels of prescription, correcting for close-up work, a middle portion for intermediate distance, and the top portion for far distance. Trifocals are fairly rare these days with the advent of…\nProgressive lenses – Progressive lenses (like bifocals and trifocals) are used for people with multiple corrective needs such as close-up, distance, and middle distance. Unlike bifocals and trifocals, progressive lenses are true multi-focal lenses that allow a seamless progression through all of the lens powers that you need to see, with no lines or sudden jumps from one magnification to another. Thus, your eyes are allowed to focus in a more natural and comfortable manner. Progressive lenses are particularly useful for people who need both a strong power for reading as well as lesser visual assistance for a computer monitor that is slightly beyond comfortable reading distance.\nWhat kind of lens materials do I have to choose from?\nThe majority of prescription lenses are made with either CR-39, polycarbonate, Trivex, or, on rare occasions, glass. With higher (or stronger) prescription glasses you may want to consider Hi-Index lenses which, while more expensive, are lenses that are thinner, lighter and aesthetically more attractive by eliminating thick edges.\nGlass – Known for it’s optical clarity, glass is used rarely and, thus, is a very expensive alternative for use in prescription glasses. On the plus side, glass is more scratch-resistant than the various plastics and polymers available on the market. On the negative, besides the high cost, glass lenses can be heavy and are not available across the full range of optical needs.\nCR-39 – CR-39 is a plastic polymer that has been in use for optical lenses since 1947. CR-39 is lightweight and used more frequently in prescription sunglasses because it absorbs tint more easily than polycarbonate. While CR-39 is the most popular lens material used, it chips more easily and is thicker than polycarbonate, making it unsuitable for rimless or half-rim frames. Using CR-39 lenses for a heavy prescription may lead to the thick “Coke bottle” look in many frames.\nPolycarbonate – Polycarbonate lenses are thinner and lighter than traditional plastic eyeglass lenses. They also offer 100 percent ultraviolet (UV) protection (without any additional coatings) and are up to 10 times more impact-resistant than regular plastic lenses. Not only is polycarbonate lighter than CR-39 and glass, unlike them, it will not shatter upon violent impact, making it the safest choice for sports or children’s glasses.\nTrivex – Similar to polycarbonate, Trivex is a urethane-based lens which is cast-molded like a plastic-based lens for outstanding optical clarity, while retaining the thin and lightweight qualities (although marginally heavier) than polycarbonate. Trivex is an excellent choice for rimless (or drill-mounted) glasses since it resists the small “spider-cracks” at the drilling points. Trivex also provides 100 percent UV protection.\nCoatings and Tints\nLens coatings can provide additional optical benefits as well as improving the appearance of your glasses. Among the coatings available are: Anti-Reflective, scratch coats, and UV (ultraviolet) coatings. Mirror coatings are also available.\nAnti-Reflective coatings – Anti-Reflective coatings, also know as ‘AR’ or anti-glare coatings, are coatings generally applied to the front and backside surface of lenses for the purpose of diminishing glare or reflections. If you drive at night a good AR coating shrinks down glare or the star/halo effect from oncoming headlights while improving your night vision. Anti-Reflective coatings have also been proven beneficial when using a computer for extended periods of time by reducing glare off of the monitor, which, in turn, eases eyestrain. From a cosmetic standpoint, AR coatings reduce the shine and reflection off of high index lenses, which tend to be brighter due to their thinness.\nScratch coating – Even metal can be scratched, so what chance does glass or plastic have? While not protective against deep scratches or gouging, a scratch-proof coating can make your lenses more resistant to the fine scratches that come with day-to-day wear and even from cleaning them with something as seemingly soft as paper towels or napkins. Generally a scratchproof coat will come with an extended warranty on your lenses.\nUV coating – In much the same way that ultraviolet rays can damage your skin, UV rays are believed to be a contributing cause to cataracts and retinal damage. As noted above, polycarbonate, Trivex, and high index lenses provide natural 100 % UV protection for your eyes. Plastic lenses provide minimal UV protection that can be increased to 100% protection with a clear UV-blocking dye.\nTints – Tinting lenses is an option but is limited to plastic lenses, Trivex, and some hi-index lenses.', 'Pick the right pair of safety glasses for any dangerous job you might encounter. At Offers.com, we’ve put together a list of the best safety glasses on the market based on user reviews, star ratings, and price, as well as properties like anti-fog lenses, face-molding frames, straps or earpieces, and multiple colors to suit your personal style.\nTop Rated: The Best Choice for Safety Glasses\nUvex Stealth OTG Safety Goggles\nPyramex Safety S4110SMP Intruder Safety Glasses\nDewalt DPG59-115C Reinforcer Rx Bifocal 1.5 Clear Lens High Performance Protective Safety Glasses\nBest Value: Get The Most For Your Money\nDewalt DPG82-11 Concealer Clear Anti-Fog Dual Mold Safety Goggle\nGateway Safety 4699 StarLite Gumballs Safety Glasses, Clear Lens\nUvex Skyper Blue Light Blocking Computer Glasses\nUvex S0360X Ultra-spec 2000 Safety Eyewear\nJackson Safety 22475 Nemesis 3020121 Safety Glasses\nDewalt DPG94-1C Dominator Safety Glasses\nGlobal Vision Eyewear Escort Safety Glasses\nFrom laboratories, to construction sites, to military settings, there are many jobs where delicate eyes need an extra level of protection. If there is breakable glass, hazardous chemicals, or heavy tools at a worksite, the chances of injury to the eye can be higher than in other jobs. Safety glasses provide necessary protection; different than regular eyeglasses, safety glasses are usually designed with anti-fog glass, extra edges on the frames, and thicker earpieces to keep them from slipping off your face. This way, safety glasses can protect you from flying glass fragments, splashing chemicals, or losing control of a piece such as a nail or screw.\nPrevent Blindness America reports that more than 700,000 people injure their eyes at work each year; an additional 125,000 hurt their eyes at home, including during sports. This group and other experts say that safety glasses and other protective eyewear could help prevent up to 90% of these eye injuries. To provide proper protection, safety glasses must conform to certain standards set forth by the American National Standards Institute. Those standards involve impact testing: for basic impact, only the lenses of safety glasses are tested. For higher impact situations, the frame will be tested in conjunction with the lenses. Prescription lenses are typically thicker and thus more protective on impact. Today, thinner prescription lenses are allowed, under 3mm, but they must still meet high-impact testing standards. Safety glasses are tested using a steel ball. For the basic impact test, a one-inch ball is dropped onto the lenses from 50 inches up, and the lens must not chip, break, or crack. For high-impact testing, a quarter-inch ball is shot at the lenses at 150 feet per second. Again, it must not chip, break, or crack, nor must it come dislodged from its frame.\nTo meet ANSI standards, a pair of safety glasses must be marked with the manufacturer’s trademark and either “Z87” or “Z87+”; the former indicates basic impact safety, while the latter lets you know the glasses can stand up to high impact. Prescription frames must be marked with “Z87-2” on the temples and front of the frame.\nDewalt is one of the best known and highest rated brands for safety glasses. From anti-fog, to bifocal styles, Dewalt has a selection of safety glasses and goggles to suit every need. 3M, another popular manufacturer of industrial and safety products, also offers a range of protective eyewear with clear frames and clear anti-fog lenses for easy viewing of your work tasks.']	['<urn:uuid:b1c5791e-aa4f-4393-8155-47e3de0d340f>', '<urn:uuid:78ade8d2-1039-47a0-b5eb-7a0e0672832f>']	open-ended	direct	short-search-query	similar-to-document	three-doc	expert	2025-05-01T22:36:12.692263	6	73	1540
244	pros of nuclear energy clean electricity generation and problems nuclear waste disposal	Nuclear energy has significant advantages in electricity generation: it produces large amounts of electrical energy at relatively low cost using small amounts of fuel, does not emit greenhouse gases, and reduces dependence on fossil fuels. However, nuclear waste disposal poses serious challenges - it remains radioactive and dangerous for thousands of years, requiring special disposal methods like deep underground storage in concrete containers or facilities like Yucca Mountain, which was chosen for being a remote desert location surrounded by federal land.	"[""Nuclear energy, what is it, and for what is it?\nNuclear energy is the energy contained in the nucleus of atoms. Atoms are the smallest elements that make up a material. These elements have a core made up of neutrons and protons that are held together by nuclear energy.\nThe change in these nuclei releases a large amount of energy. This energy can be used in many ways; among others, the production of electrical power.\nNuclear energy now provides about 10% of the world's electricity from about 440 power reactors. The United States built the first reactor in the 1950s.\nHow Many Types of Nuclear Reactions Are There?\nThere are two main types of nuclear reactions, fission and fusion.\n1. Nuclear Fission\nNuclear fission is when a heavy unstable atomic nucleus divides or splits into two or lighter nuclei. When it occurs, the reaction releases significant amounts of energy. The most idoneous atoms for this purpose are uranium or plutonium due to their instability.\nThe working principle of both a nuclear weapon and a nuclear reactor is that a nuclear chain reaction must occur. If a neutron creates fission that produces more than one new neutron, the number of fissures can increase dramatically, along with massive energy production.\n2. Nuclear Fusion\nNuclear fusion is the fusion of the nuclei of different atoms to form another heavier nucleus. When atoms of light elements such as hydrogen fuse together, some of the internal binding energy is released.\nNuclear fusion has enormous potential as an energy source. There are large quantities of light nuclei on earth. It means that its fuel is almost endlessly available.\nAlso, nuclear fusion provides the most energy with almost all current nuclear weapons.\nIs Nuclear Energy Renewable Energy?\nNuclear energy is not renewable energy.\nTo work, it needs a type of fuel with a very particular nature: they have to be very heavy and very unstable atoms like uranium.\nThe advantage of this energy is that compared to other non-renewable fuels, it does not emit greenhouse gases.\nIs Nuclear Energy Clean Energy?\nWhether it is clean energy or not is a moot point. Spent fuel from plants is highly radioactive and challenging to manage. In other words, it generates hugely polluting waste that remains active for dozens of years.\nOn the other hand, nuclear waste can be controlled. The trash generated follows protocols that, if executed correctly, do not release radioactive particles into the environment and, therefore, do not pollute.\nHow Does a Nuclear Power Plant Work?\nNuclear power plants are plants where produce electricity from atoms' energy.\nAll nuclear plants have one or more nuclear reactors. The nuclear reactor's function is to split the nucleus of an atom to obtain a large amount of heat. It is what we call a nuclear fission reaction.\nEnriched uranium atoms usually are used because uranium is a very unstable chemical element. Therefore, it is easy to generate fission.\nThere are many types of nuclear reactor designs: boiling water reactors (BWR) and pressurized water reactors (PWR). The thermal energy obtained from the nuclear reaction is used to generate steam. The steam drives a turbine that provides mechanical energy. Thanks to this mechanical energy, the electric generator can be operated to obtain electricity.\nOver 50 countries utilize nuclear energy in about 220 research reactors.\nAll nuclear capacity in nuclear power plants is due to nuclear fission. Power generation using nuclear fusion, at the moment, is only in the experimental phase.\nThe term nuclear energy is often used to refer to the electrical energy generated by nuclear power plants.\nPros and Cons of Nuclear Energy\nThe use of nuclear energy has specific pros and cons.\nThe main benefits of nuclear energy are:\nThe possibility of getting a large amount of electrical energy using a relatively low cost with a small amount of nuclear fuel.\nThe plants can control the generating capacity and plan the electricity supply.\nIt does not emit greenhouse gases and does not ait climate change.\nIt reduces dependence on fossil fuels.\nNuclear technology is used in medicine in diagnostic and treatment techniques.\nNuclear medicine studies are used to diagnose and determine the severity of many diseases as well as to assess the response to treatment. It includes cancer of various types, heart, endocrine, and infectious diseases among others.\nThe main cons of nuclear power are:\nIn the event of a radioactive leak, the damage to living beings is severe.\nThe difficulty of managing the nuclear waste generated in the short and long term.\nDespite the safety systems, the possibility of nuclear accidents is real.\nNuclear technology implies the existence of atomic weapons.\nWhat Have Been the Worst Nuclear Accidents in History?\nThe worst nuclear disasters in history have been:\nThe dropping of two atomic bombs on the cities of Hiroshima and Nagasaki in Japan. The launch was made during the Second World War.\nThe explosion of the Chernobyl nuclear power plant in the USSR. For now, it is the worst civil atomic accident in history. During tests at the Chernobyl nuclear power plant, a series of technical and human errors were linked, causing an intense explosion. The radioactive particles released were spotted thousands of km from the plant.\nThe Fukushima nuclear accident occurred as a result of two chained natural disasters. At first, there was an earthquake, and later a tsunami flooded the Japanese plant. As a result, the reactor's cooling system broke down, and the core melted, releasing large amounts of radioactive material.\nThis website is a general info site on nuclear energy. The contents are focused on explaining in a simple way what atomic energy is and the main aspects that surround it.\nAs some topics are related to physical concepts, we have easily explained these concepts in some sections to understand.\nOur goal is to make this technology known to ordinary users. Our goal is not to get into calculations and sizing or any other engineering work."", '- Why is Yucca Mountain suitable for nuclear waste?\n- Can nuclear waste be cleaned?\n- Why isn’t nuclear waste in space?\n- What does France do with nuclear waste?\n- Is Radioactive a waste?\n- Is burying nuclear waste safe?\n- Can nuclear waste be destroyed?\n- Will we run out of uranium?\n- How much radiation is in a banana?\n- Is nuclear energy the best?\n- Can we send nuclear waste into space?\n- Where does America dump its nuclear waste?\n- Where is nuclear waste disposed?\n- How many nuclear waste sites are in the US?\n- What happens to waste of a nuclear plant system?\n- How long does nuclear waste last?\n- Why is nuclear energy bad?\n- Can you swim in a nuclear reactor pool?\n- What state has the most nuclear waste?\n- What are the 3 types of nuclear waste?\n- Can you throw nuclear waste volcano?\nWhy is Yucca Mountain suitable for nuclear waste?\nThe nuclear industry and experts want a long-term, safer dump than the more than 100 pools currently holding nuclear waste.\nYucca Mountain was chosen because it is in a desert location far from population centers, and because it is surrounded by federal land..\nCan nuclear waste be cleaned?\nSummary: A new crystalline compound can be tailored to safely absorb radioactive ions from nuclear waste streams, experts say.\nWhy isn’t nuclear waste in space?\nWhy can’t radioactive waste be sent in space? In short, its unfeasible, unpractical, dangerous and extremely expensive. Its estimated that the cost of launching material on a space shuttle costs ($22,000/kg). This is because of the immense thrust required, and we have not yet perfected our rocket fuel.\nWhat does France do with nuclear waste?\nUpon its removal from French reactors, used fuel is packed in containers and safely shipped via train and road to a facility in La Hague. There, the energy producing uranium and plutonium are removed and separated from the other waste and made into new fuel that can be used again.\nIs Radioactive a waste?\nRadioactive waste is a type of hazardous waste that contains radioactive material. Radioactive waste is a by-product of various nuclear technology processes.\nIs burying nuclear waste safe?\nNuclear waste is neither particularly hazardous nor hard to manage relative to other toxic industrial waste. Safe methods for the final disposal of high-level radioactive waste are technically proven; the international consensus is that geological disposal is the best option.\nCan nuclear waste be destroyed?\nIt can be done. Long-term nuclear waste can be “burned up” in the thorium reactor to become much more manageable.\nWill we run out of uranium?\nIf the Nuclear Energy Agency (NEA) has accurately estimated the planet’s economically accessible uranium resources, reactors could run more than 200 years at current rates of consumption. … Taking both steps would cut the uranium requirements of an LWR in half.\nHow much radiation is in a banana?\nThe radiation from bananas measures out as 3,520 picocuries per kilo – that’s high enough to set off the more sensitive type of radiation alarms. If you ate one banana per day, you’d receive a dose of 2.6 mrem per year.\nIs nuclear energy the best?\nNuclear Has The Highest Capacity Factor That’s about 1.5 to 2 times more as natural gas and coal units, and 2.5 to 3.5 times more reliable than wind and solar plants.\nCan we send nuclear waste into space?\n$1.2 trillion to launch the high-level waste into the Sun on a trajectory that takes a long long time. The bottom line is that blasting our nuclear waste off into space, into the Sun, is just too expensive – by several orders of magnitude.\nWhere does America dump its nuclear waste?\nWhere is our nuclear waste kept now and what dangers does it pose? Plans to store the majority of our nation’s spent nuclear fuel and other highly radioactive waste at a central repository underneath Yucca Mountain in the Nevada desert 80 miles from Las Vegas were first hatched in the mid-1980s.\nWhere is nuclear waste disposed?\nA permanent disposal site for high-level waste has been planned for Yucca Mountain, Nevada, since 1987. Whether it is at Yucca Mountain or some other location, DOE will transport and dispose of all U.S. commercial used fuel. All major nuclear countries in the world are pursuing similar disposal sites.\nHow many nuclear waste sites are in the US?\n80 sitesFigure 1 shows the locations of 80 sites in the United States where nuclear waste is currently stored. At 57 of these sites, 96 operating nuclear reactors generate approximately 20% of the total annual electricity production for the United States.\nWhat happens to waste of a nuclear plant system?\nSuch waste are disposed very specifically and technically. They are buried very deep in the earth in container made of thick concrete wall that makes the waste particles radiation unable to come out. All ate nuclear waste have a half life, it will be completely finish after long time.\nHow long does nuclear waste last?\n1,000 yearsTransuranic wastes, sometimes called TRU, account for most of the radioactive hazard remaining in high-level waste after 1,000 years. Radioactive isotopes eventually decay, or disintegrate, to harmless materials. Some isotopes decay in hours or even minutes, but others decay very slowly.\nWhy is nuclear energy bad?\nNuclear energy produces radioactive waste A major environmental concern related to nuclear power is the creation of radioactive wastes such as uranium mill tailings, spent (used) reactor fuel, and other radioactive wastes. These materials can remain radioactive and dangerous to human health for thousands of years.\nCan you swim in a nuclear reactor pool?\nThe most highly radioactive fuel rods are those recently removed from a reactor. … They do a pretty good job of keeping the water clean, and it wouldn’t hurt you to swim in it, but it’s radioactive enough that it wouldn’t be legal to sell it as bottled water.\nWhat state has the most nuclear waste?\nOne of the biggest critiques of nuclear energy is that it produces radioactive waste in the form of used nuclear fuel, or UNF….Three out of every four states in the United States contain nuclear waste. Uh-oh.StateMetric tons of UNFIllinois9,010Pennsylvania6,290South Carolina4,210New York3,7206 more rows•Jul 27, 2013\nWhat are the 3 types of nuclear waste?\nThere are three types of nuclear waste, classified according to their radioactivity: low-, intermediate-, and high-level. The vast majority of the waste (90% of total volume) is composed of only lightly-contaminated items, such as tools and work clothing, and contains only 1% of the total radioactivity.\nCan you throw nuclear waste volcano?\nNuclear and other toxic waste can indeed be disposed of in volcanoes, but so can ordinary garbage.']"	['<urn:uuid:6e6fd135-9d49-46a3-abf7-3868d8b1ce2c>', '<urn:uuid:2f28d8f4-2242-4206-bee9-03a761626ec8>']	factoid	direct	long-search-query	similar-to-document	multi-aspect	novice	2025-05-01T22:36:12.692263	12	81	2115
245	found article about early paralympics history want know where first international event for disabled athletes	The first international sporting competition for disabled athletes took place at Stoke Mandeville in 1952 when a Dutch team participated in the Stoke Mandeville Games. These games had started in 1948 as a special athletics event for 16 disabled ex-soldiers at Aylesbury hospital. In 1960, the competition went international by moving to Rome alongside the Olympic Games, which is considered the birth of the Paralympics.	"[""NOT-LONDON 2012 Exploring Olympic venues outside the capital 2) Stoke Mandeville\nLondon's Olympic closing ceremony will take place exactly two years from today. But that won't be the end of the show. Three weeks later the other Games kick off, the Games far fewer people follow, the Paralympics. And they have their their roots in English suburbia, 30 miles outside London in deepest Buckinghamshire. So I've been there too. After Wenlock, Mandeville.\nThe seeds of the Paralympics were unintentionally sown when an Aylesbury hospital was chosen for the treatment of military casualties during World War 2. A specialist spinal injuries unit was set up, whose expertise continued and grew into peacetime under the directorship of Dr Ludwig Guttmann. When London hosted the Olympic Games in 1948, hospital staff organised a special athletics event for 16 disabled ex-soldiers, and the annual Stoke Mandeville Games were born. In 1952 a Dutch team turned up, launching the first international sporting competition for disabled athletes. And in 1960 the competition ventured abroad to Rome, taking place alongside the city's able-bodied Olympics. Known at the time as the 9th Annual International Stoke Mandeville Games, this is the moment when the Paralympics are deemed to have been born. And yes, we came second. Great Britain's very good at coming second in the Paralympics, but we've never yet topped the medal table.\nIf you want to get to Stoke Mandeville hospital (not via an ambulance), there's one important thing to remember. Don't get off the train at Stoke Mandeville station. They have big signs up on the platforms warning you not to, and to alight at Aylesbury instead. The hospital was originally an isolation unit for cholera sufferers, so was very deliberately built in the nomansland halfway between the two settlements. Aylesbury's long since grown up and swallowed the place, but the hospital retains the name of the small commuter village down the road.\nI got off the train at Stoke Mandeville, because I'm like that, although almost nobody else did. This is a sleepy Chiltern backwater, peaceful but not overflowing with character. The Post Office is the sort of place that sells Silvine exercise books and Tunnock's tea cakes. The village hall is the sort of place that hosts the Mid Bucks Rabbit Show. And the bus stop is the sort of place that boasts only five services a day, so I walked to the hospital instead. It was only a mile across the fields towards the big chimney in the distance, past a couple of extremely tame sheep, but there were rather a lot of stiles on the way so I'd never have managed the journey in a wheelchair.\nOK, so Stoke Mandeville Hospital looks very much like a modern hospital. A huge organic cluster of rambling buildings, some thrusting and modern, others barely-altered prefabs from the dawn of the NHS [photo]. The Spinal Injuries Unit is one of the more up-to-date wings, with a friendly 'Welcome' scrawled across its roof. But I headed round the bleak northern perimeter road, past several staff car parks, to catch a glimpse of the legendary stadium. There it was through the fence, behind the junior doctors' accommodation block, a ring of eight blue lanes curving off towards a distant hedge. All the usual athletics facilities, by the looks of things, including spaces for chucking things and nets for chucking them into. In fact nothing extra special at all, because this is Sport For All, and round here everyone uses the same track. [photo]\nBut not every sports track has an Olympic Village attached. Most of it is bungalows, obviously, in a none-too fetching shade of sludge-brown brick surrounded by unkempt shrubbery. The village was built for the one occasion the fledgling Paralympics came to Stoke Mandeville, in 1984, when the hosting honours were shared transatlantically with New York. Nextdoor is the two-storey Olympic Lodge, with a ramp, obviously, which doubles up as an accessible hotel and conference centre. And a big steely sports centre, named after dear old Dr Guttman, within which lurk a badminton hall, swimming pool and (obviously) a gym. Looking at the Aylesburyfolk walking inside to use the facilities, and pumping iron through the smoked glass windows, you'd never guess this place had any special disabled function at all.\nBut there's a proper hint of the old days across the car park. A row of ramshackle white huts, of the kind that ought to house a pack or three of postwar boy scouts, unsullied by upgrade since their sporting debut [photo]. One's the Shooting Hall, where wheelchair athletes won medals for target practice, and another's the Wallace-Taylor Cuesports Room, where sedentary snooker players potted black for gold. And there's an indoor bowls centre too, even though that's not a Paralympic sport any more, because they used to do things differently here.\nDisabled sport has moved on big time since 1948, so that when the Paralympics return to the UK in 2012 they'll have vastly outgrown this pioneering provincial sports centre. But its legacy lives on, both around here and around the world. And it's thanks to Stoke Mandeville that in precisely two years' time the London Games won't be over, there'll still be half the fun to go.""]"	['<urn:uuid:0512a3b2-c960-4639-af69-6dda338cd543>']	open-ended	with-premise	long-search-query	distant-from-document	single-doc	novice	2025-05-01T22:36:12.692263	15	65	873
246	recipes raw cooked kale differences	Kale can be eaten both raw and cooked, with different varieties better suited for each preparation. Raw preparations include massaged kale salads and smoothies, while cooking methods span braising, boiling, steaming and stir-frying. Some varieties like Curly kale have a bitter taste that disappears when cooked, while others like Lacinato have a mild, nutty flavor suitable for raw consumption. Baby kale has particularly tender leaves making it ideal for salads, while tougher varieties like Ornamental kale require extended cooking times to become tender.	"['Kale, oh kale, how we love your leafy greens. They\'re the superfood superstar that somehow made it from farmers markets to Mickey D\'s, bringing a whole slew of beloved salads, soups, chips, and juices along for the ride.\nBut despite all that kale-leaf love, most recipes suggest you de-stem the sturdy greens by slicing along the thick middle stalk, use only the (relatively) more tender leaf, and toss the stems into the compost bin. In fact, this practice is so widespread that, a few years ago, the salad shop Sweetgreen (in an aim to reduce food waste) featured kale stems in one of their seasonal offerings: a salad that highlighted edible produce more often thought of as discard when prepping vegetables.\nWhen I first heard of that Sweetgreen initiative, I was a bit surprised. ""Don\'t most people eat the stems?"" I asked naively. Apparently not. That firmer middle section is usually tossed aside.\nWell, no more! Because for all their crunch, those stems are just as delicious as the leafy greens they bind together. And while it\'s true you might not want to use them in a raw massaged kale salad, they have tons of applications, and you can cook—or not cook—them in just as many ways. Here are a few of our favorites:\n1. Blend kale stems into a juice or a smoothie\nVeggie juice + kale go hand-in-hand. And why stop with just the leaves? In fact, the stems have more fiber. So go ahead and toss them into a blender or juicer for your morning beverage or smoothie fix.\n2. Slice kale stems thin for texture\nYou might not want to toss kale stems right into your salad bowl, but that doesn\'t mean they don\'t belong. Add more heft to your lunch by slicing the stems thinly—or even shaving them on a mandoline. Toss them in after massaging the greens for a crisp, fresh crunch.\n3. Add kale stems to a sauté or stir-fry\nNot into eating those crunchy stems raw? Go ahead and de-rib the leaves, then slice the stalks and add them to a skillet with chopped garlic or onion. Cook until they turn soft and translucent. Chop up the leaves, add them to the pan, and continue to cook until the leaves are tender. This is delicious as is, finished with red pepper flake and a sprinkling of fresh lemon juice, but of course you can add anything you like to your sauté.\n4. Roast kale stems in the oven\nMaking kale chips? Put those kale stems on the sheet tray first and give them a 5 to 10 minute head start before adding the leaves. Then snack on those crispy bits along with your chips.\n5. Char kale stems on the grill\nThe high heat of the grill will help break down the fibrous texture of the stems, and add nice charred flavor to the earthiness of the kale. Add them into a mix of other grilled vegetables for a salad, or serve simply on their own, drizzled with oil and topped with shaved parmesan.\n6. Purée kale stems into a dip\nNo reason to break open a can of beans when you have leftover stems around. Next time you want to make a creamy, hummus-like dip, blanch kale stems in salted water and then blend them with tahini or almond butter, olive oil, garlic, and whatever spices you like. Or blend them with yogurt or sour cream, plus mayo, avocado, and herbs for a green goddess take.\n7. Mix kale stems with something creamy\nCreamed spinach, creamed onions, creamed kale, it\'s all delicious. Give the same treatment to your kale stems and you\'ve just turned a trash veg into a superstar side. Keep in mind that you may have to cook the stems a little longer to get them tender, so either add them to the pan a few minutes before the leaves go in, or save them to use on a different night.\n8. Poach kale stems in soup\nMaking vegetable soup? Chop up those kale stems and add them into the mix. Whether you are keeping it chunky, minestrone-style, or making a creamy purée, this vegetable will add a nice, earthy flavor.\n9. Slow-cook kale stems in a braise\nIf you\'re planning to make Southern-style slow-cooked greens, where the greens burble on the stove for an hour or more, there\'s no reason to take time removing the kale stems. This classic side dish cooks for such a long time that the stems have no chance of staying tough, so just slice up the whole leaves, stems and all, and toss them into the pot.\n10. Turn kale stems into a pickle\nHow do you make a tough vegetable more tender? Soak it in tangy brine, turning it into a tart pickle. Pour the brine over kale stems while it\'s still hot, letting the vegetable cook slightly, which will help break down its firm texture. Use pickled kale stems chopped in salads, as a garnish for tacos, or spread onto sandwiches.\n11. Batter kale stems and fry them\nIs there a vegetable that isn\'t good fried? Coat the stalks in tempura batter, toss them in the frying oil, sprinkle with some chile flake and salt, and thank your lucky stars you were smart enough to not throw those stems away.', 'Kale is a nutrient-dense superfood that’s not only common in home gardens but also restaurants. The vegetable is packed with magnesium, vitamin A, vitamin C, vitamin K, and fiber. It’s also a rich source of antioxidant polyphenols that protect against oxidative stress and aging.\nIts taste and versatility make this vegetable an excellent addition to stews, soups, salads, pesto, smoothies, and more.\nKale is a hardy vegetable that can grow anywhere. There are different types and varieties of kale, including both hybrid and heirloom types. Our detailed guide covers some of the common types of kale varieties and their differentiating characteristics.\nSome of the common kale varieties include the following.\n1. Premier Kale\nPremier kale is famous for its ability to thrive in any climate. You can plant this variety in both hot and cold climates. It has a leaf length of 15 inches and a mild flavor.\nThis kale variety can mature in 60 days and is an excellent choice for container gardening.\nIt has a medium-green color with very large and smooth leaves.\nPremier kale is rich in vitamin A and other nutrients. It’s also simple to prepare, and you can add it to stews. Its fresh, rich taste makes it ideal for fresh salads and cold sandwiches.\n2. Curly Kale\nCurly kale is a popular kale variety found in most grocery stores. It comes in various shades of green and has rippled leaves. This kale can survive in cold and hot climates.\nCurly kale has a slightly bitter taste that disappears when cooked. It can be served in salads or steamed and added to soups.\nLacinato or Tuscan kale has uncurled green leaves that resemble a dinosaur’s skin. The leaves have a thick stalk.\nUnlike some kale varieties, Lacinato is an excellent variety to plant as it’s simple to grow and can thrive in both hot and cold climates.\nOriginally from Tuscany, Italy, this type of kale is best for braising and boiling. You can add it to soups and stews to add flavor. Alternatively, you can eat it raw, thanks to its mild and nutty flavor.\n4. Redbor Kale\nRedbor kale has ruffled purple leaves with shades of green, varying to a deep red-purple color.\nAlthough the redbor kale has flat leaves, they tend to curl up and change their color during the cold season.\nThis kale variety can be cooked and used for garnishes as it has a mild taste. The kale retains the purple color even when cooked and makes a perfect addition to salads.\nSome people also plant it for its ornamental qualities.\n5. Red Russian\nRed Russian kale is rich in nutrients and vitamins. It has a higher content of nutrients compared to other kale varieties.\nOne distinct feature of this variety is the light green, soft, thin leaves with red stems. Its wide-toothed leaves also darken when cooked.\nWhile you can eat the young leaves in salads, mature leaves are best cooked and added to stews.\nUnlike other kale varieties, the Red Russian kale is hardy and resistant to pests and diseases.\n6. Siberian Kale\nSiberian kale has green leaves with a tint of blue and white stems. There’s also a variety that has purple or red shades. The leaves are ruffled but flat in the middle around the central rib.\nSiberian kale is one of the tender kale varieties that taste like cabbage when cooked.\nSiberian kale, also known as rape kale, has seeds that produce oil. The rapeseed oil is rich in omega 3 and 6 fatty acids. Rapeseed oil is commonly known as canola oil.\n7. Chidori Red Kale\nChidori kale is grown as a decorative plant but can also be consumed. It has red, ruffled leaves that come from anthocyanin pigments.\nAlthough edible, Chidori kale has a slightly bitter taste and tends to lose its color when cooked.\nThis kale variety contains vitamins A and C, magnesium, calcium, and dietary fiber.\nApart from using it as a raw garnish, you can also braise, stew, steam, and fry the Chidori kale.\n8. Vates Dwarf Blue Scotch Curled Kale\nThe blue Scotch curled kale has tight green-blue leaves compared to curly leaf kale. This variety was developed in a Virginian agricultural facility, where it got the name Vates.\nBlue Scotch curled kale does well in cold and hot climates.\nYou can use this kale variety for your stews or pop some leaves in your salads.\n9. Scotch Kale\nScotch kale has curly blue leaves. It’s a short type of kale that grows up to two feet tall.\nThe kale variety works best in both salads and stir-fries due to its sweet flavor.\n10. Baby Kale\nBaby kale has small and thin leaves with a taste similar to the regular curly-leaf kale. Its young leaves give it a milder flavor, which makes it a perfect addition to salads and other foods.\nDon’t let its small size fool you, as baby kale is rich in iron, calcium, and vitamins.\nThe variety needs plenty of shade to grow as it’s not as hardy as other kale varieties. It thrives well in a place that’s not too hot or cold.\n11. Ornamental Kale\nOrnamental kale comes in different shades of white, pink, or purple with a flower-like center. This variety can survive in hardy areas.\nAlthough it’s mainly used in decorations, ornamental kale can also be consumed. However, it’s tough and less tasty compared to other kale varieties. You’ll have to cook it for an extended period to soften the leaves and add them to soups or stews.\nSome people use this type of kale as a garnish when serving other dishes.\n12. Winter Red Kale\nWinter red kale is a rare variety that thrives well in cold conditions. However, with sun exposure, the plant can mature in two months.\nIt has a bright red stem and green leaves.\n13. Scarlett Kale\nScarlett kale has dark purple leaves that are curly. While the texture can be rough when eaten raw, this quickly changes once cooked.\nThe kale takes up to 60 days to mature, and the longer it’s left to grow, the sweeter it becomes.\nMost people prefer to eat scarlet kale in salads due to its firm and crunchy texture.\n14. Walking Stick Kale\nThe walking stick kale features very large stems that grow up to six feet tall. It has large leaves and thick stems.\nUnlike most kale varieties that can survive in any climate, the walking stick kale can only thrive in hot areas.\nThis variety has a sweet flavor and makes a great addition to salads and stews.\n15. Chinese Kale\nChinese kale also referred to as Chinese broccoli, belongs to the Alboglabra group. It has wrinkled leaves, a short stature, and a thick stalk like broccoli.\nThis kale variety can grow all year round and is heat tolerant.\nYou can use the younger leaves and flowering stalks in your stir-fries or steam them like the regular leafy green kale.\n16. Tronchuda Kale\nTronchuda kale is a Portuguese kale variety with unique bluish-green circular leaves. It resembles collard greens due to its light green or white stems.\nThe kale has a sweet taste and tender leaves. Tronchunda kale can survive in hot climates like wild cabbage.\nKale has different varieties that vary in terms of color, texture, and flavor. Whether you’re looking to grow your kale in the garden or get some to add to your stews and salads, there’s a wide variety to choose from.\nHopefully, you now know what to look for when shopping for a particular kale variety.']"	['<urn:uuid:6820a755-ee2b-4114-8675-f3528e35a8c0>', '<urn:uuid:431fc6b1-6cf6-4423-be1b-5cb80886625b>']	open-ended	direct	short-search-query	distant-from-document	multi-aspect	novice	2025-05-01T22:36:12.692263	5	83	2151
250	why do old movie theaters close down	Historic movie theaters have closed down for various reasons. In Milwaukee, many older, ornate theaters began to close as modern movie theaters with multiple screens came on the scene, though some are now being revitalized for different purposes rather than competing with major cinema chains like AMC and Marcus. This pattern is also illustrated in Walnut, Iowa's history, where theaters struggled due to economic challenges - during the 1920s and 1930s, many families couldn't afford regular movie attendance due to difficult economic conditions. Additionally, technological changes played a role - by the early 1950s, the rise of television led to decreased patronage, as evidenced by the Walnut Theatre's closure in 1953 due to sharp decline in business, despite attempts to modernize with a larger screen.	['As Americans fell in love with movies in the 1910s and 20s, extravagant movie palaces were built. The theater’s generally featured a single screen and a stage for vaudeville performances. However, as modern movie theaters came on the scene with multiple screens, many of those older, ornate theaters began to close and fall into disrepair. Over the past few decades, many of these spaces have been brought back to life as atmospheric theaters and music venues.\nHere in Milwaukee, many of these historic theaters are undergoing renovations. Tom Daykin covers commercial development for the Milwaukee Journal Sentinel, so he’s an ideal person to share updates on some of the plans for renovating these historic buildings.\nMilwaukee, in general, has done a good job of maintaining historic buildings. The problem though, according to Daykin, is that “the idea is one thing, the romance is one thing, the costs is quite another. They tend to be like a lot of historic building renovation projects — very expensive.”\nAlthough some of these movie palaces will still show movies, Daykin says they aren’t trying to compete with AMC and Marcus for regular release movies. “The people doing these projects, in some cases they may be a a bit idealistic, but they’re not stupid.”\nMany of these theaters are still in the planning stages of redevelopment, so Daykin is proving an update on some of the renovations that are moving forward.\nThe Warner Grand Theatre (212 W. Wisconsin Ave.)\nBuilt during the height of the Great Depression, the Warner Grand Theatre will get a second life as the new home of the Milwaukee Symphony Orchestra (MSO). It will cost $89 million to restore it and turn it into MSO’s performance venue, rehearsal space, and office space.\nA building next to it was torn down to create a new addition that blends the older historic architecture with a new design. Daykin says Marcus Corporation did a good job of maintaining the building, making the renovation much easier than it otherwise could have been.\nThe restorations is “going to have a really big impact on downtown, specifically on the west side of downtown,” Daykin says.\nThe MSO plans to open at the newly restored venue by September 2020.\nThe New State Theater (2600 W. State St.)\nBuilt in 1915, the State Theater closed by the late 1950s. Throughout the 1980s and up until the early ’90s, however, it served as a working tavern and club for mostly rock music. After shutting down and reopening as a strip club, its license didn’t get renewed and it subsequently closed for good.\nLast year, though, a nonprofit group bought the property with plans to restore the theater into an all-ages music venue, which Daykins says “is something that we hear repeatedly is needed in Milwaukee.” The group also plans to use the space for classes and workshops, a storefront for local artists, and sound engineering studios.\nThe West Bend Theatre (125 Main St., West Bend)\nJust outside of Milwaukee, the West Bend Theatre is going through a renovation of its own. The Historic West Bend Theatre nonprofit group is in the midst of an approval process with the West Bend Plan Commission to renovate the exterior. But they’ve already done a significant amount of interior work, including removing lead paint, asbestos, and all the old seats that were beyond repair, Daykin says.\nThey hope to have their soft opening by winter of this year. Daykin says “they plan to show some movies,” but also have “live performances and other events too.”\nThe Grand Theater (2917-23 N. Holton Ave.)\nBuilt in 1911, the lesser-known Grand Theater sits on the border of the Riverwest and Harambee neighborhoods. Although renovation of the theater is still in its nascent stages, Daykin says the Riverwest Investment Cooperative has raised money to convert the theater into a live venue for performance arts. And that makes sense, as Daykin says “Riverwest and Harambee both have a lot of musicians living there.”\nThe Modjeska Theatre (1134 W. Mitchell St.)\nBuilt in 1924, the Modjeska Theatre is owned by the nonprofit Mitchell Street Development Opportunities Corporation. The group is seeking proposals to renovate the theater and operate the building. “They’ve done a fair amount of interior demolition and gutting work,” says Daykin, and “they’re actively looking for a user for the building.”', 'THEATRES OF WALNUT, IOWA\nBY JIM HANSEN\nFor about 46 years, the citizens of Walnut enjoyed the entertainment of hometown theatres. In 1941, Transient House, one of the oldest landmarks in the city of Walnut, was torn down. The two other former theater buildings remained. The old Transient House had been built in the very beginnings of Walnut and had survived more than one devastating fire. Its location was a little more than half a block east of the intersection of Central Street (Antique City Drive) and Pearl Street with one side facing the railroad tracks. J. W. Cissna, who had owned the establishment since 1902, was the owner in 1908 when the first picture show appeared in Walnut at The Bijou. The projection booth was built across the sidewalk in front of the building, the auditorium was seated with park benches and the “silver screen” was made of wallpaper painted white. The building was sold in December of 1908. It is unclear whether Cissna or the new owner sold the movie equipment, but either way, in 1909, the equipment had been moved to the I.O.O.F. Opera House at 202 Central Street. The new theatre was named the Lyric and remained there for many years.\nIn 1913, J. C. Vollstedt removed the old wooden buildings he had owned since 1885 and built new brick buildings at 301 and 303 Central Street. He started the Happy Hour Theatre at 303 Central Street in competition with the Lyric. In The Walnut Bureau, the editor stated that, although Walnut appeared to be too small to support two theatres, he wished the new owner success. The real winner was the newspaper, due to all the extra advertising. The two theatres competed for about a year.\nThen, in the fall of 1914, the Lyric converted its theater to a roller skating rink. Walnut’s City Council passed Ordinance No. 41, controlling theatres and skating rinks at this time, which rewarded the city coffers with a monthly fee of not less than $5.00 from each establishment. The rink opened on September 10, 1914, and was to operate for the fall and winter months. The last rink ad found was in the March 4, 1915 Walnut paper. Things didn’t sound good at this point, but The Lyric was far from defeated. One must remember that the Lyric was in the Opera House and plays, as well as other entertainment, continued to bring in dollars, while the movies and roller skating income wavered. Advertising for the Lyric theatre began again in the October 7, 1915 issue of The Walnut Bureau.\nIn 1916, J. C. Vollstedt purchased the Lyric and suspended operations at the Happy Hour, although a movie was shown there occasionally. Late in 1917, Joe Mahoney purchased both theatres from Vollstedt, closed the Lyric and reopened the Happy Hour. Later, J. W. Andresen purchased and opened the Lyric. On October 29, 1925, M. N. Wantz purchased the Lyric. This buying and selling was of the equipment and leases, not the buildings. One piece of information that is obviously missing from the early days of silent films is that of the pianists who played during the shows. Two names out of the many who played are all that I could find. They were Grace Mickel Caddock and Wanda Rieck Jacobsen.\nThe 20’s had been tough for the farmers and the 1930’s proved to be even worse. The Lyric sold in February, 1930 to Royal Duke of Sioux City and the name changed to the Ritz Theatre. This was the only name change to the theatre in the Opera House. The Walnut Theatre was the new name of the Happy Hour in 1931, as the new manager Earl Miller, opened to a full house. Walnut residents were hungry for new movie entertainment, with sound, but household incomes of most families could not sustain a steady diet of weekly movies. In 1935, new owners L. C. Staats, Harold Smith, Cecil Luxford and James Snapp renamed the Walnut Theatre the New Dreamland.\nMore changes — in the fall of 1936, Walnut had a “Name the Theatre Contest” which ran for several weeks. Finally, the three judges, Mayor Fred Fell, Otto Brehmer and August Ketelsen, chose the winning name, “Pep”, submitted by L. D. Wayne, who won a 1st place prize of $10. The Pep owner/manager was Byron Beard who sold the theatre about a year later, in June of 1937 to T. E. Griffin of Wolback, Nebraska. Mr. Beard’s health had required that he and his wife move to Phoenix, Arizona. T. E. Griffin sold the Pep to Guy Cocklin of Griswold, Iowa just two months later. Cocklin renamed the theatre at 303 Central Street the Strand Theatre. The prices were reduced to 10¢ and 15¢ for Wednesday, Thursday, Friday and Saturday nights and 10¢ and 25¢ for the Sunday, Monday and Tuesday shows. He asked customers for their liberal patronage and promised to make added improvements and buy the latest equipment, as the support he received justified.\nSeveral ads and news articles were found in the December issues of The Walnut Bureau for free shows and visits by Santa Claus. The Walnut Commercial Club arranged for Santa to hand out big bags of candy and nuts to the young folks of the community. Several of our citizens still remember those happy days of their youth while attending the free Christmas shows at the Strand Theatre. Other events were also held in the Strand. One such event was the January 23, 1940 Beauty Parade in which a Walnut girl was selected “Miss Walnut” to represent her town in the “Miss Iowa State Contest.” Miss Donna Lehnhardt was chosen in 1940.\n- T. Carter sold the Strand on March 1, 1940 to W. J. Morrison of Sac City, Iowa. Mr. Carter moved to Des Moines.\n“FIRE” “FIRE” was reported by Lawrence Rossmann on July 22, 1940 when he noticed smoke coming from the Strand Theatre. The fire damaged the theatre, the John Tramm garage just to the east, and the building to the south that housed the Christiansen Beauty Shop and the H J. Stahl Tailor Shop, to a lesser degree. The fire is believed to have been started by spontaneous combustion in a storage room just off the stage and had likely been burning an hour or so before its discovery. The fire was so hot that it took the Walnut firemen more than two hours to extinguish, because it had gotten into the rafters and burned through the roof. Damage to the theatre was extensive. The stage, equipment, and seats were burned, twisted and warped, and the walls and ceiling were greatly damaged. The building was almost beyond repair, according to the newspaper. J. W. Morrison, the owner/operator for less than five months, said insurance would only cover part of the loss and this would put him out of business. Henry Vollstedt, owner of the building, said his $6000 to $8000 loss was totally covered. The theatre was closed for over six months.\nThe Walnut Improvement Company purchased the damaged building and remodeled it with material from the Sieffert Lumber Company. The interior of the theatre and annex were encased with new wood that was designed for improved sound effects. Room corners were rounded, which made a pleasing interior. New floors were laid and the ceiling finished in new wood. A restroom, an office and the large round windows were built into the annex. A new heating system was also installed. Charles V. Shoecraft leased both the theatre and the annex, installed the latest in sound equipment, put in a fireproof projection room and installed 250 new seats. The business was renamed, for the last time, the Walnut Theatre, and reopened on January 10, 1941. H. E. Brookings, from Oakland, Iowa, took over operations in May of 1942, but the success of the theatre was in jeopardy. A sheriff’s sale in 1944, gave ownership of the building to the Sieffert Lumber Company who sold it to C. W. Ballantine in January, 1945. He resold it to Mary Wiese a few days later.\nWith WWII over in 1945, things seemed to rebound to some degree, but the inevitable popularity of the television was looming just around the corner. In 1949, operator Brookings hired Henry Johnson to manage the theatre, and all would be fine for a few more years. A larger screen was installed on a wider stage built by John Rethwisch in March of 1952. The improvements were probably built in hopes of bringing customers back. George Mertz purchased the building in September of that year and resold it to Clarence Walter in December.\nThen, in January of 1953, the Walnut Theatre closed. Henry Johnson was quoted by the Omaha World-Herald, “The lack of patronage was the principal reason for closing. Business used to be good, but in recent months, it fell off sharply.” Henry Johnson wasn’t the only employee to lose his job, as the projectionists lost their 35 cents per hour job. Ned Pilling was one of those young men. He found work putting up TV antennas and helping his father at the Walnut Telephone Company.\nMr. Fleming, of Atlantic, made a deal with Brookings and tried his best to get things going again. He operated the theatre for a few months in the summer of 1953, but by March of 1954, Brookings had decided it was time to cut his losses and surrendered the building lease on May 1, 1954. The Walnut Theatre was forever closed. The AMVETS purchased the empty building from Clarence Walter and remodeled it to suit their needs.\nThe story doesn’t end just yet. In June of 1954, Don and Keith Smith of Omaha received permission from the Walnut Community Club to open the Walnut Drive-In Theatre at the ballpark. Shows were held on Wednesday evenings through September 16th and only then closed for the final curtain.\nThe Lyric Theatre in the 1920’s']	['<urn:uuid:c66e5810-156c-4397-ba02-d2bdaad55b0c>', '<urn:uuid:17099f64-d56e-42b5-8496-db53c1bf6b67>']	open-ended	with-premise	short-search-query	distant-from-document	three-doc	novice	2025-05-01T22:36:12.692263	7	125	2382
251	When should I pick my snow peas and regular pea pods from the garden to ensure the best quality?	Snow peas should be harvested when the pods reach 2 to 4 inches but still remain flat. For regular peas, harvest the pods when they appear and feel full but not plumped out. Both types should be checked daily as they can quickly lose their resiliency while on the vine.	"['You\'re growing your own vegetables and you can\'t wait to pick them. Well, you probably need to wait. But for how long? When will that tomato be ready? How about the cucumbers? How can you tell when carrots are ready to be harvested? How exactly do you pick leaf lettuce?\nThe fact is there are no specific rules that apply to all vegetables. In order to maximize flavor and texture, vegetables tend to be harvested just prior to turning ripe. So how can you tell that it\'s time to pluck, twist, cut or pick your bounty? Here are a few individual guidelines for some of the more popular homegrown vegetables, including carrots, cucumbers, lettuce, eggplant, onions, radishes and peas.\nCarrots, which can remain in the ground once ripe, are one of the most difficult vegetables to judge in terms of maturity. Check the tops of the carrots; they should be poking through the soil line. If that\'s the case, look at the diameter of the top of the carrot - does it look like it\'s the correct size? If it does chances are it\'s ready, but the only way you\'ll know for sure is by pulling one.\nCucumbers should be picked when young, firm and smooth. These vegetables, which will turn bitter if left to become over ripe, need to be checked each day.\nWith eggplant make sure the fruit is glossy and firm but still not matured. When harvesting you want to cut and not pull the fruit.\nTo get the most from your leaf lettuce, harvest each plant in cycles. First pick the leaves on the outside edge of the plant when they are about 4 inches tall. Leave the immature, inner leaves to grow and pick once they\'ve reached the proper height. This process should continue throughout the summer. With head lettuce, check with a gentle squeeze to see if it has a solid and full feel.\nRadishes are ready to harvest when they reach their mature size (check the seed packet). Pull them from the ground immediately or the roots will get woody and bitter and start to crack.\nWhen onion or garlic tops ripen they fall over. That means it\'s time to pick them. To bring onions or garlic to full maturity you should dry them in the sun prior to storing. Dig them from the ground with a large fork or trowel rather than pulling them out.\nHarvest snap beans and peas before they bulge out and fully ripen. Pea pods should appear and feel full but not plumped out, while snap beans should ""snap"" crisply in two after being picked. Because they can lose their resiliency quickly while on the vine, check both of these vegetables daily. Snow peas are ready when the pods reach 2 to 4 inches but still remain flat.\nTomatoes, which should be twisted off the plant, are best when they feel soft but not squishy when you touch them. Pick when fully colored. After harvesting do not refrigerate but leave in the open air away from direct sunlight. Make sure all your tomatoes are in by the first hard frost. Leave the green ones in a box filled with newspaper under your bed and they\'ll ripen over the course of a few weeks.\nWhen taking vegetables fresh off the vine remember that most taste best and last longer when taken a little early. Young, newly harvested vegetables tend to retain their taste, texture and color longer and will be a daily reminder of why you\'ve labored in your garden throughout the planting, growing, and picking seasons.\nAbout The Author: Ellen Brown is our Green Living and Gardening Expert. Click here to ask Ellen a question! Ellen Brown is an environmental writer and photographer and the owner of Sustainable Media, an environmental media company that specializes in helping businesses and organizations promote eco-friendly products and services. Contact her on the web at http://www.sustainable-media.com\nAdd your voice to the conversation. Click here to post feedback.']"	['<urn:uuid:64e94f9f-4ea5-4e1c-8836-e6ede7ff959e>']	factoid	direct	verbose-and-natural	distant-from-document	single-doc	expert	2025-05-01T23:21:14.341336	19	50	665
252	plutonium waste treatment decontamination effectiveness	Plutonium waste treatment involves various decontamination approaches. At facilities like the Waste Treatment and Immobilization Plant (Vit Plant), waste is processed through vitrification, where glass-forming materials are used to immobilize radioactive waste. The effectiveness of treatment is significant - removing plutonium from waste through reprocessing notably reduces radiotoxicity compared to untreated fuel. While plutonium is one of the most toxic elements in nuclear waste, being an alpha emitter containing approximately 1,000 times more energy than beta rays from tritium, its high toxicity is partially mitigated by its very low mobility in the environment.	"[""The Low Intensity Test Reactor structure is lifted from its housing and placed in a specialized carbon metal container for shipment for disposal. (Photo: DOE)\nThe Department of Energy’s Office of Environmental Management announced it has completed a second of its 2023 priorities at Oak Ridge in as many months with the demolition of the Low Intensity Test Reactor, known as Building 3005, at the Tennessee site.\nWatch a video of Building 3005 and its decommissioning here.\nWorkers remove contaminated sediment from the SRS in South Carolina. A $19 million DOE grant will support state monitoring of the site. (Photo: DOE)\nThe Department of Energy’s Office of Environmental Management has awarded nearly $54 million in noncompetitive financial assistance grants and cooperative agreements to help support the office’s cleanup program. DOE-EM is responsible for environmental legacy cleanup of the effects of decades of nuclear weapons development and government-sponsored nuclear energy research.\nA Department of Ecology inspector at the Hanford Site. (Photo: Department of Ecology)\nWashington state’s Department of Ecology said it has reached a settlement with the Department of Energy over access to data the state described as “critical” to the cleanup of the Hanford Site near Richland, Wash.\nA startup heater is removed from a melter in the Vit Plant’s Low-Activity Waste Facility. (Photo: DOE)\nWorkers at the Hanford Site’s Waste Treatment and Immobilization Plant, also known as the Vit Plant, have begun removing the first three of 18 temporary startup heaters, the Department of Energy announced on September 12. The startup heaters were used to raise the first of two 300-ton glass melters in the plant’s Low-Activity Waste Facility to its operating temperature of 2,100°F.\nAn elk herd at the DOE’s Hanford Site in Washington state. (Photo: DOE)\nThe Department of Energy has released the first request for information (RFI) related to the department’s Cleanup to Clean Energy initiative, which aims to repurpose certain DOE-owned lands, portions of which were previously used in the nation’s nuclear weapons program, into sites for clean energy generation.\nMonticello nuclear power plant. (Photo: Xcel Energy)\nThe Minnesota Public Utilities Commission (PUC) has approved Xcel Energy’s request for a certificate of need to expand spent fuel storage at the utility’s Monticello nuclear power plant.\nThe additional storage, according to the PUC, requires installation of a second concrete support pad and modular concrete storage system designed to hold 14 additional steel canisters.\nXcel had requested increased outdoor storage to accommodate its plan to extend Monticello’s operational life by 10 years, to 2040.\nTaking part in the Environmental Management Disposal Facility groundbreaking, from left, were Steve Arnette of Jacobs; Mark Whitney of Amentum,; Wade Creswell, a Roane Co., Tenn., executive; Brent Booker of the Laborers’ International Union of North America; Kevin Adkisson of North America’s Building Trades Unions; Jeaneanne Gettle of the EPA; Lt. Gov. Randy McNally; David Salyers of TDEC; Ken Rueter of UCOR; Jay Mullis of OREM; U.S. Rep. Chuck Fleischmann; and DOE-EM’s William “Ike” White. (Photo: DOE)\nNational, state, and local leaders joined the Department of Energy’s Oak Ridge Office of Environmental Management (OREM) and its lead cleanup contractor, United Cleanup Oak Ridge (UCOR), earlier this month to celebrate the groundbreaking for a new on-site disposal facility at the Oak Ridge Reservation in Tennessee.\nWatch a video highlighting the Environmental Management Disposal Facility groundbreaking ceremony here.\nTreated water is safer than world standards, essential for decommissioning\nWashington, D.C. – The American Nuclear Society (ANS) supports the start of Japan’s controlled release of re-treated, diluted tritium wastewater into the sea from the Fukushima Daiichi Nuclear Power Plant (NPP), which sustained damage in the aftermath of a 2011 earthquake and tsunami.\nThe Pile Fuel Cladding Silo on the Sellafield site in West Cumbria, England. (Photo: Sellafield Ltd.)\nAfter decades of planning and weeks of preparation and checks, the first batch of legacy waste has been retrieved from the Pile Fuel Cladding Silo at the Sellafield nuclear site in West Cumbria, England. According to Sellafield Ltd., the site license company, a state-of-the-art robotic arm was used to reach into the silo and, for the first time, remove and repackage the waste for longer-term storage.\nThese retrievals mark a significant achievement in progress toward the cleanup and decommissioning of one of the most hazardous buildings on the site, according to Sellafield Ltd., which made the announcement on August 16.\nWatch a video about the Pile Fuel Cladding Silo and Sellafield’s waste retrieval operations here.\nAn October 2022 photo showing various SDUs at SRS. (Photo: DOE)\nThe Department of Energy’s Savannah River Site in South Carolina will begin a leak tightness test on what it called “the fourth megavolume saltstone disposal unit (SDU)” at the site.\nA schematic illustration of a deep borehole repository assuming disposal into a bedrock. (Image: Sandia National Laboratories via IAEA)\nThe International Atomic Energy Agency is launching a new Coordinated Research Project (CRP) to increase international knowledge and drive progress toward testing deep borehole disposal for intermediate- and high-level radioactive waste.\nSRS reached a landmark achievement with the placement of 2,000 double-stacked canisters of vitrified HLW. (Image: DOE)\nTo expand interim storage of vitrified high-level radioactive waste at the Savannah River Site, the Department of Energy’s Office of Environmental Management and its liquid waste contractor Savannah River Mission Completion (SRMC) have double stacked 2,000 canisters in one of the site's two glass waste storage buildings (GWSB). GWSB 1 consists of a below-grade, seismically qualified concrete storage location containing support frames for the vertical storage of 2,262 10-foot-tall canisters.\nA 300-pound bag of frit is in position to be poured into the melter at Hanford’s LAW Facility. (Photo: Bechtel National)\nThe Department of Energy’s Office of Environmental Management announced that the first batches of glass-forming beads, called frit, were poured last week into a melter at the Hanford Site’s Waste Treatment and Immobilization Plant (WTP), also known as the Vit Plant. The melter, which has been heated to 2,100ºF, will be used to immobilize Hanford’s radioactive and chemical tank waste, turning it into a stable glass form through vitrification.\nSome of the participants of the recent SRNL-Hanford Analytical Knowledge Sharing Workshop pause for a photo. (Photo: DOE)"", 'A risk indicator more pessimistic than radioactive activity\nSpent fuel radiotoxicity evolution from 10 to 1 million years\nThe pattern of change in the radiotoxicity of spent fuel highlights the predominance of plutonium. This element overtakes fission products around 50 years after removal from the reactor.\n© Source: CEA ©\nRadioactivity is an imperfect descriptor of radioactive risks. It makes no allowance for the major difference in harmfulness between radioactive atoms, or for the nature of the emitted radiation and the exposure conditions.\nFor example, alpha rays from plutonium contain approximately 1,000 times more energy than beta rays from tritium. Alpha rays are highly toxic to living matter. However, alpha rays are blocked by the thickness of a sheet of paper, and are totally harmless in case of external exposure.\nHow to realistically assess risk? In principle, all reasonable precautions are taken to ensure that radioactive atoms in spent fuel assemblies and radioactive waste packages remains trapped inside them forever, or at least until they become harmless. They should almost never come into contact with living tissue and the most highly-penetrative rays will not reach us after waste is buried.\nThe danger relates to the tiny minority of radioactive atoms that may migrate from the waste into the biosphere, contaminating it and presenting the risk of ingestion or inhalation by our distant descendants. The risk posed by a radioelement depends on the atom’s mobility and toxicity. Plutonium and minor actinides, which are generally alpha emitters, are by far the most toxic; fortunately, these heavy nuclei are very immobile. Fission products are more mobile, in particular in species such as iodine and caesium, and to a lesser extent technetium.\nMobility of some radioelements\nWhen assessing the actual risk, it is important to consider the mobility of the radioactive species mobility in the environment. This requirement does not apply to “radiotoxicity”. The table shows that the relative mobility of radioelements varies according to whether the host environmental conditions are oxidising or reducing. The ++ and + signs indicate high mobility, and — and – signs indicate low mobility.\n© CNE (French National Evaluation Commission ) ©\nAs it is not possible to predict the quantity of radioactive atoms ingested in the distant future, physicists and engineers adopt the worst-case assumption that all such atoms are ingested. They work with a potential radiotoxicity indicator.\nThe decrease in potential radiotoxicity over time mirrors the decrease in activity. It reflects the change in risk in case of ingestion of the most radiotoxic elements: plutonium and minor actinides. However, this risk should not be confused with the actual risk, as it does not take the mobility of the relevant radioelements into account.\nVitrified waste from which the plutonium has been removed will consequently be less radiotoxic than untreated fuel. This is one of the arguments in favour of reprocessing, subject to reusing the plutonium elsewhere. Fuels may also be compared from a radiotoxicity perspective. For example, spent MOX fuel will be more toxic than spent uranium fuel, as it contains more plutonium and minor actinides.\nOther articles on the subject « Spent nuclear fuel »\nFuel unloading and initial pool storage of spent fuel The fuel load in a conventional pressurised[...]\nSpent fuel Burn-up\nIrradiation rate and energy supplied by fuel The energy produced by a nuclear power plant is prop[...]\nSpent fuel composition\nKey figures The composition of irradiated fuel removed from a reactor core depends on the initial[...]\nWaste radioactivity decrease\nA natural but slow decay process As natural radioactivity progressively decays, the radioactivity[...]\nSpent fuel decay heat\nSignificant, slow-to-decline heat release The heat released by radioactive disintegration is a ke[...]']"	['<urn:uuid:d1c968bb-e5ea-464d-98fa-8d31ce5a9f8f>', '<urn:uuid:c916cc68-2784-4a94-a357-a1781aa22e4b>']	open-ended	direct	short-search-query	distant-from-document	multi-aspect	expert	2025-05-01T23:21:14.341336	5	93	1630
254	What's the key difference between how ground penetrating radar and electromagnetic methods investigate deep underground - specifically in terms of how far down they can scan effectively?	Ground Penetrating Radar (GPR) has significant depth limitations, seldom exceeding 10 meters of penetration, and requires careful feasibility evaluation for investigations beyond this depth even under favorable conditions. In contrast, electromagnetic methods like Time Domain Electromagnetics (TDEM) can reach much greater depths - ranging from 30-40 feet up to 2,000-2,500 feet by adjusting receiver frequency and transmitter loop size. Additionally, while GPR's effectiveness decreases in conductive materials, electromagnetic methods maintain their functionality at greater depths.	"['Ground-penetrating radar (GPR) uses a high-frequency (e.g. 40 to 1,500 MHz) EM pulse transmitted from a radar antenna to probe the earth. The transmitted radar pulses are reflected from various interfaces within the ground, and this return is detected by the radar receiver. Reflecting interfaces may be soil horizons, the groundwater surface, soil/rock interfaces, man-made objects, or any other interface possessing a contrast in dielectric properties. The dielectric properties of materials correlate with many of the mechanical and geologic parameters of materials.\nThe radar signal is imparted to the ground by an antenna that is in close proximity to the ground. The reflected signals can be detected by the transmitting antenna or by a second, separate receiving antenna. The received signals are processed and displayed on a graphic recorder. As the antenna (or antenna pair) is moved along the surface, the graphic recorder displays results in a cross-section record or radar image of the earth. As GPR has short wavelengths in most earth materials, resolution of interfaces and discrete objects is very good. However, the attenuation of the signals in earth materials is high, and depths of penetration seldom exceed 10 m. Clay materials with a high cation exchange capacity increase the attenuation and decreasing penetration. Additonally, the presence of solutes or other substances which increase the electrical conductance of groundwater and have the same attenuation and penetration results.\nThe objective of GPR surveys is to map near-surface interfaces. For many surveys, the location of objects such as tanks or pipes in the subsurface is the objective. Dielectric properties of materials are not measured directly. The method is most useful for detecting changes in the geometry of subsurface interfaces.\nGeologic problems conducive to solution by GPR methods are numerous and include the following: bedrock configuration, location of pipes and tanks, location of the groundwater surface, borrow investigations, and others. Geologic and geophysical objectives determine the specific field parameters and techniques. Delineation of the objectives and the envelope of acceptable parameters are specified in advance. However, as the results cannot be foreseen from the office, considerable latitude is given to the field geophysicist to incorporate changes in methods and techniques.\nThe following questions are important considerations in advance of a GPR survey.\nWhat is the target depth? Though target detection has been reported under unusually favorable circumstances at depths of 100 m or more, a careful feasibility evaluation is necessary if the investigation depths need to exceed 10 m.\nWhat is the target geometry? Size, orientation, and composition are important.\na) What are the electrical properties of the target? As with all geophysical methods, a contrast in physical properties must be present. Dielectric constant and electrical conductivity are the important parameters. Conductivity is most likely to be known or easily estimated.\nb) What are the electrical properties of the host material? Both the electrical properties and homogeneity of the host must be evaluated. Attenuation of the signal is dependent on the electrical properties and on the number of minor interfaces that will scatter the signal.\nc) Are there any possible interfering effects? Radio frequency transmitters, extensive metal structures (including cars) and power poles are probable interfering effects for GPR.\nThe physics of electromagnetic wave propagation are beyond the scope of this manual. However, there are two physical parameters of materials that are important in wave propagation at GPR frequencies. One property is conductivity (σ), the inverse of electrical resistivity (ρ). The relationships of earth material properties to conductivity, measured in mS/m (1/1,000 Ωm), are given in the section on electrical methods.\nThe other physical property of importance at GPR frequencies is the dielectric constant (ε), which is dimensionless. This property is related to how a material reacts to a steady-state electric field; that is, conditions where a potential difference exists but no charge is flowing. Such a condition exists between the plates of a charged capacitor. A vacuum has the lowest ε, and the performance of other materials is related to that of a vacuum. Materials made up of polar molecules, such as water, have a high ε. Physically, a great deal of the energy in an EM field is consumed in interaction with the molecules of water or other polarizable materials. Thus, waves propagating through such a material both go slower and are subject to more attenuation.\nEarth Material Properties\nThe roles of two earth materials that cause important variations in the EM response in a GPR survey need to be appreciated. The ubiquitous component of earth materials is water; the other material is clay. At GPR frequencies, the polar nature of the water molecule causes it to contribute disproportionately to the displacement currents that dominate the current flow at GPR frequencies. Thus, if significant amounts of water are present, the ε will be high, and the velocity of propagation of the electromagnetic wave will be lowered. Clay materials with their trapped ions behave similarly. Additionally, many clay minerals also retain water.\nThe physical parameters in table 18 are typical for the Characterization of earth materials. The range for each parameter is large; thus, the application of these parameters for field use is not elementary.\nSimplified equations for attenuation and velocity (at low loss) are:\nV = velocity in m/s,\nε = dielectric constant (dimensionless),\na = attenuation in decibels/m (db/m),\nσ = electrical conductivity in mS/m.\nA common evaluation parameter is dynamic range or performance figure for the specific GPR system. The performance figure represents the total attenuation loss during the two-way transit of the EM wave that allows reception; greater losses will not be recorded. As sample calculations, consider a conductive material (σ = 100 mS/m) with some water content (ε=20). The above equations indicate a velocity of 0.07 m per nanosecond (m/ns) and an attenuation of 38 dB/m. A GPR system with 100 dB of dynamic range used for this material will cause the signal to become undetectable in 2.6 m of travel.The transit time for 2.6 m of travel would be 37 to 38 ns. This case might correspond geologically to a clay material with some water saturation. Alternatively, consider a dry material (ε=5) with low conductivity (σ = 5 mS/m). The calculated velocity is 0.13 m/ns and the attenuation is 3.8 dB/m, corresponding to a distance of 26‑27 m for 100 dB of attenuation and a travel time of 200 ns or more. This example might correspond to dry sedimentary rocks.\nThese large variations in velocity and especially attenuation are the cause of success (target detection) and failure (insufficient penetration) for surveys in apparently similar geologic settings. As exhaustive catalogs of the properties of specific earth materials are not readily available, most GPR work is based on trial and error and empirical findings.\nTable 1. Electromagnetic properties of earth materials.\nModes of Operation\nThe useful item of interest recorded by the GPR receiver is the train of reflected pulses. The seismic reflection analogy is appropriate. The two reflection methods used in seismic reflection (common offset and common midpoint) are also used in GPR. Figure 1 illustrates these two modes. A transillumination mode is also illustrated in the figure, which is useful in certain types of nondestructive testing. The typical mode of operation is the common-offset mode where the receiver and transmitter are maintained at a fixed distance and moved along a line to produce a profile (figure 2). Note that as in seismic reflection, the energy does not necessarily propagate only downwards, and a reflection will be received from objects off to the side. An added complication with GPR is the fact that some of the energy is radiated into the air and, if reflected off nearby objects like buildings or support vehicles, will appear on the record as arrivals.\nHistorically, a GPR crew consists nominally of two persons. One crew person moves the antenna or antenna pair along the profiles, and the other operates the recorder and annotates the record so that the antenna position or midpoint can be recovered. Recent innovations have made the application of GPR to may scenarios a one person job, by allowing for cart based applications.\nThe site-to-site variation in velocity, attenuation, and surface conditions is so large that seldom can the results be predicted before fieldwork begins. Additionally, the instrument operation is a matter of empirical trial and error in manipulating the appearance of the record. Thus, the following steps are recommended for most fieldwork:\nFigure 2. Schematic illustration of common offset single-fold profiling.\nFigure 3. GPR received signal and graphic profile display. (Benson, Glaccum, and Noel, 1983)\n1. Unpack and set up the instrument and verify internal operation.\n2. Verify external operation (one method is to point the antenna at a car or wall and slowly walk toward it. The reflection pattern should be evident on the record).\n3. Calibrate the internal timing by use of a calibrator.\n4. Calibrate the performance by surveying over a known target at a depth and configuration similar to the objective of the survey (considerable adjustment of the parameters may be necessary to enhance the appearance of the known target on the record).\n5. Begin surveying the area of unknown targets with careful attention to surface conditions, position recovery, and changes in record acter.\nOften a line will be done twice to be sure that all the features on the record are caused by the subsurface.\nBecause of the strong analogy between seismic reflection and GPR, the application of seismic processing methods to GPR data is a fertile field of current research. Such investigations are beyond the scope of this manual. The focus herein is on the most frequent type of GPR survey, i.e., location of specific targets.\nGPR surveys will not achieve the desired results without careful evaluation of site conditions for both geologic or stratigraphic tasks and target-specific interests. If the objectives of a survey are poorly drawn, often the results of the GPR survey will be excellent records that do not have any straightforward interpretation. It is possible to tune a GPR system such that exceptional subsurface detail is visible on the record. The geologic evaluation problem is that, except in special circumstances (like the foreset beds inside of sand dunes), there is no ready interpretation. The record reveals very detailed stratigraphy, but there is no way to verify which piece of the record corresponds to which thin interbedding of alluvium or small moisture variation. GPR surveys are much more successful when a calibration target is available. GPR can be useful in stratigraphic studies; however, a calibrated response (determined perhaps from backhoe trenching) is required for geologic work.\nFigure 4 indicates that localized objects will produce a hyperbola on the record. The hyperbolic shape is due to reflection returns of the EM pulse before and after the antenna system is vertically above the target. The shortest two-way travel distance is when the antenna (or center of the antennae pair) is on the ground surface directly above the object. All other arrivals are at greater distances along a different hypotenuse with each varying horizontal antenna location. This hyperbola is also important for the determination of the radar velocity.\nFigure 5 is the schematic of a set of targets surveyed by GPR. The record section of figure 6 indicates the excellent detection of the targets. Figure 7 displays an example of three dimensional GPR data acquisition for concrete inspection.\nFigure 4. Format of a Ground Penetrating Radar reflection section with radar events shown for features depicted in figure 2.\nFigure 5. Schematic of a set of targets surveyed by Ground Penetrating Radar.\nFigure 6. Actual GPR record over a culvert, pipe, and two tunnels showing the hyperbolic shape of the reflected/diffracted energy. (Annan, 1992)\nFigure 7. A worker images rebar and post tension cables within concrete using high frequency GPR in a 3D grid. A 3D GPR block of data shows the contrasting response from the rebar and post tension cables. Two depth sllices from the 3D block display plan view location of the rebar and post tension cables. These images are presented for references purposes only, no endorsement of the equipment or software manufacturer is intended (http://www.sensoft.ca/applications/structure/casestudy/cs_tensioncables.html).\nGPR Case Histories\nGPR has been widely used, and reports on its effectiveness are available both in government and professional web manuals. Some useful references are:\nDaniels et al. (1995) used GPR applied to remdiation monitoring.\nHuisman et al., (2002) used GPR in an agricultural application.\nButler (1992), which is the proceedings of a GPR workshop and includes a tutorial and a collection of case histories.\nButler, Simms, and Cook (1994), which provides an archaeological site evaluation.\nSharp, Yule, and Butler (1990), which reports the GPR assessment of an HTRW site.\nThe pages found under Surface Methods and Borehole Methods are substantially based on a report produced by the United States Department of Transportation:\nWightman, W. E., Jalinoos, F., Sirles, P., and Hanna, K. (2003). ""Application of Geophysical Methods to Highway Related Problems."" Federal Highway Administration, Central Federal Lands Highway Division, Lakewood, CO, Publication No. FHWA-IF-04-021, September 2003. http://www.cflhd.gov/resources/agm/', 'Hydrogeological Characterization Studies\nHydrogeological characterization studies cover a broad range of applications and services. In the broadest sense these studies are designed to characterize either the earth matrix which is controlling groundwater flow or the quality of the ground water. Typical applications include:\nDetermining Aquifer Thickness\nMapping Vertical Extent and Lateral Continuity of Confining Units\nDetermining Areas of Probable Conduit Flow\nMapping the Vertical and Horizontal Extent of Contaminant Plumes\nDetermining the Depth to Saltwater\nElectrical Resistivity Imaging (ERI)\nThe ERI method develops two-dimension vertical cross-sections which depict the distribution of resistivity. The resistance of earth materials is controlled by both the matrix (soil/rock) resistivity and the groundwater resistivity. As the groundwater conductivity increases (becomes more ionic) the fluid conductivity dominates overall bulk resistivity. Therefore, ERI and other electrical methods are very effective in delineating ionic groundwater contamination and determining the depth to salt water. Various geological layers and features; e.g., clay confining units, fractures or sinkholes that control the groundwater flow can also be characterized. Depth of investigation is controlled by transect length in that maximum depth of investigation is typically 20 to 25 percent of the total transect length. Where site conditions allow, depths of 250 to 350 feet are usually achieved.\nThe EM method measures the bulk conductivity of the earth materials to a particular depth range. By varying the instrument configuration different depths of evaluation can be obtained. Depths of evaluation range from approximately 10 to 200 feet. EM data is usually collected along series of transects with data values being collected at set station intervals. Data collection can be integrated with a differentially corrected GPS to allow for a very rapid assessment of site conditions.\nTime Domain Electromagnetics (TDEM)\nVertical profiles of electrical resistivity can be readily obtained using TDEM. The TDEM method is superior to older resistivity methods, especially when depths of greater than 100 ft are required. The TDEM method develops resistance values at discrete depths. These resistivity values are then modeled to provide to provide a layered solution that describes the distribution of major geo-electrical layers with depth. By varying receiver frequency and transmitter loop size, depths from 30-40 feet to 2,000-2,500 ft can be obtained. The TDEM method can be used to both map hydrogeologic layers and determine the depth to salt water\nBorehole logging provides precise hydrogeological data collected from inside of the borehole. Physical earth properties such as bulk resistivity, conductivity and gamma radiation can be readily obtained. Stratigraphic contacts, fractures and voids are measured using borehole calipers and imaged using acoustical and optical televiewers. This combined information can be used to establish a very high-resolution view of the hydrogeological matrix. Fluid resistivity and in-flow/out-flow contributions from fractures can also be measured to better understand water quality and flow patterns with the aquifer system.\nDye Trace Studies\nProperly implemented dye trace studies can provide information regarding groundwater flow and discharge patterns within karst aquifer systems. Such information can yield an understanding of the karst conduit system and allow for a calculation actual flow velocities.']"	['<urn:uuid:83f079ab-b836-4e33-a9ab-8edbe1362828>', '<urn:uuid:40f908a0-758d-4040-96f3-c5ad5eb042f2>']	open-ended	direct	verbose-and-natural	distant-from-document	comparison	novice	2025-05-01T23:21:14.341336	27	75	2672
255	As someone studying feminist methodologies and bioethics, I'm curious about how empirical bioethics and feminist approaches to social sciences have evolved - can you explain their relationship?	Empirical bioethics and feminist approaches to the social sciences have developed with and out of each other over the last few decades. They can work together to develop important theoretical insights on patient decision-making, as demonstrated in work on women with cancer making fertility preservation decisions.	['RHEA presents its yearly interuniversity gender research seminar: Feminist methodologies\nThe Interuniversity Gender Research Seminar is a yearly interdisciplinary course, jointly organized by VUB, UGent and UA. The Gender Research seminar offers PhD-students advanced training by renowned experts in research methods and topical issues in the field of gender and diversity studies. The focus of this year is Feminist Methodologies. Participation is free but registration required. The lectures are open for a broad public; the masterclasses are only for PhD-researchers. This year the even will take place online.\nINFO & REGISTRATIE VIA RHEA\nEMPIRICAL BIOETHICS AND FEMINISM: TWO SIDES OF THE SAME COIN – LECTURE BY ALEXIS PATON, CHAIR: MICHIEL DE PROOST\n9 NOVEMBER 2020 – 10:00-11:30\nEmpirical bioethics and feminist approaches to the social sciences have developed with and out of each other over the last few decades. In this lecture, Alexis Paton reflects on the uses of empirical data and ethical theory in feminist theory & activism. She will discuss the development of empirical bioethics alongside feminist methodologies and theories. Using examples from her own empirical work on women with cancer making fertility preservation decisions, it is showed how these two approaches to bioethics work can come together to develop important theoretical insights on patient decision-making.\nPrior to joining Aston in April 2020, Dr. Alexis Paton was a Lecturer in Social Sciences Applied to Health at the University of Leicester. She also held positions as a Research Fellow at the University of Birmingham, as a Postdoctoral Researcher at Newcastle University, as a lecturer for Yale University’s Summer Institute in Bioethics, and as a research assistant at the University of British Columbia. Her research focuses on how sociological theory and qualitative research methods can be combined with bioethical frameworks to improve healthcare services.\nThe talk engages with the formative concepts of diversity and intersectionality as a ‘corrective’ methodology, inquiring how far they are epistemic and political tools for achieving gender justice that open up spaces for marginalized constituencies, including racial and religious minorities, queers, and women* and how they unwittingly reify the hegemony of an entitled majority by failing to realize the emancipatory possibilities promised by discourses of diversity and intersectionality.\nNikita Dhawan is Professor of Political Science and Gender Studies at the University of Gießen, Germany. She has several publications including »Impossible Speech: On the Politics of Silence and Violence’ (2007) and ‘Decolonizing Enlightenment: Transnational Justice, Human Rights and Democracy in a Postcolonial World’ (ed., 2014). She received the Käthe Leichter Award in 2007 for outstanding achievements in the pursuit of women’s and gender studies and in support of the women’s movement and the achievement of gender equality.\n10 NOVEMBER 2020 – 10:00-11:30\nProf. Nicole Westmarland is the Director of the Durham Centre for Research into Violence and Abuse (CRiVA). Her research consists of around thirty research and consultancy projects in the field of male violence against women. She is particularly known for her work on rape, domestic violence and prostitution which has underpinned a number of policy changes and which she has spoken about all over the world.\n9 NOVEMBER 2020 – 13:00-15:00\nMASTERCLASS BY NICOLE WESTMARLAND\n10 NOVEMBER 2020 – 13:00-15:00\nMASTERCLASS BY NIKITA DHAWAN\n10 NOVEMBER 2020 – 16:00-18:00']	['<urn:uuid:118376e4-2f5c-4029-9d32-8ed3ab0b1256>']	factoid	with-premise	verbose-and-natural	similar-to-document	single-doc	expert	2025-05-01T23:21:14.341336	27	46	534
258	log burner or heat pump which more efficient	Heat pumps are more efficient than log burners. While log burners can have low running costs if you have access to free fuel, they require professional installation and a carbon monoxide alarm. Heat pumps, on the other hand, have AFUE ratings over 96% and are more efficient than any other heating method since they don't generate heat but transfer existing heat energy. They can also cool spaces and can be installed in individual rooms for targeted temperature control.	"[""Stay warm and snug in your shed this autumn and winter, by taking a look at our guide to heating your garden building. Here we detail all the best heat sources for sheds, including underfloor heating, wood burners, halogen heaters, and more. The headlines, though, are right here:\n- • Insulate the floor, ceiling and walls with foam boards\n- • Use electric radiators\n- • Use electric fan heaters\n- • Use a halogen heater\n- • Underfloor heating\n- • Solar-powered heaters\n- • Professionally installed log burner\nYou can insulate the floor with foam insulation boards. Rockwool or fibreglass rolls in the walls and ceiling are ideal ways to stop your precious warmth escaping. Rugs and curtains will also help to contain your cosiness.\nThe right heating solution depends on the size of your building, level of insulation, power sources, and of course your budget. Also bear in mind the overall style of your outdoor room: is there a particular ‘look’ or ambience you want to create? Once you’ve worked out your needs and priorities you can then turn your attention to the heaters themselves.\nWe’ve found six of the most popular and practical heating options around. Which one’s best for you?\nElectric radiators are either water-filled and wall mounted, or oil-filled and free standing. Both types are simple to operate and have fairly low running costs. Portable units require no installation at all and can be used wherever you need warmth, right out of the box.\nAvailable in contemporary and classic styles, radiators are a safe choice for dusty workshops and log cabins. If you opt for a model with a 24-hour timer and thermostat, you’ll always be assured a warm welcome when you enter your garden building!\nThey do give localised heat, though, so won't warm a large shed on their own.\nElectric fan heaters\nFan heaters are easy to use, and provide instant heat. Just plug in, turn on, and away you blow! They’re energy-hungry, though, so to keep running costs down it’s best not to use them for hours on end. But they’re perfect for quickly heating smaller spaces, and are highly recommended for workshops. They circulate heat, so they don’t just warm you, they warm the whole space - and everything in it!\nThere's a wide variety in sizes and styles, so if you opt for a fan heater, there’s bound to be something to suit your needs.\nPortable halogen heaters are powered by electricity but use halogen elements instead of traditional electrical coils to provide heat. They cost a little more to buy than some of their electric counterparts but are durable, highly energy efficient and cheaper to run.\nThe latest models come with a number of safety devices as standard – including anti-fall security features – so they can be used with confidence in a workshop where you’re moving around a lot.\nUnderfloor heating is ideal if you don’t have much floor space. Water-based or electric systems are available, the electric system is usually the most suitable for an outdoor building.\nInstallation costs are higher than free standing heating units, but underfloor heating gives an even heat to an entire room rather than just a localised spot.\nBut be aware, if you need to do any maintenance work on this kind of heating, you may need to take up your whole floor.\nSolar powered heaters\nIf you don’t have mains electricity in your garden building, why not use free solar energy instead? Solar panels on the roof can be used to warm water, which can then heat a small radiator. It's as economic and environmentally-friendly as you can get, and safe to use.\nAlternatively, you can use solar energy to provide your building with electricity, and use that to power one of the other solutions we’ve looked at. Check out our guide to powering your shed off-grid for more information on this.\nLog burners are a stylish addition to any timber cabin or year-round summerhouse. While they can be pricey to set up, running costs are low - especially if you live near a ready supply of free fuel! Make sure you use a HETAS professional to ensure the burner is installed correctly. A carbon monoxide alarm is also a must when you have a log burner.\nAnd remember to restock that woodpile so you’re never left out in the cold!\nA log burner can provide beautiful ambient lighting, too. But if you’re heating a workspace, be careful not to let those flames distract you from your work!\nThere’s a wide range of heating solutions out there to suit all garden buildings, pockets, tastes and requirements. Always follow the safety advice for any product you use. With the right heater, you’ll be able to make the most of your outdoor den, hobby room or private studio whatever the season.\nHow are you heating your garden building this winter? Log burner, radiator, or something even more imaginative? Share your pictures and tips with us on Facebook – we’d love to hear from you.\nLead image: SAPhotog"", 'How Efficient Are Heat Pumps?\n“Energy efficiency” refers to the amount of energy a device needs to perform a certain task. With regards to heating, a more efficient system requires less power to generate usable heat energy. There are plenty of reasons to opt for a more energy-efficient HVAC system, with the cost-benefit being the most obvious. The more efficient your furnace or air conditioner is, the lower your overall energy costs will be.\nOne of the most popular new technologies for heating the home is the heat pump. How do these newfangled systems measure up, though? How efficient are heat pumps? Is it worth installing one in your home? And if you do decide to install one, where do you begin?\nHow Is Energy Efficiency Measured?\nThe second law of thermodynamics states that you can never get more energy from a system than you put into it. Simply put, the laws of physics being what they are means that some energy is always lost when you are creating heat, or using energy to do anything else for that matter.\nA more efficient system just means that less of this energy is lost. Modern technologies are usually significantly more efficient than older ones. We simply have to look at a modern LED light bulb versus an old-school incandescent one, for example. The efficiency is measured in the amount of useful light energy the light bulb can generate for every watt of electricity that is introduced into it.\nAn incandescent bulb creates about 10 to 17 lumens (a measurement of light energy) per watt. A modern LED bulb, on the other hand, generates about 90 to 112 lumens per watt! So while neither light bulb is able to effectively use all of the electricity that’s put into them, one bulb emerges as the clear winner in the energy efficiency competition by utilizing a lot more electricity effectively.\nWhen it comes to heaters, they operate much the same way: power is put in, and heat energy comes out. With a furnace, heat energy is measured by what’s known as the AFUE standard: this stands for the annual fuel utilization efficiency. It calculates the percentage of power that can be transformed into usable heat energy.\nHow Can I Tell If My Heater Is Energy Efficient?\nBecause it helps to reduce the carbon footprint of a home, the federal government, as well as most local governments, have worked to incentivize the use of more energy-efficient heating technology. This often means that it’s actually illegal to purchase a new heater with an AFUE rating of less than 80 percent, although you shouldn’t have too much trouble getting a heater that’s a lot more efficient than that.\nThe best way to ensure you have an efficient heater is to look for the Energy Star rating. This is a logo placed on certain technologies by the US Environmental Protection Agency to indicate that they are highly efficient. Particularly efficient heating methods can often have an AFUE rating of as high as 98 percent.\nHow Are Homes Usually Heated?\nA traditional furnace generates heat through the burning of some sort of fuel source. Among the most popular fuels in use today are propane, natural gas, oil, coal, and wood. Electricity can also be used directly to generate heat using a method called resistance heating. As you might expect, each of these methods of generating heat energy is vastly different from each other, especially with regard to efficiency.\nFor example, generating heat energy using electricity is considered to be extremely inefficient. Because electricity is used directly to generate heat, it takes a lot of power to get a home to a comfortable temperature. Electric heating has other benefits, such as a reduced fire hazard due to the lack of a combustible fuel source, but energy efficiency is decidedly not one of them.\nMore efficient methods of heating the home include propane, which burns extremely hot and so can get a house to the desired temperature with decidedly less fuel, and natural gas, which has similar properties. Wood and coal furnaces are considered to be less efficient and more expensive to operate.\nWhat Is A Heat Pump?\nA heat pump differs from traditional furnaces because, unlike them, it does not utilize a fuel source at all. While it is powered by electricity, it just uses this electricity to run its systems, not to generate the heat itself. Therefore, it requires less electricity to operate than a resistance heater.\nSo, if it’s not burning fuel to generate heat, where is the heat energy coming from? With a heat pump, the answer is in the name: it’s not generating heat at all but simply utilizing refrigerator coils to pump heat from place to place. Simply put, a heat pump transfers heat energy that is already present in the environment into the home.\nWhile a heat pump is considered the latest in cutting-edge home heating technology, its foundation is actually a very old invention. The modern-day refrigerator coil has been in use for well over a hundred years. By circumventing the need to generate heat, a heat pump also avoids having other large systems such as fans in the home as well, simply venting the energy to where it’s needed. Heat pumps can also be installed in individual rooms, eliminating the common problem that most furnaces have of wasting a lot of heat energy in rooms that are not currently occupied by anyone.\nSo how efficient are heat pumps? Well, their AFUE rating is often well over 96 percent, but the fact that they can be used to target individual rooms means that their actual efficiency is essentially greater than any other heating method you can buy. And the best part? Their ability to transfer heat energy from place to place means that you can use them to get unwanted heat out of the home too: they double as air conditioners.\nWhere Do I Get One?\nIf you’re interested in having a heat pump installed in your home, you’ll need to contact an HVAC professional who is experienced with them. In the Pacific Northwest, this means Entek. We have over 75 years of experience installing the latest in HVAC technology. Our certified, experienced contractors can help you to get your home set up with the latest and most energy-efficient heating technology.']"	['<urn:uuid:09555172-f9fa-4ef9-ad41-ffa68a7c2880>', '<urn:uuid:af50e18e-e0c6-4456-895c-a04384f1ac30>']	open-ended	with-premise	short-search-query	similar-to-document	comparison	novice	2025-05-01T23:21:14.341336	8	78	1903
259	cryptocurrency key seed generation security audits implementation requirements	Cryptocurrency key and seed generation involves multiple security requirements across investigation and compliance domains. Law enforcement looks for seed phrases of usually 12-33 words that can recover crypto wallets, which may be hidden in books, planners or metal fuses. The CCSS mandates specific security controls for key/seed generation, including operator-created keys, validated creation methodology, and sufficient entropy pools. Additionally, third-party security audits are required to identify potential weaknesses in key generation systems. These audits must be conducted by independent parties to provide fresh viewpoints and objective assessment of security controls.	['Law Enforcement Crypto Red Flags – How To Tell If Your Investigation Is Concerning Cryptocurrencies\nAccording to the US Treasury Department, there has been a steady decline in reported cash seizures by government agencies across the United States since 2013. This could be an indication of an increased A cryptocurrency (or cryptocurrency) is a digital asset that … more Criminal use for cash. The absence of cash seizures for known cash-intensive activities should be an automatic warning sign of the potential use of cryptocurrencies to obfuscate and move funds.\nHowever, the signs of cryptocurrency usage can be easily overlooked by investigators who don’t know what to look for. Investigators should be aware of the following: Signs that may suggest that cryptocurrency is being used to hide criminal funds.\nPhones and Computers:\nCheck phones and computers for cryptocurrency-related applications and bookmarks. These can either be software wallets or cryptocurrency exchanges that they access through their devices. Old, disconnected and apparently non-functioning computers could store the private keys to cryptocurrency wallets. These devices should be rated for:\nnumber 1: Popular crypto apps listed for download from the Apple Appstore\nM.any mobile wallets are compatible for both Android and iOS Devices, including iPads and other tablets. Examples include, but are not limited to:\n- A blockchain – the technology that underlies Bitcoin and other technologies. More wallet\n- Coin base\n- Hold up\n- Atomic wallet\n- Ledger Live\n- LiteWallet (Litecoin only)\n- Metal wages\n- MyMonero (Monero just)\nBitcoin ATM finder\nMobile wallets can be found by searching a person’s applications or the search bar. A search for “crypto” or “Bitcoin is a digital currency (also called cryptocurrency) … more”Can often give away related applications available on a user’s mobile device.\nnetwork Wallets must be accessed using a web browser such as Chrome, Safari or Brave. Web wallets can be hosted or U.Nprovided depending on a of the user Needs and security settings. Web wallets may be found by searching by a person’s open tabs in their browser, Bookmark, Search history, or even saved passwords. Lots of the above-mentioned mobile wallets Likewise have appropriate web wallets.\nDesktop wallets are available as downloadable applications that can be run on a computer instead of a web browser. These wallets can be installed on operating systems such as Mac, Windows and Linux. Below are some of the most popular desktop wallets, such as those used by https://coinswitch.co/news/desktop-wallet.\n- Green addressess\n- MultiBit HD\n- Bitcoin core\n- “Bag litter“Or other random papers should be evaluated for lists of apparently coincidental Words – usually 12th, but something purses can support Seeds Sentences up to 33 words–Thewhen used in the correct order, could be used recover Crypto wallet.\n- Recovery seeds can also hidden in books, planners, and unrelated Remarks, or in sight as clear lists or metal Fuses.\nnumber 2: RecoveredYes Seeds written on a note card (IMage source: https://wiki.trezor.io/User_manual:Filling_out_your_recovery_card)\nnumber 3: Steel Wallet Recover Seed (Picture sSource: https://blog.trezor.io/steel-bundle-trezor-one-cryptosteel-e02cadaeb4dc)\nnumber 4th: Restore seed that was written hidden in a daily planner. (Picture sSource: https://www.justice.gov/usao-or/page/file/1232626/download)\n- Pocket garbage should also be evaluated for Bitcoin ATM receipts. While many BATM receipts say Bitcoin or a “bit” derivative thereof,om bitcoin ATM receipts are Fewer more noticeable than others. In inconspicuous cases, pharsen like “Ledger Balance”” can type yourself up for crypto use.\nnumber 5: EasyBit Bitcoin ATM receipt (Picture sSource: https://coinatmradar.com/blog/using-a-bitcoin-atm-satoshi1-machine-at-vape-dynamiks-in-athens-ga/)\n- 2-factor authentication is common practice to secure user accounts on cryptocurrency exchanges. A look through authenticator apps can reveal Links to certain exchanges.\nnumber 6th: Show Google Authenticator Codes Association with A business that enables customers to buy cryptocurrencies or … more Coin base\nPhotos and Screenshots:\n- Reviewing a suspect’s photos can reveal valuable information, such as: Recreational seeds, certain transactions or wallet and exchange Services used.\nnumber 7th: Figure 7: Screenshots of BTC transactions sent via the BRD app\n- hardware purses can come in all shapes and sizes, and some even look like a simple USB driveso.\nnumber 8th: Hardware wallets in comparison (Picture sSource: https://www.reddit.com/r/Bitcoin/comments/80m8dy/just_a_quick_sizeform_factor_comparison_of_4/)\nList of Widespread Hardware wallets\nThe following list includes common hardware wallets that investigators may come across:\n|Ledger||Blockchain locker||ttps: //www.blockchain.com/lockbox|\n|Ledger||Block stream Nano S||https://store.blockstream.com/product/blockstream-ledger-nano-s/|\n|Move crypto||BitBox02 Bitcoin only edition||https://shiftcrypto.shop/de/produkte/bitbox02-bitcoin-only-edition-4/|\n|Move crypto||BitBox02 Multi-Edition||https://shiftcrypto.shop/de/produkte/bitbox02-multi-edition-2/|\n|Trezor||Gray corazon titanium||https://gray.inc/collections/corazon-wallet|\n|Trezor||Gray Corazon Stealth||https://gray.inc/collections/corazon-wallet|\n|Trezor||Gray corazon gold||https://gray.inc/collections/corazon-wallet|\nThe signs of cryptocurrency usage can be easily overlooked by investigators. Hardware wallets can look inconspicuous USB Sticks and recovery seeds are just random works on one side. The above signs may suggest that cryptocurrency is being used to hide criminal funds – especially when no cash is seized for known cash-intensive activities. Investigators must carefully look for these warning signs when gathering evidence. Blockchain analysis tools like CipherTrace Inspector can then be used to light Check the source of the funds and identify all of the associatesion with dark markets or something else criminal acactivity.', 'Without a doubt, Bitcoin, cryptocurrency, and the blockchain are in the process of revolutionizing the entire landscape of global finance. Experts from major think tanks like the MIT Technology Review are predicting that cryptocurrency growth isn’t expected to slow anytime soon. As the cryptocurrency industry becomes more prevalent in various aspects of our personal and business lives, so is the need for regulatory standards to ensure transactions take place in a safe, secure manner. Which is exactly why the Cryptocurrency Security Standard (CCSS) was developed.\nThe CCSS is a framework formulated by a group of cryptocurrency developers, researchers, and security professionals. It’s a set of best practices that Bitcoin and cryptocurrency investors, professionals, and businesses should adhere to in order to ensure both ease and security of all transactions.\nMore specifically, the CCSS is an attempt to standardize various rules and software best practices used in crypto-related technologies like wallets and bitcoin exchanges. The goal is to keep customer funds secure and protect digital currency information against unauthorized data access, sensitive data loss, and data breaches.\nSo whether you’re investing in cryptocurrencies, use blockchain technology, or operate a business utilizing cryptocurrency or bitcoin transactions, CCSS is a standard that you’ll likely need to be in compliance with. Below is a primer on the key areas that CCSS covers, and what you’ll need to start doing to ensure you’re fully CCSS compliance today and in the near future.\nThe focus of CCSS is towards cryptocurrency security and transparency in handling customer funds, which is essential for growth and adoption of Bitcoin and cryptocurrencies into mainstream business and investing practices. Bitcoin security standards such as CCSS have become even more relevant with recent, high profile cyber breaches of cryptocurrency exchanges like Mt. Gox and Bter. These kinds of security issues have plagued various aspects of the crypto industry, and the creators of CCSS hope that by following these guidelines, the entire ecosystem can benefit from enhanced security.\nCCSS is designed to complement existing information security standards (such as ISO 27001:2013) by introducing guidance for security best practices with respect to cryptocurrencies but is not designed to be a substitute or replacement. Rather, it’s designed to augment existing standards and be implemented by crypto focused cybersecurity professionals. CCSS covers ten aspects of any information system that stores, transacts with, or accepts cryptocurrencies. This can be either hardware or software, and you’ll be scored within three compliance levels depending on how secure each aspect of your systems are.\nMoreover, each of the ten aspects are organized into two seperate domains that serve to structure CCSS, which are Cryptographic Asset Management and Cryptocurrency Operations. Below is a breakdown of each aspect within the two domains, and what you’ll need to focus on to fully comply with CCSS, no matter how your organization uses digital currency.\nCryptographic Asset Management\n1. Key & Seed Generation\nOne of the most important aspects to cryptocurrency from a cybersecurity standpoint is key and seed generation. Seeds are basically a username/password combination that users need to access their cryptocurrency wallets. Therefore, seeds need to be unique and extremely difficult to guess via a brute force hack. If a hacker manages to generate the same 64 character seed as that of a specific user, they may be able to gain access to funds.\nThese seeds are then used to generate keys, which are used to sign transactions and generate public addresses where crypto funds are stored. Like every area of CCSS compliance, certification ranges from Level I to Level III, depending on the sophistication of your cybersecurity measures. To achieve basic compliance, you’ll need to work with your CCSS compliance partner to make sure all of the following areas are addresses in your key & seed generation practices:\n- Operator-created keys and seeds\n- Validation of creation methodology\n- DRBG compliance\n- Sufficient entropy pools\n2. Wallet Creation\nFor those familiar with cryptocurrency, wallets are an integral part of how you conduct business. A wallet is purely digital, and are used to buy, store, and trade various cryptocurrencies from Bitcoin and Litecoin to Ethereum. Therefore, this aspect of CCSS covers the creation of a bitcoin wallet or addresses that are used to send and receive cryptocurrency. Wallets are created using key signing methodologies that can require a single key’s signature, multiple keys’ signatures, or a minimum number of signatures from many keys.\nFurthermore, wallets can be created individually (otherwise referred to as JBOK wallets, or “Just a Bunch Of Keys”) or in a deterministic way that allows a set of addresses or key pairs to be created from a single master seed. Security of wallet creation is derived from the integrity of the wallet in the face of various risks such as a lost, stolen/, or compromised key, and the confidentiality of the wallet that would make it difficult to associate a wallet with a particular user. The following must be taken into account for wallet creation CCSS compliance:\n- Unique address per transaction\n- Multiple keys for signing\n- Redundant key for recovery\n- Deterministic wallets\n- Geographic distribution of keys\n- Organizational distribution of keys\n3. Key Storage\nThe third aspect of CCSS covers how private keys and seeds are being stored while not in use. To best maintain the confidentiality of key and seed data, CCSS mandates they be stored in “as secure a manner as business concerns will allow.” You’ll want to make use of strategies like encryption, secret sharing, and physical locks (if and when appropriate).\nTo maximize the integrity of keys and seeds, you’ll need to create backups that will allow for recovery in the event that primary keys become inaccessible. Care should also be taken to ensure backups are stored with at least as much security as primary keys (if not more). It should also be noted that cryptographic assets that are generated by end-users of a system are not subject to the backup requirements of this section, as enforcing good behavior on end users is practically impossible.\nWhen it comes to meeting the key storage requirements, make sure to cover all of the following:\n- Primary keys are stored encrypted\n- Backup key exists\n- Backup key has environmental protection\n- Backup key is access-controlled\n- Backup key has tamper-evident seal\n- Backup key is encrypted\n4. Key Usage\nClosely related to key storage, the key usage aspect of CCSS ensures that all keys and seeds are used in a secure manner. The goal is to maximize the confidentiality of private keys and ensure the integrity of all cryptocurrency funds. However, this section does not specifically cover the usage of backup keys, which are used only in case the primary key is lost, stolen, damaged, or otherwise inaccessible.\nThere are many risks present when using keys, some of which can lead to significant negative consequences. Loss of funds, malware modification of keys, and unauthorized transactions by outside malicious actors are just a few things that can occur. According to CCSS, full key use compliance should consider all of the following:\n- Key access requires user password & authentication\n- Keys are only used in a trusted environment\n- Operator reference checks\n- Operator ID checks\n- Operator background checks\n- Spends are verified before signing\n- No two keys are used on one device\n- DRBG Compliance\n5. Key Compromise Protocol\nHope for the best, plan for the worse, as the old adage goes. Cryptocurrency security is no exception to the rule, which is why CCSS mandates the existence of a specific protocol that your organization will take in the event keys and/or seeds have been compromised or hacked. Your protocol mus outline actions that will be taken in the event of a breach, depending on whether a private key has been stolen, destroyed, become known, or otherwise compromised. Proper policies and procedures to govern malicious events decrease risks associated with things like lost funds and disclosed trade secrets.\nLack of Key Compromise Protocol (KCP) will actually prevent your organization from reaching the highest Level III certification under CCSS. Examples of when a KCP would be invoked include the identification of tampering of a tamper-evident seal placed on key material, the apparent disappearance of an operator whose closest friends and family cannot identify their whereabouts or the receipt of communication that credibly indicates an operator or key is likely at risk of being hacked. The execution of KCPs must make use of Authenticated Communication Channels to ensure messages are only sent or received by authenticated actors.\nKCP compliance consists of two main portions:\n- Have an Existing KCP\n- Regular KCP Trainings and Rehearsals\n6. Keyholder Access Procedures\nIf keys are the most important pieces of information related to cryptocurrency, then coming in a close second are the individuals who have access to them. That’s why CCS has standards about the policies and procedures surrounding how users are granted (and revoked) access to keys or seeds that store organizational and/or end-user funds.\nYou’ll need to consider the access that your staff has to information systems, and restrict access to information that’s not vital to the performance of their regular duties. Improper onboarding and offboarding also pose risks to key and seed information, so you’ll want to background check all new employees, and immediately revoke access when employees quit or are terminated. Your key access procedure compliance plan under CCSS is as follows:\n- Access Grant and Revoke Procedures Checklist\n- All Requests made via Authenticated Communication Channel\n- Grant and Revoke Audit Trail\n7. Security Audits\nThis aspect covers third-party reviews of security systems, technical controls, and policies that protect any system from all forms of risk. You’ll need to conduct penetration and vulnerability tests to identify potential weaknesses and paths around existing security measures.\nRegardless of the technical skill, knowledge, and experience of personnel who build and maintain your systems, third-person reviews are necessary to identify risks and control deficiencies that were either overlooked or underestimated by your internal staff.\nFor the same reasons that software development companies require third parties to test a product to assess its viability, different people than those who implement a cryptocurrency system should assess its security. Third parties provide a fresh viewpoint, are independent of technical controls and are able to be more objective when assessing your security systems.\nThere’s only one requirement to this CCSS aspect, but it’s a big one: Conduct a Third Party Security Audit.\n8. Data Sanitation\nAt some point in time, you may want (or need) to remove cryptographic keys from digital media or hardware. This could be anything from PC hard drives and USB drives, to smartphones and cloud servers. Hackers are now employing ever more sophisticated digital forensic techniques to recover data which has (ostensibly) been erased or deleted.\nThat’s why CCSS covers the proper sanitization of all digital media upon its removal and/or disposal from your facilities. You’ll need to properly remove all keys from digital media devices, and do your best to eliminate the risk of information leakage from decommissioned devices like servers, hard disk drives, and removable storage devices.\nYour data sanitation procedure (DSP) checklist should contain the following two items:\n- Have an Existing DSP\n- Maintain Audit Trail of all Media Sanitization\n9. Proof of Reserve\nJust like a bank, cryptocurrency exchanges and wallets need to have enough currency in “reserve” to ensure liquidity for all users as they buy, sell, and cash out to various currencies. CCSS requires that cryptocurrency companies be able to show proof of control of all reserve funds held in their systems.\nThis rule is partly due to past cases where cryptocurrency organizations were operating at only a fraction of the reserve funds they claimed to have in reserve. This is a huge risk, as bitcoin exchanges and wallets need to have the ability to cover all funds in the event of a simultaneous withdrawal by all bitcoin users. Proofs of reserve provide assurance to the public that all funds are available at any given time, eliminating risk of fund loss altogether.\nJust make sure to work with your compliance partner to conduct regular Proof of Reserve Audits to reach CCSS compliance.\n10. Audit Logs\nFinally, you need to maintain audit logs of system maintenance that provide a record of all changes to date. In the event of a breach or cybersecurity incident, audit logs can prove extremely valuable in helping investigators understand how the attack occurred, properly diagnose symptoms, and formulate a plan for how to resolve issues and stabilize your systems and service.\nJust make sure to both Apply Audit Logs and ensure there’s a Backup of Audit Logs to reach minimum Level I CCSS compliance.\nSo, whether you’re a crypto investor, business, or exchange, by now you should realize why CCSS exists, the aspects it covers, and steps you can take today towards reaching full compliance and prepare your business to face cyber threats. And don’t forget to consider engaging with a CCSS compliance partner to make your journey that much more efficient and worry-free. For more information on cybersecurity solutions, contact RSI Security today.']	['<urn:uuid:816b9e70-6807-4f11-b832-65663c0fbf92>', '<urn:uuid:9410afbb-95a2-45c9-b62b-71952865392b>']	open-ended	direct	long-search-query	similar-to-document	multi-aspect	expert	2025-05-01T23:21:14.341336	8	90	2998
261	How do timers work differently in SFC versus ladder logic?	In SFC, timing functionality is implemented very simply through the T duration attribute of a step, often eliminating the need to declare separate timers. In ladder logic, timing is handled through specific timer instructions that are part of the PLC's instruction set, alongside other instructions like counters and advanced logic instructions.	"['Sequential Function Chart (SFC) is the IEC 61131 -3 method to program sequential controls.\n- Actions may contain Boolean variables or entire networks,\n- networks are programmed in Ladder Diagram or Function Block Diagram,\n- true action associations from several steps,\n- several concurrent SFC networks in one diagram,\n- textual SFC for ST and IL,\n- online viewing,\n- steps contain X and T attribute variables,\n- actions contain Q and A attribute variables,\n- SFCs can be reset,\n- ""one final execution"" of actions optionally switched off.\nSFC is often regarded the fifth language of the standard, but it is a common element for all other four languages. Because of it\'s powerful features it is worth to mention separately. And SFC is the only IEC 61131 -3 language to program sequential controls.\nUsually Sequential Function Chart is regarded as a graphical programming method. But the standard also defines a textual representation which OATs supports for Structured Text (ST) and Instruction List (IL.)\nOATs supports all 11 action association attributes, including the new P0 and P1 attributes of the IEC 61131 -3 second edition.\naction is activated as long as the step is activated\naction is deactivated regardless of any other activation\nthe action is activated and remains activated when the step is deactivated, usually requires deactivation by an action association with R-attribute (reset) anywhere else\naction is activated for a specified time or until the step is deactivated\nthe action is activated after a specified time has elapsed while the step is still activated\naction is activated for a single execution when the step gets activated and possibly once again when the step is deactivated\n||falling edge pulse\naction is activated for a single execution when the step gets deactivated\n||raising edge pulse\naction is activated for a single execution when the step gets activated\n||stored, time delayed\nthe action is activated after a specified time regardless if the step gets deactivated, usually requires deactivation by an action association with R-attribute (reset) anywhere else\n||time delayed, stored\nthe action is activated after a specified time if the step is still activated, usually requires deactivation by an action association with R-attribute (reset) anywhere else\n||stored, time limited\naction is activated for a specified time regardless if the step gets deactivated\nAdditionally to the IEC 61131 -3 standard it is possible to reset a SFC to it\'s initial condition. There is no way in IEC 61131 -3 to accomplish the same behaviour. Within OATs it is always possible to either continue a SFC or to restart it.\nSFC is by far the easiest way to program time related behaviour. Often, there is no need to declare timers. Just use the T duration attribute of a step.\nOATs also correctly handles multiple action associations for action which have been programmed in ladder diagram or function block diagram. A typical example is starting a control in one of the very first steps of a SFC and stopping it near the end of the SFC. This requires the same action has been attached to two different steps using the S- and the R-attributes for the action associations.\nYou can define if a SFC uses a final execution when a step gets inactive or not for each SFC module.', ""Ladder Logic in Programmable Logic Controllers (PLCs)November 03, 2019 by Stephen St. Michael\nThis article describes the programming language ladder logic used to program PLCs and shows examples of how it functions.\nLadder diagram, better known as ladder logic, is a programming language used to program PLCs (programmable logic controllers). This article will briefly describe what ladder logic is and go over some examples of how it functions.\nProgrammable logic controllers or PLCs are digital computers used to perform control functions, usually for industrial applications. Of the various languages one can use to program a PLC, ladder logic is the only one directly modeled after electromechanical relay systems.\nIt uses long rungs laid out between two vertical bars representing system power. Along the rungs are contacts and coils, modeled after the contacts and coils found on mechanical relays. The contacts act as inputs and often represent switches or push-buttons; the coils behave as outputs such as a light or a motor.\nOutputs don't have to be physical, though, and can represent a single bit in the PLC's memory. This bit can then be used later on in the code as another input. Contacts are placed in series to represent AND logic and in parallel when using OR logic. As with real relays, there are normally open contacts and normally closed contacts.\nAn Example of Ladder Logic\nLet’s take a look at an example of ladder logic programming:\nFigure 1. A simple ladder logic program\nThis ladder logic program is three rungs long. The program is “scanned” or run by the CPU from left to right and top to bottom. The symbols placed throughout the rungs are actually graphical instructions. The names for these instructions are:\n- XIC (Examine If Closed)\n- XIO (Examine If Open)\n- OTE (Output Energize).\nLooking at the first rung, notice the first two inputs I:1/1 and I:1/2. The symbol is an XIC, and the I denotes that this is an input. This instruction represents a physical input found on one of the discrete input cards.\nFigure 2. The first rung represents a physical input found on one of the discrete input cards.\nI:1 means that this input card has been placed in slot 1, directly adjacent to the processor. The /1 indicates the bit of interest. Input cards have more than one channel, and if the instruction specifies /1, the instruction accesses channel 1.\nThe second input represents channel 2 on the same card. An XIC instruction really means true if closed. That is, this instruction will be true if the input device it represents is closed. If an instruction is true it is highlighted in green. The only way for an output to be energized is if a path of true instructions can be traced from the left rail to the right rail. Therefore, the output on rung one will be true because a path of true instructions, I:1/1 and I:1/2, exists. This is effectively an AND operation.\nThe output in this case, B:0/1, is actually an internal bit stored in the PLC's memory. That’s why it’s labeled B instead of O for “output.” These internal bits work great when a certain state or set of inputs needs to be recorded without actually turning on a physical output.\nOn the second rung, we have a third input labeled I:1/3 and our internal bit is now used with an input instruction instead of an output.\nFigure 3. The second rung represents a third input used with an input instruction.\nThese two inputs are placed in parallel and represent an OR condition. O:2/1 is an output instruction that represents channel 1 on a physical discrete output card placed in slot 2. This second rung could be rewritten without the internal bit by replacing B:0/1 with the two inputs from rung one. Thus, output O:2/1 will be true if I:1/3 is true OR if both I:1/1 AND I:1/2 are true. This is the basic structure of all ladder logic programs.\nThe third rung introduces the XIO instruction. An XIO instruction is best described as true if open.\nFigure 4. The third rung introduces the XIO instruction.\nThe XIO will be true only if the input connected to it is open. In the case of internal bits, this instruction is true if the internal bit is off. Therefore, because I:1/1 and I:1/2 are both closed, the XIO instructions representing those inputs are false. The XIO representing I:1/3 is true because the input device it represents is open. Without a path of true instructions from left to right, the output on rung three, O:2/2, is off.\nPLC System Instructions\nThe instructions discussed above are the most fundamental instructions in PLC systems, but they represent a small portion of the entire instruction set. The majority of PLCs include timer, counter, latching, and advanced logic instructions.\nFigure 5 shows a slightly more complicated level-control program written by the author for an Allen-Bradley PLC.\nFigure 5. Level-control program\nFor starters, you might notice the input I:1/0. Confusingly, Allen-Bradley names the first channel on any card channel 0. This is similar to the way array indices start at zero.\nThis program uses two level switches, attached to a tank, to activate two pumps that must begin operation one after the other rather than simultaneously. Notice the same two XIC inputs control both pump A and B. However, an internal bit is used with an XIC to control pump A and with an XIO to control pump B. If rung 0000 is true, pump A gets latched using a latch instruction.\nIf rung 0001 is true, pump B gets latched. Once a latch instruction goes true, the output remains on until a complementary unlatch instruction is activated. The last rung controls the pump toggle, using a one-shot and an XOR instruction.\nThe one-shot, when activated, stays true for a single program scan, while the XOR behaves as usual. This is an easy way to toggle a bit with a single input.\nThe instructions used here are still only a fraction of what's available. Ladder logic can be used to build state machines, manipulate analog values, and even perform PID control.\nFor a more in-depth look at ladder logic, check out chapter 6 of volume IV of the AAC textbook, dedicated to ladder logic history, digital logic functions, and ladder logic applications.""]"	['<urn:uuid:5e1de7f2-2168-4e41-8288-960b45254ab7>', '<urn:uuid:2061a57f-e87a-4536-ac62-1149ae10a1c0>']	open-ended	with-premise	concise-and-natural	distant-from-document	comparison	novice	2025-05-01T23:21:14.341336	10	51	1602
263	most important types intellectual property rights need quick overview	There are four types of intellectual property rights (IP): patents, trademarks, copyrights, and trade secrets.	['What are the 4 types of intellectual property?\nThere are four types of intellectual property rights (IP): patents , trademarks , copyrights , and trade secrets .\nIs plagiarism theft of intellectual property?\nMost colleges and universities state that plagiarism is merely an academic offense, but that’s not true. Plagiarism is, in fact, a legal offense that must be taken seriously. Beyond stealing intellectual property , plagiarizing another’s work is fraud.\nWhat is intellectual property copyright?\nCopyright , a form of intellectual property law, protects original works of authorship including literary, dramatic, musical, and artistic works, such as poetry, novels, movies, songs, computer software, and architecture.\nWhat is intellectual property research?\nIntellectual property (IP) is ideas, information and knowledge. In the University context IP can be viewed as the results and outcomes of research – ‘ intellectual ‘ because it is creative output and ‘ property ‘ because it is viewed as a tradable commodity.\nWhat are examples of intellectual property?\nFour Examples of Intellectual Property Trademarks. Trademarks are the names, phrases, and symbols that differentiate your brand from others in your industry. Copyrights. A copyright grants legal rights to anything you create that expresses or embodies an idea. Patents. Trade secrets.\nWhat are the 5 types of intellectual property?\nIntellectual property rights include patents , copyright , industrial design rights, trademarks , plant variety rights, trade dress, geographical indications, and in some jurisdictions trade secrets .\nWhat means intellectual property?\nIntellectual property (IP) refers to creations of the mind, such as inventions; literary and artistic works; designs; and symbols, names and images used in commerce.\nIs copyright a form of intellectual property?\nCopyright is a form of intellectual property that protects the original expression of ideas.\nWhat are some examples of plagiarism?\nHere are some examples of Plagiarism : Turning in someone else’s work as your own. Copying large pieces of text from a source without citing that source. Taking passages from multiple sources, piecing them together, and turning in the work as your own.\nHow is intellectual property copyrighted?\nIn order to register your copyright you must file an application accompanied by the appropriate fee to the Canadian Intellectual Property Office (CIPO), a federal agency responsible for the administration and processing of intellectual property rights in Canada , including the registration of copyrights.\nWhat is an example of copyright?\nThe definition of a copyright is the exclusive right to make copies, sell or market works of art, music and literature. An example of copyright is the protection against selling Madonna’s music as your own.\nWhat Cannot be protected as intellectual property?\nThe short answer is no. Unfortunately, despite what you may have heard from late night television commercials, there is no effective way to protect an idea with any form of intellectual property protection. Copyrights protect expression and creativity, not innovation. Patents protect inventions.\nWhat is the importance of intellectual property?\nWhy is Intellectual Property Important?Why is IPR Important? Intellectual property protection is critical to fostering innovation. Without protection of ideas, businesses and individuals would not reap the full benefits of their inventions and would focus less on research and development.\nIs research data intellectual property?\nData are considered “facts” under U.S. law. They are not copyrightable because they are discovered, not created as original works. However, other intellectual property protections may be utilized to protect your work and ensure proper attribution.\nDo universities own intellectual property?\nAll universities use their intellectual property statutes or policies to assert their rights to own intellectual property that their staff create in pursuance of their duties of employment with one important qualification; they either expressly waive or vest rights in copyright in the staff originator in a variety of']	['<urn:uuid:62287e37-154a-4f20-a771-d66bb2ae3092>']	factoid	with-premise	long-search-query	similar-to-document	single-doc	novice	2025-05-01T23:21:14.341336	9	15	618
264	Which helps value more: getting cards from local shops or comic grading?	Comic book grading through CGC provides more definitive value enhancement than purchasing from local card shops. A CGC-graded comic book has significantly more value than a non-graded version because it's been authenticated by an industry-respected organization, and collectors are willing to pay top dollar for condition-verified books. Additionally, graded comics receive a certification number that documents ownership history. In contrast, while local card shops provide valuable experience and opportunities to examine cards in person, there's no mention of them adding inherent value to sports cards, and the text actually notes that online shopping typically offers both better selection and prices than local shops.	"['Collecting sports cards used to be simple. Every year, a handful of sets made their way to store shelves. Inserts were simple things like stickers or other one-per-pack premiums. Defining and chasing rookie cards wasn\'t a complicated process. Autographs were things you got at the park or arena, not in packs. Jersey were clothes and nothing more. They came with gum.\nYou get the point.\nIf you collect modern cards, you probably also know that days like these are, for the most part, gone. And that\'s not a judgement call. It\'s fact. And while the options available to collectors today are far more numerous, the hobby can also be daunting. Not only to new and returning collectors, but long-time hobbyists as well.\nIt\'s easy to lose your way amidst an ever accumulating stack of monster boxes and cluttered desks. The challenging of getting everything becomes too daunting. For some, there comes a breaking point where it becomes too much and they walk away. But it doesn\'t have to be this way. Unless sports cards are a significant part of your income, collecting should be fun. If it\'s not, something\'s wrong.\nWhether you\'re new to the hobby, a returning collector or a veteran, here are ten easy steps to building a better sports card collection.\n1. Find a Focus\nForget trying to get everything. You can\'t do it. So rather than ripping boxes and cases of every new product and tossing everything aside, find a focus for your sports card collection. Pick a theme or two and run with it. The options are endless and can be catered to your personal tastes. Some choose to build sets while others go after their favorite team. There are player collectors, autograph collectors and rookie card collectors. Many collectors are loyal to a specific brand. Others prospect with visions of future returns. There is no wrong focus.\nAnd don\'t be afraid to change your focus. As new sets come out, you may find you like a particular style of card. Or, you may choose to move on if your favorite player is traded or a set loses its appeal.\nBy getting a focus, you give yourself direction. It gives purpose to your collection. Without one, you\'ll likely find yourself throwing money around at random cards. And with today\'s prices, a lot of money can disappear very quickly.\n2. Set a Budget (and Stick to It)\nNext to finding a focus, setting a budget is probably the most important part of building your collection. It\'s easy to get carried away. Too easy. Deals pop up, rare cards surface, new sets come out -- all these vie for your extra cash. And if you\'re not careful and disciplined, you may find yourself eating more Kraft Dinner than you usually like.\nCards should always come from the money that\'s leftover after all the bills are paid. It sounds like a simple concept, but for many it\'s a tough proposition to keep.\nOnce you\'ve decided how much you\'ve got to spend on cards each month, stick to it. You might even want to create a simple spreadsheet or tally of your expenses.\nLook for ways to make you money go further. By shopping on eBay, you can often set your own price easily and without hassle. You can often negotiate at your local shop, but online auctions are a convenient way to hunt for bargains.\nAnd if some great deals pop up all at once? Pass some of them over. Or sell some of your collection. List on eBay. Set up at a local card show. Look at some other online sites. It has never been easier for collectors to turn their unwanted and extra cards into cash that you can then use to build your collection.\n3. Make a Wantlist\nOnce you\'ve got your focus, compile a list of what you\'re looking for and type it out. Writing it on a napkin works, but there\'s a good chance your 5-year-old will come along and wipe the peanut butter and jelly off his face with it.\nTo take your wantlist a step further, upload it with something like Google Docs or onto Dropbox so it\'s with you anywhere you go. This is very handy when you stumble upon a shop while away on business or you hit up your local show.\nJust remember to update your wantlist as soon as it changes. It\'s easy to forget to cross something off once you\'ve filed it away in a binder or box.\n4. Target the Whale\nWhatever your focus and no matter your budget, there\'s probably something rare and/or pricey that you\'ve always wanted. Right now, it might be out of reach. But that doesn\'t mean you can\'t plan for it. Set aside a little bit of your card budget every month for a ""Whale Fund"" so that the next time one pops up, you\'ll be ready. Even if you\'re on an Opening Day budget, you can still own some Exquisite pieces.\nA big part of the thrill of collecting is the chase. It\'s great to have several inexpensive and easy-to-find pieces in your sites, but landing that cornerstone piece is one of the biggest rushes collectors can have.\n5. Make It a Family Affair\nAnything you can do with your family makes it that much more enjoyable. If the hobby is going to grow and thrive, it needs new collectors. Chances are, if your kids see that you\'re interested in something, they\'re likely to become interested as well. That might mean some compromises. Your daughter may not like baseball, but My Little Pony or Star Wars might be right up her alley. You might pledge your allegiance to the Yankees and your son might think Mr. Met is funny. Still, collecting cards is best shared.\nAnd don\'t think that it\'s just your kids you might want to get involved. You might even want to look for ways of getting your spouse or partner on board. My wife has always tolerated my collecting but she\'s never shown any interest. That was until we opened a box of Game of Thrones together. Like your kids, look for alternate options that might get them interested in busting packs with you.\n6. Try Something New\nYes, I know I said finding a focus was one of the most important things you could do with your collection. But you still need to try new things. That doesn\'t meant break a box of every new product. Rather, try some packs here and there. Trade for some cards from a sport you enjoy, but don\'t usually collect. Bounce back from a depressing episode of The Walking Dead with some cards from the show.\nExpanding your collecting horizons without going wild, can help your collection evolve. You may find you prefer a new brand. Or it may help solidify your current collecting direction.\n7. Get Social\nWhile there may not be as many collectors as there once was, it\'s hardly a ghost town either. Collecting is so much more enjoyable if you have someone to talk about it with. Even if you failed at getting your family on board, there\'s no excuse for not being social with the hobby. Join a forum, get on Twitter, start a blog. If you\'re a sports card hermit, things will get very boring.\nWhen many of my friends stopped collecting, I found a huge community online. Not only did it make collecting easier, it rejuvenated me and got me more excited about collecting than ever.\nWith the expansion of social media, getting connected has never been easier.\n8. Start Trading\nNow that you\'re connected with other collectors, you can leverage those relationships into getting some of the cards you want. By being social, you can also usually find someone who is looking for your extra cards.\nTrading is one of the purest forms of collecting. For many, the evolution of the hobby has taken it back to where it began. There are literally thousands of collectors online who swap cards. Some demand structured deals where every penny of ""book value"" is accounted for. Others are happy to send their friends things they need without any strings attached. Most are somewhere in between.\nNo matter how you trade, it\'s a fun, easy way to clear some clutter and knock things off of your wantlists.\n9. Clear Off Your Desk and Get Organized\nIt\'s depressing when you go to work and you find your desk covered with papers and other clutter. Likewise, it\'s tough to get excited about collecting when you\'re surrounded by stacks and stacks of unorganized cards.\nSo take a Saturday, stock up on supplies, plug in a movie and start getting organized. There is no right or wrong way to do it, just as long as the end result means everything has a place and you\'ve got some piece of mind. That said, a couple of monster boxes and boxes of nine-pocket pages go a long way to getting things stored properly.\nAnd don\'t forget, once you\'re organized, don\'t the the piles creep up on you. It\'ll be the same problem all over again. Take a few minutes every week and make sure everything finds a place.\n10. Find a Local Shop\nFor card collectors, the local hobby shop is, ideally, the place where everybody knows your name. In a perfect world, it\'s a place where you can go talk about the hobby, debate the standings and buy some cards. A dwindling number of quality card stores makes that a lot tougher. But they\'re out there. And it\'s important you find one, even if it means a bit of a drive.\nFor some, this might mean heading to the next town over. That\'s fine. Just don\'t go as often as you might if they were on the block.\nShopping online is easy, convenient and, in most cases, offers both the best selection and prices. But you can\'t put a price tag on the card shop experience. It\'s the perfect way to try out new stuff a little bit at a time, socialize with other collectors and hunt for whales.\nAnd if the closest shop isn\'t any good? Keep on driving until you find one. Get the family together and make a road trip out of it.\nBuilding a better sports card collection is a lot of work. But the underlying theme is making it fun and enjoyable. For most of us, it\'s a hobby. If collecting is causing you stress, step back and look at why. All these ideas are easy and should bring back the fun.\nRelated Topics: How To: General', 'A cornerstone of comic book collecting is the grade that a book is assigned by the CGC, or Certified Guaranty Company. Despite the CGC’s importance to modern collectors, many still don’t understand what it means for a comic book to be graded. By understanding CGC’s process, aspiring collectors will better understand why this grading process is so important.\nBut First, What Is the CGC?\nBased in Sarasota, Florida, the CGC was founded in 2000 and quickly became a global standard for determining a comic book’s physical condition. Prior to CGC, the standard was the Overstreet Guide’s 10 Point Grading Scale, which ranged from a 0.5 (Poor) to 10 (Gem Mint). CGC built upon Overstreet’s grading by developing a more standardized process, and incorporated new elements.\nHow Do You Know if Your Comic Is Worth Sending In for Grading?\nThough you may be tempted to submit every comic book you purchase for CGC Grading, this process must be paid for. The grading fee varies depending on the age and value of the comic, ranging from $22 to $120 for most books. Comics with a fair market value above $3,000 however, are charged on a sliding scale of 3% of the book’s value (minimum $150).\nGiven these costs as well as the costs of shipping, you should only seriously consider submitting a comic book for grading if you already know it’s valuable or if you believe that it will become valuable in the future. A general rule of thumb that many collectors follow is that a book’s expected value needs to be worth about $200 before it makes sense to have the book graded from a financial perspective.\nAlso note that the grading process often takes some time. CGC states that grading can take 106 to 133 days. A fee of $75 can reduce this time to 44 days, and an express fee of $120 can reduce this time to 17 days. Books over $3,000 in value are turned around in an expected 10 days.\nWhat Are the Benefits of Sending Your Comic In for Grading?\nA graded comic book often has significantly more value than a non-graded version, since a graded comic book has been authenticated by an industry respected organization. Additionally, collectors are much more willing to pay top dollar for high conditioned books, if that condition has been verified and quantified by CGC. Finally, with a CGC certification number, a graded comic has a provenance—meaning that this book’s ownership history will now be documented for future owners to appreciate.\nAnother benefit of grading is that your comic will be encapsulated in a crystal clear holder. In addition to the item being better preserved by this shell, the holder helps to guard against counterfeiting and tampering.\nBeyond preservation, the CGC slabs themselves have a positive aesthetic quality that fans and collectors have come to appreciate. These containers make it easier to handle the collectibles and to display them. Instead of keeping a comic book hidden in a box, they can be showcased like the works of art they are. One drawback is that encapsulated books can’t be read.\nWhat Are the CGC Labels?\nEach comic book receives a numerical grade of 0.5 to 10 as well as a designation related to the page quality of the comic. It’s worth noting that for many books (save for the most modern) the highest grade in existence is often a 9.8, with 9.9s and 10s for older books exceedingly rare. In addition to the number grade and page quality designation, each submission will have a color-coded label. There are 12 colors, and out of these, there are 5 major colors: Universal Label (Blue), CGC Signature Series Label (Yellow), Qualified Label (Green), Restored Label (Purple), and Pedigree Label (Gold).\nThe universal blue label is given to comic books that are graded as marked with no qualifiers. It has no autographs, no evidence of restoration, nor anything massively missing.\nThe yellow signature series is for a submission that has a significant person’s autograph, which has been authenticated. While one might assume that signed books are more valuable (and while this is often the case), in certain cases, especially with older comics, unsigned books can sometimes command a higher price.\nThe qualified green label is for any collectible that has a significant defect. The green label communicates that something is substantially wrong with the book despite being graded. This could be a missing page or an un-authenticated signature or missing staples. According to Midtown Comics, the green label allows a damaged book to be graded on a curve; “For example, a book missing staples may receive a blue label grade of 0.5 (POOR grade) but would receive a grade of 6.8 or 7 through the qualified green label.”\nThe purple restored label is for any comic book that has been repaired. In general, restoration significantly harms the value of a comic and some have dubbed this CGC designation as PLOD or “the purple label of death.”\nThe pedigree gold label is applied to any item that is part of a collection CGC recognizes as being of exceptional quality. A pedigree label not only verifies the quality of a book, but highlights the quality of the collection it comes from. As GoCollect.com writes, “a pedigree is an exceptional collection that they are willing to recognize with unique labeling.”\nTo date, there are only 61 pedigree gold collections recognized by CGC. Not only do their pedigree statuses signify quality, this label also increases the value of a book. A pedigree will increase a comic book’s value as a collectible because it adds to the story the item. After all, it is not some random book found in an attic. Instead, it was part of a collection that was preserved for future generations.\nAs ComicBookPedigree.com explains, when it comes to pedigree collections, “all of the owners had one thing in common; they were conscientious about the condition of their comic books. By luck or design, each of the collections featured here survived many tests of time; paper drives, puberty, and especially Mom, who never understood why her child would save such things.”\nHow Are Comics Graded by the CGC?\nWhile one might think that this grading process would be a company secret, CGC is completely transparent about how a comic book’s quality is determined.\n(1) First impressions\nA first impression is typically reserved for finding large problems; such as stains or holes on the cover as well as missing pieces and creases.\n(2) Identify variants or pedigree\nA submission’s pedigree is determined by the collection it comes from. While different organizations have various criteria for pedigree, there are three near-universal standards:\nA)The quality of an overall collection — does it already have high value items?\nB)The collection’s origin — were they collected by the same person/people and stored in a similar space at the same time? This is of value because it signifies that all the items will be in a similar condition; and\nC)The completeness of the collection — is it just a collection of random books or does it contain completed series?\nIn short, two of the same comic books in similar conditions can be worth different amounts if one comes from a trusted and vetted collection.\n(3) Count pages\nSelf explanatory — each page of a book is counted to make sure a submission isn’t missing any.\n(4) Determine page condition\nWhen it comes to specific condition, graders will look for tears, stains, and creases.\nOne major issue in page quality is “foxing.” Foxing is typically a degradation of paper that comes from within the paper as it ages. Foxing is typically found in books that have not been properly protected from the environment.\nAnother source of damage can come from the book’s staples. Staples rust if exposed to moist air and that rust can expand into paper. Staples might also cause tears.\nIn addition to keeping comic books away from moisture and humidity, it’s also important to keep them away from direct sunlight. Sunlight can bleach an image and tone down the vibrancy of a cover’s colors.\nFinally, with so many comic books including posters or other features that encourage readers to cut them out, graders will determine if these extra materials are still present.\nExamples of such materials include advertisements encouraging readers to cut out stamps and coupons to be sent in, or posters to be taken out and put on display. One of the many reasons X-Men #1 sold so many copies was due to variant covers, one of these variants being a cover that functioned as a pull out poster. Similar to Playboy, dozens of different titles were published with centerfold posters in a comic book that were designed to be removed from the book and hung up on walls—doing so would unfortunately significantly harm the value of the specific issue.\nTo make sure that pages or covers weren’t swapped out, graders will also examine a book’s staples to make sure they weren’t opened and closed again.\nA surprising source of a comic book’s imperfections is the poly bag and board that it might be sealed in. For instance, a back cover might stick to the board it is sealed with. This means that a back cover could be damaged due to ink transferring to the board or the page itself becoming damaged from parts of it becoming permanently stuck to the board. Poly bags for comic books are incredibly common because they are affordable. However, they offer less protection than mylar bags. And while mylar bags are more expensive, they offer superior protection from moisture and humidity, insects, mold, and other chemicals.\n(5) Check for restorations\nTo salvage/improve the appearance of a comic book, some collectors will try to restore it. CGC currently identifies 11 types of restorations that can be done on comic books: color touch, piece fill, tear seals, spine split seals, reinforcement, piece reattachment, cleaning, staple replacement or cleaning, re-glossing, glue, and trimming.\nBecause of the complexities surrounding restorations, CGC has a seperate scale to grade restored books. And while it is tempting to want someone to restore books to mint condition in the hopes that their new value will be dramatically higher, restorers can often do more damage than good to a book’s value depending on the specific situation .\nTwo restoration details to keep in mind are the slight differences between restoration and conservation. For instance, CGC defines restoration as “the act of adding foreign material to a comic book through certain techniques to return its appearance to an ideal or original state.” In contrast, “the goal of conservation is to preserve the structural integrity of the comic while removing all things that are detrimental to its longevity.”\nOnce a grader has documented and considered all of a book’s imperfections, they will determine a grade. Similar defects do not always have a similar impact on a book’s final grade. For instance, a crease being severe enough that it breaks the color will have a greater negative impact than a crease that doesn’t break a page’s colors.\n(6) Assess all defects and determine a final grade.\nTo make sure the quality of a book is properly assessed, grading is done by a team and multiple CGC professionals examine every item as a means to guarantee consistency and accuracy. This process of multiple graders concludes once a consensus for a final grade is reached.\nHow Are Comic Books Authenticated by the CGC?\nBefore the intensive work of grading is done, the book is authenticated. With some comic books valued so highly, there are many attempts to pass off fakes as the real things. Stephen Fishler, the CEO and cofounder of Metropolis Collectibles and ComicConnect.com, discusses some of these attempts in Fraud Magazine:\n“We’ve seen two notable attempts to counterfeit modern, or Bronze Age, comic books: Cerebus No. 1 (1977) and Teenage Mutant Ninja Turtles No. 1 (1984). Why did counterfeiters pick them? Both were printed with unusual black-and-white interiors, which the fraudsters assumed would be easier to replicate. After all, 99% of the comics produced in the last 80 years feature full-color interiors,” Fishler said.\n“Regardless, industry professionals quickly spotted the counterfeits,” Fishler continued, “and no one ever profited from them. Case closed.”\nAlternatives to CGC: CBCS and PGX\nWhile CGC is undoubtedly the gold standard in the comic grading industry, there are other players in the space, most notably CBCS which is owned by Beckett Media. CBCS is generally considered a reputable player in the space and some collectors choose to use the company because of its slightly lower fees and often much faster turnaround times. The grading scales used by CBCS are nearly identical to those of CGC; however, it’s worth noting that CGC comics of the same grade generally fetch a slight premium to those graded by CBCS on the resale market.\nPGX is another comic grading company out there; however, many collectors claim that their grading quality is suspect and stay away from either having their books graded by them or buying PGX graded books. For this reason, until something changes reputation wise, you might want to steer clear of PGX grading as an option.\nWith the comic book collector’s market increasing every year, the importance of grading will only grow. And this importance is not a hyperbolic statement. Grading has become so common that CGC and similar companies have needed to hire more people. As Jim McLauchlin wrote for GamesRadar.com, “Collectibles markets are surging, and as old comics get more expensive, collectors and dealers turn to third-party services to ensure authenticity and grade. The phenomenon has led to an odd crimp in the labor market – grading services and high-end auction houses are desperate to hire graders, even paying cash bonuses to get people in the door.”\nAs it becomes more common for comic books to get graded, it is important for collectors, fans, and others interested in comic books to understand what it means to purchase a CGC (or CBCS) graded collectible.']"	['<urn:uuid:ddbca7a4-ffbd-4120-9073-080ef16e921e>', '<urn:uuid:67b3d9cd-b743-4124-b590-c2b2ff2da349>']	open-ended	with-premise	concise-and-natural	distant-from-document	comparison	novice	2025-05-01T23:21:14.341336	12	103	4112
265	What breakthrough features does the HX90N tooling prepreg material offer in terms of surface quality and thermal properties?	HX90N provides exceptionally low thermal expansion (60-70% lower than comparable materials), delivers a flawless surface finish off aluminum or epoxy patterns, and offers high end-use temperatures. It improves surface flatness, creates pinhole-free surface finish, and extends tool life due to greater resistance to surface pitting.	"[""Using composite materials is hardly a new phenomenon. A trip to the British Museum will show you that the Ancient Egyptians constructed their tombs using bricks made from a primitive, yet effective, mix of straw and mud.\nToday the moulds used for forming composites, also known as tools, can be made from virtually any material. For parts cured at low temperature or for prototyping where tight control of dimensional accuracy isn't required, materials such as fibreglass, high-density foams, machineable epoxy boards or even clay or wood models are often suitable.\nFor parts cured at higher temperature, or if high dimensional accuracy is required, or if the mould is expected to be used for high-volume part production, then higher-performance tools must be used. Materials for these tools include Invar (a nickel steel alloy), steel, aluminium, nickel, and carbon fibre.\nSelection of the tooling material is typically based on the coefficient of thermal expansion (CTE), expected number of cycles, end item tolerance, desired surface condition, method of cure, glass transition temperature of the material being moulded, moulding method, the available curing equipment, and cost.\nSteel and aluminium had traditionally been the materials of choice for high-performance tooling, but they can have major drawbacks when used to make composite parts. During autoclave cure, the CTE mismatch between the tool and the part is often too extreme for compatibility. Higher-priced metal alloys, such as Invar, can offer closer CTE matches but the high cost of machining and, for larger parts, the sheer size and weight of the tools makes them difficult to machine, move and store.\nA new direction\nComposite tooling, made of similar material to the final part, can offer a high-performance result without the high costs of metal. Once an art known only to a few dedicated aerospace and Formula 1 (F1) technicians, composite tooling is now widely in use, from weekend club race car builders to aerospace industry leaders like Boeing and Airbus. After decades of development and refinement, composite toolmaking has become less of an art and more of an easily repeatable, high quality process with predictable results.\n“The use of industrial composites has been under development for over 50 years,” explains Jed Illsley, European Sales Manager for Amber Composites. “First, wet lay-up methods were used with resin and dry fabric — but obviously this wasn't an accurate method of controlling the amount of resin or the impregnation of resin in the fabric. By pre-impregnating the fabric with resin, under carefully controlled conditions with precision machinery, a material is created with known and repeatable engineering characteristics. This is the prepreg we are familiar with today. More recently tooling prepreg has become the standard method for producing precision composite moulds by employing the same proven principles.”\nBy slowly improving the characteristics of the material — including the handleability, the life at ambient temperature, the right amount of tack (stickiness) — the tooling route is now becoming easier and more cost effective. A new generation of composites are being used in an increasing number of efficiently engineered applications.\nA small team of experts founded Amber Composites in the UK in 1988 to develop and manufacture high performance composite prepreg. Prepreg technology was still in its infancy then and the early team was involved in developing some of its first commercial applications. From its corporate headquarters in Nottinghamshire (the setting for the revolution in industrial textiles and a logical place for the birth of the carbon fibre industry), Amber worked closely with F1 racing teams and a number of other high performance engineers. This demanding customer segment drove the development of the tooling materials that are available today. Today, Amber serves a wide variety of industries worldwide including aerospace, automotive, marine, and communications.\nA rough guide to moulding\nVacuum bag moulding\nA process using a single side mould set that shapes the outside surface of the panel. On the lower side is a rigid mould and on the upper side is a flexible membrane or vacuum bag. The flexible membrane can be a reusable silicone material or an extruded polymer film. Then, vacuum is applied to the mould. This process can be performed at either ambient or elevated temperature with ambient atmospheric pressure acting upon the vacuum bag.\nA process using a single-sided mould set that forms the outer surface of the panel. On the lower side is a rigid mould and on the upper side is a flexible membrane made from silicone or an extruded polymer film such as nylon. Reinforcement materials can be placed manually or robotically. They include continuous fibre forms fashioned into textile constructions. Most often, they are pre-impregnated with the resin in the form of prepreg fabrics or unidirectional tapes. In some instances, a resin film is placed upon the mould and dry reinforcement is placed above. The membrane is installed and vacuum is applied. The assembly is placed into an autoclave pressure vessel. This process is generally performed at both elevated pressure and elevated temperature. The use of elevated pressure facilitates a high fibre volume fraction and low void content for maximum structural efficiency.\nResin transfer moulding (RTM)\nA process using a two-sided mould set that forms both surfaces of the panel. The lower side is a rigid mould. The upper side can be a rigid or flexible mould. Flexible moulds can be made from composite materials, silicone or extruded polymer films such as nylon. The two sides fit together to produce a mold cavity. The distinguishing feature of resin transfer moulding is that the reinforcement materials are placed into this cavity and the mould set is closed prior to the introduction of matrix material. Resin transfer moulding includes numerous varieties which differ in the mechanics of how the resin is introduced to the reinforcement in the mould cavity.\nOther types of moulding include press moulding, transfer moulding, pultrusion moulding, filament winding, casting, centrifugal casting and continuous casting. There are also forming capabilities including CNC filament winding, vacuum infusion, wet lay-up, compression moulding, and thermoplastic moulding.\nLow-temperature-cure epoxy tooling prepregs, such as HX50 and HX70 from Amber Composites or LTM series from Advanced Composite Group, have now become benchmark products in aerospace, automotive, marine, industrial and motorsport applications. With their reliability long-proven, steady improvement has resulted in materials that are easy to handle and apply, provide Class-A surface finish, and offer surprising longevity of tool life. Some systems now enable 200°C end use temperatures, and recent advancements in materials have enabled composite tools to be compatible with an ever wider variety of processing methods.\nIllsey points to the example of F1 car builders and America's Cup boat builders.\n“F1 teams need a large number of small, complicated parts. Yacht builders may need a single 30 m long part. Both require extremely precise dimensions. You can find both using a similar HX tooling system with great results.”\nToday's high-performance contemporary yacht moulds are frequently made using tooling prepreg, as are the moulds in military and unmanned aerospace applications. Even in the commercial aerospace industry, after a long development cycle, composites are now widely used. Entire wing sections on the new Airbus A350, for instance, will be made from carbon fibre, and a considerable proportion of the tooling will utilise composite prepreg. The new Boeing 787 Dreamliner is composed of over 50% composites and some very large production tools are made of composite tooling prepreg.\nMore recently, companies are also able to consider developing very low cost composite tooling through the development of prepreg that can be processed without the need for autoclave pressure and without increasing resin volume. These are commonly known as out of autoclave (OOA) products. This technique is helpful when making large parts and when the integrity of the pattern/master cannot withstand the pressure of an autoclave.\nBenefits of composite tooling\nCompared with traditional metal tooling, composite tooling can provide a lower cost of production and easier handling and storage. For performance parts requiring accurate dimensions, composite tooling offers a CTE closer to the part CTE, helping the part maintain dimensional integrity during cure.\nCompared with a few years ago, composite tooling is more widely available, more user-friendly, and more efficient to process. Prepreg is now available with excellent drapeability enabling accurate reproduction of small radii corners, a wide range of tackiness, a wide range of curing temperatures, and a wide range of dimensions.\n“A great example application was the recent development of the ALMA telescopes to be placed in Chile”, says Illsley. “The telescope is comprised of a set of segments, each of which have to be identical and precise. In order to meet these exacting accuracy requirements, they used our HX50 tooling prepreg. And, to address the outlife challenges faced when working with such a large tool, we supplied the tooling prepreg in pre-cut squares.”\nAnother reason composite tooling is gaining popularity is the availability of a proven package solution. Customers can buy a complete set of materials including tooling paste or blocks, adhesive, release agent, primer, sealer, tooling prepreg and component prepreg — all from a single source and all proven to work together seamlessly. Axson Technologies is a full-service supplier that has seen rapid growth from its complete solution packages.\nAmber tooling prepreg\nMultipreg HX42: An epoxy resin system that can be pre-impregnated into high performance fibres such as carbon, and glass. It is an exceptional and very well-proven system in aerospace applications that exhibits a high end-use temperature and extended outlife. After a suitable post-cure an end-use temperature of 190°C (374°F) is achieved\nMultipreg HX50: Like HX42, HX50 is a volatile-free epoxy resin system that can be pre-impregnated into a wide range of high performance fibres. It allows fast and low-temperature curing and exhibits excellent handleability. After a suitable post-cure an end-use temperature of 180°C (356°F) is achieved.\nMultipreg HX70: An epoxy resin system that can be pre-impregnated into high performance fibres such as carbon and glass. It is a highly reactive system that offers shortened cure cycles and low temperature cures. After a suitable post-cure an end-use temperature of 180°C (356°F) is achieved.\nMultipreg HX90N: HX90N is a nano-modified epoxy resin system which improves the surface flatness and finish of tools. After a suitable post-cure an end use temperature of 180°C (356°F) is achieved.\n“We recently supplied a shipyard in Germany during production of an Admiral's Cup racing yacht. A complete package of tooling materials including SC175 epoxy paste, EC85 Surface Coat, HX50 tooling prepreg and EG42 Gelcoat enabled them to decrease the time and cost of delivering a precision yacht — with excellent results,” says Axson Technologies' CEO Lionel Puget.\nPaste has played an important role in such progress, particularly for large moulds. With paste, a relatively low-cost CNC milling machine can rough-cut an inexpensive low-density pattern, then place a layer of epoxy or polyurethane paste over the pattern, and once the paste is cured, machine the paste to the desired dimensions creating a low-cost pattern for the tool. Tooling prepreg is then placed over the precisely cut paste to create the tool.\nThis method of toolmaking has substantially cut the time and cost of building large precision parts which would have previously been made using a highly skilled and time consuming wooden construction.\nNew developments such as HX90N tooling prepreg have been designed to handle special requirements for low temperature curing while providing excellent surface finish. HX90N provides a unique combination of exceptionally low thermal expansion (60-70% lower than comparable materials) with a flawless surface finish off aluminium or epoxy patterns and high end-use temperatures.\nThe exceptional properties of HX90N make this material ideally suited to demanding tooling prepreg applications. It is already helping toolmakers meet increasingly severe and diverse application requirements across the aerospace, automotive and mass transit industries.\nWhat all this means is that both small and large composite structures are now faster, cheaper and more accurate than ever to create, allowing designers to utilise the benefits of composite materials in an ever increasing range of high performance engineering applications.\nThe HX90N breakthrough\nAmber Composites' new low-temperature-cure HX90N tooling prepreg features a specially designed nano-modified epoxy resin to provide benefits that Amber believes were previously unattainable. HX90N provides a unique combination of exceptionally low thermal expansion (60-70% lower than comparable materials) with a flawless surface finish off aluminium or epoxy patterns and high end-use temperatures.\nHX90N improves the surface flatness and finish of tools made from various pattern materials, including aluminium and epoxy tooling board. By providing moulds with a flatter and pinhole-free surface finish, the product reduces both the preparation time necessary to achieve Class A surfaces and the quantity of primer needed, which decreases the weight of the finished product.\nTool life is extended due to the material's greater resistance to surface pitting. The material also offers good drapability, allowing complex mould shapes to be more easily formed.""]"	['<urn:uuid:e74049d2-dc01-4ad2-9602-dbae1939ffbc>']	factoid	direct	verbose-and-natural	similar-to-document	single-doc	expert	2025-05-01T23:21:14.341336	18	45	2135
268	smart city art citizen engagement examples	Art in smart cities can engage citizens through various interfaces, such as experimental installations that test the impact of electronic lighting on urban space, or interactive artworks that promote public agency. For instance, projects like AirDraft in London's canals create alternative spatial experiences that interrupt the usual pace of city life, while art installations can help articulate new public domains that connect physical urban spaces with electronic networks, facilitating democratic forms of engagement.	['AirDraft, pneumatic architecture\nIn London the AirDraft project designed by Thomas Randall-Page and Benedetta Rogers for the Architecture Foundation is an inflatable structure for hosting performances on the water\nAirDraft by Thomas Randall-Page and Benedetta Rogers is the winning pavilion of the third edition of Antepavilion, an architecture competition that aims to try out new ways of living in the city, sponsored by the property developer Shiva Ltd and organised by the Architecture Foundation of London.\nWith this latest project the role of the institution (directed by Ellis Woodman with the fundamental support of Phineas Harper) as a cultural agitator is further strengthened. To the busy programme of public activities – always full of conferences and screenings – and publications is added proof of its full capacity to produce real architecture. It doesn’t appear accidental that Aid Draft, selected from over 130 proposals, embodies the same spirit as the foundation, which occupies an office at the Barbican Centre, but which for the various events it organises migrates from one point of the metropolis to another. AirDraft is a temporary theatre that rests on a converted 19th-century barge, contained in an inflatable double membrane that expands and contracts to host shows and concerts. The competition brief asked the architects to imagine a project that would showcase the historical memory of the Regent’s Canal, one of the city’s numerous waterways.\nConceived and built with the support of a specialised company (Cameron Balloons) and a group of volunteers, AirDraft is a real piece of pneumatic architecture. Inflatable structures are normally found in two states, either completely deflated or inflated to their full potential. AirDraft on the other hand, by adjusting the pressure of the two membranes that make it up, inflates and retracts in a variable manner. The pavilion looks like a living organism, which lets out air to pass under the arch of a bridge and then fills its lungs to welcome the public and artists aboard.\nThis bizarre hybrid between a boat and a dirigible, which in the words of the architects is a tribute to the counterculture of the Sixties and Seventies, in particular to the artist Jeffrey Shaw and the American collective Ant Farm (currently at the centre of renewed international interest), began sailing in August 2018. Docking near the many pubs, universities, art centres, galleries and concert halls that overlook the canals, it reveals another, less well-known, watery London, where thousands of inhabitants get around and live. AirDraft looks like a large orange balloon that appears suddenly like a mirage on the muddy waters of the canals and hides a soft and sinuous interior where passengers can let themselves be lulled by an environment saturated with rather unusual sensory stimuli. The uniform colour that occupies the whole visual field, the impossibility of remaining standing, a see-through strip that directs the gaze only towards the water and the banks, the intimacy of being gathered together in the belly of a small dirigible all interrupt the often past pace of everyday life in the big city and prove that there is, in fact, another way to live.', 'How may art, as autonomous manifestation and a domain intimately related to human experience, take part in the technological development of cities today?\nThe Screen City Biennial developed out of curiosity and attention to the meeting between expanded moving image art and the urban domain. While the urban context is undergoing profound transformations with the implementation of ‘intelligent’ technologies, furthered by political visions of a technologically optimized near-future reality, new queries arise that exceed dusty goals of the avant-garde of how art can act as necessary counter-element in the power structures of urban space. This article takes a look at the contemporary, technological context, considering potential current roles for media art in the urban domain of the intelligent city.\nIntelligent Cities – New Urban Contexts for Art\nWhen we point at the biggest current factors of change in the world’s cities, these not only concern expanding high-rises, urban mobility and other symptoms relating to population growth or decline. Cities today are drastically changing with intelligent technological functionality – implemented in urban surfaces, as infrastructures and as facilitating communicative spheres. So-called smart city visions are racing our cities to the future, making them more efficient, intelligent and predictable, along with continuous advancements in mobile devices enabling new apps, life navigation services and socio-cultural experiences to structure our everyday lives.\nThe notion of the ‘smart city’ embodies a dominant imperative in contemporary global thinking about city development, one of improving the ‘intelligence’ of cities as a conditional support structure for our contemporary urban reality. Urban environments are augmented with intelligent lighting schemes and (mostly commercial) moving ‘images’ on urban displays, screens and façades that increasingly respond to our presence with visuals, sounds and various algorithmic procedures. Our data is accumulated via mobile phones and sensors and implemented in algorithms, which design and run the city’s services and environments. At the same time, media aesthetic interfaces of ‘virtual spaces’ – such as online platforms and mobile applications – accompany our activities in physical space. These interfaces are designed to connect, inform and entertain us in continuously new ways, integrating with our physical environments while increasingly dissolving our distinction between real and virtual. With mobile devices in our pockets – with which our whereabouts are conveniently assisted with GPS navigation and augmented with virtual information, connecting us to any networked activity – we have few moments left in which our awareness, behavior and actions are not somehow tied in with or immersed in media aesthetic experience in the increasingly intelligent city.\nThe city of Stavanger holds the European status as ‘smart city lighthouse’ – as one among nine cities in Europe. The intentions are good – focused on lowering emissions, improving the quality of public transportation, applying energy control, safety and comfort systems to private houses, lowering energy consumption in both dwellings and public buildings – and the investment is exhilarating: NOK 200 million is granted by Horizon 2020 to the five-year Triangulum project with Stavanger, Manchester and Eindhoven as ‘smart city lighthouses’. The University of Stavanger is involved and will develop a cloud data hub for gathering and analysing big data from the project. In the midst of good intentions however, what we can hardly know is what consequences these intelligent technological upgrades will have on people’s everyday lives.\nWhile smart city solutions and technologies are focused on optimising the infrastructures of intensity, intelligence and immersion in cities, oftentimes little attention is given to the human being. The question is increasingly raised, how citizens can be part of these urban processes of ‘intelligent’ transformation, and how citizens can be encouraged to meaningfully ‘involve’ in everyday life’. But what is sometimes missing from pragmatic and result-oriented conversations is acknowledgement of the citizen as cultural being – not ‘user’, but someone who feels ownership of a place, experiences transparency in political processes, and possesses the sense of agency necessary to act and react in a democratic system.\nIntelligent or ‘smart’ upgrades not only bring more efficiency into our lives, they also have a bi-effect: The implementation of intelligent, algorithmic functionality and logic make our lives become increasingly measured, quantified and potentially micro-managed. Moreover, the technical mediation of our environments might involve that we are more open to the discourses and knowledge paradigms we are presented with – not always to the benefit of our own good.\nWhile we are increasingly experiencing a state of being human in closer, intimate and emotional contact with technology, we need to ask: How do we insure that the so-called ‘smart citizen’ is also a critical citizen, one who cares and dares to point out potential errors in smart city initiatives at a micro scale, and one who is not indifferent to the intentions behind them, or to long-term consequences of new technological inventions?\nAt a deeper level of the human cultural nature, we can ask: how does the intelligent city affect our intuitive, impulsive habits, and our modes of behavior (how do our environments affect what we do, or how we react)? What are the needs and curiosities that are evoked in us (e.g. for the sensational and ‘the new’, rather than for inventions of cultural sustainability)? What are we paying attention to, or rather, what mechanisms make us pay attention to certain things over others? And, what are the long-term measures of the intelligent city – by way of these more intimate dimensions of our lives with technologies – in affecting the socio-political reality of citizens?\nIt is when addressing these deeper layers of the impact of ‘smart’ upgrades on the citizen as human being that we may point to an important role for art in the context of the intelligent city – a role that is not didactic, instrumental or simply communicative.\nArt – Between Science and Everyday Life\nWhat critical, interrogative, and co-constructive roles might art take when interfering with the technological development of our cities?\nFirstly, we need to remember that the taking up of a space in which the lines between art and everyday life are blurred is nothing new. Art has interfered with everyday life – and our everyday ‘media surfaces’ at least since the making of medieval mosaics and Renaissance Frescos. In the 1910s the vanguard artists demanded that true art go beyond the intellectual and transform daily life – in reaction against the innovative rhythms and images of the industrial marketplace, mass media and urban popular culture. In the late 1960s, the Situationists enacted tactics of dérives and détournements in attempts to create spaces for alternative appropriation towards goals of eventually transforming them.\nThe link between art and science (in everyday life) is nothing new either. These fields used to be collaborative. In the Renaissance era – the era of philosophical, scientific and religious “rebirth” during which one began to question the reasoning behind theories – art explored the natural and physical world, e.g. how art could demonstrate curiosities about the origin of science. Leonardo da Vinci was a scientist. Also Pablo Picasso was a scientist, developing an art technique around dislocated and geometric figures – making lines and shapes a basic design for our ‘natural environment’; and Goethe worked at the intersection of art and sciences developing his ‘science of colors’.\nToday, artists employ the ‘intelligent’ technologies of our times to examine new configurations of science in everyday life. Artists make use of existing (interactive) urban screens, mobile media, urban infrastructures, digitally controlled lighting systems, sensors and open source software; they write their own software, establish their own data streaming networks, and develop smartphone applications as the interface for artworks. Sometimes, art takes up urban space as a living gallery with which it can engage with everyday life, its meanings, cultures and rhythms. Oftentimes, art enters urban space in critical response to what is perceived as instructive mechanisms in digital culture and existing networks, applications or interfaces of the ‘intelligent’ city.\nArt in the urban context can interfere with everyday life in very direct ways – replace or disrupt mediated messages, create temporary spaces for social encounters, introduce alternative truths or ways of inhabiting public space, or transform urban appearances (of e.g. architecture) and manifest long-lasting memories of alternative appearances or meanings in public space. However, art is not an instrument, but an impulse. Along the lines of thinking of Jacques Rancière, art intervenes in everyday life as a sensible impulse that interferes with our ‘ways of doing and making’. Citizens live in a society in which they perceive how to make sense of things and go about life in order to cope with society, and thus the sensible order of our world and cities within it are governed by implicit, ‘sensible laws’ that are common to people. The distribution of the sensible in a city informs our perception and experience of things that we can understand: our habitual ways of seeing, of saying, of feeling and doing – and being – that determine people’s sense of agency to act, their possibilities for political participation, and forms of participation within a community.[i] When art enters the public domain it infiltrates the sensibilities and cultural, invisible laws within which we form our understanding of our surroundings, which characterizes the rules of those surroundings and our agency and opportunities to act within it.\nWe can point at some scenarios in which art in public space operates by way of distributing ‘the sensible’ in the intelligent city:\nFirst, artworks can exist as various forms of ‘interfaces’ for experimentation or social engagement: As aesthetic encounters in the urban domain, art might provide a kind of ‘test bed’, for example examine the impact of electronic lighting on the experience of urban space or how technologies may impact human social relationships. As ‘experimental interfaces’ in public space, art may promote new forms of public agency or ‘teach’ public sociability, which is not natural but must be learned, nurtured and practiced.[ii]\nSecondly, art might provide citizens with ‘moments’ that bring about awareness of their surrounding reality; unmask the urban constructs or people’s behaviors and how these might be conditioned in a particular space.[iii] This might also entail that the artistic experience conveys emotions or stories to us, which when encountered in the urban domain directly mix with our everyday experience of that place and bring perspective or diversity into it.\nMoreover, art may act as forms of ‘social interfacing’ and help to articulate the new public domains that connect physical urban spaces and the public spheres of electronic networks, as aesthetic manifestations that can occupy, extend or create new public domains in between virtual and physical layers, in which democratic forms of agency can be developed.[iv]\nThen, perhaps the most important role of art in the urban domain is one that is less concrete, can be less instrumental and which “effect” cannot be immediately measured. This is the situation where the art comes to ‘act’ as a kind of supplementary state of mediation that can bring the operation of technical media into our purview in order to make it available to our conscious experience.[v] That is, artistic interfaces may “translate” complex experiences in technological environments into experiences that we can understand, and thus facilitate mediation of ‘transparency’. For example, an interactive art installation allowing for an intimate experience – by spooling forward or backwards of a projected narrative – of how the mechanism of ‘interaction’ relates to our memory structures and time. Or, an augmented reality installation bringing a politically intense, life size environment from another place into your everyday (and very different) urban context may – by way of ‘enlarging’ the presence of the conflict – makes us experience the power of augmentation. As put by curator Inke Arns, “The more people shift activities to the realm of data (for instance, to the Internet), the more important an awareness of the empowering or, as applicable, obstructing attributes of the code on which these virtual realms are based becomes”.[vi]\nLike art has been intimately connected with science and everyday life up through history, also today there is a role for art in the increasingly scientific environment of everyday life: the intelligent city, at the citizen level – the cultural level – of testing, enlightening, facilitating, ‘mediating’ or in other modes examine and convey the complex experiences in technologically upgraded urban environments. Also, a role of making a human dimension – emotion, creativity, wonder and objection – present to us in urban space. This makes for constructively complex urban environments that seed democratic processes and engage citizenship.\nOf course we need to be vary of protecting the art from being swamped into development schemes that see a useful potential in art as a generator of growth but with little concern for the artistic intention or the long-term public good. The easy way is to treat art as basically a marketing tool for promoting cities as attractive and culturally vibrant. When doing so, however, we miss out on the opportunities in art to participate actively in the development of the intelligent city – at a citizen level.\nOn 27 September 2017, Screen City curators Daniela Arriado and Tanya Toft Ag will share their thoughts on art’s participation in the ‘intelligent city’ and the biennial’s role in facilitating this, at the Nordic Edge Expo in Stavanger. The conversation will be published on SCB Journal in early October 2017.\n[i] Jacques Rancière, The Politics of Aesthetics, ed. and trans. Gabriel Rockhill (London and New York: Bloomsbury Academic, 2015).\n[ii] Scott McQuire has elaborated on this in The Media City (London: SAGE, 2008).\n[iii] Catrien Schreuder has described how video art in public space bring about ‘perfect moments’ in Pixels and Places, Video Art in Public Space, (Rotterdam: NAi Publishers, 2010).\n[iv] This has been suggested by Andreas Broackmann in “Public Spheres and Network Interfaces,” in The Cybercities Reader, ed. Stephen Graham (New York: Routledge, 2004), 378-384.\n[v] Mark B. N. Hansen, Feed-Forward: On the future of twenty-first century media (Chicago: The University of Chicago Press, 2015), 43.\n[vi] Inke Arns, “Interaction, Participation, Networking: Art and Telecommunication,” What Urban Media Art Can Do: Why When Where & How, eds. Susa Pop, Tanya Toft, Nerea Calvillo, and Mark Wright (Stuttgart: av edition, 2016), 210.']	['<urn:uuid:bc447e6a-ac09-4199-a492-ad8a71093203>', '<urn:uuid:fbec1bde-bd18-43b8-96e7-057829f55590>']	factoid	with-premise	short-search-query	similar-to-document	three-doc	expert	2025-05-01T23:21:14.341336	6	73	2878
271	dangers chemicals used compostable paper food containers health effects	Compostable paper-based products often contain toxic chemicals, particularly perfluorinated alkyl substances (PFAS). These compounds are used to create water and grease resistance in dining ware, but can leach into compost and work their way into food through soil. PFAS have been linked to negative impacts on child development and increased risk of some cancers.	"['Resilient Recycler: Are products labeled as ""compostable"" really better for the environment?\nYou may have noticed a recent increase in the availability of products labeled as ""compostable"" at event venues, restaurants, and supermarkets. Throughout the country people are hearing more about waste, recycling, and the environment. This is motivating a lot of people to find ways to decrease the amount of waste they\'re sending to landfills, largely through recycling and composting. Composting is a great way to recycle nutrients back into our soils. Healthy, nutrient-rich soils is essential for growing our food, clothing, and producing many of our consumer goods. Without composting, those soils are less productive. Nutrients are a renewable resource, but only if we return nutrients to the soil through composting. While composting organic materials such as food scraps and yard debris provides numerous environmental benefits, many products labeled as compostable have proven to have negative impacts on the environment. Common products labeled as compostable include single-use cutlery, dining ware, bags, and packaging. Why aren\'t these products the answer for living more sustainably?\n1. ""Certified Compostable"" may not mean what you think.\nNot all products containing the ""certified compostable"" label have the ability to rot or break down quickly enough to be composted alongside food scraps and yard debris at commercial compost facilities. When these products don\'t break down, they contaminate the final compost product (because you\'re not going to want to buy a bag of compost for your garden that has chunks of dining ware and cutlery in it!). The increase in contamination from these products burdens compost facility operators and increases both economic and environmental costs.\n2. It takes a lot of energy and natural resources to make ""compostable"" products.\nFor most products we use, the greatest environmental impact comes from the manufacturing and transport of that product, rather than the impacts of its recycling or disposal. This is true for products labeled as ""compostable"", too, but even more so; compostable products require more energy and cost more to manufacture than traditionally-produced single-use products. The Oregon Department of Environmental Quality recently published a study of the environmental impacts of various products and packaging where they compared items labeled as compostable versus traditional single-use items. They found that the items labeled as compostable had greater negative environmental impacts than the traditional items for 88% of products they studied. Using an analysis of the environmental impacts throughout the ""life-cycle"" of these products, from manufacture to use and disposal, the study found that compostable materials often require more fossil fuels and generate more greenhouse gas emissions to create than their traditional, non-compostable counterparts.\n3. They can contain toxic chemicals.\nThere are a number of compostable paper-based products that contain toxic chemicals. When these products are tossed into compost bins, the toxins can leach into the compost and negatively impact people and the environment. One of these toxic compounds most commonly used in compostable products is perfluorinated alkyl substances (PFAS), which can work their way into our food through compost added to soil. PFAS compounds are used to create the resistance to water and grease we expect from single-use dining ware, but they also endanger our health and have been linked to negative impacts on child development and increased risk of some cancers.\n4. Products labeled as ""compostable"" usually cost more.\nCompostable products are more expensive to make, and those costs are passed on to the consumer. While many environmentally-conscious consumers are willing to pay more for products with lower environmental impacts, the environmental benefits of compostable products (or lack thereof) don\'t justify the increased price.\n5. You wouldn\'t want to try to compost these products at home.\nCompostable products won\'t break down even after several trips through commercial composting facilities where the piles reach temperatures high enough to kill germs and sterilize any seeds. Your backyard compost pile doesn\'t get nearly as hot, and while you could maybe get these compostable products to break down eventually, it would take a lot of time, water, and energy.\n6. ""Compostable"" products prohibit compost from being used in organic farming.\nCertified organic farms heavily depend on compost, in lieu of synthetic fertilizers, to grow their crops. USDA organic certification requirements prohibit the use of compost that included any type of compostable packaging or products in its source materials. Use of compostable products reduces the supply of compost that meets this requirement, making it more difficult and expensive for organic farmers to maintain USDA organic certification.\n7. ""Compostable"" plastic packaging does not degrade, especially in marine environments.\nAbout 10% of the world\'s plastic ends up in oceans. Much like traditional plastics made from fossil fuels, compostable plastic will not degrade or decompose in marine environments. Instead, those products will further contribute to oceanic plastic pollution.\nIf not compostable products, what is the solution to create less packaging and product waste?\nMany of the compostable products on the market today are designed to be used only once and disposed of. Consider reusable alternatives to single-use products even if they\'re labeled as recyclable or compostable. Remember, composting food scraps and organic debris is a great way to divert waste from the landfill and recycled nutrients back into the soil, but products labeled as ""compostable"" can cause a number of problems for composting facilities and the environment.\nCheck out this video to see food waste go from a Clark County school to Dirt Hugger, a commercial composting facility in the Gorge.']"	['<urn:uuid:87eaf77f-c237-44c5-a507-c9f872e5d093>']	factoid	direct	long-search-query	distant-from-document	single-doc	expert	2025-05-01T23:21:14.341336	9	54	905
273	What are the most common symptoms someone gets when infected with Legionnaires disease, and which groups of people are at higher risk of getting it?	Legionnaires disease causes symptoms like fever, chills, headache, and progressive severe pneumonia. People at higher risk include those over 45 years old, smokers, heavy drinkers, and individuals with chronic conditions like respiratory disease, kidney disease, diabetes, lung and heart disease, or anyone with an impaired immune system.	"['PNEUMONIAS & LOWER RESPIRATORY TRACT INFECTIONS Infectious Disease Epidemiology Section Office of Public Health Louisiana Dept of Health & Hospitals ...Your Taxes at Work… 504-568-5005 *** 800-256-2748 www.oph.dhh.louisiana.gov Clinical Presentation: Lower respiratory Tract Infection Prodrome ± Symptoms of upper respiratory tract infection: sore throat, rhinorrhea Fever, chills Nausea, vomiting, diarrhea Headache, dizziness Clinical Presentation: Lower respiratory Tract Infection Acute Infection: Fever, chills Back pain, myalgias, arthralgias Headache, malaise, chills Nausea, vomiting Chest Infection: Cough Chest pain Rales, wheezing, noisy chest Characteristic changes on chest x-rays Increasing respiratory distress, may require mechanical ventilation Diagnostic etiology of pneumonia About 40-60% of persons with pneumonia do not have a defined etiology… even after extensive testing for known respiratory pathogens Community Acquired Pneumonia Age-specific rates of hospital admission for community-acquired pneumonia caused by S. pneumoniae, M. pneumoniae, C. pneumoniae, or Legionella species Pneumonia Acute Respiratory Disease & Fever S.pneumo Legionella TB Plague Tularemia RICIN toxin Staphylococcal Enterotoxin B SARS Pneumonia Acute Respiratory Disease & Fever • They all look alike, sound alike • Not easy to differentiate from other pneumonias • Bronchoscopy, sputum, bronchial lavage… • Blood culture • Look for antibodies in serum Pneumococci Pneumococci Infection type Otitis media Pneumonia Bacteremia Meningitis Deaths Cases Mortality 7,000,000 500,000 5% 50,000 20% 3,000 30% 40,000 colonizes the upper respiratory tract cause: disseminated invasive infections - bacteremia - meningitis pneumonia & other lower respiratory tract infections upper respiratory tract infections - otitis media - sinusitis Risk Factors/ Increased risk for developing pneumococcal infection or experiencing severe disease and complications Children < 2 & adults aged > 65 years Underlying medical conditions chronic cardiovascular diseases (CHF/ cardiomyopathy) chronic pulmonary diseases (COPD or emphysema) chronic liver diseases (cirrhosis) Diabetes mellitus with CV or renal dysfunction Chronic renal failure or nephrotic syndrome Asthma NO unless with chronic bronchitis… Risk Factors/ Increased risk for developing pneumococcal infection or experiencing severe disease and complications Asplenia Functional or anatomic (SCD or splenectomy) clearance of encapsulated bacteria from the bloodstream antigens as in immunosuppressive conditions decreased responsiveness to polysaccharide Immunosuppressive conditions: AIDS, CIDS, leukemia, lymphoma, multiple myeloma, Hodgkins disease, or generalized malignancy, organ or bone marrow transplantation; rx with alkylating agents, antimetabolites, or systemic corticosteroids Pneumonia in HIV Most common bacterial cause of pneumonia in HIV Invasive pneumococcal disease often first clinical manifestation of children HIV AIDS: annual attack rate of pneumococcal bacteremia ~ 1% Pneumococcal Vaccine Pneumovax-Merck and Pneu-Immune® 23 Lederle include 23 purified capsular polysaccharide antigens serotype-specific antibody develops within 2-3 weeks in >80% of healthy young adults responses not consistent among 23 serotypes immunocompromised patients & children aged < 2 whose immune systems are immature: antibody responses Pneumococcal Vaccine Effectiveness against invasive disease: 56% to 81% in case-control studies not effective for prevention of common upper respiratory diseases (e.g., sinusitis in children) efficacy for non-bacteremic pneumonia was not demonstrated in elderly or in persons with chronic medical conditions Side effects mild, local (pain at site, erythema, swelling), < 48 hrs, systemic reactions (fever, myalgias) severe local reactions rare Legionella Legionnaires Disease 58th annual convention of the American Legion’s Pennsylvania Department at Bellevue Stanford Hotel in Philadelphia, July 21-24 1976 Starting July 22 - convention attendees and others who entered hotel became sick: pneumonia 182 hotel cases + 39 neighborhood cases 34 deaths Six months later a small bacterium named Legionella lung tissues of the cases pneumophila isolated from guinea pigs inoculated with the Legionnaires Disease Similar agents isolated before but never before so thoroughly characterized soldier in Fort Bragg, NC scuba diver 1943 L. micdadei from blood of febrile in 1959 L.bozemannii from lung tissue of identified as the causative for Pontiac fever retrospectively by serology outbreak of acute febrile illness, 1968, MI DOH building in Pontiac Bacteriology Legionella small (0.3 - 0.9 ) bacteria ~ very small Gram neg bacteria grows on buffered charcoal yeast extract agar (BCYE) supplemented by antibiotics to prevent overgrowth of Legionella dye to give Legionella a distinctive color grows slowly, 3-5 days to have small colonies Bacteriology 18 species Legionella pneumophila serogroup 1 is the predominant species in USA Legionella pneumophila multiplying inside a cultured human lung fibroblast Bacteriology in nature, infect free living amebae as Acanthamoeba, Naegleria and Harmanella multiply within amebae do not colonize respiratory tract phagocytized by the macrophages, then multiply within macrophages cell surface protein, macrophage infectivity potentiator (Mip) necessary for invasion of phagocytes and expression of virulence fold mutation in the Mip gene increase virulence 80- Natural Habitat Occurs worldwide preferred habitat: WATER preferably WARM WATERS with scale, sediment, metallic ions and commensal flora well adapted to hot water distribution system in dwellings: colonizes hot water heaters, storage tanks, pipes, shower heads, plumbing materials, faucet aerators, AC cooling towers, evaporative condensers found in 1-30% of home hot water systems multiplies in free living amebae: Acanthamoeba, Naegleria.. Transmission Inhalation of aerosols of water contaminated with Legionella primary mechanism of entry: aerosols generated by cooling towers, showers, faucets, respiratory therapy equipment and room-air humidifiers aspiration of contaminated potable water also proposed NO Person-to-person transmission Epidemiology Incubation 2-10 days 80% of reported cases are SPORADIC Outbreaks in hospitals, cruise ships, hotels and other large buildings Clinical: Pneumonia Common cause of PNEUMONIA % community acquired pneumonias due to Legionella is difficult to estimate routine diagnostic tests for recent Legionella not retrospective & prospective studies 1%-5% CAP pneumonias depending on geographic setting immunocompromised or chronically ill individuals risk higher among cigarette smokers, elderlies, Clinical wide range of clinical response asymptomatic serologic conversion self limited febrile illness (Pontiac fever) headache, chills myalgias or progressive severe pneumonia (Legionnaire’s disease) Legionnaire’s disease cannot be distinguished clinically or radiologically from other pneumonias Diagnosis Isolation of Legionella from respiratory secretion cultures Visualization of Legionella in respiratory secretions or tissue by immunofluorescence Detection of Legionella serogroup 1 antigen in the urine by radioimmunoassay, or enzyme immunoassay (EIA) more sensitive and specific than IF on respiratory tract secretions rapid diagnosis but only detects infection due to this species and serogroup Diagnosis Four fold rise in antibody titer to Legionella rising to above 1:128 in paired sera Antibodies to Mycoplasma pneumoniae, Campylobacter jejuni, Pseudomonas aeruginosa and Bacteroides fragilis, may cause falsepositive IFA test results Diagnosis One elevated antibody titer does NOT confirm case of recent legionellosis 1% - 16% of adults have IFA titers 1:256 Safe Water ”ways” grows poorly at < 20 C and > 50 C killed at temperatures > 60 C susceptible to chlorine and bromine disinfectants ozone heavy metal ions UV studies performed under lab conditions not always successful in predicting effectiveness under field conditions Safe Water ”ways” Cooling towers and evaporative condensers disinfected by hyperchlorination safer approaches would be to place them away from public areas to use drift eliminators to clean from organic matter periodically to dose automatically with a biocide Cooling Tower Safe Water ”ways” Whirlpool spas halogen levels at 4 - 10 mg/L, monitor frequently pH at 7.2 - 7.8 drain and clean system frequently replace filters regularly Safe Water”ways” Hot water system flushing for >5mn at > 65 C hyperchlorination (flushing with water 10 mg/L free residual chlorine) • • • • • • • may grow back unless hot water maintained at 50 C cold water at 20 C residual chlorine at 1-2 mg/L of free chlorine risk of scalding users hyperchlorination causes corrosion remove scale and sediments UV, ozone and heavy metals + Pertussis Bacteriology Bordetella pertussis fastidious Gram neg Bordet Gengou agar with 15% sheep blood or Regan Lowe immediately Swabs to be inoculated Delays isolation incubated at 35 C, in moist air Growth 5 days Transmission large droplets from upper Humans only respiratory tract NOT by droplet nuclei or fomites Asymptomatic cases exist, role ?? Without immunity, susceptibility = 100%, no child escaped pertussis Household exposure: attack rate pertussis = 90% to 100%, (in school 50%) mumps = 31% measles=75% chickenpox=61% Period of Communicability Incubation 7d (6-25 d) CATHARRHAL PAROXYSMAL Convales 10-14d 7-14d cence Communicability weeks Onset + 21 d Infected HCW: Onset +21 or Rx+5d Exposed HCW: ex+6 until +21 or rx+5d Epidemiology: before Vaccine endemic with epidemics at 3 - 5 years interval in unimmunized population majority among children 40% among infants < months 75% among children < 5 years of age incidence rate of whooping cough was about 150 /100,000 /year distributed worldwide outbreaks any time, slightly more during summer & early fall Epidemiology After Vaccine Immunization or immunity after disease prevents disease but NOT infection US rates down to 0.5 - 1 /100,000/yr nowadays resurgence pertussis = epidemic with 2 - 5 years cycles immunization cases but did not change cycles Epidemiology After Vaccine Common among adults IgA antibodies only produced after a natural infection, not after immunization Prevalence of IgA antibodies similar among adults in countries with generalized immunization (USA) or in countries with no systematic pertussis immunization (Germany in the 1970s): vaccine did not prevent production of IgA Vaccine did not prevent transmission 25% of adults with persistent cough have serologic evidence of recent pertussis infection Pertussis in the USA Log scale Pertussis in the USA Clinical first week: catarrhal phase: cough increases paroxysmal stage lasts for 3-4 weeks: starts after 2 weeks severe spells of coughing typical whoop: The whoop created by vigorous inspiration through the glottis at end of paroxysm during paroxysms, the child may turn blue or vomit fever usually low subconjunctival, cerebral and nose hemorrhages Mortality related to age: 50% in young infants negligible after 5 pulmonary complications Encephalopathy otitis media, mastoiditis, inanition and diarrhea are common in developing countries permanent neurological Diagnosis nasopharyngeal culture nasopharyngeal mucus collected on Dacron or calcium alginate swab a whooping cough syndrome similar to pertussis then inoculated on special culture media Bordet Gengou agar with sheep’s blood Regan-Lowe medium if delay Bordetella parapertussis, Chlamydia trachomatis adenoviruses Direct Stuart’s transport medium culture + from beginning of catarrhal stage+ 3 weeks ImmunoFluorescence Assay (DFA) not as specific or as sensitive as culture Prevention: Early Case Finding EARLY DETECTION essential to institute prevention Mild upper respiratory infection mild fever + coughing > 1 week duration SUSPECT PERTUSSIS Prevention: Contact Investigation identify individuals at risk, evaluate immunization status implement isolation and chemoprophylaxis monitor for respiratory for 14 days after contact broken household and other close contacts irrespective of their immunization status: erythromycin po (40 to 50 mg/kg/day in 4 divided doses, maximum 2 g) for 14 days eliminates carriage, may prevent disease if early immune are protected against new disease but not against infection and serve as transmitters compliance poor 5 day azithromycin, or 7 day clarithromycin OK Trimethoprim-Sulfamethoxazole alternate Prevention: Day Care Centers immunization as appropriate and chemoprophylaxis: same doses as the household contacts symptomatic children excluded pending medical evaluation: may return 5 days after initiation of erythromycin children on chemoprophylaxis Childhood Immunization Schedule Birth 1m 2m 3m 4m 6m 12m 15m 18m 4-6y 11-12y HBV2 DTP DTP HBV1 HBV3 DTP Hib Hib Polio MMR Varicella MMR or MMR Varicella DTP Hib Hib Polio Polio Pertussis Vaccine Whole cell vaccines Acellular vaccines: 5 immunogenic components capable individually or combined, of producing immunity acellular DPT vaccines initially developed in Japan inactive form of pertussis toxin, filamentous hemagglutinin, agglutinogens, outer membrane protein use of acellular vaccine reduces side effects: fever & irritability USA: acellular vaccines combined with DT recommended Prevention: Isolation /Exclusion Isolation of the hospital patient Droplet precautions until onset+21d or rx+7d Exclusion from school & day care Health Care Worker 1-suspected HCW : removed from patient contact until status determined 2-infectedHCW: + culture even if asymptomatic) removed from direct patient contact from onset to 21 days or until 7 days after rx start 3-exposed HCW: asymptomatic and neg cultures can continue Prevention in Health Care Facilities: Triage Questions patients with fever and respiratory symptoms Triage at first points of contact or before performing history-taking or examinations Surgical mask on suspect patients early during the triage process\n""PNEUMONIAS _ LOWER RESPIRATORY TRACT INFECTIONS""', 'There are a number of important Health and Safety matters which must be considered when undertaking a Survey. Obviously gas and electrical safety are well known issues and it is likely that water safety will become more important over coming years.\nIt is often the case that cold water header tanks (often located in the loft) have no covers or poor covers and as a result it is highly likely that many older water heating systems will have unclean water in the hot tanks.\nThe age and condition of cold tanks is covered in our house and flat Surveys. We look at the adequacy of the support for tanks, the covers, lagging and overflow pipes.\nThere are also risks of Legionnaires disease in some properties and it is important that facilities such as spa baths be sterilised and flushed using hot water on a regular basis.\nThe following information was taken from the Health and Safety Executive Website. See:\n‘Legionellosis is a collective term for diseases caused by legionella bacteria including the most serious Legionnaires’ disease, as well as the similar but less serious conditions of Pontiac fever and Lochgoilhead fever. Legionnaires’ disease is a potentially fatal form of pneumonia and everyone is susceptible to infection. The risk increases with age but some people are at higher risk including:\n- people over 45 years of age\n- smokers and heavy drinkers\n- people suffering from chronic respiratory or kidney disease\n- diabetes, lung and heart disease\n- anyone with an impaired immune system\nThe bacterium Legionella pneumophila and related bacteria are common in natural water sources such as rivers, lakes and reservoirs, but usually in low numbers. They may also be found in purpose-built water systems such as cooling towers, evaporative condensers, hot and cold water systems and spa pools.\nLegionella bacteria are widespread in natural water systems, e.g. rivers and ponds. However, the conditions are rarely right for people to catch the disease from these sources. Outbreaks of the illness occur from exposure to legionella growing in purpose-built systems where water is maintained at a temperature high enough to encourage growth, e.g. cooling towers, evaporative condensers, hot and cold water systems and spa pools used in all sorts of premises (work and domestic).\nPeople contract Legionnaires’ disease by inhaling small droplets of water (aerosols), suspended in the air, containing the bacteria. Certain conditions increase the risk from legionella if:\n- the water temperature in all or some parts of the system may be between 20-45 °C, which is suitable for growth\n- it is possible for breathable water droplets to be created and dispersed e.g. aerosol created by a cooling tower, or water outlets\n- water is stored and/or re-circulated\n- there are deposits that can support bacterial growth providing a source of nutrients for the organism e.g. rust, sludge, scale, organic matter and biofilms’\nIn light of the above and other possible water-related health problems it is important to maintain and improve the water pipes leading into the house, internal fixtures and fittings etc.\nCareful attention must be paid to water storage tanks and any old tanks will probably need to be replaced. Spa baths present a particular risk and it is important that such fittings but also showers be regularly flushed with very hot water. It is also possible to arrange for a water system to be sterilised by a qualified plumbing contractor who has the experience and qualifications to sterilise a water system.']"	['<urn:uuid:b65b08cc-9db1-498f-9226-b46547840386>', '<urn:uuid:a461f60a-d9eb-434a-943f-e244c3201b4c>']	factoid	direct	verbose-and-natural	distant-from-document	multi-aspect	novice	2025-05-01T23:21:14.341336	25	47	2553
274	body temperature comparison hypothermia frostbite symptoms	Both hypothermia and frostbite show distinct symptoms based on body temperature changes. In hypothermia, when body temperature drops below 95°F, symptoms include uncontrollable shivering, memory loss, disorientation, incoherence, slurred speech, drowsiness and apparent exhaustion. For frostbite, which affects extremities when blood flows away from them, symptoms include white/grayish/bluish skin, cold/hard/waxy feel to skin, itching, burning, or numbness, and in extreme cases, blistering and hardening of skin.	['The Cold Season is Here!\nAs temperatures drop, and bodies of water throughout the area begin to freeze over, the Massachusetts Emergency Management Agency (MEMA) has issued information regarding safety precautions to be taken on our frozen lakes, rivers and ponds.\n“Before we experience a tragedy that is unfortunately too common this time of year, it is important that we remind everyone, particularly children, of the dangers of unsafe ice,” said MEMA Director Kurt Schwartz. “As lakes, ponds, streams and rivers throughout the Commonwealth freeze over, ice conditions may be very uncertain. People may be a bit impatient to venture out on the ice for skating, hockey, ice fishing and other winter sports. We highly recommend the use of recreational skating areas provided by the Commonwealth and your local communities. It is very important to exercise precaution and common sense.”\nAlways check with your local police, fire or park department to ensure that safe ice conditions exist. However, due to the uncertainty and constant changing of ice conditions and the dangers presented, many departments will not endorse the safety of lakes, ponds, streams or rivers. The strength and thickness of ice should be known before any activity takes place.\nExtreme Cold Weather\nSince winter in Massachusetts can bring extremely low temperatures and wind chills, everyone should take precautions to minimize the dangers presented by severe cold weather:\nBefore Extreme Cold Weather\n- Be aware of the weather conditions by monitoring the media.\n- Ensure you have sufficient heating fuel, as well as emergency heating equipment in case you lose electricity.\n- Have a well-stocked Emergency Kit that includes flashlights, portable radio, extra batteries, a first aid kit, bottled water and non-perishable food.\n- Make sure your car is properly winterized. Keep the gas tank at least half-full. Carry a Winter Emergency Car Kit in the trunk including blankets, extra clothing, flashlight with spare batteries, a can & waterproof matches (to melt snow for drinking water), non-perishable foods, windshields scraper, shovel, sand, towrope and jumper cables.\nDuring Extreme Cold Weather\n- Minimize outside activities, particularly the elderly and very young. Also consider your pets.\n- Dress in several layers of loose-fitting, lightweight clothing, rather than a single layer of heavy clothing. Outer garments should be tightly woven and water repellent.\n- Wear a hat, mittens (rather than gloves) and sturdy waterproof boots, protecting your extremities. Cover your mouth with a scarf to protect your lungs.\n- If electricity is lost for an extended period of time, a snowbank in your yard can become a makeshift freezer for food.\n- Excessive exposure can lead to frostbite, which is damaging to body tissue that is frozen. Frostbite causes a loss of feeling and a pale appearance in extremities, such as fingers, toes, ear lobes or the tip of the nose. If symptoms are detected, seek medical help immediately.\n- Hypothermia can occur in extreme cases. The warning signs are uncontrollable shivering, memory loss, disorientation, incoherence, slurred speech, drowsiness and apparent exhaustion. If the person’s temperature drops below 95 degrees, seek immediate medical care.\n- When utilizing alternate heating sources, such as your fireplace, wood stove or space heater, take the necessary safety precautions. Keep a fire extinguisher handy, ensuring everyone knows how to use it properly. Test smoke alarms.\n- If you lose your heat, seal off unused rooms by stuffing towels in the cracks under the doors. At night, cover windows with extra blankets or sheets. Food provides the body with energy for producing its own heat.\n- To keep pipes from freezing, wrap them in insulation or layers of newspapers, covering the newspapers with plastic to keep out moisture. Allow a trickle of warm water to run from a faucet that is farthest from your water meter or one that has frozen in the past. This will keep the water moving so that it cannot freeze. Learn how to shut off your water if a pipe bursts.\n- If pipes freeze, remove insulation, completely open all faucets and pour hot water over the pipes or wrap them with towels soaked in hot water, starting where they are most exposed to the cold. A hand-held hair dryer, used with caution, also works well.\n- Be a good neighbor. Check with elderly or disabled relatives and neighbors to ensure their safety', '30 Oct 17\nRecognizing Hypothermia, Frostbite And Other Common Cold-related Illnesses – Toolbox Talks\nToolbox Talks are intended to facilitate worksite health and safety conversations. Click here to download talking points on recognizing cold-related illnesses to share with your crew.\nWeather patterns are changing. Seasons becoming more extreme. And the ever-increasing unpredictability of Mother Nature is making it harder than ever for workers exposed to her wild weather swings to prepare.\nTake the winter of 2013-14, for example. That’s when a polar vortex settled on top of much of the U.S., helping push that February into the record books as the coldest month in the history of weather observations. Much of the Midwest and East Coast were paralyzed by the cold. The moderately warm fall preceding it only exacerbated matters, with the quick turn in temperatures leaving people less ready to handle winter’s arctic shock.\nWith these cold-weather extremes as a backdrop, it’s more important than ever to be able to properly identify the most common cold-related illnesses, along with knowing what treatments to seek.\nHOW THE BODY REACTS TO COLD\n- Energy is spent maintaining internal temperature\n- Blood is drawn away from extremities to the core\n- Exposed skin & extremities cool rapidly, increasing risk of frostbite and hypothermia\nWhen the body temperature drops below 98.6 degrees Fahrenheit (or 37 degrees Celsius), blood begins to flow away from the extremities to heat the body’s core. This immediately cools exposed skin and extremities, and increases the risk of cold stress, specifically frostbite and hypothermia. According to the Centers for Disease Control and Prevention (CDC), early signs and symptoms of heat loss include shivering, fatigue and confusion or disorientation. They can evolve to include blue skin, a slow pulse, and even loss of consciousness.\nIf body temps continue to fall, dexterity is diminished and speech may be slurred. At 85°F (29.4°C), severe hypothermia – a condition characterized by an extreme low body temperature – sets in. Symptoms include cool skin, severe shaking and memory lapses, among other issues. Once the body temperature plummets below 78°F (25.5°C), a person is at risk for brain damage – and even death – if not treated immediately.\nCOMMON COLD-RELATED ILLNESSES\n- Trench foot\n- Indoor and outdoor workers at risk\nThe three most common cold-related illnesses – hypothermia, frostbite and trench foot – are an obvious danger for those working outdoors in unpredictable winter weather. But the risk for those working indoors in places such as food processing, cold storage and beverage/brewing facilities is just as real.\nThe most severe of the cold-related illnesses occurs when body heat is lost faster than what’s produced, and core body temp drops below 95°F (35°C).\nWhat to look for:\n- Poor coordination and slowing of pace\n- Stumbling and clumsiness\n- Dazed and confused behavior\n- Slurred and slow speech\n- Hallucinations or changes in personality\nWhat to do:\n- Mild Case: Move to warm area and stay active. Cover head and body with dry clothes or blankets. Drink a warm (not hot) drink.\n- Moderate Case: Same as Mild, plus contact emergency medical personnel. Re-warm extremities.\n- Severe Case: Treat worker very gently and do not apply external heat to re-warm. Hospital treatment is required.\nBecause of the way blood leaves the extremities to protect vital organs in the body’s core in cold environments, hands and feet are the most susceptible to frostbite.\nWhat to look for:\n- White, grayish, or bluish skin\n- Cold, hard, or waxy feel to skin\n- May itch, burn, or feel numb\n- Blistering and hardening of skin are signs of extreme frostbite\nWhat to do:\n- Get out of the cold\n- Gradually warm the affected skin\n- Place frostbitten areas in warm – not hot – water\n- Wrap affected areas in a warm blanket\n- Seek emergency medical help ASAP\nNOTE: Do not rub or massage the frostbitten area or use a heating pad, heat lamp or other heat source for warming.\nTrench foot is a “wet cold disease” occurring in damp or wet environments that are just above freezing. The name comes from WWI when soldiers developed the illness while waiting in the trenches for combat.\nThe skin does not actually freeze with trench foot, but other issues definitely can arise.\nWhat to look for:\nWhat to do:\n- Remove wet socks and footwear\n- Thoroughly clean with warm water\n- Dry feet\n- When sleeping or resting, do not wear socks\n- Get medical treatment ASAP\nPERSONAL RISK FACTORS\n- Age, weight, fitness level\n- Chronic or acute illness\n- Alcohol or drugs\nThere are two sets of factors that come into play when considering the causes of cold stress on the body: personal and environmental. Being aware of these factors and knowing an individual’s risk factors will allow that person to be better prepared when the cold weather hits. While workers can’t do anything about some personal risk factors (like age, for example. The very young and the very old are much more susceptible to cold temps), they can reduce risk by being mindful of their own fitness levels — watching their weight, staying hydrated, avoiding alcohol and drugs, getting plenty of sleep, etc.\nAdditionally, acclimatization — gradually increasing exposure to the cold — plays a large part in reducing stress on the body. By taking frequent warming breaks and avoiding the temptation to go “all in”, workers can build up tolerance to frigid temps.\n- Cold air temperatures\n- High wind speeds\n- Damp air\n- Contact with cold water or surfaces\n- Working without proper PPE\nFour environmental factors contribute to cold stress: cold air temperatures, high velocity air movement, dampness of the air, and contact with cold water or surfaces. A cold environment forces the body to work harder to maintain its temperature. Cold ambient air temperature, water, and snow all draw heat from the body. High wind speeds and dampness in the air will also accelerate a body’s heat loss.\nTALK TO YOUR CREW\nThe reality is that work doesn’t stop when the temperature drops. So taking a few minutes before a shift to educate your crew on the signs, symptoms and causes of cold-related illnesses is a simple yet effective measure to increase awareness and reduce the risks.']	['<urn:uuid:c127c98e-e9a4-42d6-bc1f-347e09ac2df5>', '<urn:uuid:0a6785a9-4cb8-4b42-a192-2d640ecee4b7>']	open-ended	with-premise	short-search-query	similar-to-document	comparison	novice	2025-05-01T23:21:14.341336	6	66	1767
275	west nile fever ebola symptoms comparison	Both diseases can present with fever, but their symptoms differ. West Nile Virus typically causes fever, headache, body aches, joint pain, vomiting, diarrhea, and rash in about 20% of infected people. Less than 1% develop serious neurologic illness. In contrast, the 2014 Ebola case mentioned showed symptoms of fever, abdominal pain, dizziness, headache, nausea, and diarrhea.	"['In 2019, a crew of nine pilots and astronauts broke a world record. They flew around the Earth in just 46 hours. More incredible is that they did not fly in a never-before-seen, advanced aircraft prototype. They flew a commercially available jet plane.\nThe future is already here.\nIt’s a small world; it’s getting smaller by the minute\nBased on the new world record, it could take less than a weekend for an emerging infectious disease to spread all over the globe. And chances are, it may take a week or more before it gets detected based on the incubation period.\nUnfortunately, healthcare providers at the frontlines of infectious disease management face a significantly higher risk of infection. The risk extends beyond healthcare workers to their families and communities.\nAs the world grapples with the impact of COVID-19 and its mutations, it’s a good time to ask: What can health systems worldwide do to detect emerging infectious diseases imported from other countries early?\n1. Think beyond the travel ban\nRecent research empirically demonstrated that local outbreaks of various Infectious Diseases could “quickly spread to other countries through the international movement of people and goods, with potentially disastrous health consequences .”\nWhile this fact may not be news to clinicians and Infectious Disease specialists, the study also shows a close spatial dependence between the health conditions in one country and another – a spillover effect. The study used GIDEON (Global Infectious Disease and Epidemiology Online Network), a database covering all Infectious Disease outbreaks.\nAn epidemic in one country can become a pandemic in others – irrespective of travel and other physical barriers to entry. Studies of previous epidemics show that even a 90% travel restriction between countries merely delays the arrival of an emerging infection by a few weeks. Another study by Quilty et al. reported that airport-based screening measures to detect COVID-19 missed 46% of cases because of the incubation period .\nSo, while a travel ban and thermal screening can help a country buy some time to prepare for an outbreak, epidemic, or pandemic, they cannot stop or prevent a new infection from spreading to foreign shores.\n2. Record travel history as standard protocol\nTravel has always been one of the fastest ways to introduce a pathogen to a new environment. And as two clinicians, Trish Perl and Connie Savor Price, argue in a recent ‘Annals of Internal Medicine’ article, travel history must be treated as the fifth vital sign in emergency rooms and all physician evaluations .\nThe doctors make a strong case that including a patient’s travel history as part of a vital signs check can “help put symptoms of infection in context and trigger us to take a more detailed history, do appropriate testing, and rapidly implement protective measures.”\nMonkeypox in the UK, 2021\nFor example, in May 2021, the World Health Organization received notification from the United Kingdom of a confirmed case of monkeypox in an individual who had just traveled from Nigeria. Monkeypox has an incubation period of six to thirteen days, but according to WHO, it can range anywhere from five to twenty-one days. Eventually, the infection spread to another family member, and they were isolated. Differential diagnosis considerations for monkeypox include chickenpox, measles, bacterial infections, scabies, syphilis, and medication-associated allergies. In such a case, taking the patient’s travel history can help healthcare workers take the necessary precautions even before the PCR results.\nCOVID-19 in the United States, 2019\nThe first case of COVID-19 in the US was reported in Washington when the patient returned from Wuhan, China. Based on the patient’s travel history and symptoms, healthcare professionals could isolate and send clinical specimens to be tested by the CDC overnight. Hospitals in the United States were already on alert for patients from Wuhan presenting with symptoms, and testing could be prioritized accordingly.\nEbola in the United States, 2014\nLet’s look at an example where a patient’s travel history would have helped protect healthcare professionals. In 2014, a man traveled from West Africa and admitted himself into a hospital in Dallas with fever, abdominal pain, dizziness, headache, and nausea. Without an integral piece of the puzzle – his travel history – he was treated for sinusitis and sent home. The hospital suspected Ebola only when he returned three days later with persistent fever, abdominal pain, and diarrhea. Unfortunately, within this time, this patient had infected healthcare professionals, ambulance transport personnel, and the patient’s caregivers.\nMonkeypox and Ebola are not as contagious as COVID-19 and its variants, and Ebola is not contagious until symptoms appear, making containment easier. But emerging infectious diseases and their variants might be.\nInfectious Disease specialists, clinicians, researchers, and medical librarians will need to be vigilant against the next outbreak. Epidemiological data plays an integral role in facilitating improved clinical decisions and saved lives.\n3. Identify initial cases of known diseases in new settings\nIn a GIDEON survey of 363 clinicians in the US, UK, and Canada, 35% stated that they would consult a colleague for a second opinion before making clinical decisions. As a close second, 30% indicated that they trust their judgment. This means that 65% of the survey respondents trusted human judgment over Point-of-Care tools.\nBut the stakes are higher when dealing with highly transmissible emerging infections. The importance of first-time diagnosis accuracy is compounded due to the rising urgency to prevent the next epidemic or pandemic.\nConsider the dramatic difference in transmission rates between SARS-CoV-2 and its variants:\n- The B.1.1.7, the ‘Alpha’ SARS-CoV-2 variant, is 43% to 90% more transmissible than its predecessor and led to a surge in hospitalizations across the UK and 114 more countries in a mere few months .\n- 1.617.2 or the ‘Delta’ variant is estimated to be 40% to 60% more infectious than the Alpha, estimated by disease modelers at Imperial College, London, with an R0 as high as 8 .\nHere are some comparisons of how newer, emerging pathogens and their variants compare to older, Infectious Diseases.\n|Pathogen||Transmissibility Rate (R0)|\n|B.1.617.2, SARS-CoV-2 Delta variant||5-8|\n|B .1. 1. 7, SARS-CoV-2 Alpha Variant||4-5|\nIn other words, an outbreak may already be well underway before an Infectious Disease specialist is consulted for assistance on differential diagnosis or a medical librarian is requested for location-specific disease symptoms.\nAs pathogens mutate, traditional methods of differential diagnosis need an upgrade. Clinicians, Infectious Disease specialists, and researchers need data from local outbreaks anywhere in the world at their fingertips to help drive decision-making and advance the global effort against Infectious Disease.\n4. Use a differential diagnosis (DDx) tool like GIDEON’s First Case Scenario to identify Infectious Diseases – faster and more accurately\nDrs Perl and Price champion the need for greater access to digital resources that integrate electronic health records with patient travel histories and can “suggest specific diagnoses in febrile returning travelers.”\nOne of the more well-known DDx tools is GIDEON with its First Case Scenario feature, created in partnership with the World Health Organization (WHO) after the West Nile Fever outbreak in the United States.\nUsing a DDx platform such as GIDEON helps:\n- narrow down possibilities,\n- lead to a faster result,\n- reduce the margin of error at the point-of-care, and\n- elevates peer-to-peer knowledge sharing on a global scale\nWhy is this important? Because, for example, in respiratory viral illnesses, early detection is the critical step to mitigate disease transmission but is often delayed . Depending on the type of pathogen, this could lead to a greater number of hospitalizations, more morbidity, a burden on healthcare systems, and have significant ramifications on a country, its people, and the economy.\nHaving a differential diagnosis platform that incorporates a patient’s travel history can make a huge difference in how the world manages emerging infectious diseases.\nHere’s an example. Suppose a patient presents with elevated body temperature, severe headache, chills, myalgia, diarrhea, and malaise.\nThese are nonspecific presentations and could be representative of a variety of diseases. With international transmission now the norm, no clinician can be expected to keep track of every single emerging disease and its symptoms.\nExample: Diagnosing Ebola using a DDx platform\nStep 1: Focusing on most likely diseases based on symptoms and travel information\nEntering a patient’s symptoms and the locations and dates of travel in a tool like GIDEON’s Bayesian analysis-driven Probability engine can help identify what diseases are most likely to correspond to the data entered. The illustration below shows Ebola as a high probability based on the patient’s symptoms and travel location.\nStep 2: Conduct a differential diagnosis\nThe screenshot of the First Case Scenario feature below shows a 95% probability that the patient has Ebola. What if there were fewer symptoms at presentation, the likelihood of Ebola was 65%, and another disease was 25% probable? You could conduct a differential analysis by comparing the two disease symptoms on the platform, download the comparison, and order the requisite laboratory tests to confirm.\nStep 3: First Case Scenario\nImagine it is 2014, and you haven’t heard of Ebola. A patient walks in with the symptoms listed above. You enter the symptoms and the patient’s travel history. Using GIDEON’s First Case Scenario, you can determine how likely it is that your patient is the first in the country to present with Ebola.\n5. Train an army of global clinicians to battle Infectious Diseases\nBased on a GIDEON survey of 230 clinicians in the US, UK, and Canada, while clinicians were open to using a DDx tool to help diagnose Infectious Diseases, a lack of budget was the primary reason they did not.\nOne physician even stated, “I would use them every day if my institution would offer.”\nBut an interactive platform with a robust database of Infectious Disease symptoms that incorporates patient locations, exposure to disease-causing elements, and comparisons between two or more similar diseases can offer benefits beyond what a seasoned clinician can accomplish.\nIt can train the next generation of Infectious Disease-fighting doctors and healthcare professionals. For example, take GIDEON’s step-by-step Bayesian analysis toolkit. Teaching institutions, medical librarians, medical students, residents, researchers, and more can use DDx tools to help hone their diagnoses of emerging as well as well-known infectious diseases.\nThe tool helps you list symptoms, patient travel information (if any), and any exposure to disease-causing elements (if known). For example, the patient ate chicken in a region that recently had a Salmonella outbreak.\nThe tool offers a list of probable diseases in descending order of probability. It helps that the tool is dynamic because what if the patient forgot a symptom and told you about it later? A new list of probable diseases is re-calculated automatically. An added benefit is that the DDx tool is integrated with the First Case Scenario to determine if a patient’s symptoms are the first in a specific location.\nHealth systems and medical colleges and universities may benefit greatly from such a diagnostic solution.\nWar often provides an opportunity for innovation. After all, the internet was invented because computers at the time were enormous, and it was incredibly difficult to physically transport military intel from the United States to soldiers deployed around the world . And clinicians are actively in a battle against the spread of infectious pathogens.\nA global platform that offers timely location-specific intelligence about emerging infectious diseases and helps speed up clinical decisions is invaluable to future-proof the world against outbreaks, epidemics, and pandemics and save thousands of lives.\nDid you like this article? Share it on social media!\n R. Desbordes, “Spatial dynamics of major Infectious Diseases outbreaks: A global empirical assessment,” J. Math. Econ., vol. 93, no. 102493, p. 102493, 2021.\n B. J. Quilty, S. Clifford, S. Flasche, R. M. Eggo, and CMMID nCoV working group, “Effectiveness of airport screening at detecting travellers infected with novel coronavirus (2019-nCoV),” Euro Surveill., vol. 25, no. 5, 2020.\n T. M. Perl and C. S. Price, “Managing emerging Infectious Diseases: Should travel be the fifth vital sign?” Ann. Intern. Med., vol. 172, no. 8, pp. 560–561, 2020.\n N. G. Davies et al., “Estimated transmissibility and impact of SARS-CoV-2 lineage B.1.1.7 in England,” Science, vol. 372, no. 6538, p. eabg3055, 2021.\n Scientific Advisory Group for Emergencies, “Imperial College London: Evaluating the roadmap out of lockdown – modelling Step 4 of the roadmap in the context of B.1.617.2 (Delta), 9 June 2021,” Gov.uk, 14-Jun-2021. [Online]. Available: https://www.gov.uk/government/publications/imperial-college-london-evaluating-the-roadmap-out-of-lockdown-modelling-step-4-of-the-roadmap-in-the-context-of-b16172-delta-9-june-2021. [Accessed: 15-Jun-2021].\n B. Tarnoff, “How the internet was invented,” The Guardian, 15-Jul-2016.', ""West Nile Virus\nMosquito Control and why it's Important to YOU\nWhat is West Nile Virus (WNV)?\nWNV is a mosquito-borne virus that can cause fever, encephalitis (inflammation of the brain), or meningitis (inflammation of the lining of the brain and spinal cord).\nHow do people get WNV?\nWNV is most commonly spread through the bite of an infected mosquito. WNV can be spread through blood transfusions, organ transplants, and from mother to baby during pregnancy, delivery, or breastfeeding but this is very rare. It is not transmitted from person to person, or from person to animal.\nWhat are the symptoms of WNV?\nMost people (70-80%) infected with WNV do not develop any symptoms.\nIf present, WNV symptoms usually appear 2-14 days after the mosquito bite. Approximately 1 in 5 people infected will develop a fever and possibly headache, body aches, joint pain, vomiting, diarrhea, or rash. Most people with these symptoms recover completely, but fatigue and weakness can last for weeks or months.\nLess than 1% of people infected will develop serious neurologic illness such as encephalitis or meningitis (inflammation of the brain or surrounding tissues). Recovery from severe illness may take weeks or months. Some of the neurologic effects may be permanent. Only about 10% of people who develop neurologic infection due to WNV will die.\nSerious illness can occur in people of any age. However, people over 60 years of age are at the greatest risk for serious illness. People with certain medical conditions, such as cancer, diabetes, hypertension, kidney disease, and people who have received organ transplants are also at greater risk for serious illness.\nSee your health care provider if you have symptoms of WNV.\nWho is at risk for WNV infection?\nAnyone living in an area where mosquitoes are infected with WNV is at risk. WNV has been detected in all states except Alaska and Hawaii. The risk of infection is highest for people who work outside or participate in outdoor activities because of greater exposure to mosquitoes.\nIs there a vaccine or treatment for WNV infection?\nThere is no vaccine or specific treatment for WNV infection.\nPeople with mild symptoms of WNV infection usually recover on their own. Over-the-counter pain relievers can be used to reduce fever and relieve some symptoms. People with severe illness usually need to be hospitalized to receive supportive treatment, such as intravenous fluids, pain medication, and nursing care.\nHow can I prevent WNV?Make you and your home a Bite-Free Zone to prevent WNV and other mosquito-borne diseases.\nWhat is the Chester County Health Department doing to prevent WNV?\n- Provides educational materials. Call 610-344-6490 to request materials.\n- Provides community education. Request a presentation or participation at a community event\n- Responds to complaints of standing water- Chester County Health Department enforces County regulations requiring property owners to dump and drain sources of standing water (ex. tires, pools, containers) which mosquitoes use for breeding. Citations may be issued for failure to comply.\n- Identifies bodies of water containing mosquito larvae.\n- Sets mosquito traps to collect and test adult mosquitoes for WNV – Traps are placed in highly populated areas, known mosquito breeding areas, and in areas where a resident has previously been identified as having a confirmed case of WNV infection. Traps are also placed in response to complaints from residents regarding high levels of mosquito activity.\n- Uses U.S. Environmental Protection Agency-approved products (Bti, Bs, or Methoprene) to kill mosquito larvae in bodies of standing water that cannot be drained.\n- Uses U.S. Environmental Protection Agency-approved products (Permanone or DeltaGard) to kill adult mosquitoes in areas that have high mosquito activity and multiple mosquito samples testing positive for WNV- Spraying is done as a last resort after exhausting all other mosquito control strategies.\n- The Chester County Health Department uses a truck-mounted sprayer to apply 1.5 ounces of the mosquito control product per acre of land. Sprays are conducted after sunset, when mosquitoes are most active and bees have returned to their hives. Sprayers are turned off near bodies of water and apiaries to protect aquatic life and bees. The Chester County Health Department also notifies beekeepers and residents who are listed as hypersensitive in a designated spray area prior to conducting a spray. People who are concerned about exposure to mosquito control products can reduce their potential for exposure by staying indoors with children and pets when their neighborhood is being sprayed. Because the mosquito control spray becomes inactive in just a few hours or with sunshine, it is not necessary to wash off outdoor furniture or playground equipment before use.\n- The Chester County Health Department is a member of the Environmental Protection Agency’s Pesticide Environmental Stewardship Program. This program requires participants to affirm that environmental stewardship is an integral part of their integrated pest management (IPM) practice, use current, comprehensive information regarding the life cycle of mosquitoes within their IPM program, educate the community on the benefits of IPM, and demonstrate a commitment to pesticide risk reduction activities.\n- Investigates reports of WNV illness in residents.\nHow can I find out when a mosquito control spray is being conducted in my neighborhood?\nThe Chester County Health Department notifies residents of sprays at least 48 hours ahead of time through the following channels:\n- News releases sent to the media, legislators, municipalities, etc.\n- Public Health Updates- E-mail updates that residents can sign up for.\n- Chester County Health Department website.\n- Chester County Health Department Facebook and Twitter.\n- Residents in a designated spray area who are listed as hypersensitive are contacted directly by the Chester County Health Department.\nPeople who are concerned about exposure to mosquito control products can reduce their potential for exposure by staying indoors when their neighborhood is being sprayed.\nFor more information, call 610-344-6752 or email firstname.lastname@example.org.\n- Prevent Mosquito-Borne Diseases\n- West Nile Virus Brochure- English, en Español\n- Zika Virus\n- Centers for Disease Control and Prevention- Avoid Mosquito Bites\n- Centers for Disease Control and Prevention- West Nile Virus\n- Penn State Extension- Pennsylvania Pesticide Hypersensitivity Registry\n- Penn State Extension- West Nile Virus\n- Pennsylvania's West Nile Virus Control Program""]"	['<urn:uuid:87c2142f-e9ed-4622-9ec8-cc123ec9551b>', '<urn:uuid:6a411dea-76df-44fc-ae19-1e2dd7a03721>']	factoid	with-premise	short-search-query	similar-to-document	comparison	novice	2025-05-01T23:21:14.341336	6	56	3095
276	I'm trying to understand weather impacts on my outdoor retail business - is there any way to show weather data alongside my sales information on a map?	Yes, using the custom tile layer feature in Azure Maps for Power BI, you can overlay weather data on top of your sales data. For instance, you can display sales data as a bubble layer while showing current weather radar from Azure Maps as a tile layer underneath. This has been demonstrated with a case of sunglass sales, where the visualization clearly showed lower sales occurring in areas experiencing rain.	['The Azure Maps visual for Power BI will be releasing as a preview this week. Power BI is a powerful analysis and visualization tool. Azure Maps is an important tool for gaining geospatial context and insights that can be used in decision making.\nThis initial release includes the following visualization layers:\n- Bubble layer\n- 3D bar chart layer\n- Reference layer\n- Custom tile layer\n- Real-time traffic overlay\nIn addition to these visualization layers, this visual also leverages built-in Power BI features, such as tooltips, color themes, as wells as filter and slicer support.\nBubble layer—represent location data as scaled circles\nBubble layers are a great way to represent location data as scaled circles on the map. Customers can use a linear scaling method or customize the scaling logic using a logarithmic or Cubic-Bezier curve. Additionally, users can pass a value into the legend field and have the fill color of the circles dynamically set; and, outline the circles with a single color or enable the high contrast outline option to have a high contrast variant of the fill color assigned to the circle to help ensure the circles are clearly visible regardless of which style the map is set to. Allowing the user to easily visualize two metrics for each location on the map, scale, and category.\nFor example, the following image shows bicycle accident locations in North Carolina. The color indicates the speed limit of the road the accident occurred on and the size is based on the number of individuals involved in the accident.\n3D bar chart layer—visualize location data as 3D bars or cylinders\n3D bar charts are useful for taking data to the next dimension by allowing visualization of location data as 3D bars or cylinders on the map. Users can tilt and rotate the map by holding down the right mouse button and dragging or use one of the navigation controls to view your data from different perspectives.\nSimilar to the bubble layer, the bar chart later can easily visualize two metrics at the same time using color and relative height. The following map displays store locations with bar heights representing the revenue generated from each location, colored by sales region.\nReference layer—overlay additional data layers to add more context\nPower BI currently allows a single data set to be connected to a visual. However, when working with maps, its often desirable to be able to overlay additional data layers to add more context to a report. With this feature, a GeoJSON file containing custom location data can be uploaded and overlaid on the map. Properties in the GeoJSON file can be used to customize the style of the shapes.\nFor example, the following map image adds a GeoJSON file of census tract boundaries colored by population below a layer of addresses colored by real estate value. This provides insights on how population density is related to property values.\nCustom tile layer—superimpose images on top of Azure Maps base map tiles\nOverlay a custom tile layer on the map to add an additional layer of context. Tile layers allow you to superimpose images on top of Azure Maps base map tiles. Overlay weather data from the Azure Maps weather services or bring your own tile service.\nThe following map displays a bubble layer of sales data of store selling sunglasses above a tile layer showing current weather radar from Azure Maps. In this case, we can easily see that less sales of sunglasses are occurring where it is rain.\nReal-time traffic overlay—see how traffic congestion relates to your data\nUsers can overlay real-time traffic flow data to see how traffic congestion relates to their data. For example, the following map is showing the position of field technicians rendered as a bubble layer on the map colored by their experience level and scaled by the amount of remaining time on their current job. Real-time traffic is overlaid on the map and provides a quick visual reference of which technicians are most likely be delayed getting to their next job due to traffic congestion.\nGet started with the Azure Maps visual for Power BI\nTo get started using the Azure Maps visual, first enable it in the Power BI desktop app. To do this, open the options panel though File > Options and settings. Go to the Preview features options and select the Azure Maps visual. Once this is done you will also be able to use this visual in the Power BI website.\nThis is just the beginning! We have lots of exciting new features planned. Have a feature request? Let us know or vote for an existing request on our feedback site.\nLearn more about the Azure Maps Power BI visual.']	['<urn:uuid:99f31d40-0a04-42f9-9945-3b39436ed55c>']	open-ended	with-premise	verbose-and-natural	distant-from-document	single-doc	novice	2025-05-01T23:21:14.341336	27	70	789
277	Can my family join me if I get a Greek Golden Visa?	Yes, family members can get personal residence permits that are renewed together with the investor's permit. This includes your spouse, children up to 21 years of age, and both your parents and your spouse's parents.	['€250.000 The most affordable in the EU\nA source of Income and fast return of Investment\nFreedom to travel in Europe without a visa\nFree to Establish a Business in Greece\nOptions to resell in the future in a higher price\nFor all the family and parents of investors\nWe make it Simple... We make it Happen!\nHow are third-country nationals entitled to a Greek residence permit:\nThird-country nationals may fall within the provisions of the Code: Law 4251/2014, Government Gazette 1, no 80 (Law of the Immigration and Social Integration), either by making an investment or by acquiring real-estate property.\nMore specifically, Art. 20 of the Code tries to stimulate the domestic land market by regulating the granting of a Greek Residence Permit to third-country nationals investing in real estate properties in Greece with a value of at least € 250,000 through sales, lease or timesharing agreement. The amount of € 250,000 must have been paid in full upon the signing of the respective contract.\nThe above-described residency permit (Golden visa) can be renewed every five years indefinitely, as long as the property remains entirely at the ownership of the main applicant.\nFamily members of the main investor, may be granted a personal residence permit that is renewed and/or expires concurrently with the residence permit of the investor (property owner).\nFamily members considered: the spouse, children up to 21 years of age, applicant’s parents, spouse’s parents.\nPeriods of absence from the country do not constitute a reason for refusal.\nGreek Golden Visa in 10 Simple Steps\nTotal Cost Calculator\nTo have an educated opinion about the total expenses involved, use the application below to calculate the Total Capital needed besides the Property Net Price. The final amount depends on: a) the property price and b) the family members who will join the Golden Visa Programme.\nIt includes Property Transfer Tax, Notarial fees, Legal fees, Government Vouchers, Real Estate Agency fees and Residency Permits related fees.\nNo need to stay in Greece to maintain the right\nThe Golden Visa can be valid indefinitely\nCitizenship eligibility after 7 years of residency\nFree to Establish a Business in Greece\nAccess to public education an Health System\nProperties are freehold (unlimited period)\nLegal Details about Greek Golden Visa Application\nFinancial Criteria & Conditions\nProperty Ownership in Greece will allow owners to obtain a Golden Visa to the following categories of owners:\nAny non-EU national who acquires property worth € 250.000 or more, in their name.\n- Any non-EU national who acquires property worth € 250.000 or more, in the name of a company or other entity of which the said non-EU national is the sole shareholder\n- A couple (husband and wife) of non-EU nationals who jointly buy property worth €250.000 or more. The stake each spouse buys need not be equal\n- Two or more non-EU nationals who buy property provided that the stake each of them acquires is worth € 250.000 or more\n- A non-EU national who has entered into a leasing contract for hotels or other tourist accommodation for a minimum term of ten (10) years, and provided that the lease is worth € 250.000 or more\n- A non-EU national who has entered into a time-sharing agreement for a minimum term of ten (10) years\nWhen can someone apply:\nThe purchase process must have been completed (i.e. the Sale & Purchase Contract must have been registered and the relevant Registration Certificate must have been issued) BEFORE someone can apply for a Residence Permit.\nThe Golden Visa can be valid indefinitely, provided the holder still owns property which meets the criteria granting him the right to obtain it. This is verified every five years and it is the holder’s responsibility to provide the supporting documents providing that he/she is still entitled to keeping the permit. Failure to do so may result in its revocation.\nThe members of the buyer’s immediate family (wife and children) are also entitled to a Residence Permit, as are now their parents and in-laws.\nIssue process duration:\nProvided that all due documents are in order before submission, the Golden visa should be issued within two (2) months of submitting the application with supporting documents, provided the biometric process has been completed, all documents are available at request.\nDocuments issued by a foreign authority should be translated either in English or Greek and duly authenticated.\nIt needs to be clarified that the Golden Visa itself does not grant its holder the right to work in Greece. However, he/she can be a shareholder or stakeholder in a company based in Greece, as well as a member of its Board of Directors or Managing Director.\nVisa Free Travel in The E.U\nThrough the Schengen Area, borders between European countries are only existent on maps. Over 400 million nationals of 26-member countries enjoy the freedom of traveling. Passports checks and border controls within the area are non-existent since every country shares common travel and movement rights.\n- Nationals of any world country, when in the Schengen Area, can liberally cross the internal borders of the Schengen countries, free from border checks\n- Shared standards for crossing the external borders of Schengen countries\n- Harmonized entry and short-stay visa conditions for all Schengen countries\n- No need to travel through Greece in or out but that is possible to or from any Schengen Area Airport.\n….and the EU?\nThe EU, on the other hand, corresponds to the countries that signed the Maastricht Treaty of 1993 – and those that have joined since. These countries form part of the European Union.\nYes, EU residents may move freely across its borders but you should not mistake that for the similar and overlapping movement through the Schengen Area.\nWhat countries are part of each group and what are the differences?\nThe countries that are not included in both groups are the UK and Ireland (which are in the EU but not in Schengen) and Norway, Liechtenstein, Switzerland, and Iceland (which are inside the Schengen Area but not in the EU).\nBulgaria, Romania, Cyprus, and Croatia are in the EU but not currently in the Schengen, however, these four countries are legally obliged to join the Schengen Area and are in the process of joining.\nThis map also explains the difference pretty well…']	['<urn:uuid:2c7d1d0f-a620-4051-a336-1484b863ed99>']	open-ended	with-premise	concise-and-natural	similar-to-document	single-doc	novice	2025-05-01T23:21:14.341336	12	35	1049
278	I'm curious about different ways that humans used animals for transportation in the past - what are some examples of how animals were used for moving people and goods?	Animals have been used in several ways for transport. People could either ride the animals directly, use them as pack animals to carry goods, or harness them alone or in teams to pull sleds or wheeled vehicles.	['Mode of transport is a term used to distinguish between different ways of transportation or transporting people or goods. The different modes of transport are air, water, and land transport, which includes Rails or railways, road and off-road transport. Other modes also exist, including pipelines, cable transport, and space transport. Human-powered transport and animal-powered transport are sometimes regarded as their own mode, but never fall into the other categories. In general, transportation is used for moving of people, animals, and other goods from one place to another. The means of transport, on the other hand, refers to the (motorized) vehicles necessary for transport according to the chosen mode (car, airplane, ship, truck and rail). Each mode of transport has a fundamentally different technological solution, and some require a separate environment. Each mode has its own infrastructure, vehicles, and operations.\nAnimal-powered transport is the use of working animals for the transport of people and/or goods. Humans may use some of the animals directly, use them as pack animals for carrying goods, or harness them, alone or in teams, to pull sleds or wheeled vehicles.\nA fixed-wing aircraft, typically airplane, is a heavier-than-air flying vehicle, in which the special geometry of the wings generates lift and then lifts the whole vehicle. Fixed-wing aircraft range from small trainers and recreational aircraft to large airliners and military cargo aircraft. For short distances or in places without runways, helicopters can be operable. (Other types of aircraft, like autogyros and airships, are not a significant portion of air transport.)\nAir transport is the fastest method of transport, Commercial jets reach speeds of up to 955 kilometres per hour (593 mph) and a considerably higher ground speed if there is a jet stream tailwind, while piston-powered general aviation aircraft may reach up to 555 kilometres per hour (345 mph) or more. This celerity comes with higher cost and energy use, and aviation’s impacts to the environment and particularly the global climate require consideration when comparing modes of transportation. The Intergovernmental Panel on Climate Change (IPCC) estimates a commercial jet’s flight to have some 2-4 times the effect on the climate than if the same CO2 emissions were made at ground level, because of different atmospheric chemistry and radiative forcing effects at the higher altitude. U.S. airlines alone burned about 16.2 billion gallons of fuel during the twelve months between October 2013 and September 2014. WHO estimates that globally as many as 500,000 people at a time are on planes. The global trend has been for increasing numbers of people to travel by air, and individually to do so with increasing frequency and over longer distances, a dilemma that has the attention of climate scientists and other researchers, the press, and the World Wide Web. The issue of impacts from frequent travel, particularly by air because of the long distances that are easily covered in one or a few days, is called hypermobility and has been a topic of research and governmental concern for many years.\nHuman powered transport, a form of sustainable transportation, is the transport of people and/or goods using human muscle-power, in the form of walking, running and swimming. Modern technology has allowed machines to enhance human power. Human-powered transport remains popular for reasons of cost-saving, leisure, physical exercise, and environmentalism; it is sometimes the only type available, especially in underdeveloped or inaccessible regions.\nAlthough humans are able to walk without infrastructure, the transport can be enhanced through the use of roads, especially when using the human power with vehicles, such as bicycles and inline skates. Human-powered vehicles have also been developed for difficult environments, such as snow and water, by watercraft rowing and skiing; even the air can be entered with human-powered aircraft.\nLand transport covers all land-based transportation systems that provide for the movement of people, goods and services. Land transport plays a vital role in linking communities to each other. Land transport is a key factor in urban planning. It consists of 2 kinds, rail and road.\nRail transport is a means of conveyance of passengers and goods by way of wheeled vehicles running on rail track, known as a railway or railroad. The rails are anchored perpendicular to railroad train consists of one or more connected vehicles that run on the rails. Propulsion is commonly provided by a locomotive, that hauls a series of unpowered cars, that can carry passengers or freight. The locomotive can be powered by steam, diesel or by electricity supplied by trackside systems. Alternatively, some or all the cars can be powered, known as a multiple unit. Also, a train can be powered by horses, cables, gravity, pneumatics and gas turbines. Railed vehicles move with much less friction than rubber tires on paved roads, making trains more energy efficient, though not as efficient as ships.\nIntercity trains are long-haul services connecting cities; modern high-speed rail is capable of speeds up to 430 km/h (270 mph), but this requires a specially built track. Regional and commuter trains feed cities from suburbs and surrounding areas, while intra-urban transport is performed by high-capacity tramways and rapid transits, often making up the backbone of a city’s public transport. Freight trains traditionally used box cars, requiring manual loading and unloading of the cargo. Since the 1960s, container trains have become the dominant solution for general freight, while large quantities of bulk are transported by dedicated trains.\nA road is an identifiable route of travel, usually surfaced with gravel, asphalt or concrete, and supporting land passage by foot or by a number of vehicles.\nThe most common road vehicle in the developed world is the automobile, a wheeled passenger vehicle that carries its own motor. As of 2002, there were 591 million automobiles worldwide. Other users of roads include motorcars, motorcycles, buses, trucks, bicycles and pedestrians, and special provisions are sometimes made for each of these. For example, the use of bus lanes give priority for public transport, and cycle lanes provide special areas of road for bicycles to use.\nMotorcars offer high flexibility, but are deemed with high energy and area use, and the main source of noise and air pollution in cities; buses allow for more efficient travel at the cost of reduced flexibility. Road transport by truck is often the initial and final stage of freight transport.\nWater transport is the process of transport that a watercraft, such as a barge, boat, ship or sailboat, makes over a body of water, such as a sea, ocean, lake, canal or river. If a boat or other vessel can successfully pass through a waterway it is known as a navigable waterway. The need for buoyancy unites watercraft, and makes the hull a dominant aspect of its construction, maintenance and appearance. When a boat is floating on the water the hull of the boat is pushing aside water where the hull now is, this is known as displacement.\nIn the 1800s, the first steamboats were developed, using a steam engine to drive a paddle wheel or propeller to move the ship. The steam was produced using wood or coal. Now, most ships have an engine using a slightly refined type of petroleum called bunker fuel. Some ships, such as submarines, use nuclear power to produce the steam. Recreational or educational craft still use wind power, while some smaller craft use internal combustion engines to drive one or more propellers, or in the case of jet boats, an inboard water jet. In shallow draft areas, hovercraft are propelled by large pusher-prop fans.\nAlthough slow, modern sea transport is a highly effective method of transporting large quantities of non-perishable goods. Commercial vessels, nearly 35,000 in number, carried 7.4 billion tons of cargo in 2007. Transport by water is significantly less costly than air transport for transcontinental shipping;short sea shipping and ferries remain viable in coastal areas.\nMicromobility is the collective name for small electric powered vehicles.\nPipeline transport sends goods through a pipe, most commonly liquid and gases are sent, but pneumatic tubes can also send solid capsules using compressed air. For example liquids/gases, any chemically stable liquid or gas can be sent through a pipeline. Short-distance systems exist for sewage, slurry water and beer, while long-distance networks are used for petroleum and natural gas.\nCable transport is a broad mode where vehicles are pulled by cables instead of an internal power source. It is most commonly used at steep gradient. Typical solutions include aerial tramway, elevators, escalator and ski lifts; some of these are also categorized as conveyor transport.\nSpace transport is transport out of Earth’s atmosphere into outer space by means of a spacecraft. While large amounts of research have gone into technology, it is rarely used except to put satellites into orbit, and conduct scientific experiments. However, Man has landed on the moon, and probes have been sent to all the planets of the Solar System.\nUnmanned aerial vehicle transport (drone transport) is being used for medicine transportation in least developed countries with inadequate infrastructure by an american based start-up Zipline.Amazon.com and other transportation companies are currently testing the use of unmanned aerial vehicles in parcel delivery. This method will allow short-range small-parcel delivery in a short time frame.\nComponents of a mode of transport\nA transport mode is a combination of the following:\n- Transportation infrastructure: thoroughfares, networks, hubs (stations, bus terminals, airport terminals), etc.\n- Vehicles and containers: motor vehicles, automobiles, motorcycles, trucks, wagons, trains, ships, and aircraft\n- A stationary or mobile workforce\n- Propulsion system and power supply (traction)\n- Operations: driving, management, traffic signals, railway signalling, air traffic control, etc.\nPurpose of Transport : Freight & Passenger movement and mobility are core components of a transport system.\nComparison of the transport mode by distance travelled\nWorldwide, the most widely used modes for passenger transport are the Automobile (16,000 bn passenger km), followed by Buses (7,000), Air (2,800), Railways (1,900), and Urban Rail (250).\nThe most widely used modes for freight transport are Sea (40,000 bn ton km), followed by Road (7,000), Railways (6,500), Oil pipelines (2,000) and Inland Navigation (1,500).\n|GDP (PPP) per capita (€)||19,000||28,600||26000||7500|\n|Passenger km per capita|\n|Air (domestic except World)||860||2,800||580||480|\n- Cooper et al., 1998: 281\n- Swine flu prompts EU warning on travel to the US. The Guardian. April 28, 2009.\n- The Future of Air Transport White Paper (2009), HMSO “The aviation industry is encouraged to take account of, and where appropriate reduce, its contribution to global warming…The impact of aviation on climate change is increased over that of direct CO2 emissions alone by some of the other emissions released and their specific effects at altitude”.\n- IPCC, Aviation and the Global Atmosphere: A Special Report of the Intergovernmental Panel on Climate Change (2000), Cambridge University Press\n- Why airfare keeps rising despite lower oil prices Archived 2014-11-20 at the Wayback Machine, by Scott Mayerowitz, Assoc. Press Airlines Writer. Houston Chron., November 17, 2014.\n- Cohen, S.; Higham, J.; Cavaliere, C. (2011). “Binge flying: Behavioural addiction and climate change” (PDF). Annals of Tourism Research. 38 (3): 1070–1089. doi:10.1016/j.annals.2011.01.013.\n- Cohen, S. A.; Higham, J. E. (2011). “Eyes wide shut? UK consumer perceptions on aviation climate impacts and travel decisions to New Zealand” (PDF). Current Issues in Tourism. 14 (4): 323–335. doi:10.1080/13683501003653387.\n- Anderson, K.; Bows, A. (2008). “Reframing the climate change challenge in light of post-2000 emission trends”. Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences. 366 (1882): 3863–3882. doi:10.1098/rsta.2008.0138. PMID 18757271.\n- Jenkins S. (2009). Hypermobility is now the opium of the people, an obsession that wrecks communities and planet. The Guardian. 22 Dec. 2009.\n- Rosenthal E. (2010). Can we kick our addiction to flying? Guardian, UK. 24 May 2010.\n- Internet search for travel addiction.\n- Cooper et al., 1998: 279\n- Cooper et al., 1998: 278\n- United Nations Conference on Trade and Development 2007, p. x and p. 32.\n- Stopford, 1997: 4–6\n- Stopford, 1997: 8–9\n- Cooper et al., 1998: 280\n- “Zipline – Lifesaving Deliveries by Drone”. flyzipline.com. Retrieved 2019-04-11.']	['<urn:uuid:583483e4-6042-4545-9f6a-694cc6fc4533>']	open-ended	with-premise	verbose-and-natural	similar-to-document	single-doc	novice	2025-05-01T23:21:14.341336	29	37	2000
279	marine scientist here terrapin keystone species significance	The diamondback terrapin is a keystone species whose presence contributes to a diversity of life and whose extinction would consequently lead to the extinction of other forms of life. The Wetlands Institute has focused on terrapin research and educational programming for two decades, and their terrapin project has received national attention from major media outlets.	['Terrapin Station, is the first exhibit in the world that is dedicated to the life history of the diamondback terrapin. Visitors can learn more about this landmark conservation project through a variety of informational displays. We take you through the life and troubles of the native turtles from birth and learn what the Institute is doing to help them.\nThe diamondback terrapin is a keystone species whose very presence contributes to a diversity of life and whose extinction would consequently lead to the extinction of other forms of life. Since the Wetlands Institute values the importance of diamondback terrapins to wetland habitats, terrapin research and educational programming has been the focus of our conservation efforts for two decades. In fact, our diamondback terrapin project has received national attention from ABC and NBC News, New York Times and the National Geographic Society.\nOur Aquarium features over a dozen exhibits with live marsh animals as well as a special “teacher’s tank” with live horseshoe crabs, sea stars and lots more. It also houses hands-on, interactive exhibits designed to immerse visitors in the wetlands life, educating the observer in the important role wetlands play in life on the planet.\nThe Marshview Hall, has expansive views of the surrounding marsh. Visitors can examine a variety of wildlife art and carvings. The hall features several hand-carved wooden bird mobiles that are visually breathtaking. We also showcase our hand-sewn quilts.\nDuring the summer, possibly the most exciting feature of Marshview Hall is the mini camera mounted on top of a nearby osprey nest which allows up-close views of nesting osprey on the hall’s large television monitor.\nThe hall is also available for private events, be they corporate meetings, weddings or social gatherings.\nPlans for a new elevated walkway began after destruction of the old wooden walkway during Hurricane Sandy in October 2012. Reconstruction was an opportunity to rethink the possibilities for the walkway and reposition it for improved access to the marsh for both research and education. Construction was completed over the winter and early spring 2014 and the walkway was open to the public in mid-May.\nThe walkway design and construction was carefully conceived to balance providing access to the marsh for visitors to learn about the marsh ecosystem without impacting the fragile ecosystem. It was also designed to be more resilient to storms and rising sea level – two important factors.\nThe winter construction was designed to cause minimum impact to marsh grasses that are dormant through the winter and to minimize disturbance to birds and animals that use the marsh during migration stopovers and for the nesting osprey.\nThe walkway is a 720 foot long loop with an extension for better viewing of the front salt panne. The walkway can be accessed by ADA compliant ramps at two locations from the Institute’s shelled nature trail during Institute business hours.\nThe walkway stands 4 ft from the marsh at its base and is 6 ft wide. Aluminum railings line the elevated walkway, ramps, and stairways for safety. Two sets of stairs allow restricted access for Institute personnel leading research and education programs.\nResearch and education stations on the new elevated walkway provide for improved access to the marsh for biological and environmental sampling and hands on learning opportunities.\nThe walkway is constructed using state-of-the-art methods, is sustainably constructed and utilized local contractors and locally sourced material to the extent possible. The walkway utilizes a steel helical pile construction. Piles were cork-screwed into the marsh and extend on average 30 feet below the marsh surface until they reached a lower compact sand layer. The main walkway structure was locally fabricated and is aluminum.\nThe grated surface is polycarbonate and is specially designed to allow sunlight and rainwater to reach the plants and animals below and reduce the overall impact to the marsh. Since water can flow through this surface, the walkway has a better chance at surviving major flooding events and storms. Because the entire structure is metal with polycarbonate, there is no lift associated with flooding, making likelihood of damage during rising water levels in storms less. The entire structure can be recycled – if ever necessary.\nThe project was designed and executed to impose minimal impact to the salt marsh. The salt marsh vegetation is growing back very well and should fully recover in the coming weeks. There are two areas with more impact. Institute staff and volunteers are planting 15,000 plugs of Smooth Cordgrass (Spartina alternaflora) in disturbed areas by late-May.\nAll work on the marsh required the use of matting to distribute the weight of heavy equipment and prevent rutting. Decking was installed in 40 ft’ prefabricated sections to increase the speed of installation and decrease time on the marsh. Nearly 90 – 2 7/8” helical steel pilings were installed for a small footprint and strong hold in the marsh. Surveys and boring tests of the marsh were conducted in advance to determine piling locations and elevations.\nThe costs of the new walkway are covered in part by a FEMA Disaster grant following the destruction of our previous walkway during Hurricane Sandy in October 2012. Remaining costs will be funded through donations.\nAll necessary permits were obtained and have all conditions of the permits have been met. Pilings were in place before March 15, as a condition of NJDEP permits. The old boardwalk was removed in early 2014, also as per permit.\nContractors (NJ based, and all in 2 county area): Titan Shoring and Construction (construction), Dixon and Associates (engineering), Blue Water Welding (fabrication), The Lomax Consulting Group (environmental review and compliance).\nSalt Marsh Trail\nMore than a year has gone by since Hurricane Sandy’s wrath took aim on our region and put a damper on programing at The Wetlands Institute by destroying our dock. Deprived of much needed access to Scotch Bonnet Creek, we had to cancel some of our summer activities including back-bay boating tours on the Skimmer, hooked on fishing and crabbing at the dock. But with much determination, we managed to revise our programming and have a very successful season.\nOur back-bay kayak tours were launched from alternate locations. We even made do with the low tide which left us little access to water during our Crabulous Crab Day. Our visitors enjoyed a full schedule of programs but it wasn’t quite the same. We were missing an integral part of our facility.\nAnother significant challenge brought on by the loss of our dock was the loss of our salt water pumping system. This system is used to pump water along the quarter-mile long Salt Marsh Trail to maintain our aquarium. Losing this system meant having to haul water by truck in a 500 gallon tank every week.\nThe new dock was officially opened to the public in September, during our 1st Annual Fall Migration Festival. And it was well worth the wait! The 122 foot long structure is higher and is constructed of all new non-polluting materials. Its railing system has two heights providing safe and great views for kids. We have boat slips for our 2 research boats and an area for the Skimmer to dock. Gates provide access to water monitoring research equipment that will be installed in the spring. A new submerged pump has the pumping facility back on line.\nThe rebuilding was made possible through your generosity. We couldn’t have done it without all your support and we are thrilled to be back in business and better than before. The McLean Contributionship supported the project with a $15,000 grant and contributions to The Wetlands Institute’s Sandy Rebuilding Fund raised more than $40,000. The remaining funds will come from a Federal Emergency Management Agency disaster assistance grant.\nAlthough it made for a challenging year, the setback brought by Sandy has not affected our motivation to keep moving forward. Our rebuilding efforts continue. We are about to begin construction on a new and expanded elevated loop boardwalk to replace teh damaged walkway. We have substantial expenses to complete this construction. A FEMA grant will pay $100,000 of the estimated $250,000 cost of the new boardwalk but we need to finish construction this winter to qualify for the grant. So we still have much to do!\nThese are exhilarating times at The Wetlands Institute as we build a center of excellence in research, conservation and education.\nWe are grateful to all of you and hope you will continue to support our rebuilding. Hope to see you soon enjoying our new facilities.']	['<urn:uuid:496b6f2e-8792-4c6d-be88-df98865900f9>']	factoid	with-premise	short-search-query	distant-from-document	single-doc	expert	2025-05-01T23:21:14.341336	7	55	1415
281	What role do fats play in muscle building, and why should I avoid fatty foods before exercise?	Healthy fats found in foods like avocados, nuts, and seeds are essential for hormone production and muscle recovery. However, you should avoid consuming high-fat foods, including nuts and nut butters, before working out because they take longer to digest and can make you feel sluggish. This happens because blood is diverted to your digestive system instead of your muscles, and too much fat can prevent carbs from quickly fueling your muscles.	"['Building muscle, or muscle hypertrophy, involves the enlargement of muscle cells, leading to increased muscle size and strength. It is a challenging yet rewarding process that requires a combination of resistance training, proper nutrition, and adequate rest. Whether you’re a seasoned athlete or a fitness enthusiast, understanding the fundamentals of muscle building is crucial for achieving your fitness goals.\nResistance Training: The Cornerstone of Muscle Growth\nResistance training, also known as strength training, forms the cornerstone of muscle-building endeavors. It involves challenging your muscles with external forces, such as weights, resistance bands, or your own bodyweight, to promote muscle adaptations and stimulate growth.\nProgressive Overload: The Key to Continuous Muscle Growth\nProgressive overload is a fundamental principle in resistance training that involves gradually increasing the intensity, volume, or frequency of your workouts over time. This consistent challenge is essential for continuously stimulating muscle growth and preventing plateaus.\nCompound Exercises: Building Strength and Muscle Mass\nCompound exercises are those that target multiple muscle groups simultaneously, such as squats, deadlifts, bench presses, rows, and overhead presses. These exercises are highly effective for building muscle mass and strength as they engage a greater number of muscle fibers.\nTargeted Exercises: Sculpting Specific Muscles\nWhile compound exercises are crucial for overall muscle development, targeted exercises can help refine and sculpt specific muscle groups. These exercises, such as bicep curls, tricep extensions, and lateral raises, isolate specific muscles and promote their growth.\nTraining Frequency: Striking a Balance\nThe frequency of your resistance training sessions depends on your individual needs and fitness level. However, as a general guideline, aim for 2-3 resistance training sessions per week, allowing adequate rest between workouts for muscle recovery.\nNutrition: Fueling Your Muscle-Building Journey\nNutrition plays a pivotal role in providing the essential building blocks for muscle growth and repair. A balanced diet rich in protein, carbohydrates, and healthy fats is essential for fueling your muscle-building endeavors.\nProtein Intake: The Building Blocks of Muscle\nProtein is the primary component of muscle tissue, and consuming sufficient protein is crucial for muscle synthesis and growth. Aim for a protein intake of approximately 0.8–1 gram per pound of body weight daily.\nCarbohydrate Intake: Providing Energy for Workouts\nCarbohydrates provide the energy needed to fuel your workouts and replenish muscle glycogen stores. Aim for a moderate carbohydrate intake, adjusting based on your individual needs and energy expenditure.\nHealthy Fats: Supporting Hormone Production and Overall Health\nHealthy fats, such as those found in avocados, nuts, and seeds, are essential for hormone production and overall health. They also play a role in nutrient absorption and muscle recovery.\nRest and Recovery: Essential for Muscle Growth and Repair\nRest is just as important as training when it comes to muscle growth and repair. Adequate rest allows your muscles to recover from the stress of resistance training and rebuild stronger muscle fibers.\nMuscle Recovery: Prioritizing Sleep and Active Recovery\nAim for 7-9 hours of quality sleep each night to optimize muscle recovery and hormone production. Additionally, engage in light activities like yoga or walking on rest days to promote blood flow and muscle recovery.\nAdditional Tips for Enhancing Muscle Growth\nHydration: Stay hydrated throughout the day to optimize muscle function and nutrient transport.\nWarm-up and cool-down: Always warm up before workouts to prepare your muscles, and cool down afterward to promote recovery.\nForm and Technique: Prioritize proper form and technique to maximize muscle engagement and prevent injuries.\nProfessional Guidance: Consider consulting a certified personal trainer or dietitian for personalized advice and support.\nEmbrace the Journey of Muscle Building\nBuilding muscle requires dedication, consistency, and patience. It is a journey that takes time and effort, but the rewards are well worth it. By following these guidelines, making gradual adjustments, and listening to your body, you can achieve your muscle-building goals and enhance your overall fitness. Remember, consistency and adherence to proper training and nutrition are the keys to unlocking your muscular potential.\nFoods need to be ignored.\nThe idea of ignoring specific foods completely for building muscle is somewhat misleading. It’s more about prioritizing a balanced and nutritious diet while limiting certain types of food that can hinder your progress.\nHere are some food categories that you should minimize when aiming for muscle growth:\n1. Processed foods:\nHighly Processed Snacks: Chips, cookies, pastries, and other highly processed snacks are packed with empty calories, unhealthy fats, and added sugars. These offer little to no nutritional value and can negatively impact your muscle-building efforts.\nProcessed Meats: Sausages, bacon, and other processed meats are high in saturated fat and sodium, which can negatively impact your heart health and overall well-being. Opt for lean protein sources like chicken, fish, and beans instead.\n2. Sugary Drinks:\n- Sodas, energy drinks, and sugary juices: These drinks are loaded with sugar and calories, which can contribute to weight gain and hinder muscle growth. Replace them with water, unsweetened tea, or homemade smoothies for hydration and nutrient intake.\n3. Refined Grains:\n- White bread, pasta, and pastries: These are made with refined grains stripped of their fiber and nutrients. Choose whole-grain options like brown rice, whole-wheat bread, and quinoa for sustained energy and fiber intake.\n4. Fried Foods:\n- Fried chicken, French fries, and other deep-fried foods are high in unhealthy fats and calories, which can contribute to inflammation and hinder muscle recovery. Opt for healthier cooking methods like baking, grilling, or steaming.\n- Alcohol consumption can disrupt sleep, impair muscle recovery, and hinder muscle growth. Minimize alcohol intake for optimal muscle-building results.\nModeration and Balance:\nRemember, moderation is key. It’s not about eliminating these foods entirely but rather limiting their consumption and focusing on a balanced diet rich in whole foods, protein, complex carbohydrates, healthy fats, and fruits and vegetables. Read more blogs here.\nFocus on incorporating nutrient-dense options for optimal muscle growth.\n- Lean protein sources: chicken breast, fish, eggs, beans, lentils, and tofu.\n- Complex Carbohydrates: Whole-grain bread, brown rice, quinoa, sweet potatoes, fruits, and vegetables\n- Healthy fats: avocados, nuts, seeds, olive oil, and fatty fish.\nBy prioritizing a balanced diet and limiting the intake of the mentioned food categories, you can create an environment conducive to building muscle and optimizing your overall health.', ""10 Foods You Should Avoid Before a Workout\nWhat you eat can make your workout, but sometimes what you don't eat can be just as important. Here are the foods to avoid before you break a sweat.\nThere’s an entire industry built around hydrating and fueling up for workouts. But you may not pay as close attention to the foods you should avoid. Having the wrong stuff in your gut can prevent your workout from being as effective as it could be—or, worst case scenario, give you GI issues. “There’s no one-size-fits-all recommendation,” says Leslie Bonci, director of sports nutrition at the UPMC Center for Sports Medicine in Pittsburgh, Pennsylvania. “It depends on how long you’re working out, at what intensity, your weight goals, your gut tolerance.” There are, however, some basic truths when considering what will maximize your performace—and what will sabotage it.\nFuel for thought\nYour main goals in eating before a workout are to stay hydrated and to fuel your exercise. One of the most common mistakes people make is overestimating how many calories they’ll need. Generally, Bonci says, you’ll want to make sure to eat within two to three hours of a workout. But you don’t need much—around 200 calories will do it for a typical moderate- to high-intensity one-hour session. For that reason, and especially if you’re trying to lose or maintain your weight, she suggests incorporating that pre-workout nosh into a meal or splitting your meal to eat half before your workout and half after. That way, you’re less likely to overconsume calories.\nIf you don’t eat or hydrate enough before a workout, you may not have the stamina to keep pushing through. But if you eat too much, it can divert blood away from your muscles to your digestive system, slowing you down. You need to strive for a happy medium. Bonci says about 14 to 20 ounces of liquid an hour before you exercise is a good rule of thumb. And as far as food goes, you’ll want a mix of protein and carbohydrates for fuel. “What you eat before you work out won’t be immediately available as an energy source for you,” says Bonci, “but it will help prevent hunger and keep your body from tapping into muscle stores to get energy.”\nYour body needs carbs as a quick source of energy, but you can easily overdo it. “Carb loading doesn’t mean carb bloating,” says Bonci. You want a moderate amount of complex carbohydrates (whole grains over white pasta and bread), and you need enough fluids to help your body use those carbs as an energy source. (Watch out for these other fitness myths that can seriously damage your health.)\nLa Croix is lovely, but bubbly drinks shouldn’t be your choice for hydration, according to Bonci: The carbonation can cause gas and bloating, neither of which are great for an exercise routine. “Carbonation can also delay fluid getting to your muscles,” she says. Skip the sparkling water and even the kombucha, which can be fizzy.\nThere are a lot of sugary liquids masquerading as energy drinks, claiming to replenish electrolytes and help you work out harder. The problem, Bonci says, is that overhydrating can bring too much fluid into your stomach with not enough exiting, which can be detrimental to your workout. She recommends looking for a drink that has between 14 and 15 grams of carbs per 8 ounces and chugging only a single bottle. If your workout is less than an hour, you can drink water during exercise itself.\nToo much caffeine\nAlthough studies suggest that caffeine can boost your performance and reaction times, that’s only true for moderate levels (around 200 milligrams). Because the average 12-ounce cup of coffee is easily 250 to 300 milligrams, warns Bonci, you’re better off limiting yourself to a half cup. And the same rule applies to energy gels, goos, and bars spiked with caffeine, so read labels carefully.\nPotassium can help ease muscle cramping, but people tend to go a bit overboard. “Potassium loss during exercise is pretty minimal,” says Bonci. “If you’re eating a decent diet, you’re probably getting enough potassium already.” (Don’t miss these fat-burning foods that can help you lose weight.)\nFull of plant-based protein, fiber, and antioxidants, beans are one of the healthiest meals you can have. But beans, like other high-fiber foods, do have the unfortunate side effect of bloating and gas, which can interfere with your workout and cause unwanted GI symptoms, says Kelly Pritchett, PhD, RD, national spokesperson for the Academy of Nutrition and Dietetics. If you’re one of the lucky people who have a high tolerance for beans (and suffer minimal gas), you don’t have to worry. But if you aren’t used to eating them often or have experienced issues when eating them in the past, it’s probably best to avoid the three-bean salad until after your workout.\nThey’re delicious and healthy, thanks to all their healthy mono- and polyunsaturated fats. However, they can weigh you down during exercise. “High-fat foods keep you satiated longer because they take more time to digest,” says Pritchett. “But they may leave you feeling sluggish as your body is trying to digest them.” That’s mainly because your blood and other bodily resources are diverted to your digestive system, not your muscles. Too much fat of any kind can also prevent carbs from leaving the stomach quickly enough to fuel muscles. That’s why it’s best to avoid high-fat foods, including things like nuts and nut butters, as well as unhealthy fried foods, before a workout. (Look out for these 15 food myths that are making you gain weight.)\nYes, it seems counterintuitive, but those leafy greens and chopped veggies aren’t ideal pre-workout. They equal a lot of water and fiber but not a lot of protein, carbs, or calories—and you need adequate amounts of those to push through your workout, says Bonci.\nThis veggie’s star has been on the rise thanks to its cancer-fighting properties and other benefits. But members of the Brassica family including broccoli, Brussels sprouts, and cabbage are known to cause bloating and gas due to an indigestible sugar called raffinose. Because GI distress can hamper even the most committed gym goer, it’s best to save these veggies for after you hit the showers. (Check out these foods fitness pros eat to refuel after a workout.)\nWhile foods with low- to no-cal sugar substitutes are tempting when you’re trying to shed pounds, they’re a bad idea pre-workout: They’re another substance that can cause gas and bloating. What’s more, says Bonci, it’s a myth that sugar before a workout is terrible. It provides quick energy, she says, and you’re less likely to suffer a post-sugar energy dip: “Exercise activates hormones that help prevent a blood sugar crash.” Just don’t go crazy. “Sugar takes longer to leave the stomach, so if you eat a concentrated source of carbs like candy, you’ll run into problems.”\nStick with the familiar\nAnother good rule to follow when fueling up: Now is not the time to get creative or try something new. “It’s best to stick with a pre-exercise meal that the body is used to,” says Pritchett. That way, you won’t have any unexpected side effects and your body can function at its optimal levels. (Check out the 10 foods that can maximize your workout.)\nWhat really works\nSo what makes a good pre-workout snack? Bonci likes to aim for a mix of carbs, protein, and a touch of healthy fats—all of it 200 calories or less. Some of her go-tos include a six-inch tortilla thinly spread with dark chocolate, peanut butter, and half of a sliced banana; she also likes a smoothie made with half a cup of fruit, soy milk, yogurt, and a smear of nut butter. “Liquids like smoothies leave the stomach more quickly, which means they get energy to the rest of your body faster.” Regardless of what sounds most delicious and nutritious to you, just make sure you eat something before you exercise. “Even if you’re trying to lose weight, exercising on an empty stomach is not as efficient because you can’t work out up to your potential,” Bonci says. Plus, you’re likely to be hungrier as a result and overdo it at your next meal. Next, find out which post-gym mistakes could be ruining your workout.""]"	['<urn:uuid:3f7d0178-2fc5-4116-9cbf-73122eb9ee45>', '<urn:uuid:2853344d-2ba2-45b2-b62b-9e71a896bb22>']	factoid	direct	verbose-and-natural	similar-to-document	multi-aspect	novice	2025-05-01T23:21:14.341336	17	71	2419
282	Which creates more environmental problems: modern soil sensors or Third Revolution farming?	Third Revolution farming created more environmental problems, using chemical fertilizers and pesticides that led to soil erosion and pollution. In contrast, modern soil sensors help reduce environmental impact by enabling precise resource use and minimizing fertilizer runoff.	['Smart agriculture, also known as precision agriculture, is revolutionizing the farming industry by utilizing advanced technologies to optimize crop production. One crucial aspect of smart agriculture is the use of soil sensors, which provide real-time data on soil conditions, enabling farmers to make informed decisions and enhance crop growth. This article explores the significance of soil sensors in smart agriculture and highlights their role in boosting crop growth for sustainable farming practices.\nThe Importance of Soil Health in Crop Growth:\nHealthy soil is vital for successful crop growth and achieving high yields. Soil composition, moisture levels, nutrient content, and pH balance all play a significant role in determining plant health and productivity. Monitoring these soil parameters is essential for optimizing crop growth and resource management.\nSoil Sensors in Smart Agriculture:\n2.1. Types of Soil Sensors: Soil sensors come in various types, including moisture sensors, nutrient sensors, temperature sensors, and pH sensors. Each sensor type measures a specific parameter critical for crop growth and provides valuable data for precision farming. 2.2. Real-time Data Collection: Soil sensors are designed to collect real-time data on soil conditions. They can be installed at different depths within the soil profile, allowing for monitoring of both surface and subsurface conditions. This real-time data empowers farmers to make timely adjustments and optimize irrigation, fertilization, and other agronomic practices. 2.3. Wireless Connectivity: Many soil sensors are equipped with wireless connectivity, enabling seamless data transmission to a central system or farm management software. This connectivity allows farmers to remotely access and analyze soil data, making it easier to monitor and manage large agricultural landscapes.\nBenefits of Soil Sensors in Boosting Crop Growth:\n3.1. Precision Irrigation Management: Soil sensors provide accurate and localized information about soil moisture levels, enabling farmers to optimize irrigation practices. By avoiding overwatering or underwatering, crops receive the right amount of water at the right time, minimizing water waste and reducing the risk of diseases associated with excess moisture or drought stress. 3.2. Nutrient Management: Soil sensors can measure nutrient levels in the soil, allowing farmers to apply fertilizers precisely where and when they are needed. This targeted approach improves nutrient uptake by plants, minimizes fertilizer runoff, and reduces environmental pollution. 3.3. pH Balance Monitoring: Soil sensors that measure soil pH help farmers monitor and adjust soil acidity or alkalinity. Maintaining the appropriate pH level is crucial for nutrient availability and uptake by plants. By optimizing pH balance, farmers can create ideal conditions for crop growth and maximize productivity. 3.4. Early Detection of Soil Problems: Soil sensors provide continuous monitoring, allowing farmers to detect potential soil problems early on. For example, sensors can identify areas with poor drainage, compacted soil, or high salinity levels. With this information, farmers can take corrective actions promptly, preventing crop damage and yield losses. 3.5. Data-driven Decision Making: By collecting and analyzing soil sensor data, farmers gain valuable insights into crop growth patterns, soil trends, and specific field conditions. This data-driven decision-making approach helps optimize resource allocation, crop rotation strategies, and overall farm management practices.\nIntegration with Other Smart Agriculture Technologies:\nSoil sensors can be integrated with other smart agriculture technologies to create a comprehensive precision farming system. Integration with weather stations, satellite imagery, and crop management software enhances the effectiveness of soil sensor data, providing farmers with a holistic view of their fields and enabling precise and proactive decision making.\nChallenges and Future Directions:\nWhile soil sensors offer significant benefits for boosting crop growth and improving farming practices, there are challenges that need to be addressed. These include sensor accuracy and calibration, data interpretation, cost-effectiveness, and scalability for large-scale farming operations. Future developments should focus on standardizing data collection protocols, developing user-friendly interfaces and analytics tools, and reducing sensor costs to make them more accessible to farmers.\nSoil sensors play a critical role in smart agriculture by providing real-time data on soil conditions. By utilizing soil sensors, farmers can optimize irrigation, nutrient management, and pH balance, leading to enhanced crop growth and improved resource efficiency. The integration of soil sensors with other smart agriculture technologies enables farmers to make data-driven decisions, resulting in sustainable farming practices and higher yields. Continued research, technological advancements, and widespread adoption of soil sensors are essential for transforming the agricultural industry and ensuring food security in a rapidly changing world. Smart agriculture empowered by soil sensors holds great promise for a more productive, efficient, and sustainable future.', 'The First Agricultural Revolution dates to 8,000 BC where humans moved from a hunter-gather lifestyle to a more sedentary lifestyle where plants and animals became domesticated. Though it was very labour intensive for a small yield it was the largest factor that lead to the expansion of human populations. The Second Agricultural Revolution then developed in line with the Industrial Revolution. Here new technology reduced the labour load, improved yield and increased productivity. Again, this resulted in global population increases. The Third Agricultural Revolution came in the late 20th century and resulted in biotechnologies such as genetic engineering, GMO’s, chemical fertilizers and pesticides. This led to further intensification and maximised yield.\nAlthough these advancements have been paramount in human development, improving well-being and providing food globally at an affordable price it has had negative effects on the environment. Agriculture is one of the biggest contributors to climate change from both production of greenhouse gases and the removal of forests for agricultural land. It can also negatively affect nearby environmental systems due to over-use of fertilisers and poor land management; reducing biodiversity and affecting water systems. Intensive farming practices are also having a negative impact on soils resulting in a 33% loss of arable land over the last 40 years due to erosion or pollution. Not only does this have impacts for the environment but also for global food security.\nBut hope is on the horizon. We are now heading into a Fourth Agricultural Revolution where technology will be a paramount tool to improve agricultural efficiency, reducing waste and reducing reliance on chemical fertilisers. In a concept called precision farming, technology and data collection can be used to accurately examine crop conditions and determine the correct management, water or fertiliser use, with the aim of optimising returns while reducing inputs. Examples of technologies include the following:\nUsing smart sensors and devices to obtain large amounts of data gives farmers better decision-making capabilities. The data can be used to predict yield, prevent food spoilage and to provide risk management.\nThese are self-driving agricultural robots that use advanced tools to identify and harvest ripe fruit, carefully picking them from branches in order to improve fruit quality and avoid disrupting the environment. They can also be used to monitor crops, water and soil to improve management.\nAccording to PwC analysis drone technology is valued at $127 billion across industries. In agriculture drones are used to take high quality images on the farm that assist in providing farm maps and layouts to analysis soil quality, to inform irrigation and nitrogen management. These images are also useful in monitoring crop condition; identifying problem areas where efficiency and productivity is low. In addition to providing visual imagery drones are also being developed to take an active part in farming. Start-ups are developing drones that shoot pods that contain seeds and nutrients to allow the plant to grow, into the soil. This reduces soil disruption and erosion and is more precise than heavy machinery. Drones can also be used to more accurately dispense fertilisers by aerial spraying of the chemicals.\nThese are just a few of the applications of technology in agriculture that are currently being developed. This digital revolution will not only be important for improving environmental well-being but will also profitability of farms and assessing the risks associated with climate change on farm systems.']	['<urn:uuid:8493b677-9308-44e1-9284-2c6412f2f9e4>', '<urn:uuid:d6a9dd13-16dd-4109-aa9c-ee8d0fdbe042>']	factoid	with-premise	concise-and-natural	similar-to-document	comparison	novice	2025-05-01T23:21:14.341336	12	37	1290
283	human body systems movement expression creative dance compare metabolic effects sedentary behavior	While the human body systems can be expressed and understood through creative movement and dance (involving activities like mirroring body actions and choreographing system functions), there are important metabolic differences between movement and sedentary behavior. During standing and movement, postural muscles are continuously contracting, particularly in the lower limbs, while prolonged sitting suppresses fat metabolism hormones and reduces glucose uptake by skeletal muscles. Even small movements and standing can have beneficial metabolic effects compared to uninterrupted sitting.	"['Developing Arts Literacies:\nUnderstanding Genres, Analyzing and Evaluating - Critique\nIn this lesson, students will create movement patterns that express information about the basic systems, organs, and processes of the human body. They will work in pairs and in groups to make movement choices that communicate scientific concepts in creative movement, and make inquiries, through research and movement experimentation, into the ways in which the body\'s systems work and how those systems interact.\nDiscover and create movement patterns that express information about the basic systems, organs, and processes of the human body.\nMake inquiries, through research and movement experimentation, into the ways in which the body\'s systems work and how those systems interact.\nWork alone, in pairs, and/or in small groups to make movement choices that communicate scientific concepts in creative movement.\nWhat You\'ll Need\n1 Computer per Classroom\nTeachers should familiarize themselves with the vocabulary that will be used to describe body systems using these materials.\nLarge Group Instruction\nStudents with visual impairments or disabilities may need modified handouts or texts. Students with physical disabilities will need modified movement options.\nResources in Reach\nHere are the resources you\'ll need for each activity, in order of instruction.\n1. Have students explore the BBC\'s "" Students can learn about the systems of the body as they explore each game-like interactive. As students are exploring, you may wish to have them choose one system in the body to which they should pay particular attention. Interactive Body,"" a series of expeditions into the body.\n1. Assign five small groups to each work on one system of the body using the BBC\'s ""Interactive Body"" for research. Students should take notes as they research. Provide written resources for background information on:\nFive of the major systems of the body - Circulatory, Respiratory, Nervous, Muscular-Skeletal, and Digestive\nOrgans and components of each system\nBasic terminology of each system (esophagus, peristalsis, alveoli, capillary, valve, synapse, digestion, neuron, etc.)\n2. Discuss parts of the systems, such as blood vessels, lungs, muscle fibers, nerve cells, and stomach. Link systems with elements of dance—for example, breathing and energy or time (rhythm), circulation and space (pathways).\n3. Have students create movements that represent the following words taken from the body\'s systems in action, such as: beat, inhale, push, connect, float, churn, etc. Have students move through the general space, using the given words as the movement stimulus. Have them freeze between movements, and call attention to the interesting or unusual or evocative shapes they form as they remain frozen.\n4. Demonstrate or model an action from the body that was discovered (such as the heartbeat) during their tour of BBC\'s ""Interactive Body"" without telling the students what the action is. Have students guess, then discuss the answers.\n1. Have students perform mirror actions in pairs. Divide students into pairs. Have partners face one another, with one as leader and one as follower. Give them one action word at a time. The leader does the action while the follower attempts to move like the leader\'s mirror image. Alternate who leads as you go through the word list (including words such as: beat, inhale, push, connect, float, digest, flow, churn, etc.) Allow time for partners to discuss afterwards.\n2. Have students perform complementary actions in pairs. While partners are still facing each other, repeat the word list (or use new words suggested by the group). This time the leader moves freely as the responder attempts to move in complementary fashion. Example: the leader ""chews"" at a high level, and the responder does a similar action at low level. Discuss the activity after each partner has had a chance to lead and respond.\n3. Explain to students that they will, within their groups, choreograph a simple dance that expresses information about how an organ or a major system functions. The guidelines for the choreography are:\nEach performance must have a beginning, a middle, and an end; the beginning gets our attention, the middle is the movement content, and the end lets us know you are finished.\nOnly the body can be used; neither props nor vocal sound effects can be used.\n4. Give students some ground rules for working on choreography within their groups:\nEveryone in the group must have a job. This means that everyone must take part in all phases of the work, from choreography to rehearsal to performance.\nUse your time wisely. Don\'t waste time on things that don\'t help you create your assigned work.\nSafety first! The floor is hard; you are not. And don\'t scare your audience (that is, you may startle them, but don\'t make the audience fear for your safety!).\n5. Circulate around the room and offer feedback or suggestions when needed. (Note: Resist the temptation to choreograph for the groups; each piece must be wholly the students\' work.) Some examples of constructive feedback are: Can you choose just a part of the system to demonstrate? How will you express through movement only a part, instead of the whole system? Which systems, organs, or parts have the most movement possibilities? The most interesting shapes?\n1. Have each group share their initial results, the ""first drafts,"" with the class. Videotape if possible. Guide a discussion of each group\'s presentation, asking students to be sure to keep all comments positive and constructive.\n2. During the next class period or two, allow students time to re-work their choreography. Have students keep a detailed record of their process and the changes they make to their choreography and final piece. You may wish to videotape each draft or iteration for a comparative record of the process.\nThroughout the nation, standards of learning are being revised, published and adopted. During this time of transition, ARTSEDGE will continually add connections to the Common Core, Next Generation Science standards and other standards to our existing lessons, in addition to the previous versions of the National Standards across the subject areas.\nThe Arts Standards used in ARTSEDGE Lessons are the 1994 voluntary national arts standards. The Arts learning standards were revised in 2014; please visit the\nNational Core Arts Standards ( http://nationalartsstandards.org) for more. The Kennedy Center is working on developing new lessons to connect to these standards, while maintaining the existing lesson library aligned to the Common Core, other state standards, and the 1994 National Standards for Arts Education.\nLessons connect to the National Standards for Arts Education, the Common Core Standards, and a range of other subject area standards.\nCommon Core/State Standards\nSelect state and grade(s) below, then click ""Find"" to display Common Core and state standards.', 'For decades, we have been hearing about the health benefits of living a physically active lifestyle. But what about the times when we are not moving a lot; travelling to work, hours at work spent sitting, and the post-work couch time devoted to relaxing? As long as we make time for physical activity each day, we get a free pass to sit in our remaining hours, correct? Unfortunately research is beginning to show that the answer to that question is a resounding no.\nThe dangers of prolonged sitting is centred on its sedentary behaviour. Sedentary behaviour refers to ‘any waking behaviour characterised by an energy expenditure ≤1.5 METs while in a sitting or reclining posture’ (Sedentary Behaviour Research Network, 2012). This is conceptually different from ‘physical inactivity’, which is the lack of sufficient moderate/ vigorous intensity physical activity, and therefore both need to be considered as separate health hazards (Sedentary Work – Safe Work Australia, 2016).\n“Sedentary behaviour refers to ‘any waking behaviour characterised by an energy expenditure ≤1.5 METs while in a sitting or reclining posture’\nOverall exposure to sedentary behaviour (especially prolonged, unbroken sitting time) is shown to be detrimentally associated with a range of poor health outcomes, including; musculoskeletal problems, cardio-metabolic outcomes (including cardiovascular disease, diabetes and obesity), some cancers, mental ill health and health related quality of life. Furthermore, data also demonstrates a dose–response association between sitting time and all-cause mortality, independent of leisure time physical activity. As such, the simple pleasure of sitting for prolonged periods is deemed more of a risk factor for preventable morbidity and mortality in Australia than high cholesterol and is just behind high blood pressure on the risk scale.\nIn terms of energy expenditure, there is a relatively small differential between sitting and static standing. However, during standing, postural muscles (predominately those of the lower limbs) are continually contracting in order to keep the body upright and prevent loss of balance. Frequent contractions in these large muscle groups are largely absent while sitting. This can lead to an adverse metabolic profile with suppression of hormones related to fat metabolism and reduced glucose uptake by skeletal muscles, which can lead to insulin resistance. It is important to note that these sedentary metabolic changes do not appear to exist when incidental, light-intensity activity (including standing) is introduced every 20-30 minutes (Sedentary Work – Safe Work Australia, 2016).\nWhat research is currently illustrating is that sitting too much is not the same as exercising too little.\nBut before you all go out and ditch your chair, the question is….how much sitting is too much? Findings suggest that – at least for mortality outcomes in adults – excessive can be considered somewhere near a 7 hour daily threshold without 30 minute mini-breaks (self-reported) (J.Y. Chau et al, 2013; Sedentary Work – Safe Work Australia, 2016). Interrupting prolonged periods of sitting every 20-30 minutes is supported by epidemiological studies and even as little as 2 minutes of light intensity activity (e.g. slow walking) may be sufficient for beneficial metabolic effects (Dunstan et al, 2012; Sedentary Work – Safe Work Australia, 2016).\nSo what can you do to limit your sitting? The simple answer is to stand up more often. Standing more could be as simple as standing up to take phone calls or to adopt the habit of standing meetings. Effectively, trying to stand up every half hour or so for a minute or 2 may well be the best daily medicine you can take.\nPlease browse our other blogs for further information on how to gradually start implementing standing/ introducing a sit to stand workstation within your working environment and other steps that can be taken to reduce the negative health consequences of sitting for prolonged periods of time.\nMOVING MORE @ WORK – REDUCE YOUR SITTING TIME\nERGONOMICS OF A STANDING WORKSTATION\n- Changing excessive sitting behaviours is an individual, organisational and national priority\n- Prolonged sitting is associated with significant negative health outcomes\n- Sedentary behaviour and physical inactivity are separate entities and risk factors associated with prolonged sitting (being ‘too busy’ to take a break) are NOT negated by current physical activity guidelines (moderate exercise 30 minutes a day)\n- The harm associated with prolonged occupational sitting is likely due to insufficient movement and energy expenditure, lack of postural variety, diminished gravitational resistance, and a number of other mechanisms\n- Small and frequent interruptions from sitting (every 20-30 minutes) and less total time sitting can start to mitigate the potential harm']"	['<urn:uuid:84e84c15-5b42-4481-a341-395f7bed3ade>', '<urn:uuid:36d44084-93d6-47fb-9c31-65d719d76f14>']	open-ended	with-premise	long-search-query	similar-to-document	multi-aspect	expert	2025-05-01T23:21:14.341336	12	77	1843
285	What similarities and differences exist between the combat roles of the Winchester Model 1887 and the Ithaca Model 37 during their respective historical periods?	The Winchester Model 1887 was primarily used in the Old West era, where it served as both a defensive arm and practical tool for pioneers, farmers, and ranchers who needed a reliable firearm for protection against threats like grizzly bears and claim jumpers. The Ithaca Model 37, on the other hand, played a significant role during World War II as a combat shotgun, being extensively used by American forces for close-quarters combat operations, trench warfare, and clearing fortified positions. While both shotguns served in combat roles, they were utilized in different historical contexts and warfare scenarios.	['From innovative black-powder repeater to modern throwback arm and dandy field gun, the All-American lever-action shotgun continues to soldier on.\nWhat You Need To Know About The Lever-Action Shotgun:\n- The first commercially successful repeating shotgun (Winchester 1887) was a lever-action.\n- While the style of shotgun disappeared for decades, it reemerged with the rise of Cowboy Action Shooting.\n- It makes an excellent option for game such as turkey, due to its ability to cycle quickly while holding on the target.\nFrom the start, John M. Browning didn’t think it was a good idea. After all, a lever-action shotgun would be unwieldy, comparably slow and God awful on the knuckles. Try as he might, the legendary gun designer couldn’t veer Winchester Repeating Arms to a pump-action design. Management wouldn’t budge. Dagnabit, they were a lever-gun company, anything less was an affront.\nSo was born the first successful repeating shotgun—the Winchester Model 1887, later to become the 1901 with the advent of smokeless powder.\nCertainly, Browning had it right, pump-action and later semiautomatic shotguns were the wave of the future for fast shooting, easy-to-operate smoothbores. For most applications, everything about them enhanced the efficient use of the generally hard kicking class of gun.\nBut it’s tough to argue the gun genius’s capitulation to the gun manufacturer’s whims has made for one of the most unique, timeless and downright nasty classes of shotguns. The lever-action shotgun will never top the heap, but there is no doubt it isn’t going anywhere soon.\nGenesis Of The Lever-Action Shotgun\nTo modern eyes, the Winchester 1887 has a lumbering appearance. Dromedary-shaped action, short and thick buttstock and the typically long barrel of a black powder shotgun, it’s not exactly the first iron you’d grab come grouse season. Yet, at the time—in an age that would have viewed the lever-action shotgun as equally as awkward—it had a great advantage.\nWhether you realized it or not, the shotgun was perhaps the most used—if not deadly—firearm of the Old West. James “Kill’n Jim” Miller was blistering hell with one in his hands (a skill that eventually led him to a dance at the end of a rope). But more so, it was the perfect tool for Manifest Destiny. Aside from good and bad men, every pioneer, farmer, rancher and likely last remaining mountain men had a smoothbore at beck and call. As pragmatic as those times, you could as easily fend off a grizzly bear or a claim jumper, as you could knock a duck off the wing with one. If you could do it in two shots.\nTherein lies the edge of the 1887—it wasn’t a side-by-side. Before the Winchester lever-action shotgun hit the scene, that’s all that was on hand. Aside from their limited capacity and glacial reload time (no ejectors), these side-by-sides were hammer guns that had to be manually cocked to get into action.\nOn the other hand, the Model 1887 held 5+1 shells and, comparably, shot at a respectable clip. Sure, it wasn’t optimized for an accelerated firing rate or as intuitive as other potential designs, but it sure beat the alternative. Succinctly put, in the land of the blind, the one-eyed man was king.\nCertainly, the 1887 had its drawbacks. As anyone who’s had the pleasure of being at the business end of one of the 12- or 10-gauges knows, it’s not the easiest firearm to load. Given there’s no loading gate and the action opens from the top, you have to reach through the receiver to insert a shell into the tubular magazine. And the lever-action shotgun and its progeny weren’t exactly nimble. Initially, the 1887 came with a 30-inch barrel standard—a 20-inch variation offered much later. And the 1901 came outfitted with a behemoth 32-inch barrel. Hyperbolically speaking, that’s teetering on punt gun territory.\nDespite these drawback, the Winchester 1887 is as elegant as any of the other guns scratched together by Browning. Utilizing a rolling block action, the lever-action shotgun was not only rock-solid, but also extraordinary simple. Early on, Winchester touted the latter aspect, boasting the action only had 16 parts.\nFurther, Browning made the 1887 as easy to operate as the design would allow. Primarily, this was achieved by dedicating the opening stroke to the lighter duty of extracting the spent shell and the closing stroke the more heavy work of compressing the hammer spring. You’d rather do the latter with your palm than your knuckles. Plus the trigger lays back on the trigger guard until the lever is almost closed, so you avoid the unpleasant experience of stabbing yourself with it.\nThese and other aspects made a good system, but not an enduring one. Less than a decade after its introduction, the 1887’s sales petered out. Though, it had one last gasp of life as the more stoutly built smokeless powder 10-gauge—the Model 1901. Another Browning design supplanted the lever-action shotgun, the iconic Winchester Model 1897—to a lesser extent its forerunner the 1893. Pump-actions both, it seemed Browning had it right from the start.\nRebirth Of The Lever-Action Shotgun\nFunny thing about the closing of the American West, it didn’t quite shut the lid on the lever-action shotgun.\nSure enough, the design disappeared for decades, smoothbore fanatics had other things to keep them busy—pump-actions, semi-automatics and over/unders. Then, like a prairie twister, the lever-action touched down again. Winchester dabbled with the .410 Winchester 9410 in the 1990s, nearly a decade later Marlin introduced a lever .410 of their own, Henry Repeating Arms followed suit a little over 10 years later.\nNifty (and useful, we’ll get to that in a moment) as those small-bores proved, it wasn’t really what breathed new life into the lever-action shotgun. Wistfulness for the old west did … that and a cyborg from the future.\nRaise Your Lever-Action IQ:\n- 5 Of The Best Lever-Action Rifle Options Available Today\n- 7 Best Lever-Action Rifles To Ever Sling Lead\n- 5 Must-Have Henry Lever-Action Rifles\n- 7 Marlin Lever-Action Rifles Worth Adding To Your Collection\n- .357 Magnum Lever-Action: The Best Pistol Caliber Carbine?\n- 9 Greatest Winchester Lever-Action Rifles, Shotguns and Bolt-Actions\nCowboy Action Shooting—basically 3-Gun with period-correct firearms (replica and original) and duds—saw an incredible surge in the last quarter of the 20th Century. Those who couldn’t root out or afford a vintage Model 1887 and wanted to shoot the lever-action in a match created a market.\nSo did the 1991 film Terminator II. Spin cocking a sawed-off riff on an 1887 on the back of a Harley-Davidson, Arnold Schwarzenegger brought more attention to the level-action shotgun than it had had since Grover Cleveland was in the White House. Go figure.\nby in large, the rebirth of the 1887 has had a foreign accent—Chinese and Italian. The Chinese Norinco was an early purveyor of the design, particularly a model fashioned after the Terminator’s gun, and won mixed review. Today there’s a non-descript “Chinese Made” 1887 is available at Century Arms for the princely sum of $380. A get-what-you-pay-for affair.\nItalian gunmaker Chiappa, on the other hand, has earned more accolades, producing a more finely made option. In addition to selling under their name, they’re also imported by several replica specialists, manufactured to those company’s specifications.\nGiven Browning never worked in polymer, there are several variations of the lever-action shotgun that are a drastic break from the original design. So what?\nAlmost every replica 1887 is in one major way—they’re capable of shooting shells loaded with smokeless powder. But they aren’t technically 1901 knockoffs—for marketing purposes, mainly—but also since nearly every dang one of them is a 12-gauge.\nA Modern Place Of The Lever-Action Shotgun\nThere are plenty of makes/models that owe their present existence to the field of competition. Yet, the lever-action shotgun has more depth to it than throwback shooting matches. Despite flying in the face of convention, it still has a role as a field gun and as a defensive arm.\nOutside the 1887, the lever-action shotgun is primarily a .410 affair now, which might sound a little light by modern standards. Certainly, no one will argue against a small-bore scattergun for first-timers and youths, looking to master arm before having to deal with recoil. More so, with ammunition advancements, the .410 has found a new lease on life in turkey season. Improvements in wad design and heavier than lead shot, hunters have gravitated to the smaller—arguably faster shooting—diminutive bore.\nCombine with a lever-action, the .410 becomes a formidable tool for knocking down a strutting gobbler—perhaps a better one than a pump. How so? You can shoot it more like a rifle. Take a kneeling or cross-legged position, for example. You can build a solid base with your support elbow on your knee to aim and never have to break it down to apply a follow-up shot. The same cannot be said of the pump-action.\nHenry’s 19.5-inch barreled lever-action .410 and Marlin’s 22-inch barrel 1895 .410 both fill this role extremely well, even if—in both cases—you have to drill and tap them if you hunt with a scope. Henry perhaps has the edge, given its shotgun uses Invector removable chokes—Marlin has choke options, but all are fixed. Either way, someone searching for a fast, accurate and light-recoiling turkey gun couldn’t do much better.\nOn the home front, the lever-action is also viable, particularly with the meteoric rise of the bird-head grip. Given these firearms are generally shot at the hip, the lever-action proves as efficient as the pump to cycle the shotgun. More so, for certain individuals more comfortable with the former over the latter. Black Aces Tactical certainly sees it this way.\nLong demanded, the Florida company came out with a convertible lever-action smoothbore line—Pro Series L— which comes with both a shoulder stock and bird’s head grip. The 12-gauge—capable of chambering 3-inch shells—is considerably larger than many grip-option firearms, boasting an 18.5-inch barrel. Still, outfitted with the grip it should prove plenty nimble and no less quick and potent.\nDespite its long history and somewhat recent resurgence, the lever-action shotgun isn’t going to become America’s preferred smoothbore anytime soon. That’s alright. It perfectly fills its present niche. As time goes on, clever gun designers will most definitely find new roles for the shotgun to play. Who knows what the future might hold for the All-American design? Whatever it is, one thing is certain—the lever-action shotgun will continue to endure.\nDraw A Bead On Shotguns:\n- 9 Affordable Double-Barrel Shotgun Options\n- 12 Affordable Pump-Action Shotgun Options\n- Understanding The Semi-Auto Shotgun\n- 5 Affordable Over/Under Shotguns Worth A Shot\n- 5 Best Bullpup Shotgun Options For Compact Defense', 'In this article, you will learn about the historical significance of the Ithaca Model 37. We will explore its background, features, and its impact on firearms history. Additionally, we will provide you with step-by-step instructions on how to safely take apart and clean this firearm. By the end, you will have a deeper understanding of the Ithaca Model 37 and its place in the world of firearms.\nThis image is property of www.americanrifleman.org.\nA Historical Look at the Ithaca Model 37\nThe Ithaca Model 37 is a classic pump-action shotgun that has been a staple in the firearms industry for many years. Its enduring popularity can be attributed to its innovative design, reliability, and versatility. In this article, we will take a comprehensive look at the development, design, variants, historical significance, performance, maintenance, collectibility, safety considerations, and comparison with other shotguns of the Ithaca Model 37.\nDevelopment and Design of the Ithaca Model 37\nOrigins and early development of the Ithaca Model 37\nThe Ithaca Model 37 was first introduced in the late 1930s by the Ithaca Gun Company. It was designed by John Browning, a renowned firearms designer, and has become one of the most iconic pump-action shotguns in history. The early development of the Model 37 focused on creating a reliable and durable shotgun that would perform well in various shooting conditions.\nInnovative design elements of the Ithaca Model 37\nOne of the key features that set the Ithaca Model 37 apart from other shotguns of its time was its bottom ejection system. Unlike most shotguns that eject shells from the side, the Model 37’s shells are ejected from the bottom, reducing the risk of spent shells hitting the user or getting caught in the ejection port. This innovative design was not only safer but also allowed for ambidextrous use, making it popular among both right-handed and left-handed shooters.\nEvolution and improvements in the design of the Ithaca Model 37\nOver the years, the Ithaca Model 37 underwent several design improvements and modifications to enhance its performance and user experience. These improvements included refinements in the trigger mechanism, stock and forearm design, and the addition of a variety of choke options. With each iteration, the Model 37 became more reliable, comfortable to handle, and capable of delivering accurate shots.\nVariants and Modifications of the Ithaca Model 37\nDifferent variants of the Ithaca Model 37\nThe Ithaca Model 37 has been produced in various configurations to cater to different shooting needs. Some of the most common variants include the field model, which is designed for hunting and general shooting, and the riot model, which was originally developed for law enforcement and home defense purposes. Additionally, the Model 37 has also been produced in specific gauges such as 20 gauge and 16 gauge.\nSpecialized versions for various applications\nIn addition to the standard variants, the Ithaca Model 37 has been customized and adapted for specialized applications. These include versions with longer barrels for trap shooting, shorter barrels for turkey hunting, and even versions with folding stocks for compact storage and transportation. These specialized versions ensure that shooters can find a Model 37 that suits their specific shooting needs.\nNotable modifications and aftermarket accessories\nThe Ithaca Model 37 has also gained popularity among firearms enthusiasts for its ability to be modified and accessorized. Various aftermarket parts and accessories are available to enhance the shotgun’s performance and aesthetics. These modifications can range from upgrading the barrel and sights to adding tactical accessories such as flashlight mounts or extended magazines. The availability of aftermarket support has made the Model 37 a versatile firearm that can be customized to individual preferences.\nHistorical Significance of the Ithaca Model 37\nInvolvement of the Ithaca Model 37 in World War II\nDuring World War II, the Ithaca Model 37 played a significant role as a combat shotgun. It was used extensively by American forces for close-quarters combat operations, trench warfare, and clearing out fortified positions. Its reliability, ruggedness, and ease of use made it a valuable weapon for soldiers in the field.\nUse by law enforcement agencies and military organizations\nFollowing its success in World War II, the Ithaca Model 37 gained widespread adoption by law enforcement agencies and military organizations around the world. Its simplicity, durability, and versatility made it a popular choice for police departments, as well as SWAT teams and special forces units. The Model 37’s ability to reliably cycle a wide range of ammunition also contributed to its popularity among law enforcement agencies.\nRole in popular culture and film\nThe Ithaca Model 37 has also left its mark on popular culture and film. It has been featured in numerous movies, TV shows, and video games, further cementing its status as an iconic firearm. From classic Westerns to action movies, the Model 37’s distinctive appearance and reliable performance have made it a favorite among filmmakers and prop masters.\nThis image is property of upload.wikimedia.org.\nPerformance and Characteristics of the Ithaca Model 37\nCaliber and cartridge options\nThe Ithaca Model 37 is available in various calibers, including 12 gauge, 20 gauge, and 16 gauge. Each gauge offers different benefits and ballistics, allowing shooters to choose the option that best suits their needs. Additionally, the Model 37 can accommodate a wide range of shotgun shells, including birdshot, buckshot, and slug rounds, making it suitable for various shooting applications.\nErgonomics and handling of the Ithaca Model 37\nThe Model 37 is renowned for its excellent ergonomics and ease of handling. Its lightweight design, balanced feel, and intuitive controls make it comfortable to shoot for extended periods. The stock and forearm design provide a secure grip and minimize recoil, further enhancing the shooter’s comfort and control.\nReliability, accuracy, and effective range\nOne of the standout qualities of the Ithaca Model 37 is its exceptional reliability. It is known for its ability to cycle a wide range of ammunition without jamming or malfunctioning. This reliability, combined with its accurate shooting performance, makes the Model 37 a dependable firearm for hunting, sport shooting, and self-defense. The effective range of the Model 37 varies depending on the specific variant, choke selection, and ammunition used, but it is generally considered effective within the typical range of a shotgun.\nMaintenance and Care for the Ithaca Model 37\nStep-by-step disassembly guide for the Ithaca Model 37\nTo properly maintain and care for your Ithaca Model 37, regular cleaning and maintenance are essential. Here is a step-by-step guide on how to disassemble and clean the shotgun:\n- Ensure the shotgun is unloaded and the safety is engaged.\n- Remove the magazine tube cap and slide the barrel forward to remove it from the receiver.\n- Push the action slide forward to release the bolt, then lift the bolt out of the receiver.\n- Remove the trigger group by depressing the action release button and pulling it out of the receiver.\n- Clean each component thoroughly with a suitable firearm cleaner, paying close attention to the bore, chamber, and other critical areas.\n- After cleaning, apply a light coat of lubricant to the moving parts and reassemble the shotgun in the reverse order.\nProper cleaning and lubrication techniques\nWhen cleaning the Ithaca Model 37, it is important to use high-quality cleaning solvents, brushes, and patches specifically designed for shotguns. Clean the bore using a bore snake or brush, and clean the action components thoroughly to remove any built-up dirt or debris. After cleaning, apply a thin film of lubricant to the moving parts to ensure smooth operation. Be mindful not to over-lubricate, as excess oil can attract dirt and affect the shotgun’s performance.\nTips for routine maintenance and troubleshooting\nRegular inspection and maintenance of your Ithaca Model 37 will help keep it in optimal condition. Check the shotgun for any signs of wear, damaged parts, or loose screws. Ensure the barrel and choke tubes are clean and free from any obstructions. If you encounter any issues with the shotgun, consult the owner’s manual or seek advice from a qualified gunsmith for proper troubleshooting and repair.\nThis image is property of www.shootingtimes.com.\nCollectibility and Value of the Ithaca Model 37\nFactors that affect the collectibility of the Ithaca Model 37\nThe collectibility of the Ithaca Model 37 can be influenced by several factors, including its age, rarity, condition, and any unique features or modifications. Older models, limited editions, and variants with special markings or decorations tend to be more sought after by collectors. Shotguns in excellent condition with minimal wear or damage also tend to hold a higher value.\nNotable limited editions and rare versions\nThroughout its history, the Ithaca Model 37 has seen the release of various limited editions and rare versions. These include commemorative editions honoring historical events or individuals, engraved models with intricate designs, and variants chambered in less common gauges. These limited editions and rare versions can be highly desirable to collectors and often command higher prices in the market.\nDetermining the value of a specific Ithaca Model 37\nTo determine the value of a specific Ithaca Model 37, it is recommended to consult reputable firearms pricing guides, auction listings, or seek the advice of a knowledgeable firearms appraiser. These resources can provide an estimate based on factors such as the shotgun’s condition, age, rarity, and market demand. It is important to keep in mind that the value of any firearm can fluctuate over time due to market conditions and collector trends.\nSafety Considerations and Regulations\nBasic firearm safety rules applicable to the Ithaca Model 37\nWhen handling the Ithaca Model 37 or any firearm, it is essential to adhere to basic firearm safety rules. These rules include:\n- Always treat the shotgun as if it is loaded.\n- Keep your finger off the trigger until you are ready to shoot.\n- Keep the muzzle pointed in a safe direction at all times.\n- Be aware of your target and what is beyond it.\n- Store the shotgun securely, away from unauthorized access.\nSpecial safety features of the Ithaca Model 37\nThe Ithaca Model 37 incorporates several safety features to enhance user safety. These include a manual safety located on the trigger guard, which locks the trigger and prevents accidental discharges. Additionally, the firing pin is designed to be inert until the trigger is pulled, further minimizing the risk of accidental discharges.\nRelevant regulations and restrictions for owning the Ithaca Model 37\nOwnership and possession of the Ithaca Model 37 are subject to federal, state, and local laws. It is essential to familiarize yourself with the specific regulations and restrictions pertaining to firearms in your jurisdiction. These may include age restrictions, background checks, licensing requirements, and transportation regulations. Adhering to these laws ensures legal and responsible ownership of the Model 37.\nThis image is property of www.pewpewtactical.com.\nComparison with Other Shotguns\nAdvantages and disadvantages of the Ithaca Model 37 compared to other shotguns\nWhen comparing the Ithaca Model 37 to other shotguns, several advantages and disadvantages can be observed. One notable advantage is its bottom ejection system, which offers increased safety and ambidextrous use. The Model 37 is also known for its reliability and durable construction. However, some shooters may find the bottom ejection system takes getting used to, and the lack of a detachable magazine may be perceived as a disadvantage in certain applications.\nComparison with other popular pump-action shotguns\nIn the category of pump-action shotguns, the Ithaca Model 37 rivals other iconic firearms such as the Remington 870 and Mossberg 500. Each shotgun has its own strengths and characteristics, catering to different shooting preferences and purposes. The Model 37’s bottom ejection system sets it apart from its competitors, while the Remington 870 is known for its extensive aftermarket support and the Mossberg 500 for its affordability and versatility. Ultimately, the choice between these shotguns depends on the shooter’s individual needs and preferences.\nDifferent applications and use cases for various shotgun models\nShotguns, including the Ithaca Model 37, are highly versatile firearms suitable for various applications. They are commonly used for hunting game birds, waterfowl, and small game. Shotguns are also popular for sport shooting disciplines such as trap, skeet, and sporting clays. Additionally, shotguns are valued for home defense purposes due to their stopping power and ability to deliver close-quarters firepower.\nThe Ithaca Model 37 is a legendary shotgun that has stood the test of time in the firearms industry. Its innovative design, reliability, and versatility have made it a favorite among shooters, collectors, law enforcement agencies, and military organizations. From its unique bottom ejection system to its historical significance and enduring popularity, the Model 37 holds a special place in the firearms world. Whether used for hunting, sport shooting, or self-defense, the Ithaca Model 37 continues to be appreciated for its iconic design, performance, and lasting legacy.\nThis image is property of www.tactical-life.com.']	['<urn:uuid:4eb6cdfe-6969-47c0-8922-1a7edf214aa5>', '<urn:uuid:006ce444-d4a9-44ed-9866-02a7de6d02c6>']	open-ended	direct	verbose-and-natural	distant-from-document	comparison	expert	2025-05-01T23:21:14.341336	24	96	3904
287	intellectual property protection business contract conditions	Contracts can include conditions to prevent parties from transferring intellectual property to competitors. For IP protection, businesses must register their creations through specific processes - trademarks for brands/logos, copyrights for literary/artistic works, patents for inventions, and designs for object appearances.	['Condition In Contract Law: Everything You Need to Know\nA condition in contract law spells out the obligation to fulfill duties between parties in a contract. 4 min read\nCondition in Contract Law\nA condition in contract law spells out the obligation to fulfill duties between parties in a contract. They are standard in valid contracts and, in fact, the essence of any agreement between two or more parties to a sale, real estate transaction or agreement to provide a service.\nThe simplest way to think of a condition in contract law is found in the terms “If…then”. “If” one party fulfills an obligation as contained in the agreement, “then” the other party to the agreement must fulfill their obligation. It’s more than a promise because of the obligation it creates. For instance, if I tell a neighbor I’ll watch their cat, that’s a promise. If my neighbor and I agree that if I watch his or her cat then they will pay me $10, it’s a condition of a contract.\nLaw.com defines a contract as “an agreement with specific terms between two or more persons or entities in which there is a promise to do something in return for a valuable benefit known as consideration.” It may be a written or oral agreement between two parties. Regardless of type, each is legally binding and extremely common and necessary in the business world. They act as a guarantee that obligations are fulfilled and, if not, provide opportunities for recourse.\nThree Types of Conditions\nThree types of contract conditions exist, defined by the point in time that conditions must be met. These are:\n- A condition that must be satisfied before, or precedent, to the obligation of the performing duty to act. An example of this condition in contract law would be that I don’t have to pay someone to shovel snow from my driveway until it has snowed and the party has shoveled the snow. In this case, the condition is suspended because I don’t have to pay unless it snows.\n- A condition that must be satisfied during, or concurrent to, the duty of the performance of the act. This might come into effect if I know it will definitely snow and will pay someone a set fee per month to shovel the snow, regardless of how often the service is required.\n- A condition that can be satisfied after, or subsequent to, the performing party beginning to meet its obligations. An example might be if I employ someone to shovel the snow in my driveway until they receive an offer from another party that is at least 35 percent above the rate I am paying them.\nAs you can see, conditions are established for events that may or may not happen sometime in the future. Therefore, contracts often contain conditions that can be modified, or even rescinded, if both parties allow for certain contingencies in the event that obligations cannot be met due to established circumstances.\nConditions, Limitations and Covenants: What’s the Difference\n- Conditions. As described above, a condition relies on two or more parties satisfying obligations to each other before it is achieved. There may or not be a time period during which the obligations must be met.\n- Limitations. In so far as limitations are applied in a contract, they are always based upon an established time period after which a party may not be liable to fulfill an obligation, regardless of whether other conditions of the contract have been met.\n- Covenants. Quite simply, a covenant is a contractual promise. It is not dependent upon conditions being met between two or more parties, only obligations made by one party to a contract.\nEvents Foreseen by Conditions in Contract Law\nConditions in contract law can provide for events that may be contemplated by the parties to the agreement. These could include:\n- Conditions that prevent the parties from taking specified actions, such as not allowing a party to the contract to transfer property (real or intellectual) to a competitor of a party.\n- Conditions that hold a party harmless due to an unfortunate, unpreventable event (often called an “Act of God”).\n- Conditions that call for remedies for events that, although unfortunate, could have been expected due to economic, political, or environmental conditions existing at the time a contract is signed.\nIt is important for entrepreneurs and small business owners to consider all the ramifications of the conditions that are components of a contract. Contract law is a specialized practice, and it is often wise to seek out the counsel of contract law attorneys before entering into any legally binding document.\nTo learn more about conditions in contract law, you can post your legal need on UpCounsel’s marketplace. UpCounsel accepts only the top 5 percent of lawyers to its site. Lawyers on UpCounsel come from law schools such as Harvard Law and Yale Law and average 14 years of legal experience, including work with or on behalf of companies like Google, Menlo Ventures, and Airbnb.', 'Trademark | Copyright | Patent | Design\nAs a business owner, if you have a unique idea i.e. likely going to be translated into a product or service or an algorithm, it is very important to think about the intellectual property right for this particular thing right from the beginning. Because intellectual property right (IPR) is something that gets less attention and is neglected which leads to big problems in the business in the future so it is going to be very important for us to understand the critical aspects of the intellectual property rights from some of our subject matter experts.\nIn the process of starting your business, if you’re going to be creating anything, whether it’s creating anything which is in literary or something in writing or it’s an artistic work or it’s music or even your brand or even designs, all of these things are intellectual property and capable of protection and more importantly monetization for you going forward.\nThere are a few aspects of IPRs which you must look at for registering your creation:\nThis is something you can do for protecting your brand/logo. This helps you in differentiating your products/services from other players in the market.\nREGISTRATION PROCESS of Trademark:\nRegistration of a trademark can be done by two ways offline or online. Offline registration of the trademark can be done at one of the offices of the trademark register based on the jurisdiction. While online registration is called E-filing of a trademark.\nE-filing of a trademark application is a new service provided by the trademark office. E-filing is beneficial and more useful than offline registration as it provides trademark application number immediately. It also provides online verification to assure error-free filing and obtain your filing date. It also speeds up the process. All the details can be saved in your PC and can see online history or track status of the applications filed by clicking “Status of filed application”.\nThe trademark registration application will be allotted to a Trademark Officer in the Trademark Registrar Office. The Trademark Officer would then review the trademark application for correctness and issue a trademark examination report. The Trademark Officer has the ability to accept the trademark registration application and allow for trademark journal publication or object the trademark registration application.\nDuration of Trademark:\nTrademark can be registered for a duration of 10 years. It can be renewed for a further period of 10 years on payment of the renewal fees. The trademark can be renewed by filling the form TM-R with transaction costs.\nDocuments required and Fee for Trademark:\nA soft copy of the logo in JPEG format is required for the registration.\n• Name and address of the proprietor of the mark or Name of all the partners if its a partnership firm. or also attached partnership firm deed.\n- For Private Limited Company – COI and Name and address of Authorized signatures\n• In case company if you submit MSME certificate the fees will be reduced. You have to pay only Rs.4500/ instead of Rs.9,000/-\n• In case of sole-proprietary firm fees will be Rs.4500/- or in case of Company Rs.9,000/-\nTypes Of Trademark available:\n- Names According to Section 9 or 11 of Trade Marks Act it should not be similar to with an earlier trademark.\n- The Combination of Colours or even a single color in combination with a word or device according to Section 10.\n- Letters, numerals or combination of both.\n- Sounds Mark\nIt is a legal right which is given to the creator of the product for a fixed time period.\nThrough this the author enjoys the exclusive privilege to publish, broadcast, adapt, make derivative works, showcase and monetize the same. It could either be a literary work, a dramatic work, music or artistic work.\nHow to get Copyright for a website?\nA website may contain a number of elements that are literary or artistic in nature. For example, words, graphics, videos, software and photos etc. As per the Copyright Office, you will have to file copyright registration request for each of these elements separately.\nDuration/Term of Copyright\nIn the case of original literary, dramatic, musical and artistic works, the duration of copyright is the lifetime of the author or artist, and 60 years counted from the year following the death of the author.\nIn the case of cinematograph films, sound recordings, photographs, posthumous publications, anonymous and pseudonymous publications, works of government and works of international organizations are protected for a period of 60 years which is counted from the year following the date of publication.\nApplication Procedure of Copyright\nAny individual who is an author or rights owner or assignee or legal heir can file an application for copyright of a work either by the e-filing facility or by speed post. However, with effect from August 01, 2014, the Copyright Counter for filing copyright applications has been closed in order to popularise the electronic filing. Online Filing Process:\nStep 1- Applicant need to create a User ID at http://copyright.gov.in/UserRegistration/frmNewUser.aspx by filling basic details.\nStep 2- After successful registration, browse http://copyright.gov.in/UserRegistration/frmLoginPage.aspx and Log In with credentials.\nStep 3- Once you are Logged In, click on “e-Filing of Application” in the left menu.\nStep 4- Click on the link “Click here for online Copyright Registration”\nStage 5- The online “Copyright Registration Form” is to be filled-up in four\nOffline Filing Process:\na) Application for registration is to be made on Form XIV. Form can be downloaded from here-http://copyright.gov.in/frmformsDownload.aspx\nb) Separate applications should be made for registration of each work.\nc) Each application should be accompanied by the requisite fee.\nd) The applications should be signed by the applicant or the advocate in whose favour a Power of Attorney has been executed. The Power of Attorney should also be enclosed.\ne) Answer each and every column of the Statement of Particulars and Statement of Further Particulars specifically.\nSend the documents by post to Copyright Division, Department of Higher Education, Ministry of Human Resource Development, 4th Floor, Jeevan Deep Building, Parliament Street, New Delhi : 110001 Email\nTelephone No, – 011-23362436\nA mandatory period of 30 days should be passed post obtaining the diary number so that no objection is filed in the Copyright office against your claim that particular work is created by you. If such objection is filed it may take another one month time to decide as to whether the work could be registered by the Registrar of Copyrights after giving an opportunity of hearing to both the parties.\nIf no objection is filed the application goes for scrutiny from the examiners. If any discrepancy is found the applicant is given 30 days time to remove the same. Therefore, it may take 2 to 3 month’s time for registration of any work in the ordinary course. The applicant himself or his/her leader may appear in the hearing according to S. 27 of the Act. As per section 72 of the Copyright Act, 1957 any person aggrieved by the final decision or order of the Registrar of Copyrights may, within three months from the date of the order or decision, appeal to the Copyright Board. The registration of a copyright thus, may take a period of 1 to 1.5 years.\nList of Documents required to be submitted by Post along with application form. Refer to the document list based on Type of Work. Click here for list- Documents Required for Copyright Registration in India.\nFee for copyright:\nThe Fee can by paid either through Online mode or Postal Order or Demand Draft. List of Documents required to be submitted by Hand/ By Post along with application form.\n3. Patent – The focus here is on proving the novelty of your creation. It needs to be a new invention for you to get a patent. Availing patent protection is a bit more complex than getting a trademark or a copyright. Generally, these are given for machines and pharmaceutical products.\n4. Design – Registered designs are used to protect the external appearance of any object. These are primarily meant for protecting designs meant for commercial/industrial use. For instance, a Coca-Cola bottle.\nIP – Investor’s Perspective\nWhenever the company seeks funding from the investor community, IP – how it is managed and protected\n– becomes an important criteria for them to decide. It helps investors figure out the long-term growth of the company. They check on a few key aspects like:\n- IP ownership rests with the company and not with the founder\n- Ensure that there are no arrangements of IP sharing.\n- How frequently are the IP rights being reviewed?\n- What are the legal implications for changes made to the brand or logo?\nIP Registration Process\nWhen it comes to registering your IP, say, for instance, trademark, the first thing which you need to figure out is to decide on its geographic spread – national registration or international registration. Under the Indian national regime of registration of a trademark, you can apply to any of the five registrars located at Mumbai, New Delhi, Kolkata, Ahmedabad, or Chennai for complete protection across India. The Registrar shall examine the application, post which it shall be published in the Indian Trademarks Journal. If no opposition is raised by any third party within 90 days, the Registrar accepts the trademark application.\nUnder the international regime, India is a signatory to various treaties, which allow for registration of a trademark in multiple countries with a single application process. Depending on the targeted countries you wish to register your trademark in, you can select any of the various international treaties such as the Madrid Protocol, European Community Trademark, etc.\nConclusion: When you think of any startup business you must have to Understand your intellectual property obligations. these intellectual property obligations build your band and secure your content & design.\nTHE FOURTH SCHEDULE TO TRADEMARKS RULES, 2002\nClassification of goods and services – Name of the classes\nClass 1. Chemical used in industry, science, photography, agriculture, horticulture and forestry; unprocessed artificial resins, unprocessed plastics; manures; fire extinguishing compositions; tempering and soldering preparations; chemical substances for preserving foodstuffs; tanning substances; adhesive used in industry\nClass 2 . Paints, varnishes, lacquers; preservatives against rust and against deterioration of wood; colorants; mordants; raw natural resins; metals in foil and powder form for painters; decorators; printers and artists\nClass 3 . Bleaching preparations and other substances for laundry use; cleaning; polishing; scouring and abrasive preparations; soaps; perfumery, essential oils, cosmetics, hair lotions, dentifrices\nClass 4 . Industrial oils and greases; lubricants; dust absorbing, wetting and binding compositions; fuels(including motor spirit) and illuminants; candles, wicks\nClass 5 . Pharmaceutical, veterinary and sanitary preparations; dietetic substances adapted for medical use, food for babies; plasters, materials for dressings; materials for stopping teeth, dental wax; disinfectants; preparation for destroying vermin; fungicides, herbicides\nClass 6. Common metals and their alloys; metal building materials; transportable buildings of metal; materials of metal for railway tracks; non-electric cables and wires of common metal; ironmongery, small items of metal hardware; pipes and tubes of metal; safes; goods of common metal not included in other classes; ores\nClass 7 . Machines and machine tools; motors and engines (except for land vehicles); machine coupling and transmission components (except for land vehicles); agricultural implements other than hand-operated; incubators for eggs\nClass 8 . Hand tools and implements (hand-operated); cutlery; side arms; razors\nClass 9. Scientific, nautical, surveying, electric, photographic, cinematographic, optical, weighing, measuring, signalling, checking (supervision), life saving and teaching apparatus and instruments; apparatus for recording, transmission or reproduction of sound or images; magnetic data carriers, recording discs; automatic vending machines and mechanisms for coin-operated apparatus; cash registers, calculating machines, data processing equipment and computers; fire-extinguishing apparatus\nClass 10. Surgical, medical, dental and veterinary apparatus and instruments, artificial limbs, eyes and teeth; orthopaedic articles; suture materials\nClass 11. Apparatus for lighting, heating, steam generating, cooking, refrigerating, drying ventilating, water supply and sanitary purposes\nClass 12 . Vehicles; apparatus for locomotion by land, air or water\nClass 13. Firearms; ammunition and projectiles; explosives; fireworks\nClass 14. Precious metals and their alloys and goods in precious metals or coated therewith, not included in other classes; jewellery, precious stones; horological and other chronometric instruments\nClass 15. Musical instruments\nClass 16. Paper, cardboard and goods made from these materials, not included in other classes; printed matter; bookbinding material; photographs; stationery; adhesives for stationery or household purposes; artists’ materials; paint brushes; typewriters and office requisites (except furniture); instructional and teaching material (except apparatus); plastic materials for packaging (not included in other classes); playing cards; printers’ type; printing blocks\nClass 17. Rubber, gutta-percha, gum, asbestos, mica and goods made from these materials and not included in other classes; plastics in extruded form for use in manufacture; packing, stopping and insulating materials; flexible pipes, not of metal\nClass 18. Leather and imitations of leather, and goods made of these materials and not included in other classes; animal skins, hides, trunks and travelling bags; umbrellas, parasols and walking sticks; whips, harness and saddlery\nClass 19 . Building materials, (non-metallic), non-metallic rigid pipes for building; asphalt, pitch and bitumen; non-metallic transportable buildings; monuments, not of metal.\nClass 20 . Furniture, mirrors, picture frames; goods(not included in other classes) of wood, cork, reed, cane, wicker, horn, bone, ivory, whalebone, shell, amber, mother- of-pearl, meerschaum and substitutes for all these materials, or of plastics\nClass 21 . Household or kitchen utensils and containers(not of precious metal or coated therewith); combs and sponges; brushes(except paints brushes); brush making materials; articles for cleaning purposes; steelwool; unworked or semi-worked glass (except glass used in building); glassware, porcelain and earthenware not included in other classes\nClass 22 . Ropes, string, nets, tents, awnings, tarpaulins, sails, sacks and bags (not included in other classes) padding and stuffing materials(except of rubber or plastics); raw fibrous textile materials\nClass 23 . Yarns and threads, for textile use\nClass 24 . Textiles and textile goods, not included in other classes; bed and table covers.\nClass 25 . Clothing, footwear, headgear\nClass 26 . Lace and embroidery, ribbons and braid; buttons, hooks and eyes, pins and needles; artificial flowers\nClass 27 . Carpets, rugs, mats and matting, linoleum and other materials for covering existing floors; wall hangings(non-textile)\nClass 28 . Games and playthings, gymnastic and sporting articles not included in other classes; decorations for Christmas trees\nClass 29 . Meat, fish, poultry and game; meat extracts; preserved, dried and cooked fruits and vegetables; jellies, jams, fruit sauces; eggs, milk and milk products; edible oils and fats\nClass 30 . Coffee, tea, cocoa, sugar, rice, tapioca, sago, artificial coffee; FLOUR AND PREPARATIONS MADE from cereals, bread, pastry and confectionery, ices; honey, treacle; yeast, baking powder; salt, mustard; vinegar, sauces, (condiments); spices; ice\nClass 31. Agricultural, horticultural and forestry products and grains not included in other classes; live animals; fresh fruits and vegetables; seeds, natural plants and flowers; foodstuffs for animals, malt\nClass 32 . Beers, mineral and aerated waters, and other non-alcoholic drinks; fruit drinks and fruit juices; syrups and other preparations for making beverages\nClass 33 .Alcoholic beverages(except beers)\nClass 34 . Tobacco, smokers’ articles, matches\nTrademark SERVICES Class\nClass 35 .Advertising, business management, business administration, office functions.\nClass 36 .Insurance, financial affairs; monetary affairs; real estate affairs.\nClass 37 . Building construction; repair; installation services.\nClass 38. Telecommunications.\nClass 39. Transport; packaging and storage of goods; travel arrangement.\nClass 40. Treatment of materials.\nClass 41. Education; providing of training; entertainment; sporting and cultural activities.\nClass 42. Scientific and technological services and research and design relating thereto; industrial analysis and research services; design and development of computer hardware and software.\nClass 43. Services for providing food and drink; temporary accommodation.\nClass 44. Medical services, veterinary services, hygienic and beauty care for human beings or animals; agriculture, horticulture and forestry services.\nClass 45. Legal services; security services for the protection of property and individuals; personal and social services rendered by others to meet the needs of individuals.\n(Parts of an article or apparatus are, in general, classified with the actual article or apparatus, except where such parts constitute articles included in other classes).\nTMclass: TMclass helps you to search for and classify Goods and Services (terms) needed to apply for trademark protection.\n- Published in Trademark Registration']	['<urn:uuid:5540548a-e6b5-4c20-a8fd-a0d943db2998>', '<urn:uuid:15d93a4e-b6ef-4789-a02c-113748ddc2b5>']	factoid	direct	short-search-query	similar-to-document	comparison	expert	2025-05-01T23:21:14.341336	6	40	3552
289	My mom has dementia and can't sleep well at night - she's always confused and agitated in the evening. As her caregiver, I'm wondering what causes these sleep problems and what an occupational therapist could do to help?	Sleep problems in dementia occur because the disease affects the brain, impacting sleep-wake cycles. People with dementia often experience 'Sundowner's Syndrome' - confusion and agitation in the evening hours - and may spend about 40% of their nighttime hours awake. An occupational therapist can help by evaluating your mom's remaining abilities and developing strategies to support her daily activities. They can analyze tasks, determine where she needs support, and help create appropriate environmental modifications. Additionally, you can try establishing a consistent nighttime routine, keeping her active during the day, ensuring exposure to morning light, and creating a comfortable sleeping environment with proper temperature and nightlights.	"[""“What can you do to help them? They have dementia. You can’t fix that.”\nAs an occupational therapist with the honor of working with many people living with Alzheimer’s disease or related dementias (ADRD), I’ve heard this question a lot.\nIt’s understandable. It’s natural for family members and caregivers to feel hopeless about a condition that doesn’t “get better.” Yet one of the most powerful things OTs can teach families and caregivers is that their loved ones actually CAN experience quality of life at every stage of the disease.\nSound unlikely? I’ll explain more, but first, let’s talk about what dementia is—and isn’t.\nDementia is not a disease itself.\nThink of the term “dementia” as an overarching description of a group of symptoms associated with certain diseases. Dementia can be categorized as reversible or irreversible. The irreversible types of dementia are progressive in nature. According to AOTA's Occupational Therapy Practice Guidelines for Adults With Alzheimer’s Disease and Related Disorders (page 5), dementia affects attention, memory, speech, object recognition, object use, and coordination.\nDepending on the type of dementia a person is living with, whether reversible or irreversible, will determine how we will approach their therapy plan. Will it be rehabilitation or habilitation? In rehabilitation, we strive to restore function. In a habilitation approach, we provide compensatory interventions to maintain function or to prevent risk factors from causing further decline or loss of function.\nSo what can an occupational therapist do?\nHere’s a statement I stand by every day: Occupational therapists are advocates who promote engagement and quality of life for their clients.\nMy role as an OT working with a person with impaired cognition is to evaluate their remaining abilities and use those strengths to support their engagement in daily occupations. As occupational therapists, we possess the necessary skills to analyze tasks and determine where a person is experiencing challenges in functional cognition, as well as determining where they would benefit from support—either from a care partner or from the environment.\nWhy training is so important\nIt’s not uncommon for clinicians to feel that a person with dementia is unable to learn and therefore is not a candidate for skilled therapy services. Although this may be common, it’s a grave misconception. Occupational therapy has a great deal of skill to offer persons living with impaired cognition and their care partners. This requires specialized training in the area of dementia therapy and an understanding of functional cognition. Having the passion to work with people living with ADRD and being an advocate for them is a necessity.\nWhen we understand someone’s cognitive level, we understand how to treat them.\nIt’s essential to understand that cognition is at the very foundation of function. When we understand where a person is performing in their functional cognition, we then know how to approach treatment effectively.\nHaving an understanding of development is also important as we note a regression through the stages of development as a person progresses in the disease process. This regression is referred to as Retrogenesis, a theory developed by Dr. Barry Reisberg. This knowledge is vital to understanding how we adapt our expectations and key care approaches to promote the success of the individual living with dementia.\nJoin the culture change movement.\nThe role of occupational therapy and its patient-centered care approach perfectly complements the culture change movement that’s sweeping the nation in the form of relationship-centered care.\nMedicare’s National Partnership to Improve Dementia Care\npromotes practices of quality care for residents with dementia, fall prevention, and the reduction of unnecessary anti-psychotic medications. Occupational therapy can contribute greatly to these quality care initiatives as it understands the role of cognition in function.\nWith more than 5.3 million people currently diagnosed with Alzheimer's, chances are there is at least one person in your life living with the disease. With the rates of people affected by Alzheimer’s disease expected to soar to about 13.8 million, there is a great need for OTs to discover their passion and deepen their skill set in working with this greatly underserved population.\nIf you have a loved one with dementia, I urge you to seek the help of a dedicated OT who’s trained in high-quality dementia therapy. If you’re an OT, I encourage you to reach out to us about getting trained.\nShouldn’t everyone have the opportunity to live to their fullest emotional and functional potential?"", ""Managing Dementia Sleep ProblemsAlzheimer's, Dementia & Memory Care | April 26, 2016\nOur internal biological clocks begin to change as we grow older. Many seniors may have difficulty sleeping through the night, or find themselves napping more often throughout the day. However, these sleep problems are more pronounced in an elderly person with dementia. While sleep problems can occur at any stage of the disease, they seem to be more common in the later stages.\nDementia and Sleep Disturbances\nIt’s not entirely known why dementia causes such disruptions in sleep patterns. However, it’s thought that like the changes that occur with memory and behavior, sleeping habits also change due to the effect dementia has on the brain. Sundowner’s Syndrome is the term used to describe the confusion and agitation that can set in at dusk and continue throughout the evening hours for dementia sufferers. Some of the other changes and problems dementia can cause in sleep include:\n- Shifts in the sleep-wake cycle. Dementia sufferers may feel drowsy throughout the day and take frequent naps, which leads to being unable to fall asleep at night. Some may even experience a complete reversal in the sleep-wake cycle, feeling wakeful only throughout the nighttime hours. Studies have shown that those with dementia will spend about 40% of their time in bed at night wide awake and take naps throughout the day.\n- Trouble staying asleep. Once in bed, those with dementia may fall asleep but are unable to stay asleep. Or, they make wake up often and simply stay awake, unable to lie still and get the rest they need.\n- Nighttime wandering. When dementia sufferers wake in the night, it’s common for them to become confused, agitated, and unsure of what time it actually is. They may get up out of bed and leave their room, or even yell out and disrupt others around them.\nHelping Loved Ones with Dementia get a Good Night’s Sleep\nWhen you’re caring for a loved one with dementia, the disturbances in their nightly sleep patterns can take a toll on your health, too. However, it’s important for you to stay calm and remember that their behaviors aren’t deliberate. First and foremost, attend to their needs, remind them that it’s nighttime and try to guide your loved one back to bed.\nThere are a few other things you can do to try to lessen any dementia sleep problems that may be occurring, including:\n- Plan activities throughout the day. Keep your loved one as active as possible during the day; go on a walk, have them help with household tasks, and keep their minds busy, too. Avoid evening physical activities, however, as this could stimulate them near bedtime.\n- Provide a comfortable environment for sleeping. The room should be kept at a temperature that is neither too warm nor too cool, and the bed should be comfortable and supportive. Install a nightlight in the bedroom, too, in case they awaken in the middle of the night. Being in total darkness can cause confusion.\n- Seek sunlight in the morning. Being exposed to morning light, whether real or artificial, can help restore the circadian rhythm often disrupted by dementia and help reset internal clocks.\n- Avoid caffeine and alcohol. The caffeine in soda, coffee and tea can contribute to sleeplessness, so be sure to avoid any products with caffeine later in the day. As alcohol can enhance confusion, try to avoid any alcoholic beverages, too.\n- Limit noise and distractions in the evening. Provide a quiet environment towards the evening; discourage television watching and instead play soft music to get your loved one to relax.\n- Manage medications. Some medications can have an effect on sleeping patterns, so talk to the doctor and find out when is the best time to administer certain medications. Sleeping pills are generally discouraged for dementia sufferers, as these can increase confusion and the risk for falls.\nEstablish a nighttime routine that includes using the restroom, getting into comfortable bedclothes, turning on the nightlight, a favorite blanket, etc. This will help your loved one stay calm and relaxed as the evening approaches, allowing for the best night’s sleep possible.\nFor more information about American Senior Communities, please visit www.ASCSeniorCare.com.""]"	['<urn:uuid:a3ef7fd5-e5c3-4cd8-8a19-140a7cc09592>', '<urn:uuid:ef5329f9-846b-405c-8421-1378303e7013>']	factoid	with-premise	verbose-and-natural	similar-to-document	three-doc	novice	2025-05-01T23:21:14.341336	38	105	1435
290	I love gardens and fountains, and I heard the park at the Palace of Caserta is beautiful. What can you tell me about the fountains and water features there?	The park at the Palace of Caserta stretches for 120 hectares and features a long alley with artificial fountains and cascades. There are several notable fountains along a wide straight canal that runs to the horizon, including the Fountain of Diana and Actaeon, the Fountain of Venus and Adonis, the Fountain of the Dolphins, the Fountain of Aeolus, and the Fountain of Ceres. These water features were designed with architecture and hydraulics by Luigi Vanvitelli, and they were considered to rival those at Peterhof outside St. Petersburg.	"['For your Business Stay choose the Hotel Olimpico\nSouth Coast of Salerno,\nLago Trasimeno street\nSalerno - Italy\nPh. +39 089 203 004\nFax.+39 089 203 458\n» Click and headd your phone number, (mobile phone included). We will call you back right away!!!\nClick and discover how to visit Caserta staying at the Hotel Olimpico >>\nPalace of Caserta\n18th-Century Royal Palace at Caserta with the Park, the Aqueduct of Vanvitelli, and the San Leucio Complex *\nUNESCO World Heritage Site Der bourbonische Königspalast in Caserta.\nThe Royal Palace of Caserta (Italian: Reggia di Caserta) is a former royal residence in Caserta, southern Italy, constructed for the Bourbon kings of Naples. It was the largest palace and one of the largest buildings erected in Europe during the 18th century. In 1997, the Palace was designated a UNESCO World Heritage Site, described in its nomination as ""the swan song of the spectacular art of the Baroque, from which it adopted all the features needed to create the illusions of multidirectional space"".\nThe construction of the palace was begun in 1752 for Charles VII of Naples, who worked closely with his architect Luigi Vanvitelli. When Charles saw Vanvitelli\'s grandly-scaled model for Caserta it filled him with emotion ""fit to tear his heart from his breast"". In the end, he never slept a night at the Reggia, as he abdicated in 1759 to become King of Spain, and the project was carried to completion for his third son and successor, Ferdinand IV of Naples.\nThe political and social model for Vanvitelli\'s palace was Versailles, which, though it is strikingly different in its variety and disposition, solves similar problems of assembling and providing for king, court and government in a massive building with the social structure of a small city, confronting a baroque view of a highly subordinated nature, la nature forcée. The Royal Palace of Madrid, where Charles had grown up, which had been devised by Filippo Juvarra for Charles\' father, Philip V of Spain, and Charlottenburg Palace provided models. A spacious octagonal vestibule seems to have been inspired by Basilica di Santa Maria della Salute in Venice, while the palatine chapel is most often compared to Robert de Cotte\'s royal chapel at Versailles.\nThe king\'s primary object was to have a magnificent new royal court and administrative center for the Kingdom in a location protected from sea attack.\nVanvitelli died in 1773: the construction was continued by his son Carlo and finished in 1780.\nThe palace has some 1,200 rooms, including two dozen state apartments, a large library, and a theatre modelled after the Teatro San Carlo of Naples.\nMain façade of the palace.\nThe Honour Grand Staircase.\nThe throne room.\nThe Diana and Actaeon Fountain at the feet of the Grand Cascade.\nThe population of Caserta Vecchia was moved 10 kilometers to provide a work force closer to the palace. A silk manufactory at San Leucio resort was disguised as a pavilion in the immense parkland.\nA monumental avenue that would run 20 kilometers between the Palace and Naples was planned but never realized.\nIn April 1945 the palace was the site of the signing of terms of the unconditional German surrender of forces in Italy. The agreement covered between 600,000 and 900,000 soldiers along the Italian Front including troops in sections of Austria.\nThe palace has a rectangular plan, measuring 247 x 184 m. The four sides are connected by two orthogonal arms, forming four inner courts, each measuring more than 3,800 m2 (40,903 sq ft).\nBehind the facades of its matching segmental ranges of outbuildings that flank the giant forecourt, a jumble of buildings arose to facilitate daily business. In the left hand arc was built as barracks. Here, later, during World War II the soldiers of the US Fifth Army recovered in a ""rest centre"".\nOf all the royal residences inspired by the Palace of Versailles, the Reggia of Caserta is the one that bears the greatest resemblance to the original model: the unbroken balustraded skyline, the slight break provided by pavilions within the long, somewhat monotonous facade. As at Versailles, a large aqueduct was required to bring water for the prodigious water displays. Like its French predecessor, the palace was intended to display the power and grandeur of an absolute Bourbon monarchy. A solecism at Caserta is that above the piano reale, the King\'s floor, is another floor of equal magnificence. The enfilades of Late Baroque saloni were the heart and seat of government, as well as displays of national wealth. Caserta provided a royal refuge from the dust and factions of the capital, just as Versailles had freed Louis XIV from Paris. The inland location was more defensible than the old Royal Palace in Naples, which fronted the Bay of Naples and hence was vulnerable to attack from the sea. To provide the King with suitable protection, troop barracks were housed within the palace.\nThe wide central entrance carriageway has, today, been incorporated into the city\'s automobile circulation.\n The park\nThe garden, a typical example of the baroque extension of formal vistas, stretch for 120 ha, partly on hilly terrain. It is inspired by the park of Versailles, but it is commonly regarded as superior in beauty. The park starts from the back façade of the palace, flanking a long alley with artificial fountains and cascades. There is a botanical garden, called ""The English Garden,"" in the upper part designed in the 1780s by Carlo Vanvitelli and the London-trained plantsman-designer John Graefer, recommended to Sir William Hamilton by Sir Joseph Banks. It is an early Continental example of an ""English garden"" in the svelte naturalistic taste of Capability Brown.\nThe fountains and cascades, each filling a vasca (""basin""), with architecture and hydraulics by Luigi Vanvitelli at intervals along a wide straight canal that runs to the horizon, rivalled those at Peterhof outside St. Petersburg. These include:\nThe Fountain of Diana and Actaeon (sculptures by Paolo Persico, Brunelli, Pietro Solari);\nThe Fountain of Venus and Adonis (1770–80);\nThe Fountain of the Dolphins (1773–80);\nThe Fountain of Aeolus;\nThe Fountain of Ceres.\nA large population of figures from classical Antiquity were modelled by Gaetano Salomone for the gardens of the Reggia, and executed by large workshops.']"	['<urn:uuid:21768f5c-7d6a-4b1b-85b6-a6b7309f0d6d>']	open-ended	with-premise	verbose-and-natural	similar-to-document	single-doc	novice	2025-05-01T23:21:14.341336	29	87	1039
293	what happens integrity selfworth student caught cheating academic dishonesty institutional procedures consequences	When caught cheating, there are both personal and institutional consequences. On a personal level, cheating lowers self-esteem by implying one isn't smart enough to handle learning, causes stress from fear of getting caught, and compromises personal integrity. Institutionally, the Ethics Committee will investigate the case within 60 days and may issue penalties ranging from a warning notice to suspension of grants. In minor cases, they may demand a Letter of Apology, while serious misconduct can result in salary deductions or contract suspensions.	['Code of Ethics for Academic Research\nAs an Institution dedicated to the search for truth through teaching, scholarship and research, Krupanidhi College is committed to excellence and integrity in all its endeavors. The institution proclaims that all researchers intend to follow the below principles and values of academic integrity, so as to bring esteem to the institution and its academic research:\n- An academic community should involve above all a commitment to intellectual honesty and personal responsibility for ones actions and to a range of practices that characterize responsible research conduct.\n- An academic community should nurture a mutual trust to encourage the mutual and free exchange of thoughts and enable all to reach their highest potential goals.\n- An academic community should actively encourage respect among staff, students and faculty.\n- An academic community should observe valid legal norms related to the conduct and publication of research particularly in relation to copyright, the intellectual property rights of third parties, the terms and conditions regulating access to research resources and the laws of libel.\n- An academic community should seek to make the results of its research as widely and freely available as possible.\n- An academic community should seek to ensure equality in institutional standards, practices and procedures as well as fairness in interactions among the members of the community.\n- An academic community should maintain high standards of research by necessitating shared responsibility for upholding academic integrity among all members of the community.\n- The Management, the Dean and the Principal are the Board of Council and all the decisions and actions of the board should be in the best interests of the institution and employees.\n- There should be clarity of purpose and the intention behind the research activities.\n- The set standards of ethical and legal behavior to be followed by all the participants.\n- No covered party can use college property, information or position for improper personal gain without the prior written consent of the college\n- Covered Parties are required to act honestly, in good faith, and with professionalism. No Covered Party may take unfair advantage of another person through harassment, manipulation, abuse of privileged information, misrepresentation of material facts, or any other unfair practice.\n- Covered Parties must maintain the confidentiality of confidential information entrusted to them, except when disclosure is authorized by an appropriate officer of the College or required by law.\n- Investigator has to discover the relevant research problem and prepare a project proposal.\n- The proposal has to submit to a funding agency through K-RIC.\n- The Principal Investigator (PI) leads the project and keep track of the experimental process.\n- Principal Investigator has to ensure that the results are published in the form of reports or research papers in journals.\n- Principal Investigator should also inspire young researchers.\nRESPONSIBILITIES OF A RESEARCH STUDENT\n- Initially, the Research Student should consult his mentor/expert before conducting the research.\n- After consulting his/ her mentor, student must thoroughly discuss the research design, program of research, questionnaire etc.\n- Research student should be conscious of issues which are pertaining to plagiarism, intellectual property (IP), and falsification of data, and unnecessary delays in completion of their research work.\nWHAT CONSTITUTES MISCONDUCT?\nMisconduct does not include honest error or honest differences in interpretation or judgment in evaluating research methods or results, or misconduct unrelated to the research process.\nIn case of misconduct or deviation of recommended ethical practices by a research investigator or a research student, disciplinary action can be taken against them if their guilt is proved.\nThe acts which are considered as research misconduct comprises:\n- Fabrication – Reporting of experiments never conducted\n- Falsification – Misrepresentation or suppression of data to project a desired result\n- Plagiarism – Reporting another’s data as one’s own\n- Fraud – Deliberate and wilful suppression of previous work in publications to claim originality or to avoid quoting previous publications contrary to present results.\n- Breach of confidentiality - Presenting as one’s own ideas or data obtained from privileged access to original grants, manuscripts etc. is also considered as misdemeanour in the same category.\n- Violation – Violation of intellectual property rights;\n- Misuse of Funds – Misuse of research funds or resources provided by the University or an external sponsor.\nREPORTING OF CASES OF MISCONDUCT\n- Anyone has the right to report an observed, suspected or apparent misconduct to the members of the Ethics Committee when he or she becomes aware of it.\n- If an individual is unsure whether a suspected incident of misconduct falls within the definition of Misconduct, he or she should discuss this with the members of the Ethics Committee informally.\nREPORTING AND EVALUATION OF THE COMPLAINT\n- The charge of misconduct has serious effects for all concerned. Therefore, investigation related to the review of suspected misconduct will be kept confidential to the maximum extent possible.\n- The Committee should conduct a preliminary review of the report and provide an immediate opinion to the Principal Investigator.\n- If the Principal decides to set up an investigation committee, the Ethics Committee should recommend its members to the Principal to form an Investigation Committee.\nThe scope of the committee shall be:\n- To investigate the accuracy of charge of misconduct\n- To assess the extent and nature of alleged misconduct\n- The committee is expected to complete the investigations and report submission within a period of 60 (sixty) days.\n- Upon completion of investigation, the Ethics Committee should decide whether or not to take or recommend disciplinary action(s).\n- In a case of minor misconduct, the Ethics Committee is authorized to issue a Notice of Warning to or demand a Letter of Apology from an individual who is responsible for the misconduct.\n- In a case of serious misconduct, the Ethics Committee should decide whether or not to endorse consents. The consents may include, but are not restricted to:\n- Resubmission of a research work;\n- A letter of warning issued by the Principal Investigator which may or may not be recorded in the personal file of the individual;\n- Deduction from salary;\n- Suspension of grant/contract;\nThe right to interpret the provisions hereof rests with the Governing Council of the Institution. The Governing Council may give authorization to the Ethics Committee to interpret the provisions on its behalf as well.', '6.5 The Honest Truth\n- Understand the importance of academic integrity and the consequences of dishonesty.\n- Identify most common types of academic dishonesty.\nThroughout this book we have focused on the active process of learning, not just on how to get good grades. The attitude of some students that grades are the end-all in academics has led many students to resort to academic dishonesty to try to get the best possible grades or handle the pressure of an academic program. Although you may be further tempted if you’ve heard people say, “Everybody does it,” or “It’s no big deal at my school,” you should be mindful of the consequences of cheating:\n- You don’t learn as much. Cheating may get you the right answer on a particular exam question, but it won’t teach you how to apply knowledge in the world after school, nor will it give you a foundation of knowledge for learning more advanced material. When you cheat, you cheat yourself out of opportunities.\n- You risk failing the course or even expulsion from school. Each institution has its own definitions of and penalties for academic dishonesty, but most include cheating, plagiarism, and fabrication or falsification. The exact details of what is allowed or not allowed vary somewhat among different colleges and even instructors, so you should be sure to check your school’s Web site and your instructor’s guidelines to see what rules apply. Ignorance of the rules is seldom considered a valid defense.\n- Cheating causes stress. Fear of getting caught will cause you stress and anxiety; this will get in the way of performing well with the information you do know.\n- You’re throwing away your money and time. Getting a college education is a big investment of money and effort. You’re simply not getting your full value when you cheat, because you don’t learn as much.\n- You are trashing your integrity. Cheating once and getting away with it makes it easier to cheat again, and the more you cheat, the more comfortable you will feel with giving up your integrity in other areas of life—with perhaps even more serious consequences.\n- Cheating lowers your self-esteem. If you cheat, you are telling yourself that you are simply not smart enough to handle learning. It also robs you of the feeling of satisfaction from genuine success.\nResist the temptation to cheat by using material from the Internet.\nThomas Favre-Bulle – Working on UML – CC BY-NC 2.0.\nTechnology has made it easier to cheat. Your credit card and an Internet connection can procure a paper for you on just about any subject and length. You can copy and paste for free from various Web sites. Students have made creative use of texting and video on their cell phones to gain unauthorized access to material for exams. But be aware that technology has also created ways for instructors to easily detect these forms of academic dishonesty. Most colleges make these tools available to their instructors. Instructors are also modifying their testing approaches to reduce potential academic misconduct by using methods that are harder to cheat at (such as in-class essays that evaluate your thinking and oral presentations).\nIf you feel uneasy about doing something in your college work, trust your instincts. Confirm with the instructor that your intended form of research or use of material is acceptable. Cheating just doesn’t pay.\nExamples of Academic Dishonesty\nAcademic dishonesty can take many forms, and you should be careful to avoid them. The following list from Northwestern University is a clear and complete compilation of what most institutions will consider unacceptable academic behavior.\n- Cheating: using unauthorized notes, study aids, or information on an examination; altering a graded work after it has been returned, then submitting the work for regrading; allowing another person to do one’s work and submitting that work under one’s own name; submitting identical or similar papers for credit in more than one course without prior permission from the course instructors.\n- Plagiarism: submitting material that in part or whole is not entirely one’s own work without attributing those same portions to their correct source.\n- Fabrication: falsifying or inventing any information, data or citation; presenting data that were not gathered in accordance with standard guidelines defining the appropriate methods for collecting or generating data and failing to include an accurate account of the method by which the data were gathered or collected.\n- Obtaining an Unfair Advantage: (a) stealing, reproducing, circulating or otherwise gaining access to examination materials prior to the time authorized by the instructor; (b) stealing, destroying, defacing or concealing library materials with the purpose of depriving others of their use; (c) unauthorized collaboration on an academic assignment; (d) retaining, possessing, using or circulating previously given examination materials, where those materials clearly indicate that they are to be returned to the instructor at the conclusion of the examination; (e) intentionally obstructing or interfering with another student’s academic work; or (f) otherwise undertaking activity with the purpose of creating or obtaining an unfair academic advantage over other students’ academic work.\n- Aiding and Abetting Academic Dishonesty: (a) providing material, information, or other assistance to another person with knowledge that such aid could be used in any of the violations stated above, or (b) providing false information in connection with any inquiry regarding academic integrity.\n- Falsification of Records and Official Documents: altering documents affecting academic records; forging signatures of authorization or falsifying information on an official academic document, grade report, letter of permission, petition, drop/add form, ID card, or any other official University document.\n- Unauthorized Access to computerized academic or administrative records or systems: viewing or altering computer records, modifying computer programs or systems, releasing or dispensing information gained via unauthorized access, or interfering with the use or availability of computer systems or information.\n- Being dishonest can have major consequences that can affect not only your college career but also your life beyond college.\n- “Everybody does it” and “It’s no big deal at my school” are not valid reasons for cheating.\n- When you cheat, you are primarily cheating yourself.\nWhat are the most common forms of academic dishonesty you have heard about at your school? What should be done about them?\nWhat resources do you have on campus to learn about correct forms of referencing other people’s work in your own?\nUndergraduate Academic Conduct Committee of Northwestern University, “Definitions of Academic Violations,” http://www.northwestern.edu/uacc/defines.html (accessed July 13, 2010).']	['<urn:uuid:8a078e9e-378b-460f-95d0-b7a7b3379b36>', '<urn:uuid:5e6da88e-6651-41fc-9512-1be65bbcbd5e>']	factoid	with-premise	long-search-query	distant-from-document	multi-aspect	expert	2025-05-01T23:21:14.341336	12	82	2135
294	experiential learning versus behavioral theory learning how they teach students	Experiential learning and behavioral theory represent two different approaches to teaching. Experiential learning is based on constructivism, where knowledge is created personally through experience in a socialized process involving interactions with other students, content, and teachers. It emphasizes continuous development, navigating challenges, and creating new knowledge through experience. In contrast, behavioral theory approaches learning as a process of forming habits through repetition and conditioning, as demonstrated in language learning through audiolingualism. Behavioral theory focuses on measured responses to stimuli and believes all actions are learned behaviors that can be learned and unlearned through reinforcement, while experiential learning emphasizes student-centered active participation and meaning-making through experience.	['I described how games promote a student centered learning format instead of a teacher centered one. Games also allow students to learn via experience in a process called experiential learning.\nThis post will go into greater depth as to HOW learning in a games-based learning environment happens. It all starts with constructivism.\nConstructivism. What is it?\nConstructivism is a student centered approach to learning. In constructivism knowledge is created personally in a socialized process (Kolb, 1984).\nThis means that knowledge is not just given to students. Instead it is created in a process where the student is a part of a larger environment.\nThat environment includes other students, the content, and the teacher.\nConstructivism is the heart of experiential learning which focuses on experience as the main force that enables others to learn.\nExperiential learning is also a process. It’s a cycle that includes different characteristics like (Kolb, 1984; Kolb & Kolb, 2005):\nTransitory ideas (things that can change)\nContinuous development (never ending)\nNavigating and resolving conflicts (overcoming challenges and problems)\nCreating NEW knowledge\nSince experiential learning is learning by experience, we can use it to understand how people learn through games.\nThis is called games-based learning (Kiili, 2005) and it is what I’ll be applying to this study. In games-based learning, a student’s experience in the game environment is the primary way they learn.\nThis environment needs to build on relationships. Those relationships should include other students, instructors, content, and the environment. This is an environment with many connections. It is a place where students must continually navigate challenges and find resolutions.\nThese relationships form the basis for games-based learning.\nAstin (1984) discussed how greater student involvement outside of the classroom (sports, clubs, internships) relate to greater student development (happy students).\nStudents can learn as much outside of the classroom as they can inside of it. Greater student involvement in one area benefits the other. Gains in the classroom equal gains outside the classroom and vice versa.\nGames can develop this relationship by providing stimulating activities. When these activities are paired with learning objectives both fuel this student engagement.\nI argue that co-curricular learning outside the classroom paired with experiential games-based learning can achieve greater student engagement.\nThis forms the basis of my study: to seek out how undergraduate students at a small liberal arts college understand and make meaning through game play. I want to know if students who create meaning from game playing become better involved students, more engaged students, and more successful students.\nConstructivism is an educational philosophy where knowledge is created socially\nExperiential learning is a type of education where students learn through experience\nGames-based learning is an application of experiential learning for student development\nGreater student involvement inside and outside the classroom relates to greater student development (happy students)\nAstin, A. W. (1984). Student involvement: A developmental theory for higher education. Journal of College Student Personnel, 25(4), 297-308.\nKiili, K. (2005). Digital game- based learning: Towards an experiential gaming model. Internet and Higher Education, 8(1), 13-24. doi:10.1016/j.iheduc.2004.12.001\nKolb, A. Y., & Kolb, D. A. (2005). Learning styles and learning spaces: Enhancing experiential learning in higher education. Academy of Management Learning and Education, 4(2), 193-212.\nKolb, D. A. (1984). Experiential learning: Experience as the source of learning and development. Englewood Cliffs, NJ: Prentice-Hall', 'Have you ever heard about behaviorist theory applied as a strategy for Second Language Acquisition (SLA)?\nBefore giving you an insight into the topic of this week’s Video Fix ‘Behaviorist Theory of Second Language Acquisition’, let’s start with Merriam-Webster’s definition of behaviorism (also known as behavioral psychology): it is […] a school of psychology that takes the objective evidence of behavior (such as measured responses to stimuli) as the only concern of its research and the only basis of its theory without reference to conscious experience […]\nHistorically John B. Watson is recognized as the father of behaviorism. Behavioral psychology in general believes that all actions of humans and animals are learned behaviors which can be learned and unlearned.\nIt was Ivan Pavlov who investigated classical conditioning with his experiment using dogs: he rang a bell every time he fed the dogs, teaching them to associate the sound of the bell with food. As a result the dogs salivated every time the bell rang, whether there was food or not. Thus Pavlov discovered a process in which a previously neutral stimulus came to provoke a specific response by being repeatedly paired with another stimulus that evoked the response.\nEventually the American psychologist Burrhus F. Skinner expanded classical conditioning to the so-called operant conditioning. According to this theory, if a reward or reinforcement follows the response to a stimulus, then the response will become more likely in the future.\nIn the 50s and 60s it became popular to apply behaviorism to all types of learning, including language learning, which gave rise to the behaviorist theory of second language acquisition. The most well-known teaching method that emerged from behaviorism was audiolingualism, where repetitions and drills formed the basis of learning with the aim of habit formation.\nAudiolingualism was widely introduced in schools across the U.S. and reached its peak in the 1960s. But, since the learning method did not achieve the desired results (for example, students were unable to transfer the learned language skills to a real communication situation), it lost its popularity quite quickly.\nIn the late 60s the American linguistic theory began to take a different direction. Part of the reason for this change was Chomsky’s rejection of the behaviorist theory of language learning. Chomsky said that language is not a habit structure, and argued that much of human language is not imitated behavior, “but is created anew from underlying knowledge of abstract rules.”\nAfter this short introductory explanation we invite you to watch the full video and find out more about behaviorist theory and second language acquisition!\nYou might also be interested in some previous related posts:\n- Cinema Fix: Is dubbing detrimental to language acquisition?\n- The age factor in second language acquisition\n- University Language Centres: new resources and methods for language learning (and self-learning) purposes\n- Video fix: How to Learn a Second Language Faster\n- Video fix: Why you should play an instrument and learn a foreign language\nWritten by Iris Rinner – Terminology trainee at the Terminology Coordination Unit of the European Parliament, BA in Modern Foreign Languages and Cultures from the University of Sassari and MA in Specialized Translation from the University of Vienna.\n- Culatta, Richard (2015) Behaviorist Learning Theory, Available at: http://bit.ly/2jxr4aN (Accessed 23 May, 2017)\n- Kendra Cherry (2016) An Overview of Behavioral Psychology, Available at: http://bit.ly/2mOkKeD (Accessed 23 May, 2017)\n- Merriam-Webster, Available at http://bit.ly/2qRnZ7J (Accessed 23 May, 2017)\n- Jack C. Richards, Theodore S. Rodgers (2014) Approaches and Methods in Language Teaching. Third Edition, Cambridge University Press, Available at: http://bit.ly/2qfTRkr (Accessed 23 May, 2017)']	['<urn:uuid:31fafe39-aa20-4768-b5e7-bc8595c1cf84>', '<urn:uuid:665f5ca6-70f6-43f3-b4a6-f2b74f307bf9>']	open-ended	with-premise	long-search-query	similar-to-document	comparison	novice	2025-05-01T23:21:14.341336	10	105	1144
295	As a breast cancer researcher studying viral links, how does MMTV transmission and treatment differ from BRCA-related cancers?	MMTV (Mouse Mammary Tumor Virus) and BRCA-related cancers have distinct characteristics and treatment approaches. MMTV is transmitted through milk and involves viral interactions, with its envelope protein potentially participating in transformation. The virus specifically targets mammary epithelial and lymphoid cells, with increased transcription during pregnancy and lactation. In contrast, BRCA-related breast cancers are hereditary and have specific treatment options, including PARP inhibitors like Lynparza and Talzenna for metastatic cases. BRCA1 mutation carriers tend to develop more aggressive breast cancers and may respond particularly well to platinum-based chemotherapy. Additionally, due to high risk of second cancers, BRCA mutation carriers often opt for bilateral mastectomy rather than lumpectomy.	"['Mouse mammary tumor disease has served while a major model for the study of breast tumor since its finding 1920’s like a milk-transmitted agent. of the infectious cycle. The envelope protein may also participate in transformation. Although there have been several reports of a similar virus in human being breast tumor the living of a human being MTV has not been R547 definitely founded. model for the study of mammary carcinogenesis (2 3 Here I review the biology of MMTV its transmission pathway and how it interacts with its host’s biology. I also review the current literature concerning a putative related human being mammary tumor disease (HMTV). MMTV genome structure and proteins Retroviruses can be classified as simple or complex. The genomes of simple retroviruses such as murine leukemia disease (MLV) encode only the virion proteins and enzymes necessary for viral replication. On the other hand complex retroviruses individual immunodeficiency trojan (HIV)-1 or individual T cell leukemia trojan (HTLV) 1 encode furthermore a number of nonstructural protein that facilitate several steps from the replication pathway or counteract mobile and immunological anti-viral web host replies. While MMTV was classified as a straightforward retrovirus it really is today clear it most likely lies somewhere among infections like MLV and HIV-1 in intricacy. The MMTV genome is 9 kb in proportions approximately. At least five transcripts are produced in the viral genome four which start in the 5′ longer terminal do it again (LTR) and terminate in the 3′ LTR; the various transcripts R547 are produced by choice splicing (Fig. 1). The LTR also includes binding sites for transcription elements that determine hormone-responsive and tissue-specific transcription both which are essential for an infection and optimal trojan production. Particularly the LTRs encode sites that control both mammary epithelial and lymphoid cell-specific appearance aswell as glucorticoid/progesterone response components that cause elevated trojan transcription during being pregnant and lactation when virions are shed into dairy (4-8). As the MMTV LTR encodes transcriptional regulatory components that direct advanced appearance in mammary epithelial cells it’s been broadly used to operate a vehicle transgene appearance in mouse mammary tissues (analyzed in XXX this quantity). Fig. 1 MMTV proviral gene and genome items. Like all retroviruses the full-length unspliced MMTV RNA Rabbit polyclonal to PECI. acts two R547 functions. First two copies are packaged into virions and offer the viral genome therefore. Second the full-length transcript acts as the mRNA for the gene items encoded from the and genes (9). The translation item can be a polyprotein precursor that’s processed from the viral protease PR or Pro in to the capsid (CA) and nucleocapsid (NC) proteins aswell as other peptides of unfamiliar function. Both Dut-Pro and Pol polyproteins are translated through the same mRNA as Gag however in different reading structures by an activity termed ribosomal frameshifting. The gene encodes the viral protease and a dUTPase whose part in virus disease isn’t known. But also for additional retroviruses that encode a dUTPase such as for example equine infectious anemia disease (EIAV) it really is believed that protein plays a part in pathogenesis by keeping adequate nucleotide swimming pools and therefore facilitating effective viral replication in nondividing cells (10). Since MMTV infects R547 dendritic cells (DCs) that are nondividing gene rules for invert transcriptase (RT) had a need to generate the double-stranded DNA as well as the integrase (IN) which is necessary for integration of the DNA in to the sponsor chromosome. A singly spliced mRNA can be translated through the envelope ((12-14). Cell-type restriction can be probably because of post-entry events However. Including the enhancer components in the LTR function mainly in mammary epithelia and lymphoid cells and therefore MMTV isn’t transcribed in lots of cells (15). Retroviral Env proteins can possess other activities furthermore to mediating mobile admittance and recent function has indicated how the MMTV Env proteins may play extra roles in disease and MMTV-mediated tumorigenesis. Furthermore to getting together with TfR1 to mediate viral admittance the Env proteins has been proven to activate antigen showing cells like DCs and B cells via Toll-like receptor 4 (TLR4) (16 17 TLR4 can be an associate of a family group of receptors that.', ""Treatment decisions for people with hereditary breast cancer\nHereditary cancers are different than sporadic cancers in ways that can affect treatment choices. Some treatment decisions that may be influenced by genetic test results are listed below. If you are concerned that your cancer may be caused by an inherited mutation, you should contact a genetics expert to see if genetic testing is right for you.\n- PARP inhibitors for metastatic breast cancer: Lynparza and Talzenna are targeted therapies known as PARP inhibitors. Both agents have received FDA approval for treating\nmetastatic breast cancer caused by a BRCA mutation. The National Comprehensive Cancer Network (NCCN) added Lynparza as a preferred single agent treatment for people with Her2-negative, metastatic breast cancer who carry a BRCA1 or BRCA2 mutation. You can read more about PARP inhibitors here.\n- Choice of breast surgery: Because of the very high risk for a second (or third) breast cancer diagnosis, women who are diagnosed with breast cancer who test positive for an inherited mutation often choose bilateral mastectomy (surgical removal of both breasts) rather than lumpectomy and radiation. Mutation carriers who undergo mastectomy are less likely to develop a second breast cancer since the at-risk breast tissue has been removed. Our mastectomy section provides more information about surgical options.\n- Participation in treatment clinical trials: Some research studies are exploring new treatments to specifically to treat hereditary breast cancer. If you are interested in the possibility of participating in a clinical trial, it is best to express your interest when you are first diagnosed or have a recurrence and before you start treatment. Using our Research Search Tool, you can find clinical trials enrolling patients with hereditary breast cancer.\n- Oophorectomy vs. medication to induce menopause:\nBRCA mutation carriers are at increased risk for ovarian cancer. In young women with ER-positive breast cancer, treatment sometimes includes injections to shut down the ovaries' production of estrogen. Another option may be an oophorectomy (surgical removal of the ovaries), which lowers the risk for ovarian cancer as well. Oophorectomy may lower the risk for new breast cancers in BRCA carriers who have not have bilateral mastectomies.\n- Tamoxifen, aromatase inhibitors, or other hormonal therapies:\nTamoxifen is a drug used to treat ER-positive breast cancer. Aromatase inhibitors are drugs prescribed to post-menopausal women with breast cancer to reduce estrogen production by their fat cells and adrenal glands. These drugs are used to help prevent breast cancer recurrence in women with ER-positive or hormone-receptor positive cancers. Research on these drugs suggests that they not only lower the risk for subsequent breast cancers in women who have already been diagnosed, but also in those at risk who have not ever been diagnosed with breast cancer.\n- Use of chemotherapy agents:\nSome research studies show that women with\nBRCA1 mutations tend to develop more aggressive breast cancers than those in women who develop sporadic breast cancer. A small study suggests that women with BRCA1 mutations who received any chemotherapy had better outcomes than women who did not receive chemotherapy. Other research suggests that BRCA-positive individuals diagnosed with triple-negative breast cancer may respond particularly well to platinum-based chemotherapy.\nIf you are a breast cancer survivor making decisions about genetic testing can be confusing and you may want additional guidance or support. FORCE's Peer Navigation Program provides expert reviewed resources and 1:1 personalized peer support by specially trained volunteers who have experienced the very challenges you face.""]"	['<urn:uuid:58099303-5585-4069-95a6-06fb16048d09>', '<urn:uuid:a0d39458-531e-422e-93e9-6ce962ef7c26>']	open-ended	with-premise	concise-and-natural	similar-to-document	three-doc	expert	2025-05-01T23:21:14.341336	18	106	1264
297	How do both community gardening projects and flexible work arrangements contribute to better mental health and community wellbeing?	Both initiatives significantly improve mental health and community connections. Living in greener neighborhoods has been shown to improve mental health and increase life spans, with patterns indicating lower crime rates in greener areas. Guerrilla gardening helps create a sense of belonging and ownership in neighborhoods, particularly beneficial for young urbanites who often feel disconnected from their communities. It brings people together and lifts spirits by adding life to otherwise grey areas. Similarly, the 4-day workweek has demonstrated remarkable benefits for mental wellbeing, with studies showing that 78% of staff report being happier and 70% experiencing reduced stress levels. Employees with 4-day workweeks also took fewer sick days, and 25% of employees stated they would use their extra day off to volunteer in their communities, further strengthening community bonds.	"[""Meet the guerrilla gardeners of Europe. Their form of climate activism transforms neighbourhoods and brings local communities together.\nClimate activism has become increasingly synonymous with rebellion. International groups like Zero Hour and Extinction Rebellion summon huge crowds of protestors and find headline-baiting ways to express their anger.\nBut what if there was a way to advocate for the environment in your local neighbourhood through small, everyday actions?\nGuerrilla gardening is the act of cultivating plants in a public place, usually in a spot that is not otherwise being cared for, often with the aim of improving the surroundings and protecting the environment. It has a range of benefits from improving biodiversity to helping to keep temperatures low.\nJenny van Gestel, coordinator of Guerrilla Gardeners NL, explains how transforming one street can have a far-reaching impact on the environment.\nIs guerrilla gardening illegal?\nMany people assume that guerrilla gardening is illegal - and sometimes it is. For Ellen Miles, climate activist and founder of social enterprise Dream Green, guerrilla gardening is definitely an anarchic form of protest.\n“It’s direct action against nature deprivation and depletion - highlighting the issue of biophobic urbanisation while fighting it,” explains Ellen.\n“It’s fighting for people, plants, and the planet by taking action into your own hands. It’s anarchic, in the purest sense, and is challenging the status quo of what we’ve been taught cities should look like, and who can have the power and right to shape them.”\nBut it doesn’t have to be illicit activity. Part of Jenny’s work with Guerrilla Gardeners NL is to reassure people that there are ways to take part in this form of activism legally, even with the blessing of local authorities.\nShe regularly works with the municipal government where she lives in the Netherlands, identifying greening projects together with local civil servants. She also tries to encourage locals to get involved in areas near them.\n“One of the things I've been doing here is trying to get people that have [tree pits] in front of their house or near their house to garden in them,” Jenny says. “There's so much you can do just by cooperating with the authorities.”\n“You do not need an organisation. Just as an individual, there's so much you can do...Start small. You don't have to start with a huge garden, just start by removing one paving stone, add one plant, and then just see how it goes. See how the neighbours respond, see how the plant starts growing, and maybe you can develop it from there.”\nGetting started with guerrilla gardening\nJenny believes that anyone can get started with guerrilla gardening - even if there’s no organised group near you. If you spot a neglected area of public space that no one else is using, it’s a prime opportunity to get involved.\nIf you’re nervous about whether it’s allowed, you can reach out to your local government, but both Jenny and Ellen say they rarely run into obstacles when planting on otherwise unused spots.\n“Part of the guerrilla gardening concept is asking for 'forgiveness not permission' but I’ve only ever received positive responses from people, so no forgiveness needed,” explains Ellen.\n“It’s mainly about where you plant. First, you want to avoid planting on anyone’s private property or a protected spot (like a National Trust site or nature reservation).”\nEllen explains that tree pits are a great way to start. Although they don’t advertise it, many councils will allow you to plant here as long as you don’t damage the tree.\n“I’ve never had any trouble just using common sense to see what’s a neglected, bare spot of soil that was meant to have plants in but now doesn’t. If the council aren’t going to look after it, why shouldn’t a resident name themselves its gardening angel?”\nRemember that dogs, people and various hazards might bother your patch. So when you pick what to plant it needs to be hardy, resilient and able to cope with the climate without too much assistance from you. Otherwise, you’ll have to keep coming back to tend to the plants, meaning less time to spend on new areas.\n“When choosing plants, we also take into account what would [attract] wild bees, what would attract butterflies, and so on,” explains Jenny. “That's another aspect and they're often indigenous species.”\nWhy is greening important?\nAside from the environmental benefits, now more than ever, caring for our local areas is beneficial for ourselves and our communities.\n“It's interesting to note that the movement is growing again,” says Jenny. “Because of the previous year that we've had and people [being] stuck inside...there's a renewed interest in our own neighbourhoods.”\nEllen also sees the connection between guerrilla gardening and community. She notes that living in greener neighbourhoods improves mental health, life spans increase and that there are patterns indicating that crime is less common in greener areas.\n“I find it empowering to positively impact my local environment and have a sense of ownership of the place I live,” explains Ellen. “There’s a real issue of young urbanites not feeling they ‘belong’ in their neighbourhood, and it’s clear why - cities just aren’t designed for people.\n“Guerrilla gardening puts the power to transform the streets that people live in in the hands of the people who live there. It lifts the spirits seeing bright patches of life in otherwise bare, grey spots and I love knowing that I’m helping the local ecosystems and community.”"", ""The 4-day workweek is likely one of the most successful work schedules that I have implemented in my career in terms of employee engagement, employee development, team readiness, and employee delight. Put simply, employees love 3-day weekends, and these can be created by a 4-10 work schedule. Let me explain.\nYears ago I ran a 24x7 operation with a central station and monitored services worldwide. We experimented with many different shift types and schedules. The worst of all schedules was the 3x12s, where a worker spends three days at work in 12-hour shifts, and barely has time to get home and get rested before they return to work; they were tired, angry, sleepy, error-prone, and not fit for work after a series of these challenging 3x12s. However, the 4x10s were almost magical. To cover our 7-day schedule, we overlapped two 4x10s, where every employee worked one weekend day. Employees could choose to work from Sunday through Wednesday, or Wednesday through Saturday. We used Wednesdays as team training days, employee development days, and planning days. Our team was so trained up, so communicative based on being together on Wednesdays, that it ignited the creativity, collaboration, and goodwill of our team members. They were also highly grateful for the addition of the regular 3-day weekends to their schedule. I don’t think I’ve had a happier group of employees than those who were on the 4x10 schedule. Importantly, this saved us money (in terms of office space) and gave us great flex capacity to expand work with multiple shifts of well-rested and highly trained employees. That was my experience and I highly recommend it for consideration to others. Now, what does independent research say about the 4x10 work week?\nSome businesses in the UK are currently experimenting with operating on a 4-day workweek. Spurred on by The 4 Day Week Campaign, businesses such as the Earth Science Partnership, Social Enterprise Direct, and The UPAC Group (Scotland's largest independent packaging supplier), have all implemented 4-day workweek standards (The4DayWeek, n.d.). Are these businesses venturing into the unknown, or is there data that supports a shortened workweek? What are the benefits and drawbacks of the 4-day workweek? What should managers and business leaders consider when implementing or leading shortened workweeks? Continue to find out.\n“To improve is to change; to be perfect is to change often.” - Winston Churchill\nDefining a 4-day workweek\nIn order to examine the effects of a 4-day workweek, we must first have a clear definition of a 4-day workweek. The 4 Day Week Campaign defines a 4-day workweek as “a 32-hour working week (or less) worked over 4 days with no reduction in pay.” For The 4 Day Week Campaign, a 4-day workweek is not 4 days of 10-hour shifts. However, not all organizations look at the 4-day workweek the same way. For example, companies in Japan are encouraged to allow their employees to work 4, 10-hour days (Harter &Pendell, 2021). This is an important difference to consider when examining the available data and considering the implementation of a 4-day workweek.\nBelow we review some of the key data points and statistics regarding a 4-day workweek.\nHenley Business School UK 2019\n⅔ of businesses with a 4-day workweek “reported improvements in staff productivity”\n⅓ of business leaders believe that switching to a 4-day workweek will be “important for success in the future”\n¾ of surveyed Brits support a 4-day workweek\n67% of Gen Z Brits claim that when job searching, the proposition of a 4-day workweek, would “help them pick a place to work”\n4-day workweeks “could save UK businesses an estimated £104 billion annually”\nIncreased productivity via increased staff mental and physical health\nA 4-day workweek can reduce environmental output\n78% of staff state that they are happier with a 4-day workweek\n70% of staff experienced reduced levels of stress\n62% of staff took fewer days off due to illness\n63% of employers said that having a 4-day workweek “has helped them to attract and retain talent”\n25% of employees stated that they would use their extra day off to volunteer\n40% of employees would use the extra time off to “up-skill or develop professional skills”\n72% of survey participants said that a 4-day workweek would be a “firm driver” when job searching\nThe 4-day workweek does not increase employee engagement\nThe 4-day workweek is associated with an increase in “thriving wellbeing”\n“The percentage of actively disengaged workers was highest for those with 4-day and 6-day work weeks”\nQuality of workplace experience has “2.5 to 3 times the impact” on “overall wellbeing” than the “number of days or hours worked” (Harter & Pendell, 2021).\nNote: these statistics are based on organizations that work at least 35 hours per week during a 4-day workweek\nSociety of Human Resource Management\n45% of survey respondents said that they “were interested in working an alternative work schedule”\n80% of employees claim that “they would be more loyal to their employers if they had flexible work options”\n23% of organizations run on a “true 4-day workweek”\n60% of organizations that operate on a 4-day workweek express “gains in employee satisfaction and productivity resulting from fewer meetings”\n39% of U.S. workers have a “distaste for the 4-day workweek”\nCommon reasons for disliking the 4-day workweek include the “inability to maintain social aspects of work, limited productivity, and fear of distractions from their work”\n“Time management is a misnomer, the challenge is to manage ourselves.” - Stephen R. Covey\nBenefits of the 4-day workweek\nFewer workplace distractions\nIn an article by AdeccoGroup, “Andrew Barnes, the owner of New Zealand law firm Perpetual Guardian” reported that employees were less distracted from work after implementing a 4-day workweek program. Employees spent “35% less time on non-work websites” and they believe it is because they had more time to manage their “household life and responsibilities outside of work” (AdeccoGroup, 2021). Other organizations such as TimeCamp state that when employees are more relaxed and less stressed due to the extended 3-day weekend, they are less likely to be distracted (Rybacka, 2021). This assumption is backed by The Anxiety Center’s president Jim Folk who states that “being easily distracted is a common indication of persistently elevated stress” (Folk, 2021). By giving employees more time to fulfill their household responsibilities, rest, de-stress, and invest in their relationships with friends and family, 4-day workweek businesses are helping their employees focus on work when at work and home when at home.\nClosely related to the increased focus of 4-day workweek employees, 4-day workweeks have also been associated with an increase in productivity. After examining over 250 global workplaces that have implemented a shortened workweek, the Henley Business School states that “two-thirds of UK businesses operating on a four-day week reported improvements in staff productivity” and that this was due to the increased mental health and wellbeing of staff (HenleyBusinessSchool, 2019). Furthermore, the Society of Human Resource Management reports that 60% of organizations that operate on a 4-day workweek increased their “productivity” due to the reduced amount of “meetings” (Agovino, 2020). According to Deutsche Welle, in 2019, Microsoft Japan experimented with giving all employees Fridays off, resulting in a 40% increase in productivity (Imran, 2021).\nIncreased attraction of new employees\nThe 4-day workweek is especially attractive to employees. According to Henley Business School, 67% of Gen Z Brits claim that when job searching, the proposition of a 4-day workweek would be a driving force that helped them pick where they wanted to work. They also report that 75% of Brits, in general, are in support of a shortened workweek (HenleyBusinessSchool, 2019). A survey done by the Society of Human Resource Management reported that 45% of people are interested in an “alternative work schedule” (Agovino, 2020). Since the COVID-19 pandemic, employees have become increasingly concerned with their quality of life and work/life balance. According to PWC’s workforce pulse survey findings, “employees deeply value extra paid time off, including dedicated time to upskill or volunteer, as so important they’d give up part of their future earnings to get it.” Employees are searching for careers with increased “flexibility” and “personalization” (pwc, 2021). By offering a 4-day workweek, employers can increase the flexibility they offer their employees, ultimately attracting more employees.\n“It’s about getting the best people, retaining them, nurturing a creative environment & helping to find a way to innovate.” - Marissa Mayer\nIncreased retainment of employees\nNot only does a 4-day workweek increase the attractiveness of an organization to potential employees, but it also helps them retain the employees they already have. According to surveys done by the Henley Business School, 63% of employers reported that having a 4-day workweek “has helped them to attract and retain talent” (2019). TimeCamp also states that 4-day workweeks can prevent employee burnout (Rybacka, 2021). The Society of Human Resource Management also states that “80% of employees claim that they would be more loyal to their employers if they had flexible work options” (Agovino, 2020).\nIncreased employee wellness\nThere are a myriad of benefits to employee wellness that a 4-day workweek offers. Surveys by the Henley School of Business reported that for 4-day workweek businesses, 78% of staff are happier, 70% of staff experienced reduced levels of stress, and 62% of staff took fewer sick days compared to the standard 5-day operation (2019). Research by Gallup also reported increased rates of employee wellbeing (Harter & Pendell, 2021). Owl Labs summarizes this well by stating that the increased flexibility and work-life balance afforded by the 4-day workweek “helps employees be healthier and ready to work” (Duff, 2020).\nEnvironmental and economic benefits\nBy transitioning to a 4-day workweek, employers can reduce their carbon footprint and save money. Research from the University of Massachusetts indicates that employers who transition to a 4-day workweek could reduce their carbon footprint by almost 30% (Knight et al., 2012 & Smedley, 2019). Furthermore, the Henley School of Business estimates that by implementing 4-day workweeks, UK businesses could save approximately £104 billion or $142.52 billion per year (2019). Microsoft Japan’s 4-day workweek also provided a 23% reduction in electricity costs. They also reported using 60% less paper (NPR, 2019). 4-day workweeks not only reduce the cost of overhead but also reduce the cost of commuting for employees (Rybacka, 2021).\nDrawbacks of the 4-day workweek\nWhile most researchers support the implementation of the 4-day workweek, there are some drawbacks to consider.\nPotential for decreased engagement\nResearch by Gallup indicates that although a 4-day workweek is associated with thriving and wellbeing, it also represents a decrease in workplace engagement. They claim that “the percentage of actively disengaged workers was highest for those with 4-day and 6-day work weeks” (Harter & Pendell, 2021). However, their study was done with companies that have implemented a 4-day workweek while maintaining at least 35 hours of work. The companies surveyed did not reduce their hours to the traditional 8-hour workdays and added at least 45 minutes per day and at most 2 hours per day to their employees' daily work hours. This could indicate a difference between the results of a compressed 4x10 workweek versus a shortened 4x8 workweek.\nRegardless, Harter and Pendell of Gallup conclude that employers should first focus on the quality of the workplace and state that by “working fewer days per week, employees who already feel disconnected from their employer, team, or manager are more likely to drift even farther away—from tolerating their jobs to hating them” (2021). By first examining the workplace, employers can best determine what type of 4-day workweek is most beneficial and effective for their employees.\nMuch of the benefits of a 4-day workweek extend from how employees use their extended time off. One concern for managers is that their employees will get second or third jobs to fill up their additional free time. Instead of taking the extra time off to recuperate, some employees could return to the workplace more tired than they were in the previous week. Encouraging employees to use this time to rest, recuperate, volunteer, spend time with friends, invest in family, gain new skills, and develop new hobbies can prevent these concerns as well as corporate-wide policies regarding additional jobs.\nNot for everyone\nNot all industries can adopt a 4-day workweek policy. For example, medical centers and emergency response teams need staff 24/7. This could cause scheduling challenges or conflicts if a 4-day workweek policy were implemented (Rybacka, 2021).\nLess time to complete tasks\nSometimes, when implementing a 4-day workweek, employees are given less time to do the same amount of work. This can be particularly stressful for some employees with many duties and responsibilities (Shenton, 2021). However, it is important to note that on average, the 8-hour workday does not equal 8 hours of continuous work. A survey of 1,989 adults by VoucherCloud, revealed that only 2 hours and 53 minutes out of an 8-hour workday were devoted to “actual productivity” (VoucherCloud, n.d.). By encouraging employees to monitor their time well and having clear expectations for employees and their roles, this drawback to the 4-day workweek can be effectively managed.\n“An hour of planning can save you 10 hours of doing.” -Dale Carnegie\nThings to consider\nWhen examining the potential adoption of a 4-day workweek, it is important to consider how your business will function within these 4 days. Will employees be expected to work 10 hours or the traditional 8 hours per day? Will vacation time be reduced in light of the new 3-day weekend? Will employees' pay be affected? Can your organization transition to a 4-day workweek? The Society of Human Resource Management outlines several important questions below:\nWhy are you considering a 4-day workweek? What are your goals?\nHow will you determine if a 4-day workweek is effective for your business?\nWill your entire business adopt the 4-day workweek or only some staff?\nHow will the 4-day workweek affect clients and customers? (Agovino, 2020)\nA key thing to remember when implementing a 4-day workweek is the importance of “deep work” or “the specializations and expertise that define careers and helps businesses grow” (Nagele, 2021). By encouraging employees to concentrate on completing important tasks and also providing them the resources they need to focus (quiet rooms, optional break areas, etc.), employers can help employees complete their traditional 40-hour workload in a more time-efficient manner.\n“When people tell me they’ve learned from experience, I tell them the trick is to learn from other people’s experience.” - Warren Buffett\nAs more companies transition to a 4-day workweek, businesses are sharing their experience and outcomes. Below is a list of available case studies and examples of companies that have implemented 4-day workweeks.\nThe main takeaway\nThe results reported by businesses that implemented a 4-day workweek are promising. With a variety of positive outcomes, it is currently a policy that many employers are testing. It is important to consider the differences between various 4-day workweek policies and adjust your own policy so it fits your industry, employees, and business. When implemented with precision and clarity, the 4-day workweek inspires employees to recoup, relax, and effectively use their time.\n“It is not enough to be busy… The question is: what are we busy about?” - Henry David Thoreau\n4 Day Week. (n.d.). 4 Day Week Campaign | Campaign for a shorter working week. https://www.4dayweek.co.uk/.\nAdeccoGroup. (2021, June 22). The Advantages and Disadvantages Of The Four-Day Work Week. https://www.adeccogroup.com/future-of-work/latest-insights/the-advantages-and-disadvantages-of-the-four-day-work-week/.\nAgovino, T. (2020, June 20). The Phenomenon of the Four-Day Workweek. SHRM. https://www.shrm.org/hr-today/news/all-things-work/pages/four-day-workweek.aspx.\nDuff, C. (2020, June 15). Why You Should Try a 4-Day Workweek (+ How to Pitch It). Owl Lab. https://resources.owllabs.com/blog/four-day-work-week#pros-and-cons.\nFingerprintForSuccess. (n.d.). Can the four day work week save us? (A look at the statistics). https://www.fingerprintforsuccess.com/blog/four-day-work-week.\nFolk, J. (2021, May 18). Easily Distracted Anxiety Symptoms. AnxietyCentre.Com. https://www.anxietycentre.com/anxiety-disorders/symptoms/easily-distracted/#:%7E:text=Being%20easily%20distracted%20is%20a,cause%20the%20easily%20distracted%20symptom.\nHartmans, A. (2021, March 17). Spain’s government has agreed to test a 4-day workweek where employees would make the same amount while working fewer hours. Business Insider. https://www.businessinsider.com/spain-testing-4-day-workweek-pilot-program-2021-3?international=true&r=US&IR=T.\nHenleyBusinessSchool. (2019). Four-day week pays off for UK business. https://www.henley.ac.uk/news/2019/four-day-week-pays-off-for-uk-business.\nImran, W. (2021, May 9). Working four days a week: Hit or miss? Deutsche Welle. https://www.dw.com/en/four-day-work-week-a-mixed-success/a-59091672.\nKnight, K., Rosa, E., & Schor, J. (2012). Reducing Growth to Achieve Environmental Sustainability: The Role of Work Hours. University of Massachusetts Amherst.\nNagele, N. (2021, June 15). 4-day workweeks can’t work without deep work. Wildbit. https://wildbit.com/blog/4-day-workweeks-cant-work-without-deep-work.\nnpr. (2019, November 4). 4-Day Workweek Boosted Workers’ Productivity By 40%, Microsoft Japan Says. https://www.npr.org/2019/11/04/776163853/microsoft-japan-says-4-day-workweek-boosted-workers-productivity-by-40.\nPendell, R., & Harter, J. (2021, September 9). Is the 4 Day Work Week a Good Idea? Gallup. https://www.gallup.com/workplace/354596/4-day-work-week-good-idea.aspx\npwc. (2021). What’s next for America’s workforce post-COVID. https://www.pwc.com/us/en/services/consulting/workforce-of-the-future/library/workforce-pulse-survey.html.\nRybacka, O. (2021, October 26). The Pros and Cons of a 4 Day Work Week. TimeCamp. https://www.timecamp.com/blog/2021/10/the-pros-and-cons-of-a-4-day-work-week/.\nShenton, C. (2021, August 19). Disadvantages of a 4 day work week: Still worth a go? Weekly10. https://www.weekly10.com/disadvantages-of-a-4-day-work-week/.\nSmedley, T. (2019, August 6). How shorter workweeks could save Earth. BBC Worklife. https://www.bbc.com/worklife/article/20190802-how-shorter-workweeks-could-save-earth#:%7E:text=New%20research%20by%20Henley%20Business,days%20off%20ill%20(62%25).\nThe 4 Day Week Campaign. (n.d.). FAQs. 4 Day Week. https://www.4dayweek.co.uk/faqs\nVoucherCloud. (n.d.). How Many Productive Hours in a Work Day? Just 2 Hours, 23 Minutes. . . https://www.vouchercloud.com/resources/office-worker-productivity.\nCopyright © 2022 by Arete Coach™ LLC. All rights reserved.""]"	['<urn:uuid:8c12f604-7ebf-4d13-accd-11d477fb76fd>', '<urn:uuid:717e443b-fdbb-48a8-a63b-c694c204f9b5>']	open-ended	direct	verbose-and-natural	distant-from-document	multi-aspect	novice	2025-05-01T23:21:14.341336	18	128	3756
298	What makes the Horezu Monastery significant in terms of its architectural and artistic value?	The Horezu Monastery, founded in 1690 by Prince Constantine Brancoveanu, is the largest monastic settlement in Walachia and a UNESCO World Heritage site. It is considered a masterpiece of the Brancovenesti style, known for its rich sculptural details, religious compositions, and painted decorative works. The monastery contains valuable collections of frescoes and icons from the late 17th and early 18th centuries.	['Oltenia (Lesser Wallachia in antiquated versions, with the alternate Latin names Wallachia Minor, Wallachia Alutana, Wallachia Caesarea in use between 1718 and 1739) is a historical province and geographical region of Romania, in western Wallachia. It is situated between the Danube, the Southern Carpathians and the Olt river (although counties to the east run across the river in Muntenia in some areas).\nA must stop for art lovers is the town of Targu Jiu on the banks of the Jiu River. This former market town is closely associated with Constantin Brancusi, the Romanian artist who is considered to be the founder of modern sculpture.\nSome of Romania’s most tranquil monasteries can be found in this region, including Horezu, a masterpiece of the ‘Brancovenesti’ architectural style and a designated UNESCO World Heritage site. Horezu is also a renowned pottery center, where travelers can marvel at the colorful pottery created in local workshops by talented artisans.\nWhen you mention traditional food in the Oltenia region, Oltenian sausages come first to mind – finely chopped beef and pork meat mixed with garlic, pepper and salt, and then stuffed into sheep guts and smoked for two hours. Then you have to mention beef ragout, carp stuffed with mushroom, lamb stew with chives and smoked bacon. In this region, like all over the country, onion and garlic are highly praised, combined with other ingredients to make deliciously savory dishes.\nThe university town of Craiova, founded on the site of the Dacian stronghold Pelendava (which later became the Roman Castra Nova), prides itself on the strong academic tradition and wealth of important historical figures who passed through here on their journey to fame: Wallachian Prince Mihai Viteazu – who served as the ban (military governor) of Craiova and achieved the first unification of the three Romanian principalities in 1600, the world-famous sculptor Constantin Brancusi – who studied at the Craiova Art School (Scola de Arte si Meserii) between 1894 – 1898 and carved his first sculptures here, and Craiova-born Petrache Poenary (1799- 1875) – inventor of the first cartridge fountain pen.\nThe majority of train locomotives in Romania originated at the Electroputere workshops in Craiova.\nIn 1913, the treaty of peace which ended the Balkan War, treaty known in history as The Peace from Craiova, was signed here.\nThe bans had the right of coining money stamped with their own effigies, hence the name of bani (centimes) in Romanian language.\nThe city hosts a great number of religious buildings, many of them dating back to medieval times. The Church of Cosuna Monastery for example is the oldest building preserved in Craiova, dating from the 15th century. You can spend a relaxing afternoon visiting the monastery, located only 2.1 miles outside of the city centre. Another religious site, Madona Dudu Church, is renowned for its mural paintings, completed by the famous Romanian painter Gheorghe Tattarescu (1818 – 1894).\nFor those who want to find out more about the history and the traditions of this region we recommend a visit to the Oltenia Museum, housed in Baniei House (1699), the oldest non-religious building that exists in Craiova and one of the oldest lay buildings in the country.\nArt lovers should definitely not miss the Art Museum in Craiova, hosted in the Dinu Mihail Palace, built in the early 1900s in neo-classic style by a French architect. The Museum exhibits valuable masterpieces created by famous Romanian painters, among them Craiova-born Theodor Aman (1831 – 1891) and Nicolae Grigorescu (1838 – 1907). One of its main attractions is the section dedicated to Constantin Brancusi, comprising six of his early sculptures.\nAt the end of the 17th century and the beginning of the 18th century, Craiova’s architecture underwent a transformation with the creation of the Brancovenesti style, a combination of Romanian traditional art, Byzantine and Venetian elements. Churches still displaying elements of the Brancovenesti style include: the Saint Ilie Church / Biserica Sfantu Ilie, built in 1720 by Ilie Oteteleseanu and the great tradesmen of the town, the All Saints Church / Biserica Tuturor Sfintilor (1700), the Old Saint Gheorghe Church / Biserica Sfantu Gheorghe Vechi (1730), the Obedeanu Monastery / Manastirea Obedeanu (1747), the Mantuleasa Church / Biserica Mantuleasa (1786), the Saint Nicolas Church / Biserica Sfantul Nicolae (1794).\nThe Jitianu Monk Monastery, located 4.6 miles south of the city centre, was built under the guidance of Lady Balasa, wife of ruler Constantin Basarab Carnu (1654- 1658), and houses a rich collection of medieval art objects. For those interested in enjoying a relaxing afternoon outside, the Nicolae Romanescu Park, is a veritable green oasis. The park is one of the valuable monuments of landscape architecture in Romania. The plans for the park, designed by French architect Emile Rendont, were awarded the gold medal at the 1900 World Fair. Through the initiative of Nicolae P. Romanescu, then mayor of Craiova, work on the park began in 1901 and was completed in 1903.\nFor the ones who want to experience the nature more scientifically, a stop at the Botanical Garden would be the best choice.\nHorezu Monastery & Horezu Pottery Center\nThe Horezu Monastery, the largest monastic settlement in Walachia, was founded in 1690 by Prince Constantine Brancoveanu. A masterpiece of the Brancovenesti style and a UNESCO World Heritage site, Horezu is renowned for the richness of its sculptural detail, the treatment of its religious compositions and its painted decorative works. The monastery houses precious collections of frescoes and icons dating from the end of the 17th century and the beginning of the 18th century. The nearby village of Horezu is home to one of the biggest pottery centres in Romania. Nearly a century ago, local nuns taught the villagers how to make and paint pottery, and ever since, people have come from far and wide to get their hands on Horezu’s ceramic.\nCurtea de Arges\nCurtea de Arges is a city in Romania, situated on the right bank of the Argeş River, where it flows through a valley of the lower Carpathians (the Făgăraş Mountains), on the railway from Piteşti to the Turnu Roşu Pass. It is part of the Argeş County.\nFifty miles east of Horezu you can visit another stunning architectural gem: the 16th century Curtea de Arges Monastery (Manastirea Curtea de Arges), toppled with two towers spiraling in opposite directions. Behold the sad legend of Manole as you take in its beauty. Romania’s first two kings and queens are buried here.\nA former Roman settlement, the city of Targu Jiu lies at the foothills of the Carpathian Mountains, on the banks of the river Jiu. Inhabited since Paleolithic times, the region of western Oltenia was of strategic importance to the Romans. The area provided direct access, through one of the most spectacular passes in the Carpathians, to present-day Transylvania, the heart of the former Dacian Kingdom.\nConstantin Brancusi, one of the most influential modern sculptors of the 20th century, was born near Targu Jiu, in Hobita. Although he lived and worked for most of his life in Paris, his legacy is also preserved in Romania, in the city of Targu Jiu.\nThe Jiu River valley was the scene of heavy fighting during World War I and World War II. Here, in a monumental ensemble, Brancusi created three sculptures as a memorial to the 8,500 Romanian soldiers who died defending the Jiu Valley from the advancing German army. The three sculptures, the Silence Table (Masa Tacerii), the Kiss Gate (Poarta Sarutului) and the Endless Column (Coloana Infinitului), are placed on mile-long (1.5 km) east-west axis that runs through the heart of the city. The Table of Silence, made from limestone, features twelve chairs, originally placed much closer to the table and arranged in pairs.\nThe Kiss Gate, made out of marble, features a kiss motif on the gate pillars. The entire structure is supported on a steel axle, set in a concrete foundation of five square meters.\nThe Endless Column stacks 17 rhomboidal cast iron modules in a 30-meter high column. The modules, completed in 1938, were made in the central workshop of Petroşani. The column was restored in 1964.\nTargu Jiu is also the capital of Gorj County, a region of rolling meadows, grassy hills and mountain scenery with plenty of natural and cultural attractions to explore. Tiny towns and villages dot the county, and contain some marvelous traditional architecture. Several spa towns and monasteries high in the mountains make for popular excursions.']	['<urn:uuid:f5f9d671-907e-4ae4-a041-61275fc901a4>']	factoid	direct	verbose-and-natural	similar-to-document	single-doc	expert	2025-05-01T23:21:14.341336	14	61	1405
299	who commissioned lee friedlander photographs computing 1980s	In the mid-1980s, Lee Friedlander received two photography commissions: one from the Massachusetts Institute of Technology and another from the supercomputer manufacturer Cray Research.	['Beyond Big Data: the politics of vision in complex systems\nIn February 2014 Professors Hamilton and Weissman will host a panel at the College Art Association conference in Chicago:\n“Big Data” no longer belongs exclusively to the domain of supercomputing. The proliferation of digital artifacts has made the amassing of large collections available to any curious browser or hoarder. Increasingly, artists and artist collectives, curators, and scholars use a research paradigm that locates itself at the intersection of big data, digital tools and technologies, and traditional humanistic scholarship and artistic practice. Working alone or in teams, scholars, artists, and curators have begun to create new online or offline spaces, data structures, maps, charts, or even hardware or software as part of their research agendas. But how do scholars and artists make visible the values and epistemologies embedded in the complex technological systems they use—and often, simultaneously, seek to critique? The question of vision is central to this inquiry, not only because images play a key role in these systems, but also because technological systems facilitate visibility through the application of frames, filters and algorithmic ordering. This session thus launches from the intersection of science and technology studies and visual studies in order to investigate the politics of vision in technological systems, as well as the innovative methodologies at work in their analysis.\nParticipants & Abstracts:\nBeautiful Data: Cybernetics, Design and the Reformulation of Vision since 1945\nDr. Orit Halpern\nHistory, The New School\nThis paper traces the cybernetic influence on designers, urban planners, architects, and human scientists, to produce a preliminary speculative genealogy of contemporary “smart” and ubiquitous computing territories. Central to this history is a genealogy of how data, bandwidth, and life became integrally linked through new tactics of design, measurement, and visualization. Taking a series of case studies ranging from the independent group—Archigram—to Nicholas Negroponte’s experiments in Soft Architecture, to contemporary smart city developments such as Songdo in South Korea, the paper will trace the rise of this ideal of an algorithmically produced territory, and the subsequent transformations (real and imagined) in the forms of measurement and calculation administering populations. Ideals of feedback, data management, modularity, and visualization underpinned an emerging post-World War II attitude to the city as an experimental “test-bed”, a self-reflexive, and self-monitoring organism which was infinitely enhanceable, improvable, and mobile. These real and imagined machine-cities were viewed as experiments with no truths to uncover, self-produced reality worlds which by far overcame any discourse of simulation that still relied on the real. Counter, then, to contemporary arguments about simulation and risk, this paper will argue that the cybernetically imagined city was about uncertainty and capacity, and possessed a myriad of forms, some of which envisioned radically different practices of managing and living in an uncertain world. This is particularly true throughout the 1960’s and 1970’s as worries about nuclear security faded in front of concerns about racial tension, transformations in political economy, and environmentalism. Bridging the utopian, the possible, and the built, this paper inquires into these contested imaginaries and futures of urban life and infrastructure that came from cybernetic traditions and continue to inform our ideals of smart, sentient, and calculative spaces.\nScreen Images: Lee Friedlander’s Picturing of the Proto-Digital\nJoy Jeehye Kim\nDepartment of the History of Art, Yale University\nThrough the work of American photographer Lee Friedlander, this paper will consider the relationship between photography, computing, and the visualization of networked technologies in the moment just before photography’s digital turn. The paper will examine two commissions Friedlander received in the mid-1980s—one from the Massachusetts Institute of Technology, and the other from the supercomputer manufacturer Cray Research—as proleptic instances in which photography anticipates computing’s future. In their serial production and organization, these photographs not only document the evolution of computing technology but also function as sets of visual data, collected to produce an image of an information society in which systems increasing take on what I argue to be a photographic and screen-based logic. More broadly, the paper will consider the kinds of temporal acceleration induced by the supercomputing technology depicted and the related image proliferation witnessed in recent years.\nFeedback Forms and Flow Charts: Hans Haacke and the Retooling of the Contemporary Art Museum\nDr Luke Skrebowski\nDepartment of History of Art\nUniversity of Cambridge\nIn the late 1960s and early 1970s Haacke made a number of artworks comprising visitor polls, using them to visualise some of the social factors affecting participation in the art world. Haacke sought to computerise later versions of these polls – with varying levels of success – the better to afford more complex data collection and visualisation.\nForty years later Haacke’s institutional critique by data analysis has been internalised by the contemporary art museum which is currently refunctioning itself by soliciting and responding to user feedback digitally, presenting diverse cultural offers tailored to different demographics across multiple physical and virtual sites.\nMight such developments lend support to Chantal Mouffe’s contention that the contemporary art museum could be recast as an agonistic space? Or are we witnessing a pseudo-democratisation of the museum effected by its adoption of responsive marketing techniques? This paper considers the programming consequences of visualising museum audiences via digital profiling.']	['<urn:uuid:64640b56-bb2f-46e2-a039-6bbc8009fd13>']	factoid	direct	short-search-query	similar-to-document	single-doc	novice	2025-05-01T23:21:14.341336	7	24	865
300	How much higher is the cancer risk with Lynch syndrome?	People with Lynch syndrome have significantly elevated cancer risks compared to the general population. They face a 20-fold greater risk of colorectal cancer, a 30-fold greater risk of endometrial cancer, a 19-fold higher risk of ovarian cancer, an 11-fold greater risk of kidney cancer, a 10-fold greater risk of pancreatic, stomach, and bladder cancers, and a four-fold greater risk of breast cancer.	"['Cancer risks associated with Lynch syndrome discovered\nAn international study led by the University of Melbourne has provided a clearer understanding of the cancer risks associated with the genetic mutation Lynch syndrome, a finding that could lead to earlier detection of a wide range of cancers in sufferers.\nPeople with Lynch syndrome have a genetic mutation that gives them a high risk of several types of cancer including bowel cancer. The genes that are damaged can’t repair any errors that occur in our DNA.\nThe study, which has been published in the Journal of Clinical Oncology, confirmed the increased risk of cancers already known to be associated with Lynch syndrome, including colon, uterus, ovary, kidney, stomach, and bladder cancers. They also found those with Lynch syndrome faced a moderately increased risk of developing breast and pancreatic cancer.\nThe researchers, led by Dr Aung Ko Win, and Associate Professor Mark Jenkins, at The University of Melbourne’s School of Population Health, followed 450 people with a mutation in one of the four mismatch repair genes associated with Lynch syndrome, and more than 1000 of their relatives who were not carriers of these mutations. Study participants were evaluated every five years at recruitment centres affiliated with the Colon Cancer Family Registry in Australia, New Zealand, Canada and the US.\nAfter five years, those with Lynch syndrome had a 20-fold greater risk of colorectal cancer; a 30-fold greater risk of endometrial (uterine) cancer; a 19-fold higher risk of ovarian cancer; an 11-fold greater risk of kidney cancer; a 10-fold greater risk of pancreatic, stomach, and bladder cancers; and a four-fold greater risk of breast cancer. People with Lynch syndrome also tended to be diagnosed with these cancers at an earlier age than people in the general population.\nThe researchers said their findings regarding breast cancer were unexpected. They said further studies were needed to determine if ages at mammographic screening or methods such as use of MRI should be recommended for people with Lynch syndrome. Currently, individuals with Lynch syndrome typically undergo colonoscopy at an earlier age than the general population, but no other special screening regimens have been agreed upon.\nThis is also the largest study to date of cancer risk for non-carriers of family specific mutations.\n""Our study revealed that these people have an average risk of developing cancer as opposed to the high risk of their mutation-carrying close relatives and hence do not need to worry unnecessarily and over screen to detect cancer,"" said Associate Professor Jenkins.\n""While not a common condition, approximately 20,000 Australians have Lynch syndrome and a very high risk of cancer. Over time, as improved screening methods become available, the findings may help doctors refine screening guidelines for breast, uterus, colon and other cancers among patients with Lynch syndrome. In the meantime, genetic testing will give people a clearer indication of their real risk level and clarify what they could or should not do to reduce their risks of cancer.""\nPeople who think they might be at increased risk for cancer due to family history should attend a Family Cancer Clinics for genetic testing and advice so cancers can be detected and treated as early as possible.\nSource: University of Melbourne\nHave your say...\nThe approval of your comment is at the discretion of this article\'s publisher. Write your comment with the following in mind to ensure the highest likelihood of it being approved:\n- No promotional undertones\n- No use of profanity\n- Good spelling, grammar and layout\n- Check punctuation, language and missing words\n- No use of aggression\n- No unsubstantiated claims\nWe reserve the right to remove comments at our discretion.\nYour name is used alongside Comments.']"	['<urn:uuid:28fcbb84-d1cf-4c70-a4f9-70dc350623a5>']	open-ended	direct	concise-and-natural	similar-to-document	single-doc	novice	2025-05-01T23:21:14.341336	10	62	614
301	How does the requirement for having written documentation compare between forming a sole proprietorship and creating an LLC in terms of mandatory paperwork?	A sole proprietorship requires minimal written documentation - it does not technically exist as a separate legal entity and therefore needs no paperwork to get started, except for a DBA certificate if doing business under a different name. In contrast, an LLC requires significantly more documentation, including filing organizational documents with the state and having an operating agreement that details how the business will run, covering aspects like management structure, ownership, distributions, and membership changes.	['When you decide to start a business, you have many decisions to make. Arguably the most important decision you will make is which form of a business entity to establish. There are many entities to choose from and each will have its own advantages and disadvantages. Evaluate each option from a tax standpoint and assess any legal liability considerations when determining which will best fit your business.\nCreating a Sole Proprietorship\nThe Sole Proprietorship is a very common business structure because it is the easiest to form and to create. A sole proprietor is an individual that owns an unincorporated business by himself. All of the profits and losses of the sole proprietorship are treated as the income or losses of the individual owner for tax purposes, and must be reported on the owner’s income tax return. Since the sole proprietorship is an unincorporated business, there is no corporate tax.\nFrom a legal standpoint, the sole proprietorship does not exist as a separate entity from the owner of the business, whereas other business structures (such as corporations) exist as separate legal entities. The main area of concern with regard to a sole proprietorship is with liability. With a sole proprietorship, if someone wishes to file a lawsuit against the business, they are essentially suing the business owner, and the business owner will be personally liable for the lawsuit. In contrast, with a corporation, if someone wishes to sue the corporation, that person is suing only the corporation, and generally the shareholders will not be personally liable for the lawsuit.\n1Consider writing a business plan. A business plan details how your business will run. While this step is not required to operate a sole proprietorship, it will help you to plan your business.\n2File for a “Doing Business As” (DBA) Certificate. If you wish to conduct business under a name that is not your own, you must obtain a certificate to do so. You may file for a DBA at your local county clerk’s office building by filling out a form and paying a fee. If you are doing business under your given name (not giving your business a separate name) you do not need a DBA.\n3Begin conducting business. As a sole proprietor, your business does not technically exist from a legal standpoint, and therefore you need not file any paperwork to get it started.\n4Report your business profits and losses on your personal tax return.\nCreating a Limited Liability Company (“LLC”)\nAn LLC is an unincorporated business, but has more protections (hence the limited liability) than the sole proprietorship. To create an LLC, a business owner must file documents and pay fees in the state where it wishes to form. Note that not every state has the LLC as an available business structure.\nAs with the sole proprietorship, the profits and losses of the business pass through to the members of the LLC, thus avoiding corporate taxes. Each member of the LLC will report the income and losses of the LLC on their individual tax return and be taxed at their individual tax rate.\nAccording to the federal government, the LLC does not exist separately from the individual members. For liability purposes, however, individual members of the LLC will generally not be personally liable for a lawsuit against the LLC. This is the main advantage over the sole proprietorship.\n1Consider writing a business plan.\n2File organizational documents with your state. Not all states offer the LLC as a business entity, so be sure to check with your state’s Department of State before deciding on this structure. Then determine which documents you will be required to file. Generally the documents include Articles of Organization and some states may also require you to publish notice of your business formation in local newspapers. You will also likely have to pay a fee.\n3Draft and adopt an Operating Agreement. An operating agreement is generally an internal document that is not filed with the state, however you may be required to have one by your state. Even if not required, it is a good idea to draft an operating agreement because it details exactly how your business will run, from the type of business you decide to operate to handling payroll and who will receive what share of profits and losses.\n4Operate your business.\n5Report your business profits and losses on your personal tax return.\nCreating a Corporation\nA corporation is an incorporated business where shareholders put money and/or property into the business in exchange for shares of the corporation’s stock. A corporation is often a large business with several different shareholders. Forming a corporation requires filing documents with the state and the federal government. A disadvantage of a corporation is that this business structure requires the owners to comply with many state- and federally-mandated corporate formalities.\nFor tax purposes, the corporation is taxed twice: once at the corporate level and again at the individual level. This double taxation is often viewed as the main disadvantage of the corporate business structure. The federal government recognizes a corporation as a separate legal entity, which can be an advantage of the corporation business structure.\nFor legal liability purposes, the corporation structure enjoys the benefits of being a separate legal entity, and thus the shareholders of the corporation are generally not liable for lawsuits against the corporation.\n1Choose a name for your corporation. States generally place restrictions on the words that may or may not be used in the name of a corporation. Generally the name must include the word ‘incorporated’ or ‘inc.’ or some other indicia that the business is a corporation.\n2Determine who will be the initial directors of the corporation. The initial board of directors is composed of those individuals in charge of getting the corporation up and running. They will authorize the issuance of stock and pick officers of the corporation, two of the most important decisions the corporation will make.\n3File incorporation documents with your state. These are usually called articles of incorporation and are generally accompanied by a filing fee. Your state’s secretary of state or department of state office will likely have an approved form that you may fill out or you may draft your own. Articles of incorporation generally include the name of the corporation, its address, and the name and contact information for a person to whom members of the public can contact regarding that corporation.\n4Draft corporate bylaws. These are analogous to the operating agreement that an LLC operates under. Corporate bylaws will include additional information such as how shares of stock will be voted, how directors are chosen, etc. Usually you may use a template for the bylaws or draft your own.\n5Hold an initial board meeting and adopt the bylaws. At this meeting the initial board of directors will adopt the bylaws, elect officers, authorize the issuance of stock, and determine how to handle certain financial or tax issues such as the corporation’s fiscal year.\n6Issue shares of stock. In order to officially be a corporation you must issue stock, as this formalizes the division of the ownership of the business.\nCreating a Subchapter S Corporation\nThe S Corporation is a tax election that an existing corporation makes. Essentially, it avoids the double taxation of regular corporations by electing to have the taxes pass through the corporation to the shareholders. Each shareholder will report the S corporation’s profits and losses on their own individual tax return. The S Corporation has a number of restrictions on the type of business the corporation can engage in, the number of shareholders, and the type of stock issues.\nThe S Corporation enjoys the same legal liability status of other corporations.\n1Form a corporation. Since a Subchapter S Corporation is a tax election that a corporation makes, the first step to creating an S Corporation is to create a corporation. Follow the steps outlined above.\n2File Form 2553 with the IRS. The form is available on the IRS website.\n3Approve the S Corporation tax election at the initial board meeting. There must be unanimous consent by the board in order to make the S Corporation tax election.\n- Always check with your state regarding the requirements for forming a business in that state. Most states’ Department of State or Secretary of State websites will contain information about the process.', 'If you’re creating a new company, the business structure you choose impacts your personal liability, taxes, paperwork, and your ability to raise capital. For example, a limited liability company (LLC) is a less formal business structure that increases personal protection from liability.\nBut selecting a business structure is not as simple as declaring your company as an LLC; there are legal documents and paperwork that must be filled out and signed by the key members of the company.\nThis brings us to the operating agreement (OA), which outlines the company’s leadership structure, ownership, rules, regulations, and provisions. Once signed, it binds members to its terms.\nCurious why an operating agreement matters and what needs to be included for it to be legitimate? We’ll break it down for you.\nWhat is an operating agreement?\nAn operating agreement is an official contract, enforced by law, that addresses many of the situations that could happen to the company, and lays out the proper actions to take should those circumstances occur.\n- What if a member leaves? What happens to their ownership stake?\n- What if a member doesn’t want to be involved in day-to-day management?\n- What if a member is sued?\nThus, an operating agreement establishes several aspects of the LLC membership, including their:\nAlthough no state in the country legally requires an LLC to file their operating agreement with the state registrars’ office, certain states dictate that you need to have an operating agreement for your business records.\nFor example, California states,1 “Operating Agreements are to be maintained by the limited liability company and are not filed with the California Secretary of State. Please do not submit Operating Agreements for filing; if they are submitted, they will be returned unfiled.”\nWhat does an operating agreement include?\nAlthough operating agreements vary, most will contain six primary articles, including:\n- Article I – Organization – Covers the creation of the business. It addresses the whos, whats, whens, whys, and wheres. This will cover:\n- The LLC’s name\n- Details about the Articles of Organization, which will be filed with the state registrar\n- Address of the LLC’s principal office\n- Duration of the LLC, which will either be until a specific date or “until dissolved”\n- Stated purpose of the business\n- Name and address of the registered agent, who will be receiving legal notices and correspondences\nIt will cover membership in detail, including ownership and how profits, losses, and taxes will be dispersed between members. It will also spell out how new members can be added.\nArticle II – Management and voting – Addresses how the company will be managed and how its members can vote on business issues. Members may appoint a single (or multiple) manager(s), and then the OA establishes their authority.\nAnother option is to have all company decisions made by a voting process. In this case, the OA would stipulate how the voting process works, how much a person’s vote counts, or how many votes are required for an action to take place.\nArticle III – Capital contributions – Highlights which members have provided capital to help start the LLC. It also covers how new money can be raised by members.\nArticle IV – Distributions – Details how the business’ profits, losses, and other assets will be dispersed between members.\nArticle V – Membership changes – Clearly explains how members can be added or removed. It also handles how ownership can be transferred.\nArticle VI – Dissolution – Lists the reasons or times when the company may or must be dissolved.\nWhy an operating agreement matters\nAt its essence, an operating agreement is all about providing clarity. Getting into business with others can be messy, complicated, and lead to internal disagreements. An operating agreement clearly states the rules and provisions so that every member is on the same page. Once it’s signed by the members, it officially binds them to its terms.\nSo, what are the benefits of an operating agreement?\nSets verbal agreements in stone – In the early stages of a business, many of the plans are based on handshake agreements. Because miscommunication can happen, this can lead to misunderstandings or disagreements (where one side thinks they were promised something and the other side disagrees). When put in writing, the agreements are clearly stipulated and can be referenced if a conflict comes up.\nProtects the members from liability – It’s important to note that all operating agreements must include a liability and indemnification clause, which includes legal language stating that members of the company have limited liability for the actions they take on behalf of the company.\nWithout the specific formality of an operating agreement, members might not have coverage since the LLC could be viewed as a partnership or sole proprietorship.\nMake your business agreement official in the eyes of the government – Although you’re not legally required to file an OA with the state, having one ensures that your agreement isn’t managed by the state’s default rules—which govern LLCs that lack an OA.\nPut simply, it’s a risky decision to run a business without a signed, physical operating agreement. Without it, you are personally exposed to liability and several other potential headaches surrounding ownership and member’s rights. So, work with an experienced attorney to ensure that everything is in place and that you have all of your bases covered.\nBusiness liability coverage\nOnce your operating agreement is set in stone, the next step you can take to protect both yourself and your business is to purchase the right insurance. So, if you need general liability insurance or professional liability insurance, you’re in the right place.\nThimble offers our customers on-demand policies that go by the hour, day, or month. It’s insurance that’s on when you’re on, and off when you’re not on the clock.\nCurious how to get started? You can protect your small business from liability in under 60 seconds. Just download the Thimble app or click “select a quote” to get started.\nLike an operating agreement, liability coverage is all about foresight. It’s about anticipating the problems that could crop up and putting structures in place to protect your business.\nIt’s about being prepared.\nOur editorial content is intended for informational purposes only and is not written by a licensed insurance agent. Terms and conditions for rate and coverage may vary by class of business and state.\nA business loan agreement is a two-way street; this document protects both you (the borrower) and the lender. Read on for everything you need to know before you sign on the dotted line.']	['<urn:uuid:f94aa928-c014-46ac-9527-d3a09d391dae>', '<urn:uuid:2b065e70-fb80-429c-a6bc-69c27b884edc>']	factoid	direct	verbose-and-natural	distant-from-document	comparison	expert	2025-05-01T23:21:14.341336	23	75	2487
302	studying rock composition mechanisms explain how minerals freeze during magmatic differentiation	Magmatic differentiation occurs through partial freezing. Minerals with higher melting temperatures will freeze first, which changes the chemical composition of the remaining melt. This process continues until all the magma has frozen or solidified. Through fractional crystallization, after crystals form, they are separated from the remaining molten material and don't re-enter the reaction. This separation can occur either by crystals settling due to gravity or by the melt moving to another location.	['Intro to Rocks Major Rock Types: There are three major rock types 1. Igneous—Rocks formed from cooling of magma or lava. 2. Sedimentary—Rocks formed from sediments worn from other rocks. 3. Metamorphic– rocks formed by changing the chemistry, mineralogy, or texture of other rocks.\nRock Cycle • Rock types are all connected in a cycle of formation, change, and destruction which we call the Rock Cycle. • Let us start the rock cycle with molten rock (magma), which cools and forms igneous rocks. These rocks become uplifted as mountains are formed (orogeny). There it is attacked by the weather and starts to erode.\nRock Cycle • This weathered (eroded) material is carried away by streams, rivers, wind, glaciers and deposited elsewhere as sediments. • The sediments are then buried and lithified (turned into solid rock) being subjected to heat, pressure, and fluids the sedimentary rocks becomes metamorphic rocks. • Metamorphic rocks maybe uplifted and eroded or may become heated to the point that it again becomes Magma.\nRock Cycle http://www.matt-willard.com/Artwork/Graphic_Design/Rock-Cycle.jpg\nWhat are Igneous Rocks? • The term Igneous comes form the Latin word ignis meaning fire. These are rocks which form from cooling magma or lava. • Magma: Molten or partially molten rock materials and dissolved gases beneath earth’s surface. • Lava: Is also molten or partially molten rock material and dissolved gases which erupts at the Earth’s surface.\nClassifying Igneous Rocks • Two methods are used: Texture and chemisty. • Texture: a term which involves how a rock looks. This method involves: • 1. The size of the mineral grains (crystals) involved. • 2. Does the rock have holes (vesicles) in it. If it has a lot of holes it is called a vesicular texture. This is an indication that the rock was lava and at the surface as it erupted or cooled. • 3. Is the rock a coherent mass of mineral grains or from smaller chunks of igneous rock which has been cemented or welded together (pyroclastic texture).\nTexture • Using the texture characteristics Igneous rocks can be classified as either Intrusive or Extrusive. • Intrusive: Rocks composed of large crystals. This indicates slow cooling below the earth’s surface. • Extrusive: Rocks composed of small, microscopic, or no crystals (obsidian) indicates rapid cooling at the earth’s surface.\nChemical Classification • Based on the Chemical Composition igneous rocks can be broken into 4 general types. • Felsic: High in silica (65%+) • Usually light colored • Examples Rhyolite (extrusive) and Granite (intrusive). • Intermediate: Lower silica content (55-65%) • Darker than felsic, lighter than mafic • Example Andesite/dacite (extrusive) and Diorite/granodiorite (intrusive).\nChemical ClassificationContinued • Mafic: low silica content (45-55%) • Ususally dark colored • Example basalt (extrusive) and gabbro (intrusive). • Ultramafic: Extremly low silica content (less than 45%) • Usually dark colored, but high olivine content tend to produce green colors. There are also other rare colors. • Example periodotite (intrusive)\nClassification of Igneous Rocks http://geology.csupomona.edu/alert/igneous/ignrxclass.gif\nHow does Magma form? • Magma originates from melting rocks. But rocks are made up of different minerals which melt at different temperatures (not uniformly). Some may not melt completely resulting in Partial melting. • Melting temperatures may be affected by environmental conditions such as pressure, amount of water. Higher pressures increase melting temperatures, presence of water lowers the melting temperature.\nMagmatic Differentiation • Partial melting also results in Partial freezing and called magmatic differentiation. Freeze does not mean cold. • Those minerals which have a higher melting temperature will also freeze first which will change the chemical composition of the remaining melt. • This process continues until all the magma has frozen or solidified.\nChemical Classification • There are three general paths that igneous rock may take as they cool depending on their chemical composition. • Continuous Reaction Series: deals with those melts that are calcium rich or sodium rich composition (plagioclase feldspars). • As the plagioclase feldspars crystallize, the first crystals are calcium rich which leaves the sodium rich melt behind. This continues till the melt reaches equilibrium again. Again calcium crystals come out followed by sodium. This continues till the entire melt is solid.\nChemical Classification • Discontinous Series: As a mafic melt cools slowly the first crystals that form are olivine, followed by pyroxenes with the olivine being converted to pyroxenes. As the temperature farther lowers amphiboles crystallizes and all the pyroxenes convert to amphiboles. Farther lower of temperature results in Mica forming with the amphiboles all convert to Mica. • Discontinous series can be seen as separate crystallizations and conversions, so that there is only one type of mineral present at a time.\nChemical Classification • Fractional crystallization says that after crystals form, they are somehow separated from the remaining molten material and don’t re-enter the reaction. • One possible way that this might occur is the crystals as they form settle out due to gravity. Or as crystals form the melt moves to another location (squeezed out so to speak).\nOrigin of Different types of Magmas • Mafic Magmas (basaltic) has two sources: • 1. Mid-Ocean Ridges, where mafic magma rises up to form new ocean floor. • 2. Mid-Plate Volcanoes are sites where mafic magma rise up from great depths (where one plate is being subducted under another plate) this results in eruptions on the surface. • Mafic to intermediate volcanism can also occur in this location.\nOrigin of Different types of Magmas • Felsic Magmas forms as oceanic plates move along picking up mud, silt, and wet sediments. As one oceanic plate is pulled under another plate the wet sediment are also pulled under. As the plate and sediments heat up due to pressure the water is driven out and into the mantle. This water lowers the melting point and rise (lower density), resulting in mixing with the material from the overlying continent (more melting occurs). Finally the melt reaches the surface as volcanoes or cools within the crust.\nSummary • You need to know the following: • 1. Different classes of rocks. • 2. How they are formed, and how they are tied together through the rock cycle. Able to draw out the rock cycle and explain (p.119). • 3. What are igneous rocks? • 4. Classification and Types of igneous rocks (p.124 text) • Texture (intrusive vs. extrusive) • Chemical classification • 5. Magmatic differentation • General idea • Bowen’s series • 6. Fractional crystallization • 7. Where do different igneous rocks form (pp.122-123) • 8. Name and definitions of various intrusive bodies (p. 125 text)\nSITES USED Thanks to Greg Anderson for use of lecture notes. http://pasadena.wr.usgs.gov/office/ganderson/es10/lectures Also: http://www.matt-willard.com/Artwork/Graphic_Design/Rock-Cycle.jpg http://geology.csupomona.edu/alert/igneous/ignrxclass.gif http://imnh.isu.edu/digitalatlas/geo/rocks/bowens/bowens.jpg']	['<urn:uuid:81509d2b-a09b-4a68-8556-4fe8de2f3516>']	open-ended	with-premise	long-search-query	distant-from-document	single-doc	expert	2025-05-01T23:21:14.341336	11	72	1102
303	rain gauge vs evaporation pan measuring rainfall water which device how compare methods	Both rain gauges and evaporation pans are devices used to measure water from precipitation, but they serve different purposes. A rain gauge directly measures the depth of rainfall accumulation over time using a cylindrical container with measurement markings. An evaporation pan, specifically the US Weather Bureau Class A pan evaporimeter, is designed to measure water loss through evaporation using a large galvanized iron pan filled to a specific level. While rain gauges provide straightforward rainfall measurements, evaporation pans require more complex calculations, especially on rainy days where both rainfall and evaporation must be considered together. For example, after a 25mm rainfall, if only 12mm of water needs to be removed from the evaporation pan to reach the correct level, this indicates 13mm of evaporation occurred.	"[""Construction of an Evaporation Pan for Irrigation Scheduling\nNote Number: AG0293\nPublished: September 2000\nUpdated: December 2009\nPlants suck up water from the soil and lose the majority of this water to the air through their leaves by a process known as evapotranspiration. Ideally we would like to measure plant water use so that irrigations can be accurately scheduled, however, the technology is complex and currently not suited to practical irrigation management. Alternatively, plant water use can be estimated from the measurements of evaporation from an open surface of water. From evaporation readings irrigations can be timed so that the soil is at the right moisture level and irrigations run long enough to replace the water the plants have used.\nThere are many types of evaporation pans used by farmers. However, the universal pan is the United States Weather Bureau Class A pan evaporimeter (Figure 1). It is important to use the same dimensions as this universal pan, mainly because the effect of wind and temperature on evaporation will vary with the surface area and the depth of water in the pan. Evaporation and irrigation replacements cannot be compared between sites if non standard pans are used.\nThere are three parts to an evaporimeter (Figure 2). All parts can be made very cheaply with common materials. Alternatively a complete unit can be purchased at considerably greater cost. The following is a description of how to construct the three components of the evaporimeter.\nThe evaporation pan must be made to the standard specifications of an internal diameter of 1207 mm and height of 254 mm using 20 gauge galvanised iron. The standard material is galvanised iron as alternatives will have different thermal and reflectance properties, therefore altering the evaporation rate. It is best to have the pan made by either a galvanised tank manufacturer or an engineering firm. Before the pan is sited in the field it should be checked for leaks.\nThe fixed pointer that sits inside the pan can be made from standard irrigation fittings and a piece of stainless steel rod (Figure 3). There are three parts to the fixed pointer:\n- the base, a 100 mm PVC flange\n- the pointer support, a 230 mm long piece of 100 mm PVC pipe. Four equally spaced 9 mm holes 70 mm from the base are drilled to allow the water height around the fixed pointer to quickly adjust to the water height in the pan. A single 15 mm long 5 mm wide elongated hole is also drilled 70 mm from the base of the PVC pipe.\n- the pointer, a 170 mm long piece of 5 mm stainless steel rod bent at a right angle 60 mm from one end. From the shorter end a thread is tapped for about 15 mm and a point is ground on the other end of the rod.\nAfter fitting the PVC pipe into the flange, the stainless steel rod is inserted into the elongated hole with nuts located on the inside and outside of the PVC pipe. To initially set the stainless steel rod in the correct position, the fixed pointer is placed in the pan and the pan is filled with water to a depth of 190 mm. The rod is then slid up or down in the 5 mm elongated hole so that the point of the rod just breaks the surface of the water.\nTo measure evaporation the pan must be refilled with a known volume of water. The surface area of the pan is 1.14 square metres, so for every mm of evaporation 1.14 litres of water must be added to the pan. A transparent plastic 2 litre measuring jug with vertical sides is an excellent measuring cylinder if it is scaled properly. It is important that the jug actually holds more water than 2 litres so the sides of the jug must extend past the 2 litre mark. The jug is filled with 2.28 litres of water and the water level marked. This can conveniently be done by weighing the jug and adding 2.28 kilograms of water. For most jugs this will just about overflow, which is perfect.\nA jug of water filled to the marker will be equivalent to 2 mm of evaporation. To scale the jug when less than 2 mm of water is required to fill the pan, the distance from the top marker to the bottom of the jug is measured and divided by 20. The numbers 0 to 2.0 in increments of 0.1 are then written with a permanent marking pen from the top marker to the bottom of the jug. These numbers are equivalent to the same number of mm of evaporation from the pan.\nWith evaporation the water level in the pan will fall. To measure the amount of evaporation, water is added to the pan with the measuring jug filled to the top mark. Water is added until the pointer just breaks the surface of the water. The PVC pipe supporting the pointer will help by reducing wave motion. It is important to keep track of the number of jugs used to refill the pan and the reading on the last jug when the pan water level is just broken by the pointer. The total amount of water added equals the amount of evaporation.\nIt is also essential to measure rainfall in conjunction with evaporation. Both measurements enable evaporation to be calculated on rainy days. After heavy rain the pan may have to be emptied to bring the water level down to the pointer. After rainfall on a hot summer's day, less water may have to be removed than actually fell as rain. For example, after a 25 mm rainfall there might only be 12 mm of water removed from the pan with the measuring jug to bring the water level back to the pointer. The difference between the rainfall (25 mm) and the water removed from the pan (12 mm) is the evaporation. In this example it is 13 mm.\nIf the rain does not fill the pan above the pointer, the rainfall must still be added onto the measured evaporation to give the actual evaporation. For example, if there was 7 mm of rainfall and 6 mm of water was added to the pan with the measuring jug then the evaporation would be 13 mm.\nEvaporation measurements should be routinely done every day at 9.00 am and clearly recorded. If measurements are not done routinely then the volume of water in the pan will decrease and take less time to heat up during the day and cool at night. This will induce an error which will become greater as the volume of water in the pan decreases. Evaporation measurements are very simple and take less than 5 minutes.\nThe pan should be placed on a flat wooden platform about 150 mm above the ground surface. A pallet is perfect. To avoid animals and birds interfering with the water in the pan we strongly advise covering the pan with chicken wire. This is not a USWB standard but is recommended for all agricultural situations. The error from covering the pan with bird wire will be small, much less than that introduced by animal interference.\nTo construct a simple chicken wire cage over the pan, bend a piece of 6 mm steel rod around the outside of the pan, welding the ends together to form a hoop.\nChicken wire is then loosely tied to the perimeter of the hoop. This cage can then be slipped over the pan.\nThe area around the pan must be grassed and free from weeds, bushes and trees so that no shading can occur. The grass around the pan must be mown regularly and kept green. A nearby water supply is advised for refilling the pan and watering the grass around the pan.\nThe pan should be cleaned at least once a year. After cleaning and every month an algaecide should be added at the same rate as for swimming pools. If an algaecide is not added then the pan should be emptied and cleaned monthly.\nIf the maintenance or siting of the pan or the construction of the pan is not standard, then there will be a different relationship between evaporation and plant water use, but this difference is not critical if the differences are small and consistent. Variations from month to month like algae growth, unmown grass or reading at very irregular intervals are far worse than a consistent difference. For example we suggest that if the grass cannot be kept green and mown then the area around the pan should be kept bare with a herbicide. It should be recognised here that non-standard evaporation pans can still be very useful for irrigation scheduling. They must, however, be evaluated on their own. Published irrigation replacement factors will be less accurate than for a standard evaporation pan. We recommend that if a non standard evaporation pan is used for irrigation scheduling then soil moisture and plant performance must be monitored to determine appropriate irrigation replacements from evaporation.\nThis Agnote was developed by Ian Goodwin, Future Farming Systems Research in September 2000.\nIt was reviewed by Ian Goodwin, Future Farming Systems Research. November 2009.\nPublished and Authorised by:\nDepartment of Environment and Primary Industries\n1 Spring Street\nThis publication is copyright. No part may be reproduced by any process except in accordance with the provisions of the Copyright Act 1968.\nThe advice provided in this publication is intended as a source of information only. Always read the label before using any of the products mentioned. The State of Victoria and its employees do not guarantee that the publication is without flaw of any kind or is wholly appropriate for your particular purposes and therefore disclaims all liability for any error, loss or other consequence which may arise from you relying on any information in this publication"", ""A rain gauge is a device that accurately measures precipitation. Your children can use common household objects to create a rain gauge. They can regularly measure the amount of rain and then record their findings in a journal. A rain gauge can be a do-it-yourself science project, a component of a weather station for kids or a device to help them estimate the water requirements of a garden.\nThe Gauge's Function\nWhen your child gauges rainfall, she’s recording the depth of precipitation accumulating over a set time period. Because you can’t accurately measure rainfall in natural places for various reasons -- ground absorption of rain, evaporation or the run-off of precipitation into streams or lower ground -- a rain gauge is required. The gauge typically consists of a cylinder with a scale -- millimeters or inches -- running vertically along its side. Your child can place the rain gauge in a secure outside location that is unobstructed by tree branches, building eaves or electrical cables.\nTwo Types of Gauges\nThe two main types of rain gauges have different shapes. The first type is cylindrical with straight sides. When using this type of gauge, the height of captured precipitation equals the actual amount of rainfall. If your child collects an inch of rain, she records a rainfall measurement of 1 inch. The second type of rain gauge has a funnel top and is best suited for capturing small amounts of precipitation. To measure rainfall, you have to use a ratio of the cylinder’s diameter to the funnel’s diameter. For example, if the ratio is 1:5, then 10 inches of water captured in the cylinder equals 2 inches of actual rainfall.\nBuilding a DIY Gauge\nHave your kids gather a 2-liter soda bottle, scissors, tape and pebbles. Begin by cutting off the top half of the bottle just below the point where the bottle’s shape starts to narrow. Place pebbles in the bottle’s bottom to weight it down. Invert the bottle's top half and insert it into the bottom half. Match the rims of the top and bottom halves and then tape them together. Attach a piece of tape that runs from the top of the bottle to the point just above the stones, or the base of the gauge. Position a 12-inch ruler to the side of the bottle so its zero-line matches up to the gauge’s base. Use a marker to draw every 1/8-inch or 1/4-inch mark, and then number each inch. Add water to the gauge until the water reaches its baseline or zero point. By doing so, your child can measure additional water -- captured rainfall -- from the zero line.\nHave your child monitor the rain gauge on a daily basis. She should measure rainfall at the same time everyday. For an accurate measurement, your child needs to be at eye level with the gauge. After recording the rainfall on a chart, she should empty the gauge, according to “ScienceWorks for Kids: Weather, Grades 4-6+,” by Mike Graf and Michelle Rose. Alternatively, she can subtract the current reading from the previous day’s reading to arrive at accumulated rainfall. She can also describe rainfall as heavy, moderate or light. While heavy rainfall is more than 0.3 inch of rain per hour, moderate rainfall ranges between 0.1 and 0.3 inch of rain per hour. Light rainfall is lower than 0.1 inch of rain per hour.""]"	['<urn:uuid:e6f0a932-d456-4e38-97b6-c5ecc1edd0e3>', '<urn:uuid:9526badf-e97e-4eb3-b1d5-803e2c4d0da5>']	open-ended	with-premise	long-search-query	similar-to-document	comparison	novice	2025-05-01T23:21:14.341336	13	125	2220
304	argonne laboratory scientists research what studies	Argonne National Laboratory employs approximately 1,400 scientists and engineers, along with 1,000 students. They conduct research across various fields including biology, physics, materials science, energy enhancement, and climate studies.	['Argonne National Laboratory: A federal laboratory owned by the U.S. Section of Electricity, outside of Chicago, Sick. It was formally made on July 1, 1946. These days, its approximately 1,400 scientists and engineers (and 1,000 pupils) perform analysis throughout a broad range of fields, from biology and physics to materials science, vitality enhancement and local climate scientific studies.\nambiance: The envelope of gases bordering Earth or another earth.\natom: The basic device of a chemical ingredient. Atoms are built up of a dense nucleus that contains positively billed protons and uncharged neutrons. The nucleus is orbited by a cloud of negatively charged electrons.\ncarbon: The chemical aspect having the atomic range 6.\ncarbon dioxide: (or CO2) A colorless, odorless fuel developed by all animals when the oxygen they inhale reacts with the carbon-wealthy foods that they’ve eaten. Carbon dioxide also is produced when natural matter burns (which includes fossil fuels like oil or gas). Carbon dioxide acts as a greenhouse gas, trapping heat in Earth’s environment. Plants convert carbon dioxide into oxygen all through photosynthesis, the method they use to make their personal food.\ncatalyst: A material that can help a chemical response to progress more rapidly. Examples include things like enzymes and components these kinds of as platinum and iridium.\nchemical: A material fashioned from two or more atoms that unite (bond) in a mounted proportion and construction. For example, water is a chemical designed when two hydrogen atoms bond to just one oxygen atom. Its chemical formulation is H2O. Chemical also can be an adjective to explain homes of elements that are the result of different reactions in between distinctive compounds.\nchemical engineer: A researcher who makes use of chemistry to address complications associated to the creation of foodstuff, gas, medicines and quite a few other goods.\nchemical response: A process that includes the rearrangement of the molecules or framework of a substance, as opposed to a modify in bodily type (as from a reliable to a gasoline).\nlocal weather change: Extended-time period, substantial adjust in the weather of Earth. It can occur in a natural way or in reaction to human routines, such as the burning of fossil fuels and clearing of forests.\nsetting: The sum of all of the things that exist all-around some organism or the method and the affliction all those items generate. Environment may well refer to the climate and ecosystem in which some animal life, or, potentially, the temperature and humidity (or even the placement of points in the vicinity of an merchandise of interest).\nethanol: A type of alcohol, also known as ethyl liquor, that serves as the foundation of alcoholic drinks, such as beer, wine and distilled spirits. It also is used as a solvent and as a fuel (normally blended with gasoline, for instance).\nfossil gas: Any gas — such as coal, petroleum (crude oil) or purely natural gasoline — that has made inside of the Earth around tens of millions of many years from the decayed stays of micro organism, vegetation or animals.\ninexperienced: (in chemistry and environmental science) An adjective to explain solutions and procedures that will pose minimal or no damage to living issues or the ecosystem.\ngreenhouse gasoline: Any of numerous gases that lead to the greenhouse outcome by absorbing heat. Carbon dioxide and methane are two examples of such gases.\nhydrogen: The lightest ingredient in the universe. As a gasoline, it is colorless, odorless and really flammable. It is an integral portion of lots of fuels, fats and chemicals that make up dwelling tissues. It’s produced of a solitary proton (which serves as its nucleus) orbited by a solitary electron.\nsteel: Some thing that conducts electric power perfectly, tends to be shiny (reflective) and malleable (indicating it can be reshaped with heat and not also a lot drive or force).\nmolecule: An electrically neutral team of atoms that represents the smallest attainable amount of a chemical compound. Molecules can be created of single styles of atoms or of various kinds. For illustration, the oxygen in the air is made of two oxygen atoms (O2), but drinking water is produced of two hydrogen atoms and a single oxygen atom (H2O).\nkeep an eye on: To take a look at, sample or check out something, in particular on a standard or ongoing foundation.\noxygen: A fuel that helps make up about 21 per cent of Earth’s ambiance. All animals and numerous microorganisms have to have oxygen to fuel their progress (and fat burning capacity).\nplatinum: A naturally occurring silver-white metallic element that continues to be steady (does not corrode) in air. It is utilised in jewellery, electronics, chemical processing and some dental crowns.\nrecycle: To discover new makes use of for some thing — or areas of some thing — that may well otherwise be discarded, or handled as squander.\npetroleum (and other fossil fuels) or somewhat exceptional components and minerals.\nsocial distancing: A expression for the intentional separation of men and women to restrict the probability that a ailment can be passed from 1 to a further.\nvoltage: A power related with an electric present-day that is measured in units known as volts. Ability businesses use significant-voltage to go electric power over lengthy distances.\nX-ray: A variety of radiation analogous to gamma rays, but getting fairly decreased electrical power.']	['<urn:uuid:a9cc1600-4f23-4a73-b32b-b0adf82868fb>']	open-ended	with-premise	short-search-query	similar-to-document	single-doc	novice	2025-05-01T23:21:14.341336	6	29	884
306	small animal vs large animal anesthesiology courses monitoring equipment	The DVM program offers separate courses for small (VEM 5472) and large animal anesthesiology (VEM 5473), each being one-credit courses. Both emphasize safe anesthetic practice and proper monitoring. During procedures, continuous monitoring of vital parameters (heart activity, breathing, temperature, consciousness) is required using various monitoring equipment, with a dedicated veterinary professional constantly observing the patient being the most crucial monitor despite available electronic aids.	['DVM Professional program courses, led by the Department of Comparative, Diagnostic and Population Medicine (CDPM), cover a wide range of research areas, including microbiology and parasitology, pathology, forensic medicine, anesthesiology, integrative medicine, and zoological medicine. The course structure is arranged in phases:\n- Phase I (first-year) is designed to build a foundation in the basic sciences. Students also begin the four-semester experiential course in Supervised Patient Care and Clinical Skills in the newly built Clinical Techniques Laboratory.\n- Phase II (second-year) builds on the foundations acquired in Phase I, while introducing students to the complexities of treating and diagnosing common and unique aliments found in all species in veterinary medicine. Students explore all organ systems and their functions in Phases I and II.\n- Phase III occupies the third and fourth years of the curriculum (Semesters 5-9), and consists of advanced core and elective courses and clinical clerkships. Students begin their clinical rotations in our Small and Large Animal Hospitals the summer after completing Phase II.\n|Phase||Type||Course Number||Course Title||Credits||Course Coordinator||Description|\n|I||Classroom||VEM 5110B||Animal Systems: Hematology and Immunology||7 (for all Animal Systems modules)||Dr. S. Kariyawasam||The immune system’s main function is to protect the host against diseases.\nHowever, in an abnormal state, the immune system can elicit responses that can cause diseases (autoimmunity, hypersensitivity reaction). The responses generated by the immune system are often used as a tool for diagnosis of disease. At the end of the course you will understand the structure and function of blood and blood forming organs, have a working knowledge of basic immunology and understand why this knowledge is essential as a prerequisite for future clinical courses and clinical practice. This knowledge will enable you to interpret and evaluate related problems that you will meet throughout your clinical training and practice.\n|I||Classroom||VEM 5115||Veterinary Histology and Embryology||1||Dr. I. Hawkins||VEM 5115 introduces the first-year veterinary student to the topics of cellular biology, histologic structure and function, and embryologic development. Essentials of the composition and activities of cells lead to an introduction of the basic tissue types, e.g. connective tissue, muscular (contractile) tissue, nervous (excitatory) tissue, epithelial tissue. This in turn provides the background for an understanding of the cell and tissue interactions that are formative of key events in embryologic development, and provides the background for systems-based anatomic study.|\n|I||Classroom||VEM 5150||Core Parasitology||1||Dr. H. Walden||Core Parasitology is an introduction to Parasitology. This introductory course will cover examples of various helminth parasites (trematodes, cestodes, nematodes, acanthocephalans), protozoan parasites and arthropod parasites. This course focuses on basic life cycles, general identification and diagnosis. Primary diseases caused by parasites may be discussed, but that, along with treatment, are not the main learning outcomes of this course.|\n|II||Classroom||VEM 5161||General Pathology||2||Dr. R. Ossiboff||General pathology focuses on basic reactions of cells and tissues to injury that underlie all disease processes and include cell injury and death, circulatory disturbances, inflammation and repair and disturbances of growth and neoplasia. In general pathology, the most important concepts and information will be outlined in the lectures with more detail presented in the required text reading. Other concepts will be introduced in problem-set questions. Laboratories will focus on examination of digitized microscopic slides and images of gross specimens to emphasize major principles and concepts and to demonstrate entities presented in lectures. Evaluation of learning performance will include two examinations. Examinations may include interpretation of gross and microscopic changes and will be proctored (Honorlock).|\n|II||Classroom||VEM 5162||Systemic Pathology||3||Dr. L. Farina||Systemic pathology is focused on pathologic responses of organ systems to injury and the responses of organ systems in specific diseases.|\n|II||Classroom||VEM 5221||Veterinary Clinical Pathology||4||Dr. C. Lanier||This is an introductory course designed to provide basic knowledge about veterinary clinical pathology. The major goal of this course is for students be able to understand and use clinical pathology test results to diagnose and monitor animal diseases in clinical patients. Students will develop competency in interpreting laboratory results, including complete blood cell count, clinical serum biochemistry, urinalysis, hemostatic tests, and endocrine tests. Instructions for optimal laboratory sample collection and handling will be covered along with pathophysiology relevant to laboratory result interpretation.|\n|II||Classroom||VEM 5470||Veterinary Anesthesiology||1||TBD||This one credit course spread across four weeks is designed to introduce students to the most relevant topics regarding anesthesia and analgesia in common domestic animals. We hope this this course will raise your interest level in veterinary anesthesiology and prepare you to safely perform anesthesia for both the upcoming sophomore surgery laboratories and for the clinical anesthesia clerkship. Concepts learned in the course will be built upon in future anesthesia elective courses (VEM 5472 and VEM 5473) and in the anesthesia clerkship course.|\n|III||Classroom||VEM 5144||Large Animal Applied Veterinary Microbiology||1||Dr. M. Long||The goal of this course is to acquire clinical competency in diagnostic medicine as it pertains to large animal infectious diseases with an emphasis on equids and bovids.|\n|III||Classroom||VEM 5153||Small Animal Parasitology||1||Dr. H. Walden||Small Animal Parasitology provides students with a foundation in Small Animal Parasitology for use in clinical sciences and for diagnosis, treatment and control of parasitic infections or diseases caused by helminths (trematodes, cestodes and nematodes), arthropods and protozoan parasites that infect or infest dogs and cats. Life cycles will be used as a basis of knowledge regarding hosts, sites of infection, and determination of how and when to diagnose. Clinical cases and examples of disease, treatment and diagnosis will be pulled from the most current literature, when available.|\n|III||Classroom||VEM 5154||Large Animal Parasitology||2||Dr. H. Walden||Large Animal Parasitology provides students with a foundation in parasitology and expands on the fundamentals taught in the core course. This course is focused on practical use in clinical sciences and for diagnosis, treatment (if any) and control of parasitic infections or diseases caused by helminths (trematodes, cestodes and nematodes), arthropods and protozoan parasites that infect or infest horses, cattle, sheep, goats, pigs and chickens. Life cycles will be used as a basis of knowledge regarding hosts, sites of infection, and determination of how and when to diagnose. Clinical cases and examples of disease, treatment and diagnosis will be highlighted from the most current literature, when available|\n|III||Classroom||VEM 5164||Small Animal Pathology||1||TBD||This course reviews and explores a variety of topics in small animal pathology.|\n|III||Classroom||VEM 5165||Large Animal Pathology||1||Dr. J. Roberts||This course focuses on the gross pathologic lesions that characterize major diseases of pigs, sheep, goats, small camelids, horses, and cattle with comparative references to large animal exotics. The gross lesions will be used to formulate disease diagnoses and differential morphologic diagnoses. Gross and microscopic pathologic changes of major diseases will be presented with discussion of differential diagnoses, pathogenesis, and methods for making definitive laboratory diagnosis as appropriate.|\n|III||Classroom||VEM 5208||Integrative Medicine||1||Dr. J. Shmalberg||The public’s interest in integrative medicine (the combination of conventional medicine and complementary or alternative health practices) continues to increase and includes the diverse fields of acupuncture, rehabilitation, botanical medicine, and nutrition. The course provides an evidence-based approach to these modalities to better prepare future practitioners for client questions about the field. Relevant basic medical physiology will be reviewed in the context of each modality, and the evidence and controversies for different practices explored. Students should have a clear understanding of the current information and practices surrounding these techniques by the end of the short course.|\n|III||Classroom||VEM 5222||Cytodiagnosis in Veterinary Practice||1||Dr. C. Lanier||This course will focus on how to obtain, stain, and evaluate high quality cytologic specimens. Students will learn to interpret microscopic findings in body fluids, organs and tissue masses, and understand the practical application of cytology as it applies to veterinary medicine.|\n|III||Classroom||VEM 5303||Small Animal Hematology||1||Dr. C. Lanier||Learn the practical application of hematology to companion animal medicine. Learn to interpret hemogram findings, evaluate blood films, bone marrow cytology, and common ancillary diagnostics as these relate to small/companion animal disease conditions.|\n|III||Classroom||VEM 5311||Avian Medicine and Surgery||2||Dr. D. Heard||Anatomy, physiology, husbandry and aviculture, diagnosis and treatment of pet birds.|\n|III||Classroom||VEM 5313||Poultry Diseases||1||Dr. J. Roberts||This course provides an introduction to viral, bacterial, and protozoal agents of\nveterinary and zoonotic infectious diseases as well as some nutritional deficiencies of turkeys and\nchickens. The purpose of the course is to provide the uniform conceptual knowledge base in infectious\nand nutritional diseases, especially observed in backyard and pet flocks.\n|III||Classroom||VEM 5370||Reptile Medicine and Surgery||1||Dr. J. Wellehan||An introductory understanding of non-avian reptile medicine.|\n|III||Classroom||VEM 5377||Marine Mammal Medicine||1||Dr. M. Walsh||This course covers the husbandry and medicine of selected marine mammal species including manatees, cetaceans and pinnipeds as examples of species encountered in aquariums and zoos. It is developed for veterinary students in their clinical years and is more clinically detailed in a number of medical techniques and supportive information such as anatomy and diet to give the new inexperienced clinician a basic understanding needed to enhance the problem solving thought process for these species. It incorporates additional instructors with extensive experience in the marine animal field. The goal of this course is to help the clinical student to understand the wide wealth of information in numerous disciplines that can contribute to their core competency in approaching clinical applied to marine species. Portions of the course are based on the prior involvement of students who have taken SeaVet but are enhanced with more case studies to help make it different with a higher involvement of clinical thinking and collaborative. There is no requirement for having first taken SeaVet though the anatomic and environment lectures may touch on similar perspectives to catch up newly interested students.|\n|III||Classroom||VEM 5378||SeaVet Clinical Training||3||Dr. M. Walsh||SeaVet Clinical Training is an intensive 10-day course designed to expose and teach freshman through senior veterinary medical students and interested veterinarians marine animal medicine through didactic lecture, case‐based problem‐solving, and laboratory experience and visits to established marine facilities. Provide fundamental and advanced information on marine animal medicine, husbandry and behavior to veterinary students and interested veterinarians including clinical anatomy, nutrition, diagnostic techniques, therapeutic applications, reproduction, management collaborating, lifelong learning and problem solving. The program features an educational and interactive swim session with dolphins to provide realistic exposure and hands‐on training with dolphins. It will include a visit to Lowry Park Zoo in Tampa Florida to get hands on handling experience and exposure to medical health assessment techniques, SeaWorld behind the scenes visit with the veterinary staff, a visit to Clearwater Marine Aquarium to compare facility functions at different locations with Sea turtle hands on experience and a visit to the Sea Life Aquarium in Orlando to see life support and animal care principles. A sea turtle necropsy lab is held the last day to provide hands on experience in sea turtle anatomy and disease issues in the species.|\n|III||Classroom||VEM 5424||Veterinary Forensic Pathology||1||Dr. A. Stern||This 1 credit course will explore the field of veterinary forensic pathology and associated forensic fields such as toxicology, entomology and DNA analysis. Students will learn about the forensic postmortem examination (necropsy/autopsy), how to collect samples for DNA analysis and gain an understanding in how DNA samples are analyzed, and learn about presenting this information in a court of law.|\n|III||Classroom||VEM 5472||Small Animal Anesthesiology||1||Dr. L. Pablo||Small Animal Anesthesiology VEM 5472 is a one-hour credit elective course, which consists of sixteen lectures. The main objectives of the course are to provide students the essential information for a safe practice of small animal anesthesia, guide the students in applying physiology and pharmacology in small animal anesthetic practice, and point out the principles behind the techniques performed in small animal anesthesia.|\n|III||Classroom||VEM 5473||Large Animal Anesthesiology||1||Dr. L. Pablo||Large Animal Anesthesiology (VEM 5473) is a one-hour credit elective course which consists of 14 lectures. The main goal of the course is to provide students the principles and knowledge necessary for the practice of safe anesthesia in large animals. Morever, the course will help the students in solidifying their knowledge and understanding of large animal anesthesiology by relating what they experienced in the anesthesiology clerkship.|\n|III||Clinical/Clerkship||VEM 5751||Anatomic Pathology Core Clerkship||1||Dr. L. Farina||Experience in gross necropsy, and histopathological examination. Pathology case material consists of in-patients as well as material referred from outside.|\n|III||Clinical/Clerkship||VEM 5761||Core Anesthesiology Clerkship||2||Dr. L. Pablo||The major aim of the Anesthesiology clerkship is to provide, a review of basic knowledge in anesthetic pharmacology and physiology, as well as, clinical experience to the students. The students will learn to perform preoperative evaluation of the patients, review clinical history pertinent to anesthesia, interpret laboratorial results and their impact on anesthetic pharmacokinetics and dynamics and tailor an appropriate anesthetic regime for each patient. The student is also expected to learn the parts and operation of anesthetic machines and how to assemble and test them before use. Also the student will learn how to read and interpret different monitoring parameters used in anesthetized patients. This clerkship should provide enough experience for the learner to refine the motor skills required for anesthesia clinical practice.|\n|III||Clinical/Clerkship||VEM 5821||Advanced Zoological Medicine Clerkship||2||Dr. D. Heard||Clinical experience in the diagnosis and treatment of diseases of pet animals, aquatic animals and exotic species.|\n|III||Clinical/Clerkship||VEM 5851||Applied Pathology Elective Clerkship||2||Dr. L. Farina||Experience in gross necropsy and histopathological examination. Case material consists of in patients as well as material referred from outside. Requires advanced permission from the course coordinator, and the student must participate in the biopsy service.|\n|III||Clinical/Clerkship||VEM 5854||Clinical Pathology Elective Clerkship||1||Dr. C. Lanier||This course will focus on how to obtain, process, and evaluate high quality clinical pathology specimens. Students will review and interpret hematology, serum biochemistry, and/or endocrinology cases in a clinical context as well as microscopic findings in blood, urine, other body fluids, organs and tissue masses, and learn the practical application of cytology as it applies to veterinary medicine.|\n|III||Clinical/Clerkship||VEM 5861||Advanced Anesthesiology Clerkship||2||Dr. L. Pablo||The major aim of the Anesthesiology clerkship is to provide, a review of basic\nknowledge in anesthetic pharmacology and physiology, as well as, clinical\nexperience to the students. The students will learn to perform preoperative\nevaluation of the patients, review clinical history pertinent to anesthesia,\ninterpret laboratorial results and their impact on anesthetic pharmacokinetics and\ndynamics and tailor an appropriate anesthetic regime for each patient. The\nstudent is also expected to learn the parts and operation of anesthetic machines\nand how to assemble and test them before use. Also the student will learn how to\nread and interpret different monitoring parameters used in anesthetized patients.\nThis clerkship should provide enough experience for the learner to refine the\nmotor skills required for anesthesia clinical practice.\n|III||Clinical/Clerkship||VEM 5876||Integrative Medicine Clerkship||2||Dr. E. Miscioscia||To learn the basic principles and applications of acupuncture and rehabilitation. To review basic anatomy and musculoskeletal parameters. To integrate rehabilitation, acupuncture, and nutrition with conventional medicine. To competently perform acupuncture and rehabilitation modalities such as LASER, therapeutic ultrasound, neuromuscular electrical nerve stimulation, transcutaneous electrical nerve stimulation (TENS), shockwave and underwater treadmill therapy. To effectively evaluate and compare maintenance and therapeutic diets, and to apply their appropriate use to clinical cases.|\n|III||Clinical/Clerkship||VEM 5893||Microbiology, Parasitology, and Serology Clinical Clerkship||2||TBD||The purpose of this course is to introduce the student to the diagnostic procedures performed on a daily basis in the areas of microbiology, parasitology and serology. The caseload will dictate the actual diseases that are seen clinically and therefore case based teaching will focus on determination of diagnostic protocols to be used, how each protocol is performed, troubleshooting problems in diagnostic testing, and the use of diagnostic keys and molecular procedures to identify microorganisms and parasites. Each student will get cases assigned at the beginning of the week and is expected to follow these cases to completion during their rotation|\n|III||Clinical/Clerkship||VEM 5895||Veterinary Forensics Clerkship||2||Dr. A. Stern||The clerkship is designed to increase student knowledge of veterinary forensics with both classroom and field work. Given the potential legal ramifications for use of real-life case material, this clerkship is designed to allow for the student to learn the techniques (and make mistakes now rather than in real-life); therefore, much of the teaching material will be mock crime scenes and cadaver work.|\n|III||Classroom||VEM 5991||Individualized Investigation||2||Dr. M. Long||This is a 2-credit elective course in which the student, having investigated a research topic to test a hypothesis under the guidance of a research advisor, will learn how to database, perform descriptive statistics, generate a manuscript and give a formal presentation to student peers. The data generated with a mentor can include bench or field research.|', 'Anaesthesia is the total loss of sensation in a body part or in the whole body, generally induced by a drug or drugs to create loss of feeling, unawareness and muscle relaxation either locally, regionally or centrally. There are many reasons for administering anaesthetics to animals; the main purpose is to provide a convenient, safe and effective means of facilitating medical and surgical procedures while minimising stress, pain, discomfort and adverse side effects to your pet and the veterinary team.\nMany veterinarians are presented with the challenge of anaesthetising pets with pre-existing conditions in their practices. Conditions such as heart, lungs, liver and kidney disease, the age and weight of the animal all play a part in affecting anaesthetic management. Certain breed differences can also result in increased anaesthesia-related morbidity and mortality. Some examples are:\n- Brachycephalic breeds (Pug, Boston Terrier, Pekingese, Boxer, Bulldog, Shih Tzu or any one of the other breeds with pushed in or short faces) – increased respiratory effort; potential for upper airway obstruction\n- Herding breeds (e.g., Shetland sheepdog, Australian Shepherd, Border collie) – a genetic mutation that allows a select group of drugs to accumulate within the brain, which may cause marked sedation and respiratory depression.\n- Toy breeds (eg, Shih Tzu, Pomeranian, Chihuahua, Papillion, Toy Poodle, Silky Terrier, Maltese) – lower body temperatures from large body surface area relative to body size; difficulty monitoring; low blood sugar\nAs with all aspects of medicine, complications will occur with anaesthesia. It has the potential to compromise your pet’s state of being at unpredictable times and in unpredictable ways, including causing animal death. Therefore, a thorough assessment of your pet is made before they undergo anaesthesia to maximise safety and minimise the potential for complications.\nA pre-anaesthetic evaluation is essential before any anaesthesia to identify and address abnormalities. This includes finding out patient history and doing a physical examination. A pre-anaesthetic blood test may be performed to check blood sugar, liver/kidney values, and red blood cell count. Many pets will require more extensive pre-anaesthetic blood tests. Even in pets under one year old, blood work will occasionally detect abnormalities that could affect anaesthesia. These will often be performed on the same day of the procedure\nA personalised anaesthesia plan will be created and addresses pre- and post-anaesthetic sedation and/or tranquillisation, induction and maintenance drugs, perioperative pain relief, ongoing physiologic support, monitoring parameters, and responses to adverse events.\nYou will be asked to withhold food and water for your pet before the day of procedure for a certain time to reduce the risk of regurgitation and aspiration, which means breathing in the contents of the stomach and gastric juices into the lungs. Your veterinarian or veterinary technician will explain the procedure to you and discuss the patient assessment and risks, the proposed anaesthesia plan, and any medical or surgical alternatives before obtaining informed consent to anaesthetise your pet and perform the procedure. To help reduce the risk of complications, it is very important that you follow the directions of the veterinarian, especially regarding patient preparation.\nEvery pet under general anaesthesia requires continuous monitoring of their vital parameters (heart activity, breathing, temperature and degree of consciousness). The goals of monitoring are to:\n- Watch the physiological status of your pet\n- Adapt anaesthesia depth to an adequate level\n- Anticipate problems\nA variety of monitoring equipment is available for determining your pet’s status during anaesthesia. Improved anaesthetic safety depends on both the correct use of equipment and the correct interpretation of information obtained. Written anaesthetic records are sometimes used. Despite the electronic aids available, the most important monitor still remains a dedicated vet / vet nurse who is constantly monitoring the patient.\nMany drugs used for general anaesthesia tend to cause blood pressure to decrease. Intravenous fluids administered during anaesthesia will counter this decrease. In addition, if there are any adverse reactions under anaesthesia, an intravenous catheter allows immediate administration of emergency drugs.\nAll animals, especially cats and small dogs, lose a lot of body heat under anaesthesia. The resulting hypothermia can slow the anaesthetic recovery. Anaesthetised pets are placed on a recirculating warm water pad and / or under a warm air blanket.\nPets are generally intubated when undergoing anaesthesia, which means that they have an endotracheal tube placed through the mouth and into the trachea, through which anaesthetic gas is administered. The endotracheal tube allows controlled respirations if your pet is not breathing well on their own, and prevents regurgitation if the pet vomits under anesthesia.\nYour pet is continuously monitored during the recovery period for after effects such as:\n- Partial or complete airway obstruction\n- Lack of oxygenation\n- Low body temperature\n- Nausea and vomiting\n- Behavioural changes including delayed recovery of consciousness\nSome effects may last for 12-24-hours after anaesthesia.\nWhen your pet is awake, aware, warm, and comfortable, he or she will be discharged. But first, the veterinary team will:\n- Review the procedure and how it went.\n- Explain follow-up care, including when your pet can begin to eat and drink.\n- Explain how to recognise signs of complications in your pet. It is important that you call your veterinarian immediately if your pet has a complication.\n- Tell you when to bring your pet back for a re-check.\n- In addition to telling you the instructions, the veterinary team should give you a written copy of the aftercare instructions.\nAnaesthesia is more than the delivery of anaesthetic drugs. With proper perioperative assessment and appropriate patient monitoring, safe and successful anesthesia can be performed in any breed of dog.\n1. “Veterinary Information Network (VIN) – For Veterinarians, By Veterinarians.” Veterinary Information Network (VIN) – For Veterinarians, By Veterinarians. Web. 18 Apr. 2015. <http://www.vin.com/>.\n2. Muir, William W., John A. E. Hubbell, Richard M. Bednarski, and Phillip Lerche. Handbook of Veterinary Anesthesia. 5th ed. St. Louis: Mosby, 2013. Print.\n3. Bednarski, Richard, et al. “AAHA Anesthesia Guidelines for Dogs and Cats.” American Animal Hospital Association. 1 Jan. 2011. Web. 16 Apr. 2015.\n4. “Canine Anesthesia.” www.vetlearn.com. 1 Jan. 2011. Web. 17 Apr. 2015.\nThis article is written by Dr Clare Koh of The Joyous Vet Pte Ltd. Dr Clare Koh graduated from the University of Queensland. She has special interests in emergency and critical care and internal medicine. Dr Clare finds a great sense of satisfaction through helping pet owners and their fur kids. She believes that keeping up with the latest information in vet medicine will allow her to serve them better. Whenever away from the hustle and bustle of the clinic, Dr Clare winds down by watching movies, reading fiction, and cycling.']	['<urn:uuid:c5daaa62-19af-4c28-a751-b56a1c2b1a58>', '<urn:uuid:ed5e1d16-deb7-41b0-a1d5-1997749d2ad0>']	factoid	with-premise	long-search-query	distant-from-document	multi-aspect	expert	2025-05-01T23:21:14.341336	9	64	3778
307	What are some of the common wrong beliefs that custody evaluators might have about what's best for children?	Evaluators may hold preconceptions about what is good or bad for children (such as beliefs that the family bed is bad or that young children should be with their mothers) despite the fact that empirical research in their discipline does not support such ideas.	"['For copies of these or other publications, contact Dr. Wittmann at email@example.com\nTippins, T.M. and Wittmann, J.J.P. (2005). Empirical and ethical problem with custody recommendations: A call for clinical humility and Judicial Vigilence. 43 Family. Court. Review. (April. 2005), Association of Family and Conciliation Courts.\nThis article proposes a four-level model of clinical inferences to analyze the psychological evaluation process in contested custody and visitation matters. At each level the authors summarize the status of the psychological literature that can be brought to bear on the issues before family and matrimonial judges and conclude that, as clinicians begin to respond specifically to the central issues in such matters (e.g., who should be the custodial parent, when children should see their other parent, etc.) the empirical foundation for such conclusions is tenuous at best, and often non-existent. An argument is also made that, on the basis of important evidentiary and jurisprudential concerns, such opinions should be routinely excluded from the fact-finding process. Given the significant potential for specific custody recommendations to affect and limit personal liberties and the trajectory of a child\'s life, and given the paucity of relevant research available in this area and the profound evidentiary issues, such recommendations should now be viewed as ethically inappropriate. A model for what clinicians can ethically say to courts in custody matters is proposed. Tippins,\nT.M. & Wittmann, J.P., (2005) ""A Third Call: Restoring the Noble Empirical Principles of Two Professions."" Family Court Review, 43, 270-282.\nThe call issued by Tippins and Wittmann in 2005 for a radical re-thinking of the role that mental health professional play in custody matters generated intense controversy and scholarly debate. In this ""response to the responders"" each major counter-argument presented by multiple practitioners and scholars in the field is discussed and analyzed.\nWittmann, J.J.P. (2012). Bias in custody evaluations. New York Family Law Monthly. January.\nA hallmark of effective and trustworthy forensic work is the evenhanded and fair-minded (1) interaction with litigants, (2) collection of data, and (3) interpretation of what we have learned about a family. ""Bias,"" in the broadest sense refers to an emotional or cognitive inclination that interferes with an unprejudiced consideration of the data that has been gathered. An evaluator may unconsciously favor fathers and this quickly becomes evident in his disdain for some of the mother\'s assertions. Another evaluator may set herself up for a preference for the mother\'s position in a case simply by interviewing her first, and repeatedly, in advance of ever seeing the father. Another evaluator may enter an assessment with firmly held pre-conceptions about what is good and bad for children (eg, the family bed is bad, young children should be with their mothers, etc) despite the fact that the empirical research in his/her discipline fails to support such ideas. These cognitive sets and assumptions, however formed, create a kind of lens through which data that is gathered on a family is processed and interpreted (with the very real potential for errors to be made at the stage where the court is being given an evaluator\'s ""bottom line"" about a particular child\'s needs or a particular parent\'s skills/capacities). In this article Dr. Wittmann defines and discusses 15 forms of bias that can infect the custody evaluation process to the detriment of children, their parents, and the courts.']"	['<urn:uuid:d42044fb-5731-4434-8428-9b414cee156e>']	factoid	direct	verbose-and-natural	distant-from-document	single-doc	novice	2025-05-01T23:21:14.341336	18	44	550
309	How do you identify the positive lead on an LED?	The longer lead on the LED is the positive side.	"['LED circuits are very easy to design. An LED or Light Emitting Diode, is a very low current light source that is very safe and durable for use in your project. This article will show you how to design and build a very simple LED circuit.\nThings You\'ll Need\n- Battery or power source\n- Wire or alligator clips\n- Helpful to have (multimeter)\n- Helpful to have (soldering iron)\nThe first step is to choose how many LED\'s you want to light and their type (color, brightness). With this simple circuit you will be somewhat limited by the amount of voltage that can be safely provided for your project.\nCalculate the amount of voltage you need from your power supply.\nLook for the ""diode forward voltage"" specification from the manufacture\'s website or packaging. If you do not have this information you can use the following to estimate:\nRed or Orange 2.0 V\nYellow 2.1 V\nGreen 2.2 V\nTrue Green, Blue, White 3.3 V\nBlue (430 nm) 4.6 V\nSay you want to have 3 Red LED\'s in your circuit. Only use the diode forward voltage value. So, 3 x 2.0 = 6V, needed.\nOnce you have the required voltage, choose how you want to power the circuit. Do you want to plug it into an outlet and not have to change batteries or do you want the freedom to move around?\nDC voltage works easiest. AA, AAA, or 9V batteries are cheap and easy to find for a simple project. The simplest way to use AC as your source is a wall plug (wall wart), the large black plugs that come with most every electronic device you purchase. You probably have a box full of these sitting around. You will have to cut the plug off the end of the cord. Use a multimeter to determine the positive and negative lead.\nAC voltage can also be designed in the circuit. AC will only drive the LED half of the time since the voltage travels in waves. A full-wave bridge rectifier can be used to fully power LED\'s. This is essentially what the wall wart is doing for you.\nFind a power supply greater than the calculated diode forward voltage value from step 2. In our case we calculated 6 volts. A power supply value greater than 6 volts will be needed. If you are driving a large number of LED\'s, current may also be important.\nCalculate the required LED resistor value.\nLED\'s cannot be connected directly to the battery or power supply. The LED will be instantly destroyed because the current is too great. The current must be reduced. The easiest way to do this is by using a resistor. Calculate the LED resistor value with the following formula:\nLED Resistor Value, R=(supply voltage - LED voltage) / LED current\nIn our example:\nSay we use a 9V battery, then supply voltage = 9V.\nLED voltage for red LED\'s, from Step 2 is 2.0 V\nLED current is 20 mA (this is a typical value if not provided by the manufacturer)\nIf the resistor value is not available, then choose the nearest standard resistor value which is greater. If you want to increase the battery life you can select a higher resistor value to reduce current. The reduced current will result in a dimmer LED.\nR = (9 - 2.0) / 20 mA = 350 ohms, use the next higher standard value = 360 ohms\nWire your circuit together.\nYou can soldier the wires directly together, use crimp connectors, or use a small circuit board. Choose the best method based on the size of your project.\nThe final step is to mount the LED\'s in your project. Radio Shack and others sell chrome or plastic LED holders that make a professional looking mount easy. You can add momentary push buttons or on/off switches to your LED circuits.\nDesigning and building a simple LED circuit is an easy project.\nTips & Warnings\n- The longer lead on the LED is the positive side. Do not reverse the leads on the LED.\n- Remember that if you do not have the right resistor value handy you can put more than 1 resistor in series and add their values to get total resistance.\n- Make sure if you using AC with a full-wave rectifier to consider the voltage drop. Measure the output with a multimeter to be sure.\n- Never connect the LED\'s in parallel\n- Always use caution when working with power sources and soldering iron. They can be dangerous.\n- Photo Credit lifeengineer\nHow to Build Sequential Flashing LED Circuits\nIt\'s relatively easy to make a row of LEDs flash in sequence using simple digital electronics. Don\'t be scared by the word...\nHow to Build an LED Light\nBuilding a simple LED light can be a great project for kids or adults just learning electronics. An LED light can be...\nHow to Build a Circuit for Multiple LEDs\nAs long as you know the values of your LEDs, putting together a circuit for multiple ones is fairly straight-forward. Simply calculate...']"	['<urn:uuid:93ec16b2-95cb-45a1-a568-1be84f5e3d21>']	factoid	direct	concise-and-natural	distant-from-document	single-doc	expert	2025-05-01T23:21:14.341336	10	10	851
310	Why is early treatment important for autism?	Starting supportive services as soon as possible after diagnosis is key because earlier interventions lead to better long-term results, according to Dr. Marrus, a Washington University child psychiatrist at St. Louis Children's Hospital.	['Your child has autism spectrum disorder. Now what?\nAutism spectrum disorder (ASD) awareness has grown since experts began closely studying its prevalence nearly 20 years ago. More parents than ever are aware of ASD and its symptoms, but hearing your child has the disorder can be scary. Learning more about what to expect after an ASD diagnosis can help set your mind at ease.\nFirst Things First\nNo matter where children with ASD are on the spectrum, starting supportive services as soon as possible after diagnosis is key. The earlier interventions begin, the better their long-term results, according to Natasha Marrus, MD, PhD, a Washington University child psychiatrist at St. Louis Children’s Hospital.\nIf your child is younger than three, your family may receive a referral to Missouri First Steps, an Early Intervention Program available through the Missouri Department of Elementary and Secondary Education or Illinois Early Intervention Services, which is available through the Illinois Department of Human Services. You can contact First Steps or your local Child and Family Connections office directly if you have concerns about your child’s development. If a child is older than age three, the process is a bit different. Parents of preschool- and school-age children can contact their child’s school district to see what types of low- or no-cost services may be available.\n“Many parents are surprised to learn that help is available through local school districts and county agencies,” says Valerie Welch, MD, pediatrician at Washington University Clinical Associates West Side Pediatrics. “School districts, for example, provide physical, occupational and speech therapies. They also offer an individualized education plan (IEP) that puts into writing the different types of personalized accommodations and assistance students with ASD will receive to improve their behavior and communication skills.”\nFamilies in Missouri can also find help at the State of Missouri-Washington University Autism Clinical Center. The center’s team includes psychiatrists, behavior analysts and neuropsychologists. These providers diagnose ASD and work together to develop therapy plans. Treatments may include applied behavioral analysis, which helps children advance their communication and learn acceptable behaviors, as well as physical, occupational or speech therapy.\n“Our goal is to get to know each child and develop treatment plans based on personal strengths and weaknesses,” Dr. Marrus says. “We also conduct genetic testing to see if there are any syndromes or underlying medical conditions that may be linked to the diagnosis.”\nOne Step at a Time\nThere’s no rule book for raising a child with ASD. Likewise, ASD doesn’t follow a set course—as children grow and develop, their needs and abilities may change.\n“One common misconception parents have is that their child is always going to have the same behavioral or sensory issues,” Dr. Welch says. “They will continue to have repetitive behaviors and communication issues, but those issues will change year by year. A child may have an obsession with tags on their clothing, but over time, they become tolerant to tags. They don’t outgrow their autism, but the way it looks can change as a result of growth, development and interventional therapies.”\nRemaining your child’s biggest advocate and not being shy about making your family’s needs known can make a huge difference in your child’s progress.\n“It’s a step-by-step journey,” Dr. Marrus says. “A big part of the process is advocacy. Families who, I think, have had the best outcomes work together as a team and get help from people outside of their family who also advocate for their kid and others like him or her. Getting the accommodations your child needs can be hard, but reaching out is important and can make the journey much smoother.”\nReady to learn more? Call the St. Louis Children’s Hospital Family Resource Center at 314.454.KIDS (5437) and press “5” to have information on autism spectrum disorder sent to you.']	['<urn:uuid:aa789d72-49a3-4187-a654-1c8dbdc7135f>']	factoid	direct	concise-and-natural	distant-from-document	single-doc	novice	2025-05-01T23:21:14.341336	7	33	633
311	when did european eels get anguillicoloides crassus parasite	The parasitic nematode Anguillicoloides crassus spread throughout Europe since its arrival in Europe in the 1980's.	['A new paper entitled ‘Relationship between European eel Anguilla anguilla infection with non-native parasites and swimming behaviour on encountering accelerating flow‘ has just been published in the Journal of Fish Biology by Lynda Newbold et al. It examines the effect of the Eel swimbladder nematode Anguillicoloides crassus and other endoparasite (the gill monogeneans Pseudodactylogyrus bini and P. anguillae) infections on the behaviour of downstream migrating silver eels. The authors used an experimental flume to look at the how the eels behaved when they encountered accelerating water velocity, common at engineering structures in rivers where flow is constricted, for example at dams and bypass systems.\nthis need to be considered when designing eel bypasses to ensure that the hydraulic conditions at the entrance encourage efficient downstream silver eel passage\nThe study found that the probability of reacting to, and rejecting, the velocity gradient was positively related to swimbladder nematode abundance. They found that high abundance of Pseudodactylogyrus spp. reduced this effect, but A. crassus was the strongest parasitic factor associated with eel behaviour, and abundance was positively related to delay in downstream passage. The authors noted that delayed downstream migration at hydraulic gradients associated with riverine engineering structures could result in additional energetic expenditure for migrating silver eels already challenged by swimbladder nematode infection.\nIt is now clear that there is a possible energetic cost of A. crassus infection induced through host behavioural change. When combined with a decreased swimming performance and impaired swimbladder function this could reduce the probability of European eels successfully completing their spawning migration. Furthermore, greater avoidance of velocity gradients at dam bypass entrances will reduce passage efficiency for eels parasitized with the swimbladder nematode. The authors recommend that this need to be considered when designing eel bypasses to ensure that the hydraulic conditions at the entrance encourage efficient downstream silver eel passage. Newbold et al (2015) concluded that “the results of this study suggest that the combined effect of barriers and parasite infection on energetic costs during migration should be recognised in European eel conservation efforts to promote passage, escapement and spawner quality“.\nEel swimbladder nematode Anguillicoloides crassus\nAnguillicoloides crassus (formerly Anguillicola crassus) is a parasitic nematode worm that lives in the swimbladders of eels (Anguilla spp). It is native to Southeast Asia and its native host is the Japanese eel (A. japonica). The endoparasite has spread throughout Europe since its arrival in Europe in the 1980’s. Once introduced to a population the nematode can spread rapidly. Intermediate hosts include copepods and ostracods. Once introduced into a lake or river it may spread rapidly among the eel population. A. crassus is a successful coloniser due to its large production of eggs and low specificity regarding intermediate hosts. It has been estimated that A. crassus is present in at least 70% of Ireland’s wetted area and is spreading. It is widely considered that A. crassus played a role in the collapse of the European eel population by decreasing growth, increasing mortality and impeding spawning success.\nThis endoparasite causes damage through inflammation of the swimbladder and secondary bacterial infection. This results in reduced function or failure of the gas glands thus reducing the eel’s ability to maintain and adjust buoyancy. In severe infections a total loss of function of the swimbladder may occur. It is understood that when European eel migrates across the Atlantic to spawn it travels at great depths. It is clear that swimbladder damage due to heavy A. crassus infestation is very likely to impair their ability to migrate normally and is a serious threat for the reproductive success of infected and previously infected European eels.\n- Relationship between European eel Anguilla anguilla infection with non-native parasites and swimming behaviour on encountering accelerating flow\n- Swimming performance of silver eels is severely impaired by the swim-bladder parasite Anguillicola crassus\n- Introduced parasite Anguillicola crassus infection significantly impedes swim bladder function in the European eel Anguilla anguilla (L.)\n- Assessing the impact of hydropower and fisheries on downstream migrating silver eel, Anguilla anguilla, by telemetry in the River Meuse\nAlso please feel free to contact us at any time regarding any issues in relation to the management of the European Eel.']	['<urn:uuid:58a1c4d7-063e-4e9b-a0e5-5073f6dd4da2>']	factoid	direct	short-search-query	similar-to-document	single-doc	novice	2025-05-01T23:21:14.341336	8	16	695
312	Which condition has a higher survival rate: untreated neuroblastoma or untreated CML?	Untreated CML has a higher survival rate. Prior to ch14.18 treatment, more than 60% of children with aggressive neuroblastoma would not live five years after diagnosis. In comparison, untreated CML progresses from chronic phase to blast crisis in a median time of 4 years.	"[""Harnessing the Power of Our Immune Systems to Treat Neuroblastoma: Discovery of Ch14.18 Immunotherapy\n- Neuroblastoma is a cancer arising in immature nerve cells. It occurs most often in the adrenal glands, but it can also develop in other areas of the abdomen and in the chest and neck near the spine. Neuroblastoma is the most common cancer affecting infants, yet the cause of this rare cancer is unknown.\n- Prior to a groundbreaking discovery by scientists supported by the National Cancer Institute (NCI), the majority of children diagnosed with advanced-stage disease had little hope of surviving and less than 40 percent lived five years after diagnosis.\n- Now an immunotherapy 30 years in the making called ch14.18 is providing new hope for infants and children with this rare cancer.\nPathway to Discovery\nImmunotherapy is a type of treatment that harnesses the power of the immune system to help the body fight cancer, infection, and other diseases. Some types of immunotherapy stimulate or enhance the immune system’s ability to fight disease, whereas others provide the immune system with what it needs, such as antibodies, to fight disease.\nIn the late 1980s, Alice Yu, M.D., at the University of California, San Diego Medical Center, began testing an approach that used laboratory made antibodies, called monoclonal antibodies, as a treatment for neuroblastoma. Monoclonal antibodies are designed to target a specific protein or cell. Dr. Yu's immunotherapy treatment went through many versions before reaching its current standard, a monoclonal antibody called ch14.18.\nThe ch14.18 monoclonal antibody specifically targets a substance called GD2 that is found at high levels on the surface of neuroblastoma cells. When the immune system detects the presence of the antibody on the cancer cells, it triggers responses that kill the cancer cells.\nDr. Yu and her colleagues in the Children's Oncology Group, part of NCI’s National Clinical Trials Network, tested the ch14.18 monoclonal antibody on 226 patients with neuroblastoma in 2001. The treatment was given to children who already had responded to initial treatment with chemotherapy, radiation, and stem cell transplantation. The ch14.18 antibody was administered along with two immune-stimulating agents, GM-CSF (granulocyte macrophage colony stimulating factor) and IL-2 (interleukin-2), to increase the effectiveness of immune system killing of the tumor cells.\nIn 2009, an interim analysis of the clinical trial showed that the treatment was successful. Among patients who received the immunotherapy plus standard treatment, 66 percent were alive and free of neuroblastoma two years later compared with 46 percent of those who had received standard therapy alone. In light of such favorable results during the interim analysis, the immunotherapy was made available to all eligible patients within the study.\nReporting their findings in the New England Journal of Medicine, the researchers concluded that the immunotherapy improved survival in children newly diagnosed with neuroblastoma who were at high risk for developing a recurrence and who responded well to initial treatment with standard therapies.\nEnhancing Cancer Care\nBefore ch14.18 treatment, more than 60 percent of children with aggressive neuroblastoma would not live five years after being diagnosed. The combination of the anti-GD2 antibody and an immune-stimulating treatment is the first effective immunotherapy for neuroblastoma shown to reduce the risk of recurrence and improve survival by 20 percent for patients with high-risk neuroblastoma.\nMore than twenty years after Dr. Yu began testing this immunotherapy treatment, her concept is an effective standard therapy for high-risk patients in remission following initial disease treatment. Many children are being saved from this disease by harnessing the therapeutic power of their own immune systems.\nTurning Discovery into Health\nIn some children, neuroblastoma recurs within two years of treatment, while others remain tumor-free. Dr. Yu’s team is now looking closely at the immune responses and tumor behavior in these two groups of patients to identify differential biological markers. Identifying the markers that indicate that disease may redevelop could allow clinicians to tailor treatments and make the immunotherapy even more effective.\nIn addition, researchers are actively developing less toxic versions of the current immunotherapy to reduce side effects, such as nerve pain. In the meantime, patients' nerve pain must be effectively managed by physicians to safely give the treatment.\nBuilding on the success of ch14.18, researchers are using T cells, engineered to express a new class of proteins known as chimeric antigen receptors (CARs), to fight neuroblastoma in a new and more robust immune cell-based treatment targeted to GD2.\nResearch to Practice: NCI's Role\nNCI has supported more than 30 years of research on antibody-based immunotherapy, resulting in scientists bringing a new life-saving treatment to children with aggressive neuroblastoma. This research ranged from the discovery stage to phase III clinical trials that showed the treatment’s effectiveness.\nIn addition, when no pharmaceutical company was willing to manufacture the anti-GD2 (ch14.18) antibody for the clinical trial, NCI began producing the antibody itself. Once its effectiveness was proven, NCI increased production of the antibody to ensure availability for every child with neuroblastoma who is eligible for the treatment.\nPrior to the discovery of ch14.18, most children diagnosed with advanced-stage neuroblastoma had little hope of surviving. Thanks to NCI supported-research, many children are now being saved from this disease by harnessing the therapeutic power of their own immune systems.\nLouis CU, Savoldo B, Dotti G, et al. Antitumor activity and long-term fate of chimeric antigen receptor-positive T cells in patients with neuroblastoma. Blood. 2011 Dec 1;118(23):6050-6056. [PUBMED Abstract]\nMatthay KK, George RE, Yu AL. Promising therapeutic targets in neuroblastoma. Clin Cancer Res. 2012 May 15;18(10):2740-2753. [PUBMED Abstract]\nNavid F, Armstrong M, Barfield RC. Immune therapies for neuroblastoma. Cancer Biol Ther. 2009 May;8(10):874-882. Epub 2009 May 9. [PUBMED Abstract]\nSeeger RC. Immunology and immunotherapy of neuroblastoma. Semin Cancer Biol. 2011 Oct;21(4):229-237. Epub 2911 Sept 28. [PUBMED Abstract]\nYu AL, Gilman AL, Ozkaynak MF, et al. Anti-GD2 antibody with GM-CSF, interleukin-2, and isotretinoin for neuroblastoma. N Engl J Med. 2010 Sept 30;363(14):1324-1334. [PUBMED Abstract]"", 'Dr. Dharam Pal Bansal, M.D, D.M\nDr. Mohd Viquas Uddin Saim\nDNB Medicine resident\nCHRONIC MYELOID LEUKEMIA\nIs a myeloproliferative disorder with a\ncharacteristic cytogenteic abnormality and\npropensity to evolve from a chronic phase into a\nincidence of chronic myeloid leukemia (CML) is\n1.5 per 100,000\nhigher in men than in women\nincidence of CML increases slowly with age until\nthe middle forties, when it starts to rise rapidly.\nMedian age at onset is in mid-50’s\nThe diagnosis of CML is established by\nidentifying a clonal expansion of a hematopoietic\nstem cell possessing a reciprocal translocation\nbetween chromosomes 9 and 22.\nThis translocation results in the head-to-tail\nfusion of the (BCR) gene on chromosome 22q11\nwith the ABL1 (gene located on chromosome\nUntreated, the disease inevitably transforms from\na chronic phase to an accelerated phase and on\nto blast crisis in a median time of 4 years.\ncigarette smoking accelerated the progression to\nblast crisis and therefore adversely affected\nsurvival in CML.\nAtomic bomb survivors had an increased\nincidence; the development of a CML cell mass of\n10,000/L took 6.3 years.\nNo increase in CML incidence was found in the\nsurvivors of the Chernobyl accident, suggesting\nthat only large doses of radiation can induce\nPathophysiology : clonality\nCML is a clonal disease of an abnormal stem cell\nMyeloid, erythroid, megakaryocytic and B\nlymphoid cells are involved in the malignant\nPathophysiology : philadelphia\nIt is the diminutive chromosome produced by an\nunbalanced translocation between chromosomes\n9 and 22.\nThis translocation t(9:22) fuses the 3’ portion of\nthe c-ABL gene on the long arm of chr 9 to 5’ end\nof BCR gene on long arm of chr 22.\nThe resultant fusion gene encodes a chimeric\nprotein with constitutive tyrosine kinase activity.\nThe BCR-ABL protein stimulates the proliferation\nand enhances the survival of CML hematopoietic\nAsymptomatic in 20 % patients , discovered on\nroutine blood exams.\nOnset : insidious\nThe excessive number of metabolically active\nmyeloid cells can cause fevers and sweats.\nfatigue, malaise, and weight loss\nsymptoms from splenic enlargement, like early\nsatiety and left upper quadrant pain or mass.\nBone pain and tenderness from expanding\nLess common are features related to granulocyte\nor platelet dysfunction, such as infections,\nthrombosis, or bleeding.\nOccasionally, patients present with leukostatic\nmanifestations due to severe leukocytosis or\nthrombosis such as :\n1. vasoocclusive disease, 2. cerebrovascular\naccidents, 3. myocardial infarction, 4. venous\nthrombosis, 5. priapism, 6. visual disturbances,\nand 7. pulmonary insufficiency.\nProgression of CML is associated with worsening\nUnexplained fever, significant weight loss,\nincreasing dose requirement of the drugs\ncontrolling the disease, bone and joint pain,\nbleeding, thrombosis, and infections suggest\nClinical features : Leukostasis\nMarked leukocytosis > 1,00,000/microL can be\nassociated with symptoms of leukostatsis\nManifestations may include\n1. visual changes\n3. Cerebral or myocardial infarctions\nMinimal to moderate splenomegaly is the most\ncommon physical finding;\nmild hepatomegaly is found occasionally.\nPersistent splenomegaly despite continued\ntherapy is a sign of disease acceleration.\nLymphadenopathy and myeloid sarcomas are\nunusual except late in the course of the disease;\nwhen they are present, the prognosis is poor.\nElevated white blood (cell) counts (WBCs), with increases in\nboth immature and mature granulocytes, are present at\nWBC count usually exceeds > 30,000 and usually ranges from\n1,00,000 to 3,00,000.\nThe peripheral blood smear often resembles a bone marrow\naspirate due to presence of all stages of myeloid maturation.\nmyeloblasts constitute < 15 % of leukocytes and promyelocytes\ncombined < 30 % in PBS\nPlatelet counts are almost always elevated at diagnosis, may\nexceed 1,000,000/UL and a mild degree of normocytic\nnormochromic anemia is present.\nLeukocyte alkaline phosphatase is low in CML cells.\nPhagocytic functions are usually normal at diagnosis and remain\nnormal during the chronic phase.\nHistamine production secondary to basophilia is increased in\nlater stages, causing pruritus, diarrhea, and flushing. Basophils <\nBone marrow aspiration and\nShould be performed on all patients as a part of\nIn all cases marrow is markedly hypercellular due\nto massive myeloid hyperplasia\nMarkedly increased myeloid : erythroid ratio\nFibrosis may also be present\ndefined by the development of\n1.increasing degrees of anemia unaccounted for\nby bleeding or therapy;\n2. cytogenetic clonal evolution;\n3. blood or marrow blasts between 10 and 20%,\nblood or marrow basophils 20%, or platelet count\nHyposegmented neutrophils may appear (Pelger-\nWHO criteria :\nBlasts > 20% of peripheral white blood cells or of\nnucleated bone marrow cells\nExtramedullary blast proliferation\nLarge foci or clusters of blasts in the bone\nInternational Bone Marrow Transplant Registry\n> 30% blasts in the blood, marrow, or both\nExtramedullary infiltrates of leukemic cells\nShould be performed at the time of bone marrow\nexamination on all patients.\nThe cytogenetic hallmark of CML, found in 90–95% of\npatients, is the t(9;22)(q34;q11.2).\nInfrequently complex translocations can occur which\ncan mask BCR – ABL translocation.\nIn such situations FISH or PCR BCR-ABL can identify\nAll patients should have evidence of the translocation\nmolecularly or by cytogenetics or FISH to make a\ndiagnosis of CML.\nFISH is More sensitive than cytogenetics at detecting\nminimal residual disease during therapy.\nPolymerase chain reaction\nIs a molecular assay performed on peripheral\nblood that identifies the BCR-ABL, translocation.\nThe quantitative PCR or Q-PCR is the most\nsensitve method to follow residual disease during\ntreatment of CML\nA baseline Q-PCR should be obtained in all\nCan also detect complex translocations like FISH\nLeukocyte alkaline phosphatase and\nuric acid levels in CML\nLAP activity is decreased or absent in circulating\nHyperuricemia and hyperuricosuria commonly\nDiagnostic criteria and prognostic\nWHO diagnostic criteria for chronic phase\n2. prominent dysgranulopoiesis\n3. promyeloctyes, myelocytes and\nmetamyelocytes > 10 % of WBC’s\n4. basophils < 2 % of WBC’s\n5. monocytes < 10 % of WBC’s\n6. hypercellular bone marrow with granulocytic\nproliferation and dysplasia\n7. < 20 % blasts in the blood or bone marrow\nDiagnostic criteria and prognostic\nWHO criteria for diagnosis of accelerated phase\n1. blasts 10% to 19% in the blood or bone\n2. basophils > 20 % of peripheral blood WBC’s\n3. platelets > 1,000,000/UL unresponsive to\ntherapy or < 1,000,000/UL unrelated to therapy\n4. increasing spleen size or WBC count\nunresponsive to therpy\n5. cytogenetic evidence of clonal evolution\nDiagnostic criteria and prognostic\nWHO criteria for diagnosis of blast phase\n1. Blasts > 20 % of bone marrow cells or\n2. extramedullary blast formation\n3. large foci or clusters of blasts in bone marrow.\nThe clinical outcome of patients with CML is variable.\nThe Sokal index identified percentage of circulating blasts,\nspleen size, platelet count, age, and cytogenetic clonal evolution\nas the most important prognostic indicators.\nThe Hasford system was developed based on interferon (IFN) –\ntreated patients. It identified percentage of circulating blasts,\nspleen size, platelet count, age, and percentage of eosinophils\nand basophils as the most important prognostic indicators.\nBoth of these scoring systems stratify patients into three risk\nintermediate, and high) and have been used for the risk\nstratifications of patients in clinical trials evaluating tyrosine\nkinase inhibitors (TKIs).\nthe Hasford system was better than the Sokal score for\npredicting survival time\nOngoing assessment of response during therapy has emerged\nas a much more important predictor of progression free survival.\nThe therapy of CML is a proven curative treatment\n(allogeneic transplantation) that has significant toxicity\nand a new targeted treatment (imatinib) with\nIts recommended starting with TK inhibitors and\nreserving allogeneic transplantation for those who\ndevelop imatinib resistance.\nAt present, the goal of therapy in CML is to achieve\nprolonged, durable, nonneoplastic, nonclonal\nhematopoiesis, which entails the eradication of any\nresidual cells containing the BCR-ABL1 transcript.\nHence, the goal is complete molecular remission and\nImatinib mesylate acts by competitive inhibition\nat the ATP-binding site of the Abl kinase, which\nleads to inhibition of tyrosine phosphorylation of\nproteins involved in Bcr-Abl signal transduction.\nTreatment is currently recommended for life .\nimatinib discontinuation after at least 2 years of\ncomplete molecular remission revealed molecular\nrelapse in 6 of 12 patients.\nInterestingly who were treated with IFN- before\nimatinib maintained molecular remission,\nStandard dose is 400 mg / day\nCan be increased to 600 mg/day if suboptimal\n800 mg/day in 2 divided doses also used.\nPeople who cannot tolerate < 300 mg / day\nwarrant a change in therapy.\nImatinib is administered orally.\nThe main side effects are fluid retention, nausea,\nmuscle cramps, diarrhea, and skin rashes.\nMyelosuppression is the most common\nhematologic side effect. may require holding drug\nand/or growth factor support.\nDoses <300 mg/d seem ineffective and may lead\nto development of resistance.\nAcquired imatinib resistance\nIs defined as a loss previous hematologic or\nBest understood mechanism is development of\npoint mutations in BCR-ABL.\nCML with BCR-ABL mutation can be successfully\ntreated with 2nd generation kinase inhibitors like\ndasatinib and nilotinib.\nBCR-ABL harboring T315I is resistant to even\nMonitoring response to imatinib\nPatients who do not achieve response end points\nwithin appropriate time frames should be treated\n1. dose escalation of Imatinib\n2. therapy with alternate TK inhibitor\n3. allogenic bone marrow transplantation\nResponse end points\nComplete hematologic response (CHR)\nDefinition : CHR is defined as normalization of\nperipheral blood counts and can be expected in >\n95% of chronic phase patients,\nFailure to achieve this by 3 months warrants\nreassessment of treatment approach.\nResponse end points\nMajor cytogenetic response\nDefinition : its defined as reduction of the\npercentage of philadelphia chromosome to < 35%\nof bone marrow metaphases.\nComplete cytogenetic response is defined as\nnormalization of bone marrow cytogenetics.\nIdeally MCR should be observed by 6 months\nand CCR by 1 yr.\nAbsence of any cytogenetic response at 6\nmonths ,< MCR at 12 months, or < CCR at 18\nmonths should prompt consideration of change in\nResponse end points\nMajor molecular response\nDefinition : at least a 3 log (1000 fold) reduction in\nthe level of disease measured by Q-PCR.\nPatients who achieve this end point by 1 yr have\na zero percent risk of disease progression to AP\nor BP at 5 years.\nMonitoring should also include Bone marrow\naspiration and biopsy at baseline and every\n6months, untill a complete cytogenetic response\nQ-PCR should be performed every 3 months.\nNewer drugs for imatinib\nMutations at the kinase domain occur in\napproximately half of imatinib-resistant chronic-\nThese mutations are being targeted by novel TK\ninhibitors that have a different conformation than\nDasatinib (Sprycel) .\nNewer drugs for imatinib\nDasatinib is approved by the FDA at a dose of\n100 mg/day for the treatment of all stages of CML\nwith resistance or intolerance to prior therapy,\nNilotinib is approved by the FDA at a dose of 400\nmg twice daily for the treatment of chronic- and\naccelerated-phase CML with resistance or\nintolerance to prior therapy, including imatinib.\nBoth are oral agents, Dasatinib causes pleural\neffusions in 22% of patients.\nOmacetaxine ,Sorafenib, Bosutinib ,Ponatinib\nAllogeneic HSCT is complicated by early mortality\nowing to the transplant procedure.\nOutcome of HSCT depends on multiple factors,\n(1) the patient (e.g., age and phase of disease);\n(2) the type of donor [e.g., syngeneic\n(monozygotic twins) or HLA-compatible\nallogeneic, related or unrelated];\n(3) the preparative regimen (myeloablative or\n(4) GVHD; and\n(5) posttransplantation treatment.\nInitial management of patients with chemotherapy is\ncurrently reserved for rapid lowering of WBCs,\nreduction of symptoms, and reversal of symptomatic\n. Hydroxyurea, a ribonucleotide reductase inhibitor,\ninduces rapid disease control. The initial dose is 1–4\ng/d; the dose should be halved with each 50%\nreduction of the leukocyte count\nBusulphan, an alkylating agent that acts on early\nprogenitor cells, has a more prolonged effect.\nHowever, its not recommend its use because of its\nserious side effects, which include\nunexpected, and occasionally fatal, myelosuppression\nin 5–10% of patients; pulmonary, endocardial, and\nmarrow fibrosis; and an Addison-like wasting\nLeukapheresis and Splenectomy\nIntensive leukapheresis may control the blood counts\nin chronic-phase CML;\nIt is useful in emergencies where leukostasis-related\ncomplications such as pulmonary failure or\ncerebrovascular accidents are likely.\nIt may also have a role in the treatment of pregnant\nwomen, in whom it is important to avoid potentially\nSplenectomy was used in CML in the past because of\nthe suggestion that evolution to the acute phase might\noccur in the spleen.\nsplenectomy is now reserved for symptomatic relief of\npainful splenomegaly unresponsive to imatinib or\nchemotherapy, or for significant anemia or\nthrombocytopenia associated with hypersplenism.\nSplenic radiation is used rarely to reduce the size of\nTreatment of Blast Crisis\nTreatments for primary blast crisis, including imatinib,\nare generally ineffective.\nOnly 52% of patients treated with imatinib achieved\nhematologic remission and the median overall\nsurvival was 6.6 months.\nPatients who achieve complete hematologic\nremission or whose disease returns to a second\nchronic phase should be considered for allogeneic\nOther approaches include induction chemotherapy\ntailored to the phenotype of the blast cell followed by\nTK inhibitors, with or without additional chemotherapy\nBlast crisis following initial therapy with imatinib\ncarries a dismal prognosis even if treated with\nHarrison’s 18th edition\nNational comprehensive cancer network\nClinical manual of oncology']"	['<urn:uuid:98c03acc-f5e9-4b34-8b4b-5486813e5fbe>', '<urn:uuid:c0c86c91-7e51-43c2-94ef-8840cccd4b6a>']	factoid	with-premise	concise-and-natural	similar-to-document	comparison	expert	2025-05-01T23:21:14.341336	12	44	3134
317	What's good about eating farmed mussels?	Farmed mussels are beneficial both for health and the environment. A 3-oz. serving contains 700 mg of omega-3s, and they improve water quality by feeding on natural nutrients and algae. They also act as natural reefs that attract and provide food for other fish. However, raw shellfish from warm waters may contain harmful bacteria.	"[""Seafood Watch, the program run by the Monterey Bay Aquarium, has updated their “Super Green: Best of the Best” list of seafood that’s good for you and good for the environment. To read an updated blog post on healthy seafood, click here.\nEven though I keep up with the news on fish and health, I still get confused when it comes to buying seafood. Between worrying about contaminants like mercury and chemicals such as PCBs that I should avoid, wanting to get enough of the healthy omega-3 fats that are good for my heart and brain, and feeling like I should make an environmentally friendly choice, I have a hard time figuring out which fish is OK to eat given all my concerns. (What’s in your fish? Is it toxic?)\nSo I’ve stopped guessing at the fish counter. I just stick to these 6 fish and shellfish, identified as the “Best of the Best” when it comes to seafood that’s good for you and good for the environment by Seafood Watch, a program of the Monterey Bay Aquarium. (And I avoid these 6 fish: bluefin tuna, Chilean sea bass (aka Patagonian toothfish), groupers, monkfish, orange roughy and farmed salmon because they carry high levels of mercury and PCBs and their populations are depleted. Find out more here.)\nTo make this “Super Green” list, fish must: a) have low levels of contaminants—below 216 parts per billion [ppb] mercury and 11 ppb PCBs; b) be high in omega-3s; and c) come from a sustainable fishery. Many other options are on the program’s list of “Best Choices” (seafoodwatch.org). The Blue Ocean Institute (blueocean.org) also has sustainability ratings and detailed information.\n1. Salmon (wild-caught, Alaska)\n(Find a recipe for Blackened Salmon Sandwich and 20+ more easy, healthy salmon recipes here.)\nTo give you an idea of how well managed Alaska’s salmon fishery is, consider this: biologists are posted at river mouths to count how many wild fish return to spawn. If the numbers begin to dwindle, the fishery is closed before it reaches its limits, as was done recently with some Chinook fisheries. This close monitoring, along with strict quotas and careful management of water quality, means Alaska’s wild-caught salmon are both healthier (they pack 950 mg of omega-3s and carry few contaminants) and more sustainable than just about any other salmon fishery.\n2. Pink Shrimp (wild-caught, Oregon) & Spot Prawns (wild-caught, British Columbia)\n(Get the recipe for Emeril Lagasse's Shimp Ceviche and dozens more delicious, healthy shrimp recipes here.)\nMost shrimp are plentiful and reproduce quickly. But whether they are sustainably farmed and harvested is the big question. In an effort to reduce the by-catch caused by netting and prevent ocean floors from being scraped clean by dragging, the U.S. has strict regulations on farming and trawling. The best choices are wild-caught MSC-certified pink shrimp (aka cocktail shrimp) from Oregon or their larger sisters, spot prawns, also from the Pacific Northwest, which are caught by traps. Avoid: imported shrimp, farmed or wild.\n3. Mussels & Oysters (farmed)\n(Get recipes for Steamed Mussels in Tomato Broth and more healthy seafood recipes here.)\nFarmed mussels and oysters are good for you (a 3-oz. serving of mussels contains 700 mg of omega-3s and oysters pack 44 percent of the recommended daily values of iron). Better yet, they are actually good for the environment. Both feed off the natural nutrients and algae in the water, which improves water quality. They can also act as natural reefs, attracting and providing food for other fish. One health caveat: Raw shellfish, especially those from warm waters, may contain bacteria that can cause illnesses.\n4. Sardines, Pacific (wild-caught)\nThe tiny, inexpensive sardine is making it onto many lists of superfoods and for good reason. It packs more omega-3s (1,950 mg!) per 3-oz. serving than salmon, tuna or just about any other food; it’s also one of the very, very few foods that’s naturally high in vitamin D. Many fish in the herring family are commonly called sardines. Quick to reproduce, Pacific sardines have rebounded from both overfishing and a natural collapse in the 1940s.\n5. Rainbow Trout (farmed)\nThough lake trout are high in contaminants, nearly all the trout you will find in the market is rainbow trout. In the U.S., rainbow trout are farmed primarily in freshwater ponds and “raceways” where they are more protected from contaminants and fed a fishmeal diet that has been fine-tuned to conserve resources.\n6. Albacore Tuna (troll-or pole-caught, from the U.S. or British Columbia)\nMany tuna are high in mercury but albacore tuna—the kind of white tuna that’s commonly canned—gets a Super Green rating as long as (and this is the clincher) it is “troll- or pole-caught” in the U.S. or British Columbia. The reason: smaller (usually less than 20 pounds), younger fish are typically caught this way (as opposed to the larger fish caught on longlines). These fish have much lower mercury and contaminant ratings and those caught in colder northern waters often have higher omega-3 counts. The challenge: you need to do your homework to know how your fish was caught or look for the Marine Stewardship Council (MSC) blue eco label. Pregnant women and young children should consider chunk light tuna instead; it’s lower in mercury.\nTell us what you think:\nConnect With Us\nPoll of the week\n- Skillet Gnocchi with Chard & White Beans (189 comments)\n- Chilaquiles Casserole (103 comments)\n- Hamburger Buddy (100 comments)\n- Bev's Chocolate Chip Cookies (87 comments)\n- Balsamic & Parmesan Roasted Cauliflower (74 comments)\n- Easy Salmon Cakes (73 comments)\n- Broccoli-Cheese Chowder (72 comments)\n- Mini Mushroom-&-Sausage Quiches (63 comments)\n- Sauteed Chicken Breasts with Creamy Chive Sauce (58 comments)\n- Beef & Bean Chile Verde (52 comments)""]"	['<urn:uuid:e37a6c10-1146-4062-ba57-fc0e7d8eca82>']	factoid	with-premise	concise-and-natural	distant-from-document	single-doc	novice	2025-05-01T23:21:14.341336	6	54	957
318	Which famous Shakespeare plays featured iconic monologues or speeches?	Several of Shakespeare's most famous plays featured notable speeches - Hamlet contained the famous 'To be, or not to be' monologue, while plays like Macbeth and Romeo and Juliet also featured powerful monologues. Macbeth and Hamlet in particular are considered among Shakespeare's greatest tragedies produced in the early 1600s.	"['Nordisk musikkpedagogisk forskning Årbok 16 - NMH Brage\nFrom the play ""When Mel Fell for Nell"" ISBN-13: 978-1512007183 Buy a low cost PDF of ""When Mel Fell for Nell"" at Sellfy.com. MEL 2021-04-09 2020-12-02 A monologue from the play by William Shakespeare. HAMLET: To be, or not to be--that is the question: Whether \'tis nobler in the mind to suffer The slings and arrows of outrageous fortune Or to take arms against a sea of troubles And by opposing end them. To die, to sleep-- What does monologues mean? Plural form of monologue. (noun) 2020-11-08 Lana Del Rey - Ride Monologue Lyrics.\nAn example of a monologue is the speech by Hamlet in Shakespeare\'s play. noun 2020-09-18 · Literally speaking, executing a monologue within a screenplay is as simple as it being a long passage of text on the page. However, pacing is crucial to the monologue coming off convincingly. An ill-timed monologue, one coming seemingly out of nowhere, can really throw off the pacing and flow of a scene. Each monologue entry includes the character\'s name, the first line of the speech, whether it is verse or prose, and shows the act, scene & line number. Each entry provides a link to the full text of the scene. 2021-04-09 · A monologue is a long speech which is spoken by one person as an entertainment, or as part of an entertainment such as a play.\nKontextbaserad undervisning i naturvetenskap Elevers\nThis text forms the basis of the exhibition which highlights the fictional Insects works as a metaphor for the unfathomable and as tools for the search of meaning. by the sounds that are played between the paragraphs of the monologue.\nCiigoo Afaan Oromoo Idioms – Appar på Google Play\nin turn are different from those used for slang expressions. time line, comes from a monologue in which a signer talked about a conference. av J Dahlin · 2014 — handling—as Godard says, “Womanhandling the text in translation would monologue, and he therefore concludes that ejaculation is a av SB Arnolds-Granlund · 2009 · Citerat av 9 — In the intertextuality as these texts meet new meaning will appear.\nWhen someone takes an audio or video recording of an important conversation or speech and converts it into usable text, that\'s transcription. A transcript is a word-\nWhen to Use Soliloquy. definition of soliloquy definition of monologue definition What does soliloquy mean? A soliloquy is one person speaking for an extended\nFeb 29, 2020 A monologue is a speech given by one person to express his or her thoughts aloud. This speech will have one or more listeners, and it will be a\nMonologue tips from Guildford School of Acting audition panellist Joe you\'d look for something in your accent, that reflects your context - that doesn\'t mean you\nDetta innebär att allting berättas som ett textflöde utifrån den enskilda individens perspektiv. Tekniken kan också leda till tvära kast i tiden, där till exempel ett\nav C Gehrmann · 2011 · Citerat av 5 — Mode refers also to what House calls \'participation\', and according to her definition this text would be complex, i. e., a monologue with built-in fictional dialogic\nav LB Karlsson · 2007 · Citerat av 5 — Data consist of talks in focus groups and of written autobiographical texts.\nCuben fiber tent\nA soliloquy ( q.v.) is a type of monologue in which a character directly addresses an audience or speaks his thoughts aloud A literary composition in monologue form. 2. A continuous series of jokes or comic stories delivered by one comedian. 3. A long speech made by one person, often monopolizing a conversation. v.\nalso mon·o·log n. 1. a. A lengthy, uninterrupted speech by a single character, as in a play or novel. b. Text; A; A; A; A; Language: Share on Facebook Twitter\nWhat does MONOLOGUE mean? MONOLOGUE meaning - MONOLOGUE pronunciation - MONOLOGUE definition - MO http://www.theaudiopedia.com What is MONOLOGUE?\nMasterprogram sociologi göteborg\nThe double meaning that lies at the heart of the dramatic monologue, A dramatic monologue, whether on stage or in a poem or story, can perfectly be quite in scare-quotes (meaning ""that which Shelley is putting himself forward as""), We\'d have a completely different poem -- one that, on These strategies include comprehending and analyzing messages for implicit and explicit meaning, identifying linguistic and cultural challenges in the text, and We are not allowed to display external PDFs yet. You will be redirected to the full text document in the repository in a few seconds, if not click here. Sep 2, 2009 Text analysis is a method of interpretation that relies on the meaning and to a certain extent the rhythm of any given block of text. In brief, you Direct interior monologue (also known as quoted interior monologue) is in short bursts, particularly when your thoughts differ to the surrounding text in tense or Jul 11, 2019 When heard reading aloud, Tuwhare performed this monologue in the enough to the doors that if the worst happens – meaning he gets laid Dec 26, 2019 Selected by Dr Oliver Tearle The dramatic monologue is a literary form that really came of age in the 1830s, thanks to Tennyson and Browning Analyzing an author\'s style involves understanding the particular way a text is written.\nNot sure the difference between the two?\nOffentliga jobb enköping\nDialogue Behavior Management in - CiteSeerX\nAccording to PC.net, there are several meanings behind this acronym. The primary meaning is ""Same old stuff."" This is a common reply to questions such a A monologue is a speech or composition presenting the words or thoughts of a single character in a work, either spoken or written. Robert R McElroy / Getty Images A monologue is a speech or composition presenting the words or thoughts of a Are you a leetspeak expert? Do you often abbreviate what you type? Have you ever said your ROLFing or referred to your BFF? If you know what all those terms mean, test your texting abbreviation knowledge with this quiz!\nOla wong fru\n- Andis master clippers\n- Svanen förskola blogg\n- Vad händer i hjärnan vid en hjärnskakning\n- Medicinteknik jobb uppsala\n- Hemnet arvika kommun\n- Jysk sodertalje\n- Vodka flaska pris\n- Bostadspriserna sjunker\n- Windows 10 high performance mode\nnarrow-mindedness - Swedish translation – Linguee\n• Context dialogues resulted in 2684 utterances with a mean of 112 utterances per dialogue.\nJimmy Kimmel - Jimmy Kimmel\'s Quarantine Monologue\nKeep reading for monologue examples from works of literature and film in which characters express their thoughts and emotions. noun a form of dramatic entertainment, comedic solo, or the like by a single speaker: a comedian\'s monologue. a prolonged talk or discourse by a single speaker, especially one dominating or monopolizing a conversation. any composition, as a poem, in which a single person speaks alone. 1660s, ""long speech by one person, scene in a drama in which a person speaks by himself,"" from French monologue, from Late Greek monologos ""speaking alone or to oneself,"" from Greek monos ""single, alone"" (from PIE root *men- (4) ""small, isolated"") + logos ""speech, word,"" from legein ""to speak,"" from PIE root *leg- (1) ""to collect, gather,"" with derivatives meaning ""to speak (to \'pick out words\')."" What Is a Monologue? A monologue is a long speech by a single character in a theatre production or film.\nA complete database of Shakespeare\'s Monologues. The monologues are organized by play, then categorized by comedy, history and tragedy. You can browse and/or search so you can find a monologue whether you know which one you want, or you\'re looking for monologue ideas.', ""visión de conjunto:Reseña del editor Three powerful radio productions from the BBC archives starring Ian McKellen Ronald Pickup and Paul Scofield and a host of celebrated acting talent . These three legendary plays performed by some of the best-known theatrical actors of the 20th Century are the perfect way to commemorate England's greatest dramatist. Romeo and Juliet: The Montagues and the Capulets are sworn enemies so when Romeo Montague falls in love with Juliet Capulet tragedy ensues. This fateful tale of two young star-crossed lovers isone of Shakespeare's most popular dramas. First broadcast in 1970 starring Ian McKellen as Romeo. Hamlet: One of the most powerful influential and thrilling tragedies in the English language and the story of Prince Hamlet and his quest for vengeance never fails to enthral. First broadcast in 1971 starring Ronald Pickup as the Prince of Denmark. Macbeth: The notorious 'Scottish Play' is a gripping tale of vaulting ambition witchcraft madness and murder that has kept generations of audiences spellbound. First broadcast in 1966starring Paul Scofield as Macbeth and Peggy Ashcroft as Lady Macbeth. Recorded at BBC Broadcasting House and featuring the BBC Drama Repertory company with specially composed music including a score from the BBC Radiophonic Workshop this is classic radio drama at its finest. Duration: 7 hours 30 mins approx. Biografía del autor William Shakespeare was born in Stratford-upon-Avon in Warwickshire and was baptised on 26 April 1564. His father was a glove maker and wool merchant and his mother Mary Arden was the daughter of a well-to-do local land owner. Shakespeare was probably educated in Stratford's grammar school. In 1582 he married Anne Hathaway and the couple had a daughter the following year and twins in 1585. Shakespeare's theatrical life seems to have commenced around 1590. We do know that he was part of the Lord Chamberlain's Company which was renamed the King's Company in 1603 when James I succeeded to the throne. The Company acquired interests in two theatres in the Southwark area of London near the banks of the Thames - the Globe and the Blackfriars. Shakespeare's poetry was published before his plays with two poems appearing in 1593 and 1594 dedicated to his patron Henry Wriothesley Earl of Southampton. Most of Shakespeare's sonnets were probably written at this time as well. Records of Shakespeare's plays begin to appear in 1594 and he produced roughly two a year until around 1611. His earliest plays include Henry VI and Titus Andronicus. A Midsummer Night's Dream The Merchant of Venice and Richard II all date from the mid to late 1590s. Some of his most famous tragedies were written in the early 1600s; these include Hamlet Othello King Lear Macbeth and Antony & Cleopatra. His late plays often known as the Romances date from 1608 onwards and include The Tempest. Shakespeare died on 23 April 1616 and was buried in Holy Trinity Church in Stratford. The first collected edition of his works was published in 1623 and is known as 'the First Folio'.""]"	['<urn:uuid:ffabe4ef-088d-48ec-8cb7-efb68bc4a144>', '<urn:uuid:5af2bdab-338f-4136-9f50-f91e201193f8>']	open-ended	direct	concise-and-natural	similar-to-document	comparison	novice	2025-05-01T23:21:14.341336	9	49	1772
319	Between Foster's Beijing airport and Creative Group's Goa terminal, which has the bolder roof design?	Foster & Partners' Beijing airport has a more ambitious roof design, being the world's biggest building under one roof when completed in 2008. In comparison, Goa's terminal features a simpler semi-circular design with a half arch and steel portal frames, though it does incorporate an iconic wave-like solid roof with skylights.	['Listen to this article\nAt a press conference earlier this year, listening to architect Luis Vidal talk about his design for Heathrow’s new £2.5bn Terminal 2, I heard the word “destination” and my nerves began to jangle. Vidal suggested that this was a new generation of airport, that this was a “gathering place”, a “piazza”, a place people would want to come to whether they were flying or not. He compared the amount of retail space with Covent Garden. By now my teeth were grinding and I wanted to scream: who the hell wants to spend any more time in an airport than they have to?\nBy the following day I’d calmed down. After all, I thought, airport architects face an invidious conundrum. They are designing a building type that, like a prison, no matter how luxuriously appointed, everyone wants to escape as soon as possible.\nAs long ago as the 1960s, the French cultural theorist Paul Virilio suggested that the airport concourse would replace the city square as the fundamental site of urban and international interchange. It hasn’t. Few meetings take place in airports. Instead people flying in for even a few hours make great efforts to get away from them – even if it entails hours in traffic or an anonymous airport hotel. People dislike being in airports. And the more they travel, the more they dislike them.\nWhich gives everyone designing one a problem. All the carefully wrought metaphors of wings and flight, the great curving roofs mirroring the landscape, the views of planes and sky and the intuitive way-finding don’t really matter because, ultimately, they all end up feeling pretty much the same anyway.\nPartly this disillusion with the airport as a building type is due to the rapid transformation of flight over the past half-century from exotic treat to everyday annoyance – airports are victims of their own success. A big chunk of the problem is the process of being processed, the small humiliations of exposing your toiletries, of standing beltless in your socks being patted down, the queues, the nagging fear of missing your flight, the overpriced, overfamiliar products in shops which can only survive because they have a captive market comforted by the soothingly familiar act of consumption.\nPartly, though, it is also due to the increasingly ubiquitous architectural language which effectively disorients us, desensitising us to where we are. And that is something that architects could control. There is an assumption that glass walls, soaring roofs, stainless steel details and terrazzo floors are the de facto finish for the modern airport. But are they? Why? Why do airports need to look like malls?\nThe question, then, is what should architects do? Should they just design the most functional, well-engineered spaces possible? Should they attempt to design impressive gateways embodying national pride? Or should they be doing something else entirely?\nA slew of airport openings and newly commissioned designs should allow us to take the temperature of the genre, to detect emerging trends.\nOne rather elegant type is what we might call “airport orientalism”. Just as it was in art, orientalism is chiefly an invention of the Occident (pace Edward Said) and mostly then the British, who have managed an incredible dominance of international airport design. Leading that charge is London-based architectural practice Foster & Partners, which started with Stansted, in Essex, and ended with world domination – almost. Its Beijing international airport in particular is an extraordinary structure. When it was completed in 2008, it was the world’s biggest building under one roof.\nLast year the firm completed Jordan’s lovely Queen Alia airport, a cool space beneath a roofscape of domed parasols, a space somehow simultaneously shaded and perfectly naturally lit. The same architects’ designs for Kuwait international airport feature elegant concrete vaults, a blend of Grand Central Station’s Roman arches, a Middle Eastern bazaar and Eero Saarinen’s expressionist concrete at JFK’s 1960s TWA terminal.\nAnother British architect, Sir Nicholas Grimshaw, recently released designs for Istanbul’s new six-runway airport (due to open in 2018 and destined to be the world’s largest terminal under one roof). Here, slender concrete columns support a series of filigree vaults, vaguely Islamic and very elegant.\nGrimshaw has also designed the delicate golden origami roofs of St Petersburg’s Pulkovo airport which opened earlier this year; glittering oligarch bling toned down – just enough.\nAlongside airport orientalism is the space age, another emerging oeuvre (taking its cue from a 1960s techno-futurism). On top of the heap is Italian architect Massimiliano Fuksas’s astonishing Shenzhen Bao’an airport. A set of perforated tubes, the structure creates a mind-bending landscape, something strikingly unfamiliar. Skidmore, Owings & Merrill’s new sci-fi Terminal 2 at Mumbai’s Chhatrapati Shivaji international airport, with its Mughal mushroom columns and waffle roof, does something similar, if a little more conventionally.\nPossibly most impressive of all, however, is the weird and wonderful world of Georgia’s aesthetically integrated transport infrastructure. Here almost the whole caboodle has been entrusted to German architect J Mayer H. Everything from border crossings to motorway service stations have been turned into opportunities for audacious national branding. Mestia’s Queen Tamar airport might be a tiddler, with its terminal building bent upwards like a paper clip to create a viewing tower, but it is also a symbol of a country that is using airports – and everything else it builds – to signal an identity.\nDutch architect UNStudio was also brought in and its design for the red-and-white Kutaisi international airport, with its folded planes and bulging fractal ceiling, is anything but conventional.\nPerhaps the most intriguing recent airport story has been about Berlin’s disused Tempelhof, which had become so beloved in its overgrown state that plans to redevelop it were thrown out and its runways will now be turned into a public park.\nFirst built in 1923 and rebuilt in its present form by the Nazis in 1934, it is a rare survivor of the era. Designed in the shape of an eagle (already a heavy piece of symbolism), Tempelhof has a fiercely charged history, as the site of the 1948 Berlin airlift. Its form is that cold yet also rather elegant blend of art deco, modernism and classicism that characterised the Nazi era, a cocktail of limestone, marble and brass. A huge curving canopy sweeps passengers in (this is Foster’s favourite airport and he copied this gesture in Beijing). It had the mass, articulation and permanence of a city station, a place always alive and as solid as the city itself, of which it was determinedly a part.\nThis old-fashioned airport was, despite its history, hugely popular. Why? In part because it was merely a few minutes from the city centre, so the building felt part of the urban fabric. But it was also that its architecture gave it a scale related to the city, and its materials reassured with their familiarity and a sense of calm (if rather formal) permanence. It was the architecture of the museum and not the mall, a place that reassured and inculcated a sense of place, which allowed travellers to locate themselves somewhere specific (albeit many travellers might not want to locate themselves in Nazi Germany). Only a handful of other airports have done something similar as successfully, such as Budapest’s now-defunct Ferihegy 1 and Copenhagen’s beautiful timber-encased airport.\nIn the 1930s there were all kinds of proposals for city-centre airports. One was proposed over London’s King’s Cross station and it was envisaged that airships would dock on the crowns of New York skyscrapers. Now it seems that airports will never return to the city centre (though cities are growing outwards to meet them).\nPerhaps, however, architects, engineers and airport authorities need to stop thinking in the language of the generic and instead build airports as if they were embedded elements of the metropolis, as grand and solid as the stations once were, buildings scaled to city streets and civic architecture rather than to the blank expanse of runways or to the mega-malls they increasingly resemble.\nEdwin Heathcote is the FT’s architecture critic\nWhere waiting for a flight is fun\nSauna From August, passengers at Helsinki airport will be able to enjoy a classically Finnish treat while waiting to leave the country, writes Kasia Delgado. Finnair is due to open a unisex sauna in its new business class lounge, as well as private showers. Although Finns traditionally go nude, towels are provided, along with Finnish forest berry-based shampoos and lotions. Other airlines’ passengers can pay €48 to use the sauna.\nGolf Seoul’s Incheon airport has an 18-hole golf course five minutes away – a free shuttle bus connects it to the terminal. But for those in a hurry, there’s also a “golf town” within the airport boundaries, offering a 330-yard driving range and 18-hole putting course. Hong Kong International also has a nine-hole course between Terminal 2 and the Marriott airport hotel. Hole seven of the Nine Eagles course even features a green on an island in a man-made lake.\nSwimming Numerous airport-perimeter hotels offer pools, and there’s one inside the airside G-Force health club at Dubai International, but Singapore’s Changi airport is in a different league. It boasts a Balinese-themed pool on the roof of Terminal 1, with a whirlpool, cabana beds, a poolside bar and views over the apron. Entry costs S$13.91 (£6.50).\nArt Airports often feature work by local artists, but Amsterdam’s Schiphol offers a rather more highbrow take, with an airside offshoot of the city’s celebrated Rijksmuseum. It is currently closed as the airport is refurbished but an improved version is due to reopen next year. Meanwhile Terminal 2E at Paris’s Charles de Gaulle airport has an Espace Musées which displays a revolving collection from some of the city’s best galleries and museums. It is currently showing 17th-century tapestries and furniture. Both are free.\nIce skating For those who still have energy left after their round of golf, Seoul’s Incheon airport also offers the Ice Forest skating rink. Skate hire costs Won4,000 (£2.30).\nPhotographs: Corbis; LHR Airports Limited; Getty; Nigel Young; Nakanimamasakhlisi; AFP; Reuters; Robert Polidori; Nakanimamasakhlisi; Nigel Young; Marcus Buck; AFP; Yuri Molodkovets; LHR Airports Ltd\nGet alerts on Travel when a new story is published', 'Modern and Bold Designs of Airports in India\nDesigning an airport is a complex task – while symbolically the designs need to embody the city’s and country’s identity by acting as the first and last handshake; the key factors of the sensitive nature and security concerns of airports also have to painstakingly taken in consideration in the designs. In recent times with terror attacks hounding the country, Airport designing has become all the more critical and vital.\nAirport designing for any city also leads to the enhancement and development of the city, what with metro links/stations and retail centres planned around them. Sites for such projects have to bear in mind the proximity to existing highways, to possess a location away from the hub of the city due to security factors and the availability of such a huge expanse of land. With the escalating air traffic in India, a number of airports are looking to expand or set up new terminals to accommodate the growing number of passengers. A look at the new modern and bold forms of airports with imposing roof structures and you realise that India’s coming of age.\nDelhi based Architect Charanjit S Shah apart from adorning the very famous hat of being the creator of ‘The Indian Time Savers Standard’ has been credited with highly acclaimed architectural projects practiced under his 41 years old firm Creative Group. The firm takes a special interest in green initiatives in architecture and works on diverse projects related to Architecture, Planning, Urban Design, Structural Design, Interiors, Project Management & Valuation. The firm has won a lot of design competitions, four of them being major airports of India – Chennai, Goa, Vadodara and Raipur. Prof Shah, a widely travelled architect while admitting that Modern Airport Designs in India imitate the western world designs, cites his favourite approach to airport designing as ‘transparency and a simplistic approach for proper functionality of the building’.\nCreative Group collaborates with New York based Frederic Schwartz & Associates as the global partner for all their Joint venture projects and the Chennai and Vadodara airport projects have been the outcome of their collaborations along with Gensler – a global architecture, design, planning and consulting firm.\nOn airport designing Prof Shah adds, “Besides aesthetics, it is thefunctionality of the building which is very important and involves the proper segregation of visitors, passengers and the baggage system. As one has to stay for a longer period in hold areas, queuing immigration and check in areas, proper care is desired for providing good visual effect within the building. Minimizing heat gain and maximizing day light through passive strategies of good planning should be emphasized while designing Airport Terminal Buildings.”\nOn design constraints he mentions the redevelopment of such airports on the existing premises and the limitation of site areas available on city side developments as challenges. Lighting forms an important part of such projects as besides the day factor, it is the night illumination which is of utmost importance too. In these following airports, the architect has used a combination of local and international light fixtures which besides optimizing the count of the fixtures also increase the illumination outputs. “Lighting typology and patterns have been carefully selected to define different public spaces without any physical segregation. Even though it is a wide known fact that the terminals by virtue oftheir nature are energy guzzlers, but with due diligence the lighting power load has been kept to 1W/sqft in most of the areas,” informs Architect Shah. This has been done by using CFL’s andT5 in all the areas and metal halides in combination with CFL’s for high ceiling areas.\nWhile designing airports, one has to understand that the design needs to be in regional as well as global context- a challenging combination to conceive and execute. The mantra definitely is to think globally and to act locally. Discourses still exist to which Prof Shah explains, “In today’s global context and keeping in the overall international trend of Airport Planning, modern large span steel structures have overshadowed the ethnic/ heritage buildings. Heritage does play a vital role and goes with the overall vocabulary of the city development but technological advancement has overpowered it. Contemporary designs are well suited and are in line with public’s aspirations.” Admirably, in all the airports that Creative Group are designing, while elements have been taken out of the regional character of the cities, the execution and technology adapted produce the outcome fitting for the global context.\nNo doubt, Chennai is the most enthusiastic city in India when it comes to practicing green architecture. In the same line, the Chennai airport is going to be the first green airport in the world. The brief of the design in Phase 1 included a domestic terminal, extension of the existing international terminal and associated departure flyover. Phase 2 will include face-lifting of existing terminals, multilevel car park, metro stations and city side development.\n|ARIAL VIEW of Chennai domestic terminal|\nA 1700sqm central green spine comprising two green courtyards acts as the fulcrum around which the H shaped domestic terminal building evolves. Divided into two halves, the first half of the building is into the landside while the other half is into airside programmed operations related spaces (connected with a central security checkpoint for departure), and has two elliptical glass tubes on either side of the building for arriving passengers (which will connect the landside with the airside operations though the Central Courtyard).\nThe beautiful landscaping of the courtyards with tall palm groves, colourful indigenous plantings, shallow pools and vertical garden infuses freshness into the building inducing an exterior-interior dialogue. The airport is the first in the world to have gardens visible throughout the terminals. The terminal has a dramatic hovering wing like roof in tubular steel truss (37m high and 30m wide) with a cantilever of 24m – the largest in any airport building previously. The 260m long column free structure revelling in the glass curtain walls and skylights add to the spaciousness. A precast elevated departure flyover is supported on 76 ‘V’ columns and visually demarcates the departure lounge on the upper level from the arrival lounge on the lower level.\nThis sustainable green airport called for an extensive research of materials. The parking area is totally devoid of hard surface which has 95% of water runoff and no percolation. Use of Green pavers (Polypropylene Pavers) with over 90% porosity recharges the ground water that is the cause of immense concern, with water table dropping every year. Bricks have been replaced with AAC blocks (Aerated Autoclaved Concrete Blocks) which ensure thermal insulation. Sustainability aspects further include restoration of the native landscape, passive energy conservation strategies, material selection, onsite storm water detention, on site waste water treatment and dispersal systems. A parking garage with a green roof will create what the designers describe as a “green gate” to the terminal.\nAmongst other unique features are a vertical garden (a stainless steel structure lattice providing support for hanging plantings with vibrantly coloured lush vegetation) which will be visible in the inner green spine while passing through the arrival glass tube.\nThe Creative Group was awarded the Goa Integrated Terminal Building at Dabolim which they like to term as ‘The Wave’ that thematically denotes the ‘aspirations of a nation which is quickly becoming a technological and economic giant in the global platform’. Simultaneously, it represents the freedom that Goa is basking in, in being a global tourist hub. ‘The Wave’ is also emblematic of ecstasy – the ecstasy which no individual visiting Goa can miss. Eventually, it represents the city known for its sea and beaches and also symbolises the site location that is surrounded by sea on one side.\nWith Goa being a favourite tourist hub, the challenge was to have an airport building catering to various needs including chartered and civil flights, which was overcome by making the terminal flexible in terms of integration of both international and domestic passengers.\nThe form has been derived from a circle where the terminal forms a semi-circle resting on ground with a half arch emerging from one end of the semi-circle. With a bold, sleek, transparent and iconic form, the design of the airport successfully captures the vibrancy of the Goan spirit. Steel portal frames constituting the basic building envelope (leading to column free interior spaces) convey a bold look. The long curved glass facades (of a specially made double glass unit providing thermal and sound insulation with a protective blue tinge film reflecting the water proximity) and a free flowing form of solid roof (with skylights) resembling a wave make the structure iconic. A large overhang covering the kerb achieves natural light through the sun breaking louvers.\nThe vibrant interiors include specially designed types of glasses, back lit double height feature walls near the escalators and staircase (aiding in directing the vertical flow of passengers), texture granite stone flooring, wall hangings and sculptures (representing the Goan flavour) and wall cladding of Compact Laminated panels (a recyclable green material).\nTo fight the limited scope of expansion, the terminal has been designed to accommodate maximum built up area for limited ground coverage by introducing more floor slabs in the same volume, making it economically more efficient. Also through the planning of service equipment in the basement and their cooling towers and AHU’s on the open-to-sky mezzanine, saving of space has been done on the main floors. The multi-level parking has been accommodated in the basement.\nA new integrated terminal building has been conceived to aid the handling of passengers and introduce international services with a challenge posed of bringing art into the functionality of the terminal building.\nVadodara having been developed as an industrial hub with the development of automobile, engineering, chemical and other industries, its airport needed to be an ultra modern structure. The airport responds with a single arching, sweeping roof sheltering the North and South sides through 18 m overhangs while wrapping around the east and west side. The archway corresponding to an aerodynamic roof with circular skylights brings in much light apart from that received through the curtain walls on the North and South facades. From a distance, the building is visually nothing short of an ‘aerodynamic volume’ rising above the landscape. The RCC framed structure of the Terminal Building has steel tubular trusses covered with self-supported concealed Galvanized Metal Sheeting standing-seam double skin roofing systems with acoustical treatment and thermal insulation to meet as close to GRIHA/ECBC requirements on noise and echo reduction.\n|View of the Vadodara Airport|\nThe terminal sticks to its green features with ample natural ventilation, a careful implementation of materials in compliance with the ECBC code (AAC blocks, flat seam metal panels concealing the east-west facades, interior finishes of GFRC panels etc).\nThe sub surface car parking for 250 cars enjoys complete view of the terminal from the roadway system. On one hand while the airside and landscape spaces are clearly demarcated, the terminal is connected visually around the central zone in the absence of any partitions. Proper planning has been made to avoid mingling of the domestic and international travellers.\n|Dates of Commencement of Construction|\n|Date of Completion|\n|Chennai||–||Dec 2011 (domestic terminal); Sep 2012\n(International and City Side development)\n|Built Up Areas|\n104.000sqm (Multi Level Car Parking)\nThe emphasis in this integrated passenger terminal for Raipur was not only on the airport’s iconic form, but also in the space modulated to conform to the needs of the passengers to make them most comfortable.\nAn indigenous design with a 3-Dimensional curvilinear roof consisting of 12 trusses (supported by steel ‘tree columns’ with flaring arms) with skylights brings about a floating effect. The organic form has a sliced dome at the centre (that maximises the daylight and emits light at night) and multiple wings elevating the roof profile. The form is akin to a bird set to take off with its wing raised high while the rear side (airside) design is inspired from a spaceship. Looking at such structures one wants to thank technology for the advancement it has got in today’s designs. Giving it full credit Architect Shah avers that being an important tool for all advancement and innovations, with adequate know-how and proper understanding oflatest technology, the variety of usages can be adopted to achieve the best of results in terms of properutilization of materials.\nThe aesthetics of the interiors have been intelligently dealt with. Circular stainless steel columns in the volumetric arrival and departure lounges have props in the upper end that serve as architectural and structural elements of expression. Care has been taken to combine services with the aesthetic elements of the building. For example, these columns serve in integrating the vertical AHU system. Indoor landscape courtyards and water bodies provide relief while the strategic planning of mounds and contours camouflage the ongoing traffic movement.\nWith building services aptly planned in the underground trenches, the building has been made ‘Green’ by incorporating elements of energy conservation, waste water and resource management. Dwelling further on green aspects, Architect Shah adds, “Materials of the building envelope, heat loads, indoor air quality, air conditioning equipment, insulation materials, its wrappings and duct leakage rates are all in conformity with the recommendations of ASHRAE / IES STANDARD 90.1/IECC to minimize the energy demand of the building. All joints in the building, door and window frames, which are potential source of air leakage, have been sealed and the systems have been aimed f\n- Chennai’s Second International Airport (chennaifocus.wordpress.com)\n- Modernized Domestic Airport to Open for Public on April 14 2012 (chennaifocus.wordpress.com)']	['<urn:uuid:93662120-5b1c-4317-812d-9d7b726b6750>', '<urn:uuid:9bde939f-6cf8-453e-8c7e-fc4d7d099550>']	factoid	with-premise	concise-and-natural	distant-from-document	comparison	expert	2025-05-01T23:21:14.341336	15	51	3964
320	I'm new to guns. What exactly does ballistics mean?	Ballistics refers to the science of projectiles - it describes how a round moves, from the initial squeeze of the trigger to when the bullet hits a target. This can apply to anything from a thrown stick to an intercontinental warhead.	['The ballistics of a firearm can refer to multiple processes inside and outside a gun. Overall, it refers to how a round moves, from the initial squeeze of the trigger to when the bullet hits a target.\nThe word “ballistics” is a word we hear often but don’t actually consider its meaning. Referring to the science of projectiles, ballistics can apply to a stick you’ve thrown through the air or an intercontinental warhead carrying a hydrogen bomb.\nA ballistics chart is an instrumental piece of data for any gun owner. If you want to discharge your firearm safely and more effectively, then you should familiarize yourself with the ballistics chart specific to your firearm.\nBelow we’ll cover the key features of ballistics charts to help you better understand your firearm.\nBefore we get to how a bullet actually travels through the air, it is important to note that the ballistics of a firearm begins in the barrel when the gun discharges. Let’s take a Winchester ballistics chart, specifically the .222, as an example.\nA Winchester .222 ballistics chart has varied options for ammunition weight, from 40 to 60 grains. This refers to the amount of powder within each cartridge. The more powder, the greater the pressure within the barrel when the firearm discharges.\nHigher pressure in the barrel means a higher exit velocity. Exit velocity is the speed the bullet is traveling immediately as it leaves the barrel. Since this calculation depends on the type of round and the length of the barrel, it is critical to understand ammunition ballistics and the specs of your firearm.\nA faster moving projectile, therefore, will have a completely different trajectory than one that exits the barrel at a lower speed. As well, the shape and type of round you are discharging, such as hollow point versus soft point, will change the trajectory of the projectile.\nHeaded to the shooting range? Be sure to check out our top picks for gun range bags.\nA rifle ballistics chart outlines how a given round will behave upon discharge from a specific rifle. However, these charts have different numbers and calculations that may seem confusing at a glance. Below is an outline and explanation for each category of a ballistics chart:\n- Velocity – probably the most easily understood spec, this measures the speed of a bullet at certain distances. Measured in feet per second, the speed of a bullet depends on its mass. The greater the mass, the slower the projectile will travel.\n- Energy – this is a vague term that is perhaps the most important stat on a ballistics chart. The energy of a projectile refers to the amount of energy delivered to a target by a bullet. This factor is affected by drag, also known as retardation, the projectile encounters as it moves through the air.\n- Short Range Trajectory – this part of the ballistics chart indicates how high or low you should sight your firearm depending on the distance to the target. Short range trajectories assume you have sighted your gun to zero at a nearer distance, such as 150 meters.\n- Long Range Trajectory – trajectories for targets at further distances are set to zero at a greater distance, such as 200 meters, compared to the short range trajectory.\nExternal Ballistics Explained\nNow that you have a basic understanding of what and why certain information is on a ballistics chart let’s break down further what some of the more complicated terms, such as trajectory and energy, actually mean when firing a weapon.\nEnergy is, in part, the speed of the projectile as it leaves the firearm. However, this speed depends on the length of the barrel, the size of the cartridge, and the shape.\nThe ideal shape for a cartridge is much like those you see today, a parabolic-shaped nose cone with a long, skinny body. Naturally, jamming more powder into a cartridge would increase the energy of a weapon. However, the barrel of a firearm can only withstand certain pressure. Too much powder would result in excess gas in the barrel, and cause injury to the shooter.\nAnother factor, mentioned above, is drag, or retardation. The faster the bullet goes, the more drag. If you look at a ballistics chart for the Winchester .222, it lists rounds from 40 to 60 grains. A 60 grain round has lower energy than a 55-grain round since the round with greater mass is more affected by drag.\nMeasuring the trajectory of a projectile is tricky. The sight of a firearm is typically two inches above the barrel and angled downward, so that the line of sight (LOS) of the shooter meets, at some pre-calibrated point, the path of the projectile.\nAnyone with a sighted rifle will calibrate their site depending on location and target type. If you want to shoot small game at short distances, then you will calibrate your sight to match the zero on the short-range trajectory ballistics chart for your weapon. Using the chart, you can then raise or lower your gain as specified in the chart for the type of ammunition you are using.\nFor longer range trajectory, you will adjust your sight to the distance indicated in the long-range section of your firearm’s ballistics chart. Adjust your aim accordingly depending on the distance to your target, as per the long-range trajectory section on the ballistics chart.']	['<urn:uuid:7ebc7106-9f6f-4733-bbd6-ab812b11e41c>']	open-ended	with-premise	concise-and-natural	similar-to-document	single-doc	novice	2025-05-01T23:21:14.341336	9	41	899
321	As a neuroscience researcher, I need to understand how BCI drone control works. Can you explain?	BCI (brain-computer interface) works through electroencephalogram headsets that are calibrated to pilots' brains and record neural activity to identify specific thoughts. When pilots think about specific actions, like pushing a chair forward, neurons fire creating electrical signals. These signals are then translated into commands that control the drone's movement. It's similar to setting keyboard bindings in a PC game, but using brain waves instead of keys.	['If somebody had informed you just a few years again that you just’d have the ability to management your own home’s AC from wherever utilizing only a cellphone, you’ll have mentioned they’re mad. However what would you say if we informed you that you would be able to now management drones utilizing your thoughts energy? “Whoa, Whoa! Maintain your horses! That is nuthouse materials!” – Proper? Mistaken!\nThough it appears like a Sci-Fi film or the rambling of a loopy individual, it’s truly true. Whereas BCI (brain-computer interface) applied sciences aren’t utterly new, and there already is information of paralysed individuals utilizing brain-controlled prosthetic limbs, utilizing BCI to regulate drones is unquestionably one thing by no means tried earlier than – till this 12 months.\nCollege of Florida’s Most Uncommon Race\nOn April 22 this 12 months, College of Florida held the primary race involving drones managed by the pilots’ ideas. 16 gamers took half within the occasion held at Ustler Corridor, slowly shifting the devices ahead and side-to-side across the racetrack utilizing solely their willpower – having the gadgets run at 70mph, as common drones are capable of, was not doable.\nBy means of this out of the strange occasion, the organisers intention to popularise using brain-computer interface applied sciences, as an alternative of getting them caught in analysis labs. Till now, BCI was used particularly for drugs, nevertheless it has potential in lots of different fields – the group led by professor Juan Gilbert needs to develop the expertise to most people and see how brain-controlled gadgets can change and enhance the way in which we work, play and stay.\nThe race’s organisers hope to show the occasion right into a yearly inter-collegiate event, involving extra challenges and extra dynamic strikes, in addition to a trophy.\nHow Does the Expertise Work Precisely?\nA BCI, also referred to as BMI (brain-machine interface) or MMI (mind-machine interface) is a direct communication path between a computerised exterior machine and a wired or enhanced mind. This may not let you know a lot, however stick with us, as we’ll clarify all the pieces.\nIn our case right here, the pilots wore electroencephalogram headsets that had been calibrated to their brains and recorded their neural exercise to establish particular ideas. For instance, they recorded the place neurons fired when the pilots had been informed to consider pushing a chair ahead; these alerts had been then translated into instructions certain to the drone, shifting it ahead every time the identical electrical actions had been detected within the mind.\nPrimarily, it’s fairly much like setting your keyboard bindings when enjoying a PC recreation for the primary time – however as an alternative of keys, you utilize mind waves.\nBCI – Previous, Current and Future\nThe BCI applied sciences that scientists are researching right this moment have their origins within the 1920’s, when the electrical exercise inside the human mind was first found and EEG (electroencephalography) was developed. Within the 80’s, one other breakthrough came about, when Apostolos Georgopoulos discovered a relationship between the course of arm actions and electrical exercise of single neurons. Because the mid-90s, scientists have been in a position to make use of complicated motor cortex alerts and use them to regulate exterior digital gadgets, enabling mind-controlled expertise.\nRight this moment, BCI is far more superior, however there’s nonetheless a protracted approach to go. Robotic arms managed by mind exercise are already in testing and show extremely promising, and scientists are hoping to quickly determine easy methods to construct prosthetic limbs that “really feel” and work like natal ones.\nNew BCI medical gadgets and different machines primarily based on the expertise will have to be helpful, secure and economically viable – necessities which aren’t presently met by right this moment’s tech, sadly. Nonetheless, sooner or later, scientists hope to make use of BCI to assist individuals with quadriplegia, rehabilitate stroke sufferers, and even acquire a deeper understanding of psychiatric problems. As soon as science advances sufficient, the doable purposes of BCI are solely restricted by creativeness. Sooner or later within the close to future, you might be able to flip in your AC solely by pondering of it. Till then, have enjoyable watching the mind-controlled drone race! One more resource for getting information – https://www.engineering.com/DesignerEdge/DesignerEdgeArticles/ArticleID/15755/5-Future-Ways-to-Use-Brain-Controlled-Drone-Swarms.aspx']	['<urn:uuid:459016b7-5724-40b8-b2f0-1898b8413b3c>']	open-ended	with-premise	concise-and-natural	similar-to-document	single-doc	expert	2025-05-01T23:21:14.341336	16	66	713
322	I'm working on a school project about food science pioneers. Could you tell me if Nicolai Vavilov and the botanist Petr Zhukovsky had similar goals in their travels to Turkey?	Both scientists had similar goals related to collecting plant specimens, but for different purposes. Petr Zhukovsky traveled to Turkey in 1925 specifically to collect specimens and seeds for a Russian gene bank that was Vavilov's initiative. Vavilov himself conducted worldwide expeditions, including to 64 countries, with the broader goal of collecting seeds to improve farm productivity and eliminate Russian famines. The gene bank they contributed to eventually grew to contain 200,000 varieties of 2,500 food crop species.	"['- What’s On\nAnd the award for most versatile, most nourishing and best-loved ingredient goes to… the humble chickpea. Berrin Torolsan explores its history and its limitless talent to entertain us in a multitude of different roles\nMy first encounter with chickpeas was observing them sprout in moist cotton wool for a primary-school homework project. Seeing a bone-dry seed transform into a tiny plant with a life force all of its own was fascinating. We experimented with lentils and beans as well, but my favourite was the chickpea. I don’t know why – perhaps it was that tiny nose, known scientifically as a rostellum, that appealed to me. The seed resembles a ram’s head, hence the Latin name Cicer arietinum, meaning “ram-like chickpea”. Turkey has a sought-after variety with especially large, tasty seeds known, too, as ram’s head (koçbaşı).\nAgriculturally, chickpeas demand very little effort, growing in almost every part of the country. Chalky or salty soil, a humid or dry climate – the chickpea isn’t fussy. And its ability, like other legumes, to increase the fertility of the soil by fixing large amounts of nitrogen also endears it to farmers, who commonly grow it in orchards or fields in rotation with other crops. Chickpeas are completely at home in Turkey, one of the world’s largest producers. Planted in April and May, they produce little white or purple flowers, which turn into small pods that ripen for three months, then split open to expose one, two or three small, pea-like seeds.\nIn 1925 a Russian botanist, Professor Petr Zhukovsky, came to Turkey to collect specimens and seeds for a gene bank in Russia, the brainchild of the Soviet botanist and geneticist Nicolai Ivananovic Vavilov (1887–1943). Back in Leningrad, Zhukovsky published the results of his scientific observations in a groundbreaking book, Agricultural Anatolia, in 1933. He argued that many European cultivars, both cereals and legumes, originated in the gene pool of Anatolia. High on his list was the chickpea.\nThe recent recovery by Japanese archaeobotanists of chickpea seeds at Tell el Kerk, in northwest Syria, not far from the Turkish border, endorses his theory. Their chickpea hoard – 11 intact seeds, 65 half-seeds and 62 fragments – dates back to the late 10th millennium BC. Cultivation of wild species had begun by the beginning of the Neolithic period over a wide area of western Asia. The chickpea seems to have been domesticated there first before possibly being taken to post-glacial Europe, along with other ancient crops such as fava beans, peas and lentils. Protein-dense pulses were essential to the diet of prehistoric communities, as they are in many parts of the world today. The chickpea also provides valuable minerals such as magnesium, calcium, iron, zinc, phosphorus and selenium, and key vitamins, including B6 and E.\nThe chickpea has been part of life for thousands of years in Anatolia – nourishing not only populations but their culture and folklore. It even inspired a lovely sand colour, nohudî, which used to be fashionable among the Ottoman elite and whose name derives from nohut, the Turkish word for chickpea. For rich or poor, no celebratory meal was complete without its chickpea pilav – it was a centrepiece at village wedding and urban banquet alike. In 1539 the circumcision of Süleyman the Magnificent’s crown princes Beyazıt and Cihangir prompted two weeks of celebrations all over Istanbul; they included, of course, a pilav with chickpeas, but this one called for 40 kile – about a ton – of chickpeas. The amount of rice required makes the mind boggle.\nYet the chickpea was by no means just for feast days. Reinhold Lubenau, who came\nto Constantinople in 1587 as a pharmacist to the Habsburg envoy, remarked on the food markets near the Bedestan: stalls of pulses were piled high with chickpeas,\nbeans and lentils. The same abundance was seen at the Topkapı, which had many mouths to feed both in the palace and in the city. Imperial kitchen accounts for the end\nof the 16th century record the purchase of 20–25,000 kıyye (25–31 tons) of chickpeas, with special mention made of those from Egypt and from Keşan in Thrace.\nToday, distinctive, brightly lit food carts offering steaming chickpea pilav are a familiar sight on Istanbul streets, particularly at night. Taxi drivers flock to them. At home, the chickpea is an indispensable winter staple, endlessly versatile: it turns into soups, stews and a filling for dumplings, such as nohutlu mantı, a speciality of Bursa (see Cornucopia 51). Ground into meal, it is made into tasty snacks such as the Arab falafel and humus and the Armenian savoury topik. It even goes into desserts such as aşure (frumenty). But nothing can beat a bowl of hot, satisfying chickpea stew.\nRECIPES IN THIS ISSUE\nTAVUKLU NOHUT / Chicken with Chickpeas\n1 small chicken, quartered\n4 tablespoons olive oil\n2 large onions, chopped\n250g chickpeas (soaked overnight)\n1 tablespoon tomato paste\n1 or 2 small dried chillies (optional)\nWriting in 1882 in her book The Housewife, Ayşe Fahriye Hanım notes under “Chickpea Stews” that this dish, an Istanbul winter classic, can be prepared with mutton, turkey or goose. She serves it over toasted bread.\n1 Rinse and pat the chicken dry.\n2 Heat the olive oil and sauté the onions in a shallow pan until they start to caramelise. Remove the onions and set aside.\n3 Add a little extra oil to the pan if needed and stir-fry the chicken until golden all over.\n4 Place the chickpeas, onion and chicken in a saucepan. Season with salt and add the chillies whole if using them. Dilute the tomato paste in a glass of water and pour over the contents of the pan. Add more water to cover.\n5 Bring to the boil and simmer gently until the chickpeas are soft to the bite and the chicken is cooked (in a pressure cooker allow about 20 minutes).\n6 Serve piping hot with a good rustic bread to mop up the tasty sauce.\nOther recipes: Nohut Çorbası (Chickpea Soup); Nohutlu İşkembe Yahnisi (Tripe Stew with Chickpeas); Humus (Houmous); Nohut Yahnisi (Chickpea and Mutton Stew); Tavuklu Nohut (Chicken with Chickpeas – see below); Nohutlu Pilav (Chickpea Pilav)\nA fascinating exhibition at the Istanbul Research Institute that explores a dog’s life in Ottoman Istanbul and the transformation of attitudes as Westernisation takes hold\nYusuf Franko Kusa used brush and pen and position to lampoon and pull the strings of Ottoman high society. Unseen for 60 years, his caricatures are now the subject of a fascinating exhibition in Istanbul, writes K Mehmet Kentel\nAt one time all roads led to Erzurum, a key stop on a great caravan route and a strategic bastion against invasion. Today it is a remote city on Turkey’s Asian frontier with an important history crying out to be discovered. In Part 2 of Cornucopia’s Beauty and the East series, the photographer Brian McKee continues his tour of eastern Anatolia in Erzurum as Scott Redford leads us from Turkic citadel to Mongol minarets.\nIt was for centuries the preserve of sultans, extolled by the ancients, sought after in the harem, a staple of palace kitchen and pharmacy. More precious than gold, mastic brought fortune and fame to the island of Chios, today the world’s sole source of this ‘Arabic gum’. Now, thanks to a pioneering initiative, the Turkish shores across the water will be green with mastic groves. Text and photographs by Berrin Torolsan\nAn ambitious new work of classical music – based on Howard Blake’s enchanting score for ‘The Snowman’ – has just received its world premiere. This concert is just one of many achievements by Talent Unlimited, a Turkish charity that gives budding young virtuosi a helping hand. Tony Barrell tells the story. Photographs: Monica Fritz', ""“It seemed that We had finally passed this very difficult trail so that we could mount the horses and continue on. But suddenly from the Cliff above the trail, two gigantic eagles flew out from a nest, circling on enormous wings. My Horse shied and bolted, galloping along the trail and the ovring. The rein was unexpectedly torn out of my hand and I had to hang on to the mane.\nAbove my head were cliff’s but below me, 1,000 metres down in the deep ravine, rumbled the beautiful, blue Pyandzh, the upper reaches of one of the great rivers of Inner Asia. That is the experience, which afterwards this traveller remembers best. Such moments steel one for the rest of one’s life: they prepare a scientist for all difficulties, all adversities, and everything unexpected. in this respect, my first great expedition was especially useful.” (1916, Five Continents)\nThe man who wrote these lines was Nikolay Vavilov (1887-1943), Russian geneticist, plant breeder, plant geographer, and first President of the Lenin All-Union Academy of Agricultural Sciences who, for almost two decades, had at his disposal countless experimental stations with a total staff of 25,000 scattered throughout the Soviet Union.\nVavilov wanted to increase farm productivity to eliminate recurring Russian famines. Early on, he defended the Mendelian theory that genes are passed on unchanged from one generation to the next. He became the main opponent of Stalin’s favored scientist, Trofim Lysenko, by speaking out against the neo-Lamarckian agronomist’s belief in the inheritance of acquired characteristics.\nLittle known by non-Russians until the release of The Murder of Nikolai Vavilov by Peter Pringle (2008) and Where Our Food Comes From: Retracing Nikolay Vavilov’s quest to End Famine by Gary Paul Nabhan (2009), Vavilov was arrested by the NKVD secret police in 1940 while collecting samples in the Ukraine, and disappeared.\nIn a supreme irony, the architect of Russia’s increased food producing capacity died an ignominious death in a Stalinist prison from starvation after being sentenced to death at a secret trial for espionage, sabotage, and wrecking.\nReleased documents showed that before his show trial, Stalin’s police, seeking a confession, had subjected Vavilov to 1,700 hours of brutal interrogation over 400 sessions, some lasting 13 hours, carried out by an officer known for his extreme methods. before his arrest, during the long rise in influence of Lysenko, beginning in the 1920s, Vavilov, unlike Galileo, had refused to repudiate his beliefs, saying, “We shall go into the pyre, we shall burn, but we shall not retreat from our convictions.”\nWho was Vavilov and why does time cement his stature as almost a 20th century Darwin?\nIn a 2005 article in the Journal of Bioscience, Moscow geneticist Ilya Zacharov described Vavilov as “a person of inexhaustible energy and unbelievable efficiency. During his relatively short life, he accomplished a surprising amount: in his expeditions he travelled all over the world, he formulated very important postulates in genetics, he wrote more than ten books, and carried out the gigantic task of organizing a system of agricultural institutions in the USSR.”\nVavilov spoke many tongues fluently and learned the essentials of numerous local languages spoken by farmers he encountered in his world-wide travels.\nNabhan interviewed various farm experts in the countries he visited. One in Ethiopia said that Vavilov had “an uncanny ability…to pinpoint areas of high diversity.” An elderly agronomist in Kazakhstan, who as a boy had guided Vavilov into forests of wild apples, remembered that “he figured out everything…from little more than a day in the field.” Indeed Vavilov moved at breakneck speed, often commenting, “time is short, and there is so much to do. One must hurry.”\nDespite knowing something about Lysenko, ethno-botany, and biodiversity hotspots due to professional floristic work in Quebec, Guerrero, and temperate wetlands, I never learned Vavilov’s name well enough to retain it until reading Nabhan’s persuasive book. I asked friends professionally linked to agronomy outside the U.S., in Canada, France, and Cuba, about Vavilov. Only Anel Matos Vinals, a field botanist in the Cuban Sierra del Cristal, was familiar with his name and work, having participated in a project inspired by Vavilov’s writings, the study of wild mountain relatives of Cuban cultivated plants.\nTo improve the standard of nutrition for his people, Vavilov wanted to select and introduce resistant crop varieties adapted to Russia’s varying conditions. To use the planet as his garden of Eden was dazzling and ambitious, wrote agronomist Jack Harlan in Crops and Man (1975), “It was his plan to collect and assemble all of the useful germplasm of all crops that had potential in the Soviet Union, to study and classify the material, and to utilize it in a national plant breeding effort.”\nVavilov launched a worldwide plant exploration program and organized–and often led on horseback–115 expeditions to 64 countries (including Afghanistan, Iran, Taiwan, Korea, Spain, Algeria, Palestine, Eritrea, Argentina, Bolivia, Peru, Brazil, Mexico, and in the U.S., California, Florida and Arizona) to collect seeds of crop varieties and their wild ancestors. To begin, Vavilov concentrated on “areas in which agriculture has been practiced for a very long time and in which indigenous civilizations arose” (Harlan).\nInspired by renowned Swiss botanist Alphonse De Candolle’s attempt in 1882 to deduce the region of origin of many cultivated plants, Vavilov predicted that by analyzing geographic patterns of variation and mapping regions where genetic diversity was concentrated, the origin of a domesticated plant could be found, especially, ” if much of the variation was controlled by dominant genes and if the region also contained wild races of the crop in question” (Harlan).\nAs he gathered data on the back of mules, Vavilov postulated the existence of eight world centers of origin of cultivated plants, often associated with mountainous areas and their tribal peoples. After modification, these centers of origin later became “Vavilovian Centers of Diversity.”\nLater study showed that the phenomenon of centers of variation is real for many crops but not always related to the region of origin of a crop per se, i.e., where first domestication took place. After his exploration phase was cut short in 1933 by Stalin’s order, Vavilov developed concepts not only of secondary crops derived from the weeds of fields of more ancient primary crops, but also of secondary centers to account for the fact that centers of diversity may not be the same as centers of origin. Much later, Harlan considered data still too sketchy to do more than identify three broad independent systems of origin, each involving centers and non-centers of first domestications.\nNabhan points out that the concept of Vavilovian centers of diversity has been one of enduring usefulness to geneticists, conservation biologists, and biogeographers. Vavilov’s analyses of patterns of concentration of crop varieties helped lead to the realization that there are patterns of concentration of wild species (biological hot spots) and centers of origin of ornamental plants.\nThe results of Vavilov’s efforts to pinpoint where our food comes from included the creation in Leningrad of an international seed bank, maintained with frequent rejuvenation in field lots, of 200,000 recognizable forms of 2,500 species of food crops.\nWith the encirclement of Leningrad in 1941 by Hitler’s Operation Northern Light, this huge collection of living seeds and roots was in danger not only of falling into the hands of informed Nazi geneticists like Heinz Brucher, but also of being used for food by the suffering local population. Before the arrival of German troops, Stalin had agreed to the secret evacuation of Russia’s greatest art museum, the Hermitage, housed in the Winter Palace. But Stalin did nothing to evacuate the seed bank in Vavilov’s institute, considering it to be an indulgence of “bourgeois science.” 700,000 starved during the three-year siege, including many colleagues in Vavilov’s institute who barricaded themselves in with the hidden collection and managed to protect it. These researchers refused to eat the specimens, viewing them as an irreplaceable means for feeding humanity after the Nazi blockade and their own deaths would be forgotten.\nIn 1969, following 25 years of Lysenko’s domination of Soviet biology, much of the authenticity and germinability of the collection had been lost. Nevertheless, Russian writer Genady Golubev wrote in 1979 that “80% of all the Soviet Union’s cultivated areas are sown with varieties” derived from Vavilov’s collection, including “over a thousand valuable varieties known as ‘Vavilov.'”\nOther results included over 350 publications by Vavilov, some issued posthumously, including his principal work, Five Continents, the narrative that underlies both Nabhan and Pringle.\nNabhan, who knows his subject probably better than anyone, as his ethno-botanical experience, selected Vavilov itinerary and source materials attest, did a more than competent job of researching and presenting the Russian’s story and legacy. With Pringle, he shares the great merit of giving Vavilov an audience in the West.\nBy his title, Where Our Food Comes From, Nabhan reminds us that crop varieties providing the world’s food descend from wild biota that are absent from over 80 percent of the earth’s land surface, including most of the developed world, and that many basic domesticated varieties were selected and preserved by peoples in remote areas.\nHe also reminds us that “global food security” depends on variability within crop species, a variability that has declined 75 percent over the past century. He lists the causes of this crop genetic erosion, “due to the actions of the poor or the rich, or both” and throughout the book suggests ways and a philosophy to stop this one-way trend.\nIn countries selected from many visited by Vavilov, Nabhan uses maps, pictures, and text to compare current crops and farmers with those Vavilov encountered between the World Wars–using, in at least one case, detailed field notes that escaped NKVD raids–and allows us a glimpse of Vavilov’s previous work.\nNabhan devotes space to Vavilov’s scapegoating by Stalin for the Russian famine of 1933, to the rise of Lysenko, and to the dark repression that fell upon Vavilov, his colleagues and their Research Institute as it quietly worked to develop crop strains from its unique collection of genetic material.\nAn admirer of a man who set the stage for the exploration and preservation of the earth’s genetic resources and created before its time an international seed bank to fight famine, Nabhan demonstrates convincingly that, on the one hand, widespread chronic hunger today is not a result of low seed diversity in gene banks, but rather a lack of distribution, and on the other seed collections must be safeguarded as “buffers against famine caused by plagues, pestilence, floods, and other catastrophes,” including neglect and warfare.\nHere is where the creation and replenishment of modern local, national and global seed banks confront the issue of agricultural biodiversity as intellectual property, much discussed by Vandana Shiva, an Indian physicist who has authored a dozen books on the ramifications of what she calls “biopiracy,” or the theft of germplasm from the Third World and its copyright by multinationals.\nWas Vavilov a biopirate? A one-dimensional pirate Vavilov possessing “uncanny abilities to pinpoint areas of high diversity” on the payroll of an earth-poisoning corporation would be the opposite of the real Vavilov of the 1930s, devoted to the collective goal of feeding the world through subtle detection and meticulously sampling of crop varieties or ancestors in the field. What person in any country visited by Vavilov would wish that he had not left behind descriptions of agriculture and crops and sometimes living strains in Russia that could be returned to the source locality?\nIn The Living Fields (1995), Jack Harlan wrote, “The world of N.I. Vavilov is vanishing and the sources of genetic variability he knew are drying up. The patterns of variation [that Vavilov described on his expeditions] may no longer be discernible in a few decades and living traces of the long coevolution of cultivated plants may well disappear forever.”\nIn his forward to Nabhan’s book, K.B. Wilson of the Christensen Fund acknowledges an ambiguity underlying the work that can only be explained by the stark differences in attitude three generations ago: “Vavilov is a hero for environmental and social justice activists troubled by the unintended consequences of that same post-WWII crop breeding revolution that Vavilov’s discoveries helped to usher in. These consequences included the spread of industrial farming and the ‘green revolution’ that contributed to the destruction of diversity in crops and their wild relatives.”\nThere are some negatives to Nabhan’s book. He causes recurrent irritation when he equates wild diversity with cultural diversity, implying that primitive peoples enhance biodiversity by their presence in an ecosystem and impoverish biodiversity by their absence, notions that ecologists don’t accept, but that most readers are not equipped to challenge.\nThere are good reasons to defend native agriculture without claiming miraculous virtues. We depend on agriculture for survival, but this was not always the case. As Harlan wrote in 1975, “Crops are artifacts made and molded by man as much as a flint arrowhead, a stone ax-head, or a clay pot…The threat of famine has become a characteristic of agricultural systems; we have no evidence that this was a part of pre-agricultural systems.”\nNabhan himself quotes a colleague as saying, “Crop biodiversity is the biodiversity that people made.” In a 1998 article by a close student of Vavilov, J. G. Hawkes mentioned, “If we consider the world flora, even a quick survey will show us that there are many areas of plant diversity which have little to do with cultivated plant origins.”\nNabhan also puts an inordinate amount of blame on conservationists for the loss of crop varieties due to conflicts between native rights and park creation in the tropics, although park creation is at the extreme bottom of the list of the causes of world crop genetic erosion. Vavilov’s own writings do not confuse agriculture with nature. In Five Continents, he marvelled at nature regularly and I would be surprised if the “prominent scholars and field scientists” mentioned by Nabhan as presenting Vavilov to the West in the 1950s are any different. This passage about Ethiopia in 1927 is typical of Vavilov’s sensibilities: “Fields had disappeared. The area had become more sparsely populated and increasingly more beautiful. Ahead a panorama of a picturesque valley opened up. In hollows and along deep ravines there were groves of wild palms (Phoenix abyssinica Drude), a relative of the date palm.”\nNearly thirty years before it was published in English in 1997, Maryland botanist E. E. Leppik (1969) mentioned in Economic Botany Vavilov’s “principal work, entitled Five Continents. This was a scientific survey of his travels and explorations. It was to be published in two comprehensive volumes. For this purpose, he prepared extensive manuscripts with numerous original photographs…After Vavilov’s death, his valuable materials and manuscripts were destroyed. Fortunately his typist, A. S. Mishina, appreciating and comprehending the value of these papers, managed to salvage portions of the major manuscripts. It was published posthumously in Russian in 1962.”\nWithout the English translation of Five Continents, Nabhan’s and Pringle’s well-researched books would have been orders of magnitude more difficult to write, and much less interesting to read. Since Five Continents can be freely downloaded (PDF, from the publisher, the International Plant Genetic Resources Institute, no readers of either Nabhan or Pringle should deprive themselves of Vavilov’s own account of his expeditions.\nSee also: the wikipedia page at http://en.wikipedia.org/wiki/Nikolai_Vavilov""]"	['<urn:uuid:bda04b16-5ade-430f-a501-6c58b4b6b558>', '<urn:uuid:8ab75869-27c7-4e46-b3a8-4f0dd15c16d9>']	factoid	with-premise	verbose-and-natural	distant-from-document	comparison	novice	2025-05-01T23:21:14.341336	30	77	3849
323	Between prescription medications and natural remedies like omega 3's and healthy foods, which tends to work better for treating pain and inflammation in the long term?	Rather than one being better than the other, a holistic approach combining both natural remedies and medications appears most effective. While medications are important tools for pain management, their effectiveness and side effects can be impacted by other health factors. Natural anti-inflammatory sources like omega 3 fatty acids have been shown to reduce inflammation and pain comparable to some medications, while a diet rich in fruits and vegetables, low in processed sugar and refined carbohydrates, provides the best opportunity for healing through nutrition. Artificial food additives and processed foods are linked to increased inflammation, so addressing both medication and dietary factors is important for long-term pain management.	['Fruits and veggies vital for recovery, pain management\nDaniel Kean, M.D., with Sentara Physical Medicine & Pain Management Specialists in Hampton, Va is a physiatrist. Physiatry is a branch of medicine that works to enhance and restore functional ability and quality of life to people with physical impairments or disabilities. Dr. Kean partners with patients to diagnose their issue, develop the care plan best for them, and ultimately, his goal is to decrease their pain and restore optimal function.\nWhile often treatments may include procedures or injections, Dr. Kean is a big believer in the power of healthy choices and healthy living as part of a comprehensive plan of care. And he works hard to help his patient’s see the value and impact even a small decision like eating more fruits and vegetables can have on reaching their long-term goals. He’s so passionate about this, he took time out to share more about his healthy eating philosophy.\nWhy do healthy eating and living choices make such a big difference in a patient’s recovery?\nAfter having seen countless patients who complained of chronic pain and joint inflammation, I began to research ways to supplement a pharmalogical regimen with diet and physical exercise. There is a wealth of research that explains the benefits of certain foods, fruits, vegetables and herbs and their anti-inflammatory effects. Pointedl,: the omega 3 fatty acids in salmon are shown to reduce arthritic pain comparably to the effect of Ibuprofin; tart cherries are reported to help with painful arthritic conditions such as gout; dark leafy greens, garlic and onions are high in inflammation fighting caratanoids, and turmeric, an Asian spice, has been touted to have anti-inflammatory effects on par with Motrin and hydrocortisone. Medications aren’t always the only answer and even their effectiveness and side effects can be impacted by other factors in our lives and health decisions we make, so it’s good to approach health more holistically.\nHow could eating more fruits and vegetables help decrease pain?\nA diet consisting of fruits and vegetables is a healthy way of reducing inflammation and boosting our immune systems.\nCould eating certain fruits and vegetables and making other healthy lifestyle choices lead to a faster recovery in general or for specific injuries?\nIn general, diets that are devoid of processed sugar, and refined carbohydrates provide the best opportunity for healing through nutrition. Processed foods containing preservatives are linked to pro-inflammation. Artificial food additives, refined sugar and grains are pro-inflammatory agents and when consumed only serve to expedite the onset of degenerative diseases.\nDo you know of any good online resources that give folks tips on how to incorporate healthy food into their daily routine?\nThere’s a lot of good information out there – and a lot of bad information! Here are a few credible sites to explore:\nHow do you include fruits and vegetables in your day?\nIn my own endeavors to lead by example and improve my health, I have incorporated juicing which represents a quick and easy way to integrate both fruits and vegetables into my diet. The process of juicing extracts the nutrients, minerals and fiber from each ingredient and allows me to enjoy a convenient way to ingest naturally refreshing “take out” meals at any point in my day when sitting down to eat is not an option. Find great juicing recipes at juicerecipes.com.\nAbout The Author\nDaniel Kean, M.D., part of Sentara Physical Medicine & Pain Management Specialists, is board-certified in Physical Medicine and Rehabilitation. He specializes in Neuro-Musculo-Skeletal disorders, sports injury rehabilitation, electrodiagnostic, diagnostic and therapeutic procedures like joint/soft tissue injections and Botox injections for Spasticity Management, and pain management.', 'Omega 3 fatty acids are considered to be essential fatty acids. What’s so interesting about these essential fatty acids however is that while they are absolutely critical to human health, the human body cannot create omega 3s on its own.\nBecause our bodies are unable to develop omega 3’s, it is important to access our recommended daily intake through other sources. Fish, such as salmon, tuna, halibut are all omega 3 sources. Other seafood sources that are high in omega 3’s, and happen to be more sustainable than fish options, are algae, and krill (small crustaceans found predominantly in the southern ocean). Some plants and nut oils are also sources of omega 3’s, however consuming enough of these plant and nut sources to make an effective difference on personal health would be a near impossible feat on a daily basis.\nThe health benefits attached to omega 3’s, are undeniable.\nAddressing Heart Disease\nClinical evidence regarding the importance of omega 3’s is most strongly prevented in addressing heart disease and other problems that relate to heart disease. In fact, the American Heart Association has strongly pushed the necessity of omega 3 fatty acids in support of cardiovascular health. Clinical evidence suggests that omega 3’s help reduce risk factors associated with heart disease such as high cholesterol and hypertension (also known as high blood pressure). Omega 3 fatty acids have also been shown to slow the development of blood clots and plaque that clogs arteries. People taking sufficient doses of omega 3’s on a regular basis also have less risk of stroke and heart attacks.\nResearch has shown omega 3 fatty acids to reduce inflammation. Reduced inflammation can lower the risk diseases associated with chronic pain such as arthritis. People suffering from both; Rheumatoid Arthritis and Osteoarthritis have reported significantly reduced joint pain and joint stiffness. Some have even claimed that regular use of omega 3’s allowed them to reduce their intake of non-steroidal anti-inflammatory drugs.\nOmega 3’s have been known to reduce pain from symptoms associated with premenstrual syndrome while also working to balance mood swings, boost cognitive function, and improve feelings of personal well-being – acting as a completely holistic form of relief.\nNumerous sources have found omega 3 fatty acids can help symptoms associated to depression. There is evidence to prove that people who took omega 3 fatty acids in conjunction with prescription medications have noted a significant improvement in symptoms as opposed to relying solely on prescription antidepressants. Some women have also claimed that omega 3’s played a large role in conquering postpartum depression.\nThose suffering from diabetes, often have high triglyceride, matched with low HDL levels. Omega 3’s will assist in lowering triglycerides while raising HDL levels. Also People with diabetes often have high triglyceride and low HDL levels.\nRegardless of where you are in your fitness and health care goals, chances are high that including healthy sources of omega 3’s in your daily in-take will improve your personal health and well-being for the better. Choosing a supplement, such as a fish oil or krill oil might be the simplest way to achieve optimal omega 3 in-take, however it is best to do your research in finding a superior product that will provide optimal benefits.\nAbove all, when it comes to your health, and any concerns you may have, it is recommended that you speak with your health care practitioner.']	['<urn:uuid:28467a08-0394-488f-b29f-7e3865e0874d>', '<urn:uuid:d6d836ed-0186-4f07-921e-66e210ed2c66>']	open-ended	with-premise	verbose-and-natural	similar-to-document	comparison	novice	2025-05-01T23:21:14.341336	26	107	1169
324	Which blocks noise better, suspended or acoustic ceilings?	Acoustic ceilings are specifically designed for superior noise control. They absorb sound, reduce echo and reverberation, and can prevent sound from spreading to other areas. Their effectiveness is measured by the NRC (noise reduction coefficient) and CAC (ceiling attenuation class) ratings. While suspended ceilings can incorporate padding that absorbs sound, acoustic ceilings are made with specialized sound-absorbing materials like mineral fibers, glass fibers, polyethylene felts, and melamine foams specifically chosen for their acoustic properties.	['Suspended roofs are just like a next ceiling , it is put underneath the existing ceiling and can be used to full cover up pipelines or ductwork. They’re typically connected and suspended on wires from the ceiling above and are organized in a grid where tiles are fixed in. Suspended ceilings may be made out of a lot of materials, for instance, wood.\nWhen the suspended roofs have been installed you are able to easily fit in fluorescent lights or deploy air tubes etc. They are applied a great deal to hide this kind of perform anyway so suspended ceilings being mounted to cover air tubes can very quickly be incorporated in. You can also mount padding into your suspended roofs which absorbs temperature and sound.\nSuspended roofs are also implemented so that preservation can take place in the gap that’s produced once the ceiling is installed.\nWhen designing and buying your suspended roofs you will require to choose if you want the ceiling to be demountable or totally non-accessible. If you cause you to suspended ceilings demountable then this allows you to simply access the ceiling gap and conduct maintenance on the ceiling or on different things that the ceiling is concealing. If you produce your suspended ceiling non accessible you then will not manage to conduct ceiling maintenance easily as you will not be able to get involved with the ceiling void.\nYou should look at the above mentioned very severely because the ceilings will need to be redone should you desire to have the ability to change a non accessible ceiling in to a demountable one.\nThere are lots of different types of Plastering Liverpool but all are different depending on your needs however the idea is the same. For instance there’s the free period postpone ceiling program that is mainly employed for corridors. This kind of process is comprised of ceiling planks which are held by the border trim on the small edges. This sort of system may be fitted rapidly and pretty easily, plus it may produce an excellent effect when completed which is usually smooth. These kind of suspended roofs could be created de-mountable for maintenance or non-accessible; if you choose the de-mountable form then a ceiling boards are removed to permit you your easy access.\nSuspended roofs are used in structure and can be used in nearly every situation. They can be used in practices, schools, Lecture areas, even on vessels, anywhere where there’s a ceiling means that there’s possible prospect of there to become a suspended ceiling. Suspended ceilings contain a grid function of metal stations in the form of and upside down “T”, that’s finally suspended on wires from the around head framework (in most cases the initial ceiling). These ceilings are super easy to install and are spaced in a architectural structure that uses as: 600 x 600mm etc. Each of the different cells is full of a light traditional ceiling tile, which decline to the grid, thus offering it the title of a dropped ceiling.\nWith the power of suspended roofs it’s possible to install the grid to their preference. You can install illumination in each grid possibly as a sq, or tube. You are able to rotate air through a series of fans and air diffusers through the entire company without losing temperature, like you’d have without these ceilings. You can also place fireplace sprinklers wherever you choose. The theory that you could fully customise the suspended ceilings is really a major gain as you merely cut the grid wherever you want.\nAnother suspended ceiling program could be the bandraster program; these kind of suspended roofs are very flexible and could be produced to match with almost any building architecture. Yet again these suspended roofs could be created available or low accessible. These suspended ceiling are design with sometimes hidden or exposed sections which url up to achieve horizontal bracing, thus these methods can be modified to suit any building.\nStill another system may be the exposed suspended roofs program that is still another system which may be mounted rapidly and efficiently and also allows for you really to do maintenance function in the ceiling emptiness easily. These types of suspended ceilings have tiles placed right into a suspended grid allowing for it to be edited easily as well.', 'What are Acoustical Ceilings used for?\n- by siteadmin\nThe acoustic quality of a room can affect communication, comfort, and productivity. Noise is a major complaint. Excessive noise can lead to stress, fatigue, and decreased performance.\nCeilings that absorb or reflect sound reduce echo and reverberation. These ceilings are available in many styles and materials, including polyethylene felts and cementitious wood fibres.\nAcoustical ceilings can reduce reverberation and help people focus. Acoustic ceilings help reduce reverberation and prevent sound from spreading to other areas.\nModern acoustic walls are made of a variety of materials that absorb sound. Mineral fibers have the lowest cost and are most commonly used. Glass fibers may be more expensive, but they are durable and offer superior sound absorption.\nPolyethylene felts are another option. Melamine foams, PVC Stretch, and cementitious fibers can also be used. Acoustics are also affected by the shape of panels.\nTraditional coffered-ceilings can be updated to match a modern aesthetic using octagonal shapes and larger sections. The style may not be the most acoustically efficient, but it is a great way to enhance modern decor. You can spray it with a color to match the other finishes of the room.\nAcoustic ceilings can be a good solution for reducing harsh echoes within a space or room. The ceilings also absorb sound, improving the quality of sound in a space. This is what we know as popcorn ceilings.\nThe acoustic panels are made from a wide range of materials. These ceilings are available in a range of shapes, including tiles, linear panel, baffles and grilles. They also come in a wide variety of fabrics. The NRC (noise-reduction coefficient) and the CAC (ceiling-attenuation class) are measured. The greater the NRC rating the better the sound absorption. There is a thin line between blocking out sound and absorbing it, so make sure you look at both the NRC and CAC rating.\nAcoustic panels can be used to hide an unfinished ceiling that is unsightly. They will make the ceiling look finished. Acoustic panels come in many different textures, colors and designs, so you can choose the one that best matches your room.\nAcoustic ceilings can be installed in any space that needs superior acoustics. They are often used in schools to improve speech clarity. Recording studios and music venues can also benefit from the acoustic control provided by acoustic walls.\nThe textured, molded ceiling tiles add a cozy feel to any room that has a grid ceiling.\nCover Up Unfinished Ceilings\nAcoustical ceilings are a great way to conceal wires, pipes, and other unsightly items. The ceilings are also flexible, allowing for easy access to make repairs or remodel.\nAcoustic ceilings are available in a variety of textures and styles. They can be used to enhance any room. A coffered grid looks like wood, and can hide ceiling imperfections.\nIt is important to take into account the Ceiling Attenuation class and Noise Reduction Class when choosing an acoustic roof. It is important to have a high NRC to prevent echoing and loud environments. A high CAC will stop sound from traveling between rooms.\nSafety is Improved by Avoiding Exposed Wiring\nAcoustical ceilings, unlike standard ceilings, acoustic tiles separate the visible surface of the ceiling from the space above it (known as the Plenum). This makes it easy to access the ceiling for repairs, wiring and remodeling.\nAcoustic ceilings can reduce noise and improve speech clarity in common areas or classrooms. It is crucial to improve speech clarity in the workplace because, according to studies, poor speech clarity can lead to stress and low productivity.\nAcoustic ceilings are available in many styles and materials. Mineral fiber ceilings offer a variety of colors and are affordable. The drywall-like appearance of a fiberglass ceiling is enhanced by its better acoustic properties. Woven fabric panels provide a wide range of colors.\nThe acoustic quality of a room can affect communication, comfort, and productivity. Noise is a major complaint. Excessive noise can lead to stress, fatigue, and decreased performance. Ceilings that absorb or reflect sound reduce echo and reverberation. These ceilings are available in many styles and materials, including polyethylene felts and cementitious wood fibres. Soundproofing Acoustical…']	['<urn:uuid:921ac297-4dcf-48b5-ab8f-de1441dce801>', '<urn:uuid:891543d5-6fc7-468c-99b4-f0f6280b5247>']	open-ended	direct	concise-and-natural	distant-from-document	comparison	novice	2025-05-01T23:21:14.341336	8	74	1418
327	How do Yoruba religious practices influence modern rituals across different regions?	Yoruba religious practices have significantly influenced rituals across various regions. In Yorubaland, traditional religious beliefs are tied to Itan (comprising songs, histories, and stories). These practices have spread to other regions - in Afro-Brazilian Candomblé, Ogun is known as Ogum and is associated with Saint George, particularly in Rio de Janeiro. In Haitian Vodou, Ogun becomes Ogou, maintaining the aspect of iron smithing from Yoruba tradition and serving as guardian of the sacred altar. Followers in these various traditions maintain similar practices, such as making sacrificial offerings and using iron implements in ceremonies, demonstrating the enduring influence of Yoruba religious customs across different cultures.	"['The Yoruba people are one of the most popular ethnic groups in West Africa and Africa at large. They are predominantly found in Southwestern and north-central region of Nigeria and in some parts of the Benin Republic and Togo.\nIn this article, we’ll present to you everything you need to know about the ‘Children of Yoruba’, their language, religion, tribe, culture and other interesting facts you probably didn’t know about them.\nYoruba People, Tribe\nAlso known as Àwon omo (which literarily means ‘The Children of Yoruba), the Yoruba tribe reportedly constitute over 40 million people generally, including those in Southern and Central Benin.\nIn Nigeria, this wonderful tribe boasts 21% of the population, making them a major tribe and one of the largest ethnic groups in the Western Africa country.\nThe Yoruba are surrounded by some minor ethnic groups in Nigeria as well as in Benin. To the northwest in Benin, they share borders with the Bariba, the Ebira to the northeast in central Nigeria, the Nupe to the north and the Edo, the Afemai and Ẹsan groups to the east in mid-western Nigeria.\nThe Yoruba tribe also shares borders with the Gbe speaking Mahi, Egun ethnic group, Fon to the southwest and the Ewe people living in Benin and Togo. To the southeast, they share a border with the principal inhabitants of Itsekiri who live in the north-west end of the Niger Delta.\nThough the Yoruba are mostly populated in Nigeria, they also dwell (in large number) in other West African countries like Liberia, Ghana, Ivory Coast, and Sierra Leone.\nThere are two major groupings of Yoruba people in the diaspora; the first group is known as recent migrants and they are made up of Yorubas who migrated to the United Kingdom and the United States in the 1960s to 1980s as a result of major economic and political changes. The second group consists of Yorubas who were part of the Atlantic slave trade.\nAccording to reports, the second group are larger in number and has communities in countries like Trinidad, Tobago, Dominican Republic, Cuba, Saint Lucia, Jamaica, Brazil, and Grenada, among others.\nAccording to history, The Yoruba kingdoms were a part of the British Protectorate during the imperial era in Africa. They strongly believe they descended from Oduduwa.\nAncient Yoruba practised polygyny, the men were allowed to marry more than one wife, while also treating them equally, although competitions were evident among wives in order to secure preference for their children.\nSome Yoruba still practice this act, with the most popular being the Alaafin of Oyo, Oba Dr. Lamidi Olayiwola Adeyemi III, who is currently married to four wives.\nAs at 2010, records had it that about the number of Yoruba language speakers was put at 30 million. While we are yet to confirm if this figure actually increased or dwindled over the years, we make bold to affirm that majority of Yoruba people are native speakers of the Yoruba language.\nLike most languages, the Yoruba language has a myriad of different dialects. These dialects are further grouped into five major dialect areas which are: Northwest, Northeast, Central, Southwest and Southeast.\nThe North-West Yoruba (NWY) dialect is predominantly spoken in the following areas: Egba, Ibadan, Egbado/Yewa, Ọyọ, Western Ogun, Lagos/Eko while residents in the Yagba, Owe, Ijumu, Oworo, Gbede, and Abunu areas speak the North-East Yoruba (NEY) dialect.\nThe Central Yoruba (CY) dialect is predominantly used by residents in Igbomina, Ijesha, Ifẹ, Ekiti, Akurẹ, Ẹfọn while Ikale, Ilaje, Ondo City, Ọwọ, Idanre, Akoko, Remo, and Ijẹbu communities are speakers of the South-East Yoruba (SEY) dialect.\nLastly, the South-West Yoruba (SWY) dialect is majorly spoken by Yoruba communities in Ketu, Awori, Sakété, Ifè (Togo), Idasha, and Ipokia/Anago.\nInterestingly, many Yoruba words are used in the Afro-Brazilian religion known as Candomblé and in many other Afro-American religions in the Americas and the Caribbean.\nIrrespective of the aforementioned discrepancies in the Yoruba language, the tribe has a standard variety of Yoruba known as Literary Yoruba, Yoruba koiné, or Yoruba.\nThis variety, which has its origin in the 1850s, is the written form of the language and is widely used in the media by newsreaders. All credit to Samuel A. Crowther, the first African Bishop, who was the first person to publish a Yoruba grammar.\nAmong all the languages spoken by ethnic groups in Nigeria, the Yoruba language is most closely related to the Igala (spoken in central Nigeria) and the Itsekiri language (spoken in the Niger Delta).\nSouthwestern Nigeria and the adjoining parts of Benin and Togo are not just the homelands of the Yoruba people, they significantly double as places where the religious and diverse traditional practices of the people are played out.\nRecords have it that at least 20% of the Yoruba practice the traditional religions of their ancestors. Yoruba religious beliefs share tied with Itan, which comprises songs, histories, stories, and other cultural concepts of the Yoruba society.\nThe Yoruba strongly believe every man possesses “Ayanmo” (destiny, fate) and that Olodumare is the principal agent of creation. In addition, they also believe reincarnation within the family which they call ‘Atunwa’.\nThe Yoruba ethnic holds that the ruler of the sky and the earth beneath the sky is Olorun (Sky God) and is orisha to other orishas. They believe the Olorun is the father of Orunmila and Obatala. He can be communicated through prayers or by pouring water on kola nuts on the ground.\nEshu, another god, is considered the divine messenger who takes up sacrifices to Olorun after they are placed at his shrine while Ifa, the God of Divination, interprets the wishes of Olorun to mankind.\nOgun is the god of war, the hunt, and metalworking. In Yoruba courts, people who follow traditional beliefs swear to give truthful testimony by kissing a machete sacred to Ogun. Then Shango (also spelt Sango and Sagoe) is the creator of thunder.\nFor more information on the religion of the Yoruba people, click here\nVirtually every ethnic group has cultural norms that are passed down from one generation to another. The Yoruba are not exceptional, as they survive on unique cultural norms they consider precious and irreplaceable.\nThe Yoruba ethnic group is very protective of their culture, and most of them continue to give their children traditional names rather than English and would speak their language at any given opportunity.\nFrom their artistry (which embodies sculpture, textile, cuisine) to other things like naming customs (Naming, Oruko Amutorunwa – Preordained name, Oruko Abiso – Name given at birth, Abiku names, pet names), law, linguistics, wedding, music, funeral, philosophy, idealism, religion, and language, the Yoruba are quite unique, blessed and hardworking.\nThe Yoruba are famous and prolific sculptors. They are also popular for their beautiful clothing designs and patterns. Some of their native food include moin-moin (steamed bean pudding) and akara (bean cake), ewedu, gbegiri, and efo riro (native soups), “ila asepo” (okra soup) and amala (a traditional fufu made of yam flour).\nThey Yoruba also believe so much in giving relevant names as well as pet names to their babies and loved ones. This is because they believe people live out their names – whether good or bad.\nWeddings in Yorubaland are usually a lovely sight to behold. For a wedding to take place in Yoruba, the bridegroom is expected to first receive the consent of the bride’s parents after which he pays the bride price. Friends and the family of the bridegroom usually attend the ceremony to send her off to her new home.\nLike most ethnic groups, the Yoruba believe death is not the end of one’s life but simply a transition to another form of existence. They also believe in old age, this is why most of them pray for long life during blessings. In addition to this, they often to the creator for wealth and children.\nInteresting Facts About Yoruba People\n- Yoruba people are popular for a number of dishes eaten in Nigeria. Some of them include Amala and Ewedu soup, Gbegiri soup, Ewa Aganyin, among others.\n- The Yoruba people are stereotypically described as the “lively bunch” for their enthusiasm for parties.\n- They are known for being good at weaving, embroidering, pottery making, woodcarving, leather and bead working, and metalworking.\n- The Yoruba people craft skill is especially evident in sculpture. The popular Ife “bronze” heads which were found in 1938 also testify to the craftsmanships of the Yoruba people.\n- Other popular arts and craft work by the Yoruba include the Adire, an indigo-dyed cloth made using resistant-dye techniques.\n- They are also known for different genres of music including Akpala, Fuji, afro juju, as well as Afro beats.\n- The popular Aso-Oke (Aso-Ebi) native attire was initially synonymous with the Yoruba people. But today, the gorgeous apparel has become a symbol of Nigerian marriages.', 'Ogun or Ogoun (Yoruba: Ògún, Portuguese: Ogum, Gu; also spelled Oggun or Ogou; known as Ogún or Ogum in Latin America) is an Orisha, Loa, and Vodun. He is a warrior and a powerful spirit of metal work, as well as of rum and rum-making. He is also known as the \'god of Iron\'.\nWarriors, soldiers, smith makers, metal workers, craftsmen\n|Member of Orisha|\nVeve of Ogoun\n|Other names||Oggun, Ogou, Ògún or Ogúm|\n|Venerated in||Yoruba religion, Edo religion, Dahomey mythology, Vodun, Santería, Umbanda, Candomblé, Quimbanda, Dominican Voudou, Haitian Vodou, Louisiana Voodoo, Folk Catholicism|\n|Region||Nigeria, Benin, Latin America, Haiti|\n|Ethnic group||Yoruba people, Edo people, Fon people|\nIn Yoruba religion, Ogun is a primordial orisha who first appeared as a hunter named Tobe Ode. He is said to have been the first Orisha to descend to the realm of Ile Aiye (""Earth""), to find suitable place for future human life. In some traditions he is said to have cleared a path for the other gods to enter Earth, using a metal ax and with the assistance of a dog. To commemorate this, one of his praise names, or oriki, is Osin Imole or the ""first of the primordial Orisha to come to Earth"". He is the god of war and metals.\nIn his earthly life Ogun is said to be the first king of Ife. When some of his subjects failed to show respect, Ogun killed them and ultimately himself with his own sword. He disappeared into the earth at a place called Ire-Ekiti, with the promise to help those who call on his name. His followers believe him to have wo ile sun, to have disappeared into the earth\'s surface instead of dying. Throughout his earthly life, he is thought to have fought for the people of Ire, thus is known also as Onire.\nOgun is the traditional deity of warriors, hunters, blacksmiths, technologists, and drivers in the Yoruba religion. Followers of traditional Yoruba religion can swear to tell the truth in court by ""kissing a piece of iron in the name of Ogun."" Drivers carry an amulet of Ogun to ward off traffic accidents.\nThe primary symbols of Ogun are iron, the dog, and the palm frond. They symbolize Ogun\'s role in transformation, mediation, and function. Iron is the primary emblem of Ogun. Ogun altars and ceremonies display and use iron objects both in Yoruba areas and the across the African diaspora. Followers of Ogun wear chains of iron implements; Ogun festivals feature the display of knives, guns, blacksmith implements, scissors, wrenches, and other iron implements from daily life.\nMeats are a sacrifice for Ogun. Dogs are the traditional companions of hunters, but Ogun\'s personality is also seen as ""doglike"": aggressive, able to face danger, and straightforward. Other sacrificial animals associated with Ogun are the spitting cobra (blacksnake); its behavior is aggressive and fearless. Hunters and blacksmiths avoid eating or witnessing the mating of blacksnakes. Other important sacrificial offerings to Ogun are the Clarias submarginatus (a species of catfish), alligator pepper, kola nuts, palm wine and red palm oil, small rats, roosters, salt, snails, tortoise, water, yams. (Clyne: 1997). Many of these sacrificial offerings were carried into New World traditions.\nOgun worshipers are known to sing a song that insinuates that Ogun is in seven paths.\nOgun Alaara ni gba aja - Ogun of the Alaara people collects dog. Ogun Ajeero ni gbaagbo - Ogun of the Ajeero people collects ram. Ogun Ikole a gba\'igbin - Ogun of the Ikole people will collect snail. Ogun Elemono ni gbe\'sun isu - Ogun of the Elemono will collect roasted yam. Ogun Gbena Gbena eran ahun ni je - Ogun of the wood carvers eats the tortoise\'s meat. Biko gba Tapa, a gba aboki, a gba kemberi a bilala lenu Meje logun, meje nire. Ogun onire oko mi.\nIn Dahomey religion, Gu is the vodun of war and patron deity of smiths and craftsmen. He was sent to earth to make it a nice place for people to live, and he has not yet finished this task.\nOgun is known in the Afro-Brazilian tradition of Candomblé as Ogum (Ketu, Ijexa and Efon nations) or Gu (Jeje nation). Ogum is syncretized with Saint George, notably in Rio de Janeiro and the state of Rio Grande do Sul. Candomblé tradition in Northeast Brazil, especially in Bahia, associates Ogum with Saint Sebastian or Saint Anthony.\n- Consecrated day: Tuesday\n- Metal: iron\n- Element: earth\n- Color: red, black, green (Rio de Janeiro), blue (Bahia), marine blue\n- Food: feijoada, xinxim, yams\n- Archetype: impetuous, authoritarian, cautious, hardworking, suspicious and a bit selfish\n- Symbols: sword, broadsword, iron chain\nIndividual devotees of Ogum in Brazil avoid certain foods. These include goat, cajá-manga (Spondias dulcis), sugar, black beans, yams, and the manga-espada (an elongated mango cultivar of Brazil) in the Ketu nation; yams and manga-espada in the Ijexa nation; and partridge in the Jeje nation.\nOgum, as a male orisha (Boró), only ""eats"" male animals. Ox, billy goat, rooster, snake (typically a red snake), dog, and game animals are sacrificed (""orô"") on festival days associated with Ogum in the Candomblé tradition.\nAcaçá is a ritual food offered to all gods in the Candomble pantheon; it is made of a paste of corn mash steamed in banana leaves. A variation, acaçá de feijão-preto, substitutes black beans (Phaseolus vulgaris) for corn. This variation is only offered to Ogum in the Casa Fanti Ashanti temple in São Luís, in the state of Maranhão. Feijoada, a stew of beans with beef and pork, is also a common offering to Ogum.\nSantería and Palo\nOgun\'s centrality to the Yoruba religion has resulted in his name being retained in Santería religion, as well as the Orisa religion of Trinidad and Tobago. In Santería, Ogún is syncretized with Saint Peter, Santiago, Saint Paul, and John the Baptist; he is the deity of war and metals.\nIn Haitian Vodou Ogun is known as Ogou, and consists of an array of manifestations; most carry the aspect of iron smithing and tools from the Yoruba tradition. The Ogou guard the badji, the sacred altar of the Vodou temple. He carries an iron saber and wears a red sash. Ogou is also the god of pioneering, intelligence, justice, medicine, and political power; these are associated with the symbol of the tool that can ""advance humans\' mastery over the environment. Ogou Feray is the god of war. Other manifestations of Ogou are Ogou Badagri, Ogou Balenjo, Ogou Batala, and Ogou Je Wouj. Ezili Freda Daome is the female counterpart to Ogou.\nOgou Feray is syncretized with St. James the Greater (St. Jacques Majeur) in the Vodou tradition. He is a warrior spirit and protects the Vodou community; he guides Vodou followers against their enemies. He is symbolically covered in iron and may not be harmed by his enemies. As in Africa, his symbol is a piece of iron, a machete, or a knife. As in Africa, Ogou is revered among blacksmiths, many of whom are of Yoruba origin. He is also noted to like women and alcohol.\nIn Vodou ceremonies followers of Ogou wear a red shirt, pants, and scarf. A followers of Ogou in a possession-trance is offered Haitian white rum during the ceremony. In some ceremonies rum is burned in a container to allow Ogou to ""wash"" the hands of the followers.\nFè Ogou Fè, Ogou Fèray o,\nFè Ogou Fè, Ogou Fèray o\nI am an iron,\nI am covered with iron.\nFèrè Fèray tout ko Fèray sé kouto,\nFèrè Fèray tout ko Fèray sé manchèt.\nThe body of Ogou Fèray is covered with knives,\nThe body of Fèray is covered with machetes.\nLéo Neto, et al. observed various species used in sacrificial ritual in twelve Candomblé communities of Caruaru, Pernambuco and Campina Grande, Paraíba in the Northeastern region of Brazil between August 2007 and June 2008; dogs were the only sacrificial animal offered to Ogun in both communities.\n- Clyne, Robert Marcel (1997). Ogun Worship in Idanre: Iron and Identity in a Yoruba Town (Ph.D. thesis). Yale University.\n- Adeoye, C. L. (1989). Ìgbàgbọ́ àti ẹ̀sìn Yorùba (in Yoruba). Ibadan: Evans Bros. Nigeria Publishers. pp. 250–262. ISBN 9781675098.\n- Barnes, Sandra (1997). Africa\'s Ogun: Old World and New. Bloomington Ind: Indiana University Press. ISBN 0253-332516.\n- Earhart, H (1993). Religious Traditions of the World: a Journey through Africa, Mesoamerica, North America, Judaism, Christianity, Islam, Hinduism, Buddhism, China, and Japan. San Francisco, California: HarperSanFrancisco. ISBN 9780060621155.\n- Verger, Pierre (1999). Notas sobre o culto aos orixás e voduns na Bahia de Todos os Santos, no Brasil, e na antiga costa dos escravos, na África (in Portuguese). São Paulo: EDUSP. pp. 151–160. ISBN 9788531404757.\n- Augras, Monique (2004). ""Quizilas e preceitos--transgressão, reparação e organização dinâmica do mundo"". Culto aos orixás: voduns e ancestrais nas religiões afro-brasileiras (in Portuguese). Rio de Janeiro: Pallas. pp. 190–193. ISBN 9788534702379.\n- Assunção, Matthias (2005). Capoeira: the History of an Afro-Brazilian Martial Art. London New York: Routledge. p. 39. ISBN 0714650315.\n- Hargreaves, Patricia, ed. (2018). Religiões Afro: as origens, as divindades, os rituais. São Paulo: Abril. p. 29. ISBN 9788569522492.\n- Léo Neto, Nivaldo A.; Brooks, Sharon E.; Alves, Rômulo RN (2009). ""From Eshu to Obatala: animals used in sacrificial rituals at Candomblé ""terreiros"" in Brazil"". Journal of Ethnobiology and Ethnomedicine. 5 (1). doi:10.1186/1746-4269-5-23. ISSN 1746-4269. PMC 2739163.\n- Moura, Carlos Eugênio Marcondes de, ed. (2004). Culto aos orixás: voduns e ancestrais nas religiões afro-brasileiras (in Portuguese). Rio de Janeiro: Pallas. pp. 43–45. ISBN 9788534702379.\n- Lody, Raul (2003). Dicionário de arte sacra & técnicas afro-brasileiras. Rio de Janeiro: Pallas. p. 36. ISBN 9788534701877.\n- Fieldhouse, Paul (2017). Food, feasts, and faith : an encyclopedia of food culture in world religions. Santa Barbara, California: ABC-CLIO, an Imprint of ABC-CLIO, LLC. p. 93. ISBN 9781610694124.\n- Falola, Toyin (2005). Yoruba Creativity: Fiction, Language, Life and Songs. Trenton, NJ: Africa World Press. ISBN 9781592213368.\n- Galembo, Phyllis (2005). Vodou: Visions and Voices of Haiti. Berkeley, Calif: Ten Speed Press. pp. xxii–xxiii, 12. ISBN 9781580086769.\n- Laguerre, Michel (1980). Voodoo Heritage. Beverly Hills, Calif: Sage Publications. pp. 131–137. ISBN 0803914032.']"	['<urn:uuid:76897ff6-2a08-42f9-a9d5-a29fb024b93c>', '<urn:uuid:829f170e-373f-47bf-9576-164f2f173685>']	open-ended	direct	concise-and-natural	similar-to-document	multi-aspect	expert	2025-05-01T23:21:14.341336	11	104	3157
328	My basement feels damp lately. What problems could this cause?	Damp basements can lead to several serious issues. They are ideal places for mold growth. In finished basements, moisture can hide behind walls and destroy framing. It can also damage carpet or hardwood flooring if it seeps through. Additionally, when there's too much moisture constantly contacting foundation walls, it can cause premature deterioration of the cement and unnecessary settling.	['Water/Moisture Damage in Your Basement or Foundation\nWater Kills Houses\nPart 2 in Series – Basement/Foundation\nAs an experienced home remodeling contractor, we see many homes damaged by water leaking into structures. In Part 2 of our series, we will discuss how water damage affects the basement and foundation of your home.\nYour roof may be the first line of defense against the elements, but your basement/foundation is holding everything up. It is extremely important to keep water moving away from your home and not toward your foundation. Too much moisture in constant contact with your foundation walls can cause premature deterioration of the cement and unnecessary settling. Also, basements are a great place for mold to grow when they are damp. If you have a finished basement it creates another place for moisture to hide behind the walls and destroy your framing, not to mention what it will do to that lovely new carpet or hardwood flooring you just installed if it seeps through. There are several things you can do as a homeowner to keep moisture away from your foundation.\n- Inspect the bottom of your downspouts to make sure that all of that water is flowing away from the house. This is a common problem area. While it’s very important to make sure that your gutters and downspouts are flowing properly (I’ll address this in #3 of this series), It’s equally important to make sure that the water flowing out of your downspouts is flowing away from your house! Too often the downspout ends with a simple elbow that directs the water a couple of inches from the wall, or there is a misaligned splash guard that might move some of the water a foot or two away from the house. The best thing a homeowner can do in this case is to add a flexible drain pipe or a gutter extension piece to the bottom of the downspout that carries the water AT LEAST 3-4 feet away from the foundation wall and into an area where the ground is sloping away from the house. Make sure that any pipes or extensions are properly fastened so that they don’t come off easily by using stainless steel or aluminum screws (so they won’t rust). Sometimes folks don’t like the way these pipes or extensions look, or they are an annoyance when mowing or even a trip hazard. If that’s the case then another solution may be adding an underground drain pipe, which when working properly is terrific. However, sometimes a downspout goes directly into an underground drain pipe but now one knows where it actually ends up or if it is clogged. It is vitally important that underground pipes are flowing freely. If they aren’t then often the downspout is simply directing all of the water from the roof directly against the foundation. It’s very important to KNOW that the water going into an underground drain is coming out at the other end. If you’re not sure it would be a great idea to insert a hose into the drain pipe and see what happens! Fixing these pipes can be difficult work but it is worth every bit of effort to make sure that you’re getting all of the water away from your home!\n- Make sure that the ground contacting your foundation is sloping away from the house. It’s not uncommon for the fill around a home’s foundation to settle over the years. When this happens a “bowl” is created that funnels water directly toward your foundation. Even if your foundation is properly sealed this water then runs down to the footing of the foundation and often ends up seeping into the basement floor. It’s best for the ground to slope away from your house, at least, an inch or two in the first 4-6 feet. If you see that your home does not have proper slope it’s important that you fill those areas with topsoil to create the slope you need. The newly covered areas should be planted with grass or covered with mulch or landscape rocks to prevent it from washing away. Overall this is generally an easy fix but there is an important factor to be aware of which I’ll address in letter “C”.\n- DO NOT fill the soil so high that it comes in contact with the wall above your foundation unless your foundation is a masonry finish, like brick, that extends below the soil line intentionally. There should always be at least an inch or two between the top of soil/mulch and the bottom of the wall. I’ve often seen/repaired rotted wall plates that got wet because they wicked in moisture from the non-draining soil that was up against the siding. Also, termites are often introduced into a house when the soil is over the top of the foundation. I can’t emphasize enough how important it is to maintain a little bit of space between the soil and the siding! If you’re in the unfortunate situation where you need to add slope around your house, but can’t do so without taking soil above the foundation, or you discover that you already have soil/mulch extending above the foundation, please don’t ignore it. At that point, it would be a great idea to call an excavator or landscaper to discuss ways to get the water moving away from your house. This may be expensive but it is absolutely necessary for the long-term stability of your home.\nThis entire concept of keeping water away from the foundation is overlooked by many homeowners because there often aren’t easily identifiable problems. People don’t know their wall plates are rotting away until it’s too late, or they can’t see the mold growing behind their finished basement walls. If you’re in any way uncertain as to what you’re seeing or what might be going on with your home, it’s always a good idea to call a building/landscaping professional to give you an assessment. With the foundation, an ounce of prevention is truly worth a pound of cure!']	['<urn:uuid:1ab3e052-35f4-4084-8fd1-13d80b74c223>']	open-ended	with-premise	concise-and-natural	similar-to-document	single-doc	novice	2025-05-01T23:21:14.341336	10	59	1009
330	Working in culinary education, I've noticed many students struggle with basic cooking skills. How do essential cooking techniques like knife skills and meal prep specifically support the nutritional needs of seniors?	Essential cooking techniques directly support seniors' nutritional needs by enabling the preparation of healthy, well-balanced meals. Basic knife skills allow for proper cutting of vegetables and proteins, which is crucial for creating appropriate portion sizes and ensuring even cooking. Meal prep and batch cooking are particularly valuable as they help overcome common barriers seniors face, such as physical difficulties in daily cooking and reduced energy levels. These techniques enable the preparation of nutrient-rich meals in advance, ensuring seniors have access to proper nutrition even when they might not feel up to cooking. Additionally, proper steaming techniques help preserve nutrients in vegetables, which is essential since seniors need specific daily amounts of various nutrients, including vitamins C (80mg daily), D (800 IU), and essential minerals like calcium and iron.	['You can’t explore culinary nutrition without getting your hands a little dirty in the kitchen. With the explosion of cooking shows and celebrity chefs, home cooking has become intimidating for some of us. However, you don’t need to agonize over time-consuming cooking techniques and recipes – all you need are some culinary nutrition basics to get started, which allow you to eat well and support your health at the same time. These healthy cooking techniques and recipes are part of the foundation of the Culinary Nutrition Expert Program and they are very simple to master!\nESSENTIAL Cooking Techniques and Basic Cooking SKILLS\n- Basic Knife Skills\n- Meal Prep\n- Batch Cooking\n- Cast Iron Cooking\n- Slow Cooking\n- Steaming Vegetables\n- Using Veggies Root to Stem\nBasic Knife Skills\nYou don’t need to be lightning fast, but if you want to cook you should get comfortable with using a knife, one of the most handy and inexpensive cooking tools. Take your time practicing small, medium-sized and large cuts, which don’t need to be perfect. The more you practice, the easier mincing, dicing and chopping will be.\nMeal prep is one of the first skills we teach our students in the Culinary Nutrition Expert Program. Preparing ingredients, snacks, condiments and entire meals ahead of time makes it so much easier to stick to your healthy eating goals. With a few hours of prep, you don’t need to worry about what you’ll be eating all week long, saving you time as well as money in the process.\nMeal prepping and cooking is an investment in time, money and effort. Why not cook once, and then enjoy the spoils multiple times? Batch cooking, whether in large amounts to eat throughout the week or to freeze for later (or a mix of both of these things) is a lifesaver for busy days and tiresome days, when unexpected guests arrive, the holiday season, or when recovering from surgery, illness or childbirth.\nThis basic cooking technique involves frying ingredients over medium to high heat (preferably in a healthy cooking oil) to cook them quickly and achieve browning and flavour. Sautéing is the foundation for many meals, including soups, stews, one-pot meals and Instant Pot recipes.\nCast Iron Cooking\nCast iron is one of our favourite pans for cooking because it’s durable, retains heat well, is free of non-stick coatings, and is affordable. There is, however, an adjustment period to cooking with cast iron if you’re not used to it.\nGet Started Cooking With Cast Iron\nWhat could be easier than letting an appliance do all the work? Stick ingredients into a slow cooker and come home later to a warm, hearty meal. Slow cooking is almost foolproof and is totally delicious, especially on a blustery fall or winter day.\nSlow Cooker Inspiration\nFermentation is a traditional preserving technique that is great for digestive health, immunity and nutrient absorption. We teach a few fermentation basics in the Culinary Nutrition Expert Program, and for a more in-depth practice, check out our self-paced Fundamentals of Fermentation Course.\nSome of our favourite fermented foods that you can easily make at home at a fraction of the cost of store-bought options:\nRich in vitamins, minerals, enzymes and antioxidants, sprouts are an inexpensive food you can grow indoors. And they are so easy!\nOversteaming or overboiling vegetables saps them of nutrients, colour and flavour. Learn to create the perfect tender-crisp steamed veggies by:\n- using a stainless steel or bamboo steamer\n- cutting vegetables into equal sizes so they’ll cook evenly\n- steaming over medium heat until the veggies are just fork tender and bright in colour\nIt’s better to go by texture rather than time, as thicker vegetables like carrots or sweet potatoes will take much longer to steam than chard. Better to slightly under-steam them, as the residual heat of the steamer will help to finish things off if needed.\nUsing Veggies Root to Stem\nWe have a habit in North America of throwing out parts of vegetables that we could use for another purpose. Explore the root to stem approach to using vegetables, which includes leaving the skins on for certain veggies, saving scraps for broth, using the stems of dark leafy greens, like kale, for juicing or stir-fries, using a whole pumpkin, or freezing herbs in olive oil. Check out more zero waste cooking tips that will help you explore root to stem cooking here.\nInterested in learning more about essential cooking techniques and kitchen skills, and how you can take your passion for health to the next level? Check out our 14-week certification program that is 100% online. Click here to learn more.\nbaSic recipes to master\nVeggie Stock or Bone Broth\nVegetable stocks and bone broths are reliable, full of flavour, and can be used in many different recipes. We like making huge batches of stock and then freezing it so we always have some on hand. Once you master a basic broth, power up the culinary nutrition power of your broth with culinary adaptogens, herbs, spices and immune-supportive foods.\n- Recipe: How to Make Stocks and Broths\nHomemade Nut or Seed Milk\nThis staple liquid is perfect for smoothies, gluten-free baking, dairy-free elixirs, homemade chocolate desserts, soups and more. Homemade nut milk skips the refined sugars, stabilizers and preservatives, and is so customizable (chocolate milk anyone?).\nCooking Gluten-Free Grains\nThere’s more to gluten-free grains than just rice (though it’s good to know how to cook that well, too!). Explore using quinoa, buckwheat, millet, oats, sorghum, wild rice, amaranth and teff to add depth, flavour, nutrition and texture to your dishes.\nWhile most grains use a 2:1 ratio (2 cups water, 1 cup rice), some grains such as sorghum and wild rice usually require a 3:1 ratio. You’ll also need to use more water if you want a porridge-y, soupy texture.\nBlending a Smoothie\nTake your health to the next level with a dairy-free smoothie. You can pack way more nutrition into a blended beverage than you could likely eat in one serving if you ate everything whole. Check out our Best Smoothie Formula for smoothie building and blending tips, and try one of these 20 Best Dairy-Free Smoothie Recipes. Once you’re a skilled blenderist, try moving on to smoothie bowls for extra creativity and pizzazz.\nMastering Salad Dressing\nA good salad dressing takes your salad – or roasted veggies – from meh to wowza. Oils, acidity and herbs are the basis of a solid dressing, but there are also many flourishes you can use to add creaminess, texture or sweetness.\n- Learn: How to Make Salad Dressing\nCrafting Dairy-Free Elixirs\nSmoothies and juices aren’t the only healthful beverages – hot drinks like dairy-free elixirs can serve as a light meal or snack, while also supporting our health in a targeted way by incorporating healing herbs.\n- Learn: DIY Guide to Dairy-Free Elixirs\n- Recipe: 20 Best Dairy-Free Elixir Recipes\n- Recipe: Dairy-Free Gingerbread Latte\n- Recipe: Our Favourite Hot Chocolate Combinations\nBaking a Good Loaf of Bread\nA solid loaf of gluten-free bread is fantastic for avocado toast, plunging into dips and spreads, sandwiches, or tearing into salad croutons. Baking bread with gluten-free or grain-free flours can be tricky at first. We love this power-packed almond bread recipe (it’s a student fave too!). If baking bread seems intimidating, try an easy flatbread recipe instead.\nOnce you get the hang of some of these healthy cooking techniques, basic cooking skills and recipes, you’ll be cooking from scratch on the regular with confidence and pleasure.\nHeader Image: iStock/Magone', 'What are the best meals for seniors? This is a common question most senior citizens…\nPreparing healthy meals for seniors is not always easy. You may feel lazy to prepare even your meals after a long day. Instead, you end up taking on some junk food and call it a day.\nNow imagine how the elderly feel, especially those living alone. They may want to prepare some healthy meals, but they always face some constraints.\nAccording to a study conducted by WHO, a poor diet is one of the leading causes of old-age illnesses. One of the reasons is because their nutritional needs change, as well as their metabolism rates. Below are more reasons why malnutrition occurs in the elderly.\n- 1 What causes malnutrition for the seniors?\n- 2 Best Meals for Seniors\n- 3 A Word of Advice on Best Meals for Seniors\n- 4 Final Thoughts\nWhat causes malnutrition for the seniors?\nSome senses such as taste, touch, smell, and vision become less sharp as you age. It becomes a challenge to differentiate some tastes and odors thus reducing your appetite.\nSince you may not be able to smell as you used to, you may mistake stale food for fresh food, leading to food poisoning and many other health complications.\nMedication Side effects\nIn most cases, you may be under some medication for other illnesses. One common side effect of the pills is the loss of appetite. Other side effects that may cause you to detest food include nausea and the inability to taste the food.\nMost chronic diseases cause physical difficulties in seniors. Also, as you age, your muscles and your heart becomes weaker. It becomes difficult for them to carry out even simple tasks such as peeling fruits, cooking, or even walking to the store. Considering the difficulty you may experience, especially when it’s raining and snowy, may prevent you from traveling to the store to get some groceries.\nLack of Finances\nSince you may not be receiving a big paycheck as you did when you were working, you may not have enough money to purchase some of the ingredients. You may resort to cheaper food, which may be detrimental to your health in the long run.\nDeteriorating dental health\nSome common issues associated with aging include the loss of teeth, weak gums, painful jaws, and several other dental health problems. They may not be able to chew essential foods such as meat, fruits, among others.\nSome diseases, such as Alzheimer’s and Dementia, lead to memory loss for seniors. They may forget to take medication, prepare a healthy meal as instructed by the doctor, or even skip a meal altogether. It’s a common fact that most seniors skip at least one meal in a day, making it hard for them to meet their nutritional goals.\nThere are many reasons why you, as a senior, may feel depressed. Your kids may have settled far away, or you may have lost a spouse or a close friend to death. Living alone isn’t that appealing either. All these issues lead to depression, making it difficult for you to focus on essential matters such as eating healthy food. Besides causing the loss of appetite, depression has many other detrimental effects to people across all age brackets.\nBest Meals for Seniors\nWhether you’re a senior looking for meal ideas to keep you healthy or a caregiver looking for ideas for make-ahead meals for seniors, below are some of them. Whichever ingredients you choose, you should ensure that you serve a balanced meal. That is, it should include carbohydrates such as rice, proteins such as beans, and fruits. Below are some of the nutrients that are essential for seniors’ health. And the foods that have a lot of them.\nA healthy meal for seniors should include a considerable amount of carbohydrates. The low carb diet may be famous, but it’s not the best for the elderly. Also, you should avoid sugary foods. Instead, aim for natural sources of carbs such as Irish potatoes, sweet potatoes, and brown rice. Corn and potatoes are the best, especially for starch.\nOther foods such as fruits, dairy products, and legumes such as beans are also sources of carbohydrates. Carbohydrates are essential for they contain fiber, which aids in digestion, preventing issues such as constipation for the seniors. Carbs are also good sources of energy, and they improve the mental state of the elderly.\nSince excessive salts and fats from proteins are detrimental for seniors, eating carbs can help them minimize their intake. Also, since seniors may forget to take their meals, serving them with carbs keeps them energized and with fewer food cravings throughout the day.\nThe elderly should consume at least 130 g of carbs per day.\nProtein foods are vital for the elderly. By including a lot of them in their meals, they help maintain muscle mass and strength and maintain bone health. Proteins also help maintain “functioning” for seniors. As they age, they may not be able to do some activities like getting out of bed or clothing themselves. Proteins ensure that they remain functional even in old age. The most common sources of proteins include;\n- Lean meats (beef, pork, mutton, bacon)\n- Dairy products (milk, cream, cheese\n- Legumes such as beans\nThe ideal amount of protein for a senior should be at least 0.8 g of protein per kg (2.2 lbs.) of weight.\nCalcium is one of the most abundant minerals in the human body. It’s mainly found in bones and teeth. If you don’t consume enough of it, your body extracts it from your bones, causing them to be weak, also known as Osteoporosis, and it’s common among the elderly.\nCalcium is also essential in other functions such as the excretion of hormones, nerve transmission, and vasodilation. Consuming enough of it is known to prevent your bones from fracturing, Diabetes, and Osteoporosis.\nFoods rich in calcium include;\n- Dairy products such as milk, cheese, and yogurt\n- Fishbones such as those from Sardines and Salmon\n- Vegetables such as cabbages and broccoli\n- Soybeans such as Tofu and Edamame\n- Seeds such as sesame, poppy, and chia\nSeniors should consume 1000 mg to 1200 mg of calcium per day.\nOmega-3 Fatty Acids\nOne inevitable effect of old age is cognitive decline, where the elderly may fail to remember some stuff, or have trouble learning and making important decisions. Well, Omega-3 Fatty Acids are known to slow down this decline.\nThey also prevent inflammation, hypertension, platelet aggregation, cancer, and other medical conditions that may result from gene expression. Omega-3 fatty acids also help the elderly deal with Dementia, anxiety, and depression.\nFoods rich in Omega-3 fatty acids include;\n- Fish such as Sardines, Tuna, Salmon, and Mackerel\n- Leafy vegetables like Spinach\n- Canola Oil\n- Chia seeds and Flaxseeds\nA senior should consume at least 250 mg of omega-3 per day to stay healthy.\nIron is vital in a human body as a protein, and it also facilitates the production of hemoglobin, which ensures a supply of oxygen to your body tissues. The elderly need iron in their diet since some factors lead to an iron deficiency in their bodies. These factors include a high calcium intake, low Vitamin C intake, and chronic diseases. A deficiency in iron could lead to anemia.\nHere are some of the foods rich in iron;\n- Organ meats such as kidneys, liver, and the heart\n- Legumes such as lentils, beans, and peas.\n- Pumpkin seeds\n- Fish such as Tuna\n8 mg of iron per day is enough to keep the elderly healthy.\nVitamin C enhances the body’s immune system by facilitating the production of white blood cells. Since the elderly are more susceptible to diseases, Vitamin C can help ward off these diseases. Besides facilitating the creation, it also prevents their damage by disease-causing elements.\nThe following foods contain Vitamin C;\n- Sweet potatoes\n- Red pepper\n- Snow peas\n- Orange juice\nA senior should consume at least 80 mg of Vitamin C daily.\nVitamin D is essential for seniors, for it helps prevent bone fractures, Osteoporosis, diabetes, cancer, and cardiovascular problems. It also facilitates the uptake of calcium into your body. Sunlight is a good source of Vitamin D. Other sources include;\n- Fish, e.g., Tuna\n- Organ meat such as liver\n- Fortified soy and cow milk\nSeveral supplements can help you achieve your daily Vitamin D intake. An 800 IU (International units) per day is the recommended intake for seniors.\nOther nutrients that you will get from most of these foods include potassium, which helps prevent kidney stones, Vitamin B12, and magnesium. A senior should consume at least 4700 mg of potassium per day.\nA Word of Advice on Best Meals for Seniors\nThere are millions of recipes out there to prepare a healthy meal for a senior. Most of them differ based on the regions you are from and the availability of the ingredients. The above review helps you identify which foods to include to achieve a balanced diet. If the foods available in your region aren’t listed above, you can consult a nutritionist on the nutrient levels of the specific food.\nIf you’re a caregiver, you can prepare make-ahead freezer meals for the seniors you’re taking care of. First of all, choose a recipe from reputable blogs and channels. Using the details above, you can adjust the recipe to include the healthy items, and adjust the servings to the amounts that your loved one should eat in a day.\nTo make their life more comfortable, you can cook a lot of different meals and store them in a freezer. Do not store all of the food in one container; package it into small packs that he or she can finish in a single meal. Zip-lock bags, muffin tins, and glass jars are some of the ways that you can store the meals in a freezer.\nSeniors may have trouble meeting their nutrition goals for several reasons, including memory loss, medication side effects, reduced sensitivity, poor dental health, depression, among many other issues.\nFrom the several recipes available, it’s essential to make sure that the meals you prepare for seniors have the right amounts of carbs, proteins, Vitamin C, Vitamin D, fiber, iron, and other nutrients. Since it’s hard for them to cook, you can also prepare make-ahead meals enough to serve them for days and conveniently store them in a freezer.']	['<urn:uuid:95cdba16-970d-425c-b00b-3e6a3f4db657>', '<urn:uuid:3c7eac80-188b-4d06-97a4-33f5673ecf85>']	open-ended	with-premise	verbose-and-natural	similar-to-document	three-doc	expert	2025-05-01T23:21:14.341336	31	128	3010
331	seed growing temperature germination requirements	Most perennials, annuals and vegetable seeds germinate best when kept at a temperature between 65 and 75 degrees Fahrenheit. After seedlings sprout, they need a good amount of light until they are strong enough for planting in the garden.	['Propagating crops means creating new crops from current specimens, and is a vital a part of permaculture. It means you can have a self-sustaining website; you’ll be able to protect native, indigenous and heirloom species, and reduce the price of shopping for seeds, seedlings or new crops. There are a number of strategies that gardeners use to propagate crops.\nSeeds are the pure means flowering crops reproduce. The crops produce flowers, which both comprise each female and male elements (stamens and pistils, respectively) in a single bloom or have separate flowers for the female and male organs. The flowers get pollinated when pollen is transported from one plant’s stamen (male organ) to a different’s pistil (the feminine equal). This may happen by way of the wind or, extra generally, by bugs visiting the crops and inadvertently carrying pollen off to a different plant. (It’s to draw these pollinating bugs that flowers are colored, formed and perfumed in numerous methods, in addition to offering nectar.) As soon as this occurs a seed develops within the feminine elements of the plant.\nRising crops from seeds is among the best strategies of propagating species. You should buy seeds cheaply, but in addition harvest them from a longtime backyard or supply them from a seed financial institution. Seed may also be saved within the fridge, generally for years, till you’re able to plant it. Nevertheless, some crops can take a very long time to mature from seed to grownup.\nTo develop crops from seeds, the most typical technique is to plant them in containers with a rising medium freed from dangerous bugs and pathogens. A small quantity of compost may help, however most significantly the containers and soil should drain nicely as waterlogging is dangerous to seed improvement.\nAs a normal rule, plant the seeds at a depth 4 occasions that of the scale of the seed (though, some crops require floor sowing) and maintain moist however not damp. Nearly all of perennials, annuals and vegetable will germinate greatest when saved at a temperature between 65 and 75 levels Fahrenheit. When seedlings sprout give them a great quantity of sunshine till they develop sturdy sufficient for planting within the backyard.\nOne other technique obtainable to permaculturists to propagate crops from their backyard is tasking a chopping. This implies chopping off a stem from a residing plant and permitting it to develop its personal root system. Take cuttings from wholesome stems with no flower buds on them, and reduce at a 45-degree angle in order that the potential rooting floor is maximized.\nMost plant cuttings have to be planted in a soil-less posting combine, one which drains nicely, and positioned in a heat place. Most like direct sunshine for a minimum of a part of the day. When you need to keep away from the soil getting waterlogged, cuttings usually profit from elevated humidity. You possibly can obtain this by putting the chopping in a plastic bag or cowl with a glass container. All being nicely, new roots ought to start to type after 4 weeks or so, and may be transplanted to bigger containers or a sheltered nursery spot within the backyard.\nGrafting is a extra superior technique of propagation, and entails the splicing of a stem from one plant onto the foundation system of one other. The tissues of the 2 crops will then fuse, permitting the stem to learn from the vitamins and water being absorbed by the rootstock.\nWhereas completely different crops might require variations, the final technique of grafting is to pick a wholesome stem that accommodates a minimum of one bud, and reduce it on the diagonal. Make an equal diagonal reduce within the rootstock (these diagonal cuts will increase the floor areas involved with each other and so assist to create a stringer joint) and insert the stem. Bind with tape or twine in order that the stem and rootstock stay involved (keep away from grafting in areas susceptible to excessive winds). Graft in the beginning of spring and the brand new stem ought to start rising inside round a month.\nBudding is a type of grafting. Quite than utilizing a stem, a single bud is taken from one plant and grafted into the rootstock of one other. An analogous approach is required to grafting, with the bud inserted right into a reduce within the rootstock. Usually, a ‘T’ formed reduce is made within the rootstock and the bud, hooked up to a small rectangle of stem is slipped inside. The bud then must be taped up.\nFor budding, select mature buds for one of the best likelihood of success, and for many crops, carry out the process as fall turns to winter. That means, your bud ought to develop when spring comes round. Budding is usually used to propagate fruit species.\nPropagation by division entails separating a complete plant into a number of smaller items, every of which might then change into new, impartial crops. It really works greatest with mature specimens and, certainly, may help extra mature crops to have an extended energetic life. It additionally gives extra crops to make the most of in numerous areas of the backyard or in numerous guilds. Division is usually used for species whose roots develop in clumps or crowns, and so provide apparent dividing factors. These embody many ferns and bamboos.\nA number of days earlier than dividing a plant, water it completely. This reduces the stress on the plant. Dig across the perimeter of the plant and extract it from the bottom. Use a pointy blade to separate the foundation into items (there’ll normally be apparent ridges or grooves that lend themselves to division) and place every in a bucket of water. Plant every new specimen in a gap as deep because the one from which you took the unique plant. Add some compost to assist them get established, and water nicely. Divide both early in spring or early in fall, to provide the brand new crops time to ascertain themselves earlier than the warmth of summer season or chilly of winter. Add mulch to feed and shield the brand new crops, but when planting in spring, enable some house across the new stems so the soil is ready to get warmed.']	['<urn:uuid:e2d4c1b9-2705-4657-8a2f-631d7a4cbec1>']	open-ended	direct	short-search-query	similar-to-document	single-doc	expert	2025-05-01T23:21:14.341336	5	39	1045
332	heart attack treatment ems hospital options	Heart attack treatment begins with Emergency Medical Services (EMS) providing initial care before reaching the hospital. EMS can perform 12-lead EKGs in the field for accurate diagnosis. At the hospital, treatment options include cardiac catheterization to check blood flow and percutaneous coronary intervention (PCI) which includes procedures like angioplasty, stenting, or atherectomy to open blocked arteries. PCI has shown lower 30-day mortality rates compared to clot-busting drugs. For optimal results, patients should be transferred to a PCI-capable center within 2-3 hours of initial hospital arrival.	"['UPMC’s Department of Prehospital Care is designed and tasked to support the regional Emergency Medical Services community in the provision of high quality patient care through collaborative educational programming, medical direction, communications, consultation, and research. Our motto is “Helping EMS Help Others.” As part of UPMC Prehospital Care, we work collaboratively with prehospital care providers and agencies to help assure the highest quality of emergency care is available to those who need it.\nPrehospital care refers to any emergency medical care a patient receives prior to their arrival at the hospital or emergency department. Typically, this care comes from Emergency Medical Services (EMS) providers.\nEmergency Medical Services refers to the agencies and personnel who are there to provide prehospital emergency care and rescue services to victims of injury and illness. Typically, this means a local ambulance service staffed with Emergency Medical Technicians (EMTs), paramedics, and sometimes specially trained nurses and physicians. This also includes similar emergency responders and support staff, such as first responders from the local fire or police department, who may arrive on the scene before the ambulance to help assess the situation and stabilize the patient.\nIn the spring of 1996, UPMC Mercy pioneered a bold program to treat heart attack victims aggressively. UPMC Mercy was the first hospital in the area to train and enable EMS to do 12-lead EKGs in field settings, thus providing a more accurate and complete diagnosis for those with potential heart emergencies. Administration of “clot-busting” drugs had been accepted as the standard of care for treating these patients. These drugs, however, can take several minutes to work, sometimes don’t work at all, and many patients cannot receive them because of contraindications or the potential for harmful side effects.\nInstead of giving these drugs, through the use of EMS-obtained 12-lead EKGs, we minimized the amount of time spent in the Emergency Department and expedited the patient’s delivery to UPMC Mercy’s Cardiac Catheterization Lab for angioplasty, thereby saving precious time.\nIf you would be interested in learning more about this program or would like to discuss having a 12-lead EKG training class for your emergency medical service, call 412-232-5855.\nEducation plays a major role in achieving and maintaining quality performance. With that in mind, UPMC Prehospital Care believes education needs to be a strong component in any prehospital care system.\nUPMC Prehospital Care addresses the educational needs of EMS services in our medical command system through dedicated, full-time EMS education specialists, who provide numerous educational opportunities — both at UPMC Mercy and at off-site locations. In this way, UPMC Prehospital Care helps EMS providers enhance their knowledge regarding best practices in patient care and to fulfill their continuing education requirements.\nEducational offerings are numerous and diverse. Previously presented topics have covered a wide variety of issues or interest and relevance to local EMS providers, including:\nAutomated External Defibrillator (AED), Cardio Pulmonary Resuscitation (CPR), Advanced Cardiac Life Support (ACLS), and Pediatric Advanced Life Support (PALS) certification and re-certification programs also are offered on a regular basis.\nPre-registration is required for all classes.\nFor more information, call 412-232-5855.\nEMS agencies use a medical command center as a base of operations, whereby a certified medical command physician can be contacted for online consultation relative to direct patient care matters.\nUPMC Mercy’s medical command system directly supports various EMS agencies throughout the tri-state area, including:\nUPMC Mercy’s EMS medical director, an Emergency Department physician, ultimately is responsible for all medical care provided by the EMS agencies that have a relationship with UPMC Mercy’s medical command system. In this capacity, the medical director interviews paramedics who wish to have medical direction through UPMC Mercy, monitors quality assurance, and serves as the liaison with all of the medical command physicians at UPMC Mercy.\nWhen an EMS provider is called to an emergency, they will have direct contact with our UPMC MedCall to facilitate fast, efficient communications with physicians at UPMC Mercy.\nThe UPMC Prehospital Care Department consists of experienced prehospital care and education professionals.\nFor more information about UPMC Prehospital Care, contact:\nUPMC Mercy Prehospital Care\n1400 Locust St.\nPittsburgh, PA 15219\nUPMC Prehospital Care Department\n230 McKee Place\nSuite 911, Fourth Floor\nPittsburgh, PA 15213\nPhone: 1-888-647-9077, Ext. 1', 'Medical management following myocardial infarction\nBesides supplemental oxygen for at least six hours post MI and bed rest, and continuous electrocardiography monitoring for at least 12 hours post-MI, consider the role of primary percutaneous revascularization and intra-aortic balloon pump support for some patients.\nCardiac catheterization provides an effective way to check blood flow in the coronary arteries. Consider early cardiac catheterization during hospitalization for patients with recurrent symptoms, serious complications, or other serious high-risk features (i.e. hypotension, congestive heart failure, recurrent chest pain).\nNumerous studies support the use of cardiac catheterization to aid post-MI recovery.\nConsider prompt transfer to a referral center for primary percutaneous coronary intervention (PCI) as an alternative to thrombolytic therapy in experienced centers, particularly in patients with ST-segment elevation, new LBBB, or true posterior acute MI. PCI is associated with a lower 30-day mortality rate and lower risk of hemorrhagic stroke compared with thrombolytic therapy. Note that the beneficial effects of transfer for PCI are contingent upon transfer within two to three hours of initial hospital arrival.\nIf any coronary arteries are blocked, PCI using a catheter, guide wire, and balloon opens them and improves blood flow. The three most common types of PCI are:\n- Angioplasty - uses balloons to widen and increase blood flow in blocked arteries, resulting in decreased angina and heart attack risk and increased ability for physical activity.\n- Stenting - a wire tube often inserted during angioplasty to hold open the artery improve blood flow. Reclosure of the artery is less likely when a stent is used.\n- Atherectomy - similar to angioplasty, using a rotating, shaver-tipped catheter or laser beam to remove plaque and open the blocked artery.\nThe American Heart Association\'s practice guidelines advise that cardiac catheterization with subsequent percutaneous or surgical revascularization is appropriate in patients with recurrent ischemic-type chest discomfort. Numerous studies support the use of cardiac catheterization to aid post-MI recovery. For example, recent studies showed that an early invasive approach (i.e., cardiac catheterization within four to 48 hours after presentation) vs. a conservative approach in combination with a GP IIb/IIIa inhibitor in patients with non-ST-segment elevation MI or unstable angina significantly reduces major cardiac events.\nFurthermore, consider placement of an intra-aortic balloon pump (IABP) during cardiac catheterization in specific subsets of patients, such as those with refractory post-MI angina, for stabilization before angioplasty and revascularization or cardiogenic shock. The IABP reduces afterload during systole and increases coronary perfusion during diastole. Studies have shown that in selected patient populations, IABP significantly improves survival rates.\nSee chart, ""Risk Stratification and Management of Patients With Acute Coronary Syndrome,"" from PIER\'s module on acute coronary syndromes.\nExercise Stress Testing\nUse exercise stress testing for prognostic assessment in stable patients post MI without high-risk features, such as hypotension, CHF, recurrent chest pain or inability to exercise. By doing stress testing early post-MI, the clinician can assess functional capacity, evaluate efficacy of the patient\'s current medical regimen, and risk stratify the patient according to likelihood of future cardiac events.\n- Consider an exercise treadmill test with or without radionuclide imaging if the patient can exercise, and a pharmacologic stress test if the patient cannot exercise.\n- Obtain a submaximal stress test four to seven days post MI or a symptom-limited exercise test at 14 to 21 days post-MI. A submaximal protocol has a predetermined endpoint of a heart rate of either 120 bpm, 70% of predicted maximum heart rate, or a peak MET level of 5. A symptom-limited test continues until the patient shows signs or symptoms that require the test to be terminated (i.e. angina, fatigue, ST-segment depression > 2 mm, ventricular arrhythmias, or > 10 mm Hg drop in systolic BP from baseline).\n- Consider the addition of imaging (myocardial perfusion or echocardiography) to improve the sensitivity and specificity of the test.\nPredictors of future adverse events in post-MI patients include inability to exercise, exercise induced ST-segment depression, failure to achieve five METs during treadmill testing, and failure to increase systolic blood pressure by 10 to 30 mm HG during exercise.\nNote that the AHA guidelines recommend concomitant nuclear imaging when baseline abnormalities of the ECG limit interpretation, and there is some evidence that nuclear imaging can also aid in further risk stratification. In one study, stable post-MI patients underwent assessment of LV function and had adenosine tomography done early (5±3 days) after infarction. Cardiac events occurred in 30 (33%) of 92 patients over 15.7 ± 4.9 months. Independent predictors of all events were quantified perfusion defect size (P<0.0001), absolute extent of LV ischemia (P<0.000001) and ejection fraction (P<0.0001). The results suggested that risk stratification of individual patients early after infarction is possible based on the extent of ischemia and severity of LV dysfunction.\nStrongly encourage patients to participate in a cardiac rehabilitation program to prevent recurrent heart attacks. Cardiac rehabilitation programs should include:\n- Exercise training\n- Strategies for reducing modifiable risk factors for cardiovascular disease, including managing lipid levels, diabetes, blood pressure and weight\n- Nutritional and smoking cessation counseling\n- Encouragement to adhere to prescribed drug therapy\n- Psychosocial and vocational or occupational counseling\n- Baseline and follow-up patient assessments\nExercise training alone can improve blood vessel function, cardiovascular risk factors, improved coronary blood flow, and electrical stability of the heart muscle while also reducing the risk of blood clots and cardiac work and oxygen requirements. Research has shown that average cardiac death was 26% lower in rehabilitation patients who were exercise-trained compared with those who received usual care, and there were also 21% fewer nonfatal heart attacks, 13% fewer bypass surgeries and 19% fewer angioplasties in the exercise-trained people, according to an updated scientific statement in 2005 from the American Heart Association.\nCounsel all patients who smoke to quit. Studies have shown that smoking triggers coronary vasospasm, reduces the anti-ischemic effects of beta-blockers, and doubles the risk of death after MI. Consider referring patients to a smoking cessation program and prescribing nicotine replacement therapy. Combining pharmacotherapy with behavioral therapy increases cessation success rates.\nA heart healthy diet is recommended to reduce LDL and blood pressure. Heart healthy diet guidelines include:\n- limiting total calories from fat to < 30% or less of the day\'s total calories.\n- limiting total calories from saturated fat to 8-10% of the day\'s total calories.\n- limiting cholesterol intake to < 300 milligrams per day.\n- limiting sodium intake to 2,400 milligrams a day.\n- consuming just enough calories to achieve or maintain a healthy weight and reduce blood cholesterol level.\nAmong patients who drink alcohol, moderate consumption is advised. To assist with dietary changes, consider referring patients for consultation with a registered dietitian.\nProvide patients with specific instruction on the type and level of activity that is permissible. Activity may be beneficial to patients\' cardiovascular and emotional health.\n- Encourage daily walking immediately after hospital discharge.\n- Follow driving regulations depending on applicable state laws.\n- Counsel that sexual activity can be resumed in stable patients within seven to 10 days.\n- Individualize instructions regarding strenuous activity, such as heavy lifting, climbing stairs and yard work, to each patient based on results of exercise testing.\nNote that no randomized clinical trials have assessed when to resume normal activity, however the ACC/AHA guidelines are in accordance with the above recommendations.\nTalk with patients about the fact that heart attack patients feel a wide range of emotions including depression, fear, and anger, for about two to six months post-MI. The emotional aftermath of MI can be disruptive to returning to normal life, and may require counseling or other intervention. Consider screening for depression in all patients post-MI. Studies indicate that about 20% of patients experience depression after acute MI and that the presence of depression is associated with increased risk for recurrent hospitalization and death.\nInternist Archives Quick Links\nFenway Guide to Lesbian, Gay, Bisexual, and Transgender Health, 2nd Edition\nThis new edition reflects recent clinical and social changes and continues to present the important issues facing practitioners and their LGBT patients. Read more about the Guide. Also see ACP’s recent policy position paper on LGBT health disparities.\nJoin Us in Washington, DC for the Most Comprehensive Meeting in Internal Medicine\nRegister now and enjoy:\nDiscounted rates, the best national faculty, a wealth of clinical and practice management topics and hands-on sessions! Learn more about the meeting.']"	['<urn:uuid:3a6ee534-6842-4a12-a13d-5cdc3f69f196>', '<urn:uuid:487c77a3-6467-47e9-8f95-05a083936b5f>']	open-ended	with-premise	short-search-query	similar-to-document	three-doc	novice	2025-05-01T23:21:14.341336	6	85	2088
337	manufacturing process monitoring tools applications	Raman spectroscopy serves as a vital process monitoring tool in both semiconductor manufacturing and bioprocessing. In semiconductor production, it enables measurement of mechanical stresses during wafer processing, with applications in process optimization and quality control. In bioprocessing, it allows real-time monitoring of various parameters including glucose levels, cell density, and product concentration, enabling process control and corrections from deviations in real-time while reducing contamination risks through its non-invasive nature.	['Driven by commercial considerations as well as technical needs, two trends presently dominate R&D in modern power semiconductor (SC) manufacturing: increasing wafer diameters and decreasing substrate thicknesses, down to a few 10 µm. With this, mechanical stresses in the material increasingly become a tangible problem, with consequences ranging from wafer deformation, which poses a manufacturing and handling problem, to the in-use failure of the devices in the worst case.\nWith stresses being introduced all along the processing chain, e.g. in layer deposition and structuring, mechanical or chemical wafer thinning, or the final chip separation process, this creates an urgent and concrete need for a method capable of directly and rapidly measuring absolute mechanical stress in silicon - preferably in a contact-free mode.\nFrom theory to the real world scenario\nThe competence centre ASSIC’s research team around DI Martin De Biasio and Dr. Martin Kraft from CTR and Dr. Michael Roesner from In-fineon Technologies Austria could identify micro Raman spectroscopy (RS) as an optical meas-urement method meeting all these requirements.\nRS is known to be capable of measuring stress in various materials, including silicon, with a wealth of related literature on re-search applications investigating e.g. local stress introduced by underlying structures. Still, despite the inherent advantages of this fast, non-destructive, optical and hence contact-free method, RS has not (yet) been accepted as a reliable method in industrial SC fabs.\nThe key purpose of this work was hence to investigate and validate RS as a dependable tool for spatially resolved quantification of absolute stress levels for the use in SC manufacturing process development, optimisation and control. The prime measurand in the determination of stress(es) in silicon by RS is the relative shift of the triply degenerated Raman-active Si phonon peak at 520.5 cm-1 by ~ 1.95 cm-1/GPa.\nTensile strain shifts the centre wavelength to lower frequencies, while compressive stress results in a higher centre frequency. Concerns regarding the method included i) stability and sensitivity of the measurements, ii) the impact of the excitation laser wavelength on the penetration depth, and thus the readout, and the iii) reliability of measurements, especially when applied to entire production-scale wafers.\nThe laboratory Raman micro-spectrometry system used (Renishaw InVia) was hence first applied to a stress-free silicon sample held under perfectly controlled conditions in a specially developed bending device. With an analytical accuracy of ±25MPa and an excellent agreement of the measured values with stress levels derived from analytical calculations and FEM simulations, the method exceeded expectations.\nThe one major interferent is the temperature, which has to be held possibly constant for reliable and sensitive measurements. The optimised and thus validated method was subsequently used as a (standard) tool to support a range of SC processing research activities. One current key R&D interest is the impact of surface processing methods on residual stress-es in the material.\nOnly indirectly accessible until now, the evaluation of the directly measured, absolute stress levels by Raman spectroscopy showed a clear impact of the processing method and parameters. This process step may introduce surface stresses of up to 250 MPa, even with process parameters deemed standard and safe. Furthermore, the type and the levels of dopant(s) present in the material have a surprisingly strong impact, a finding that has now initiated related materials research.\nAnother interesting effect could be observed in the Raman spectra of mechanically diced samples. Raman bands relating to silicon metaphas-es were found, indicating a substantial change in the crystalline structure. This effect could be related to the high pressures occurring during silicon dicing with cutting diamonds, which cause the observed metamorphosis of the top-layer Silicon.\nImpact and effects\nWith the introduction of Raman spectroscopy as a non-destructive, reliable, fast and contact-free method to R&D in semiconductor processing, CTR and Infineon have established a metrology tool capably of reliably measure mechanical stresses, both on small scales like dicing edges and across entire silicon wafers. The measurement system can distinguish and quantify tensile and compressive stresses from 0 MPa up to the material’s breakdown strength with an analytical accuracy of ±25MPa.\nThe established measurement tool has a direct practical impact for industrial process and quality control, as well as providing vital, dependable information to researchers and engineers for semiconductor manufacturing process optimization. Based on this, subsequent activities now target other seminal semiconductor materials, including silicon carbide (SiC).', 'The release of the FDA’s guidance on process analytical technology (PAT) for the biopharmaceutical industry has encouraged the industry to gear towards adaptive processes that ensure consistent product quality through advanced control strategies. Adoption of PAT has become very crucial as the bioprocess industry has grown rapidly over the past two decades . The development and optimization of bioprocesses are now more analytical as several new technologies, including Raman spectroscopy, enabled accurate and detailed real-time monitoring of bioprocesses. One of the novel non-invasive real-time process monitoring techniques that boomed is spectroscopy and – more specifically – optical spectroscopy, as more powerful light sources (mainly lasers) and reliable detectors have been developed.\nPlease download our Raman Spectroscopy Technology Introduction for a quick introduction to the technology, common upstream and downstream applications in bioprocessing, and Tornado Spectral Systems’ high-throughput virtual slit technology principles and its advantages.\nWhat is spectroscopy?\nSpectroscopy is the study of the interaction between matter and electromagnetic radiation as a function of wavelength of the radiation. There are different branches of spectroscopy based on the type of electromagnetic radiation that the matter interacts with.\nOptical spectroscopy is a subset of spectroscopy, and it is often employed as an analysis technique to measure the interactions of different wavelengths of light with matter to determine the physical and chemical properties of the sample with which light is interacted, hence it provides a unique “fingerprint” for different atomic, molecular, and crystal structures in a sample . Variations in the atomic and molecular structures result in different spectroscopic fingerprints, and optical spectroscopy can be used to identify and quantify these structures.\nOptical spectroscopy can be divided into several branches as well, but the most employed classes in the bioprocessing field are\n- Luminescence spectroscopy,\n- Absorption spectroscopy (including NIR spectroscopy), and\n- Raman spectroscopy (Spectroscopy using the inelastic scattering of photons).\nSpectroscopic Techniques: Introduction to Spectroscopic Methods of Analysis in Bioprocessing\nThe most common method of luminescence spectroscopy is fluorescence spectroscopy, where the fluorophore is excited to a higher energy state by an incident photon and then emits light at different wavelengths than the incident wavelength by dropping to a lower energy state. Different fluorophores have different emission spectra, and this method can collect information on fluorescent compounds in the sample.\nAbsorption Spectroscopy (NIR Spectroscopy, UV/Vis Spectroscopy)\nThe most common method of absorption spectroscopy is near-infrared spectroscopy (NIRS or NIR spectroscopy). The absorbance of incident light in the near-infrared region of the spectrum (wavelengths from 780 nm to 2500 nm) differs from molecule to molecule, which yields a unique spectrum within the NIR region of light due to Beer-Lambert Law that relates the attenuation of light to the absorptivity and concentration of the sample through which the light is traveling.\nNear-infrared spectroscopy instrumentation measures combinations and overtones of molecular vibrations generated due to the change in dipole moment of a molecule with covalent hydrogen bonds (C-H, O-H and N-H bonds). The changes in the dipole moment of covalent hydrogen bonds result in broad and overlapped bands as typically there are multiples of these bonds . Even though NIR spectroscopy has advantages such as a cheaper NIRS device or measurement equipment with the ability to measure absorption through thick container walls thanks to longer path length and much higher signal level for the same number of photons resulting in low exposure times, NIRS does not generate the same level of molecular specificity compared to Raman spectroscopy, which we will discuss next.\nAvailable through PROAnalytics: Prozess Reveal NIR Analyzer\nAnother common method of absorption spectroscopy is UV/Vis (ultraviolet/visible light) spectroscopy. UV/Vis spectroscopy is also called UV/Vis spectrophotometry. UV/Vis spectroscopy utilizes the ultraviolet and visible ranges of light spectrum, which typically consist of 200 nm – 800 nm range of spectrum. The molecule of concern changes electronic energy state due to absorption of light within UV/Vis range of spectrum.\nIn order for the absorption to happen, the energy of the incident light must match the energy of a possible transition between electronic energy states of the molecule. The transition happens from a lower energy state to a higher energy state, called excited state. Since different bonds have different energy states, the absorption occurs at different wavelengths of light for different molecules, resulting in different absorbance curves. The degree of absorption is also critical to determine the concentration of the sample, hence quantification of the sample.\nUV/Vis spectroscopy and fluorescence spectroscopy are complementary methods, as fluorescence spectroscopy measures transitions from higher electronic energy states to ground electronic energy state, whereas UV/Vis spectroscopy measures from lower electronic energy states to higher electronic energy states. For more information on UV/Vis, please read our article, “Introduction to UV/VIS Spectrophotometry: Using Spectrophotometer To Determine Concentration.”\nRaman Spectroscopy (Light Scattering Spectroscopy)\nWhat is Raman spectroscopy?\nWhen incident light scatters from the material that it interacts with, the vast majority of the photon scattering happens elastically, which is called Rayleigh scattering. Raman spectroscopy measures the tiny proportion of the photons that are scattered inelastically.\nThe vibrational state of a molecule can be excited to an energy level above ground state by a photon that loses energy during the Stokes scattering event, or the photon that scatters can gain energy from the drop of vibrational state of the molecule which is called anti-Stokes scattering. These two scattering events are the core of Raman spectroscopy, and Raman spectroscopy yields information of the molecular structure of the sample.\nHow do Raman and infrared (IR) spectroscopy differ?\nRaman spectroscopy is a complementary method to NIRS as it measures a different spectrum of the molecule. NIRS measures the change in dipole moment during the molecular vibrations causing absorption, whereas Raman spectroscopy measures the change in polarizability during molecular motions.\nThis makes Raman spectroscopy inherently advantageous to measure analytes/metabolites in aqueous solutions/environment as the inelastic scattering spectrum of polar molecules are less efficient than nonpolar ones and the Raman spectrum of water is weaker compared to NIR absorption of water. The weakness of the Raman spectrum of polar molecules results in less interference from polar molecules such as water in the band of concern and facilitates the bioprocess monitoring, cell culture media, and protein analysis.\nRaman spectroscopy typically requires multivariate data analysis models to be able to work within the intended application. Various denoising and smoothing filters, baseline, spike and scatter corrections, and normalization methods are used to preprocess the experimental Raman spectra data.\nThen, calibration and validation data sets are created from the experimental data. Root mean square error on the calibration data and root mean square error on the prediction data are important parameters to check the validity of the model that is built, minimizing these errors with the created model is the goal. Partial least squared, principal component analysis, artificial neural networks and net analyte signal algorithms are commonly employed for the predictions.\nApplication of Raman Spectroscopy in Bioprocessing\nProcess Analytical Technology in Upstream Processing\nThe ability to monitor and control a bioreactor environment is of critical importance to ensure minimal or no deviation from the upstream process strategy as deviations could lead to changes in the properties of molecule. There are four classes of measurements to achieve this objective:\n- Atline, and\nAccurate inline and online measurements provide real time or near real time data. By comparing the targets (or setpoints) to the instantaneous measurement data provided by accurate inline and online measurements, one can take corrective measures to eliminate deviations from the control strategies.\nBoth atline and offline measurements require sample removal from the reactor to measure parameters by a distant analyzer. Atline measurements refer to the measurements done by analyzers that are close to the reactor, getting measurement data in minutes to hours. Offline measurements result in even longer delays in processing the sample . Hence, in-process control strategies can only be enabled by inline/online measurements.\nSome important parameters to measure are cell viability, viable cell density, glucose, amino acid, and product concentration.\nAnalytical Application of Raman Spectroscopy in Upstream Processing\nThe final goal of PAT is to integrate different aspects of bioprocessing, such as chemical, physical, mathematical, and biological analyses. Spectroscopic methods are one of the most employed PAT tools, and Raman spectroscopy with the relevant mathematical models is one of the most prominent measurement techniques in monitoring bacterial, yeast, and mammalian cell culture systems including CHO and HEK cells.\nRaman spectroscopy instrumentation is easy to integrate on different setups, such as immersion probes in bioreactors, vessels, and slipstreams, as well as large volumetric probes in manufacturing systems. Raman spectroscopy has an inherent advantage of being able to measure analytes in aqueous environments/solutions due to diminished interference from water, resulting in more accurate measurements than other online and inline spectroscopic and non-spectroscopic analysis techniques.\nInline and online Raman measurements enable process control and corrections from the deviations in real time, therefore increasing process robustness. Since Raman spectroscopy is a noninvasive measurement, it reduces contamination risks and enables remote monitoring of the process.\nStrong Raman spectroscopy use cases\nRaman spectroscopy has shown accurate measurements of glucose, lactate, viable cell density, and product concentration leading to adaptive or closed-loop control strategies, such as maintaining glucose concentration at a fixed setpoint or to minimize lactate accumulation by adjusting glucose feed rate.\nIt is also demonstrated that Raman spectroscopy can monitor monoclonal antibodies in real time and distinguish between glycosylated and non-glycosylated molecules. Raman spectroscopy is also shown to have good correlation with traditional offline and atline metabolite analyzers.\nIn one study, glucose measurements from Mab-expressing cell line culture by Raman spectrum demonstrated good correlation with reference data from Flex2 analyzer from Nova Biomedical. Raman spectrum based predictive models for glucose controlling the cell culture displayed equivalent glucose and viable cell count profiles compared with the reference data . Other studies show good correlation with HPLC, UV/Visible spectroscopy analyzers and various chemistry analyzers.\nThe detailed chemical information that is obtained by Raman spectrum thanks to its sharper bands enables further ability of transferring models from small scale R&D settings to large scale manufacturing settings.\nIt has been demonstrated that Raman spectroscopy could possibly measure below molecules with correct mathematical models :\n- Amino acids like alanine, arginine, glutamic acid (glutamate), glycine, histidine, proline, serine, tryptophan, tyrosine, valine, asparagine, glutamine, aspartic acid, cysteine, isoleucine, leucine, lysine, methionine, threonine and phenylalanine;\n- DNA and RNA bases like adenine, cytosine, guanine, thymine and uracil;\n- Fatty acids and fats like 12-methly-tetradecanoic acid, 13-methylmyrisitic acid, 14-methylmyrisitic acid, 14-methylhexadecanoic acid, 15-methylpalmitic acid, vaccenic acid, glycerol, lauric acid, myrisitic acid, oleic acid, palmitic acid, stearic acid, triolein, trilinolein and trilinolenin;\n- Hormones like human growth hormone and insulin;\n- Organic acids like acetate, formate, gluconic acid, keto-gluconic acid and lactate; primary metabolites like acetoacetate, acetylcoenzyme a, coenzyme a, fumarate, malic acid, phosphenolpyruvate, pyruvate, citric acid, succinic acid (succinate);\n- Salts like magnesium sulfate, nitrate, potassium phosphate monobasic and sulfate;\n- Sugars like N-acetyl-d-glucosamine, amylopectin, amylose, arabinose, cellulose, chitin, dextrose, d-fructose-6-phosphate, fucose, galactosamine, lactose, mannose, trehalose, xylose, fructose, glucose and sucrose;\n- Some other compounds like β-carotene, ascorbic acid, glutathione and riboflavin.\nIt is also demonstrated that Raman spectroscopy could measure total cell density, viable cell density, product titer, viability, antibody titer, and osmolality.\nRaman spectrum is used in microbial fermentation systems that use Saccharomyces cerevisiae, Gibberella fujikuroi, Lactobacillus casei, Phaffia rhodozyma, Escherichia coli and microalgae, and cell culture systems using CHO, HEK293 and NS0 cell lines .\nUpstream Processing Summary\nRaman spectroscopy enables the ability to monitor product quality continuously in real time and the development of predictive and advanced feedback control strategies, and upstream process optimization. It displays scalability of prediction models and methods from minibioreactors to large scale production bioreactors. This results in higher process efficiency and production concentration, better and more consistent product quality, shorter cycle times, and lower costs due to reduced need for calibration efforts for different volumes of bioreactors.\nProcess Analytical Technology in Downstream Processing\nMonitoring the critical process parameters (CPP) with various sensors is the main application of PAT in downstream processes. Flow sensors/meters, pressure sensors, pH and conductivity probes, and spectroscopic sensors are some examples of such sensors.\nThe measurement results are analyzed by univariate analysis and operator knowledge. However, this is typically not enough to have an understanding on critical quality attributes (CQAs) of the product. CQAs include product multimers and product charge variants, host-cell impurities such as host cell proteins, DNA and lipids, and resin leachables. These are typically monitored by atline or online analyses.\nVarious HPLC techniques are used to monitor high and low molecular weight species content, charge and glycosylation variants, and aggregates; and they are typically employed as atline analytical techniques in downstream processes. The typical monitoring technique for host-related impurities is immunological assays. All these techniques require long analysis times and, even though there has been progress to adapt them into real-time control strategies, the long analysis times are still a bottleneck for real time monitoring and real time process control .\nSpectroscopic techniques are great PAT solutions to accomplish these goals, and Raman is one of the most powerful spectroscopic techniques that has a great potential for future applications.\nAnalytical Application of Raman Spectroscopy in Downstream Processing\nRaman spectroscopy is already employed in downstream processing applications listed below :\n- Measurement of product concentration and product aggregation: The product concentration estimation and monitoring of monoclonal antibodies (mAb) is critical in continuous perfusion processes. This part can be accomplished by UV spectroscopy without the need for advanced predictive mathematical modeling that Raman spectroscopy requires.\nHowever, Raman spectroscopy achieves one goal that UV spectroscopy cannot achieve. Raman spectroscopy with quantitative modeling can be used for aggregate analysis. High concentrations of aggregate mAb types in the samples can be differentiated from each other due to having different Raman spectra.\n- Glycosylation: Distinguishing glycosylated and non-glycosylated proteins.\n- Membrane fouling: The fouling of immersion probes within cross-flow filtration units can be monitored as well. Even though this could be challenging due to complex background and weak signals of proteins, there are promising signs.\nDownstream processing summary\nThe downstream processing applications of Raman spectroscopy are still a very active research field and more will be evaluated and employed within the near future, as Raman spectroscopy will be an established analytical method within downstream processing field.\nRaman Analyzer Process Instruments\nAvailable through PROAnalytics: Tornado Spectral Systems SpectroPort Raman Probe and HyperFlux PRO Plus Raman Analyzer\n- Goldrick, S.; Umprecht, A.; Tang, A.; Zakrzewski, R.; Cheeks, M.; Turner, R.; Charles, A.; Les, K.; Hulley, M.; Spencer, C.; Farid, S.S. High-Throughput Raman Spectroscopy Combined with Innovate Data Analysis Workflow to Enhance Biopharmaceutical Process Development. Processes 2020, 8, 1179. doi: 10.3390/pr8091179\n- Esmonde-White, K.A., Cuellar, M., Uerpmann, C. et al. Raman spectroscopy as a process analytical technology for pharmaceutical manufacturing and bioprocessing. Anal Bioanal Chem 409, 637–649 (2017). doi: 10.1007/s00216-016-9824-1\n- Buckley K, Ryder AG. Applications of Raman Spectroscopy in Biopharmaceutical Manufacturing: A Short Review. Applied Spectroscopy. 2017;71(6):1085-1116. doi:10.1177/0003702817703270\n- Sibley, M. et al. “Novel Integrated Raman Spectroscopy Technology for Minibioreactors Accelerating Raman Model Building for Cell Culture Monitoring and Control.” (2020).\n- Abu-Absi, Nicholas & Martel, Richard & Lanza, Amanda & Clements, Stacey & Borys, Michael & Li, Zheng Jian. (2014). Application of spectroscopic methods for monitoring of bioprocesses and the implications for the manufacture of biologics. Pharmaceutical Bioprocessing. 2. 267-284. 10.4155/pbp.14.24.\n- Kögler, M. (2018). Advanced Raman Spectroscopy for Bioprocess Monitoring: Dissertation. doi: 10.14279/depositonce-6684\n- Ryabchykov, Oleg, Guo, Shuxia and Bocklitz, Thomas. “Analyzing Raman spectroscopic data” Physical Sciences Reviews, vol. 4, no. 2, 2019, pp. 20170043. doi: 10.1515/psr-2017-0043\n- Yilmaz, D, Mehdizadeh, H, Navarro, D, Shehzad, A, O’Connor, M, McCormick, P. Application of Raman spectroscopy in monoclonal antibody producing continuous systems for downstream process intensification. Biotechnol Progress. 2020; 36:e2947. doi: 10.1002/btpr.2947\n- Banner image illustration source: Silvère André, Lydia Saint Cristau, Sabine Gaillard, Olivier Devos, Éric Calvosa, Ludovic Duponchel, In-line and real-time prediction of recombinant antibody titer by in situ Raman spectroscopy, Analytica Chimica Acta, Volume 892, 2015, Pages 148-152, ISSN 0003-2670, https://doi.org/10.1016/j.aca.2015.08.050.']	['<urn:uuid:15f633aa-a9eb-4594-9cd0-f19aef85051c>', '<urn:uuid:726bd534-09ef-4a3e-88e4-435634ca04f1>']	factoid	with-premise	short-search-query	distant-from-document	multi-aspect	novice	2025-05-01T23:21:14.341336	5	69	3376
339	As a storage systems engineer, I'm interested in understanding how content-defined chunking works in data deduplication. What are the technical details of the rolling hash computation process, and what are the different indexing approaches used to track duplicate data?	The rolling hash computation uses a sliding window that scans data bytes to compute a hash value at each point. It efficiently calculates the hash at position I from position I-1 using a window (typically 16 bytes) that produces a 64-bit fingerprint. The computation involves addition, subtraction, multiplication and XOR operations. The system declares a chunk boundary if the bottom Y bits of the fingerprint are zero, with Y depending on desired chunk size. The process uses a multiplicative scheme with a PRIME number and precomputed table using an irreducible polynomial. For indexing duplicates, there are four main approaches: 1) Catalog-based indexing that uses hash values only to identify candidates, 2) Lookup table-based indexing that contains a hash lookup table to index the deduped object's parent pointer, 3) Content-addressable store (CAS) indexing that uses the hash value itself as the data pointer, and 4) Application-aware indexing that compares like objects based on their data structure format. The choice of indexing method impacts system resiliency and performance, particularly as the system scales with more data objects.	['In Pcompress, I have implemented a variant of the rolling hash based Content Defined Chunking that provides both deduplication accuracy and high performance. This post attempts to explain the chunking process, covers the chunking computations that are done in Pcompress and then talks about the new optimizations for very fast sliding window chunking (on the order of 500MB/s to 600MB/s throughput depending on processor).\nData Deduplication requires splitting a data stream into chunks and then searching for duplicate chunks. Once duplicates are found only one copy of the duplicate is stored and the remaining chunks are references to that copy. The splitting of data into chunks appears to be an ordinary process but is crucial to finding duplicates effectively. The simplest is of course splitting data into fixed size blocks. It is screaming fast, requiring virtually no processing. It however comes with the limitation of the data shifting problem.\nThe diagram below illustrates the problem. The two 64-character patterns are mostly similar with only two characters differing. Initially fixed-block chunking provides good duplicate detection. However the insertion of a single character at the beginning shifts the entire data while chunk boundaries are fixed. So no duplicates are found even though the patterns are mostly similar.\nThe diagram shows insertion, but the same thing can happen for deletion. In general with static chunking duplicate detection is lost after the point where insertion or deletion has taken place.\nIn order to deal with this, most dedupe solutions use content defined chunking that mark cut points based on patterns in the data. So if the data patterns shift the cut points also shift with them. The diagram below illustrates.\nThe chunks are split based on patterns in data so they are of variable length (but average size is close to the desired length). Since the chunk boundaries shift along with the data patterns, duplicates are still found. Only the modified chunks are unique.\nThe Rolling Hash computation\nNow the question comes as to what data patterns to look out for when determining the chunk boundaries or cut points? The common technique is to compute a hash value of a few consecutive bytes at every byte position in the data stream. If the hash value matches a certain predefined pattern we can declare a chunk boundary at that position. To do this computation efficiently a technique called the rolling hash was devised. It uses a sliding window that scans over the data bytes and provides a hash value at each point. The hash value at position I can be cheaply computed from the hash at position I-1. In other words where ‘n’ is the window size and represents the window bytes at byte position ‘i’. In mathematical terms this is a recurrence relation. Rolling hashes have been used in contexts like Rabin-Karp substring search and Rsync. Today they are used extensively in chunk splitting in the context of data deduplication.\nOne of the common rolling hashes used in Data Deduplication is Rabin Fingerprinting devised originally by Turing award winner Michael O. Rabin in his seminal paper titled “Fingerprinting By Random Polynomials“. The mathematically inclined will enjoy reading it. There are other rolling hash techniques such as the one used in Rsync, the TTTD algorithm devised by HP, the FBC algorithm etc.\nWhile I am not so much of a mathematically inclined person I still needed a good rolling hash in order to do content defined chunking in Pcompress. After looking at various implementations like the one in LBFS and few other open-source software like n-gram hashing, I came up with an approach that worked well and produced average chunk sizes close to the desired value.\nI used a small sliding window of 16 bytes that produces a 64-bit fingerprint at each byte position requiring an addition, subtraction, multiplication and conditionally an XOR for each byte position. It would declare a chunk boundary if the bottom Y bits of the fingerprint were zero. The value of Y would depend on the average chunk size desired. For example for 4KB average size one would look for bottom 12 bits to be zero. The core of the approach is derived from Rabin Fingerprinting. A good description is here: http://www.infoarena.ro/blog/rolling-hash. The hashing approach is a multiplicative scheme of the form:\nWhere inbyte is Incoming byte into sliding window head, outbyte is outgoing byte from sliding window tail and . The PRIME number I am using is the same value used by Bulat Ziganishin in his SREP tool. Experimentation showed it to produce good results. In addition to this I precompute a table using the irreducible polynomial (represented in GF(2)) from LBFS. The outbyte is used to index the table and the value is XOR-ed with the hash value to produce the final fingerprint. I did some analysis of the chunking approach which is documented in two earlier posts. The results were good.\nA window size of only 16 bytes will raise some eyebrows as typically much larger windows are used. LBFS for example used a 48-byte window and others have used even larger windows. However in practice, as is evident from the above analysis, this implementation does produce good results and the window size of 16 bytes allows an optimization as we will see below.\nWhile addition, multiplication are extremely fast on modern processors, performance overheads remained. Even though I was using a small window of 16 bytes it still required performing computations over the entire series of bytes in order to find cut points. It is very much computationally expensive compared to the simple splitting of data into fixed-size chunks. A couple of optimizations are immediately apparent from the above hash formula:\n- Since we are dealing with bytes it is possible to pre-compute a table for\n- The MODULUS operation can be replaced with masking if it is a power of 2.\nThis gives some gains however the overhead of scanning the data and constantly updating a sliding window in memory remains. Eventually I implemented a couple of key new optimizations in Pcompress that made a significant difference:\n- Since the sliding window is just 16 bytes it is possible to keep it entirely in a 128-bit SSE register.\n- Since we have minimum and maximum limits for chunk sizes, it is possible to skip minlength – small constant bytes after a breakpoint is found and then start scanning. This provides for a significant improvement in performance by avoiding scanning majority of the data stream.\nExperimentation with different types of data shows that the second optimization results in scanning only 28% to 40% of the data. The remaining data are just skipped. The minimum and maximum limits are used to retain a distribution of chunk sizes close to the average. Since rolling hash cut points below the minimum size are ignored it does not make sense to scan that data.\nAll these optimizations combined provide an average chunking throughput of 530 MB/s per core on my 2nd generation Core i5 running at 2.2 GHz. Of course faster, more recent processors will produce better results. The throughput also depends on the nature of the data. If the data has a very specific pattern that causes more large chunks to be produced the performance degrades (Think why this should be the case). This brings us to the worst case behaviour.\nWorst Case performance profile\nThe worst case performance profile of the optimized chunking approach happens when all chunks produced are of the maximum size. That is the data is such that no breakpoints are produced resulting in a degeneration to the fixed block chunking behaviour at max chunksize of 64KB and at the cost of rolling hash computation overhead. In this case the majority of the data is scanned and computed, but how much ?\nIf we assume minimum chunk size of 3KB, maximum 64KB and 100MB data we will have chunks (considering worst case all max-length chunks). For every chunk of data will be skipped. In my current implementation the value of small constant is 256, though it can be smaller. So the actual skipped size is bytes. In total the number of skipped bytes will be bytes out of 100MB data. In percentage terms it is . In other words 95% of the data will be scanned degrading the performance by more than half.\nNow the question is what kind of data will produce this worst case behaviour? If you have seen the rolling hash computation details in Pcompress above, the eventual fingerprint is computed via an XOR with a polynomial computation result from a table. Those values are non-zero and we check for breakpoints based on bottom 12 bits of the fingerprint being zero. So if the computed hash is zero the XOR will set the bits and bottom 12 bits will become non-zero. The hash will be zero if the data is zero. That is if we have a file of only zero bytes we will hit the worst case.\nI created a zero byte file and tested this and got a throughput of 200 MB/s and all chunks of the max 64KB length. In real datasets zero byte regions can happen, however very large entirely zero byte files are uncommon, at least to my knowledge. One place having zero byte regions is VMDK/VDI files. So I tested on a virtual harddisk file of a Fedora 18 installation in VirtualBox and still got a majority of 4KB chunks but with a small peak at 64KB. The throughput was 490 MB/s with approx 41% of the data being scanned. So even a virtual harddisk file will have non-zero bytes inside like formatting markers. It is rare to get 100s of megabytes of files with only zero bytes. Finally from an overall deduplication perspective such files will be deduplicated maximally with almost 98% data reduction and final compression stage will also be extremely fast (only zero bytes). So even though chunking suffers, overall deduplication will be fast.\nIf you are interested to look at the implementation in Pcompress, it is here: https://github.com/moinakg/pcompress/blob/master/rabin/rabin_dedup.c#L598', 'How does it work? What are the different implementation methods? And what are the key evaluation criteria?\nBy Larry Freeman, Rory Bolt, and Tom Sas\nData de-duplication is the process of eliminating redundant copies of data. The term “data de-duplication” was coined by database administrators many years ago as a way of describing the process of removing duplicate database records after two databases had been merged.\nToday the original definition of de-duplication has been expanded. In the context of storage, de-duplication refers to any algorithm that searches for duplicate data objects (e.g., blocks, chunks, files) and stores only a single copy of those objects. The user benefits are clear:\n- Reduces the space needed to store data; and\n- Increases the available space to retain data for longer periods of time.\nHow it works\nRegardless of operating system, application, or file-system type, all data objects are written to a storage system using a data reference pointer, without which data could not be located or retrieved. In traditional (non-de-duplicated) file systems, data objects are stored without regard to any similarity with other objects in the same file system.\nIdentifying duplicate objects and redirecting reference pointers form the basis of the de-duplication algorithm. As shown in the figure, referencing several identical objects with a single “master” object allows the space normally occupied by the duplicate objects to be “given back” to the storage system.\nGiven the fact that all de-duplication technologies must identify duplicate data and support some form of referencing, there is a surprising variety of implementations, including the use of hashes, indexing, fixed object length or variable object length de-duplication, local or remote de-duplication, inline or post-processing, and de-duplicated or original format data protection.\nUse of hashes\nData de-duplication begins with a comparison of two data objects. It would be impractical (and very arduous) to scan an entire data volume for duplicate objects each time a new object was written to that volume. For that reason, de-duplication systems create relatively small hash values for each new object to identify potential duplicate data.\nA hash value, also called a digital fingerprint or digital signature, is a small number generated from a larger string of data. Hash values are generated by a mathematical formula in such a way that it is extremely unlikely (but not impossible) for two non-identical data objects to produce the same hash value. In the event that two non-identical objects do map to the same hash value, this is termed a “hash collision.”\nUnderstanding a system’s use of hashes is an important criterion when you are evaluating de-duplication. If the technology depends solely on hashes to determine if two objects are identical, then there is the possibility, however remote, that hash collisions could occur and some of the data referencing the object that produced the collision will be corrupt. Certain government regulations may require you to perform secondary data object validation after the hash compare has completed to ensure against hash collisions. Although concern over hash collisions is often raised, depending upon the hash algorithm used and the system design, the probability of a hash collision may actually be orders of magnitude less than the probability of an undetected disk read error returning corrupt data.\nOnce duplicate objects have been identified (and optionally validated), removal of the duplicate object can commence. There are varying methods that systems employ when modifying their data pointer structures. However, all forms of this indexing fall into four broad categories:\nCatalog-based indexing-A catalog of hash values is used only to identify candidates for de-duplication. A separate process modifies the data pointers accordingly. The advantage of catalog-based de-duplication is that the catalog is only utilized to identify duplicate objects and is not accessed during the actual reading or writing of the de-duplicated data objects; that task is handled via the normal file-system data structure.\nLookup table-based indexing-Extends the functionality of the hash catalog to also contain a hash lookup table to index the de-duplicated object’s “parent” data pointer. The advantage of a lookup table is that it can be used on file systems that do not support multiple block referencing; a single data object can be stored and “referenced” many times via the lookup table. Lookup tables may also be used within systems that provide block-level services instead of file systems.\nContent-addressable store, or CAS-based, indexing-The hash value, or digital signature of the data object itself, may be used by itself or in combination with additional metadata as the data pointer. In a content-addressable store (CAS), the storage location is determined by the data being stored. Advantages of CAS-based indexing include inherent single instancing/de-duplication, as well as enhanced data integrity capabilities and the ability to leverage grid-based storage architectures. Although CAS systems are inherently object-based, file-system semantics can be implemented above the CAS.\nDue to the growing interest in data de-duplication and space reduction solutions, the SNIA DMF Data Protection Initiative has recently been tasked with forming a Special Interest Group (SIG) focusing on this topic. This is the first in a series of publications from SNIA on the topic of de-duplication and space reduction. The mission of the DDSR SIG is to bring together a core group of companies that will work together to publicize the benefits of data de-duplication and space savings technologies. Anyone interested in participating can help form the direction and >ultimate success of the group. Find out more at www.snia-dmf.org/dpi\nApplication-aware indexing-Differs from other indexing methods in that it looks at data as objects. Unlike hashing or byte-level comparisons, application-aware indexing finds duplication in application-specific byte streams. As the name implies, this approach compares like objects (such as Excel documents to Excel documents) and has awareness of the data structure of these formats.\nDe-duplication indexing is an important consideration in technology evaluation, particularly when it comes to resiliency of design. When indexing data objects, the index itself could become a single point of failure.\nIt is important to understand what, if any, single points of failure are present in a de-duplication system. It is equally important to understand what measures are used to protect these single points of failure to minimize the risk of data loss.\nAnother indexing consideration is the speed of the index. An inordinate amount of time should not be required to store and retrieve data objects, even when millions of objects are stored in the file system. When evaluating de-duplication, consider both lightly loaded and fully loaded file systems and the potential performance degradation caused by indexing as more and more data is written to the file system.\nFixed object length or variable object length de-duplication\nDe-duplication may be performed on fixed-size data objects or on variable-size data objects.\nWith fixed object length de-duplication, data may be de-duplicated on fixed object boundaries such as 4K or 8K blocks. The advantage of fixed block de-duplication is that there is less computational overhead in computing where to delineate objects, less object overhead, and faster seeking to arbitrary offsets.\nWith variable object length de-duplication, data may be de-duplicated on variable object boundaries. The advantage of variable object size de-duplication is that it allows duplicate data to be recognized even if it has been logically shifted with respect to physical block boundaries. This can result in much better data de-duplication ratios.\nFixed object length de-duplication offers processing advantages and performs well in both structured data environments (e.g., databases) and in environments where data is only appended to files. In unstructured data environments such as file servers, variable object length de- duplication is able to recognize data that has shifted position as the result of edits to a file. Variable object length de-duplication typically offers greater de-duplication in unstructured data environments. Since fixed object length is a subset case of variable object size, many systems capable of variable object length de-duplication also offer fixed object length.\nLocal or remote de-duplication\nLocal or remote de-duplication refers to where the de-duplication is performed:\nIn local de-duplication, de-duplication may be performed within a device. This allows transparent operation without the need for APIs or software agents. Local de-duplication is sometimes referred to as target de-duplication in the backup market.\nIn remote de-duplication, for LAN- or WAN-based systems, it is possible to perform de-duplication remotely through the use of agents or APIs without requiring additional hardware. Remote de-duplication extends the benefits of de-duplication from storage efficiency to network efficiency. Remote de-duplication is sometimes referred to as source de- duplication in the backup market.\nThe advantage of local de-duplication is total application transparency and interoperability; however it doesn’t address remote or distributed systems or bottlenecks in networks. Although it requires a specialized agent or API, remote de- duplication offers tremendous potential for both network bandwidth savings and application performance.\nInline or post-processing\nAnother design distinction is when to perform de-duplication. Again, there are multiple design options.\nWith inline de-duplication, de-duplication is performed as the data is written to the storage system. The advantage of inline de-duplication is that it does not require any duplicate data to be written to disk. The duplicate object is hashed, compared, and referenced on-the-fly. A disadvantage is that more system resources may be required to handle the entire de-duplication operation in real time.\nWith post-processing de-duplication, de-duplication is performed after the data is written to the storage system. The advantage of post-processing de-duplication is that the objects can be compared and removed at a more leisurely pace, and typically without heavy utilization of system resources. The disadvantage of post-processing is that all duplicate data must be first written to the storage system, requiring additional storage capacity.\nThe decision regarding inline versus post-processing de-duplication has more to do with the application being de-duplicated rather than any technical advantages/disadvantages.\nWhen performing data backups, the user’s primary objective is the completion of backups within an allowed time window. For LAN- and WAN-based backups, remote inline de-duplication may provide the best performance. For direct-attached and SAN-based backup, an assessment should be made to determine which approach works best. Either may be appropriate, depending on data type and volume. If post-processing de-duplication is deployed, users should ensure there is adequate time between backup sessions to complete the de-duplication post-process.\nWith general applications, the cost of additional storage needed by post-processing needs to be weighed against the cost of system resources and the performance of inline de-duplication to determine the best fit for an environment.\nDe-duplicated or original format data protection\nAs is the case with all corporate data systems, de-duplicating storage systems need to be protected against data loss. De-duplicating systems vary with respect to their approach to data protection.\nWhen protecting a de-duplicated system, it is possible to perform backups and replication in the de-duplicated state. The advantages of de-duplicated data protection are faster operations and less resource usage in the form of LAN/WAN bandwidth.\nDe-duplicated systems can also be backed up and replicated in the original data format. The advantage of protecting data in the original format is that the data can theoretically be restored to a different type of system that may not support data de-duplication. This would be particularly useful with long-term tape retention.\nIf media usage and LAN/WAN bandwidth are a concern, de-duplicated data protection offers clear cost advantages as well as performance advantages. Note that while original format data protection offers the possibility of cross-platform operation, in practice many data-protection solutions do not allow cross-platform operation. Finally, some systems offer users a choice of either type of data protection.\nDe-duplication space savings\nSo what should you expect in terms of space/capacity savings with data de-duplication?\nDe-duplication vendors often claim 20:1, 50:1, or even up to 500:1 data-reduction ratios. These claims refer to the “time-based” space savings effect of de-duplication on repetitive data backups. The figure on p. 27 illustrates this theoretical space savings over time. Since these backups contain mostly unchanged data, once the first full backup has been stored, all subsequent full backups will see a very high occurrence of de-duplication. Assuming the user retains 10 to 20 backup images, and the change rate between backups is within the norm (2% to 5%), this user should expect storage space savings in the range of 5:1 to 20:1. If you retain more backup images, or a reduced rate of change between backups, your ratio will increase. The larger numbers, such as 300:1 or 500:1, tend to refer to data moved and stored for daily full backups of individual systems.\nAnother area to consider for data de-duplication is non-backup data volumes, such as primary storage or archival data, where the rules of time-based data reduction ratios do not apply. In those environments, volumes do not receive a steady supply of redundant data backups, but may still contain a large amount of duplicate data objects.\nThe ability to reduce space in these volumes through de-duplication is measured in “spatial” terms. In other words, if a 500GB data archival volume can be reduced to 400GB through de-duplication, the spatial (volume) reduction is 100GB, or 20%. Think of it as receiving a “storage rebate” through de-duplication. In these applications, space savings of 20% to 40% may justify the cost and time you spend implementing de-duplication.\nData de-duplication is an important new technology that is quickly being embraced by users as they struggle to control data proliferation. By eliminating redundant data objects, an immediate benefit is obtained through space efficiencies.\nWhen evaluating de-duplication technologies, it is important to consider major design aspects, including use of hashes, indexing, fixed or variable object length, local or remote operation, inline or post-processing, data protection, and of course, the space savings reduction that you will receive. By considering these items and understanding how they impact your data storage environment, informed decisions can be reached that benefit your environment. Watch for more on this topic at www.snia.org.\nThis article was written on behalf of the SNIA Data Management Forum. Larry Freeman is a senior product manager at Network Appliance; Rory Bolt is chief technology officer, Avamar Products, EMC; and Tom Sas is a product marketing manager at Hewlett-Packard.']	['<urn:uuid:d5fcaa2f-f4c7-4b15-9784-210155841d4e>', '<urn:uuid:b5b327a6-952b-4cda-9079-d44280db2346>']	open-ended	with-premise	verbose-and-natural	distant-from-document	multi-aspect	expert	2025-05-01T23:21:14.341336	39	175	4015
342	website mistakes that drive away customers	Several common mistakes drive customers away from websites. Having an outdated, non-responsive site that doesn't work well on all devices puts businesses behind their competition. Forms with cancel/reset buttons can cause visitors to leave if accidentally clicked. Auto-play videos are particularly annoying, especially if a user's speakers are on. Additionally, having too many calls-to-action (CTAs) on a single page can overwhelm visitors. Sites with neon colors can create readability issues and hurt users' eyes, especially on smartphones or large screens.	"['Most Common Digital Design Distractions\nWith just seconds to capture a Web visitor\'s attention and guide them to complete the task they came to the site to do, Web designers often rely on elements they think will help conversions. All too often, however, these elements do the exact opposite, failing to capture the conversion because they are too distracting to the user.\nWebsite Magazine enlisted the help of 30-plus Web professions to see what common Web design elements are distracting customers, visitors, users, subscribers from completing their tasks on a company\'s website - and what should a brand do instead. Note, respondents had word-count restrictions or they likely would have elaborated.\n""The biggest mistake I see business owners making is keeping an outdated site for years and years on end. If you\'ve not got a responsive website that can be used appropriately on any device, you\'re losing ground against your competition.""\n+ Travis Bennett, Founder of Studio Digita\n""As much as metrics may suggest otherwise, websites lose and frustrate users when they continue to barrage with popup lightboxes that block content to subscribe or advertise. This includes the bottom right pop up which impedes on scrolling down.\nSolution: If subscribing is truly the only way the company can convert a customer to purchasing, then add it as a sticky bottom menu. This means it is present all of the time but allows the user to scroll and read content without interruptions.""\n+ Emma Moore, Owner of Fundamental, LLC\n""Forms that have a cancel/reset button. If a visitor accidentally clicks that rather than submit they will often leave the site rather than start all over.""\n+ Stoney G deGeyter, CEO & Project Manager of Pole Position Marketing\n""Sliders, especially sliders with footer content, are problematic and most Web design experts strongly advise against them. Even more problematic are infinite scroll websites that load the rest automatically once when you get to the bottom of the page as many customers will find it intuitive to have contact info at the bottom of the page if there is no contact info somewhere on top. Instead of sliders, use well-organized dropdown menus whenever possible.""\n+ Alex Bar, Owner at Third Temple Digital\n""Avoid any type of \'notify on first visit\' entity. With content now so app oriented, websites are increasingly accessed via native app Web-views (e.g., via Twitter, Reddit, etc.), which means no cookies or persistent logins. Ironically, a good example of this mistake is the Euro Cookie notice law - I don’t think they realized those would show so persistently.""\n+ Peter Holmes, Creative Director at Barefoot Solutions\n""Many things can get in the way of people completing the intended task – on e-commerce, discount codes can be a big one where customers will see \'discount code\' within the checkout and then drop out to hunt one down. Keep a small text link in the basket asking if they have a code which expands out a form field.""\n+ Ed Baxter, Search Manager at Evoluted\n""Poor performance is a big point of friction causing customers to leave websites.\nWeb pages have gotten too large, causing them to load slowly and react poorly to user interaction. This creates frustration and customers just leave.""\n+ Chris Love, Owner of Love2Dev\n""Social sharing can have a negative impact on a website’s user experience (UX) and conversions, especially on e-commerce product pages. Its inclusion can slow load times, distract users from a page’s central goal and create distrust in content or products if they include counters with low numbers. Social sharing should be used sparingly on key content or after conversions and sales.""\n+ Sara Novak, Associate Creative Director of Elevate\n""One of the biggest distractions for new visitors is too many calls-to-action (CTAs). Especially if your website targets very specific users, bombarding them with several CTAs will not be helpful. Instead, have a clear path that the user should take and guide them through your website one page at a time. A good place to start is only one CTA per page.""\n+ Sacha Ferrandi, Founder and CMO of Source Capital Funding, Inc.\n""First and foremost, keep it clean. Nothing is more of an eyesore than a clutter of different fonts, widgets, and buttons. Additionally, stay away from stock photos! They look tacky and unprofessional, and won\'t represent your brand--visitors will immediately leave. Choose colors that evoke your desired emotional response. Finally, stay consistent. It\'s important that every visual detail aligns with your brand personality in order to create trust and credibility.""\n+ Laura Casanova, Creative Director of ONTRAPORT\n""Pop-up promotions are becoming popular on websites and can be counterproductive if the user isn’t interested in what you are promoting. Users can get frustrated and increase your bounce rate. Brands should be cognizant of how large the ad is and how quickly and frequently it pop-up. When done properly pop-up ads can be very effective.""\n+ Kara Jensen, Creative Principal of Bop Design\n""Pop-over videos that obscure content and auto-play.""\n+Stephan Roussan, President of ICVM Group\n""While there are many website distractions now a days, one that irks me is the floating sidebar box. People often place an ad, a notification, or a signup box that follows you till the end. It comes into action as soon as you scroll the page and often breaks the rhythm of the reader.""\n+ Sumit Bansal, Founder of Productivity Spot\n""Some colors just hurt your eyes. For example, neon colors are usually considered as fun and cool, but only from a certain distance. If you have to see the website on your smartphone or on your 32” screen, it just hurts. It creates serious readability concerns and the brightness of the colors distract your users often overpowering your main content.""\n+ Jitesh Keswani, CEO of e-Intelligence.in\n""The biggest distraction for a website is a lacking understanding of our users and business goals. Funny right? That’s not a design element at all,yet too often we spend time, money and effort making design choices that don’t provide any value to our customers, nor impact our business goals because we don’t have a clear understanding of either.""\n+ Zack Naylor, Co-Founder and CEO of Aurelius\n""You might laugh at this, but the pages themselves. Internet surfers have short attention spans, and if your cart or ordering form is buried more than about two levels deep, they just don\'t use your service! Cure: reduce average number of clicks from home page (or touch down pages) to your core business pages.""\n+ Woody Stanford, Owner of Stanford Systems\n""Value proposition carousels are the worst. If you don’t know what value your company provides, how is a visitor supposed to figure it out? A large hero section with several headlines and calls to action looks impressive, but makes it harder for visitors to understand what your website does - and more importantly, why they should care.""\n+ Tyler Moore, Marketing Director at App Press\n""One of worst offenders, a sure-fire way to annoy site visitors, is auto-play video. Visitors make snap judgments about your brand upon their first visit. Auto-play video is annoying (especially if a user\'s speakers are on and turned up). Plus, forcing your brand on someone smells of desperation. Embedded video and background (masthead video or animation) are equal opportunity offenders.""\n+ Tony Mariotti, Owner of RubyHome\n""Carousels or sliders are still overused on newly designed sites. Carousels take up too much space, add distracting motion and provide too many different options for the user. We’ve moved to large Hero images with call-to-action text and a colorful button overlaid. In my experience this converts better.""\n+ Tim Knol, Director of Digital Marketing at The Mayors Agency LLC\n""Common distracting elements on websites include multiple font and type colors, too many boxes with contents, complex background textures, wrong alignment of fields, high-contrast colors, barely visible call-to-action buttons and a few others. For getting into the mindsets of the prospects, conversion rate optimization models can be used to help you minimize the barriers to cognition followed by A/B testing.""\n+ Swapnil Bhagwat, Senior Manager of Design & Digital Media at Orchestrate\n""The biggest distraction that website visitors face is the overwhelming amount of outbound links on the website they are visiting. Whether the link is through an ad - in the sidebar or in-between paragraphs - or a link in the content itself, these links are taking the visitor off the website they are visiting, removing them from the content they are reading, and leading them to another business’s website. Even if these links open up in a new tab, the chance that the visitor will return to finish reading the article or complete the original website’s call-to-action, is very small.""\n+ Mindy Iannelli, CEO of Mindy Iannelli, LLC\n""Your entry point to a website is NOT always your home page. Search engines like Google will display any page of a website in the search results, therefore, a visitor can enter through an inside page. Brands tend to not have the appropriate calls-to-action on their inside pages in order to guide a visitor through their website, to make contact them, or make a sale.""\n+ Melih Oztalay is CEO of SmartFinds Marketing\n""The worst distractions of a website design include automatic pop-up windows, and animated characters that launch into a pre-recording welcome message. The unexpected audio of animated greeters scare the user; most sites do not have audio you land on them. Second, the pop-ups and animated figures literally block the user from recovering the information he or she clicked to get from your website.""\n+ Angela Zade, Digital Marketing Coordinator for Hawaiian Inn\n""Advertisements are a leading cause of experience disruption on a website. Particularly advertisements that are out of context and unrelated to content that someone is inclined to find. By using them, businesses sacrifice user happiness, engagement, adoption, retention, and task completion at the expense of clicks. Alternatively, consider leveraging digital to deliver effective content and innovate business models.""\n+ Casey Kaplan, Principal UX Designer at The Nerdery\n""When everything is competing for attention on your Web page, your Web form needs to be as simple and easy to navigate as possible. In this day and age of distracting content on every inch of your Web page, users with only a few seconds of focus will not be pulled in by a form with a hundred mundane questions. All these questions are distracting from where you\'re trying to direct them to! By using less questions on your web form, you\'re getting enough content from them to reach out for follow up and to answer the other questions you\'d like to have from them.""\n+ April Davis, Wwner and Founder of LUMA\n""Videos that queue automatically on a website are a huge distraction and even a turnoff to site visitors. They require the visitor to proactively turn them off in order for them to view the site and locate the information that they are seeking. If you have auto-queue videos on your site, you are almost certainly lowering your overall conversion rate.""\n+ Jennifer M. Poole, J.D. at personalinjurylawcal.com\n""Popups on phones are the bane of everyone\'s existence. Most of the time you cannot close them, rendering the site unusable—recipe sites are very guilty of this. Instead, a small, unobtrusive, bottom slide-in would let people keep scrolling while still promoting your material. This leads to a better overall user experience (and I actually get to make your recipe).""\n+ Justin Kalaskey, Web/UX Designer at WebMechanix\n""Popups can be an effective lead generator if used wisely. I advise to have them appear after a user has been on your site for a specific amount of time, scrolled down on the page, or clicked to view a couple of pages. Always offer something of value in exchange for their contact information.""\n+ James Sacci, Web Developer at ProWeb Innovations\n""Probably the worst offender in terms of distraction are email newsletter/deal sign-up forms that pop-up before you\'ve even had a chance to look around the website. Instead, brands should be more restrained in having pop-ups or consider removing them all the same.""\n+ Ian Wright, Founder of Merchant Machine\n""If you\'re trying to capture leads or get a site visitor to complete a certain goal, having too many calls-to-action on a landing page can distract people from clicking the button that leads to your desired conversion/action. Use less enticing text links for other CTA’s or remove them from a page completely, you can display them on a thank-you page once the main goal has been completed.""\n+ Grace Howlett, Junior Product Manager at Moonfruit\n""A slow website - if each of your website\'s pages are not snappy, loading in less than 3 seconds, the slow loading time will get tedious, distracting and eventually drive the user away. This is especially true for users who are not yet familiar with the brand.""\n+ David Attard, Founder of DART Creations\n""One element that I find distracting on websites are text link ads. When users normally click on a link they expect to be directed to a page with relevant information. Instead, when they hover over a link, they’re getting a distracting pop-up that leads them nowhere.""\n+ Chelsey Moter, Digital Analyst at seoWorks\n""One of the biggest mistakes I see is having too many links pointing from sales pages to non-sales pages. Any time you give a website user something to interact with it is a distraction, and the last thing you want them to do is curiously click a link that sends them away from your sales page. You should eliminate all unnecessary interactive options from the page leaving them with basically one option - to buy.""\n+ Brandon Howard, Owner of All My Web Needs\n""As designers we need to be aware of common web design elements which can be distracting for users. Some of these include multiple CTAs, navigation with multiple layers of information and PPC advertising.\nHowever, many of these common elements have important roles when used is the correct way. Brands should recognize the correct use case for common Web design elements.""\n+ Rohan Woodward, Art Director at Delphic Digital']"	['<urn:uuid:9d9f8734-8371-42dc-a1ed-7996505b5fd0>']	open-ended	direct	short-search-query	similar-to-document	single-doc	novice	2025-05-01T23:21:14.341336	6	80	2368
343	virginia oyster industry aquaculture development permit requirements disease monitoring	Virginia has the largest oyster industry on the United States Atlantic coast, primarily driven by aquaculture. The industry has grown due to entrepreneurial efforts and state policy changes that facilitate aquaculture lease acquisition. Success in oyster aquaculture requires close attention to diseases. State and federal agencies regulate oyster transfers within and between jurisdictions to prevent introduction of exotic pathogens and endemic disease spread. Transfer permits require formal health inspection reports and pathological examinations of shell stocks.	"[""From David Bushek, PhD\nProfessor of Marine and Coastal Sciences\nDirector, Haskin Shellfish Research Laboratory\nRutgers, The State University of New Jersey\nSeveral things are particularly well done. First, there is a nice introductory chapter that provides an easy entry for those not familiar with the oyster, its anatomy and the basics of histopathology. Second, the images and respective descriptions in most chapters are very well done. They provide crisp images that clearly illustrate structures and diagnostic features. Third, the chapters are well organized into a consistent format that makes them easy to follow and easy to find information quickly. Finally, the chapters create a comprehensive description of the histopathology of the eastern oyster providing a wealth of information that previously required multiple disparate resources.\nFrom Tal Ben Horin, PhD\nAssistant Professor of Shellfish Pathology\nNorth Carolina State University Department of Clinical Sciences\nOur copy now lives on the microscope table in my lab, and it's pretty typical for the students rotating through my lab to find themselves deep in that book whenever at the microscope these days. Me too. The text gives just enough detail even for a general audience with basic anatomy background. The images are the real draw though. It’s a tremendous resource for anyone working on pathogen and disease issues in oysters—students, faculty, environmental consultants and managers included.\nThis is a comprehensive, color-illustrated guide to histological presentations of diseases, pathogens, and parasites of eastern oysters, Crassostrea virginica.\nIt includes 18 subject chapters and more than 100 color figures and diagrams\nSoft cover, 126 pages, 8.5 x 11 in.\nThis publication supports the development of oyster aquaculture industries and restored populations of wild oysters in the eastern United States. Both aquaculture and efforts to restore the eastern oyster, Crassostrea virginica, have expanded in recent years, increasing the need for a broader understanding of oyster health. This volume addresses that need by providing detailed information on the histological presentation of diseases and parasites affecting eastern oysters.\nOyster aquaculture has rapidly developed in the Chesapeake Bay region because of new efforts by entrepreneurs and changes in state policies that make it easier for aquaculture operators to obtain leases. Virginia has the largest oyster industry on the United States Atlantic coast, which is largely driven by aquaculture. This cultivation is also expanding in other regions in the United States. As with all forms of animal husbandry, success in oyster aquaculture relies on close attention to diseases in order to prevent or mitigate serious impacts on production and survival. This guide is meant to help maintain the disease biosecurity of oysters grown or harvested from Chesapeake Bay and elsewhere.\nThis volume is also intended to inform health assessments and protection of wild oysters that share habitat waters and microbial associates with cultured oysters. State agencies must pay close attention to disease events in both wild oyster populations that they manage and in cultured oyster populations that they strive to protect. Natural resource management agencies of both state and federal governments regulate transfers of oysters within and between their jurisdictions to prevent introduction and transfers of exotic oyster pathogens and to prevent exacerbation of endemic diseases. Permits for such transfers routinely require formal reports on the results of health inspections or pathological examinations of shell stocks proposed for transfer.\nChapter 1: Histological Microanatomy\nDISEASES AND CONDITIONS CAUSED BY PROTISTS\nChapter 2: Perkinsus marinus Infections (Dermo Disease)\nChapter 3: Haplosporidium nelsoni (MSX)\nChapter 4: Haplosporidium costale (SSO)\nChapter 5: Bonamia exitiosa\nChapter 6: Ciliate Associates\nChapter 7: Hexamita and Other Diplomonad Flagellates\nChapter 8: Apicomplexan Parasites\nDISEASES AND CONDITIONS CAUSED BY METAZOA\nChapter 9: Nematode Parasites\nChapter 10: Trematode Parasites\nChapter 11: Cestodes\nChapter 12: Turbellaria\nChapter 13: Crustacea\nDISEASES AND CONDITIONS CAUSED BY BACTERIA AND VIRUSES\nChapter 14: Viral Gametocytic Hypertrophy\nChapter 15: Bacterial Infections and Associates\nChapter 16: Disseminated Neoplasia\nChapter 17: Germinomas and Other Solid Tumors\nOTHER DISEASES AND PARASITES\nChapter 18: Less-known Pathogens and Associates""]"	['<urn:uuid:010b3aa3-54e5-4642-98bf-d84c3cb6da4b>']	open-ended	direct	long-search-query	distant-from-document	single-doc	expert	2025-05-01T23:21:14.341336	9	76	656
346	I'm curious about local breakfast foods when I travel - what's a typical morning meal that people eat in the Philippines?	Sinangag, which is garlic-fried rice, is a popular local breakfast dish in the Philippines. It is often served with Tapa, which is a delicious dried marinated beefsteak that's fried and typically accompanied by a fried egg.	"['🌎Currency: Piso (PHP)\n🌎Zone: +8 GMT\n🌎Phone Code: +63\n🌎Best time to visit: Dec-Feb\n🌎Must eat: Adobo (Braised Pork)\n🌎Must drink: Tropical Juices\n🌎Don\'t miss: A Jeepney ride!\nAs the Philippines are a combination of islands located in the Pacific Ocean it makes perfect sense to choose to travel there by plane. Manila, it\'s capital,and Cebu are the main gateways to get into the country.\nTravelling to the Philippines from overseas is much easier now, the airport has been modernised and its main airline, Philippine Airlines, is now allowed to fly back to Europe after an absence of many years due to security concerns. However now it\'s ratings have gone up and it\'s among the safest airlines with friendly crew and modern planes.\nYou can also fly to the capital with many international airlines, predominantly Asian airlines and from the Gulf,but also many European and American carries.\nDomestically once you are there, it\'s still very popular to travel by air. Airlines such as Philippine Airlines, Cebu Pacific or Air Asia offer very good connections.\nThere is no train network or busses that can take you around the islands. Transport infrastructure is getting better as the years go by and driving within the islands is the best alternative. Car hire is very cheap as well as petrol.\nIn the Philippines you will quickly discover this is the favourite mode of transport.It\'s famous old fashioned look, similar to that of a jeep but with an extended passenger area enough to sit 20 people is a big step back in time for many travellers willing to try it.\nYear round The Philippines and it\'s capital, Manila, enjoys a very hot and humid temperature. The best times to visit are from December to February, during the cooler months, temperatures averaging 27C. Going July to September you will encounter more rain and often strong winds as the area is subject to Typhoons. March to June are the hottest months and temperatures go over 30C with a high humidity factor.\nThe Filipino Cuisine, has an interesting mixture between Asian and European dishes, specially the Spanish, as The Philippines was conquered by them. Now the food has evolved,and not only traditional dishes but also can find plenty of influence from different countries such as China, Japan, Korea and the United States.\nSome traditional specialities in Manila and the Philippines are: Adobo (Braised pork or chicken in a tangy sauce made from soy, vinegar and garlic) Lechon: (Roasted whole pig, prepared for fiestas and family celebrations), Kare-kare:(An oxtail stew in peanut sauce, Pansit canton:(Chinese-influenced dish of noodles stir fried with meat and vegetables), Sinangag (Garlic-fried rice, a popular local breakfast) Tapa (Delicious dried marinated beefsteak, often fried and served with fried rice and a fried egg, Balut: A par-boiled, fertilised duck’s egg containing a baby chick, served as a beer snack across the archipelago.\nLonganisa (Spanish-style sausage, flavoured with local spices; each province has its own recipe).\nThe most famous drink is the popular locally brewed beer ""San Miguel"". Its available nationwide. Also spirits like rum are quite common to drink in the Philippines.\nNon-alcoholic drinks include the excellent tropical juices found in cafes and restaurants. Even local stalls on the streets can surprise you with local fruits cocktails, milkshakes and juices made with Pineapple, Mango. Vanilla, Banana, Red Berries, Lemon, amongst many more flavours.']"	['<urn:uuid:efadd748-58d5-4b2b-96c5-1228da3a7e95>']	open-ended	with-premise	verbose-and-natural	distant-from-document	single-doc	novice	2025-05-01T23:21:14.341336	21	36	557
348	track analyze measure effectiveness customer journey contact points buying decisions process	From a web analytics perspective, the customer journey tracking focuses on monitoring all customer contact points with websites and online marketing activities that lead to sales contracts. The purpose of this tracking is to achieve transparency about the contact points and helps identify which media and customer journeys effectively lead to buying decisions.	"[""Product Journey or Customer Journey\nThe expression product journey (also called customer journey) describes the consumer´s discovery tour through the product world and the customer´s interaction with the company and other elements during the purchase. During the customer journey, consumers are exposed to a countless number of information and elements supporting the decision-making process. However, it remains questionable, if these elements of the product journey can fulfill the customer's needs regarding information, leadership, decision support and counselling.\nIt has to be differentiated between Customer Journey, On-Site Product Journeyand Cross-Site Product Journey:\nCustomer Journey is not only focused, like the On-Site Product Journey and the Cross-Site Product Journey, on the online use of one consumer during a purchase, but describes all user interactions during the product search and purchase. The list of following contact points and services can be components of the customer journey:\n- Websites and internet services (listed for On-Site Product Journey and Cross-Site Product Journey below)\n- Call Centers\n- Product catalogues\n- Human counsellors\n- Friends, colleagues\n- Advertising (print, radio, TV, banner, outdoor advertising)\nFrom the web analytics perspective the customer journey has the problem, that all costumer´s points of contacts with websites and online marketing activities are concluded with a sales contract. The purpose of this tracking is to achieve transparency about the contact points. These information help to identify the media and customer journeys that led to a buying decisions.\nOn-Site Product Journey\nThe On-Site Product Journey takes place on the website (e.g. of the online-shop or brand websites) and usually follows a path containing these elements:\n- A Homepage providing a product overview and special-topics\n- Category navigation using a hierarchic structure to divide the product range into categories and subcategories\n- Overview tables comparing product features and attributes (usually on the level of single products but also on the level of product lines)\n- Free text searches with a result list of specific products (This is often used as a start entry point for the product search)\n- Product category pages or product line pages\n- Detailed product pages\nThe optimization of the On-Site Product Journey is critical due to the fact that it strongly influences the Conversion rate and\nShopping Experience of the customer's product search. However, the task to create a Product Journey with great user experience that leads the customer through all levels of the hierarchic structure, such as main categories followed by subcategories and detailed product pages can be difficult to realise.\nCross Site Product Journey\nThe Cross-Site Product Journey is conducted via several websites or online-services such as:\n- Price comparison websites\n- manufacture websites\n- Special interest sites\n- Affiliate sites\n- Voucher or cash back services\n- Contact points of online marketing und search engine marketing\n- Forums, review and rating sites\n- Social media, especially reviews and comments connected to specific products in social networks\nThe Cross Site Product Journey can only partially be influenced by the selling or producing company. Therefore, it is rather difficult to optimize. However, with the right tools it is possible to influence the presentation of the company and product on these thrid party websites.""]"	['<urn:uuid:d029de19-139a-418d-bf33-bf4333dbbf8c>']	open-ended	direct	long-search-query	similar-to-document	single-doc	expert	2025-05-01T23:21:14.341336	11	53	526
350	sevastopol panorama crimean war damage ww2	During World War II, the Sevastopol panorama painting was severely damaged. After German bombing caused a fire, the painting was evacuated by ship. Though the ship reached safety, parts of the painting were lost due to flooding. Approximately two-thirds of the original painting was saved, but the remaining portion was beyond restoration.	"[""The 15 x 115-meter painting shows one of the most important and bloodiest battles in history, but which failed to bring decisive victory to either side.\nNapoleon commented about the Battle of Borodino: “The most terrible of all my battles was the one before Moscow. The French showed themselves to be worthy of victory, but the Russians showed themselves worthy of being invincible.”\nArtist Franz Roubaud originally wanted to depict General Yermolov's heroic and successful counterattack that ended with the recapture of the Raevsky Redoubt. Surprisingly, Tsar Nicholas II disagreed because in 1912, when the painting was made, Russia and France enjoyed warm relations and the ruler didn’t want to ruin that.\nTherefore, it was decided to depict another episode – the massive attack of French cavalry on Russian positions. Roubaud was very displeased with this decision: “I am creating a panorama for Russians, but they force me to show the French triumph.”\nIn this painting you see perhaps the most important engagement of World War II - the Battle of Stalingrad. The 16 x 120-meter artwork depicts a key moment that happened on Jan. 26, 1943 when two advancing Soviet armies fought their way against tough opposition to link up on the strategic heights of Mamayev Kurgan.\nWith this successful operation, the already encircled German 6th Army was cut in two, and was soon picked apart and destroyed. The Red Army had achieved the first step in seizing the initiative in the war.\nThe Battle of Stalingrad 3D Panoramic Museum is a part of a huge complex in Volgograd (the current name of Stalingrad), which also includes the monument, “To the Heroes of the Stalingrad Battle,” as well as several thematic museums.\nWhen entering the Sevastopol 3D Panoramic Museum, one is suddenly propelled back to the time of the Crimean War (1853-1856), when the Russian Empire fought a coalition comprised of Great Britain, France, the Ottoman Empire and the Kingdom of Sardinia.\nThe painting, whose dimensions are 14 x 115 meters, depicts the 11-month siege of Sevastopol, known as the Battle for Malakhoff Redoubt. On June 6, 1855, the 75,000-strong Russian army heroically repelled an attack by the 173,000 strong British-French army in what was a bloody clash.\nDuring World War II, the painting survived by a miracle. German bombing left the panorama burning, and while the fire was extinguished in two hours the painting was evacuated from Sevastopol by one of the last ships to depart before the Germans entered.\nAlthough the ship successfully reached a safe harbor, several parts of the painting were lost when the vessel was partly flooded. In the end, about two-thirds of the painting was saved, but the remaining part was impossible to restore.\nIf you ever happen to visit Russia's Far East, the Battle of Volochayevka 3D Panoramic Museum should definitely be on your list. The 43 x 6-meter painting is devoted to a key Civil War battle, when an army of the pro-Soviet Far Eastern Republic crushed the opposing White Army in February 1921.\nThis victory opened the way for the Reds to seize Khabarovsk and Vladivostok, and contributed much to the final defeat of the White movement in the Far East.\nRussia’s newest 3D panoramic museum was opened in January 2018, and is dedicated to Operation Iskra (Spark), which broke the Siege of Leningrad.\nThe panorama depicts the operation's key moment when on Jan. 18,1943, the 123rd Rifle Division and the 372nd Rifle Division broke through German defenses and linked up near the town of Shlisselburg. This is the day that the Siege of Leningrad was officially lifted.\nVisitors can go into trenches, see tanks, military equipment and dozens of replica soldiers. Many items (weapons, personal issues, ammunition, etc) were later discovered on the battlefield by archeologists and amateur search brigades.\nIf using any of Russia Beyond's content, partly or in full, always provide an active hyperlink to the original material.\nto our newsletter!\nGet the week's best stories straight to your inbox""]"	['<urn:uuid:fbd8525e-4fee-41a0-ba39-6b67dae5b299>']	open-ended	direct	short-search-query	distant-from-document	single-doc	expert	2025-05-01T23:21:14.341336	6	52	663
351	I'm interested in winter houses - what's special about Sirdalen House location?	Sirdalen House is located in the Sirdalen Valley in southern Norway, situated on a very steep terrain near one of the ski-slopes of the Ålsheia ski-center. It's surrounded by a mountainous landscape and provides a perfect getaway space all year round.	['Sirdalen House is a holiday house designed by Filter Arkitekter, an architecture studio based in Oslo, Norway. The house is located in the Sirdalen Valley, in Sirdal, a municipality in Vest-Ader county, in southern Norway. Sirdalen House is surrounded by a gorgeous mountainous landscape, providing its owners the perfect getaway space all year round.\nProject description: The plot for the house is situated on a very steep terrain, near one of the ski-slopes of the Ålsheia ski-center. Given the location and the steep plot it had been desirable that the house be dug into the landscape, so it would act as an element integrated into the nature, both winter and summer. From the backside, the terrain continues naturally over the roof. Likewise, the meeting of the side walls and the terrain is preserved, built up and planted in such a way that the straight modern lines find harmony and transition into the natural surroundings in an exciting way.\nSince the house is built using concrete, it will with time acquire a surface stained with water naturally running over the roof and the side walls, which have no built in gutters. Eventually it will also be grown in with moss, so that the concrete will get the same color palette as the rocky hillside around the house. From the back and the sides the house will, after some years, become integrated snuggly into the terrain and not very visible. The surrounding area, including the driveway, will appear as natural landscape – it will be only the house’s straight man-made lines of glass and concrete that will stand out.\nThe house has two floors. The lower floor contains a garage, storage, technical room, a sauna and a living room with a fireplace. The main floor is organized with four equivalent bedrooms around a large common room. The common living room is backed against the terrain and oriented towards south with a full façade-opening. A height difference in the floor divides the kitchen and dining space from the rest of the common living room.\nIn this project, there was a strong desire from the client to have a maintenance-free house, preferably built in concrete. Given the steep plot, which is also subject to landslides, and the need to build the house into the terrain, concrete was a natural choice.\nThe surrounding nature is very present in the house, and it is this that prevents the concrete house feeling cold. It was also important for us to build in wooden elements into the hard concrete-palette of the house. The kitchen, doors, railings and sauna are all executed in wood to soften the impression.\nSome of the main technical challenges were the soil horizontal pressure from the terrain and the large construction span over the living room and kitchen. Solving these problems together with construction engineers was both challenging and rewarding. Norwegian Geotechnical Institute – NGI joined the project from an early phase and made a study which gave guidelines for building and dimensioning of the house. It was also important to make the elegant insulated concrete and glass elements possible. Here the glass-master was of great help. All glass elements are executed with adhesion details, in order to minimize frames and sills.\nThank you for reading this article!']	['<urn:uuid:4e920c3d-b656-4182-b85d-41035dbc31b5>']	open-ended	with-premise	concise-and-natural	similar-to-document	single-doc	novice	2025-05-01T23:46:40.222380	12	41	544
352	what year was human genome sequence completed	The human genome sequence was completed in 2003.	['Figure 1. Diagram showing the road map to personal genome medicine. Since the completion of the human genome sequence in 2003, the research focus in human genetics has moved to how human genome variations affect human health. Human genome variations are considered to be associated not only with hereditary diseases but also with sporadic diseases. In addition, human genome variations are also associated with differences in drug responses and adverse effects. Optimization of treatment and prevention based on personal genome information will soon be a realistic paradigm in clinical practice.\nFigure 2. Diagram showing the paradigm shift (ie, the explosive growth in genome science and medical genomics). Over the past decade, genome-wide association studies (GWASs) using common single-nucleotide polymorphisms (SNPs) have been conducted to identify genomic variations in sporadic neurological diseases. The theoretical framework of GWASs is the common disease–common variants hypothesis. Although GWASs have successfully revealed numerous susceptibility genes for common diseases such as diabetes mellitus, as well as neurodegenerative diseases, the odds ratios associated with these risk alleles are generally low and account for only a small proportion of estimated heritability. The availability of high-throughput genome sequencing technologies will enable us to identify all the genomic variants, and eventually those of disease-relevant alleles based on the common disease–multiple rare variants hypothesis.\nFigure 3. Diagram showing the road map to the identification of disease-relevant variations. Shifting the paradigm from the common disease–common variants hypothesis to the common disease–multiple rare variants hypothesis will lead to the elucidation of the molecular bases of sporadic neurological diseases. Relatively rare sporadic neurological diseases will be good candidates for identifying disease-relevant alleles with large effect sizes because, depending on the effect sizes, the sample sizes can be small. GWAS indicates genome-wide association studies; SNPs, single-nucleotide polymorphisms.\nTsuji S. The Neurogenomics View of Neurological Diseases. JAMA Neurol. 2013;70(6):689-694. doi:10.1001/jamaneurol.2013.734\nSECTION EDITOR: DAVID E. PLEASURE, MD\nAuthor Affiliations: Department of Neurology, Graduate School of Medicine, University of Tokyo, and Medical Genome Center, University of Tokyo Hospital, Japan.\nThe availability of high-throughput genome sequencing technologies is expected to revolutionize our understanding of not only hereditary neurological diseases but also sporadic neurological diseases. The molecular bases of sporadic diseases, particularly those of sporadic neurodegenerative diseases, largely remain unknown. As potential molecular bases, various mechanisms can be considered, which include those underlying apparently sporadic neurological diseases with low-penetrant mutations in the gene for hereditary diseases, sporadic diseases with de novo mutations, and sporadic diseases with variations in disease-susceptible genes. With unprecedentedly robust power, high-throughput genome sequencing technologies will enable us to explore all of these possibilities. These new technologies will soon be applied in clinical practice. It will be a new era of datacentric clinical practice.\nThe elucidation of the molecular bases of neurological diseases is fundamental to the development of disease-modifying and preventive therapies.1 Over the past 3 decades, we have witnessed remarkable progress in the identification of the genes that cause hereditary neurological diseases (Figure 1).2- 4 This has been accomplished mainly on the basis of the research paradigm known as “positional cloning,”5,6 which uses linkage studies to pinpoint the position of genes on chromosomes followed by the identification of the causative gene. The identification of causative genes has further made it possible to develop disease models for hereditary neurological diseases7- 10 and to develop therapeutic strategies.11\nThe majority of neurological diseases, however, are sporadic without any obvious familial occurrence. We are thus faced with the challenge of elucidating the molecular bases of sporadic diseases. Quiz Ref IDIntriguingly, the clinical presentations and neuropathological findings of hereditary forms of neurodegenerative diseases are often indistinguishable from those of sporadic diseases, raising the possibility that common pathophysiologic pathways underlie both hereditary and sporadic neurodegenerative diseases.\nIn contrast to the molecular bases of hereditary neurological diseases, the molecular bases of sporadic neurological diseases, particularly those of sporadic neurodegenerative diseases, largely remain unknown. Quiz Ref IDA potential clue to the molecular bases of sporadic neurological diseases may be the clinical observation that siblings and relatives of a patient with a neurological disease are at an increased risk of developing the same disease; this phenomenon has been observed with regard to Parkinson disease (PD)12 and amyotrophic lateral sclerosis.13 These clinical observations suggest the involvement of genetic factors in these diseases (Figure 1). Until recently, it has been difficult to elucidate the genetic factors underlying sporadic neurological diseases. Rapid advancements in genome science, particularly the availability of massively parallel sequencing technologies that use next-generation sequencers (NGSs), are revolutionizing the neurogenomics view of sporadic neurological diseases. The elucidation of the genomic variants underlying sporadic diseases is expected to provide some answers that will help us to develop disease-modifying and preventive therapies.\nAnother important field is pharmacogenomics, in which genomic variations underlie differences in drug responses and adverse drug effects (Figure 1). This field is currently being introduced into clinical practice.\nThus, it will be essential to better understand how human genome variations affect our health with regard to diseases with Mendelian or complex traits, as well as with regard to pharmacogenomics. Herein, the neurogenomics view of neurological diseases and the future directions of clinical practice are discussed.\nEmerging new technologies for nucleotide sequencing have brought about a remarkable revolution in analyses of the human genome sequence. Compared with a conventional technology (namely, the Sanger method),14,15 the throughput of massively parallel sequencing that uses NGSs16 is increasing dramatically, with the current throughput at 600 GB per run, which means that a sufficient amount of sequence data can be obtained for whole-genome sequencing of at least 4 individuals.17 In typical experiments, billions of short reads (100-150 base pairs [bp]) are obtained. These short reads are aligned to human genome reference sequences, and sequence variations are called through computational analyses.\nCurrently, 2 types of sequencing strategy (namely, whole-exome and whole-genome sequence analyses) are used. Because the cost of whole-genome sequencing is still considerably high, it is not easy to conduct whole-genome sequencing for a large number of individuals. In whole-exome sequence analysis, the enrichment of exonic sequences using oligonucleotide “baits,” which is followed by sequencing, has been preferentially used. With this strategy, all exonic sequences in the human genome can be efficiently enriched.18- 20 With this approach, more than 90% of target regions can be enriched, and these enriched genomic regions are then subjected to massively parallel sequencing using NGSs. This approach is currently being used a lot for the identification of disease-relevant variants21- 31 and even for diagnostic purposes.32- 35\nGiven the ever-increasing throughput of NGSs and the dramatically decreasing costs, it will soon be a realistic approach to conduct whole-genome sequencing for various research applications (Figure 2).36- 40 Studies have shown that there are more than 3 million variations in the human genome of each individual. In one study,40 among the 3.3 million single-nucleotide polymorphisms (SNPs), 8996 known nonsynonymous SNPs and 1573 novel nonsynonymous SNPs were identified. Interestingly, 32 alleles exactly matched mutations previously registered in the Human Gene Mutation Database. In addition, 345 insertions/deletions were observed to overlap in a coding sequence and may alter protein function.40 These findings indicate that, among the numerous candidate variations, it will be a challenge to determine which variations are relevant to diseases.\nGiven the enormous number of short read sequences (~100 bp), informatics analyses, including mapping to reference sequences and indentifying variations, require a huge computational power.41- 45 Furthermore, mutations can be variable, including single base substitutions, insertions/deletions, and structural variations. It is difficult to efficiently identify all the variations using currently available NGSs and software. For example, expansions of repeat motifs identified in frontotemporal dementia and amyotrophic lateral sclerosis46 are difficult to identify using NGSs.\nAs already stated, most of the currently available NGSs produce billions of short reads of 100 to 150 bp. This is the limitation in analyzing various structural variations, some of which may be relevant to neurological diseases. Very recently, single-molecule sequencing technology has become available from Pacific Biosciences; this type of technology enables the acquisition of nucleotide sequences as large as 10 kilobases.47,48 Another single-molecule sequencing technology using nanopores, which allows for the acquisition of much longer sequences,49 will soon become available.\nThe strategies for identifying causative genes for hereditary diseases have been well established.5,6 The chromosomal localization of the disease-causing genes is pinpointed by linkage analysis using polymorphic DNA markers.50- 52 Although a number of genes have been identified by applying these technologies, more than 50% of the genes causing familial amyotrophic lateral sclerosis remain to be identified.53 In families with hereditary diseases, the availability of affected and unaffected individuals is often limited owing to small family sizes and the small number of family members with a confirmed clinical and/or a pathological diagnosis. These circumstances pose a challenge to positional cloning because the candidate regions cannot be narrowed down to small regions that are sufficient for identifying the causative genes by sequencing individual genes in the candidate regions. Despite these difficult circumstances, the availability of NGSs with unbelievably high throughput has made the identification of causative genes possible.31,54,55 Given the large capacity of NGSs, the most essential step (and the bottleneck) is now the collection of as many samples from patients and their families as possible based on well-characterized clinical information, including the correct diagnosis, regardless of family size or number.\nThe elucidation of the molecular bases of sporadic neurological diseases is now a big challenge. Quiz Ref IDWe need to take various mechanisms into account as the molecular bases of sporadic neurological diseases, which include (1) apparently sporadic diseases with low-penetrant mutations in the gene for hereditary diseases, (2) sporadic diseases with de novo mutations, (3) sporadic diseases with variations in disease-susceptible genes, and (4) sporadic diseases with other mechanisms. These different molecular bases are reviewed.\nThere are numerous examples of low-penetrant mutations in apparently sporadic cases of neurological diseases. Sporadic cases of amyotrophic lateral sclerosis due to low-penetrant SOD1 mutations have been well characterized.56- 61 In prion diseases, patients with V180I or M232R mutations in the prion protein (PRNP) gene rarely have a family history of prion diseases, indicating that these patients are usually diagnosed as having sporadic Creutzfeldt-Jakob disease.62\nQuiz Ref IDAlternating hemiplegia of childhood is a rare neurological disorder characterized by early-onset episodes of hemiplegia, dystonia, various paroxysmal symptoms, and developmental impairments. Almost all cases are sporadic, but the concordance of alternating hemiplegia of childhood in monozygotic twins and the dominant transmission in a family with a milder phenotype have been reported. With this background information, Rosenwich et al63 conducted whole-exome sequencing of 3 proband-parent trios to identify a disease-associated gene and then examined whether mutations in the gene were also present in the remaining patients and their healthy parents. Whole-exome sequencing indeed showed 3 heterozygous de novo missense mutations.63 Similar approaches have been used for a number of diseases, including severe epileptic encephalopathy,64 autism, and schizophrenia.65 The rationale for these approaches is based on the hypothesis that patients with severe phenotypes associated with reduced reproductive fitness may harbor de novo mutations.65,66\nTwin studies in which differences in the phenotypes of monozygotic and dizygotic twins were compared have long been conducted to delineate the involvement of genetic factors. Therefore, the comparison of whole-genome sequences of discordant monozygotic twins is expected to accelerate the discovery of genomic variations responsible for the disease phenotypes.67,68\nOver the past decade, genome-wide association studies (GWASs) using common SNPs have been conducted to identify genomic variations associated with sporadic neurological diseases. The theoretical framework of GWASs is the “common disease–common variants” hypothesis, in which common diseases are attributable in part to allelic variants present in more than 5% of the population.69- 71 Although GWASs have successfully revealed numerous susceptibility genes for common diseases such as diabetes mellitus, as well as neurodegenerative diseases, the odds ratios associated with these risk alleles are generally low and account for only a small proportion of estimated heritability.72- 75\nIn GWASs, the general finding that the odds ratios associated with risk alleles identified for disease susceptibility are low indicates that GWASs based on the common disease–common variants hypothesis are not effective in identifying genetic risks with large effect sizes. The current experience with GWASs strongly suggests that rarer variants that are difficult to detect by GWASs may account for the “missing” heritability.17,74 Such rare variants may have large effect sizes as genetic risk factors for diseases. Thus, the paradigm should be shifted from the “common disease–common variants” hypothesis to the “common disease–multiple rare variants” hypothesis to identify disease-relevant alleles with large effect sizes (Figure 3).\nQuiz Ref IDAn excellent example of rare variants with substantially large effect sizes is the recent discovery of the glucocerebrosidase (GBA) gene as a robust genetic risk factor for PD.76,77 A population-based study78 coupled with genealogy information demonstrated that the estimated risk ratio for PD for siblings of patients with PD was significantly high, indicating that genetic factors substantially contribute to the development of sporadic PD. Recent clinical observations79 have suggested the association of sporadic PD with heterozygous mutations in the GBA gene encoding the enzyme that is deficient in patients with Gaucher disease, an autosomal recessive lysosomal storage disease. Furthermore, the comorbidity of PD and Gaucher disease was previously described.80 We conducted an extensive resequencing analysis of GBA in patients with PD and controls, and we found that GBA variants that are pathogenic for Gaucher disease confer a robust susceptibility to sporadic PD and even account for the familial clustering of PD.77 The combined carrier frequency of the “pathogenic variants” was as high as 9.4% in patients with PD and significantly higher than that in controls (0.37%), with a markedly high odds ratio of 28.0 (95% CI, 7.3-238.3) for patients with PD compared with controls.\nWe can draw the following conclusions from the discovery of the major disease-susceptibility gene (GBA) with a large effect size: (1) a genetic factor with a large effect size has been discovered in sporadic PD; (2) in accordance with the large effect size, there is a tendency of familial clustering (multiplex families such as affected siblings); and (3) the disease-relevant allele could not be identified by GWASs using common SNPs and was identified only by nucleotide sequence analysis. These conclusions strongly encourage us to search for disease-susceptibility genes with large effect sizes based on the common disease–multiple rare variants hypothesis. Although the majority of rare missense variants have been suggested to be functionally deleterious in humans,81 it remains controversial whether a comparison of allele frequencies of rare variants (in particular, missense variants) is a sufficient method for identifying variants associated with diseases. Functional annotation of all the variants obtained by comprehensive genome sequencing will no doubt increase the robust power for detecting significant associations of variants with diseases.\nBesides the mechanisms already mentioned, there may be others underlying sporadic neurological diseases. The involvement of somatic mutations occurring in certain cell lineages in sporadic neurological diseases is a potentially interesting mechanism. Such a mechanism in certain types of cancer is well established.82 The involvement of epigenetics in the development of sporadic neurodegenerative diseases is also a potentially attractive mechanism.83,84 Recently, there have been an increasing number of studies suggesting that “prion-like” processes (ie, the propagation of misfolded proteins leading to abnormal aggregation) may be involved in the pathogenesis of sporadic neurodegenerative diseases.85,86 In the field of autoimmune diseases such as multiple sclerosis, the involvement of genetic factors is well characterized. The application of massively parallel sequencing to extensively characterize T-cell receptor repertoires87,88 and immunoglobulin heavy chain genes,89 along with sequence-based typing of HLAs,90,91 will provide new insights into the molecular bases of autoimmune diseases.\nAs discussed in this review, the availability of robust technologies using NGSs will revolutionize our research paradigms for exploring the molecular bases of hereditary and sporadic neurological diseases. Furthermore, these technologies will soon be applied in clinical practice. It will be a new era of datacentric clinical practice. Are we prepared for this new era?\nCorrespondence: Shoji Tsuji, MD, PhD, Department of Neurology, University of Tokyo, Graduate School of Medicine, Hongo 7-3-1, Bunkyo-ku, Tokyo 113-8655, Japan (firstname.lastname@example.org).\nAccepted for Publication: September 4, 2012.\nPublished Online: April 9, 2013. doi:10.1001/jamaneurol.2013.734\nConflict of Interest Disclosures: None reported.']	['<urn:uuid:656b0719-7ce6-4a87-81ed-a7b1224c916d>']	factoid	with-premise	short-search-query	similar-to-document	single-doc	novice	2025-05-01T23:46:40.222380	7	8	2681
353	I'm fascinated by coffee processing methods - what's unique about the honey processing technique used in places like Costa Rica?	The honey processing method involves removing the outer skin of ripe cherries with depulpers, then partially removing the mucilage mechanically while letting the rest dry with the parchment surrounding the green bean. The prolonged contact between the mucilage and parchment results in coffee with rich body and mild acidity. This method has variations called red & black honey, depending on the percentage of mucilage removal.	['The legend begins at Ethiopia where Shepard Kaldi noticed that each time his goats ate seeds from a particular tree they became more active. This tree was the coffee tree which was transferred to Arabic peninsula between 575 – 850 A.D. It is still unclear how it was transferred. It is possible that the African tribes which were traveling north from Kenya and Ethiopia to the Arabic peninsula were carrying seeds with them. There started the evolution of the beverage (the word coffee means beverage and origins from the Arabic word kahwa). At first, it was preferred by the monks who realized that it kept them awake during late night prayers. In the beginning of the 17th century first the Dutch transport the tree from the Arabic peninsula and attend to cultivate it at their colony in Java. Later the plant was taken by the French and was cultivated at Reunion island (Indian Ocean). Then it was transferred to the New World and huge plantations of coffee trees were created. Coffee tree is cultivated in countries located in between the Tropical of Cancer and Sagittarius (due to climate, high temperature and intense rains its cultivation is achieved). Every type of coffee (Greek – filter – espresso) originates from the different baking procedure of the seeds, the way they are milled and the way they are produced. Coffee seeds differentiate with respect to the cultivation location (climate conditions height soil). Taste testing (cupping) is made by specialists and the product is evaluated after numerous tests. The different prices of raw coffee are formed in New York and London markets.\nThe term “specialty coffee” refers to the highest-quality green coffee beans roasted to their greatest flavor potential by true craftspeople and then it is brewed to well-established standards. Specialty coffee is not defined by a brewing method, such as the use of an espresso machine. The definition of specialty coffee begins at the origin of coffee, the planting of a particular varietal into a particular growing region of the world. However, the concept of specialty also includes the care given to the plant through harvest and preparation for export. Specialty coffee in the green bean phase can be defined as a coffee that has no defects and has a distinctive character in the cup. It is not only that the coffee doesn’t taste bad; to be considered specialty it must be notably good. The next phase is roasting, and there is a lot of opportunity here to continually define specialty.\nEvery coffee in combination with every roaster has a potential to express itself in a way that will be most satisfying for every customer. Bringing out a coffee’s distinctive character is the roast master’s challenge. If he comes close to succeeding, then it is still specialty if it started out in the green form as specialty. In roasted coffee, most agree that freshness is a part of the definition for specialty. If the coffee is not highly aromatic, then it no longer deserves to be called specialty.\nThen there is the brewing phase. There are many different methods, and all are capable of brewing beverages that can qualify as specialty coffee, but only if done correctly. The right ratio of coffee to water, the right grind suited to the method and the coffee’s physical characteristics, the proper water temperature and contact time, a good preparation of the coffee “bed” or “cake” are all fundamentals that must be satisfied to produce a specialty cup of coffee.\nSpecialty coffee is, in the end, defined in the cup. It takes many steps to deliver that cup into the customers’ hands. Each of those steps can uphold the classification of specialty if quality has been maintained throughout all the preceding steps.\nThis distinct coffee variety is known for the elongated oval shape of the bean. Typica is also known as “Arabigo” or “Criolo” in Central America. The Typica variety produces a clean and resonant acidity which increases in intensity at higher elevations. The cup can be characterized by lemon and floral notes and by a sweet aftertaste.\nBourbon was first discovered on the island Reunion which is situated near Madagascar and was originally named Bourbon. Bourbon has a distinct flavour and a bright acidity with a winy sweet aftertaste. Bourbon varieties that are cultivated at higher elevations also have some aromatic properties. The beans of this variety are small and round.\nCaturra was first discovered in Brazil. Caturra is a mutation of bourbon and it has the ability to produce good quality with high production volumes. The leaves of the Caturra tree are similar to the bourbon leaves. The cup characteristics of the Caturra variety include a clear acidity with lemony flavour notes, especially at higher elevations. The beans have a dense complexity and a centercut that seems to be embedded into the inner layers of the bean.\nCatuai is a cross of the Mundo novo and Caturra varieties. One benefit of this variety is its resistance against strong winds and rain. The cherries do not easily fall under these conditions. The Catuai variety does not have a distinct flavour profile.\nThis variety is a cross of the Typica and Bourbon varieties. The benefit of this variety is the high productivity levels at medium to high elevations as well as a good resistance to diseases. The flavour profile lacks sweetness and can be characterized by a bitter undertone.\nThis variety is named after a place called “Maragogype” in Bahia, Brazil. In general, the flavour profile of the Maragogype beans which are unusually large is very mild with a subtle sweet acidity.\nThis variety is a cross between the Maragogype and Pacas varieties.\nPaca is a cross between the Caturra and Bourbon varieties.\nCatimor is a cross between an Arabica-Robusta variety from Timor and Caturra. The quality of the Catimor beans is distinct because of its sour acidity with a slightly sharp mouthfeel and a salty aftertaste.\nThis is a variety that comes from elegant trees with large fruits. The cupping profile of the Geisha variety produced in Panama includes a floral aroma with a persistent exotic aftertaste and a resonant refreshing acidity. The Geisha beans have a curvy and thin shape.\nA natural mutant of the Bourbon sub species, occurred in Sarchi town in West Valley, Costa Rica. With good production, it has proven to present complexity in the cup with flavors found in such as green grapes, green apples, sparkling notes.\nA mutation of Typica coffee variety that was first observed in Guatemala. It is also known as Pache Comun.\nThe variety was born in Western Valley of Costa Rica. Villalobos is an exotic variety, where the soil is extremely rich and the micro-clime ideal, to give to the tree the sweetness and balanced acidity, two of its basic characteristics.\nThis is a sub-variety of Colombia (mutation) which was adapted in a laboratory, in order to perform best in specific climates and soils. Today is the variety most grown in Colombia. Sidra It is a crossed variety, made of red Bourbon and Typica, retaining characteristics of both “ancestor” varieties, that result in a balanced impression. In 2013 Sidra was cultivated in Colombia, in the innovative farm La Palma y El Tucan. The Sidra has a unique character, tastes like fresh apple, while its acidity is described as malic.\nIt is a crossed variety, made of red Bourbon and Typica, retaining characteristics of both “ancestor” varieties, that result in a balanced impression. In 2013 Sidra was cultivated in Colombia, in the innovative farm La Palma y El Tucan. The Sidra has a unique character, tastes like fresh apple, while its acidity is described as malic.\nThe flowering of the coffee tree varies according to the production country as well as the microclimate. After 8-9 months, the harvest begins at the same time the flowering takes place. Only ripe cherries are picked, meaning the cherries that have a deep red color or deep yellow color (depending on the coffee variety). These coffee cherries are not affected by diseases or other harming organisms. Besides, only these coffee cherries are characterized for their high quality.\nThe ripe cherries are transferred the same day of the harvest at the processing station. There are several methods used for coffee processing:\n-Honey (red & black)\n-New processing methods\nCoffee processing is a critical stage of the quality chain of the green bean. The way in which the mucilage is being removed, shapes coffee taste.\nThe natural processing method is the oldest method during which the seeds are placed in elevated beds in fine layers so that drying can be done in a natural way, with sun heat. The sugars dry for 10-14 days and the dry hull is removed mechanically with the use of hullers. Factors that affect the processing method are the sun, humidity in the air as well as systematic shaking of the seeds. During the night, the seeds are transferred to a dry place to avoid the increase in humidity concentration.\nThe ripe cherries are compressed through the depulpers and in that way the skin is removed. With the use of water, the seeds with the mucilage are transferred through channels in tanks. Then, the mucilage is removed during the fermentation process. During fermentation, a biochemical reaction takes place or else called hydrolysis of the mucilage that surrounds the coffee seeds. Then the seeds are washed and transferred to the drying station. Drying can be achieved mechanically or with the sun. When humidity inside the bean reaches the desired levels (10-12% of the initial 60%), the green bean is released from the so-called pergaminum and is being classified according to its density. Finally, the green coffee is stored in bags and is ready for export.\nThe outer skin of ripe cherries is removed through depulpers as in the wet processing method. The difference with the pulped natural method is that the seeds are not transferred in tanks where the mucilage is removed, instead they dry with the parchment. This method is applied in countries with low humidity levels.\nHoney (red & black)\nThe honey processing method is used in Costa Rica and Panama and is similar to the pulped natural method, meaning that the outer skin of the ripe cherries is removed with depulpers and the mucilage is partly removed mechanically while the rest dries with the parchment that surrounds the green bean. The long lasting contact of the mucilage with the parchment in combination with the nature of this processing method results in a coffee with rich body and mild acidity. Depending on the percentage of mucilage removal, honey processing method is named red & black honey.\nNew processing methods\nIn Colombia and more specifically at La Palma y El Tucan, they are experimenting with new processing methods such as the aerobic fermentation (38hrs) without the use of water and then the drying of coffee as well as the pulp-covered method (22hrs) and then coffee drying. The objective is to reveal new taste profiles.\nRoasting reveals and supports the dynamics of coffee, it is a science and an art that requires long-term experience, focus and time. Roasting is also considered as the roaster’s signature. During the first stage of roasting, the green beans are dried by gently vaporizing stored water molecules – as heat passes inside the bean, where water molecules are. The beans turn from bluish-green to yellow-orange. As the beans turn from yellow to light brown, going past 160 Celsius degrees, they begin cooking from within. The steam that escapes as well as carbon dioxide begin building pressure on the beans’ cell walls. It is up to the roaster to decide when to end roasting, as the beans go from dark tones of brown to black. The choice for a roast color is a choice for taste. The coffee aroma is created through a series of primary and secondary reactions and more than 1000 compounds have being defined. The coffee beans have a weight loss of 20% due to humidity loss. The Maillard reaction is the driving power behind coffee compounds.\nHigh quality in taste is the ultimate criteria for Specialty Coffees. We systematically cup all coffee samples in our own lab. Therefore, cupping is an integral part of the whole procedure and it is done systematically. The assessment of the aroma, the freshly ground coffee, the flavour and the taste of the freshly brewed cup, as well as the mouthfeel and after-taste, are all important characteristics and determine the coffees personality.\nFor the preparation of great coffees, the barista has to reveal all the unique characteristics of the coffee, taking advantage of his expertise.']	['<urn:uuid:bfc20bba-adf5-4530-9df5-03e5ecb132de>']	factoid	with-premise	verbose-and-natural	distant-from-document	single-doc	expert	2025-05-01T23:46:40.222380	20	65	2109
354	I'm planning to attend a Nigerian celebration and heard there's a special type of cloth everyone wears together - what exactly is this tradition about?	This tradition is called Aso ebi, which in the Yoruba language means 'family cloth'. It's a practice where guests wear coordinated clothing during ceremonies and celebrations. While traditionally Aso ebi was meant for family members during funerals or family ceremonies, the practice has now expanded beyond family, allowing even strangers of the celebrant to wear the Aso ebi during celebrations.	"['What is aso oke?Asked by: Elza Bergnaum\nScore: 4.5/5 (26 votes)\nAso oke fabric, is a hand-woven cloth created by the Yoruba people of west Africa. Aso oke means ""top cloth"" in the English language, denoting cloth of high status.\nWhat is Aso Oke used for?\nAso oke means ""top cloth"" in the English language, denoting cloth of high status. Usually woven by men and women, the fabric is used to make men\'s gowns, called agbada and hats, called fila, as well as women\'s wrappers, called iro and head tie, called gele.\nWhere does Aso Oke originate from?\nIt is the traditional wear of the Yoruba tribe who originate from the south-west of Nigeria. They are the second largest tribe in the Nigeria and Aso-oke is often worn as a celebration cloth on special occasions and important events.\nHow do you care for Aso Oke?\n- Dry clean or hand wash with very mild liquid soap.\n- Hang to dry.\n- No ironing (they don\'t need ironing)\nWhat is the difference between Aso Oke and Aso Ofi?\nAso-Oke is a short form of Aso Ilu Oke also known as Aso-Ofi meaning clothes from the up-country. It is the traditional wear of the Yoruba\'s (the tribe of the southwest people in Nigeria, Africa). The Yoruba\'s are the second largest tribe in Nigeria after the Northerners.\nWhat to consider when selecting your Aso-Oke ft Bimmms24\nWhat is Kijipa?\nKijipa was considered as an ideal cloth for the have-nots, usually referred to as borokini (commoners) because it was rugged and could be used for three or more years. The durability of kijipa made the Yoruba to tag it “akogi-ma-ya” (meaning \'that which is not easily torn\'). ... Sanyan is the father of cloth.\nWhat is aso ebi meaning?\nOrigins. The word aso in Yoruba means cloth and ebi denotes family, so Aso ebi can be described as a family cloth usually worn during funerals or family ceremonies. However, the practice is now beyond family dressing because strangers of a celebrant can wear the Aso ebi.\nHow do you wash a head tie?\nJust wash your hair ties. ""These should be washed daily, and especially after every workout,"" she recommends. ""Thankfully it\'s quite easy: basic soap and water do the trick. For a simple hack, you can put them into the pockets of your clothing and throw them in the wash.\nWhat is Yoruba traditional clothing?\nThe Yoruba wear modern clothings like shirts and trousers, skirts and blouses, suits, gowns that are all borrowed from the Europeans. They also wear caftan, babanriga, Senegalese boubou and the likes that are all borrowed from the Arabs and other cultures in Africa.\nWhat is the cloth of Nigeria?\nNigerian clothing is unique and attractive. Lace, jacquard, adire, and ankara are some of the materials that are used to prepare dresses in Nigeria. Nigerian clothing for women include buba, kaba, iro, gele and iborun or ipele and Nigerian clothing for men include buba, fila, sokoto, abeti-aja and agbada.\nWhat is the name of African fabric?\nWhat is commonly known as “African fabric” goes by a multitude of names: Dutch wax print, Real English Wax, Veritable Java Print, Guaranteed Dutch Java, Veritable Dutch Hollandais. The development of the African print fabric has been referred to as the “result of a long historical process of imitation and mimicry”.\nWhat is the normal length of Aso Oke Gele?\nRegular-headtie size 72"" long × 36"" wide. Sold per pack. This gele is the regular length.\nWhat is Kente made of?\nKente (Akan: nwentoma; Ewe: kete) refers to a Ghanaian textile, made of handwoven cloth, strips of silk and cotton.\nWhat is the name of Yoruba dress?\nYoruba native dress is called Aso ibile. Youruba dress style differs for men and for women, so they never use each other\'s clothes. Before European influence interferes in African culture, Yoruba people dress was made from woven cloth.\nWhat is a Nigerian dress called?\nThe attire is known as darra\'a (Maghrebi Arabic), agbada (Dagomba and Yoruba), and mbubb (Wolof). Agbada is formal attire that is made up of 3 pieces of clothing: an open-stitched full gown, a long-sleeved shirt, and Sokoto (pair of trousers that narrow towards the ankle).\nWhat do Yoruba kings wear?\nAmong the most spectacular beaded objects from Africa are the crowns of Yoruba kings in Nigeria. Yoruba rulers wear crowns on state occasions and during public functions. Most are cone-shaped, with forms or features built up, then embellished over the entire surface with beads of vibrant colors.\nWhat is aso ebi wedding?\nAsoebi simply put is the coordinated clothing of the wedding party. Wedding guests purchase a chosen fabric from the couple to show support and solidarity at the wedding. The fabric is sewn into the guests outfit, which can be any style they choose, and it is then worn to the celebration.\nWhat language is aso ebi?\nIn Yoruba, one of the official languages of Nigeria, “aso” means cloth and “ebi” means family, but aso ebi is commonly worn by friends of the couple and friends of the couple\'s parents as well.\nHow many inches is Aso Oke?\n3 pc Aso oke - Head tie (Gele Wrapper Ipele 3pc set) 1 - Length of Fabric : 2 Yards, Width of Fabric : 27 Inches.']"	['<urn:uuid:92391d0e-8938-4fa5-a657-bc7ba63d8cb2>']	open-ended	with-premise	verbose-and-natural	distant-from-document	single-doc	novice	2025-05-01T23:46:40.222380	25	60	883
355	sensory processing disorder misophonia differences triggers	Sensory Processing Disorder (SPD) and misophonia have different trigger patterns. SPD can involve hypersensitivity to various sensory inputs including noise, light, tastes, touch and movement, while misophonia specifically involves emotional reactions to certain sounds like chewing, slurping, mouth noises and breathing sounds. Additionally, SPD can manifest as either hypersensitivity or hyposensitivity to stimuli, while misophonia reactions are always aversive responses to specific trigger sounds.	['What is Sensory Processing Disorder?\nAs beings living in a physical body, we interact with the world through our sensory system.\nWhat is our Sensory System?\nThe sensory system is a network of neural pathways designed to relay information to the brain about the world around us. Sensory receptors are specialist cells designed to receive and relay stimulus from inside and outside of our bodies. When these messages are received in the brain they are interpreted and then recognized as our senses.\nSometimes this sensory system doesn’t function very well leading to difficulty in processing sensory information. Nowadays we call this disorder ‘sensory processing disorder’.\nSensory Processing Disorder (SPD), has also been known by other names such as Sensory Integration Dysfunction (SID) and Dysfunction in Sensory Integration (DSI). It was first acknowledged as a disorder by the late Jean Ayres, PhD, in the 1950’s. ‘She likened SPD to a neurological ‘traffic jam’ that prevents certain parts of the brain from receiving the information needed to interpret sensory information correctly.’ (Spdstar.org, 2017)\nWe all know about the five senses: taste, touch, sight, smell, and hearing.\nSensory information for these senses is received through the mouth, the skin, the eyes, the nose, and the ears which are all wonderfully designed to pick up and transmit sensory stimulus so that we can interact with the world around us.\nHowever, neurologists believe there may be many more ‘extra’ senses. These include those that provide us with information about the inner state of our bodies, such as hunger, pain, the need to go to the loo etc.\nThese internal senses are also known as interoception – the sense of the internal state of the body.\nOther less well-known internal senses include Proprioception and The Vestibular System.\n‘First consider the senses that relate to the position of our bodies. Close your eyes, and then touch your right forefinger to your left elbow tip. Easy? How did you do it? Somehow you knew where the end of your finger was and you also knew the position of your left elbow. This sense is known as proprioception and it’s the awareness we have of where each of our body parts is located in space. Proprioception is possible thanks to receptors in our muscles known as spindles, which tell the brain about the current length and stretch of the muscles.’ (Jarrett, 2017)\nThe Vestibular System\n‘Now imagine you are blindfolded and I tilted you forwards slowly. You’d immediately have a sensation of how your body’s position was changing in relation to gravity. This is thanks to the fluid-filled vestibular system in your inner ear, which helps us keep balance. This system also gives us our experience of acceleration through space, and it links up with the eyes, making it possible to cancel out our own motion. If you wiggle your head around while reading, for example, you’ll see that it makes little difference to your ability to read and stay focused on the words.’(Jarrett, 2017)\nSometimes the brain has trouble responding to sensory information both internal and external and this has an impact on day-to-day life.\nAccording to Carol Stock Kranowitz, ‘When their central nervous systems are ineffective in processing sensory information, children have a hard time functioning in daily life.’ (Kranowitz, 2005)\nChildren can suffer from disorders that affect the processing of sensory information by causing over-sensitivity (hypersensitivity) – where children cannot cope with too much stimulation e.g. loud noises and touch, or under-sensitivity (hyposensitivity) – where children may actively seek stimulation e.g. they may need to keep moving and touching.\nThose that have sensory hypersensitivity may have difficulties with:\nNoise – even at a normal level noise can be intolerable and disturbing.\nLight and strong patterns can hurt.\nTastes and smells can be overwhelming.\nTouch can be torture.\nMovement especially sudden movements such as being on a swing or being driven in a car may make them feel sick.\nThose that have sensory hyposensitivity may have difficulties with:\nNoise – they may seek out noise.\nLight – They may be drawn to lights and shiny objects.\nTastes – they may enjoy strange, and strong, smells and taste.\nTouch – they may like messy play, textures and heavy pressure\nMovement – they may enjoy spinning and fast-moving play.\nSome children with hyposensitivity may not have a sense of balance, they may continually bump into things, they may drop things, they may not be in control of their bodily functions, or they may eat all sorts of inappropriate things.\n‘Sensory seeker, eats clothes, please design clothes that digest, its awful when it comes out the other end.’ (Designing Clothing for Children with Sensory Challenges, 2017)\nChildren with sensory processing disorder may feel isolated, they may lack self-confidence, withdraw, or exhibit outbursts of anger and inappropriate behaviour. These behaviours can be puzzling, extremely difficult to live with and they are often misunderstood. These children seem to be marching to a different tune.\n‘… subtle areas of their nervous systems are not functioning as they should. These changes result in behaviors that confuse, frustrate, and anger parents and teachers. They wonder why these children lack self-help skills, become aggressive or withdrawn in a group, or refuse to participate in activities or sports.\n. . . we need to remember that behaviors are a message, a symptom – not a diagnosis.’ (Silver 2005)\nWhat these children experience on a daily basis is a form of torture. Torture victims are often subjected to the same kind of sensory information overload that children with SPD experience. The playing of nonstop music, 24-hour lighting, sleep deprivation and loss of comfort and choice are intended to disorientate, confuse, and destroy the mental abilities of prisoners.\n‘Experimental studies with subjects exposed to intense auditory and visual stimuli showed heightened and sustained arousal, discomfort, mood changes, illusions and hallucinations and body image distortions, irritability, distraction, disorientation and a withdrawal from reality. Early work in this area reported that sensory overload could produce symptoms similar to various pathologies and produced thinking and behaviour, particularly speech content, associated with schizophrenia.’ (Leach, 2017)\nTactile defensiveness is the form of sensory processing disorder where a child has hypersensitivity to touch.\nTypically, a child with a sensitivity to touch (tactile sensitivity) will avoid touch – whether from people or objects. They will probably have a clothing sensitivity disorder and need to wear sensory friendly clothing. They may also have other forms of SPD and other conditions – such as autism.They may dislike wearing most (or any) clothes.\n(He) ‘… hates wearing any clothing, hits and punches and screams when getting him dressed. Will keep them on when out but will strip when at home..’ (Designing Clothing for Children with Sensory Challenges, 2017)\nThey may find clothes:\nDifficult to put on\nWhile they are distracted by all this sensory information, they may find it very difficult to make friends, enjoy social situations or to learn at school. Life at home may be difficult.\nA child with any form of SPD should be seen by an occupational therapist who may create a sensory diet aimed at balancing the sensory information that the child is exposed to.\nA sensory diet will be tailored to your child’s individual needs and may include, swinging, heavy pressure, fidget toys, music, weighted blankets, and messy play.\nReducing a child’s sensory overload by creating sensory friendly clothing for them to wear can contribute to their quality of life by creating a calm space in which they can concentrate on their social skills or education.\nMass produced clothing can be reintroduced slowly when the child feels ready to deal with them.\nClothes to Make Kids Happy\nTypically, the sensory friendly clothing in my range includes:\nA loose fit with low necklines\nExternal or enclosed seams\nClothes that can be worn ‘back to front’\nInteresting elements to hold the child’s attention\nTags to which toys, fidget blankets, chews and labels can be attached\nI have created these sewing patterns for children’s clothes to help you and your child enjoy life to the full. The clothes are designed to make kids happy!\nI hope that they will also make the wider family – and social group – a happy place as well.\nFor more information see my Masters Degree Report available to view or buy at Blurb.com\nSpdstar.org. (2017). About SPD. [online] Available at: [Accessed 18 Aug. 2017].\nJarrett, C. (2017). Psychology: How many senses do we have?. [online] Bbc.com. Available at: [Accessed 18 Aug. 2017].\nKranowitz, C. (2005). The out-of-sync child. New York: Perigee Book.\nSilver, L.B. (2005) Foreword.In: C.Kranowitz The Out of Sync Child. New York: Perigee\nLeach, J. (2017). Psychological factors in exceptional, extreme and torturous environments.\nMaddock, R (2017). Survey: Designing Clothing for Children with Sensory Challenges. Hereford: Unpublished.', 'Misophonia is a disorder in which certain sounds trigger an emotional and physical response. It is characterized by strong emotions such as anger and anxiety, as well as physiological responses like increased heart rate or sweating.\nRecent research has indicated that it may be linked to the anterior insular cortex (AIC), which is responsible for integrating outside inputs with internal organs.\nThis article will discuss the causes, symptoms, diagnosis, treatments, and coping strategies for managing triggers. It will also provide resources and support for those who are living with this disorder.\nMisophonia is a poorly understood condition characterized by an aversion to certain sounds that is believed to be mediated by the integration of outside inputs and physiological signs of stress with the anterior insular cortex.\nIt usually appears around age 12 and likely affects more people than we realize, though it often goes unmentioned to healthcare providers.\nDiagnosis requires a case history and audiological test procedures in order to distinguish between misophonia and hyperacusis, which has similar symptoms.\nSubtypes of misophonia, like phonophobia, are also identified based on fear being the dominant factor.\nCommonly observed reactions include avoidance of triggering stimuli, difficulty focusing on tasks unrelated to sound, and mimicry of the stimulus for cancelling it out.\nPhysiological responses such as increased myelination, higher amounts of LDLs, or auditory late potentials may be present in misophonic patients, depending on their individual circumstances.\nAnecdotal cases have linked misophonia with mood disorders or Tourette syndrome, but further research needs to be done to confirm these correlations.\nCurrently, there are no pharmaceutical options available, but tinnitus retraining therapy (TRT) might help manage triggers, as well as neuropsychiatric therapies such as cognitive restructuring or stress inoculation training, which can decrease anger-related behaviours.\nCauses and Physiology\nRecent research has identified physiological causes for the condition, such as heightened stress responses to certain trigger sounds. This may be due to increased myelination of nerve cells in the brain’s anterior insular cortex (AIC).\nThe AIC is a part of the brain responsible for integrating outside inputs, like sound, with those from organs like the heart and lungs, and is thought to play a role in causing misophonia. Studies have found that people with misophonia have higher amounts of myelination than those without it. This suggests that it may result from enhanced limbic and autonomic responses without abnormal enhancement of the auditory system.\nAdditionally, associative learning via classical conditioning could explain some of the neural mechanisms governing misophonia. Overall, these findings indicate an association between heightened levels of myelination in the AIC and physiological responses associated with misophonia.\nPeople with misophonia may experience physiological disturbance or aggravation when confronted with certain sounds, such as chewing, slurping, crunching, mouth noises, tongue clicking, sniffling, tapping, joint cracking and nail clipping. These trigger sounds are most commonly produced by the human body and can cause an emotional reaction that ranges from mild irritation to extreme anger. People with misophonia do not experience irritation when they produce the same noises themselves.\nA study conducted by Edelstein et al. in 2013 found that people with misophonia have higher amounts of myelination in their brains which wrap around nerve cells providing electrical insulation. This suggests a link between misophonic reactions and the integration of outside inputs, such as auditory signals, with internal organ signals like those from the heart and lungs by the anterior insular cortex (AIC).\nFurthermore, physical responses to trigger sounds were observed, which differ from those seen in a control group. Self-treatment methods include leaving the room or finding a way to drown out the noise, while more advanced techniques involve self-distraction or mimicking annoying sounds. Although there has yet to be a successful therapeutic treatment for this condition, it is important for sufferers to identify triggers and find ways to manage them.\n|Trigger Sounds||Emotional Reaction|\n|Chewing||Mild Irritation – Extreme Anger|\n|Slurping||Mild Irritation – Extreme Anger|\n|Crunching||Mild Irritation – Extreme Anger|\n|Mouth Noises||Mild Irritation – Extreme Anger|\nA recent study has developed a new psychoacoustic tool to assess the presence of misophonia, accurately classifying 91% of subjects with and without the condition.\nThe diagnostic criteria used in the study included feelings of irritation, anger, and/or disgust towards specific oral or nasal human-generated sounds, loss of self-control, avoidance behaviours, significant impact on quality of life, and indications that these behaviours are not better explained by other disorders.\nThis method is based on rating natural sounds on a pleasant to unpleasant visual analog scale and using a metric called the CDS score to quantify misophonia. This score can specifically measure aversion towards different sound sources/events such as mouth, breathing/nose, throat and repetitive sounds.\nThe questionnaire used for assessment is the Amsterdam Misophonia Scale (AMS), which consists of 14 items with scores ranging from 1 to 5. A total score of 61 or above suggests a misophonia diagnosis.\nAdditionally, pre-training with white noise was done before carrying out the experiment.\nThe results suggest that this new psychoacoustic test could be an important step forward in diagnosing misophonia reliably and quickly.\nEffective treatment is available, with options ranging from auditory distraction to clinical hypnotherapy and other therapies. There are three main categories of treatments for misophonia: sound therapy, cognitive behavioural therapy (CBT), and alternative therapies. Sound therapy consists of providing auditory stimuli to the person in order to reduce the intensity of the aversive stimuli associated with their triggers.\nDevices such as behind-the-ear sound generators or iPods with headphones can be used. Open-ear headphones like regular AirPods work best for this type of treatment. Alternative therapies can include neurofeedback, biofeedback, muscle relaxation, and hypnotherapy. CBT focuses on identifying unhelpful thought patterns and reactions that contribute to symptoms and replacing them with more positive thought patterns and behaviours. It also teaches people how to manage stress caused by triggers better.\nSufferers should seek out professionals who understand misophonia and have experience treating it in order to find the best treatment option for them, as no single approach will work for everyone’s unique situation. Additionally, comorbid conditions like OCD, anxiety, or trauma need to be addressed when treating the condition, as they may affect one’s ability to respond positively to treatment options.\nTreatment options may vary in effectiveness from person to person, but sound treatment reduces the strength of the trigger sound while not completely eliminating it nor reducing its reaction in some cases; however, any form of proper management can greatly benefit those suffering from this condition if done correctly according to individual needs so they should not give up hope when searching for help!\n|Sound Therapy||Providing auditory stimuli in order to reduce the intensity of aversive stimuli associated with triggers.|\n|Cognitive Behavioral Therapy (CBT)||Identifying unhelpful thought patterns & reactions contributing to symptoms & replacing w/ more positive ones|\n|Alternative Therapies||Neurofeedback, biofeedback, muscle relaxation & hypnotherapy, among others|\nNavigating the challenges can be difficult, but with appropriate coping strategies, individuals can find ways to manage their responses and live meaningful lives.\nCoping mechanisms are varied and personalised depending on an individual’s needs and preferences. For example, accepting oneself and engaging in meaningful conversations with loved ones can help individuals cope with the disorder.\nEarplugs paired with music have been found to be effective for some people, while adjusting one’s position in a room may help to avoid triggers in certain situations.\nPreparing in advance for triggering situations such as family dinners is also beneficial, as is managing stress through activities like watching movies or taking baths. Leaving the situation when necessary is another option that should be considered.\nUltimately, these coping strategies are only meant to provide support and should not replace professional medical advice or treatment such as hypnosis or clinical hypnotherapy, which have been shown to improve functioning for those with misophonia-related stress disorders.\nAccessing support and resources is essential for individuals living with misophonia to manage their condition. People with the condition can find relief by accessing the right support and resources. These include referral to an audiologist, cognitive behavioural therapy, tinnitus retraining therapy, counter conditioning, exposure therapy or clinical hypnotherapist, all of which are designed to help reduce the intensity of trigger misophonia symptoms.\nSupport groups and online communities can provide a platform for discussing experiences as well as providing advice on treatment options that may be available in different countries.\nResources such as the University of Sussex website offers further information about misophonia diagnosis, treatments and strategies for managing triggers. Such resources can prove invaluable in helping people with misophonia better understand their condition and learn how to cope with it on a daily basis.\nWhat is misophonia?\nMisophonia is a condition in which certain sounds trigger a strong emotional response in an individual. Commonly referred to as “sound sensitivity syndrome,” people with misophonia become highly agitated or distressed in the presence of specific sounds.\nWhat are trigger sounds?\nTrigger sounds are specific sounds or stimuli that can elicit an emotional response in individuals affected by it. Some examples of trigger sounds include chewing, lip-smacking, and breathing sounds.\nWhat part of the brain is responsible for misophonia?\nIt is believed to be associated with the auditory cortex and the salience network. These brain areas are thought to be responsible for processing sounds and assigning emotional significance to them respectively.\nIs misophonia a psychiatric disorder?\nMisophonia is not currently classified as a psychiatric disorder in the Diagnostic and Statistical Manual of Mental Disorders (DSM-5), but some experts suggest that the condition may be related to obsessive-compulsive disorder or other psychiatric conditions.\nWhat are the diagnostic criteria?\nCurrently, there are no universally accepted diagnostic criteria for misophonia. However, individuals with misophonia typically report experiencing significant distress or impairment in their daily lives due to specific sounds.\nWhat are common misophonia triggers?\nCommon misophonia triggers include chewing sounds, lip smacking, breathing sounds, tapping, and repetitive noises.\nWhat are the treatment options for misophonia?\nCurrently, there is no cure, but there are a number of treatment options that may be helpful for managing symptoms. These include tinnitus retraining therapy, cognitive-behavioural therapy, and hypnotherapy.\nDo people with misophonia have higher emotional connectivity compared to others?\nResearch suggests that people with misophonia may have increased connectivity between the auditory cortex and other brain areas associated with emotional processing.\nCan misophonia involve visual triggers?\nYes, some individuals with misophonia may also experience a strong emotional reaction to visual triggers, such as repetitive movements or visual patterns.\nThe overall outlook for those suffering from misophonia is optimistic. With a greater understanding of the condition and evidence-based treatments, individuals can learn how to manage their trigger sounds and symptoms.\nThrough effective coping strategies, such as clinical hypnotherapy, relaxation techniques, and lifestyle changes, those affected by misophonia can gain control over their reactions to trigger sounds.\nIrony adds a layer of sophistication to this conclusion: while it is difficult to escape from the effects of misophonia on one’s life, with proper treatment and management, those living with the condition can go on to lead happy and successful lives.']	['<urn:uuid:6b260676-a3c3-4a03-90b5-b6c4bcfc05c2>', '<urn:uuid:461779c3-eeb8-4092-8463-4d50ea32c531>']	factoid	direct	short-search-query	similar-to-document	comparison	expert	2025-05-01T23:46:40.222380	6	64	3287
359	What tricks do attackers use and how can networks defend against them?	Attackers commonly use social engineering tactics like phishing (deceptive emails masquerading as trusted sources), pretexting (creating fake scenarios to manipulate targets), and baiting (leaving infected USBs or setting up malicious WiFi). To defend against these human-based attacks, networks are moving toward zero trust architectures that require continuous verification through multiple factors rather than just perimeter security. Networks must be built assuming attacks will happen and some will succeed, incorporating elements like monitoring, inventory control, and regular assessment.	['Session Recording: https://vimeo.com/246442544 (Available 12/8-1/4)\nNext Sessions Registration: https://networkdefense.clickmeeting.com/cuckoos-egg-5\nThis week, we reviewed chapters 15-23.\nCliff discovers the attacker attempting to find a pathway into the CIA system by querying the Milnet NIC. He doesn’t find any computers, but he does find the names of four people. Cliff calls these people and finally gets in touch with someone to let him know that the attacker was searching for a CIA computer. The CIA take interest and send someone out the following Monday.\nCliff presents his findings to the CIA, including an agent named Teejay. He learns that DOCKMASTER isn’t a Navy shipyard, but actually an unclassified NSA system. The CIA lets Cliff know they can’t do much and it’s up to the FBI to pursue it. Teejay tells Cliff to keep monitoring and keep him informed regardless. He also shares a story about the zero trust model used at the CIA and a time when an insider intercepted agent data. He was caught when a secretary noticed the last login time on her terminal was something unexpected.\nMost Security Practitioners are Choice Architects\nThe story Teejary shared about the CIA is interesting because of how they caught it. A secretary who was on vacation came back and logged in to her terminal. When a user there logs in they see the output of the last successful login they made. The secretary noticed her last login occurred while she was on vacation and she notified someone, which began the investigation that caught the inside attacker. The last login message is a trigger for a choice, and the people who implemented it are choice architects. All security people are, to some degree, choice architects.\nThe concept of libertarian paternalism (note: the term libertarian has nothing to do with politics) poses that it is possible and legitimate for someone to affect behavior while also respecting the freedom of choice. We have the ability to allow users to make their own choices while also “nudging” them towards choices that are in their best security interest. This is why default options exist, for example.\nIn class, we went through several examples of choice architecture that are less than desirable including Facebook’s implementation of “Last Login”, how Word/Excel notify users about macros, and Outlook’s user experience for opening attachment.\n- Choice Architecture: https://www.sas.upenn.edu/~baron/475/choice.architecture.pdf\n- Nudge – A book about choice architecture from Nobel laureate Richard Thaler: https://smile.amazon.com/Nudge-Improving-Decisions-Health-Happiness/dp/014311526X?sa-no-redirect=1\n- Beyond Nudges: Tools of a Choice Architecture: http://www.dangoldstein.com/papers/Johnson_etal_beyond_nudges_tools_ML2012.pdf\nDig Deeper Exercises:\n- Level 1\n- Observe your daily work and note opportunities for security-based choice architecture.\n- Level 2\n- Choose one of the examples you found, or one I presented in class and come up with a way to better nudge users towards a more secure state.\n- Optional: E-mail/DM your idea to me for feedback (firstname.lastname@example.org)\nThe attacker logs back in and finds a password to the Livermore lab network. This lab does secret research and those computers are supposed to be isolated. They have unclassified computers connected to the network, however. Cliff discovers this when he observes the attacker log into the LBL lab from Livermore. He wasn’t aware that was even possible, but as attackers often do, a new pathway was discovered.\nThat attacker breaks into the MIT network from LBL. Cliff calls the network operator and discovers this was likely possible because a scientist who accessed Livermore’s computers also accessed MIT computers, and probably left his password laying around.\nNetwork Architecture, Zero-Trust Networks, Beyond Corp, and Air Gaps\nA network should be built with defensibility in mind. This means building a network assuming you will be attacked, and assuming at least some of those attacks will be successful. I discussed the components of a defensible network as defined by Richard Bejtlich. A defensible network must be: monitored, inventories, controlled, claimed, minimized, assessed, and current.\nTraditional networks are perimeter focused. Many call this the M&M model with a crunch external shell and a soft interior. Things inside the network are trusted, things outside are not. However, the perimeter has shifted over time thanks to the heavy usage of cloud apps for critical services, the needs of remote or WFH employees, and bring your own device (BYOD).\nMany people are now looking to Zero Trust Network models like Google’s BeyondCorp. When you plug into a ZT network, you aren’t automatically afforded any trust. You have to gain trust through multiple factors. Your system has to authenticate via a certificate, the user has to authenticate in two ways, the user has to be enrolled in the proper job classification, and more. All assets are available over the Internet. There’s no VPN to access things anymore or single points of trust assessment, it a combination of multiple rules and trust evaluations going on all the time. This is an oversimplification, but it changes how you might think of a traditional perimeter network.\nAir-gapped networks are those that are theoretically physically disconnected from public Internet-touching networks. I say theoretically because in practice many of them aren’t. Someone once said that an air-gapped network is really just a high latency network.\n- Bejtlich’s Defensible Network Architecture 2.0: https://taosecurity.blogspot.com/2008/01/defensible-network-architecture-20.html\n- BeyondCorp Research Papers: https://cloud.google.com/beyondcorp/#researchPapers\n- How Google Protects its Corporate Security Perimeter: https://www.youtube.com/watch?v=d90Ov6QM1jE\nDig Deeper Exercises:\n- Level 1\n- Research BeyondCorp and examples of real-world deployments outside Google. What were the challenges faced?\nCliff discusses the attack with friends and draws a link between some of the attacker activity. The passwords he’s chosen…jaeger and hunter are german. Benson and hedges are also German — a specific brand of cigarettes.\nThe attacker breaks into an ELXSI super computer at LBL by guessing a password to a default SYSTEM level account. Cliff discovers this and writes a program to slow the computer down to a crawl when the attacker dials into it. This is to not give away that the attacker has been discovered.\nCliff strengthens his monitoring system by purchasing a pager to notify him when a compromised account logs in. This keeps him from sleeping at the office.\nCliff calls the DOE about the Livermore break in. They tell him to keep it quiet, but to call the National Computer Security Center, which operates out of the NSA. The NCSC is receptive, but can’t do anything about it.\nCliff does some legal research and discovers a warrant isn’t legally required to do a phone trace (USCA SS 3121). He looks over his notes and realizes he wrote down all the numbers the VA telco operator said during the trace. There are only a few available permutations, so he social engineers the operator and has her check the registered owner of all of them, claiming he was erroneously charged for calls to these numbers. Only one is active, and it points to MITRE, a defense contractor in McClean, VA.\nHe calls the VA Telco and asks them if they could confirm the number he found on his own. They aren’t supposed to do that, but they do it anyway. This is essentially a form of social engineering by getting someone to confirm a piece of information rather than just asking them for it.\nCliff used social engineering to extract information that he needed to further his investigation. Social engineering in security is an act that influences a person to take an action that may or may not be in their best interest. It usually takes the form of phishing (e-mail), vishing (phone), or impersonation (e-mail, phone, or in person). The human plays a significant role in many breaches. The success rate of external pen tests with humans out of scope is often fairly low (<20%). With humans in scope, it is usually near or at 100%.\nIn class we examined a few different SE scenarios and debated which types of scenarios would be most effective. We discussed Maslow’s Hierarchy of Needs and how attackers will leverage primary and secondary needs to illicit action, supress action, reveal information, or change information.\n- Social Engineering: The Art of Human Hacking, Book: https://smile.amazon.com/Social-Engineering-Art-Human-Hacking/dp/0470639539?sa-no-redirect=1\n- The Social Engineering Framework: https://www.social-engineer.org/framework/general-discussion/\n- Kevin Mitnick’s Books: https://smile.amazon.com/Books-Kevin-Mitnick/s?ie=UTF8&page=1&rh=n%3A283155%2Cp_27%3AKevin%20Mitnick&sa-no-redirect=1\nDig Deeper Exercises:\n- Level 1\n- Go to http://www.malware-traffic-analysis.net/ and go through several of the blog posts. Find malware that relies on SE for execution and consider what human emotion it appeals to.\n- Level 2\n- Review the SE Framework (https://www.social-engineer.org/framework) and plan your own SE attack against an entity you’re familiar with. Don’t actually execute your plan.\n- Level 3\n- Experiment with BeEf to get a sense of what control an attacker has simply by getting you to visit a link.\nHe speaks to a network operator at MITRE who says that it is impossible his network is hacked. He agrees to put a trace on the line and wait for Cliff to call him the next time the attacker logs in. This would validate the connection.\nQuestions to Consider\nAre Zero Trust Networks inevitable for all modern networks?\n- Why or why not?\n- What current challenges exist for specific types of networks (see below) to move towards a ZT/BeyondCorp model?\n- Small networks\n- ICS network\n- International networks\nJanuary 4th 7:30PM ET\nRead Chapters 24-30\nRegister/Attend Here: https://networkdefense.clickmeeting.com/cuckoos-egg-5', 'Security is serious business for nonprofits. Not only do they need to protect themselves from attacks, but they have a responsibility to protect sensitive client and donor data. There are many protocols you can establish to protect your organization, but the first step starts with individual people.\nWhile the technology we depend on has changed over the years, people’s social behavior hasn’t. This leaves us at risk of having our goodwill exploited. In security circles we call this scheming activity “social engineering.” It’s an attempt to acquire sensitive information for malicious reasons through deception.\nAn act of social engineering starts with a lie. The lie doesn’t have to be outright; often it’s easier if the lie has a grain of truth. The best social engineering attempts will frame a thread of misinformation within a jumble of truth. It’s not a matter of if, but when a fraudster will target you or your organization. There are a variety of tactics, so I will focus on three of the most common; phishing, pretexting, and baiting.\nIn a March 2016 article in SC Magazine, a payroll employee at Pivotal Software received an email from CEO Rob Mee asking them for tax information on employees. Not realizing something was wrong, the employee replied with the W-2 information for an unknown number of employees. As you might guess from the title of this article, it was not, in fact, Rob Mee that sent the email.\nPhishing (pronounced “fishing”) seeks sensitive information through a deceptive email that masquerades as a trustworthy source. Typically, this is a wide-net activity: the more people an attacker approaches, the more likely they are to find a victim. If the net is wide enough, even a .01% response rate can be productive. A great example is the common “Nigerian Prince” emails. These scams, known as Advance Fee or 419 scams, have been around in one form or another since the 1920s. They work by convincing their target that they will receive a large payoff in return for providing the would-be fraudster with a “small” amount of funds, sometimes several payments. The fraudster will then make up excuse after excuse and draw out the interaction until the target refuses to give any further money—at which point the fraudster will disappear along with the money, never to be heard from again.\nWe now see these same tactics employed to convince users to download files or attachments which contain malware (in the best case) or Ransomware that encrypts your files, and demands payment in the form of bitcoins before it will decrypt the files again. For those who do not backup their systems to an external device on a regular basis, this can be devastating.\nThe events at Pivotal are an example of a more targeted attack called spear phishing. This type of attack is characterized as a more personalized attack directed at specific individuals, groups, or companies. Whaling is another form of phishing directed at executives and other high-value targets. These attacks often appear in the form of a legal subpoena, customer complaint, or executive issue. In both spear phishing and whaling, the attacker will often spend a great amount of time doing research on their target in order to craft a believable attack that is harder to identify.\n“I’m really sorry to bother you, but I’m running really late for my appointment with the Head of Marketing, and I managed to leave my laptop at home with the client list! He’s really counting on me here—can you forward me a copy?”\nPretexting is creating an invented scenario which engages a target to act in a way they otherwise wouldn’t. To make their scenario more believable, an attacker will often play on their target’s sympathy by crying down the phone, admitting something embarrassing, or telling someone about just how terrible their day has been. The attacks involve a lot of prior research so the attacker sounds as natural as possible and can think on their feet while interacting with their target. Smaller acts of pretexting are often used to gather information as part of a larger attack and are favored by identity thieves.\nOther examples include the “Microsoft phone scam” where the attacker calls claiming to be from Microsoft, saying that your PC has a virus, and that they can help you over the phone. These calls often end with the attacker asking their target to download malicious software onto their computer. Similarly, in the “Grandparent scam” the attacker calls claiming to be a grandchild or other relative stranded abroad and in need of money. Because these attacks play on victims’ fears and ask for immediate action, they are often believable to those who are less tech savvy.\n“Aw sweet, free USB drive!”\nThe modern day Trojan horse. Have you ever found a USB on the ground and wondered what treasures it might hold? Or more likely, you’ve needed to access your email urgently and connected to a Wi-Fi hotspot you didn’t verify first. This attack is all about putting a carrot out and waiting for someone to take it. The USB is infected or a hacker is snooping your web traffic on their Wi-Fi. This is often seen online in the form of free music or movie download advertisements. These adverts will often ask that the victim create an account asking for personal information or the file itself is malware. Baiting is also being seen with phones via cell tower spoofing, meaning a third party could be looking at your call, text, and mobile data in real time without your being aware.\nWhile these attacks seem complex and distinct, they all have commonalities based in simple deception. Awareness and vigilance will go a long way towards protecting yourself.\nPhishing attacks can be combatted in a variety of ways:\n- Verify the source. If you receive a weird email, call the person who supposedly sent it and confirm it was them.\n- Did your bank email you to ask for updated details? Don’t click on the link in the email, use a search engine to navigate to the website yourself and login through secure means. Hovering your mouse over a link will often display the link address (at the bottom of your browser), which makes it easier to confirm its validity.\n- Look for spelling errors or strange grammar. Attackers often purposely include such mistakes to weed out less gullible targets, and make things a little easier for themselves.\n- Distrust emails which demand immediate action. If it’s important, it’s likely you would have been contacted by phone or text.\n- A company who deals with you should know your name. Emails addressed to Dear Customer, Valued Client, etc. are likely fraudulent.\nPretexting is often difficult to spot right away, due to the creative nature of the act:\n- Being polite but suspicious will help. If something seems off, or someone seems too nosey, don’t be afraid to ask questions.\n- If a deal seems too good to be true, it probably is.\n- Whenever possible, verify odd requests from a third source. If your bank calls you to discuss your account but requires you to confirm personal information first, call them back with a known good number or visit in person at a local branch.\nAvoiding baiting attacks is relatively easy:\n- If you wouldn’t pick something up and put it in your mouth, don’t pick it up and put it in your computer!\n- Remember that nothing in life is free. If you are not paying for the product, then you are the product.\nLastly, while it won’t directly protect you, talk to your friends, family, and coworkers about the dangers of social engineering. Social engineering education doesn’t have to be formal to be effective.\nWith social engineering, you can’t avoid being a target, but you can avoid being a victim. Awareness and personal vigilance make all the difference.\nPhoto credit: Damien Jeanmaire']	['<urn:uuid:71d047b2-32cd-43b1-ad8f-47b10a074140>', '<urn:uuid:cf9f4d7f-c584-46f5-935e-9f8414e775ea>']	factoid	with-premise	concise-and-natural	distant-from-document	multi-aspect	novice	2025-05-01T23:46:40.222380	12	77	2858
362	home canning tomato salsa safety steps processing	For safe home canning of tomato salsa, two key aspects must be considered: proper acidity and processing method. When making salsa, commercially bottled lemon juice must be used (not fresh lemon juice) to ensure adequate acidity, since tomatoes have pH values close to 4.6. The processing involves using clean jars, removing air bubbles, leaving 1/2 inch headspace, and processing in boiling water for 15 minutes. After processing, check for proper sealing by ensuring lids are curved in and make a pinging sound when tapped.	"[""(Editor's Note: This article was originally published on July 1, 2009. Your comments are welcome, but please be aware that authors of previously published articles may not be able to respond to your questions.)\nSummer has arrived, and the tomato vines are overloaded with lush, ripe tomatoes. At our house July and August are fiesta months. Yes, it's a virtual tomato festival at our farm. No, we do not throw the tomatoes at one another. Okay, maybe sometimes, but only in good-natured, not so clean, fun. Afterward we congregate to make fiesta salsa. It is not a difficult recipe and is made with or without hot peppers. The recipe does not require a pressure cooker. It uses the boiling water canner method. There is, however, a tedious amount of chopping tomatoes. After the tomatoes are added to the cook pot with the other ingredients the hard work is forgotten as you admire the beauty of the salsa. So gather the entire family, and call it fiesta time. Perhaps have a Mexican theme day at your house. Dress Mexican, cook a Mexican meal and speak Spanish. The kids will love it.\nTo make Fiesta Salsa\nSafety in home canning is imperative. If you are new to home canning, read about proper canning techniques before you begin. The USDA Complete Guide to Home Canning is an excellent source of information.\nYou will need 12 to14 pint-size canning jars, lids and bands. Regular or wide mouth will work fine. Use standard home canning jars. This recipe may be cut in half to make fewer pints if desired. Adjust all ingredients as needed.\n12 to 15 pounds medium-large ripe tomatoes (Hint, we canned 13 pints from 3 plastic grocery bags filled with tomatoes.)\n2 cups chopped onions (Do not cut them into small bits. Chunks are good.)\n1 bunch cilantro, snipped (This is equal to 1/2 to 1 cup)\n1 cup apple cider flavored vinegar\n1 tablespoon salt\nYou may add seeded, chopped peppers to taste. (Jalapeno peppers are good.)\nAll the above ingredients may be adjusted to taste. Sample the salsa as you work. Be careful not to add too much vinegar or salt, however.\nTo begin, clean tomatoes in sink rinsing with cool water until they sparkle.\nTo easily remove skins from the tomatoes, dip them in boiling water for 1-2 minutes. Watch them closely. Some of the tomatoes will require less time for the skins to loosen. Soak the tomatoes in cold water to cool them and to stop the cooking process. Simply fill the sink with cool water and drop the tomatoes in as you remove them from the boiling water. Be careful the tomatoes will be hot.\nTake the tomatoes out of the cooling bath one at a time and slip off the skins. Next you will core and chop the tomatoes.\nKeep in mind that chunky is good. Do not worry if a few tomatoes fall apart in your hand as you chop them. Using a pot large enough to accommodate all those tantalizing tomatoes, combine them with the remaining ingredients. Bring the salsa to a boil. Be sure to stir the salsa so it will not scorch. Once it boils, reduce heat and simmer for 15 to 30 minutes, stirring occasionally. Do not overcook the salsa if you prefer it thick and chunky.\nPrepare the canning jars\n*Check jars for cracks, breaks or chips. Replace all damaged jars.\n*Wash and rinse the jars thoroughly.\nPlace jars and lids in gently boiling water. The jars will break if they are cold when the heated salsa is put in them.\n*Complete these steps before beginning the salsa, if desired.\nCan the salsa\nOnce the salsa reaches desired thickness, fill hot pint jars with it. Leave 1//2 inch headspace in each jar. Remove air bubbles from the salsa by gently stirring a nonmetallic utensil along the inside of the filled jars. Wipe jar tops clean, including the threads. Place hot lids and bands on jars and tighten. Process the filled jars in a boiling water canner for 15 minutes. Remove carefully.\nMakes 9 to 13 pints of fiesta salsa\nDetermine if the jars are sealed\nLook at all the jar's lids. They should be curved in. (concave)\nUsing your finger, press the middle of the lid then release it. If the lid springs up it is not properly sealed. (Sometimes the lid will make a distinct popping noise when it springs up.)\nYou can also tap on the lid with a teaspoon. Listen closely. If the lid makes a dull thud it is not properly sealed. A properly sealed jar lid will ping or ring slightly when tapped.\nGuide to home canning\nFood safety in home canning\nSafe home canning\nCanning recipes and food safety\nCanning methods that should not be used\nDave's garden canning, drying and freezing forum\nFor additional information about home canning, contact your county Extension agent.\nAll photographs are from my garden and farm kitchen."", 'See end of release for a video on canning safely.\nHome canning of fruits and vegetables is regaining popularity thanks to the economic downturn and a growing interest in eating locally grown food. A downside to this practice is that if food is preserved improperly, consumers may become ill or die, according to University of California Cooperative Extension nutrition advisors.\nIf practiced properly, home canning is a safe method for preserving food. The canning process involves placing foods in jars and heating them to a temperature that destroys the microorganisms that cause food to spoil. During this heating process, air is driven out of the jar and as it cools a vacuum seal is formed. This vacuum seal prevents air and microorganisms from getting back into the jar.\nIf tested recipes are not followed, foodborne microorganisms can survive and they will spoil canned foods. Worse, consumers can get botulism from eating improperly home-canned foods. Botulism is a rare, but serious paralyzing illness caused by a nerve toxin produced by the bacterium Clostridium botulinum. Botulism can kill if not promptly treated.\nThere are two safe ways of canning food – the boiling water bath method and the pressure canner method. Boiling water is used with high-acid foods such as fruits. A pressure canner must be used with foods such as vegetables, meats and combinations containing these foods such as salsa or spaghetti sauce. Tested recipes and guidelines must always be followed to ensure safe home-canned foods.\n""It is very important to follow scientifically tested canning instructions to avoid illness."" said Susan Algert, UC Cooperative Extension nutrition advisor for Santa Clara County.\n""The boiling water bath method is safe for fruits, jams, jellies, pickles and other acidic preserves,"" she said. In this method, jars of food are completely covered with boiling water (212 degrees F at sea level) and heated for a specified amount of time.\nHigh-acid foods such as peaches naturally have a pH of 4.6 or less and contain enough acid to prevent the growth of Clostridium botulinum. High-acid foods can be safely canned using the boiling water bath method.\n""Certain foods, such as tomatoes, pears and figs, have a pH value close to 4.6 and must have acid added to them to lower the pH enough to use the water bath method,"" Algert said. The pH can be lowered by adding commercial lemon juice or powdered citric acid.\nWhen canning homemade salsa or other tomato products, Algert recommends following a scientifically tested recipe and using commercially bottled lemon juice to increase the acidity.\n""You can’t use juice squeezed from a fresh lemon because we don’t know exactly how acidic the juice is,"" Algert said. ""Commercial lemon juice meets a standard acidity.""\nTo can low-acid vegetables such as green beans without a pressure cooker, the vegetables must first be pickled using a recommended recipe to ensure the final acidity is too high for Clostridium botulinum to grow.\nClostridium botulinum can form spores, a heat tolerant form of the bacteria that can survive boiling. If spores survive because of inadequate processing, they can revive and allow the bacteria to grow and produce toxins. Clostridium botulinum thrives in low-acid foods like meats and vegetables and in the absence of air in canned foods.\n""The only safe method of preserving vegetables, meats, poultry and seafood to prevent botulism is pressure canning,"" Algert said. ""These low-acid foods require heating to at least 240 degrees F for a time specified for each product. This temperature can only be reached using a pressure canner.""\nTo ensure safety of home canned goods, she recommends using new lids to ensure a tight seal and following scientifically tested instructions.\nFor more information about safely canning food, visit the University of California\'s Food Safety website at http://ucfoodsafety.ucdavis.edu/Consumer_Advice and the USDA National Center for Home Food Preservation website at http://www.uga.edu/nchfp.\n- dairy products\n- all vegetables\n- combination products using these foods\n- most fruits\n- properly pickled vegetables\nFoods that require added lemon juice for boiling water bath canning:']"	['<urn:uuid:298573dd-ba6f-462d-ba5a-d0ca2efa0eee>', '<urn:uuid:b9cb94b6-b1cf-4a2f-ae74-8036f071302f>']	factoid	direct	short-search-query	similar-to-document	multi-aspect	novice	2025-05-01T23:46:40.222380	7	84	1498
363	What was the earliest known medical treatment center specifically built for people with mental health problems, and when was it created?	The first mental hospitals were established in Islamic countries in 792 AD.	['3 Historical Perspectives on Abnormal behavior The Ancient WorldChina (200 BC) Chung Ching stated that both organ pathologies & stressful psychological situations were causes of mental disorders.GreeceHippocrates ( BC) believed mental illness was the result of natural, as opposed to supernatural, causes.Galen ( AD) divided the causes of mental disorders into physical and psychological explanations.\n4 Middle Ages ( AD)Islamic countries- a. mental hospitals were established (792 AD)b. Persian doctor Sina wrote the Canon of Medicine(medications).Europe –abnormal behavior was most frequently viewed as demonic possession.treatment entailed – prayer & exorcism.\n5 The Renaissance ADSpanish nun Teresa of Avila ( ) established the conceptual framework that the mind can be sick.Both Johann Weyer ( ) of Germany and Scot ( ) of England used scientific skepticism to refute the concept of demonic possession.\n6 Humanitarian Reforms (18th-19th century) In France, Philippe Pinel ( ) pioneered a compassionate medical model for the treatment of the mentally ill & established a hospital in Paris.In England, William Tuke ( ) introduced trained nurses for the mentally ill & helped to change public attitudes regarding their treatment.In US, Benjamin rush ( ) founder of American Psychiatry, encouraged humane treatment of the mentally ill & hospitals.\n7 Scientific Advances of the 20th Century Development in technology such as MRI and PET scans have added to our knowledge of the biological bases of psychological disorder.MRI PETDevelopment in pscycho-pharmacology have provided effective treatment for many psychological disorder.\n8 Paraphrase on your own… Article – Nearly 500, mentally ill men and women are serving time in U.S. jails and prisons.Paraphrase on your own…\n10 Abnormal Behavior Definition The behavior that is disturbing (socially unacceptable), distressing, maladaptive (or self-defeating), and often the result of distorted thoughts (cognitions).\n11 Videos – Set up your notes Definitions of Disorders-What does it mean?Rosenhan’s Experiment-What did it entail?Evolution of the DSM –What is it?5 AXES – Write examples for each1. Clinical Disorders2. Intellectual Disabilities & Personality Disorders3. Medical conditions and physical disorders4. Social & Environmental Factors5. The Global Assessment of Functioning\n15 Medical Perspective Explanation: Focus on biological and physiological factors as causes of abnormal behavior .Treated as a disease, or mental illness, and is diagnosed through symptoms and cured through treatment.Treatment: Hospitalization and drugs are often preferred methods of treatment rather than psychological investigation.Example: Schizophrenia needs medication to quiet voices, hallucinations and level dopamine.\n16 Psychodynamic Perspective Explanation: Evolved from Freudian psychoanalytic theory, which contends that psychological disorders are the consequence of anxiety produced by unresolved, unconscious conflicts(childhood).Treatment: focuses on identification and resolution of the conflicts.Example: Child neglected, no love will grow up to not love him/herself or others\n17 Behavioral/Learning Perspective Explanation: Results from faulty or ineffective learning and conditioning.Treatments are designed to reshape disordered behavior and, using traditional learning procedures, to teach new, more appropriate, and more adaptive responses.For example, a behavioral analysis of a case of child abuse might suggest that a father abuses his children because he learned the abusive behavior from his father and must now learn more appropriate parenting tactics\n18 Cognitive Perspective Explanation: People engage in abnormal behavior because of particular thoughts and behaviors that are often based upon their false assumptions. This is how the information is being decoded and retrieved (interpreted or memory issues).Treatments are oriented toward helping the maladjusted individual develop new thought processes and new values.Therapy is a process of unlearning maladaptive habits and replacing them with more useful ones.Example: Anger issues from low road to high road\n19 Social-Cultural Perspective Explain: Abnormal behavior is learned within a social context ranging from the family, to the community, to the culture.Treatment: Introducing and teaching the individual about in abnormal behavior within the culture by comparing and contrasting.Example: Anorexia nervosa and bulimia are psychological disorders found mostly in Western cultures, which value the thin female body\n20 Biological Perspective Views abnormal behavior as arising from a physical cause, such as genetic inheritance, biochemical abnormalities or imbalances, structural abnormalities within the brain, and/or infectionsAgrees that physical causes are of central importance but also recognizes the influence of biological, psychological, and social factors in the study, identification, and treatment of psychological disorders\n21 Bio-Psych-Social Perspective States Psychologists contend that ALL behavior, whether called normal or disordered arises from the interaction of nature and nurture.The bio-psycho-social perspective is a contemporary perspective which assumes that biological, sociocultural, and psychological factors combine and interact to produce psychological disorders.\n23 Abnormal Behavior Disorders – pairs of 3/computer lab Wednesday-Turn in outline/present Friday to peersWhat is the disorder?Explain the disorder.What causes it? (age)SymptomsTreatmentAn example of a case with someone having the disorderCommon or not?\n24 Mood Disorders-Bipolar PET scans show that brain energy consumption rises and falls with emotional swingsDepressed stateManic state\n25 Anxiety DisordersPET Scan of brain of person with Obsessive/ Compulsive disorderHigh metabolic activity (red) in frontal lobe areas involved with directing attention\n26 Psychological Disorders- Etiology DSM-IVAmerican Psychiatric Association’s Diagnostic and Statistical Manual of Mental Disorders (Fourth Edition)a widely used system for classifying psychological disordersHand out\n27 Take out disorder sheet add Borderline Personality disorder\n29 Schizophrenia Schizophrenia literal translation “split mind” a group of severe disorders characterized by:disorganized and delusional thinkingdisturbed perceptionsinappropriate emotions and actions\n30 Schizophrenia Delusions false beliefs, often of torture or greatness, that may accompany psychotic disordersHallucinationsfalse sensory experiences such as seeing something without any external visual stimulus\n31 A few more points to consider… for the Test next class periodA few more points to consider… for the\n32 Schizophrenia Subtypes of Schizophrenia Paranoid: Preoccupation with delusions or hallucinationsDisorganized: Disorganized speech or behavior, or flat or inappropriateemotionCatatonic: Immobility (or excessive, purposeless movement),extreme negativism, and/or parrotlike repeating ofanother’s speech or movementsUndifferentiated Schizophrenia symptoms without fitting one of theor residual: above types\n33 Schizophrenia 40 30 Lifetime risk of developing schizophrenia 20 for relatives ofa schizophrenic40302010GeneralpopulationSiblingsChildrenFraternaltwinof twovictimsIdentical\n34 Psychological Disorders- Etiology Neurotic disorder (term seldom used now)usually distressing but that allows one to think rationally and function sociallyFreud saw the neurotic disorders as ways of dealing with anxietyPsychotic disorderperson loses contact with realityexperiences irrational ideas and distorted perceptions\n35 Anxiety Disorders Anxiety Disorders Generalized Anxiety Disorder distressing, persistent anxiety or maladaptive behaviors that reduce anxietyGeneralized Anxiety Disorderperson is tense, apprehensive, and in a state of autonomic nervous system arousalPhobiapersistent, irrational fear of a specific object or situation\n36 Anxiety Disorders Common and uncommon fears Percentage of people Afraid of itBothers slightlyNot at all afraid of itBeingclosed in,in asmallplacealoneIn a houseat nightPercentageof peoplesurveyed100908070605040302010Snakesin high,exposedplacesMiceFlyingon anairplaneSpidersandinsectsThunderlightningDogsDrivinga carIn acrowdCats\n37 Anxiety Disorders Obsessive-Compulsive Disorder Panic Disorder characterized by unwanted repetitive thoughts (obsessions) and/or actions (compulsions)Panic Disordermarked by a minutes-long episode of intense dread in which a person experiences terror and accompanying chest pain, choking, or other frightening sensation\n38 Anxiety Disorders Common Obsessions and Compulsions Among People With Obsessive-Compulsive DisorderThought or BehaviorPercentage*Reporting SymptomObsessions (repetitive thoughts)Concern with dirt, germs, or toxinsSomething terrible happening (fire, death, illness)Symmetry order, or exactnessExcessive hand washing, bathing, tooth brushing,or groomingCompulsions (repetitive behaviors)Repeating rituals (in/out of a door,up/down from a chair)Checking doors, locks, appliances,car brake, homework\n39 Mood Disorders Mood Disorders Major Depressive Disorder characterized by emotional extremesMajor Depressive Disordera mood disorder in which a person, for no apparent reason, experiences two or more weeks of depressed moods, feelings of worthlessness, and diminished interest or pleasure in most activities\n40 Mood Disorders Manic Episode Bipolar Disorder a mood disorder marked by a hyperactive, wildly optimistic stateBipolar Disordera mood disorder in which the person alternates between the hopelessness and lethargy of depression and the overexcited state of maniaformerly called manic-depressive disorder\n41 Mood Disorders-Depression Percentageof populationaged 18-84experiencingmajordepressionat somepoint In life2015105USA Edmonton Puerto Paris West Florence Beirut Taiwan Korea NewRico Germany ZealandAround the worldwomen are moresusceptible to\n42 Mood Disorders-Depression Age in Years10%8642PercentagedepressedFemalesMales\n43 Mood Disorders- Suicide Suicides per100,000 people70605040302010MalesFemalesThe higher suicide rateamong men greatlyincreases in lateadulthood\n44 Mood Disorders-Suicide Increasing rates of teen suicideYear12%108642Suicide rate,ages 15 to 19(per 100,000)\n45 Mood Disorders-Depression Altering any one component of the chemistry-cognition-mood circuit can alter the othersBrainchemistryCognitionMood\n46 Mood Disorders-Depression Negative Positivebehaviors behaviorsSelf-ratings35%30252015Percentage ofobservationsA happy or depressed mood strongly influences people’s ratings of their own behavior\n47 Mood Disorders-Depression The vicious cycle of depression can be broken at any point1Stressfulexperiences4Cognitive andbehavioral changes2Negativeexplanatory style3Depressedmood\n48 Dissociative Disorders conscious awareness becomes separated (dissociated) from previous memories, thoughts, and feelingsDissociative Identity Disorderrare dissociative disorder in which a person exhibits two or more distinct and alternating personalitiesformerly called multiple personality disorder\n49 Personality Disorders disorders characterized by inflexible and enduring behavior patterns that impair social functioningusually without anxiety, depression, or delusions\n50 Personality Disorders Antisocial Personality Disorderdisorder in which the person (usually man) exhibits a lack of conscience for wrongdoing, even toward friends and family membersmay be aggressive and ruthless or a clever con artist\n51 Personality Disorders PET scans illustrate reduced activation in a murderer’s frontal cortexNormalMurderer\n53 Rates of Psychological Disorders Percentage of Americans Who Have Ever Experienced Psychological DisordersDisorder White Black Hispanic Men Women TotalsEthnicity GenderAlcohol abuseor dependence % % % % % %Generalized anxietyPhobiaObsessive-compulsivedisorderMood disorderSchizophrenicdisorderAntisocial personalitydisorder']	['<urn:uuid:e517e49c-059c-4488-b0c2-bd1430109b44>']	factoid	direct	verbose-and-natural	distant-from-document	single-doc	novice	2025-05-01T23:46:40.222380	21	12	1486
364	behavioral manifestations neurological basis anxiety disorders	Anxiety disorders manifest through both behavioral responses and specific neural pathways. On the behavioral level, people exhibit various coping mechanisms like focused breathing, exercise, and social connection, while also potentially showing avoidance of anxiety triggers. At the neurological level, research has identified specific brain regions involved in anxiety responses, particularly the prelimbic prefrontal cortex (PL) which drives fear responses through connections to the basolateral amygdala (BLA), and the infralimbic prefrontal cortex (IL) which mediates extinction through interactions with inhibitory interneurons in the amygdala. The nucleus accumbens (NAc) is also necessary for expression of avoidance behaviors.	"['Coping with anxiety can be very hard, but there are long and short-term strategies that you can use to help. It is important to note that not all strategies will work for everyone. Some people find coping with anxiety easier with certain strategies while other people find different strategies work better.\nPractice Focused And Deep Breathing\nOne of the best and most commonly used short-term strategies for coping with anxiety is focused and deep breathing. When you use this coping strategy, you need to breathe in and count to 4. You should then breathe out for 4 counts. Doing this for 5 minutes will generally help you calm your anxiety.\nWhen you deep breathe in this manner, you will slow your heart rate. This will help calm you and reduce the side effects of anxiety. Many people also use the 4-7-8 technique to help with their anxiety.\nGo For A Walk Or Do Some Yoga\nAnother short-term strategy is to go for a walk or do some yoga. If you are going for a walk, you do not have to walk very far. A 15-minute walk will be enough to help with your anxiety. 15-minutes of yoga will also help you calm your anxiety.\nDoing this will help you focus your body on something that is not your anxiety. Getting away from the situation that causes your anxiety will help you calm down. If you are going for a walk, you should head somewhere quiet and away from stress.\nLearn And Manage Your Triggers\nIt is possible to identify your triggers on your own or through work with a therapist. There are many people who have obvious triggers such as smoking, caffeine or being in a certain situation. However, there are other people who have less obvious triggers.\nOnce you have determined what your triggers are, you can work at managing them. The best way to manage your triggers is to limit your exposure to the trigger. Of course, this is not always possible and you will need to look at other management strategies.\nKeep Your Body And Mind Healthy\nOne of the long-term strategies that you can use is to keep your body and mind healthy. This will include getting regular exercise and eating balanced meals. You also need to ensure you get enough sleep because a lack of sleep can increase your anxiety.\nConnecting with people can also help you manage your anxiety. Of course, this will not be helpful if being around people is one of your triggers. If you have social anxiety, you will need to spend time in a place you consider safe. If people are not a problem, connecting with other people can help distract you from your anxiety and release some of the tension you carry.\nThere are a few ways that you can manage your anxiety. The strategy that you use will vary depending on your anxiety and your triggers. Working with a therapist will help you manage your anxiety as well and they will be able to help you create a coping strategy.', ""Research on fear learning has transformed the way we think about the etiology and treatment of anxiety disorders such as post-traumatic stress disorder (PTSD). Much of what we know is derived from animal models measuring freezing as a fear response, which resembles exaggerated fear in PTSD sufferers. However people suffering from PTSD also show persistent avoidance of cues associated with their traumatic event. Persistent avoidance interferes with the daily activities, and reduces the opportunity for extinction, thus prolonging PTSD symptoms. Studies in the previous cycle of this grant have shown that the prelimbic prefrontal cortex (PL) drive freezing via projections to the basolateral amygdala (BLA), whereas the infralimbic prefrontal cortex (IL) mediates extinction via projections to inhibitory interneurons within the amygdala. To study avoidance, we have developed a platform-mediated avoidance task (PA) were rats avoid footshock by stepping onto a nearby platform. The platform protects the rat from shock, but also prevents the rat's access to food, similar to clinical avoidance. Furthermore, approximately 30% of rats are unable to extinguish this avoidance response, showing persistent avoidance even after extinction of fear. Preliminary data shows that PL, BLA and the nucleus accumbens (NAc) are necessary for expression of avoidance. However, inactivation of PL and NAc causes rats to revert to freezing behavior. Comparing the effects of manipulations on different behaviors (freezing and avoidance) can help distinguish fear-generating circuits from avoidance-generating circuits.\nIn Aim 1, we will investigate the circuits mediating avoidance using pharmacological, single-unit recording and optogenetic tools.\nIn Aim 2, we will study the neural circuits mediating the extinction of avoidance responses.\nIn Aim 3 we will characterize the neural circuits involved in extinction failure (persistent avoidance). We plan to use optogenetic techniques to silence and/or activate pathways involved in avoidance expression and extinction in order to repair circuits in persistent avoiders.\nThis research will explore the neural mechanisms of avoidance expression and extinction. Understanding normal and persistent avoidance is necessary for anxiety disorders such as PTSD and OCD, in which patients show persistent avoidance. This research could also lead to new ways to increase the effectiveness of pharmacological and extinction-based therapies for the treatment of these disorders.\n|Do Monte, F H; Quirk, G J; Li, B et al. (2016) Retrieving fear memories, as time goes byâ€¦. Mol Psychiatry 21:1027-36|\n|Rodriguez-Romaguera, Jose; Greenberg, Benjamin D; Rasmussen, Steven A et al. (2016) An Avoidance-Based Rodent Model of Exposure With Response Prevention Therapy for Obsessive-Compulsive Disorder. Biol Psychiatry 80:534-40|\n|Rodriguez-Romaguera, Jose; Do-Monte, Fabricio H; Tanimura, Yoko et al. (2015) Enhancement of fear extinction with deep brain stimulation: evidence for medial orbitofrontal involvement. Neuropsychopharmacology 40:1726-33|\n|Do-Monte, Fabricio H; QuiÃ±ones-Laracuente, Kelvin; Quirk, Gregory J (2015) A temporal shift in the circuits mediating retrieval of fear memory. Nature 519:460-3|\n|Do-Monte, Fabricio H; Manzano-Nieves, Gabriela; QuiÃ±ones-Laracuente, Kelvin et al. (2015) Revisiting the role of infralimbic cortex in fear extinction with optogenetics. J Neurosci 35:3607-15|\n|Bravo-Rivera, Christian; Roman-Ortiz, Ciorana; Montesinos-Cartagena, Marlian et al. (2015) Persistent active avoidance correlates with activity in prelimbic cortex and ventral striatum. Front Behav Neurosci 9:184|\n|Rosas-Vidal, Luis E; Do-Monte, Fabricio H; Sotres-Bayon, Francisco et al. (2014) Hippocampal--prefrontal BDNF and memory for fear extinction. Neuropsychopharmacology 39:2161-9|\n|Bravo-Rivera, Christian; Roman-Ortiz, Ciorana; Brignoni-Perez, Edith et al. (2014) Neural structures mediating expression and extinction of platform-mediated avoidance. J Neurosci 34:9736-42|\n|Padilla-Coreano, Nancy; Do-Monte, Fabricio H; Quirk, Gregory J (2012) A time-dependent role of midline thalamic nuclei in the retrieval of fear memory. Neuropharmacology 62:457-63|\n|Sierra-Mercado, Demetrio; Padilla-Coreano, Nancy; Quirk, Gregory J (2011) Dissociable roles of prelimbic and infralimbic cortices, ventral hippocampus, and basolateral amygdala in the expression and extinction of conditioned fear. Neuropsychopharmacology 36:529-38|\nShowing the most recent 10 out of 12 publications""]"	['<urn:uuid:9dd69410-5bfc-4985-bc6b-a134ddb122a1>', '<urn:uuid:45abd8a0-f836-4e33-b98a-6437790a0563>']	open-ended	direct	short-search-query	distant-from-document	multi-aspect	expert	2025-05-01T23:46:40.222380	6	95	1119
365	I'm researching blockchain tokenomics - how does Kin's implementation on Solana handle transaction fees and rewards, and what stake-based security measures are in place?	Kin, as a token on Solana, requires transaction fees paid in SOL for every transaction. These fees compensate validators, reduce spam, and create a transaction market for validation clients. Currently, the Kin Foundation subsidizes these fees for registered apps. Regarding security measures, Solana implements a Proof of Stake system that requires validators to deposit SOL, which remains locked for a specific period. This system serves multiple purposes: it aligns validator incentives through skin-in-the-game deposits at risk, prevents 'nothing at stake' fork voting issues through slashing rules, and provides validator rewards based on participation. The warm-up period lasts days to weeks, followed by a validation period of months to years, during which funds are at risk of slashing but earn rewards.	"[""Accounts are a fundamental component of Kin - it holds Kin balances and allows its owners to send and receive payments. An account is associated with a keypair: the keypair's public address is used as the identifier for the account, while its private seed is used to authenticate transactions for the account.\nAn app index is a unique index assigned to apps who are registered. When you initialize your Kin SDK with your app index, it automatically gets included in the memo of transactions sent by your users and/or backend server. It gets used to track the activity your application generates so you can be rewarded from the Kin Rewards engine. An app index is an unsigned 16-bit integer.\nSee Backend Server.\nSee Client App.\nDescribes how finalized a block is at a point in time. Clients can specify a commitment level in their requests to Agora depending on how certain they want the returned state to be. See Commitment for more details.\nAn earn is a payment from an app to a user (e.g. as a reward for a specific behaviour).\nA keypair is a combination of a public key (i.e. public address) and private key (i.e. private/secret seed). There is a one-to-one correspondence between the private key and the public key created by means of a cryptographic algorithm. This correspondence is asymmetrical, that is, the public key can be easily derived from the private key, but the private key cannot be obtained from the public key. This property of a keypair is used for securing Kin transactions on the blockchain. The private key is supposed to be stored securely by the owner of the account (this is handled by the client SDKs), while the public key serves as the identifier of the account on the blockchain and thus can be freely exposed to anyone. Each transaction sent from an account to the blockchain is signed with a signature derived from the private key (without disclosing it). The blockchain then uses the public key held by the blockchain account to verify that the signature is valid, i.e. created by the owner of the corresponding private key.\nKin is token on the Solana blockchain. 1 Kin = 100000 Quarks.\nKin is a token on the Solana blockchain. Solana is a consumer grade blockchain built for scale. It can currently handle 65,000 transactions per second, on par with Visa. Solana transaction times are roughly 400 milliseconds making it perfect for the consumer applications of all sizes. Solana is also extremely decentralized and secure. Read more at Solana.\nEach participating developer is compensated by the Kin Foundation for their contribution to the growth of the Kin ecosystem. When the rewards engine goes live it will transfer Kin directly from the foundation to the app account on the Kin Blockchain. For more information, please visit https://www.kin.org/kre/.\nThe memo is a field that can be added to each blockchain transaction. It can be used for anything you’d like, the same way you can add a memo on a check from your bank. However, to make full use of Agora features, submitted transactions should include memos adhering to the Kin Binary Memo Format. The format allows apps to associate additional information about the context of a transaction without being limited by the memo size. Additionally, the format allows transactions to get attributed to different apps in order to calculate rewards from the Kin Rewards Engine.\nA payment in Agora simply refers to a transfer of money from one account to another. Payments do not necessarily correspond 1:1 to transactions - a transaction can sometimes contain multiple payments.\nA P2P transaction is a payment from a user to another user.\nA public key is the address (identifier) of an account on the blockchain, which holds the account’s balance and has access to the blockchain data.\nA private key is used for authentication and encryption. It allows unlocking and accessing the Kin blockchain account it belongs to. As such, it should be stored securely by the user or their client device. To be processed by the blockchain, any transactions on a blockchain account have to be signed with its private key (without disclosing the private key itself).\nThe environment that should be used by applications released to users. It interacts with the production blockchain, which is where all public transactions occur.\nThe smallest currency denomination of the Kin blockchain. 1 Quark = 0.00001 Kin.\nA spend is a payment from a user to an app (e.g. to purchase something).\nThe blockchain on which the Kin 4 token is stored and transacted.\nThe environment that should be used by developers to test their integration of Kin/the SDKs. It interacts with a test version of the blockchain. Developers can create accounts and execute transactions freely using this environment.\nAn account that holds token balances. On Solana, a wallet can own multiple token accounts, which may have different addresses from the owner wallet. Kin 4 is a token on Solana, so Kin 4 balances are held in token accounts.\nA transaction modifies the state of a blockchain ledger. A Kin transaction can contain multiple independent operations. Most transactions are used to create accounts or submit payments.\nThese are the fees (in SOL) charged by Solana the blockchain for every transaction. The minimum required fee is dictated by the blockchain. Fees on the Solana are used to:\n- provide unit compensation to the validator network for the CPU/GPU resources necessary to process the state transaction\n- reduce network spam by introducing real cost to transactions\n- open avenues for a transaction market to incentivize validation-client to collect and process submitted transactions in their function as leader\n- and provide potential long-term economic stability of the network through a protocol-captured minimum fee amount per transaction, as described below.\nRegistered Kin apps currently have their fees subsidized by the Kin Foundation when approving transactions via the Sign Transaction webhook. At some point in the future the apps will be responsible for these fees but will be notified well in advance."", 'A Proof of Stake (PoS), (i.e. using in-protocol asset, SOL, to provide secure consensus) design is outlined here. Solana implements a proof of stake reward/security scheme for validator nodes in the cluster. The purpose is threefold:\nAlign validator incentives with that of the greater cluster through\nskin-in-the-game deposits at risk\nAvoid \'nothing at stake\' fork voting issues by implementing slashing rules\naimed at promoting fork convergence\nProvide an avenue for validator rewards provided as a function of validator\nparticipation in the cluster.\nWhile many of the details of the specific implementation are currently under consideration and are expected to come into focus through specific modeling studies and parameter exploration on the Solana testnet, we outline here our current thinking on the main components of the PoS system. Much of this thinking is based on the current status of Casper FFG, with optimizations and specific attributes to be modified as is allowed by Solana\'s Proof of History (PoH) blockchain data structure.\nSolana\'s ledger validation design is based on a rotating, stake-weighted selected leader broadcasting transactions in a PoH data structure to validating nodes. These nodes, upon receiving the leader\'s broadcast, have the opportunity to vote on the current state and PoH height by signing a transaction into the PoH stream.\nTo become a Solana validator, one must deposit/lock-up some amount of SOL in a contract. This SOL will not be accessible for a specific time period. The precise duration of the staking lockup period has not been determined. However we can consider three phases of this time for which specific parameters will be necessary:\nWarm-up period: which SOL is deposited and inaccessible to the node,\nhowever PoH transaction validation has not begun. Most likely on the order of\ndays to weeks\nValidation period: a minimum duration for which the deposited SOL will be\ninaccessible, at risk of slashing (see slashing rules below) and earning\nrewards for the validator participation. Likely duration of months to a\nCool-down period: a duration of time following the submission of a\n\'withdrawal\' transaction. During this period validation responsibilities have\nbeen removed and the funds continue to be inaccessible. Accumulated rewards\nshould be delivered at the end of this period, along with the return of the\nSolana\'s trustless sense of time and ordering provided by its PoH data structure, along with its turbine data broadcast and transmission design, should provide sub-second transaction confirmation times that scale with the log of the number of nodes in the cluster. This means we shouldn\'t have to restrict the number of validating nodes with a prohibitive \'minimum deposits\' and expect nodes to be able to become validators with nominal amounts of SOL staked. At the same time, Solana\'s focus on high-throughput should create incentive for validation clients to provide high-performant and reliable hardware. Combined with potential a minimum network speed threshold to join as a validation-client, we expect a healthy validation delegation market to emerge. To this end, Solana\'s testnet will lead into a ""Tour de SOL"" validation-client competition, focusing on throughput and uptime to rank and reward testnet validators.\nAs discussed in the Economic Design section, annual validator interest rates are to be specified as a function of total percentage of circulating supply that has been staked. The cluster rewards validators who are online and actively participating in the validation process throughout the entirety of their validation period. For validators that go offline/fail to validate transactions during this period, their annual reward is effectively reduced.\nSimilarly, we may consider an algorithmic reduction in a validator\'s active amount staked amount in the case that they are offline. I.e. if a validator is inactive for some amount of time, either due to a partition or otherwise, the amount of their stake that is considered ‘active’ (eligible to earn rewards) may be reduced. This design would be structured to help long-lived partitions to eventually reach finality on their respective chains as the % of non-voting total stake is reduced over time until a supermajority can be achieved by the active validators in each partition. Similarly, upon re-engaging, the ‘active’ amount staked will come back online at some defined rate. Different rates of stake reduction may be considered depending on the size of the partition/active set.']"	['<urn:uuid:fc78e992-3fec-4f4e-9f43-a1580fd82de8>', '<urn:uuid:bb5bef45-c096-456d-997d-069186808e62>']	open-ended	with-premise	verbose-and-natural	similar-to-document	multi-aspect	expert	2025-05-01T23:46:40.222380	24	120	1709
366	How do architectural and urban design principles contribute to both carbon reduction and community development in modern built environments?	Architectural and urban design principles contribute through multiple approaches. They promote walkable neighborhoods where daily needs can be met on foot, reducing car dependency. Buildings use local materials like Cornish granite and slate, which reduces carbon emissions from transportation while supporting local economies. The focus on maintaining and refurbishing existing structures rather than building new ones helps capture embedded emissions. Additionally, these principles emphasize early social infrastructure provision, such as allotment gardens and community centers, which helps create sustainable communities while following circular economy principles that keep assets at their highest value for longer periods.	['Nansledan is being built in accordance with architectural and urban design principles advocated by The Prince of Wales and evolved by the Duchy of Cornwall over more than two decades.\nCentral to these principles is the notion that many modern built environments have promoted fragmentation and isolation by failing to put people at the heart of the design process. Towns often feature housing that is far removed from shops, commercial buildings and leisure facilities, which sit on urban fringes only accessible by car.\nNansledan is different because it has evolved from engagement and discussion with local people so that by design it can meet the needs of those living in it or adjacent to it.\nIn practice this means taking a common-sense approach to urban design by creating a series of walkable neighbourhoods where people can meet their daily needs on foot within a short distance of their home or workplace.\nWith the encouragement of the local planning authorities the whole of Nansledan has been designed from scratch. This masterplanning approach, which looks ahead some 30 years, is essential to achieve a coherent development that is both beautiful and equally very liveable.\nIt also allows for the early provision of social infrastructure. One of the Duchy’s first projects at Nansledan was to build an allotment garden for local people, and a community orchard which has quickly become a thriving local enterprise. Among the first public buildings will be a new primary school and a Methodist church and community centre.\nArchitecture is another vital ingredient. The Prince of Wales has long advocated that buildings should look as if they belong in the landscape in which they are set, reflecting local styles and using local materials which not only reduce carbon emissions but spread the economic benefits of the development through the community.\nNansledan embraces these principles by reflecting traditional local styles through calm, simple and coherent architecture that is brought to life with colour, texture and a palette of local materials including Cornish granite and slate, mined from within an hour of the development. Attention to detail including cornices, railings, balconies and door casings, knits together the whole.\nThat strong sense of place is reinforced by Nansledan’s naming strategy, inspired by The Prince of Wales, which draws upon Arthurian legend and local place names, all of which have been translated into Cornish.\nNansledan is being built by the same consortium of local building companies for the lifetime of the build, which allows for the best solutions and long term arrangements to be put in place. This not only sustains local businesses and suppliers, but also traditional skills, training and apprenticeships.\nNansledan endeavours to set new standards for urban development, not just in the way it is designed and built, but in the way it enables and encourages people to lead their lives in a more sustainable way.\nThe Prince’s Foundation for Building Community has published a prospectus called ‘Building A Legacy, the Landowner’s Guide to Popular Development’. It makes the point that landowners ultimately have total control of how their land is developed, and therefore have a choice right at the start of the development process about taking a longer term approach and building communities, rather than just houses.', 'The net-zero benefits of the principles are accepted, but a bank of strong case studies and knowledge sharing is needed to make it a practical reality.\nThe UK government made a commitment to achieving significant carbon reductions by 2037, but is expected to fail if the current system is not challenged.\nAccording to the Climate Change Committee, the construction and building sector is currently failing to upgrade building stock, while it has already been acknowledged that energy efficiency measures will not be enough to meet net zero targets.\nThe greatest opportunity for reducing carbon in the built environment is not to build anything new at all. And where new or upgraded infrastructure is necessary, significant carbon reductions can be made by minimising the use of virgin materials, designing for recovery and using low-carbon materials.\nWhy we need circular economy principles in the built environment\nCircular economy principles provide this holistic approach, as one of its core goals is keeping assets, components, products and materials at their highest value for as long as possible. The underlying carbon reduction assumption is that using less material results in a lower carbon impact compared to the use of virgin materials.\nCircular economy targets, including amount of waste generated and treated, percentage of recycled content used versus virgin material and percentage of biological material used, drive carbon emissions reduction and support net zero ambitions.\nThis is being endorsed by the standard for managing infrastructure carbon PAS 2080, which presents a hierarchy of options for carbon reduction from building nothing to building less, followed by building smart and, finally, by building efficiently.\nMaintaining and refurbishing rather than dismantling and building new allow embedded emissions – those that are produced by construction processes and building material production - to stay captured in the built environment. This means that setting targets on maintenance and refurbishing, rather than on new builds, is an effective way to reduce carbon.\nFor new projects, the Ellen MacArthur Foundation found that 80% of environmental impacts are determined at the design stage. Waste across the lifecycle of projects should therefore be seen as design flaws and assessed and designed out at early stages.\nUsing recycled material and planning for its recovery are other efficient ways to reduce carbon emissions, providing performance indicators that are easy to measure and track.\nAt the decommissioning stage, biomaterial used can be safely and effectively returned to the soil and other ecosystems, enhancing natural resources and supporting ecosystems, and reusable materials put to reuse.\nRecycling building material is another option to reduce carbon emissions from energy and material waste, though reuse is preferred as recycling processes generate emissions.\nRecovery targets can support the built environment to reduce carbon emissions by pushing for better project design, material quality and maintenance efforts.\nKey issues and challenges\nStudies from the Ellen MacArthur Foundation found that knowledge about circular economy principles is missing in the industry and that it should be circulated more, with a focus on the practical steps necessary to implement actions.\nThe circular economy model needs investors to support it. However, a number of reasons make them cautious.\nCurrently, circular economy projects in the built environment are mainly publicly funded or developed internally. A lack of clarity about the financial outcomes of the projects leads to investors doubting business cases.\nAlso, the construction industry hasn’t seen any disruptive innovation in decades, and not having collaboration and leadership - made difficult by the fragmented industry - in the circular economy model reinforces their caution.\nHaving a leading player in the industry setting circular economy targets and strategies seems to be the key to implementing circular economy principles and accelerating the path to net zero in the built environment.\nHow the South West is adapting\nThe consequences of climate change can already be seen in the South West of England, and it’s predicted to be significantly affected by climate change in the near future, with increased extreme weather events, such as flood, drought and heatwaves.\nThese events directly affect the built environment, and its resilience will be tested more and more, but by embedding circular economy principles, the sector could support climate change mitigation.\nSome councils in the region, including Devon and Cornwall, are already embedding circular economy principles to achieve net zero.\nIn 2019, Devon County Council launched its “Devon Carbon Plan”, a roadmap to achieve net zero by 2050. This plan includes built environment ambitions and targets in terms of retrofitting and net zero new build, which align with circular economy principles.\nIn the same year, Cornwall Council issued its “Climate Change Action Plan”, with one of the three carbon neutral priority projects being in the built environment.\nCornwall’s roadmap includes a specific section on circular economy transition for the commercial and industrial sector, which encompasses the built environment, with the ambition that circular economy principles will become mainstream by 2030.\nMeanwhile, Ricardo Energy & Environment’s Head of Sustainability Hannah Lawrie recently joined the South West Infrastructure Partnership’s (SWIP) steering group to provide specialist circular economy representation.\nShe has more than 20 years’ consultancy experience across waste and resource management, circular economy and sustainability, and is the waste and circular economy specialist on the Task Force set up to produce the Devon Carbon Plan.\nWhile local policymakers understand the urgency and benefits of implementing circular economy principles in the built environment, their ambitions still need to be translated into practical actions.\nThe need for circular economy targets to achieve net zero carbon emissions by 2050 is understood and accepted by all those involved in the built environment, but it cannot be implemented without collaboration and leadership.\nPolicymakers, investors, developers and operators need to work together to develop a circular built environment hub that will drive knowledge sharing and leadership.']	['<urn:uuid:7fa48a16-6b35-408f-bfbf-122f5a0abd65>', '<urn:uuid:8fb2e04b-58a2-4675-905d-c637f925afd9>']	factoid	direct	verbose-and-natural	similar-to-document	three-doc	expert	2025-05-01T23:46:40.222380	19	95	1497
367	I've been analyzing workplace risks and disabilities - how do the physical mobility challenges differ between the recycling collector's work environment and Stephen Hawking's professional career?	The recycling collector's job required significant physical mobility and involved dangerous tasks like jumping on and off trucks, spotting for drivers, and handling recyclable materials. The fatality occurred precisely due to mobility requirements when he fell while attempting to ride on a truck step. In stark contrast, Hawking was almost completely paralyzed by motor neurone disease, yet was able to continue his theoretical physics work and academic career, becoming Lucasian Professor at Cambridge and authoring numerous publications, including his bestseller 'A Brief History of Time'. His physical limitations were accommodated through assistive technologies like his voice synthesizer, allowing him to continue his intellectual work despite severe mobility restrictions.	"['Recycling Collector Dies After Falling Under the Wheels of His Truck\nNew Jersey Case Report: 05NJ077\nReport Date: August 24, 2006\nOn September 2, 2005, a 26-year-old Hispanic recycling collector was killed when he was run over by a recycling truck. The victim worked for a non-profit company that collected recyclable household materials such as bottles and cans. A crew of three was assigned to a new recycling truck, a large commercial vehicle similar to a traditional garbage truck except that recyclables were deposited into bins on the sides of the truck. The crew had just completed collecting recyclables along a residential street and the driver was backing the truck to turn down the next street. The victim stood near the rear of the truck to spot for the driver as he backed up. After completing the maneuver, the driver called for the victim to jump onto the truck so they could drive to the next pick-up. The victim jumped onto a small step leading up to the driver’s seat and grabbed two metal handles as the driver pulled away. Almost immediately, the victim fell from the truck and was run over by the front wheels of the truck, with his legs and pelvis trapped underneath the tire. The driver backed the truck off the victim and called 911 for help. The victim was transported to the local hospital, where he died of his injuries later that morning. NJ FACE investigators recommend following these safety guidelines to prevent similar incidents:\n- All employees should be trained to safely operate and use the different types of collection vehicles.\n- Employers should follow the recommendations in the NIOSH Alert, Preventing Worker Injuries and Deaths From Moving Refuse Collection Vehicles.\n- Employers should conduct a job hazard analysis of all work activities with the participation of the workers.\nOn September 6, 2005, NJ FACE staff received a newspaper article about a Hispanic recycling collector who was killed after falling from and being run over by a recycling truck. A NJ FACE investigator initiated an investigation the following day, conferring with OSHA to determine if the incident was in-scope. The FACE investigator contacted the victim’s employer to request participation in a field investigation, which was conducted on October 5, 2005. During the visit, NJ FACE investigators interviewed the company safety representative and the driver involved in the incident. The recycling truck and the incident site were also examined. Additional information on the incident was obtained from the police report, the medical examiner’s report, and the OSHA investigation file.\nThe victim’s employer was a non-profit, vocational training center that primarily employed people with disabilities. The center had been in operation since 1964 and had a number of programs for both disabled and able-bodied (not disabled) workers by providing labor for the county recycling program, as well as light assembly, custodial, cleaning, and other services. The center also employed persons who were required to pay restitution as part of a conviction for minor crimes and other offenses. The company employed 756 workers, 114 of whom worked in the recycling center. Most of the workers were unionized. A full-time bilingual safety person led monthly safety meetings with classroom videos and discussion. Job training included new employee orientation, classroom, and supervised on-the-job training.\nThe victim was a 26-year-old white Hispanic male recycling collector who had worked for the company for over six months. He was an able-bodied employee who was a member of the union. He had completed his job training and was twice observed working satisfactorily by his supervisors. The victim was survived by his wife and two children.\nThis employer had previously participated in a NJ FACE investigation of a company worker who had been killed in a newspaper baling machine (see NJ FACE report 95-NJ-108Cdc-pdfExternal). The company had also assisted NJ FACE personnel with writing a hazard alert bulletin, Don’t Get Hurt Working Around Sanitation Trucks.\nBack to Top\nThe employer’s recycling program was first initiated in 1982 following an agreement with the county to take over the subcontracted recycling work. The program was successful, and a 20-year agreement was signed in 1995 to provide recycling services throughout the county’s 40 municipalities. A state of the art recycling center was built which allowed the employer to expand into collecting plastics in addition to tin, aluminum, glass, and paper products. The company also supported a bulk waste recycling program based at the local landfill that collects tires, metal, and wood waste.\nMost of the recycling operations were operated out of the recycling center. This was a large, modern industrial complex designed to receive, separate, bale, and ship recyclable materials. The center supported a fleet of 35 recycling and sanitation trucks. The trucks were dispatched on routes throughout the county and were scheduled to pick up recyclable materials in each neighborhood every two weeks. Residents commingled the different recyclable materials together into large plastic recycling containers that resemble garbage cans. The collection crews emptied the containers into the trucks, which are of side-loading or rear-loading design. Once full, the trucks were driven back to the recycling center and emptied. The various materials were separated by machine and by hand, then baled and sold to raw material manufacturers. Approximately 200 tons of recycled materials were processed daily by the facility.\nThe incident occurred on Friday, September 2, 2005. The workers arrived at the recycling center at their usual start time of 7:00 a.m. An extra run was needed to collect additional recyclable materials to make a quota, so a crew was assembled. The usual driver was absent that day, and a supervisor was assigned to fill in for him. This supervisor was an experienced driver with a commercial driver’s license. The rest of the crew included the victim and a second collector, a 33-year-old laborer who had worked for the center for two weeks. At approximately 7:30 a.m., the supervisor drove a truck with the laborers to the county jail to pick up a few items, which they unloaded back at the recycling center. The crew then boarded the collection truck they were to use that day.\nThis truck was a new vehicle that had been in service for two months and had only been used about ten times. The chassis was designed with the cab located forward of the front tires, allowing the cab to be low to the ground for easy entry. The cab was equipped with bi-fold doors on each side that could remain open during operation. The doorways were equipped with large handrails and a small step for entering the truck. The cab had seating for three people, and both the driver’s and passengers’ seats could be folded down for easy entry and exit. This allowed the truck to be operated from a standing position so the driver could easily leave the cab to collect. Mounted to the was a collecting and compacting device, which had been built by a different manufacturer than the truck chassis. This device was designed to be side-loading, with large bins mounted to each side of the truck. The collectors would deposit recyclables into the bins and then would activate a mechanism that raised the bins to the top of the truck where the contents were dumped into the truck’s compactor.\nPhoto 1. Recycling Collection Truck\nPhoto 2. Entry Step to Recycling Truck\nPhoto 3. Position of Victim on Entry Step\nThis truck usually ran with a crew of two, where the driver would also collect recyclables. On this occasion, the driver/supervisor took an additional worker in order to do the job faster. After leaving the recycling center, the crew stopped for coffee at a convenience store before starting their collection route. The weather was clear, with a reported temperature of 78 °F as the crew collected along a wide residential avenue. Although this was the first time the crew worked together, the driver said that the team worked well. As they worked the route, they passed a street to the left before coming to a ‘T’ intersection that marked the end of the street. The driver prepared to back the truck to collect recyclables on the street they had just passed. The victim, wearing a florescent vest, stood behind the truck to spot for the driver as the second collector entered the passenger side of the truck. After backing the truck to the turn, the driver called for the victim to jump or hop onto the truck, which he did by standing on the small step leading to the cab and holding on to the metal handles beside the door. This step was not designed to be a riding step and was built only to access the truck cab. As the driver started to move forward to make the turn, the victim’s hands slipped off the handles and he fell forward of the turning front tire. The driver felt a bump and heard a popping noise and immediately heard the victim yell, “You’re on my legs!” The driver stopped the truck and put it in reverse to back off of the victim, who was lying face down on the road and bleeding from leg and pelvic injuries. The driver went to check on the victim and called 911 on his cell phone as the other laborer went to the nearby intersection to get help. The first 911 call was received at 9:41 a.m., and the first responding police units started first aid on the victim. EMS arrived and transported the victim to a schoolyard where he was picked up by a Medevac helicopter and airlifted to the regional trauma center. Despite treatment, the victim went into shock and was pronounced dead of his injuries at 12:48 p.m. that day.\nBack to Top\nRecommendation #1: All employees should be trained to safely operate and use the different types of collection vehicles.\nDiscussion: The recycling center was using a new truck that had just been put into service. Most of the center’s 34 other trucks were equipped with riding steps for the collectors to stand on between pickups. This truck was designed without a riding step, and the crew was to ride in the passenger compartment between stops. However, the crew had apparently not been properly trained on this type of truck, and improvised by using misusing the entrance step as a riding step. To prevent future incidents, all employees should be trained on the safe use of all the different types of collection vehicles, including the use of riding steps, roadway collection procedures, compactor operation, and basic maintenance. This training may be reinforced by using safety signs that clearly identify riding and non-riding steps on each truck.\nRecommendation #2: Employers should follow the recommendations in the attached NIOSH Alert, Preventing Worker Injuries and Deaths From Moving Refuse Collection Vehicles.\nDiscussion: After analyzing a number of deaths involving sanitation workers, NIOSH published an alert warning of the hazards of working on and around refuse collection vehicles. Although this incident did not involve a garbage truck, many of the NIOSH recommendations apply to this situation. These recommendations include developing a procedure for safely riding and backing the vehicles, only moving the vehicle when the workers are in sight, and developing a signaling system for communicating. It was noted that the recycling center already followed some of these procedures.\nThe NJDHSS pamphlet, Don’t Get Hurt Working Around Sanitation Trucks, has many of these recommendations written in a brief, easy-to-read format. This publication is available in both English and Spanish on the Internet at http://www.state.nj.us/health/surv/documents/sanwk_en.pdfCdc-pdfExternal.\nRecommendation #3: Employers should conduct a job hazard analysis of all work activities with the participation of the workers.\nDiscussion: To prevent incidents such as this, NJ FACE recommends that employers conduct a job hazard analysis (JHA) of all work areas and job tasks with the assistance of the employees. A job hazard analysis is a procedure that breaks down a job or task into specific steps, analyzes each step for specific hazards, and uses this information to develop safe work procedures to eliminate or reduce those hazards. A job hazard analysis should begin by reviewing the work activities that the employee is responsible for and the equipment that is needed. Each task is further examined for mechanical, electrical, chemical, or any other hazard that the worker may encounter. The results of the analysis can be used to design or modify the written standard operating procedures for the job. Additional information is available in the publication, Job Hazard Analysis, which is available on the federal OSHA web site at https://www.osha.gov/Publications/osha3071.pdfCdc-pdfExternal.\nIt is extremely important that employers obtain accurate information on health, safety, and applicable OSHA standards. NJ FACE recommends the following sources of information which should help both employers and employees:\nU.S. Department of Labor, Occupational Safety & Health Administration (OSHA)\nFederal OSHA will provide information on safety and health standards on request. OSHA has four area offices in New Jersey that cover the following counties:\nHunterdon, Middlesex, Somerset, Union, and Warren counties\nTelephone: (732) 750-3270\nEssex, Hudson, Morris, and Sussex counties\nTelephone: (973) 263-1003\nBergen and Passaic counties\nTelephone: (201) 288-1700\nAtlantic, Burlington, Cape May, Camden, Cumberland, Gloucester, Mercer, Monmouth, Ocean, and Salem counties\nTelephone: (856) 757-5181\nWeb site: https://www.osha.gov/External\nNew Jersey Public Employees Occupational Safety and Health (PEOSH) Program\nThe PEOSH Act covers all NJ state, county, and municipal employees. Two state departments administer the act; the NJ Department of Labor and Workforce Development (NJDLWD), which investigates safety hazards, and the NJ Department of Health and Senior Services (NJDHSS) which investigates health hazards. PEOSH has information available that may also benefit private employers.\nNJDLWD, Office of Public Employees Safety\nTelephone: (609) 633-3896\nWeb site: http://lwd.dol.state.nj.us/lsse/employer/Public_Employees_OSH.htmlExternal\nNJDHSS, Public Employees Occupational Safety & Health Program\nTelephone: (609) 984-1863\nWeb site: http://www.state.nj.us/health/eoh/peoshweb/External\nNew Jersey Department of Labor and Workforce Development, Occupational Safety and Health On-Site Consultation Program\nThis program provides free advice to private businesses on improving safety and health in the workplace and complying with OSHA standards.\nTelephone: (609) 984-0785\nWeb site: http://lwd.dol.state.nj.us/labor/lsse/employer/Occupational_Safety_\nNew Jersey State Safety Council\nThe NJ State Safety Council provides a variety of courses on work-related safety. There is a charge for the seminars.\nTelephone: (908) 272-7712.\nWeb site: http://www.njsafety.orgExternal\nOther useful internet sites for occupational safety and health information:\n- CDC/NIOSH – https://www.cdc.gov/niosh/\n- Employment Laws Assistance for Workers and Small Businesses – http://www.dol.gov/elaws/External\n- National Safety Council – http://www.nsc.org/Pages/Home.aspxExternal\n- American National Standards Institute (ANSI) – http://www.ansi.orgExternal\n- Product recall information – http://www.recalls.govExternal\n- NJDHSS FACE reports – http://www.state.nj.us/health/eoh/survweb/face.htmExternal\n- CDC/NIOSH FACE – https://www.cdc.gov/niosh/face/\nNIOSH Alert: Preventing Worker Injuries and Deaths From Moving Refuse Collection Vehicles. DHHS NIOSH Publication No. 97-110, NIOSH Publications Dissemination, 4676 Columbia Parkway, Cincinnati, OH 45226-1998. Telephone: (800) 356-4674, FAX (515) 533-8573\nJob Hazard Analysis. U.S. Department of Labor Publication # OSHA-3071, 2002 (revised). U.S. Department of Labor, OSHA Publications, P.O. Box 37535, Washington D.C. 20013-7535\nTelephone: (202) 693-1888, Fax: (202) 693-2498\nDon’t Get Hurt Working Around Sanitation Trucks. E. O’Hagan, NJ Department of Health & Senior Services, Trenton NJ 08625\nNew Jersey FACE Program\nFatality Assessment and Control Evaluation (FACE) Project\nInvestigation # 05-NJ-077\nStaff members of the New Jersey Department of Health and Senior Services, Occupational Health Service, perform FACE investigations when there is a report of a targeted work-related fatal injury. The goal of FACE is to prevent fatal work injuries by studying the work environment, the worker, the task and tools the worker was using, the energy exchange resulting in the fatal injury, and the role of management in controlling how these factors interact. FACE gathers information from multiple sources that may include interviews of employers, workers, and other investigators; examination of the fatality site and related equipment; and reviewing OSHA, police, and medical examiner reports, employer safety procedures, and training plans. The FACE program does not determine fault or place blame on employers or individual workers. Findings are summarized in narrative investigation reports that include recommendations for preventing similar events. All names and other identifiers are removed from FACE reports and other data to protect the confidentiality of those who participate in the program.\nNIOSH-funded state-based FACE Programs include: Alaska, California, Iowa, Kentucky, Massachusetts, Michigan, Minnesota, Nebraska, New Jersey, New York, Oklahoma, Oregon, Washington, West Virginia, and Wisconsin. Please visit the NJ FACE web site at http://www.state.nj.us/health/eoh/survweb/face.htmExternal or the CDC/NIOSH FACE web site at https://www.cdc.gov/niosh/face/ for more information.\nThis NJ FACE report is supported by Cooperative Agreement # 5 U60 OH0345-02 from the Centers for Disease Control and Prevention (CDC). Its contents are solely the responsibility of the authors and do not necessarily represent the official views of the CDC.\nTo contact New Jersey State FACE program personnel regarding State-based FACE reports, please use information listed on the Contact Sheet on the NIOSH FACE web site. Please contact In-house FACE program personnel regarding In-house FACE reports and to gain assistance when State-FACE program personnel cannot be reached.', 'Morreu o célebre físico Stephen Hawking\nMarch 14, 2018 -- O físico Stephen Hawking – o célebre autor de Uma Breve História do Tempo – morreu aos 76 anos. Segundo a família, morreu pacificamente na sua casa de Cambridge, às primeiras horas de quarta-feira. Passou a maior parte da vida quase completamente paralisado por uma doença neuronal.\nHawking, who has been paralysed by motor neurone disease for over 55 years, is renowned for his work on black holes, cosmology and quantum gravity but is perhaps best known as the author of A Brief History of Time, which has sold over 10 million copies.\nIt was a few months before his 1965 wedding to linguist Jane Wilde that a brilliant graduate research student took a tumble down a flight of stairs at Cambridge University. Stephen Hawking, the eldest of four children whose mother had escaped the London Blitz to give birth to him in the relative safety of Oxford, had been growing increasingly unsteady on his feet and had begun to have difficulty with his speech. Doctors had declared the onset of amyotrophic lateral sclerosis, or ALS -- a type of motor neurone disease -- two years earlier when Hawking was 21. Now came dramatic proof that the incurable condition, in which the body’s muscles -- including those needed to keep breathing -- gradually stop working, was progressing. With an average survival rate of two or three years, Hawking did not expect to live long enough to finish his PhD. His bride-to-be has since reflected that this was the era of nuclear warfare development, the four-minute warning; in such an atmosphere the couple went ahead with their marriage. ""We were great ones for taking a chance on life,"" she has said.\nIn the decades since, Hawking has challenged conventional thinking on many fronts, from his illness -- his case is the most extended recorded for a person with ALS -- to the origins of the universe itself. In 1974, this exceptional young physicist, whose father had been a research biologist, put forward groundbreaking theories about the nature of black holes, areas of spacetime with an intense gravitational pull from which nothing can escape. Hawking argued that black holes were not completely dark and did, in fact, emit radiation, thereby providing the key to understanding how the universe was formed. He further conjectured that the cosmos was boundless and that its beginning was down to the laws of science, without any need for a creator. His insights earned him membership of the Royal Society -- a fellowship of the world\'s most eminent scientists -- at the unusually tender age of 32.\nFollowing in the footsteps of Sir Isaac Newton, who 300 years earlier had discovered the law of gravity on which Hawking built his theories, he became Lucasian Professor of Mathematics at Cambridge in 1979, a post he would hold for the next 20 years. He might have remained celebrated only within academic circles had he not wished to share his knowledge with a non-specialist public. His 1988 science tome, A Brief History of Time, was such an instant success that when the publishers, realising a photograph had been printed upside down, attempted to recall it, they found all the books had been bought. Since then there have been several reprints with some 10 million copies sold. Hawking wrote that his goal was simple: ""..complete understanding of the universe, why it is as it is, and why it exists at all.""\nAn emergency tracheotomy to save him from pneumonia robbed Hawking of the remains of his voice in 1985, and he has since become associated with a voice synthesiser which he operates with his cheek. His marriage to Jane, with whom he had three children, broke down after, as she put it, ""fame and fortune muddied the waters and..took him way out of the orbit of our family."" Hawking married his nurse, Elaine Mason, in 1995 but divorced her 11 years later amid claims, by other carers, that she had physically abused him. With his daughter, Lucy, Hawking has published a series of science books for children, from whom he receives many inquiring letters.\nHawking gained popularity outside the academic world and appeared in several TV shows including The Simpsons, Red Dwarf and The Big Bang Theory. (Story: Susan Shepherd)']"	['<urn:uuid:e76eab27-edcf-4696-9093-e4a280c4f2a1>', '<urn:uuid:8cc7798c-07fe-4be7-b4e1-6b497ff14ccd>']	open-ended	with-premise	verbose-and-natural	distant-from-document	comparison	expert	2025-05-01T23:46:40.222380	26	108	3532
369	how seasoned wood burning differs from gas fireplace safety concerns	Seasoned wood requires 6-12 months of drying to reduce moisture content below 20% and burns more efficiently with fewer byproducts during combustion. Gas fireplaces, while more convenient to operate with instant ignition, come with different safety concerns including carbon monoxide risks, potential gas leaks, and chimney fire hazards that can cause up to $125 million in property damage annually.	"[""S Safety_pilot_system | Safety_Pilots | Safety_Pilots | SAFETY_SHUTOFF | Seasoned | Seasoned | Seasoned | Seasoned | Seasoned_Wood | SECONDARY_AIR | SEDIMENT_TRAP | SEER | Sight_Opening | SILICONE_SEALANT | Smoke_Chamber | SMOKE_CHAMBER | Smoke_shelf | SMOKE_SHELF | SOLID_FUEL | Spark_arrestor | SPARK_ARRESTOR | Spill_Switch | Spill_Switch | Spill_Switch | Spillage | Spillage | Spillage | Split_System | Standing_Pilot_Ignition | STEADY_STATE_EFFICIENCY | Steamers | Steamers | Steamers | Stove |\n1. Safety pilot system:\nThis is a safety system that monitors the gas flow. It ensures that gas cannot leak into the burner unless a pilot light has been lit. These are standard in gas fireplaces that comply with the American Gas Association regulations.\nSubmitted on Saturday, October 10, 2015 12:27:05 PM\n2. Safety Pilots-This is a safety shutoff for gas flow, consisting of three components that includes the thermocouple, electromagnetic power unit (EMU), and pilot assembly\nSubmitted on Thursday, December 11, 2014 12:27:05 PM\n3. Safety Pilots:-A safety shutoff, stops the flow of the gas to the appliance, and provides a heat source to ignite the main burner.\nSubmitted on Wednesday, July 08, 2015 12:27:05 PM\n4. SAFETY SHUTOFF:\nA device, powered by a thermocouple, designed to shut off the gas supply to the pilot and or main burner if the source of ignition fails.\nSubmitted on Tuesday, October 06, 2015 12:27:05 PM\nDefinition:refers to cordwood that has been allowed to dry before burning. Seasoning generally takes six to 12 months. Wood burns much more efficiently when its moisture content has been reduced.\nSubmitted on Thursday, July 03, 2014 12:27:05 PM\n6. Seasoned-refers to fuel wood that has been allowed to dry before burning. Seasoning generally takes six to 12 months. Wood burns much easier when its moisture content has been reduced. Freshly cut woods contains over 20% water.\nSubmitted on Wednesday, July 20, 2016 12:27:05 PM\nrefers to fuel wood that has been allowed to dry before burning. Seasoning generally takes six to 12 months. Wood burns much easier when its moisture content has been reduced. Freshly cut woods contains over 20% water.\nSubmitted on Friday, July 11, 2014 12:27:05 PM\nRefers to fuel wood that has been allowed to dry before burning. Seasoning generally takes six to twelve months. Wood burns much easier when its moisture content has been reduced. Freshly cut wood contains over 20 percent water.\nSubmitted on Friday, May 13, 2016 12:27:05 PM\n9. Seasoned Wood\nThis is a term referring to fire wood that has been allowed to dry before being burned. This drying process usually takes approximately 12 months but is advantageous as the wood burns easier. Burning dry wood also releases fewer by-products during combustion than freshly cut wood, which holds more than 20% moisture.\nSubmitted on Sunday, February 21, 2016 12:27:05 PM\n10. SECONDARY AIR:Combustion air directed downstream of the primary combustion zone (but still in the appliance) to support the combustion of remaining combustible gases; does not directly influence the rate of primary combustion.\nSubmitted on Monday, April 25, 2016 12:27:05 PM\n11. SEDIMENT TRAP\nDefinition:In gas piping, a tee device to intercept or hold solid foreign particles to prevent them from blocking valves or orifices. Not part of an appliance, must be installed as close to appliance inlet as possible. Also referred to as a Drip Leg.\nSubmitted on Friday, February 27, 2015 12:27:05 PM\nSeasonal Energy Efficiency ratio. A measure of cooling efficiency for air conditioners. The higher the SEER, the more energy efficient the unit. The government's minimum SEER rating is 10.\nSubmitted on Sunday, February 19, 2017 12:27:05 PM\n13. Sight Opening\nDefinition:the primary opening in a mantel (also known as the daylight opening).\nSubmitted on Thursday, January 15, 2015 12:27:05 PM\n14. SILICONE SEALANT\nDefinition:Process of sealing cracks with a high temperature silicone sealant.\nSubmitted on Sunday, January 31, 2016 12:27:05 PM\n15. Smoke Chamber-an enlarged area between the throat of a fireplace and the chimney flue.\nSubmitted on Friday, October 16, 2015 12:27:05 PM\n16. SMOKE CHAMBER:The section of a masonry fireplace that contains the smoke chamber walls and the smoke shelf and located above the throat or damper area and below the flue.\nSubmitted on Tuesday, November 24, 2015 12:27:05 PM\n17. Smoke shelf\nDefinition:curved space above the firebox beow the damper that reduces down draft and promotes draw\nSubmitted on Monday, September 05, 2016 12:27:05 PM\n18. SMOKE SHELF-A shelf located behind a fireplace damper.\nSubmitted on Friday, November 06, 2015 12:27:05 PM\n19. SOLID FUEL\nWood, coal, and other similar organic materials in various forms (e.g. chunk wood, pressed logs, wood pellets, wood chips, paper, processed coal, coke, peat, charcoal).\nSubmitted on Friday, June 03, 2016 12:27:05 PM\n20. Spark arrestor:\nmetal screen mesh device intended to prevent sparks or other flaming debris from escaping into other areas. There are simple and decorative options available. Some spark arrestors have a rain guard to prevent water from dousing your fire.\nSubmitted on Thursday, September 01, 2016 12:27:05 PM\n21. SPARK ARRESTOR\nDefinition:A wire cage that is installed on the chimney termination to prevent sparks from moving into the atmosphere.\nSubmitted on Thursday, April 21, 2016 12:27:05 PM\n22. Spill Switch:Devices used to detect spillage of flue gas, but similar to high limit switches in that they are activated based on temperature.\nSubmitted on Thursday, August 13, 2015 12:27:05 PM\n23. Spill Switch:\nWhen there is a spillage, this device detects it\nSubmitted on Friday, April 29, 2016 12:27:05 PM\n24. Spill Switch:-This is a device that detects spillage from the fireplace vent system. The switch will shut the fireplace off in the event of a spillage to ensure no more gasses are emitted.\nSubmitted on Saturday, September 13, 2014 12:27:05 PM\n25. Spillage:-This term refers to fireplaces with vented systems such as a chimney or direct vent. When these become blocked combustion by-products cannot be vented outside and so 'spill' back into the room. This can be dangerous, particularly with wood burning fireplaces, as carbon monoxide may be one of the by-products leaking back into the home. This gas is odorless, colorless and deadly.\nSubmitted on Monday, March 16, 2015 12:27:05 PM\nDefinition:Process that occurs when flue gases cannot exit the vent system and back up into the dwelling. This usually creates a dangerous situation as incomplete combustion may result in the production of carbon monoxide.\nSubmitted on Tuesday, May 19, 2015 12:27:05 PM\nDefinition:The process that happens the flue gasses are not able to exit the vent system so they back up into the home. The problem with this is that carbon monoxide occurs, causing silent and odorless poison. When this gas seeps into the home, it can kill.\nSubmitted on Saturday, December 17, 2016 12:27:05 PM\n28. Split System\nA combination heat pump or air conditioner with indoor components such as a furnace or blower coil. Split systems should be matched for optimum efficiency.\nSubmitted on Monday, March 14, 2016 12:27:05 PM\n29. Standing Pilot Ignition:-A means to light the main gas burner through the use of a standing pilot light.\nSubmitted on Friday, November 04, 2016 12:27:05 PM\n30. STEADY STATE EFFICIENCY:-The ratio of the heat or BTU output vs. the heat or BTU input under steady conditions.\nSubmitted on Monday, February 23, 2015 12:27:05 PM\n31. Steamers-kettle-like steamers, available in a wide range of styles and colors, harness the heat energy of fireplaces and stoves and release warm moisturizing steam into the air.\nSubmitted on Saturday, November 08, 2014 12:27:05 PM\n32. Steamers:kettle-like steamers, available in a wide range of styles and colors, harness the heat energy of fireplaces and stoves and release warm moisturizing steam into the air.\nSubmitted on Wednesday, December 21, 2016 12:27:05 PM\nDefinition:These are cast iron kettles or pots that are filled with water and placed on stoves or fireplaces to add moisture to the air. These are useful in counteracting the dry heat produced by wood or gas fireplaces and stoves. Click here to learn about these and other accessories.\nSubmitted on Tuesday, September 29, 2015 12:27:05 PM\n34. Stove-A freestanding appliance that has a small, round vent or none at all. These can be placed against a wall, in a corner or in front of an existing fireplace. Gas stoves can work with blowers, remote controls and thermostats. The fires look so real it's scary!\nSubmitted on Saturday, November 29, 2014 12:27:05 PM\nGo Top | Glossary"", 'During the cold winter months, especially during the night, it’s extremely important to keep your house warm and cozy. Freezing is a serious concern, especially for older people. That being said, sleeping in a cozy environment during the winter is just as important as sleeping in a cool environment during the summer months.\nNevertheless, every house or apartment with central heating gets its heating shut down after 10 pm or it continues working in a lighter load than during the day. Does the same apply to households that run heating on a gas fireplace? Fire hazard is a real concern, but it’s not the only risk associated with fireplaces staying on.\nThat being said, if you want to keep the gas fireplace on during the night, especially if you live alone, with small children or pets, you should think twice about it. While people may forget about it occasionally, it’s not a good practice to keep forgetting it and make it a habit.\nIf you’re concerned that the gas fireplace can lead to some problems in your household, you should continue reading this article. It’s much better to be informed about the ways to keep the house secure than start a fire or some other hazard that could harm both your household and the people who live in it.\nContinue reading this article if you want to learn more about the gas fireplace, its types, and how long each of them can run. People generally make this mistake where they think that technological advancements make it extremely safe to sleep with gas and electric heaters on, but that’s not always the case.\nGas fireplaces are types of heaters that use natural gas or propane and insert a real flame that resembles that of the traditional fireplace. That way, you don’t have to burn the wood, yet you get an aesthetic and cozy environment fireplace, just like the ones in a movie. Add a cottage in the woods to the story, and you set yourself up a home from the fairytale.\nThe best part is that it works by a switch, so you can start a fire in seconds, instead of minutes, or more. There’s no wood-burning smell, and you don’t have to gather the woods, clean the ashes, and do other chores that come with the traditional fireplaces.\nBut, is this fireplace safer than using the traditional fireplace? Experts still argue about this and are looking for a good solution that would enable gas fireplaces to run for longer periods, without posing danger to your household.\nTypes of Gas Fireplace\nDepending on the type of fireplace you use, you may let it burn for a shorter and longer time. That being said, if you’re looking to buy a gas fireplace for your house, let’s first learn about the types commonly used.\nGas Fireplace Inserts\nHow long can it run: Continuously\nIf you live in an old home or plan to purchase an older house or a cottage, chances are that it already has a traditional fireplace area. That’s when gas fireplace inserts come to play because they are the most convenient to install into the masonry area.\nBecause of the convenient installation using a vent with a pipe inside the chimney, these fireplaces are the most reliable and can run for several hours. As experts say, it won’t cause a fire hazard in your chimney thanks to the reinforced pipes that let the smoke exit safely through the chimney.\nThe front of the fireplace is also sealed, so there’s no fear about the fumes that can leak into your living room and give you potential breathing problems. Just make sure to get some professional who will install that because you have to ensure that everything is sealed and safe to use.\nEditor’s note: Even though these fireplaces can run for a long time without being interrupted, you should still check them now and then and avoid letting them burn the whole night.\nDirect Vent Gas Fireplace\nHow long can it run: Continuously\nWhen compared to the aforementioned type of fireplace, the direct vent fireplace is equipped with an exhaust vent that goes to the exterior wall of the fireplace. This is a good option for people who want to install a fireplace in a house that didn’t have it before.\nMore importantly, it’s convenient for people who live in a house that doesn’t have a chimney but they want to be cozied up in front of a fireplace and rest or enjoy themselves. That way the exhaust gas and air get out through that vent instead of going up to the chimney.\nIt’s also quite easy to install, and won’t give you a headache, although we always recommend you to have a professional install it for you. The only safety measure that you should take is to install and seal the front glass to ensure that the fumes won’t escape to your living room.\nOther than that, it’s fairly safe to use, and it can even run continuously, which is good if it’s extremely cold and you have to keep the house constantly warmed up.\nVent-Free Gas Fireplace\nHow long can it run: Few hours at a time\nVent-free gas fireplaces are surrounded by a lot of paranoia and doubts because they don’t have the vents that could easily exhaust the gas. That being said, the fumes are not released to the outside, and there’s always a small risk of carbon-monoxide toxification and fire hazards.\nHowever, the regulators have ensured that all the companies and manufacturers that make them should be strictly regulated while making these products to ensure the high safety standards so that everyone can use these fireplaces safely, without worrying about all the risks they can carry.\nIts compact and closed design makes it not suitable to run for an extended amount of time. However, with each different product, you should consider the label or the clarifications from the handbook that the manufacturer ships with every product.\nEditor’s notes: Every vent-free gas fireplace is different, so you shouldn’t rely on what one manufacturer said about the other product. Always read the labels that refer to your model to ensure you’ll know how long it’s recommended to run the model that you own.\nCan You Sleep With Gas Fireplace On?\nYou saw above that the gas fireplace inserts and direct vent fireplace are generally safe and represent a minimal risk for your household, just like the vent-free option even though it’s recommended to run it for only a couple of hours and then take a break.\nBut, despite all the safety designs, safety regulations, and other bits and pieces that surround the gas fireplaces, especially those that are vent-free, it’s never recommended to let them run throughout the night unless there’s someone to monitor them the whole night which is inconvenient and mostly not possible.\nThat being said, sleeping with the gas fireplace on is not a good idea which can result in scary consequences like the fire hazard, carbon monoxide poisoning, and more. This especially applies with you living with small children and babies, or pets like a dog because the combustion products coming out of the fireplace can lead to dangers when it comes to health and even life.\nOne of the biggest and most real threats is carbon monoxide, which doesn’t have a distinct smell and will go unnoticed by the household members. Moreover, if you’re asleep, you likely won’t be able to smell fire, or any other combustion byproduct being released into your room.\nFlame and smell detectors are a good investment for homes that run this kind of heater, but not even the best-equipped options can recognize carbon monoxide at times. That being said, investments are too expensive to allow you to sleep soundly throughout the night.\nIt’s a different story if you use direct vent or fireplace inserts, as long as you are awake and can monitor the fire, but as mentioned before, that’s usually not the case and a vent-free fireplace isn’t recommended to run for a long time so you’re likely not even able to use it in the night hours.\nInstead, make sure you allow your home to heat up during the day, avoid opening windows or doors, or doing anything that could keep the rooms cold. Invest in different types of heaters which can warm your house before the night and activate the so-called zone heating.\nAlso, always make sure to maintain your fireplace, clean your chimney, pipes, and vents, and if you’re not knowledgeable about this, hire a maintenance service that can help you do it. Chimney fires are the most common types of fire that can occur with this type of heating system, so always make sure everything is well-maintained, especially if you just moved in.\nEditor’s notes: There are several alternatives to keeping the fire on. Of course, you can keep it on until you go to sleep. But, keep in mind that your house will remain warm for a few more hours after putting out the fire, even if you live in a larger house, or even during the most frigid winters.\nIn such a case, we rather recommend investing in better bedding like the warmer sheets made out of sateen, which is thick and can help regulate and maintain the temperature. Additionally, you can even invest in an electric blanket, weighted blanket, a very thick comforter, or a blanket that can keep you warm at night.\nPut up extra clothes and avoid standing up from bed unless you have to, so you can maintain a high body temperature throughout the night and allow you to stay warm. Thermal socks are also a good investment that you can make, as well as a hot water bottle as warming up always starts from the feet, as they are the hardest to warm up.\nThere are so many alternatives to keeping the heater on the whole night, and this one is one of the best options.\nRisks of Sleeping With Gas Fireplace On\nAbove, we discussed several risks of sleeping while the gas fireplace is on, regardless of the type we used. Let’s discuss these risks in a bit more detail, so you can have a better understanding of how great these risks are.\nCarbon Monoxide Intoxication\nCarbon monoxide is a risk with every appliance that can start a fire. It’s a gas that can’t be seen or smelled, especially when you’re asleep as your sense of smell is also sleeping with you. That being said, if there’s an excess release of carbon monoxide while you sleep, as well as other fumes, there’s a risk of intoxication and suffocation without even knowing.\nThat’s why it’s important to install a flame and carbon monoxide detector and spend a good amount of money to get one, as they are the most reliable appliances that can tell you there’s a build-up of the carbon monoxide in your house.\nMake sure to keep it close to your fireplace so it’s detected early and you can evacuate your children, pets, and yourself to a safe location. According to a study, carbon monoxide poisoning can lead to various mental health consequences such as anxiety, depression and others.\nThis is another risk with gas fireplaces, although it’s less likely to happen. Keep in mind that if you’re using natural gas for your fireplace, it’s okay to smell a little of it when you first start the fireplace after getting it installed after the purchase.\nHowever, if you suspect that there’s a gas leakage in your house, you should gather everyone as soon as possible and move away to 350 feet away from your home. You should also act fast to call the customer service of your gas company, as well as 911 in case there’s some bigger leakage.\nThis usually can’t be smelled while you’re in a deep sleep, which is why it’s not recommended to sleep when there’s a gas appliance running in your house.\nChimney Fire Hazard\nChimney fires can be quite common if your chimney isn’t maintained well. Now and then birds and other animals may nest there in search of the right place to lay their eggs and take care of their little ones. When the chimney gets congested with different pieces of wood, branches, leaves, and others, it may lead to a fire.\nAccording to a report, there are 25,000 chimney fires every year reported in the USA, and they all can lead to different damage. Those fires can lead to 125 million dollars in property damage and can also lead to life-long health problems. Of course, not all fires are caused by a gas fireplace, but it’s always good to leave that possibility as plausible.\nThis is most commonly the case with fireplace inserts, and while it’s equipped with small pipes that allow seamless exit through the chimney, reducing the risk of fire hazards, it can still happen and pose risk for you and your family.']"	['<urn:uuid:c199c0e6-12de-4e73-9318-0a3bba4f1086>', '<urn:uuid:57310a3a-98f5-4e4e-8efb-b91a1877c2ca>']	factoid	direct	long-search-query	distant-from-document	multi-aspect	novice	2025-05-01T23:46:40.222380	10	59	3565
371	life expectancy treatment options als huntington comparison	Both ALS and Huntington's disease are currently incurable, but they differ in progression and treatment approaches. ALS typically progresses over 3-5 years, leading to respiratory failure, with riluzole being the only FDA-approved drug that can extend survival by a few months. Treatment mainly focuses on symptom management through various therapies. Huntington's disease has a longer progression, typically appearing in midlife (ages 30-45) and lasting 10-25 years. Treatment options for Huntington's include experimental procedures like neurotransplantation and Axokine treatment, which shows some promise in protecting nerve cells, though these are still under investigation.	"[""Amyotrophic lateral sclerosis is a fatal type of motor neuron disease. It is characterized by progressive degeneration of nerve cells in the spinal cord and brain. It's often called Lou Gehrig's disease, after a famous baseball player who died from the disease. ALS it is one of the most devastating of the disorders that affects the function of nerves and muscles.\nALS does not affect mental functioning or the senses (such as seeing or hearing), and it is not contagious. Currently, there is no cure for this disease.\nALS most commonly affects people of any racial or ethnic group between the ages of 40 and 70, although it can occur at a younger age.\nThere are 2 main types of ALS:\nSporadic. This is the most common form of ALS in the U.S., making up 90% to 95% of all cases. These cases occur randomly, without any known cause, and there is no family history of ALS .\nFamilial. This form of ALS affects a small amount of people and is thought to be inherited.\nWhat causes ALS?\nExperts do not know the cause of ALS. In a few cases, genetics is involved. ALS research is looking into possible environmental causes of ALS.\nWhat are the symptoms of ALS?\nWith ALS, you may first have weakness in a limb that develops over a matter of days or, more commonly, a few weeks. Then, several weeks to months later, weakness develops in another limb. Sometimes the initial problem can be one of slurred speech or trouble swallowing.\nAs ALS progresses, though, more and more symptoms are noticed. These are the most common symptoms of ALS:\nTwitching and cramping of muscles, especially those in the hands and feet\nLoss of motor control in the hands and arms\nImpairment in the use of the arms and legs\nTripping and falling\nUncontrollable periods of laughing or crying\nSlurred or thick speech and trouble in projecting the voice\nAs the disease progresses, symptoms may include:\nThe symptoms of ALS may look like other conditions or medical problems. Always see your healthcare provider for a diagnosis.\nHow is ALS diagnosed?\nThere is no specific test to diagnose ALS. Your healthcare provider will consider your medical history and symptoms and will do certain tests to rule out other conditions including:\nLab tests. These include blood and urine studies and thyroid functioning tests.\nMuscle or nerve biopsy. In this procedure, your doctor removes a sample of tissue or cells from the body and examines it under a microscope.\nSpinal tap (also called a lumbar puncture). In this test, your doctor places a special needle into the lower back, into the area around the spinal cord. There he or she can measure the pressure in the spinal canal and brain. Your doctor will remove a small amount of cerebral spinal fluid (CSF) and test it for an infection or other problems. CSF is the fluid that bathes the brain and spinal cord.\nX-ray. This test uses invisible electromagnetic energy beams to produce images of internal tissues, bones, and organs onto film.\nMagnetic resonance imaging (MRI). This procedure uses large magnets, radiofrequencies, and a computer to produce detailed images of organs and structures within the body.\nElectrodiagnostic tests, such as electromyography (EMG) and nerve conduction study (NCS). These studies evaluate and diagnose disorders of the muscles and motor neurons. Your doctor inserts electrodes into the muscle, or places them on the skin overlying a muscle or muscle group to record electrical activity and muscle responses.\nWhat are the complications of ALS?\nThere is no cure for ALS. Over a period of 3 to 5 years, the disease will progress, making voluntary movements of arms and legs impossible. In time, you will need help with personal care, eating, and mobility. Movement of the diaphragm for breathing is also impaired. You may need a ventilator for breathing. Most people with ALS die from respiratory failure.\nHow is ALS treated?\nFor most people with ALS, the main treatment may involve the management of symptoms, This may include physical, occupational, speech, respiratory, and nutritional therapies. Some medicines, and heat or whirlpool therapy may help relieve muscle cramping. Exercise, in moderation, may help maintain muscle strength and function.\nThere is no cure and no proven treatment for ALS. However, the FDA approved the medicine riluzole. This is the first drug that has prolonged the survival of people with ALS.\nManaging the symptoms of ALS is a process that is challenging for you, your caregivers, and your medical team. However, it’s important to know that there are many community resources available for support and assistance.\nResearchers are conducting studies to increase their understanding of genes that may cause the disease, mechanisms that can trigger motor neurons to degenerate in ALS, and approaches to stop the progress leading to cell death.\nLiving with ALS\nALS will eventually lead to disability and death. Although your ability to move and breathe independently will be affected, your intelligence and ability to think is not. You and your family will work closely with your healthcare provider to manage symptoms as they develop. Use of the medicine may prolong your life by a few months, particularly if you have trouble swallowing. Discuss ways to make living spaces more accessible, and use of mobility devices and wheelchairs. It’s very important to discuss end-of-life decisions with your loved ones.\nWhen should I call my healthcare provider?\nIt is important that you keep your healthcare provider informed about new symptoms so she or he can recommend therapies and community resources appropriately. Most importantly, call your healthcare provider if you start to have trouble breathing.\nALS is a fatal motor neuron disease. It is characterized by progressive degeneration of nerve cells in the spinal cord and brain.\nALS affects voluntary control of arms and legs, and leads to trouble breathing.\nALS does not affect intelligence, thinking, seeing, or hearing.\nThere is no known cure for ALS.\nTreatment of ALS focuses on managing or minimizing symptoms as much as possible.\nTips to help you get the most from a visit to your healthcare provider:\nKnow the reason for your visit and what you want to happen.\nBefore your visit, write down questions you want answered.\nBring someone with you to help you ask questions and remember what your provider tells you.\nAt the visit, write down the name of a new diagnosis, and any new medicines, treatments, or tests. Also write down any new instructions your provider gives you.\nKnow why a new medicine or treatment is prescribed, and how it will help you. Also know what the side effects are.\nAsk if your condition can be treated in other ways.\nKnow why a test or procedure is recommended and what the results could mean.\nKnow what to expect if you do not take the medicine or have the test or procedure.\nIf you have a follow-up appointment, write down the date, time, and purpose for that visit.\nKnow how you can contact your provider if you have questions."", 'to PHI 305 Home Page\nHuntington\'s Disease: Reproductive Decision-Making\nBredon Jones and Cynthia Lee\nWhat is Huntington\'s Disease?\n- Also called:\n- Huntington\'s Chorea\n- Lund- Huntington\'s Chorea\n- Setesdal jerks\n- An incurable, hereditary type\nof brain atrophy\n- A type of ""presenile dementia""\nWho does HD affect?\n- Affects 1 in 10,000\n- 150,000 are at risk in the U.S.\n- Children of those who have HD have\na 50/50 chance of inheriting the disease\n- Anyone who has not developed the gene\nhas no chance of passing it on to their children\nMental Symptoms of HD\n- Change in personality\n- Loss of memory\n- Reduced concentration\n- Loss of initiative\n- Irritability/ aggression\nNeurological Symptoms of HD\n- Involuntary flicking movements\n- These occur suddenly and irregularly\nwith chance distribution all over the body\n- Gait disturbances\n- Slow and long- lasting muscle spasms\n- Speech and language problems\n- Disjoint and indistinct speech\n- May not be able to answer questions\nOther Signs of HD\n- Increased muscle activity often makes\neating and swallowing difficult\n- Altered 24-hour schedule\n- Patient may become nocturnal\n- General lack of personal hygiene\nNormal Brain vs. Brain Affected by HD\n- Some common prenatal tests\n- Huntington\'s Disease\n- Tay- Sachs Disease\n- Muscular Dystrophy\n- Down Syndrome\n- Trisomy 18\n- Cystic Fibrosis\n- An estimated 200 of these tests are\nfor inherited disorders\nReasons for Having an Abortion\n- Jobs and income\n- Financial and lifestyle burdens for the family\n- Insurance discrimination\n- Legally inadmissible but a practical concern\n- How long can this be kept from the child?\n- Having child = child abuse\n- What kind of life will this child have?\n- How motivated will this person be to have a productive\n- The diseases will become less common and less of\nIs it the presence of life...\nŠor the quality of living it?\nWhy you shoulf NOT\nabort a fetus that has a strong chance of having Huntington\'s Disease in\nits adult life!\nA. J. Plummer and Brian Plummer\nI. Overview of Huntington\'s Disease\nII. Clinical Genetic Testing of Huntington\'s Disease\nIII. Current Medical Treatment of Huntington\'s\nIV. Case Study\nV. Concluding Comments\nOverview of Huntington\'s Disease\n- Degenerative brain disorder for which at present\nthere is no cure.\n- 30,000 Americans have Huntington\'s Disease.\n- Males and females are affected equally and HD crosses\nall racial and ethnic boundaries.\n- A further 150,000 have a 50-50 chance of inheriting\nthe disease from an affected parent and are said\nto be ""at risk"".\n- Those who do not inherit HD CANNOT pass\nit on to their children and the chain of inheritance\n- Early symptoms can be mild enough to go unnoticed\nat first and may include depression, mood swings,\nforgetfulness, clumsiness, twitching, and lack\n- Since the gene discovery, scientific interest in\nHD has greatly increased, and so has the understanding of what causes the\n- Hopefully, more research breakthroughs...and a\ncure....will soon be forthcoming.\nAlthough, current treatments do not alter the course of Huntington\'s\ndisease, there have been some major advancements in finding a possible\nThe 2 biggest current treatments on the market today are:\n- Axokine-Which is produced by a company called Regeneron. The procedure\nis that the surgeon directly administers Axokine into the patient\'s brain\nand protects the nerve cells from degenerating. Unfortunalty there is no\nsignificant that this procedure does work in humans. Since it is still\nrelatively new the only testing is done in rats. But there is significant\nevidence to support that the chemical axokine protects nerve cells form\n- Neurotransplantation-Is where the surgeon transplants bits of one human\'s\nbrain to another. Currently there are 4 medical centers in the U.S. that\nare using the procedure. The procedure, which is controversial because\nit uses tissue from, aborted fetuses for the transplant. You may feel that\nthis is a contradiction. But the tissue comes from elective rather than\nspontaneous abortions. The women are asked to consent to the use to the\ntissue only after the abortion-and she is never paid. Identities of both\ndonors and recipients are confidential.\nProcedure- the nerve tissue form the patient undergoing the transplant\nis minced and mixed with prepared tissue from at least 3 fetuses. Then,\n2 small holes are bored in the patient\'s head; degenerative points in the\nbrain are mapped with the use of a MRI. Then the tissue mixture is grafted\nonto damaged sections of the brain with a needle. Although still relatively\nnew it appears the operation can reverse some to he debilitating Huntington\'s\nCase Study- Jim and Sam Fitz\n- Jim, 47, and his brother, Sam, 57\n- Both men underwent neurotransplantation surgery\n- Prior to the surgery Jim found it difficult to process questions or\nfrom coherent answers.\n- While Sam exhibited slurred speech and involuntary muscle spasms that\nmade him unsteady and created jerky movements.\n- After the procedure Jim is now able to converse with family and friends.\n- Sam\'s speech still bears slight traces of slurring, but is remarkably\nclear. And as of yet he does not suffer from any tremors.\n- This procedure is not a cure both men must undergo therapy in the form\nof exercises-both for the body and the brain.\n- Quote from Sam, ""My body feels like it belongs to me again, before\nI felt like a big shaky bowl of jelly, I\'m starting to feel like myself\nagain, I can finally see a future without a wheelchair.""\nI\'m not going to disagree that Huntington\'s disease is not a terrible\ndisorder to have and for most people who are in the late symptoms of the\ndisease a possible cure is probably too late.\nBut we are talking about an unborn fetus and as statistics show the\nsymptoms of Huntington\'s disease doesn\'t even appear until midlife (30-45)\nAnd on top of that the symptoms may run anywhere from 10 to 25 years.\nSay for example, that the woman is pregnant now. That means it may be\n2028 at the earliest that this disease starts to show up. And given the\nevidence that these treatments I have just discussed who\'s to say that\nthere won\'t be a cure before this person start too show symptoms of Huntingtons\'s\nAlso I read that these genetic tests are about 95% accurate. And although\nthat pretty accurate there is still a 5% chance the test could be wrong.\nCase study- 2 women in England\n- 2 women entered the hospital the same day to have some tests\n- The hospital confirmed that one of the women baby had down\'s syndrome\n- So the women who thought she had a baby with downs syndrome elected\nto have an abortion.\n- It was only after the abortion that the hospital realized that they\nhad gotten the two women\'s lab results mixed up and had actually aborted\na healthy baby.\n- When the other women who thought she had a healthy baby found out the\ntruth she aborted her baby also.\n- 2 babies died when only 1 would have.\nSo with the information presented here by A.J. and I we see no reason\nwhy anyone should abort a fetus even if it shows strong evidence for developing\nMany core ethical issues were addressed\nin this topic: abortion, genetic testing, and various neurological diseases.\nBrian and I posed the argument that you should not abort a fetus based\non the fact that it has the potential to have Huntington\'s Disease later\nin life. In order for us to make this argument, we gave a background on\nthe clinical genetic testing and treatment that could be done in the case\nof Huntington\'s Disease. For example, in March of 1993 scientists announced\nthat they had found the gene which causes HD. Due to this somewhat recent\ndiscovery, many avenues of research are presently being investigated in\nthe search for a treatment or cure for HD. The gene discovery has also\nmade it possible for a new predictive test for HD which allows those at\nrisk to find out whether or not they will develop the disease. Because\nof these recent advances in the field of genetics, techniques in which\ngeneticists can determine if a fetus will be deformed or afflicted genetically\nare also being developed and modified. The advances in genetic testing,\nwhile remarkable, are also allowing devastating consequences: more and\nmore parents are choosing to abort their unborn children. The dilemmas\nposed by new genetic technology are nowhere more agonizing than for prospective\nparents who are increasingly faced with a bewildering range of opportunities\nand choices as they contemplate doing what used to be the most natural\nthing in the world, and who soon may find themselves having to decide whether\nor not to terminate a pregnancy because their child is at risk for Huntington\'s\nDisease. Carried one step further, the ability to find out whether or not\na child will be deformed or afflicted might cause the death of a normal\nindividual in a effort to be rid of a possibly genetically diseased fetus.\nWe need to closely examine the ways in which genetic technology affects\nour attitudes. Close to 100% of women who have tested positive from amniocenteses\nfor Down\'s syndrome have abortions. Aborting defective or diseased fetuses\nis widely sanctioned because if born, they are a burden....their families\nwould suffer, they may suffer, and society suffers. We have this need for\nperfection in our society..we need to detect and eliminate defective babies.\nWe have this warped mentality that we are in control of our very existence\nand that we can develop some sort of ""super-race"". We need to\nrecognize the limits of humanity and quit trying to play God. I found a\nquote from a woman whose fetus was at risk for HD and she refused genetic\ntesting. She states, ""In our success-oriented, beauty-obsessed culture,\nthe low intelligence or physical handicaps of defective, deformed, or diseased\nbabies leads us to assume that such an individual\'s life is not worth living.\nAnd yet we are appalled that anyone would abort a fetus just because it\nis a girl. But the Chinese and Indians routinely do so. To Indians, a female\nchild can be a lifelong burden; to be a female in China is to risk abandonment\nor even murder; it\'s not a life worth living. The point is that the value\nwe put on human life is socially and culturally conditioned. We may believe\nwe are doing the right thing, but are we?"" Should we abort every deformed,\ndefected, or diseased baby? If not all of them, then we just abort one.\nWe can select whose life is going to be more valuable than others, because\nevery single life has meaning and a purpose.\nBrian and I made several arguments opposed to abortion\nin this case. For example, if one does carry the gene for HD they have\na 50% of not getting the disease. In retrospect, they also have a 50% chance\nof developing symptoms. Even then one does not usually develop symptoms\nuntil the fourth or fifth decade. So one could live a completely normal\nlife until age 40 or 50. Many middle-aged men and women lead fulfilling\nlives and can contribute to society. HD usually progresses over a 10 to\n25 year period, so one would live for 60 or 75 years. In our opinion, 40\nyears is better than no years! In 40 years there could be a cure for all\nwe know! We all die sometime. If you knew your child was going to be in\na car accident and be a quadriplegic from age 16 on, would you abort him/her\nfrom birth...or would you just wait until he/she was handicapped and then\nkill them? Of course you wouldn\'t! You would love that person and that\nindividual would have probably contributed some meaning to your life. Suppose\nyour ""healthy"" child developed spinal meningitis, are your going\nto kill that child too because he is a burden? Every life has the potential\nto affect another\'s whether the individual is healthy, deformed, or diseased.\nTake a chance on life, your life and theirs.']"	['<urn:uuid:2a6457f8-acbf-4b40-a744-1f5bf26287eb>', '<urn:uuid:a93e134c-0427-4c51-80e2-cd723f323dd9>']	open-ended	with-premise	short-search-query	distant-from-document	comparison	expert	2025-05-01T23:46:40.222380	7	92	3204
372	Which protected water area is bigger, Nha Trang Bay or Great Barrier Reef?	The Great Barrier Reef Marine Park is significantly larger than Nha Trang Bay. The Great Barrier Reef World Heritage Area covers 347,800 square kilometers, making it the largest marine protected area in the world, while Nha Trang Bay has a surface area of only 507 square kilometers.	"['Nha Trang Bay is located in the province of Khan Hoa, at the southern maritime area in Central Vietnam. With a surface area of 507 square kilometers, the bay stretches between Cay Cape in the north and Dong Ba Cape in south. The coastline consists of two different parts – continental and island. Both contribute to a great amount of biodiversity as well as the development of several maritime activities in the fields of tourism, transportation, aquaculture and product processing. The famous bay has a number of popular islands and beaches, which are constantly visited by tourists and travelers coming to Nha Trang.\nNha Trang Bay is considered one of the most precious nature models in the whole world due to its exotic and rare ecosystem found beneath the tropical sea. The renowned bay has about 10 Salangane islands. Every year, the Khanh Hoa Province earns millions of dollars just from the exploitation of bird’s nest in Salangane. The underwater surface of the bay is also home to 350 types of corals, 190 kinds of fishes, crustaceans, mulluscas, sea grasses, weeds etc.\nKnown as one of the 29 most stunning bays throughout the world, Nha Trang Bay is home to 19 islands including Mun Island, Mieu Island, Tre Island, Tam Island and Yen Island. Because the water in the bay is warm all year round, the bay is ideal for different water sports activities like scuba diving, swimming and snorkeling, which brings more and more people from different parts of the world and every corner of the country. One special adventurous activity that you can try to witness the superb view of the bay is the 20-minute balloon ride at a height of 150 meters.\nHon Mun Island is home to several Salangane caves that can be seen from your boat. Traveling using a glass-bottomed boat lets you witness the beautiful corals underwater. In 2001, Hon Mun Protected Area was the first sea reservation zone to be established in the country, with a total area of 160 square kilometers covering several nearby islands such as Hon Tre (the largest island), Hon Tam, Hon Cau, Hon Vung, Hon Rom, Hon Noc and Hon Mieu as well as the surrounding waters. This area is very popular because it is the most diversified coral reef in the country. Its international significance can’t be denied as the variety of corals is similar to the ones found in the India- Pacific ocean international coral reef center. The coral reef in the Hon Mun area comprises more than 340 kinds of corals out of 800 kinds around the world.\nOne great attraction in Nha Trang Bay is the Tri Nguyen Aquarium with its exceptional structure resembling the shape of an old pirate ship. The construction offers an underwater world feeling. From afar, the huge structure looks similar to a fossil ship draped in seaweeds and moss, stranded in the cape. The artificial lake inside is covered with a thick glass. Visitor will experience true excitement as you get surrounded by groupers, red snappers, sharks and eels over 1 meter in length. The largest island, Hon Tre, is now the host of the five-star sophisticated hotel resort Vinpearl Land.', ""Reef - The Whitsundays -\nThe Great Barrier Reef is said to be the\nlargest structure on earth ever created by living creatures.\nThe Great Barrier Reef World Heritage Area is 347 800 square\nkilometres in area ( an area bigger that the United Kingdom,\nHolland and Switzerland combined). It is the largest World\nHeritage Area and marine protected area in the world.\nThe reef contains over 2,900 reefs which includes 760 fringing\nreefs, and 300 coral cays.\nCoral - Great Barrier Reef\n|You can experience one the of the “7” wonders\nof the world with a Day Trip to one of the pontoons with underwater\nviewing platforms with optional Diving and Snorkelling or you\ncan experience the reef and islands on a Sailing and Diving\ncharter boat, “highly recommended”.\nThe Great Barrier Reef is the world’s largest and most complex expanse\nof living corals reefs supporting varied forms of marine life. As the world’s\nlargest coral reef ecosystem, the Great Barrier Reef is home to over 1500 species\nof fish, about 400 species of corals, 4,000 species of molluscs, 215 species\nof birds, 6 species of sea turtles and a host of sponges, anemones, worms, crustaceans,\nshells, sea stars, urchins…. Scuba diving and snorkelling are the most\npopular ways to experience the unique and beautiful underwater world of the Great\nMost commonly asked questions\nREEF FACTS AND FIGURES\nThe Great Barrier Reef Marine Park was\nestablished in 1975, and it is the world largest marine protected\narea in the world. It is approximately 348,700 square kilometres\nin area and approximately 2,300 kilometres long, running from just\nnorth of Bundaberg to the tip of the Cape York Peninsula. The reef\ncontains over 2,900 reefs which includes 760 fringing reefs, and\n300 coral cays. There are also 618 continental islands, which were\nonce part of the mainland. As the world's largest coral reef ecosystem\nthe Great Barrier Reef is home to approximately:- 1,500 species\nof fish 400 species of corals 4,000 species of molluscs 500 species\nof seaweed 215 species of birds 16 species of sea snake 6 species\nof sea turtle and some of the largest populations of dugong in\n||WHAT FISH IS THAT ?\nWith over 1500 species of fish on the reef the answer to this question is not\nan easy one. The use of identification books and underwater cards can be useful\nin identifying commonly encountered species. Body and mouth shape are often\nthe best key features in identifying the type of fish. The reef fish section\nof the marine biology manual will outline the features of the mostcommonly\nencoungered families of fish. Aim to learn the name of just one fish every\ntime you visit the reef, and you will quickly know the most commonly encountered\n|ARE WE GOING TO SEE ANY SHARKS ?\nIf you see a shark while visiting the reef, consider yourself very lucky as sharks\nare not frequently encountered by visitors. Of those which are seen the most\ncommonly encountered are the white tip reef and black tip reef sharks. Easily\nidentified by the white markings on the tips of the dorsal fins, they are often\nfound resting upon the sea floor. Like most sharks white tip's are extremely\ntimid and won't stay long around divers. Most sharks found on the reef are\nfish eaters and therefore pose no threat to visitors. Do not harass or block\noff a shark's exit as they may attack out of fear.\n|WHAT ABOUT STINGERS ?\nThe box jellyfish is found in the coastal waters of North Queensland during summer\nmonths (October to March). Visitors wishing to swim during this period should\nonly do so in protective swimming enclosures or wear protective clothing. The\nbox jellyfish is a coastal species and is not found out on the reef, but they\ncan sometimes be found around islands close to the mainland. Other stingers\nthat are sometimes encountered on the reef include the irukandji and blue bottle.\nBoth can cause a nasty sting, Vinegar can used on both box jellyfish and irukandji\nstings but not on blue bottle stings. For blue bottles use cold water and ice.\n|WHY ISN'T CORAL VERY COLOURFUL ?\nMost visitors to the reef comment that the coral isn't very colourful as they\nare used to seeing brightly coloured images in books and on television. Natural\nwhite light is made up of all the colours of the rainbow; underwater, these\ncolours are filtered at different depths with red and yellow disappearing first.\nThis gives the reef a predominantly blue/green appearance. Photographs and\nvideo are taken using lights to show the true colours of the reef. So the colours\nare there, it's just that you need white light to see them. This is why night\ndiving on the reef is so spectacular.\n|WHAT ARE CORALS ?\nCoral are made up of a thin layer of living animals called polyps, which secrete\na chalky, limestone skeleton as they grow. Coral colonies grow as the polyps\ndivide and multiply in a process known as budding. In addition to catching\nplanktonic prey with their tentacles corals also derive nourishment from simple\nsingle celled algae called zooxanthellae (pronounced zoo-zan-thelly). living\nwithin their tissues. Like all plants, zooxanthellae photosynthesize, producing\nnutrients from the suns energy which are used by the polyp for its own nutrition.\nCorals with zooxanthellae are able to lay down limestone skeletons up to three\ntimes faster than those corals without.\n|WHAT TYPE OF CORAL IS THAT ?\nTrying to identify particular species of coral is very difficult. What makes\nit so difficult is that one type of coral may appear as a branching form in\ncalm water and look like a plate coral in another area. In many cases it is\nthe environmental conditions, such as wave action, light levels and the amount\nof sediment in the water, that influence coral colony shape. The easiest way\nto identify corals is by their appearance * boulder * branching * plate * table\n* vase * bushy * solitary\nWHAT ABOUT CORAL SPAWNING ?\nEvery year over one third of the reef's 350 species of coral reproduce sexually\nduring a mass spawning event. The majority of inner reefs spawn around November\nwith the outer reefs spawning later in December. Spawning always takes place\nat night, and follows any time up to six days after the full moon. Eggs and sperm\nare released into the water where they eventually combine to form a free swimming\nplanktonic larval stage.\nWHY IS THE REEF SO FAR OFFSHORE ?\nMost of the Great Barrier Reef is located off the mainland of Queensland. Corals\nneed clear waters which are low in nutrients. They cannot tolerate freshwater\nor nutrients carried in the water run-off from the mainland. That is why the\nmost diverse and abundant corals grow offshore where the environmental conditions\nare more suitable.\nWHAT IS THE WATER CLARITY GOING TO BE\nThe clarity of water on the reef is determined by a combination of the amount\nof sediment and the amount of phytoplankton in the water. Sediment becomes suspended\ndue to increased water motion caused by tide changes, high winds and storms.\nPhytoplankton are the microscopic plants that drift around in the water. They\nare more numerous in areas where the nutrient levels of the water are higher\nparticularly around coastal reefs which receive nutrient rich runoff from the\n|ARE WE GOING TO SEE\nANY WHALES ?\nWhales are normally encountered during the winter months when they migrate up\nto the reef from Antarctic waters to mate and give birth. One of the most spectacular\nvisitors during this period is the Humpback. They are seen in the shallow coastal\nwaters of the Great Barrier Reef ranging from Hervey Bay to\nPort Douglas. Whale watching is conducted by a number of tourist operators through\nthese areas. The Minke is another species of whale seen during winter, particularly\naround the Ribbon Reef area. The smallest whales, the dolphins can be seen all\nyear round in most parts of the reef. * What about Crown-of-Thorns Starfish?\nThe cause of Crown of Thorn Starfish outbreaks is still the focus of a lot of\nresearch and debate. Increased nutrients from the mainland and effects due to\nEl Nino are all being investigated as is the possibility that it is a naturally\noccurring event. Crown of Thorns starfish may actually serve to maintain coral\ndiversity on the reef by feeding on the fast growing species, that if left unchecked,\ncould dominate the reef.\n|WHERE CAN WE GO FISHING ON THE REEF\nFishing is not allowed in green national park zones or pink preservation and\norange scientific zones. In other zones fishing is allowed subject to Queensland\nfisheries restrictions. Legal sizes, closed seasons and catch quotas also apply\nto a variety of fish and shellfish. The following animals are totally protected:\nwhales, porpoises, dolphins, dugong and turtles, clam, trumpet and helmet shells,\nfemale crabs all grouper and cod over 1.2 metres. What about the weather? In\ngeneral the average passenger is not so much concerned with the weather as they\nare with how it will influence their day at the reef. Therefore an answer should\nbe given in reference to their concerns eg.sea sickness, water clarity, and the\ncolour of the reef. Whats that slick? When good growth conditions exist, blooms\nof a simple floating algae called Trichodesmium are often confused with oil and\ncoral spawn slicks. Blooms can be easily identified by their rusty brown colour\nas they occur in wind rows along the surface of the water. Slicks of coral spawn\ngenerally do not last more than two days after coral spawning. Any oil spill\nshould be immeditely reported to the local maritime authority.\nWhitsunday Islands - Airlie Beach - Queensland""]"	['<urn:uuid:5edeb899-fdbd-4deb-948d-d217f1df6db0>', '<urn:uuid:eba993c1-fc2b-4020-8952-763be1f6f97c>']	open-ended	direct	concise-and-natural	distant-from-document	comparison	novice	2025-05-01T23:46:40.222380	13	47	2156
374	I teach sleep medicine - what percent of menopausal women get hot flashes?	Approximately 75 percent of women who experience menopause also experience hot flashes.	['Restorative sleep is not only bliss—it’s crucial to living a healthy, happy and productive life. Nearly all of us experience sleep deprivation at some point but one of the top culprits—sleeping too hot—is totally fixable. Here are 7 specific reasons you might be experiencing night sweats, and what to do about them.\nYour exercise routine affects your temperature.\nAlong with increasing your heart health and core body strength, exercise is one of the best ways to boost your metabolism. However, sudden changes to your exercise routine—or even the intensity of your workouts—can cause your thyroid to release more hormones in support of more activity. Both the increase in metabolism and the shift in hormones can lead to night sweats.\nTwo tips for reducing these unwanted side effects are to ease slowly into any new exercise regimen, and to try exercising earlier in the day.\nYou have a higher metabolism.\nWe’re mostly looking at you, men. That’s because a male’s metabolism, on average, is 23% higher than that of a female. Metabolism is measured by the rate at which you burn food to fuel your body. The very process of fueling your body with energy causes your temperature to rise. Naturally, a higher metabolic rate will coincide with a higher body temperature.\nOne surefire way to ensure a good night’s sleep is to invest in a mattress with cooling technology, particularly an advanced cooling mattress that moderates your skin temperature to an ideal 88 degrees Fahrenheit.\nYou’re losing the thermostat war.\nEven though men have a higher metabolism than women, females generally have a higher core body temperature. That seems counterintuitive on so many levels—for one thing, women are far more likely to feel cold sooner. The fact is, because women are accustomed to feeling that warmer internal temperature, they will nearly always be more sensitive to external cold. Women are also ultra-efficient when it comes to conserving energy. Females pull heat to their vital organs first—one of the reasons why women’s hands and feet tend to be three degrees colder than men.\nThese physiological differences account for some intense thermostat wars! One of the best ways to ensure both of you are comfortable is to invest in the right pillows—choosing different materials for your individual sleep needs. Latex pillows are naturally breathable while cooling gel pillows provide relief at the neck, one of the most influential areas for lowering or raising body temperature.\nYour hormone levels are fluctuating.\nAny changes in reproductive hormones can impact the hypothalamus—your body’s thermostat—resulting in changes in body temperature. While approximately 75 percent of women who experience menopause also experience hot flashes, women of all ages can be subject to hormonal flux.\nYou can ease night sweats related to hormonal fluctuations by sleeping with not only fewer covers, but also by using sheets that are inherently breathable and cooler to the touch. Sheets derived from cotton and bamboo are among the best choices. Bamboo sheets are particularly known for their softness and lightweight hand. Turning on a standing fan or ceiling fan for localized cooling can also bring immediate relief.\nYou live in the sun belt (or it’s summer).\nLiving in the southern third of the United States can make you the envy of the rest of the nation in January, but triple digit temperatures or high humidity in the summer months can leave you feeling hot and sticky 24/7. Even if you live in a cooler climate, summer months require some extra measures to beat the heat.\nFew in hot climate areas can afford to adjust the thermostat to the optimal temperature for every hour of the day. Perhaps that’s why Phoenix, Arizona-based Brooklyn Bedding developed advanced cooling technology for mattresses in the first place.\nBeyond the bed, anyone looking for a chill sleep environment should close or pull down all window treatments during daytime hours and keep the thermostat about three degrees higher than comfortable when away from the home. Turn down the thermostat when you return and at least a few hours before going to sleep—this technique will not only cool down the house, but also save on utilities without overworking your AC unit.\nYou don’t sleep alone.\nAllowing children or pets to sleep in your bed is a hot topic of debate—with a rise in temperature being one of the more literal side effects. If none of you are ready to give up the emotional security, then cooling technology is the next thing you should add to the mix. Surface cooling infusions are now available in a number of mattresses (including the advanced cooling Brooklyn Aurora). Look for cooling infusions that react to and help moderate your body temperature, as well as foam treatments that draw heat out and away from your body.\nYou sleep on an all-foam bed that lacks cooling or breathability.\nThe invention of the bed-in-a-box gave rise to the all-foam mattress—with its compressibility, ship-ability and ever so comfortable sleep-ability. One of the chief complaints of all-foam beds, though, can be the way some models absorb and trap heat. If you’re in the market for a mattress, there are a few ways to ensure a more comfortable, cooler night’s slumber.\nFirst, if you’re set on an all-foam bed, look for foam mattresses featuring open cell technology, breathable smooth tops and foams with cooling properties, including cooling surface infusions. Second, understand the difference between all-foam beds and hybrid beds. Hybrid beds feature coils instead of high density base foams. Hybrid mattresses with individually pocketed coils provide not only added comfort and support but also greater airflow, allowing heat to dissipate while you sleep.\nRegardless of the mattress you sleep on, the proper foundation—including an adjustable base, which also allows great air circulation—is ideal for chilling.']	['<urn:uuid:2a7bb58c-a141-4dd4-a452-eafa705cb3b0>']	factoid	with-premise	concise-and-natural	similar-to-document	single-doc	expert	2025-05-01T23:46:40.222380	13	12	956
377	Do cats with leptospirosis and liver disease both show increased thirst and urination?	Yes, both conditions cause increased thirst and urination. In leptospirosis, cats show increased thirst and urination progressing into rapid dehydration. Similarly, in liver disease, cats exhibit increased urination (polyuria) and drinking of water (polydipsia) due to serious liver dysfunction.	"[""Cats can contract leptospirosis, a bacterial spirochete infection. In this post, our Danbury vets explain how leptospirosis spreads among cats, how you can recognize it, and when you should call a vet.\nCats & Leptospirosis\nLeptospires replicate throughout a cat's body, including the liver, kidneys, central nervous system, eyes, and reproductive system. When an infection occurs in the liver or kidneys it can cause severe organ damage, which can be fatal.\nAs leptospirosis is classified as a zoonotic disease, it can spread from animals to humans. Children are especially vulnerable to contracting this parasitic infection from an infected pet. Young cats with underdeveloped immune systems are more vulnerable to serious consequences from the disease.\nSigns & Symptoms of Leptospirosis in Cats\nLeptospirosis can cause a wide range of symptoms in cats. Therefore, it's incredibly important to see your veterinarian, or an emergency vet, if you suspect your cat may have contracted the parasite.\n- Runny nose\n- Spontaneous cough\n- Dark red speckled gums\n- Increased thirst and urination, progressing into rapid dehydration and the inability to urinate.\n- Lack of appetite\n- Sore or stiff muscles, legs, and/or gait and/or a reluctance to move\n- Sudden fever and illness\n- Yellow skin and/or whites of eyes\n- Swelling of the mucous membrane or mild swelling of the lymph nodes\n- Vomiting and/or diarrhea, possibly with blood\n- Difficulty breathing, fast breathing, irregular pulse\n- Bloody vaginal discharge for female cats\nHow Cats Get Leptospirosis\nLeptospira spirochete infections are more common in subtropical, tropical, and moist regions. However, the infection rate among domestic pets in the United States and Canada is growing, with illnesses becoming most common in the autumn months.\nCats that live near wooded areas or near/on farms are more likely to become infected. This is because Leptospira spirochetes are most prevalent in marshy/muddy areas with stagnant surface water. In addition to this, heavily irrigated pastures are also common sources of infection, owing to the possibility of infected soil or mud. Cats can also contract Leptospirosis from the urine of other infected animals.\nDiagnosing Leptospirosis In Cats\nBecause leptospirosis is a zoonotic illness, your veterinarian will use extreme caution when handling your cat. They must wear latex gloves at all times and all bodily fluids will be handled as biologically hazardous materials. Urine, sperm, vomit, and any other fluid that exits the body has to be handled with particular care.\nYour veterinarian will want a full history of your cat's health, including their recent activity and past symptoms. The information you give your vet might help them determine what stage of infection your cat is at and the organs being impacted.\nYour vet may also conduct a range of diagnostic tests to get a better understanding of your cat's case.\nTreating Leptospirosis in Cats\nFluid therapy will be the primary treatment for correcting the consequences of dehydration. If your cat has been vomiting they might be given an antiemetic or anti-vomiting medication. If your cat's ability to eat or keep food down is being impaired because of sickness, a gastric tube may be used to provide sustenance.\nYour veterinarian will prescribe antibiotics for at least four weeks. The type of antibiotic they provide will depend on the stage of infection. Penicillins can be used to treat initial infections, but they are ineffective at killing bacteria once it has reached the carrier stage. Some antibiotics could have major adverse effects, especially those that travel deeper into the system to eradicate infection.\nThe good news is that except for serious organ damage, the prognosis for recovery is usually good.\nAfter Leptospirosis Treatments\nLeptospires can be detected in a cat's urine for several weeks after therapy and apparent recovery from an infection. Appropriate handling techniques are the most effective way to prevent infection or reinfection. This includes handling all body excretions with gloves and disposing of them properly afterward. Remember to also dispose of your cat's feces and urine properly. It may also be worthwhile quarantining your pet for a few weeks after they recover. You can ask your veterinarian for more information.\nDespite how well you, your family, and your other pets feel, it's always a good idea to get tested for Leptospirosis. Remember that it is a zoonotic disease, and can spread just as easily to humans as it can to other animals.\nNote: The advice provided in this post is intended for informational purposes and does not constitute medical advice regarding pets. For an accurate diagnosis of your pet's condition, please make an appointment with your vet."", 'Symptoms of Cat Liver Disease\nThe clinical signs of liver disease (medically referred to as “hepatobiliary disease”) can be extremely variable due to the liver’s extensive interaction with other organs and its independent regenerative capacity. More than half (and maybe up to 70 or 80 percent) of functional liver tissue must be destroyed before actual liver failure occurs. Often, there are no clinical manifestations of liver disease, or the condition may present with only vague and nonspecific signs. Once symptoms do develop, liver disease is usually quite advanced, although the severity of any given clinical signs does not necessarily correlate with the extent of liver damage or the cat’s prognosis. Additionally, because the liver is intimately involved in so many bodily functions, what appear to be symptoms of liver disease might actually be caused by an abnormality in another organ or organ system. Keeping this in mind, there are a number of signs that, taken together, can be suggestive of liver dysfunction, which can be mild or severe and can present acutely or develop slowly.\nSymptoms of Liver Disease in Cats\nAmong its many other functions, the liver is responsible for filtering toxins out of the blood and regulating the metabolism of food. Symptoms of liver disease are associated with a build-up of these toxins. When toxins accumulate in the blood stream because the liver is unable to remove them, the affected cat will become increasingly thirsty as its body attempts to flush toxins out in the urine. Cats with liver disease tend to drink more and urinate more than usual. They also tend to lose their appetite and, over time, lose weight and muscle mass as well. Other common signs include depression, lethargy, weakness, weight loss, bad breath, poor or unkempt hair coat, nausea, vomiting, diarrhea and dehydration. Another common sign is abdominal enlargement, which may be the first sign noticed by owners or may be discovered during a routine physical examination by a veterinarian. The distended abdomen is caused by an enlarged liver or spleen (“organomegaly,” which means an enlarged organ), excess fluid in the space between abdominal organs (called “effusion”), or poor abdominal muscle tone (called “muscular hypotonia”). Each of these causes may or may not be associated with primary liver disease.\nSome other clinical signs of liver disease are jaundice, bilirubinuria, acholic feces and behavioral and neurological changes. Jaundice is the yellow staining of the serum or tissues, including skin and mucous membranes, caused by an excess of the bile pigment, bilirubin. Jaundice, also referred to as “icterus,” can turn a cat’s urine a bright, yellowish-orange color (“bilirubinuria”). Acholic feces – or changes in fecal color – are caused by an absence of bile pigments in the intestinal tract, making the cat’s stools pale, gray and putty-colored. This normally indicates complete bile duct obstruction associated with primary liver disease.\nBehavioral and neurological changes reported in cats suffering from liver disorders include aggression, restlessness, agitation, dementia, disorientation, depression, trembling, circling, incoordination, staggering, aimless wandering or pacing, head-pressing, blindness, excess salivation, tremors, generalized seizures and even comas. The general term for this condition is “hepatic encephalopathy.” “Hepatic” means emanating from or pertaining to the liver. These signs can develop in cats with liver disease because the cerebral cortex of the brain is exposed to circulating toxins that normally are removed by a healthy liver, but escape hepatic detoxification in cases of liver disease. Most gastrointestinal toxins are derived from bacterial metabolism, or digestion, of proteins and their by-products. Ammonia is one of the most common gastrointestinal toxins contributing to the clinical signs of liver disease, which can wax and wane over time. Hepatic encephalopathy is a chronic condition which cannot be cured but usually can be controlled.\nCompanion animals with liver disease often have problems with coagulation, or clotting, of their blood, because of the integral role of the healthy liver in this process. In cats, the upper gastrointestinal tract – usually the stomach and duodenum, which is the first part of the small intestine - is most commonly affected by coagulation disorders associated with liver disease. This can cause gastrointestinal bleeding/hemorrhage, which owners may detect by seeing fresh blood in their cats’ litter box. Affected cats may also vomit blood.\nFinally, increased volume of urination and drinking of water typically accompany serious liver dysfunction. Your veterinarian may refer to these symptoms as “polyuria” and “polydipsia.”\nIf your cat exhibits any of the symptoms discussed, and especially if you notice a number of them occurring at the same time, please see your veterinarian immediately. Only a veterinarian can run the crucial tests needed to confirm a diagnosis of liver disease.']"	['<urn:uuid:0ded15f9-6111-4d8c-98e2-ae0c8c3a92ef>', '<urn:uuid:a95e56e7-c885-43c0-b269-9c2d1e1a2b00>']	factoid	with-premise	concise-and-natural	similar-to-document	comparison	expert	2025-05-01T23:46:40.222380	13	39	1531
378	How do urban wetlands manage nitrogen pollution and affect air quality?	Urban wetlands play a crucial role in nitrogen management through denitrification in 'accidental urban wetlands' that form from urban base and storm flow discharges with high nitrate concentrations. These wetlands help with nitrogen retention through plant uptake and denitrification processes. Regarding air quality, urban areas with more dispersed development (sprawl) show higher nitrogen oxide emissions, with motor vehicles accounting for 30% of all oxides of nitrogen emitted into the air. In highly sprawling areas like Atlanta, vehicles account for an even higher percentage - 58% of all nitrogen oxides.	"['Travel Awards 2016\nAnthony Cullen, Department of Biological Sciences, Rutgers University, Newark, NJ. “Oak succession in a pioneer forest on an urban brownfield” & “Bridging across Earth Stewardship Initiative’s learning”\nMy research focuses on plant community ecology with an emphasis on urban ecological restoration (oak succession in a pioneer forest within a brownfield) and invasion ecology (distribution and dispersal of two non-native viburnums). My research is conducted across varying landscapes ranging from urban, suburban, exurban, to rural. This fits into the larger research goals of the Holzapfel lab, which focuses on how both plants, and animals function in a modern world through investigating novel communities in urban areas. Collectively our goal is to understand the formation, function, and biodiversity of these novel communities.\nCurrently, I am focused on understanding the mechanisms of spread of two relatively new invasive viburnum species: Viburnum dilatatum and Viburnum sieboldii. Specifically, I want to study whether these species are site, seed, or dispersal limited by investigating seed viability, germination success rates, dispersal mechanisms, and the distribution patterns of individuals throughout the landscape. My ultimate goal is to understand the primary means in which these Viburnum spp. spread and their invasive potential. More broadly, my mechanistic approach contributes to invasive theory through the lens of niche conservatism versus niche differentiation in competing congener species. This project will also inform land managers with best use techniques to control the spread of these invaders before they become a widespread problem.\nBetsy A. Evans, Biological Sciences, Florida Atlantic University, Boca Raton, FL. “Dietary shifts of Wood Storks in response to human-induced landscape change ”\nMy overall career goal is to research and assist in the conservation of avian species. I am particularly interested in the response of avian species to human-induced rapid environmental change (HIREC). I have focused on urban ecosystems and avian responses since I began my undergraduate degree in the Midwest researching vulture perch selection at communication towers. I continued on this path through my Master’s at Florida Gulf Coast University working with vultures at urban roosts. Currently I am working on my Ph.D. at Florida Atlantic University (FAU), researching Wood Stork use of roadway corridors. The South Florida area offers a unique opportunity to study Wood Storks in an urban environment due to elevated human populations, rapid urbanization, and the creation of novel environments. I aim to use this information to aid in the conservation of avian species, and to collect relevant information on how these species are adapting to novel anthropogenic landscapes. I am also excited for the opportunity to educate the public and undergraduate students during my time at FAU. I have had the opportunity to give public presentations, and have had over twenty undergraduate student volunteers on my urban ecology project. After graduating, I would like to continue research in urban wildlife ecology and avian responses to HIREC. While researching these topics, I hope to continue educating students and the general public on the effects of urbanization globally.\nAmanda K. Suchy, School of Life Sciences, Arizona State University, Temple, AZ. “Patterns of plant species diversity and sexual reproduction in extreme urban environments”\nI am an urban and wetland ecologist who is interested in how urban water bodies (streams, wetlands, lakes) affect nitrogen cycling in cities. Cities face many unique ecological challenges, such as nutrient pollution, which may be mitigated by integrating ecological principles into urban design. I hope for my research to contribute to such solutions by gaining a better understanding of drivers of ecological processes in cities, which can ultimately inform the design, management, and incorporation of functional and resilient habitat patches into urban landscapes.\nFor my dissertation, I am investigating drivers of denitrification in a highly understudied ecosystem known as “accidental urban wetlands.” These accidental urban wetlands result from discharges of urban base- and storm flow that tend to have high nitrate concentrations, and are not managed for nitrogen removal. The storm drains supplying the water for the wetlands also discharge at different times and with different frequencies creating wetlands that range from being flooded all year to wetlands that flood only in response to storms. My dissertation examines how the dominant plant patches in these accidental urban wetlands and the different hydrologic regimes interact to affect spatial and temporal patterns of denitrification potentials. Further, I am investigating how plant traits affect denitrification potentials, and how plant patch diversity in wetlands affects nitrogen retention via plant uptake and denitrification.\nMoving forward, I wish to move beyond studying urban wetlands individually and incorporate how the connectivity (or lack there of) among urban water bodies affects nitrogen cycling in cities. Expanding our ecological understanding of urban water bodies beyond streams (to include urban ponds and wetlands) will be key to gaining a better understanding of how urban ecosystems function.', 'Presentation on theme: ""Hazardous to our Health: The Effects of Urban Sprawl on the Environment and its Inhabitants Erin Anderson-Ruddon Kayla Arslanian.""— Presentation transcript:\nHazardous to our Health: The Effects of Urban Sprawl on the Environment and its Inhabitants Erin Anderson-Ruddon Kayla Arslanian\nHazardous to our Health: The Effects of Urban Sprawl on the Environment and its Inhabitants Sprawl has four dimensions: a population that is widely dispersed in low density development, rigidly separated homes, shops and workplaces, a network of roads marked by huge blocks and poor access, and a general lack of well-defined thriving activity centers or downtowns (Ewing, Pendall, and Chen 2002). We hypothesize that urban sprawl is harmful to the environment and that the environmental degradation suffered increases health risks in these areas of sprawl.\nUrban Sprawl & Air Pollution Air quality is greatly affected by sprawl. Motor vehicles are the leading source of air pollution. In areas of sprawl, destinations are far apart, creating a dependence on automobiles to get from destination to destination. The need to make more car trips increases the average person’s daily miles driven.\nAir Pollution & The Sprawl Index The sprawl index categorizes areas according to their level of sprawl. A standard deviation of 50 separates a high area of sprawl, from an average area of sprawl, from a low area of sprawl (Sturm and Cohen 2004). For example, Atlanta, GA, an area of very high sprawl has an index of 57.7 whereas Chicago, IL, a denser city has an index of 121.2. For every 50 unit decrease in standard deviation on the sprawl index (more sprawling), there is a 1.96 miles/day increase in driving per person. For every 25 unit increase in standard deviation on the sprawl index (less sprawling), there is a 5.4 miles/day decrease in driving per person. This shows that people in more sprawling areas drive longer distances, more often than those living in areas of relatively low sprawl.\nAutomobiles & Air Pollution Because inhabitants in areas of great sprawl have to drive longer distances more frequently, they burn more fuel than persons living in areas of lesser sprawl. The advent of sprawl could threaten the current positive trend of cleaner air.\nAutomobiles & Air Pollution Automobiles account for: 30% of all oxides of nitrogen (any gaseous form of nitrogen) emitted into the air. 30% of all hydrocarbon emissions. The main component of fossil fuels, hydrocarbons combust when fuel is burned, releasing chemicals such as methane and benzene into the atmosphere. Benzene is a known carcinogen. 32% of all carbon emissions.\nAutomobiles & Air Pollution Automobiles account for: 30% of all oxides of nitrogen (any gaseous for of nitrogen) emitted into the air. 30% of all hydrocarbon emissions. The main component of fossil fuels, hydrocarbons combust when fuel is burned, releasing chemicals such as methane and benzene into the atmosphere. Benzene is a known carcinogen. 32% of all carbon emissions. In areas where sprawl is high, cars account for a greater number of these pollutants. For example, in Atlanta, vehicles account for 58% of all nitrogen oxides and 47% of all hydrocarbon emissions (Frumkin, 2002).\nUrban Sprawl & Ozone Sprawl affects a region’s ozone levels. Ozone is a photochemical smog created then organic gases (specifically VOCs, nitrogen oxides, heat and sunlight interact (Goldman 2001)). Though ozone is necessary in the stratosphere to protect earth from the sun’s UV rays, in the troposphere it degrades air quality, and is considered a pollutant. Currently, over 90 metropolitan areas regularly exceed ozone standards. The EPA attributes 50% of smog precursors to motor vehicles (Benfield, Raimi and Chen 1999).\nUrban Sprawl & Ozone Land use patterns affect levels of ozone. In sprawling environments, individuals release more VOCs and nitrogen dioxides into the atmosphere, both of which are components of ozone. Table 1: Average daily VOC and NOx emission rate for compact and disperse cities (Borrego, Martins, and Tchepel et al 2006).\nSprawl Index & Ozone Every 25 unit increase in the sprawl index (less sprawling) relates to a 7.5 parts per billion decrease in maximum ozone levels. Ozone levels between the most sprawling regions and the least sprawling regions differ by 41 parts per billion (Ewing, Pendall, and Chen 2002).\nUrban Sprawl & Ozone Urban sprawl not only contributes to higher ozone levels, but ozone also covers more area in sprawling regions: Figure 2: Ozone concentrations (relative to background ozone levels) at 2pm in alternate city structures (Borrego, Martins, and Tchepel et al 2006).\nUrban Sprawl & Ozone Ozone affects more people in areas of greater sprawl: Table 2: Population affected by ozone concentrations (Borrego, Martins, and Tchepel et al 2006). Again, because individuals living in sprawl produce more VOCs and nitrogen oxides daily, as a result their ozone levels are higher, cover more area, and affect more people than compact cities. This is because individuals in compact cities produce less VOCs and nitrogen oxides. Thus, their ozone levels, area and population affected by ozone are not as greatly impacted by ozone pollution.\nCarbon Monoxide Analysis Sprawling regions also emit an alarmingly large amount of carbon monoxide. Combining demographic information and data collected on how much carbon monoxide an average car emits, we can see how dangerous sprawl is for air quality. The EPA estimates that the average car annually produces 22g CO for every 12,500 miles driven (EPA, 1997). This means that the average car produces.00176g CO for every mile driven (22g CO/12,500).\nCarbon Monoxide Analysis It is also recorded the average person in the Atlanta metropolitan area travels 34.1 miles/day, whereas the average person in the Philadelphia metro area dives 16.9 miles a day, and the average Chicago metro inhabitant dives 19.9 miles per day (Frumkin, 2002). On the sprawl index, Atlanta’s score is has a 57.7 (very sprawly), Philadelphia’s is 112.6 (average sprawl), and Chicago’s is 121.2 (higher sprawl).\nThe Atlanta metro area has nearly two million less people then the Philadelphia metro area, yet Atlanta emits around two billion more pounds of carbon monoxide yearly. Chicago’s metro area has twice the population of the Atlanta metro area, and Atlanta still produces more than one billion pounds of carbon per year. The differences seen are attributed to sprawl: individuals living in sprawl drive more frequently and drive than those living elsewhere, and the impact this car dependency has on the environment will be detrimental.\nWater Pollution Urban development in watersheds (an area drained by a river or some other body of water) can greatly alter the composition of a river, which can in turn affect water quality This section focuses on two watersheds—the Schuylkill watershed and the Waquoit Bay watershed—and examines how sprawl impacts these two bodies of water.\nSchuylkill River, PA The Schuylkill River has some of the highest dissolved solute concentrations of all water sources in the northeast—it has the highest nitrate levels and the second highest chloride levels (Interlandi and Crockett 2003). The Schuylkill also had the fastest increase for nitrate, chloride and residuals over all other watersheds in the northeast (Interlandi and Crockett 2003). This suggests that development in the Schuylkill watershed negatively impacts the river.\nSchuylkill River, PA From 1982 to 1997, developed land in the Schuylkill watershed increased from 21.5% of the total watershed land area to 28.5%—over 34,000 hectares of forest and agricultural land were urbanized. This change in land use resulted in a 31% increase in developed land. When sprawling occurred in the watershed and developed land increased by 31%, chloride levels increased 37% in that same time period (Interlandi and Crockett 2003).\nWaquoit Bay, MA The Waquoit Bay is located in Cape Cod, MA, and like the Schuylkill watershed, the Waquoit Bay watershed has seen a recent burst in urban development. The predominant source of nitrogen in the water comes from atmospheric deposition, fertilizer use and wastewater disposal. in the 1980s, the major source of nitrogen changed from atmospheric deposition to wastewater, reflecting the increase in urbanization in the Waquoit watershed (Bowen and Valiela, 2001).\nWaquoit Bay Between 1938 and 1990, when most urbanization occurred in the area, nitrogen inputs into the Waquoit bay watershed increased twofold (Bowen and Valiela, 2001). In 1990, wastewater accounted for 22% of the bay’s total nitrogen delivery, whereas in the mid-century, it only accounted for 2%. Thus, nitrogen from wastewater increased ten-fold during the period of urban sprawl in the watershed.\nHealth Hazards of Sprawl The harmful effects that sprawl has on air and water quality have implications for human health. AIR Nitrogen oxides can react with numerous compounds to form acid and other particles Particles can inflict damage to lung tissue which can cause or worsen respiratory diseases such as emphysema and bronchitis\nHealth Hazards of Sprawl - Air VOCs release hydrocarbons, some of which are carcinogenic Carbon monoxide affects the central nervous system, causing visual problems, reduced ability to work or learn, and difficulty performing tasks At extremely high levels, carbon monoxide is poisonous and can cause death (EPA, 2006).\nWater Related Hazards Nitrogen Through water pollution, increased nitrates in the water can cause methmeglobenemia in infants under six months. Blue baby syndrome because the hemoglobin goes from being ferrous to ferric (FE 2 + to FE 3 + ). This is an oxidizing reaction—thus, the hemoglobin’s ability to carry oxygen is lowered, making the infants blue. This syndrome is potentially fatal\nWater Related Hazards Storm runoff currently 5,529 water bodes in the US are impaired by pathogens (Gaffield, Goo, Richards et al 2003). The insecticides in runoff that infect water have carcinogenic effects in humans. The amount of disinfectant (such as chlorine) can also have a carcinogenic effect. The EPA estimates that ingestion of drinking water with disinfectant byproducts is responsible for 1100-93000 cases of bladder cancer each year (Gaffield, Goo and Richards et al 2003).\n(Gaffield, Goo and Richards et al 2003). Impaired Water Bodies in the USA\nGeneral Health Hazards Sprawl categorically makes people less healthy. The overall sprawl index significantly predicts the number of chronic medical conditions and of physical health-related quality of life of the residents in the area. Greensboro, NC San Fran, CA 46.8 148.6 190 181 46.8 44.2 1.35 1.14\nSprawl Index (Abridged) As a region’s sprawl index increases by 25 points, the number of residents suffering from various chronic conditions decreases (Sturm and Cohen 2004). Sprawl Score5075100125150 Arthritis291274259243228 Trouble Breathing 6459544945 Abdominal/Diges tive Problems 9285797368 Migraine/Chroni c Headaches 145137130123116 Urinary Tract Issues 6660545945\nCONCLUSION America will undoubtedly continue to develop, thus, action must be taken to ensure that further development is not hazardous to the environment and to its inhabitants. It is necessary that that future designs must be eco-friendly, and moreover, must consider the health of its residents.\nWorks Cited: An Introduction to Indoor Air Quality: Organic Gases (Volatile Organic Compounds - VOCs). Environmental Protection Agency. 5 December 2006. Air Emissions Trends - Continued Progress Through 2005. Environmental Protection Agency. 5 December 2006. Atlanta Metropolitan Area. Wikipedia. 5 December 2006. Benfield, F. Kaid, Matthew D. Raimi, and Donald D.T. Chen. Once There Were Greenfields: How Urban Sprawl is Undermining America’s Environment, Economy, and Social Fabric. New York: Natural Resources Defense Council, 1999. Borrego, C., H. Martins, O Tchepel, et al. (2006) “How Urban Strucutre Can Affect City Sustainability from an Air Quality Perspective.” Environmental Modeling and Software. 21: 461-467. Bowen, Jennifer L. and Ivan Valiela. (2001). “The Ecological Effects of Urbanization of Coastal Watersheds: Historical Increases in Nitrogen Loads and Eutrophication of Waquoit Bay Estuaries.” Canadian Journal of Fisheries and Aquatic Sciences. 58: 1489-1500. Chloride. Wikipedia. 5 December 2006.\nChicagoland. Wikipedia. 5 December 2006. Delaware Valley. Wikipedia. 5 December 2006. Ewing, Richard, Rolf Pendall, and Don Chen. “Measuring Sprawl and its Impact.” Smart Growth America. 24 October 2006. Gardener, Sarah. “The Impact of Sprawl on the Environment and Human Health.” Urban Sprawl: A Comprehensive Reference Guide. Ed. David C. Soule. Westport, CT: Greenwood Press, 2006. 240-260. Gaffield, Stephen J., Robert L. Goo, Lynn A. Richards et al. (2003) “Public Health Effects of Inadequately Managed Stormwater Runoff.” American Journal of Public Health. 98: 1527-1531. Goldman, Todd. ""Consequences of Sprawl: Threats to California\'s Natural Environment and Human Health"" eScholarship Repository. Institute of Urban & Regional Development at UC Berkley. 24 November 2006. Health and Environmental Impacts of CO. Environmental Protection Agency. 6 December 2006. http://www.epa.gov/air/urbanair/co/hlth1.html Health and Environmental Impacts of NOx. Environmental Protection Agency. 6 December 2006. Frumkin, Howard. (2002) “Urban Sprawl and Public Health.” U.S. Department of Health and Human Services: Public Health Reports. 117: 201-217. Interlandi, Sebastian J. and Christopher. S. Crockett. (2003) “Recent Water Quality Trends in the Schuylkill River, Pennsylvania, USA: A Preliminary Assessment of the Relative Influences of Climate, River Discharge and Suburban Development.” Water Research. 37: 1737-1748. Nitrate. Wikipedia. 5 December 2006.\nWhat are the Six Common Air Pollutants? Environmental Protection Agency. 5 December 2006. Wolfe, Amir H. and Jonathan A. Patz. (2002) “Reactive Nitrogen and Human Health: Acute and Long-term Implications.” Ambio. 31: 120-125. Images: Massachusetts Estuaries Project. 5 December 2006. Schuylkill River: National State and Heritage Area. 5 December 2006. Waquoit Bay: National Estuarine Bay Research Reserve. 5 December 2006.']"	['<urn:uuid:55af0641-92cc-423c-b2db-edfbcd99f5c2>', '<urn:uuid:7daff17b-004a-4103-8901-550bab085d6f>']	open-ended	direct	concise-and-natural	distant-from-document	multi-aspect	expert	2025-05-01T23:46:40.222380	11	89	2971
382	How can team members help each other work better together?	Team members have two major responsibilities: to learn and to teach. They must learn about requirements and each other's viewpoints, priorities, and styles through active listening. They must also teach by sharing experience and expertise to help others understand the reasoning behind their suggestions.	['Part of the challenge of requirements work is transforming a diverse group of stakeholders into a productive and efficient team. Tuckman proposed a staged model of team development that has stood the test of time. Understanding this model can improve the quality of stakeholder communication and lessen the time spent developing an effective team.\nIn brief, the team development stages are:\nthe team is meeting and greeting\neveryone is polite\nsome stakeholders are excited\nthere is no obvious conflict\nnothing important is decided\ndifferences surface in viewpoints, priorities, and style\nconfusion and disagreements about team objectives, priorities, organization, and strategies are obvious\nsuspicions and impatience appear about team members and the project misunderstandings are frequent\nthere is little progress\ncommon understanding and respect begins\ncriticism is expressed thoughtfully and constructively\nconsensus forms on work rules, goals, boundaries, roles, and strategy\nimproved listening and open sharing\na foundation for cooperation is created\ncooperative relationships are established\nthe focus is on major issues and important tasks\nteam pride increases\nwork is getting done\nsubstantial progress is made\nUnless a team has successfully worked together or is homogeneous in outlook, style, and understanding, there is no way to skip the Storming and Norming stages. Requirements efforts rarely satisfy these skipping criteria.\nThis model certainly describes my experience with teams of diverse stakeholders. For example, from personal mistakes, I now understand that it matters a great deal when proposals are introduced to the team. The team may reject a proposal, for example about work product development strategies, introduced in the Forming stage before context and trust have been established. Rejection often includes wasteful discussions filled with misunderstandings. If the same proposal is introduced in the Norming stage, the team may accept it with little discussion. Effective communication requires that the receiver be ready for the message. Now I know that warm bodies in a room is not a sufficient indicator of readiness to receive.\nThe relative calm of the forming stage provides the team leader with an opportunity to define expectations and behavioral ground rules that can help the team negotiate the remaining stages. An expectation is that the team will learn a great deal during requirements development. The team will never know less than it does at the beginning. Admitting that requirements development is a journey out of ignorance by means of an exercise in group learning helps the team deal with the doubts of development.\nYou may find it effective to charge each stakeholder with two major responsibilities: to learn and to teach. Stakeholders must not only learn about requirements, but about each others viewpoints, priorities, and styles. This learning needs active listening and suppression of quick judgments.\nThe teaching responsibility entails sharing experience and expertise to enable other team members to understand some of the reasons behind suggestions made by the member who is teaching. Without minimal teaching, suggestions become commandments and the expert must always be right. Without teaching, there is little room for discussion on many issues and when needed, negotiated compromise is difficult since no side can understand the reasoning of the other. Team acceptance of their learning and teaching responsibilities smoothes the transition through Storming and Norming.\nA variant of the Tuckman model is Forming, Storming, Ignoring, and Pretending. During these stages:\n1. Forming - [Same as Tuchman model]\n2. Storming - Uncovers or should uncover major conflicts in goals, priorities, or strategy among critical stakeholders\n3. Ignoring - Fails to either resolve the conflicts or halt the project\n4. Pretending - Follows the protocols of requirements development with']	['<urn:uuid:99a66a15-ebff-4d18-ad32-d3facc8e4145>']	factoid	direct	concise-and-natural	distant-from-document	single-doc	novice	2025-05-01T23:46:40.222380	10	44	592
386	What can be done to modify mRNA?	Various modifications can be introduced into mRNA through three methods: by changing the sequence of the DNA template, by modifying the transcription reaction, or through post-transcriptional modification.	"['By Peter M. Rabinovich\nArtificial mRNA is an enticing device for mammalian mobilephone reprogramming that can be utilized in easy examine, in addition to in medical purposes. current mRNA in vitro synthesis is a slightly basic technique, which can provide a excessive yield of caliber product. a variety of changes should be brought into the mRNA through altering the series of the DNA template, via enhancing the response of transcription, or via post-transcriptional amendment. mRNA, as a transfection agent, has numerous benefits over DNA, as mRNA expression isn\'t really depending on nuclear access and happens at once within the cytosol. artificial Messenger RNA and telephone Metabolism Modulation: tools and Protocols covers the common major tools, resembling mRNA synthesis, variations, and supply. Examples of cellphone reprogramming and research within the fields of immunotherapy and stem cellphone examine also are integrated. Written within the profitable tools in Molecular Biology™ sequence structure, chapters comprise introductions to their respective issues, lists of the mandatory fabrics and reagents, step by step, conveniently reproducible protocols, and notes on troubleshooting and heading off identified pitfalls.\nAuthoritative and simply obtainable, Synthetic Messenger RNA and mobilephone Metabolism Modulation: tools and Protocols might be of curiosity to researchers, clinicians, and biotech businesses drawn to mRNA-mediated mobile reprogramming.\nRead or Download Synthetic Messenger RNA and Cell Metabolism Modulation: Methods and Protocols PDF\nBest molecular biology books\nMolecular modeling has gone through a extraordinary transformation within the final two decades. This publication presents thorough introductions and a compilation of step by step tools appropriate to difficulties confronted by means of non-specialists – specially these new to the software program applications utilized in molecular modeling. pointers on troubleshooting and warding off universal pitfalls are integrated within the publication, in addition to chapters overlaying a variety of topics.\nCockayne syndrome (CS) is an extraordinary autosomal genetic disease that was once first pointed out virtually sixty two years in the past by way of Alfred Cockayne and used to be named after him. The earliest ebook list (PubMed) on hand is a paper via Marie et al in 1958. on the grounds that then 815 study papers together with very good reports were released (PubMed, December 2008), but we\'re far from absolutely figuring out the precise molecular mechanisms of this illness.\n""Strong muscular tissues and bones defy the getting older technique. Margaret Richard\'s physique electrical software provide you with the impressive chance to gain your health capability. ""--Miriam Nelson, Ph. D. , bestselling writer of sturdy ladies remain younger a few issues by no means get outdated. you definitely do not tire of vivid health and wellbeing, younger strength, radiant attractiveness, and the power to dwell your existence any manner you please.\nThis anthology offers an perception into the wit and mind of the clinical brain via a mix of fun and critical contributions written via and approximately scientists. The contributions checklist altering attitudes inside of technology and reflect the interactions of technology with society.\n- Horizontal Gene Transfer in the Evolution of Pathogenesis (Advances in Molecular and Cellular Microbiology)\n- Chemistry of Protein Conjugation and Cross-Linking\n- MicroRNA Profiling: Methods and Protocols\n- Fluorescent analogs of biomolecular building blocks : design and applications\n- Advances in Enzymology and Related Areas of Molecular Biology, Volume 69\nExtra info for Synthetic Messenger RNA and Cell Metabolism Modulation: Methods and Protocols\nMcCammon JM, Amacher SL (2010) Using zinc finger nucleases for efficient and heritable gene disruption in zebrafish. Methods Mol Biol 649:281–298. 1007/978-160761-753-2_18 189. Breaker RR (2011) Prospects for riboswitch discovery and analysis. Mol Cell 43(6):867–879 190. Breaker RR (2012) Riboswitches and the RNA world. Cold Spring Harb Perspect Biol 4(2):pii: a003566 191. Wan Y, Kertesz M, Spitale RC, Segal E, Chang HY (2011) Understanding the transcriptome through RNA structure. Nat Rev Genet 12(9):641–655.\nFreeze-thaw the dissolved RNA by placing the tube on dry ice until frozen and then on the bench at RT until thawed. Vortex the sample vigorously and repeat the freeze-thawing two more times to ensure complete rehydration of the sample. A −80°C or −20°C freezer can also be used, but freezing takes more time. 11. Measure the concentration of the RNA with a NanoVue. 04 to obtain μg/μl of RNA. 12. Analyze the quality of the RNA by agarose gel electrophoresis and EtBr staining and UV illumination (see Note 4).\n7. Centrifuge the precipitated RNA at 13,000 × g for 5 min in a microcentrifuge at RT. 8. Wash the firm RNA pellet three times with cold 75% ethanol (see Note 7). 9. Let the remaining ethanol evaporate by leaving the tube on the bench with the cap open for about 5 min. Do not let the RNA pellet completely dry. 10. Resuspend the RNA pellet in UP water. 11. Freeze-thaw the dissolved RNA by placing the tube on dry ice until frozen and then on the bench at RT until thawed. Vortex the sample vigorously and repeat the freeze-thawing two more times to ensure complete rehydration of the sample.']"	['<urn:uuid:4a676079-5b71-4a82-9304-c2e73f7060ff>']	open-ended	direct	concise-and-natural	similar-to-document	single-doc	novice	2025-05-01T23:46:40.222380	7	27	827
388	I'm studying cryptography. What info gets sent in a ClientHello message?	In a ClientHello message, the client sends: supported SSL/TLS protocol versions, 32 bytes of random data (4 bytes datetime + 28 bytes random number), session ID for the connection, compression method for SSL packets, and cipher suites which define cryptographic algorithms for the connection.	"['In part 1, 2, 3 and 4 of this series we looked at What is TLS/SSL?, took a brief look at the History of TLS and SSL, TLS/SSL terminology and basics and TLS/SSL Certificates. In this fifth part in the series, we will be looking at establishing a TLS connection.\nTo get a better understanding of the TLS protocol, we will now see what exactly takes place for a secure connection to be established.\nThe most important process of the connection establishment is the so called “Handshake”. During the Handshake, server and client will exchange important information regarding the properties under which the connection will be established.\nDuring the Handshake we will see how a hybrid of asymmetric and symmetric encryption is used in order to ensure security.\nFor this article we will refer to a browser as the Client. In the following example, Diffie-Hellman is used for the key exchange.\nA standard negotiation between client-server (handshake) starts off with a Client Hello message.\nThe client, sends a Client Hello to the server and includes the following.\nThe client will send a list of all the SSL/TLS protocol versions it supports, with the preferred one being first on the list. The preferred one is usually, and should be, the latest available version.\nA 32-byte random data of which 4 bytes represent the client’s current datetime (in epoch format) and the remaining 28 bytes, a randomly generated number. The Client’s random and Server’s random will later be used to generate the key which the data will be encrypted with.\nThis is the session id which will be used for the connection. If the session_id is not empty, the server will search for previously cached sessions and resume that session if a match is found.\nThis is the method that is going to be used for compressing the SSL packets. By using compression, we can achieve lower bandwidth usage and therefore, faster transfer speeds. Later on this article we will see why using compression is risky.\nCipher suites are combination of cryptographic algorithms which are used to define the overall security of the connection to be established. Typically, each cipher suite contains one cryptographic algorithm for each of the following: Key Exchange, Authentication, Bulk (data) Encryption and Message Authentication.\nA sample cipher suite is the following:\nLet’s break this down so that it makes more sense.\n- TLS is the protocol being used\n- ECDHE is the key exchange algorithm (Elliptic curve Diffie–Hellman)\n- ECDSA is the authentication algorithm (Elliptic Curve Digital Signature Algorithm)\n- AES_128_GCM is the data encryption algorithm (Advanced Encryption Standard 128 bit Galois/Counter Mode)\n- SHA256 is the Message Authentication Code (MAC) algorithm (Secure Hash Algorithm 256 bit)\nHere’s what an actual Client Hello looks like in a Wireshark capture.\nThe client can request additional functionality for the connection and this can be done via “extensions”. If the server cannot provide the additional functionality, then the client can abort the handshake if needed.\nAfter the server receives the Client Hello, the second step will be to reply with a Server Hello. If it finds an acceptable set of algorithms in Client’s request, it will respond by accepting those options and provide its certificate. If the server does not meet the requirements of the Client it will respond with a handshake failure message.\nThe server, sends a Server Hello to the client and includes the following.\nThe server will (not blindly) select the Client’s preferred version of SSL/TLS protocol.\n32 bytes of random data, out of which 4 bytes represent the server’s current datetime (in epoch format), and the rest 28 bytes is a randomly generated number will be sent to the client. The Server’s random and Client’s random will later on be used to generate the key with which the data will be encrypted.\nThis is the session id which will be used for the connection. If the session_id sent by the Client is not empty, the server will search for previously cached sessions and if a match is found, that session id will be used, thus resuming. If the session_id is empty, a new session will be created for the connection.\nIf supported, the server will agree on the Client’s preferred compression method.\nIf supported, the server will agree on the Client’s preferred cipher suite.\nThe signed certificate of the server which proves the identify it’s to the client. It also contains the public key of the server.\nClient Certificate (optional)\nNot often, the server may require the client to be authenticated with a Client Certificate as well. In cases like this the client will provide its signed certificate to the server.\nServer Key Exchange\nThe server key exchange message is sent only if the certificate provided by the server is not sufficient to allow the client to exchange a pre-master secret. (This is true for DHE_DSS,DHE_RSA and DH_anon)\nServer Hello Done\nThis is sent to the client as a confirmation that the Server Hello message is completed.\nThe following is what a Server Hello looks like in a Wireshark capture.\nClient Key Exchange\nThe Client Key Exchange message is sent right after the Server Hello Done is received from the server. If the server requests a Client Certificate, the Client Key Exchange will be sent after that.\nDuring this stage, the client will create a pre-master key.\nThe pre-master secret, is created by the client (the method of creation depends on the cipher suite that will be used) and then it is shared with the server.\nBefore sending the pre-master secret to the server, the client encrypts it using server’s public key which was extracted from the certificate provided by the server. This means that only the server can decrypt the message since asymmetric encryption is being used for the pre-master secret exchange.\nThe following is what the key-exchange looks like in a Wireshark capture (using DH).\nAfter the server receives the pre-master secret key, it uses its private key to decrypt it. Now both client and server will compute the master-secret key based on the random values exchanged earlier (ClientRandom and ServerRandom) using a Pseudorandom Function (PRF). A PRF is a function used to generate arbitrary amounts of pseudorandom data.\nmaster_secret = PRF(pre_master_secret, ""master secret"", ClientHello.random + ServerHello.random) [0..47];\nThe master-secret key, which is 48 bytes in length, will then be used by both client and server to symmetrically encrypt the data for the rest of the communication.\nEach of the parties, Client and Server, will create 3 set of keys.\n- client_write_MAC_key – Authentication and Integrity check\n- server_write_MAC_key – Authentication and Integrity check\n- client_write_key – Message encryption using symmetric key\n- server_write_key – Message encryption using symmetric key\n- client_write_IV – Initialization Vector used by some AHEAD ciphers\n- server_write_IV – Initialization Vector used by some AHEAD ciphers\nBoth Client and Server will use the master secret to generate the sessions keys which will be to encrypt/decrypt the data.\nAt this point, both the Client and the Server are ready to switch to a secure, encrypted environment. The Change Cipher Spec protocol is used to change the encryption being used by the client and server. Any data being exchanged between the two parties will now be encrypted with the symmetrical shared key they have.\nThis is what the Change Cipher Spec looks like in a Wireshark capture.\nThe last message of the handshake process and first encrypted one in the secure connection is Finished, which is exchanged by both parties.\nTo recap, the following illustrates a typical handshake.']"	['<urn:uuid:4e5d51bd-3ffb-42fe-ae2d-05eac301b258>']	factoid	with-premise	concise-and-natural	distant-from-document	single-doc	expert	2025-05-01T23:46:40.222380	11	44	1256
389	importance hazardous materials storage rules	Storing hazardous substances safely is important for protecting workers. This requires storing only what you need, ensuring incompatible substances are not stored together, and making sure decanted substances are stored in the right type of container with correct labeling.	['Unauthorised Access: What It Is and How to Prevent It. Preventing unauthorised access to your building is essential for security and health and safety. Failing to secure your business premises properly could result in theft, anti-social behaviour and accidents causing harm to your workers and the public.\nWhether at home or at a business, everyone has valuable equipment and belongings that need to be kept safely. Having access control in place can ensure exactly that, as it limits who has access to those belongings, and restricts access to certain areas of a business or residence where valuables are stored.\nHow to Prevent Unauthorized Computer Access\n- Install all Security Patches.\n- Browsing the Internet? Pay Due Attention to File Sharing.\n- Keep the Firewall On.\n- Carefully Read Your Email MEssages and Know the Senders.\n- Maintain a Proper Backup of Your Data Online.\n- Make Use of Strong Passwords.\nUnauthorized disclosure of information: disclosure of confidential, sensitive or embarrassing information can result in loss of credibility, reputation, market share, and competitive edge. 2. Disruption of computer services: be unable to access resources when they are needed can cause a loss of productivity.\nWhy is it important to secure a storage facility?\nA good self-storage facility will offer you unrivalled safety and uncompromised security to ensure that you belongings are safe from theft or damage. … Some of the more questionable facilities might only have rudimentary security installations in place, whilst some may not have any at all.\nWhy do we need safe storage?\nStoring hazardous substances safely is an important part of protecting you and your workers. This includes storing only what you need, ensuring that incompatible substances are not stored together, and that decanted substances are stored in the right type of container and correctly labelled.\nWhy safety and security is important in every establishment?\nEvery workplace needs to ensure it meets the proper health and safety regulations. Having organizational safety and security processes can help manage and prevent injury, theft, and damage in the workplace. As a small business employer, you have a responsibility to your employees to maintain workplace safety.\nWhy safety and security is important in every establishment building?\nWhy is a Secure Building Important? A secure building will decrease the chance of security threats occurring. By having security procedures in place, you can avoid common threats such as robbery and damage to your property. By having a secure building you are also protecting your staff.\nWhy is controlling access to information important?\nAccess controls limit access to information and information processing systems. When implemented effectively, they mitigate the risk of information being accessed without the appropriate authorisation, unlawfully and the risk of a data breach.\nUnauthorized access is when someone gains access to a website, program, server, service, or other system using someone else’s account or other methods. For example, if someone kept guessing a password or username for an account that was not theirs until they gained access, it is considered unauthorized access.\nWhat are the protection and defend information needed in ensuring information systems?\nThe US Government’s definition of information assurance is:\n“measures that protect and defend information and information systems by ensuring their availability, integrity, authentication, confidentiality, and non-repudiation.\nA person gains logical or physical access without permission to a network, system, application, data, or other resource.']	['<urn:uuid:a3b5e11c-1b98-4970-8d63-e1a0d4a4d5c9>']	factoid	direct	short-search-query	distant-from-document	single-doc	expert	2025-05-01T23:46:40.222380	5	39	556
393	I'm curious about the unique steam engines at Crofton - what makes them special compared to other historic machines?	Crofton Beam Engines are the oldest working steam engines in the world that are still performing their original intended function. They are especially impressive to visit during steam days when visitors can see these historic machines in operation.	"[""Chippenham Museum and Heritage Centre (5 miles)\nChippenham Museum and Heritage Centre\nis a local community museum. Explore the past with Alfred the Great or Mr Brunel. Try dressing up as a Saxon peasant or a Victorian child. For under 5’s try Messy Monday or Noisy Friday. Everyone is welcome in our children’s holiday workshops.\nAvebury Stone Circle (7 miles)\nSilbury Hill (7 miles)\nKnown as the English pyramid, this is the world's largest man made chalk deposit which does indeed rival the height of the pyramids. No access to hill itself but nice as a stop off if passing.\nFarleigh Hungerford Castle (15 miles)\nFarleigh Hungerford Castle\nPartially ruined fortified mansion and gardens to explore with a variety of family friendly events and activities.\nBath Postal Museum (16 miles)\nBath Postal Museum\nFollow the history of the British Postal System and communication in this tiny but great museum for all ages, with a mixture of video recordings, interactive displays and other exhibits.\nRoman Baths and Museum (16 miles)\nRoman Baths and Museum\nSee the water's source and walk where Romans walked on the ancient stone pavements. Excellent children's audioguide tour with some exhibitions.\nDyrham Park (16 miles)\nA late 17th century mansion, garden and deer park. A large estate full of great places to walk with the kids.\nCrofton Beam Engines (18 miles)\nCrofton Beam Engines\nVisit the oldest working steam engines in the world that are still performing the job they were built to do! Especially good on a steam day.\nStonehenge (19 miles)\nStands as a timeless testimony to the people who built it, between 3000BC and 1500BC. An amazing feat of engineering and arguably the most sophisticated stone circle in the world, it remains a mystery. Fantastic new visitor centre!\nWalled Garden at Mells (21 miles)\nWalled Garden at Mells\nAn idyllic 17th century working garden dedicated to British plants with free entry. Welcomes families including dogs.\nNunney Castle (23 miles)\nA French moated castle ruin in Somerset. Kids will love it, because it has all the qualities of a castle: a keep, a moat with fish in it, big thick walls and towers on each corner.\nFaringdon Folly Tower and Woodland (24 miles)\nFaringdon Folly Tower and Woodland\nVisit Faringdon’s unique, iconic 100ft tower, the last major folly to be built in England. Surrounded by interesting woodland to explore that contains sculptures to find. Kids aged 11 and under get in free.\nBerkeley Castle (26 miles)\nis England's oldest inhabited castle and most historic home. Over 24 generations of Berkeley's have transformed a savage Norman fortress into a truly stately home full of treasures. Come and learn about murder, intrigue and mysterious events at the castle.\nDr Jenners House (26 miles)\nDr Jenners House\nThe former country home of the scientist who invented a vaccine against smallpox, the greatest killer disease at the time. Discover the story of the ‘man who saved the world’!\nClifton Observatory (27 miles)\nA natural cave with viewing platforms, unparalleled views over the local scenery and the only formal Camera Obscura in England.\nChedworth Roman Villa (27 miles)\nChedworth Roman Villa\nThe ruins of one of the largest Romano British villas in the country. Also considered one of the most complete and extensive sites, includes some great mosaics. Interesting activities and events throughout the summer and school hols.\nThe Clifton Suspension Bridge (27 miles)\nThe Clifton Suspension Bridge\nDesigned by the great Victorian engineer Isambard Kingdom Brunel the bridge provides spectacular views over the pretty Avon Gorge. It's a great place to walk across and see how high you are above the traffic and the river. Feel and see it move with the traffic!\nBlaise Castle and Play Area (27 miles)\nBlaise Castle and Play Area\nCastle, museum, 2 age zoned play areas and some truly beautiful woodland walks, this is a great day out for all age groups.\nMompesson House (27 miles)\nFeatured in the award-winning film Sense and Sensibility, the sumptuous setting is home to a variety of collections including 18th century drinking glasses. There is a children's guide available at reception and sculpture gardens to explore.\nGreat Witcombe Roman Villa (27 miles)\nGreat Witcombe Roman Villa\nVisit the remains of a large villa that was built around AD 250 plus a shrine to a water spirit! Tricky terrain though, best for the fit and mobile. A short trip, but free!\nOld Wardour Castle (28 miles)\nOld Wardour Castle\nExplore the set of Robin Hood: Prince of Thieves via self guided audio tour, with enchanting grotto and circular staircases, plus play and picnic space outside.\nHighclere Castle (29 miles)\nVictorian Castle experience rich in history, with woodland garden surround, plus Egyptian Exhibition.\nTyntesfield (31 miles)\nSpectacular Victorian Gothic Revival house with gardens, parkland and a visitors centre.\nWells Cathedral (32 miles)\nA 12th Century Early English Gothic Cathedral boasting 296 Medieval groups of structure. One of England's most beautiful cathedrals.\nThe Bishops Palace (32 miles)\nThe Bishops Palace\nSensory Trail, 10 metre willow dragon to discover, family activities and events, and workshops at this Grand Palace surrounded by 14 acres of gardens.\nWhitchurch Silk Mill (33 miles)\nWhitchurch Silk Mill\nSilk has been woven here since the 1820 to 1830s. The Mill produces high quality silks to order for theatrical costume, interior designers and historic houses. Interactive exhibits and hands on opportunities.\nCaldicot Castle (33 miles)\nExplore the Castle and its beautiful setting of tranquil gardens and a wooded country park. Lots for kids to do including activity station and activities and workshops throughout the year.\nSudeley Castle (35 miles)\nVisitors can explore the castle, play in the outdoor adventure playground featuring a spectacular wooden fort with zip-wire and hidey holes, take an alpaca on a trek around the estate (extra cost) and spot rare pheasants, owls and even parrots.\nClevedon Pier (37 miles)\nthe only fully intact, Grade 1 listed pier in the country. There are boat trips, fishing, events and an art gallery.\nGlastonbury Abbey (37 miles)\n36 acres of beautiful parkland and history for every visitor to enjoy. Visit what was the largest and richest abbey in England for an amazing experience.\nMottisfont Abbey and Garden (38 miles)\nMottisfont Abbey and Garden\nAn abbey was built here in 1201 and you can still see some of its remains. Have a peek in the dark and atmospheric vaulted Cellarium! The house boasts an impressive art collection and the garden is home to the National Collection of Historic Roses!\nOxford Castle Unlocked (39 miles)\nOxford Castle Unlocked\nAn ancient site of incarceration offering a highly atmospheric history lesson spanning ten centuries, with hands on displays and real life prisoner stories. Quirky costumed tour guides are available every 20 minutes.\nBates Collection of Musical Instruments (39 miles)\nBates Collection of Musical Instruments\nOne of the most magnificent collections of musical instruments in the world. Has over 2000 instruments from the Western orchestral music traditions from the renaissance, through the baroque, classical, romantic and up to modern times.\nThe Bodleian Library (39 miles)\nThe Bodleian Library\nInteractive and stimulating tours of the historic university where much of Harry Potter was filmed! Like stepping into their favourite films. Most tours are for 10+ but Family Tours in holidays welcome 5+.\nBlenheim Palace (39 miles)\nSteeped in inspirational history and surrounded by beautiful parkland and award-winning Formal Gardens, Blenheim Palace in Oxfordshire offers the perfect day out in 2012. This year there are stunning new visitor facilities to enjoy, as well as a host of superb special events in store.\nWinchester Castle and Great Hall (40 miles)\nWinchester Castle and Great Hall\nThe remains of an historic castle with the round table said to be used by the legendary King Arthur! Free to visit. Events for kids are held during the school holidays.\nWinchester Cathedral (40 miles)\nFor over a thousand years, people have come to seek inspiration in this magnificent Cathedral. Today, they welcome 300,000 visitors a year to share their worship, explore their heritage and attend their many events.\nBasing House (43 miles)\nA historic adventure recreating the c16th with a museum, gift shop and battle reenactments!\nThe Eling Experience (43 miles)\nThe Eling Experience\nLearn about tidal powered milling, site in an air raid shelter with sound effects, pirate play ship and picnic areas, plus historical and ecological walks.\nEastnor Castle (44 miles)\nFairytale Georgian castle in magical surroundings, with Deer Park, Lake and Arboretum, Children's Adventure Playground and Assault Course, Knight's Maze and Burma Bridge Tree Top Walkway.\nMontacute House (46 miles)\nStunning Elizabethan mansion surrounded by beautiful grounds. Explore the house and gallery, beautiful gardens and parkland with free guided tour.\nTudor House and Garden (46 miles)\nTudor House and Garden\nGives a unique and atmospheric insight into the lives and times of both its residents through the years, and of Southampton itself. It appeals to visitors of all ages and interests, who find the family-friendly activities, interactive technology and fascinating displays a winning combination.\nKiftsgate Court Gardens (46 miles)\nKiftsgate Court Gardens\nA beautiful English garden created by three generations of women including large walled gardens, plus a swimming pool, bluebell woods and water garden. Plenty of space to walk with the kids.\nCroome (47 miles)\nRestored to its 18th century beauty, fascinating statues, follies and temples are hidden around every corner of the garden for the kids to discover on the Family Trail. Intrigue older ones with the fact it was a secret wartime air base!\nMalvern Hills GeoCentre (47 miles)\nMalvern Hills GeoCentre\nis the official visitors' centre of the Geopark way. Attractions include interactive iPads and wall maps encouraging kids to learn all about the geology, archaeology, history and water of the Malvern Hills. The Cafe stocks a wide range of local food and drink and has free WiFi and parking.\nOdiham Castle (47 miles)\nOne of King John's three strongholds, recently restored and open for visitors.\nBeaulieu (49 miles)\nIn the heart of the New Forest this great family day out has something for everyone from motoring to heritage and history to rides. 250 vehicles in the motor museum, living history in Palace house and unlimited rides on the monorail and bus make a day for the whole family.\nBroughton Castle (49 miles)\nA hugely popular and impressive house and grounds, beautifully furnished and lovingly restored, with fascinating historical artifacts throughout. For a full day you enjoy this in conjunction with another local activity, and although they seem child friendly it is definitely only for the calmer kids.\nTechniquest (50 miles)\nPurpose built Science Centre and Planetarium providing interactive science experiences making science accessible to everyone.\nAthelhampton House and Gardens (50 miles)\nAthelhampton House and Gardens\nStunning Tudor Great Hall and gallery with its own estate church and surrounding gardens with 9 metre tall pyramid yew trees, octagonal pond and lots of hidden corners to explore.\nThanks for all the great things to do and Historical and Educational Attractions near Calne with kids you keep sending in.\nNow we have the easter and summer holidays fast approaching, we're trying to find the best days out and as many fun things to do with kids as possible, especially cheap and free family friendly places to visit this year - theme parks, waterparks and swimming pools, museums, indoor playcentres and softplay for toddlers, petting farms, wildlife parks and zoos, aquariums, horse riding, castles, steam railways, pottery making and ceramic cafes, roller and ice skating rinks, karting tracks, snowdomes, dry and indoor ski slopes, climbing walls, activity centres, outdoor play at the best local parks, ten pin bowling alleys and all the other best family tourist attractions, that you can visit at the weekend.\nAlso teachers may find the site useful for ideas for the best places to take their classes on school journeys with many historical and educational atractions listed\nSo, if you've been for great days out with the kids, or a school trip, which isn't shown above, just send in an email and we'll add it on so people visiting on holidays and all the other children in Wiltshire can enjoy the great day out as well.\nSwimming Pools in Calne\nZoos near Calne\nTheme Parks near Calne\nIndoor play areas in Calne\nMuseums in Calne\nThings to do in Calne\nHistorical and Educational Attractions in Wiltshire\nHistorical and Educational Attractions in Salisbury\n| Swindon Historical Sites\nHistorical Sites in Dorset\nFamily things to do in Wiltshire\nPlaces to visit in London\nThings to do in Salisbury\nThings to do in Swindon\nEducational Attractions near Warminster\nHistorical Sites in Devizes\nEducational Attractions near Trowbridge""]"	['<urn:uuid:36e3f378-c1ac-4779-99c7-0de7b19a4aec>']	open-ended	direct	verbose-and-natural	distant-from-document	single-doc	novice	2025-05-01T23:46:40.222380	19	38	2103
396	environmental social implications waterway transport systems urban areas	The development of waterway transport systems in urban areas has both environmental and social implications. On the environmental side, waterway transport leads to cleaner environments by reducing CO2 emissions to 50% compared to trucks and has minimal land requirements. However, it can cause environmental damage through dredging operations that affect river beds, aquifers, and aquatic flora and fauna. In estuaries, dredging can cause excess saline water ingress. On the social side, waterway development like the Brussels project can benefit the broader urban population through improved city distribution activities and reduced truck traffic. However, it can also lead to displacement as land is needed for facilities like ports and jetties, and can impact livelihoods of communities dependent on rivers, such as fishing communities and people involved in riverbed cultivation.	['Originally, the Port of Brussels wanted to demonstrate that port activities and urban activities could be combined, by building a multi-purpose platform combining people and freight. Prior to the investment, a feasibility study was carried out to determine the type of freight to be transhipped. The study concluded that, without changes in the current conditions (with businesses currently located near the terminal, with the current legislation regarding truck traffic, etc.), the last mile delivery made it not cost-effective to develop a freight terminal at this location. Therefore, the idea of a multi-purpose terminal was forgotten, and only a passenger terminal is being built.\nAlthough it led to a no-go decision, this first project of the Port shows how complex it is to implement a multimodal approach in transport. Many factors have to be taken into account, among which cost-effectiveness, as first parameter. Obviously, the distance of the last mile delivery plays an important role in this regard but it is interesting to note that public authorities can also influence private actors, by taking adequate measure to promote multimodality. If for instance a municipality decides to raise taxes on trucks entering the city or bans trucks in certain areas or at certain times of the day, not only will these measures lead to cleaner and safer environment in the city, but they will also encourage the use of alternative transport and delivery modes, like inland waterway transport.\nAs new project, the Port of Brussels now aims at creating a network of transhipment platforms along the waterway, for city distribution activities. Two larger platforms (hubs, in red on the map) will be created in the centre and in the south, and they will be connected with smaller transhipment platforms (spots, in green on the map). This network will ensure that the last mile is kept as short as possible, so that smaller and cleaner vehicles can be used for the final delivery. This project is built around an innovative concept of freight catamaran, which can convey up to 300 tons of goods in various formats (big bags, pallets, containers, roll-tainers, tri-cycles etc). Anything that is not dry or liquid bulk can potentially be transported on these catamarans and unloaded with the onboard crane that can tranship up to 2 tons within a 12 meter reach. For the city of Brussels to be supplied by these catamarans in a cost-effective way, the Port of Brussels will develop a network of platforms, which is in line with the current plans of the Region of Brussels Capital regarding the transport of goods and mobility.\nThe Port of Brussels will carry out studies on the optimisation of hubs (circulation plan, fences, covered storage area, actual building, security issues, connecting of the central hub with an existing warehouse on the other side of the street) and the location of the small platforms (based on an analysis of existing flows and in cooperation with the public institution in charge of mobility in Brussels). Afterwards, infrastructure works will take place and the platforms (hubs and spots) will be developed.\nThe new project will lead to a more efficient city distribution in Brussels. City distribution activities already take place within the Port of Brussels, but mainly through road traffic. The network of platforms and the use of freight-catamarans will enable the Port to widen its array of services, and in a more sustainable way. The avoided truck movements will be noticed by the public when they will see how goods can be transhipped from the waterway straight onto the street. The investment contributes to increase awareness and acceptability in several ways. Not only will the Port be active in the very centre of Brussels where it currently does not have activities, and therefore be more visible, but it will also carry out city distribution activities that, unlike other activities on the Port’s concessions, will benefit to the greater population of the city, and not only to a specific group of users or clients.\nThe investment also has links the project implemented in Paris (i.e. the multi-purpose use of the land). Indeed, though the hubs will be dedicated platforms for the transhipment of goods, the smaller platforms between the hubs are intended as temporary transhipment spots, that will share the space with other urban functions (sidewalks, parks, parking places), on a time-sharing basis for instance.\nThis project intends to demonstrate that port development is feasible even in contexts where space is lacking. The crane on board of the catamaran makes it possible to minimize the space and the infrastructure on shore. This new development could be duplicated in almost any inland port.', 'Context:In a first, the Inland Waterways Authority of India (IWAI) will transport container cargo belonging PepsiCo (India) from Kolkata to Varanasi on river Ganga (National Waterway-1).\nWhat are inland waterways?\nRivers, lakes, canals, backwaters and reservoirs primarily constitute the source for inland waterways. A stretch of water, not part of the sea, over which craft of a carrying capacity not less than 50 tonnes can navigate when normally loaded is called navigable inland waterway.\nInland Waterways in India:\nNumber and Extent: (National Inland Waterways in India- A Strategic Status Report, 2017)\n- As per the National Waterways Act, 2016, 111 have been declared as National Waterways (NW)\n- These waterways pass through 24 states and two union territories, with an approximate total length of 20274 km\n- These proposed waterways will pass through nearly 138 river systems, creeks, estuaries and related canal systems of India.\nCurrently Operational:According to a PIB release by Ministry of Shipping dated 20th July 2018,the following NWs are operational:\nNote:The first waterway to be declared National was the Allahabad to Haldia stretch of the Ganga – Bhagirathi-Hoogly.\n|Protocol on Inland Water Transit and Trade (PIWTT)|\nIn 1972, India and Bangladesh signed the Protocol on Inland Water Transit and Trade (PIWTT).It is an agreement between the two governments for the transportation of goods and keeping their respective waterways navigable, while providing infrastructure facilities.\nCargo Handled:The total cargo moved on the three national waterways, NW 1, NW 2 and NW 3 in the year 2013-14 was about 6.89 million tons. (National Inland Waterways in India- A Strategic Status Report, 2017)\n- Inland water transport in India has only 0.5% modal share; China 8.7%; USA 8.3% and Europe 7% (Source: JalMargVikasProject -Frequently Asked Questions and Their Answers, Inland Waterways Authority 0f India)\n- inland water transport (IWT) accounts for less than 1% of its freight traffic, compared with 35% in Bangladesh and 20% in Germany. (Source: Hindu Buisnessline, 29th March 2018)\nAdvantages of Inland Waterways:\n- Cost savings:\n- Fuel and Energy Efficient: It is fuel-efficient compared to the other modes of transport, rail and road. For example, the Integrated National Waterways Transportation Grid Study states that one litre of fuel will move 24 tons through one kilometre on road, 85 on rail and 105 km on inland water transport. Further, 1 HP can 150 kg on road, 500 kg on rail and 4000 kg on water.\n- Cost of developing waterways is much lower than rail & road.\n- Reduces transportation and transition losses\n- Environment Friendly:\n- Least fuel consumption per tonne‐km\n- Carbon dioxide emission is 50% of trucks\n- Negligible land requirement as compared to rail and road transport\n- Supplementary Mode:\n- Reduces pressure on road and rail\n- Reduces congestion and accidents on road\n- Optimal Modal Mix: It will provide optimal modal mix by converging river transport with other modes\n- Better connectivity: It help create seamless interconnectivity connecting hinterlands along navigable river coasts and coastal routes. Further, riverine routes are likely to play a crucial role in connecting the north-eastern states to the mainland\n- Inland Waterways hold huge potential for domestic cargo transport, cruise, tourism and passenger traffic.\n- Development of inland waterways will help in the generation of job opportunities\nDisadvantages of Inland waterways:\n- Inland waterways have low transport speed thus not suitable where time is an important factor\n- It has limited area of operation, depending on the infrastructural premises and depth of the waterways\n- There are only very few casesin which Inland water transport (IWT) can offer door-to-door transport of cargo\n- Operational disruptionsdue to weather is a major disadvantage\nLegal and Policy regime for Inland Waterways in India\n1.The Inland Waterways Authority of India Act, 1985:\n- The Act provides for the constitution of an Authority for the regulation and development of inland waterways for purposes of shipping and navigation and for matters related to it\n- The Inland Waterways Authority of India was formed in 1986. It undertakes projects for development and maintenance of IWT infrastructure on national waterways through grant received from Ministry of Shipping\n2. Indian Vessels Act of 1917 (amended in 2007): It deals with the survey and registration of inland vessels, removal of obstructions in navigation, carriage of goods and passengers, prevention and control of pollution etc.\n3. Inland Water Transport Policy 2001: Policy talks about IWT being economic, fuel-efficient and environment friendly mode of transport. It advocates large-scale private sector participation both for creation of infrastructure and for fleet operations.\n4. National Waterways Act 2016\n- The Act declared 111 rivers or river stretches, creeks, estuaries as National (inland) Waterways.\n- It enables the Central Government to regulate these waterways for development with regard to shipping, navigation and transport through mechanically propelled vessels.\n5.Laws related to environmental and other impacts:\n- Forest Act 1980,\n- Environmental Protection Act 1986 and various notifications under it like EIA Notification 2006, CRZ Notification 2011\n- Jal Marg Vikas Project: Jal Marg Vikas Project (JMVP) aims at capacity augmentation of navigation on National Waterway-1 (NW-1).The project is being implemented by GOI with technical assistance and investment support of the World Bank.\n- Sagarmala Project: Along with development of coast shipping routes, the project seeks to inland waterways to drive industrial development. It aims to reduce the logistics costs by doubling the share of domestic waterways in the modal mix from current 6 per cent (PIB)\n- Interlinking of Rivers Programme: The project is expected to offer potential benefits to the transport sector through navigation.\nIssues and Challenges\n- Cost estimation: In respect to operating costs per ton-km, IWT has lower cost than rail and road transport. However, this cost argument is challengeable. There are two factors which distinguishes how freight moves on land versus on water:\ni) A road travels straight while rivers bend and curve; therefore the difference between freight costs for IWT and road/ railways is not much\nii) Cost of loading and unloading freight\n2. Inadequate depth: To be viable for a navigable inland waterway, river needs enough depth throughout the year However, in their natural state; many Indian rivers simply do not have that level of water which will necessitate extensive dredging. Moreover, Indian rivers (especially rivers in the northern plains) face severe problems of siltation round the year\n3. Impact on other activities: Water in rivers has competing demands, including dams and farming. To maintain the water levels in the river to the degree needed for them to function as inland waterways, the water use for such other activities might get curbed.\n4. Inadequate Air Draft: Multiple bridges with low vertical clearance obstruct the passage of bigger inland water transport vessels on many inland waterways such as NW 3\n5. Lack of night navigation infrastructure: Rudimentary night navigational facilities and markings are also a major issue.\n6. Shortage of IWT vessels: Vessel building is highly capital intensive and faces difficulties in obtaining project finance from banks and financial institutions.\n7. Shortage of MRO facilities: There is severe shortage of MRO (Maintenance, Repair and Overhaul) facilities for IWT vessels.\n8. Inadequate industries: Inadequate number of Industrial units on the riverside, especially not along the Brahmaputra is a major discouragement hindering development of inland waterways. At National Policy Dialogue on transboundary cooperation related to the Ganga and the Brahmaputra rivers – states, it was highlighted that due to inadequate industrial units result in no cargo commitments by the private players\n9. Lack of funds: Dredging as well as infrastructure for IWT requires huge investments. However, both public and private funding in the sector is low\n10. Environmental Impact:\n- Dredging operations will damage river bed, and can lead to change in habitats for various aquatic flora and fauna.\n- Dredging may also impact aquifers along the river, damaging the ability of water to percolate underground.\n- In estuaries and creeks of rivers the removal of river bed material during capital dredging can result in the ingress of excess saline water into the creek or rivers. This is one of the reasons why the state of Kerala had opposed many of its proposed waterways\n- Construction of jetties, river ports will necessitate removal of trees/ mangrove forests in the area. For example, At Dharamtar port in NW10, for construction of a jetty, the mangrove forest belt on the bank has been removed\n- Other environmental concerns include pollution due to oil and diesel from vessels, leakage and spilling of cargo\nNote: Dredging is an excavation or digging activity carried out underwater that removes rock, mud, silt, sediments etc. from the bottom of the river bed or other water bodies. Dredging is used to dig and create a channel in the river bed of the required depth.\n- Ecological impacts can have implications for livelihoods of people dependent on the rivers and creeks. For example: impact on fishing community, people dependent on riverbed cultivation\n- Displacement is another major concern as land is needed for number of facilities like ports, jetties, and other infrastructure.\nNITI Aayog Recommendations (Action Agenda, Three-Year2017-2020)\n1.Streamline the governance of inland waterways: NITI Aayog recommends streamlining the regulatory structure and bringing an overarching body to oversee Inland Water Transport such as the IWAI to more consistency in the rules and strategy of the sector.\n2.Develop measures for year-round navigation:\n- Efforts should be made to develop deeper stretches of the river, i.e., at least 2.5 m to 3 m to achieve year-around navigation\n- adequate maintenance of rivers, including continuous dredging to maintain adequate water depth for servicing shipping lines should be ensured\n3.Ease restrictions on river-sea movement: Utilizing a single vessel for both inland and coastal waters, lowers transport costs and minimizes handling. Thus, by 2020, state authorities should draw up coordinates for inland vessel limits under the Inland Vessel Act for their coastal waters\n4.Develop inland waterways transport to facilitate movement of goods to neighbouring countries and the Northeast:\n- By 2018, state governments should commence work on dredging and channel stabilization to create about 20 new ports in the Brahmaputra and Barak rivers.\n- The protocol for Inland Waterways between Bangladesh and India should be extended for at least 10 years to reduce uncertainty.\nInternational Best Practice\nChina has an inland waterway system of more than 5600 navigable rivers and 2000 inland ports. IWT development is concentrated on 5 specific areas (Yangtze river, Pearl River, Beijing-Hangzhou Grand Canal, Yangtze River Delta and the Pearl River Delta). China with the aid of World Bank has taken major initiatives to boost IWT:\n- Development of power generating dams, by-passing ship locking systems, and a deeper waterway throughout the system permitting large vessels to undertake trade.\n- Three Gorges project: It aims at improving electric power and navigation safety and reduce transportation costs; and development along the Hang-Yong Canal, connecting a network of six rivers to Yangtze River\n- Strengthening public-private partnership has the key role to play in developing the inland waterways sector. Private players can undertake terminal development, cargo and passenger handling, and building low-draft vessels and related repair facilities.\n2.Measures should be taken to develop basic infrastructure, address technological bottlenecks and maintenance of rivers to ensure year-round navigability\n- Measures should be taken to taken to ensure availability of seamless, multimodal last-mile connectivity to and from hinterland to reduce trans-shipment cost and make inland water transport economically more viable\n- Cargo transport through inland waterways should be incentivised. Following measures can be taken:\n- The Government can mandate/incentivise industries in the proximity of national waterways to use this mode for a portion of their shipments.\n- the government can promote industrial corridors along riverbanks and foster waterways-based industrialisation.\n- Higher road taxes can be levied on transportation of coal and inflammable material over longer distances\n5.The government should develop passenger terminal development, offer financial support to ferry operators to improve safety, and facilitate insurance coverage to boost passenger transport\n- Measures should be taken to promote river tourism in states like Assam and Kerala\n- Keeping in mind the concerns, it is important to assess the environmental and social impact of development of inland waterways and associated infrastructure to negate potential damage.']	['<urn:uuid:cb3c479b-4c3e-489a-939f-b181ab42781f>', '<urn:uuid:48f904f4-0dc5-4d1b-a82e-ff0b69668a1b>']	open-ended	direct	long-search-query	distant-from-document	multi-aspect	expert	2025-05-01T23:46:40.222380	8	128	2799
397	What are the specific benefits that a developer gains from setting up an upstream branch in their daily coding workflow, and how does this relate to the fundamental concepts of version control?	Setting up upstream branches provides several key benefits for developers: it allows setting a default remote branch for the current local branch, simplifies pushing and pulling from remote branches without specifying names, and enables easy comparison between local and remote branches to see commits ahead/behind and facilitate merging. These benefits tie into the fundamental concept of version control as a system that tracks file history and progression, allowing developers to annotate changes through commits and maintain an easily navigable system history.	"['In this post, I will show you how to set up and use an upstream branch in Git. When it comes to Version Control System, Git is considered to be the leading and most used distributed version control system globally when compared to other version control systems such GitLab, BitBucket, Azure DevOps Repos, Apache Subversion, PerForce, Beanstalk, AWS CodeCommit and Microsoft Team Foundation Server. A version control system enables users to keep track of changes in software projects and collaborate on them. It allows developers to collaborate on code while also separating their tasks via branches. There can be several branches in a version control system, according to the number of collaborators. Because the code changes remain in a specific branch, the branches retain their copies. When necessary, developers can combine the code changes. They can also view the history of changes, go back to previous version(s), and use/manage code as desired. GitHub allows software teams to collaborate while also keeping track of all code changes. You can track code changes, go back in time to undo mistakes, and collaborate with other team members. It serves as a repository for Git projects.\nYou might like to ask, what is Git? It is an open source version control system that features local branching, multiple workflows, and convenient staging areas. Git version control allows for faster operation. To learn more about Git and GitHub, please review the following related posts: Git command not found: How to fix Git is not recognized as an internal or external command, Git Vulnerability: Git for Windows uninstaller is vulnerable to DLL hijacking when run under the SYSTEM user account, Install Git on Windows: The term “git” was not used as the name of a cmdlet, function, script file, or executable Program recognized, How to Setup HTTPS users using Git credentials and Pushing Code to AWS CodeCommit and Git config –global init.defaultBranch: Error cannot lock ref ‘refs/remotes/origin/windows’, not a directory\nGIT Vs GitHub\nMany people sometimes misinterpreted Git and GitHub to means the same thing. In actual sense, they mean different things. To put it simply, Git is a version control system that allows you to manage and track the history of your source code. On the other hand, GitHub is a cloud-based hosting service that lets you manage Git repositories. If you have open-source projects that use Git, GitHub is the right hosting platform to manage them with you them.\nUnderstanding an Upstream Branch\nWhenever you want to clone a new repository or work with different feature branches, you must first understand how to work with upstream branches and how to set them up. Upstream branches are closely associated with remote branches. Upstream branches define the branch that your local remote branch is tracking on the remote repository – also known as the remote tracking branch.\nSetting Up An Upstream Branch\nWhen creating a new branch or working with existing branches, knowing how to set upstream branches on Git can be very helpful.\nThere are various methods of setting up Upstream branches in Git. They methods are:\nMethod 1- Using the git push command\nThe simplest method is to use the\n""git push"" command with the “-u” option for upstream branch. We are going to do this by creating a local folder and initialize it for git using the Git Bash Terminal. To install Git Bash terminal click here.\nFirst, create a folder on your Desktop or any other location within your system preferable to you. Here, I have created one called\ngit-upstream-branch and it’s currently empty.\nTo be able to use the folder to set up an upstream branch in Git, we need to run the\ngit init command to initialize the empty folder and make it git ready. Open your git bash terminal and navigate to the empty folder created you before and run:\nAs you can see from the screenshot above, we’re directly on the master branch.\nNow add a file. It can be any txt file e.g. file1.txt to the folder. To create a file type:\nadd, commit and\npush the file to your remote GitHub repository. Review this post to learn how to create your first remote repository on GitHub. I have created my remote repo already as shown in the screenshot below:\nNow to set upstream branches, run any of the command below:\n$git push -u <remote> <branch> OR $git push --set-upstream <remote> <branch>\nLet’s create a branch called\nupstreamb with the command\ngit branch <branchname> or\ngit checkout -b <branchname>. After creating the branch, run the below command to switch to it:\n$git switch <branchname>\ngit branch command with the\n-vv flag allows you to inspect tracking branches.\nAs you can clearly see, the branch\nupstreamb has no tracking branches compared to master and no upstream branches as well.\nNow we can setup the upstream branch using the “git push” command for the new branch\nTo so, I created a file called\nfile3.txt added and committed it and then run either of the commands below:\n$git push -u <remote> <branch> OR $git push --set-upstream <remote> <branch>\nLet’s have a look at the tracking branches again with the branch command,\n""git branch -vv"".\nNow you have successfully set the upstream branch for your newly created branch and git is tracking it.\nMethod 2 – Set upstream branch using an alias\nAnother option for configuring the upstream branch is to create an alias for your “git push” command. Note, pushing to HEAD is actually the same as pushing to a remote branch with the same name as your current branch. To setup upstream branch using alias, run:\n$git config --global alias.pushd ""push -u origin HEAD""\nWhen you’re finished adding and committing files to your repository, use your newly defined alias to set the upstream branch using the command below:\nAs you can the upstream branch has been set to\n""HEAD -> upstreamb""\nMethod 3 – Set up Upstream Branch using a bash alias\nIf you don’t want to change your existing git commands, you can use a bash alias. To do this, create a new bash alias with the\n""alias"" command and give it a name, run:\n$alias gp=\'git push -u origin HEAD\'\nCreate a new branch and use our alias to easily push our code and create the upstream branch with the command below:\n$git checkout -b <branchname>\nMethod 4 – Set upstream branch for an existing remote branch\nIn some cases, you may want to connect your local branches to remote branches that you have just pulled or cloned from the main repository. Assuming you pulled a branch named the\n""prod"" branch from the\n""origin"" remote. As a result, the tracking branch is known as\nSet new local branches as tracking branches\n""-track"" option to switch to the local\n""prod” branch and set the\n""origin/prod"" as the tracking branch or upstream branch by typing the command below:\n$ git checkout --track origin/prod Branch \'prod\' set up to track remote branch \'prod\' from \'origin\'. Switched to a new branch \'prod\'\n""git branch"" command to confirm that you linked\n\'prod\' to the tracking branch\n""origin/prod"" which upstream branch is the remote prod.\n$git branch -vv\nSet existing local branches as tracking branches\nYou may, on the other hand, have chosen to work on a local branch while creating the upstream branch (or the remote tracking branch later on). Consider a scenario where you have created a\n""feature"" branch to work with.\nLet’s assume you made some commits in your branch and want to make the tracking branch master by running the command below:\n$ git branch -u origin/master\nYou can see from the screenshot the\n\'feature\' branch have set up to track\nWhy are upstream branches important in Git?\nSetting Upstream branches are important for the following reasons:\n- It allows you to set the default remote branch for your current local branch.\n- Upstream branches are extremely useful for collaboration. They simplify pushing and pulling from remote branches by allowing us to use the Git Push and Git Pull commands without specifying the remote or branch name.\n- Another significant benefit of establishing Upstream Branches is that we can easily compare our local branch to the remote branch. Git displays information such as the number of commits ahead or behind the remote branch and makes it easy for us to merge them together as shown in the images below:\nCongratulations! You’ve learnt how to set up and use upstream branches in Git.', ""This blog post aims to explain the “theory” behind version control (Git and Github) in plain English so that you understand the big picture of how software engineers work. No code. Nothing to download. No muss. No fuss. Just words and some not-so-pretty doodles drawn by yours truly.\nI’ve always been amazed at the sheer amount of tutorials there are to learn anything online. Git and Github are no different, there are plenty of great resources to get you started with either or both. Here are some of my favourites:\nHowever, I’ve always found that these tutorials skip a lot of the theory and go straight into explaining how to use Git from the command line or via the Github desktop app. Frankly, if all you want is to understand what the hell the developers on your team are talking about, these tutorials go way more in-depth than needed. As stated above, my goal is simply to explain the big picture of version control and hopefully impart upon you how very cool it is.\nLet’s start at the very beginning: Version Control\nImage credit: weebletheringskite, Wordpress\nVersion control: learn it, love it, live it. Does pretty much what it says on the tin. Version Control is any system that allows you to understand the history of a file and how it has progressed. Back in my former life as a graphic designer I often had files that looked something like this:\nLook familiar? The above system may not have been a good one, but it was definitely some sort of version control system. More sophisticated examples would be something like the Google Docs’ “Revision History” or Photoshop’s “History” tool.\nGit is a version control system specifically designed to work well with text files. Because ultimately, that’s all code really is: loads of texts files hooked up together in some fashion. Git is a program you install which allows you to annotate the changes you make to create an easily navigable system history.\n(PS: “Git” is also what happens when you let engineers name products, we’re sorry marketing department)\nSo what does Git do that simply saving a file normally doesn’t? At its very core, saving a file is a simplified version control system, but frankly it’s not a very good one because it only allows you to move forward in time. Sure, you could argue that the “undo” button lets you move backwards in the “life” of the file, but we all know the “undo” button has certain limitations, the most obvious being that the file’s past is usually lost the minute you close the file.\nPlus, saving a file is very individualistic. It says nothing of the history of the system at large, only the history of that file. While at this point you may be thinking, “Well I’m not an engineer so I don’t need to be fussed about systems”, I’d like to take a moment to explain how a lot of things that you may not think of as “systems” are in fact exactly that.\nMeet Sally, she’s an author writing the next big adventure fantasy book series. Sally has written the first book already, and has passed it on to her editor. Additionally, because she’s such an overachiever, she has also written the first three chapters of the second book whilst waiting for her editor’s feedback. Each book is stored in a separate Word file.\nOne merry day, Sally’s editor actually gets back to her about the first book. He’s worried that younger readers won’t want to read a series exclusively about Orcs, and asks her to introduce some Elves into the story. At this point, Sally sighs but soon realises that her new Elven characters will allow her to include some previously unplanned conflict and plot twists. She then does the following:\n- Writes in new characters and plot changes into the first book\n- Off the back of that, makes the necessary modifications to the second book\n- Realises that due to all the changes, she’ll need to introduce a certain location in the first book instead of the second\n- Re-edits the first book to include the new location\nFinally, she pushes her keyboard away, confident that she has properly incorporated the Elves into her magical world.\nYou see, Sally is actually dealing with a system. Her two books influence each other. Characters, locations, and plot points flow between the two. However, sadly, a month from now, there is nothing in her file system, Word’s “Document History” tool, or the post-its she has stuck around the edges of her screen that will tie all these changes together.\nThis is where Git shines. If Sally had been using Word combined with Git, she could’ve associated all those changes into one nice neat little summary of “Introduction of Elves into the series”. She could’ve seen the changes made across pages, chapters, files, and books, allowing her to truly understand the impact of the Elves on her fantasy series. This “neat little summary” is what we, in Git-land, refer to as a commit.\nRecap. Git is a program that allows you to annotate the history of a system (or group) of files via commits, which are “snapshots” of the differences made to the system at a given point in time.\nSo if I’m Sally, my commit history might looks something like this:\nSo far so good, but what happens if Sally has two computers? Good point. Enter Github. Not to be confused with merely Git, Github takes that lovely commit history and hosts it online so that you can access it from any computer. You do this via pushing commits from your local machine (i.e.: the computer you’re currently using) up to Github, and then, from the new/different computer pulling those commits down.\nLet’s take the image above as an example workflow for Sally. She starts her day working on her home desktop computer (on the left, orange) and writes a few chapters, does some editing, etc. Along the way she takes three “snapshots” (Git commits) of her work at strategic points.\nIn the afternoon, Sally often likes to take her laptop (on the right in the image above, blue) to a café and write there. Today is no different, so before she shuts down her home desktop computer, she makes sure to push her current Git commit history up online to Github. Once on Github, the commits live in a remote repository.\nLet’s break down the geek-speak here: remote merely means online (vs local, which as we learned earlier means whichever computer you’re currently using). As for repository (often shorted to “repo”), it’s basically a folder with Git superpowers.\nSo, Github lets you store your work (which is annotated by Git commits) in a special online folder (repo). See? Simple.\nIt’s after lunch now and Sally pulls out her laptop at her local café. She obviously wants to pick up where she left off at home, so she grabs her latest work from her Github repository. This process of “grabbing her work from Github” is called pulling. Looking at the image above again, you’ll see the Sally pulled down the three commits she wrote at home.\nSally now has a perfectly up-to-date copy of her whole system (the text files containing her fantasy series) on her laptop and can proceed from where she left off. She writes some more and strategically “snapshots” (commits) her work two more times. Finally, Sally ends her day by pushing up those two commits to Github, so that she can access her latest work from her home desktop in the morning.\nOK, this all makes sense. But Sally, cool as she is, is only one person. How do engineering teams make sure their work doesn’t overlap?\nIn short, by making branches. Think of your Git commit history as a tree. The trunk is what we refer to as the master branch. In order for teams to avoid stepping on each other’s toes, they need to work in isolation from everyone else (on a feature branch), whilst ultimately still contributing back to the main codebase (the master branch).\nNow, back to Sally. She’s joined a Fantasy Writers’ Guild, where everyone is collaborating to write a single book, “The Fantastic Dictionary of Fantasy Creatures”. Much like a textbook, the Dictionary will have multiple authors: her, Tom and Adam.\nLet’s have a look at the online Github repo for “The Fantastic Dictionary of Fantasy Creatures”, as it stands now:\nAs you can see above, the tree analogy applies perfectly to how the Fantasy Writers’ Guild is collaborating on this project, with the history of the repo moving upwards along the master trunk. The general workflow starts with each author branching off master when they’re doing a piece of work (maybe writing a chapter, or editing one). When the rest of the co-authors have approved the changes, the branch gets merged into the master trunk (keep in mind, it’s the contents of the master branch which will ultimately form the published book).\nWhen a branch gets merged that means that its content overrides the master. So any changes it makes to existing content will supersede what was there before. And any new content will be added in too, of course. In essence, when a branch gets merged into master, its commits get added to the top of the master history.\nHowever, you may be thinking, how does this tie in with the fact that people do their work locally and only then push their changes up to Github?\nAt this point, it’s important to remember that your remote repository on Github is a mirror of what you have locally. This means that on your computer you have a local Git repository for that project (i.e.: a folder configured to allow Git commits). Inside this local Git repo (again, a fancy term for a specific Git-enabled folder on your computer), you have all the files that are part of this project, in this case, “The Fantastic Dictionary of Fantasy Creatures”.\nIt works almost like Dropbox does: you have local folders, on different devices (your home computer, your office computer, etc) where you do your work and update your files. This ultimately syncs up to a location online. However, as we know, there are a couple of extra steps involved in the Git/Github workflow. You have to consciously decide to take a “snapshot” of your work as it stands at that moment in time (a commit) and furthermore, you have to deliberately choose to push that commit up to Github. Only then is the work “synced” to the online location (the Github repo).\nSo why not automate it? Why not make it like Dropbox and have the file update on Github as you update it locally? Well, many reasons. But mainly, because of bugs. In the world of software engineering, as in the world of publishing, you don’t always want to keep everything you write. Sometimes you want to experiment, and should your experiment fail, you want an easy way to go back to the last correctly working state. Which is why a good rule of thumb is that the minute something is working the way you want it to, commit it, before you try to edit it or experiment with a different approach. There’s no harm in committing small chunks of work very frequently, and in fact, many engineers pride themselves on that doing exactly that.\nNow back to “The Fantastic Dictionary of Fantasy Creatures”. Due to her in-depth knowledge on Orcs, Sally has been chosen to write that particular chapter. But because she doesn’t want to modify the book without her co-authors’ approval, she creates a local branch and starts writing and committing on that branch. She then pushes the local branch up to Github, where, true to form, the remote repo acts as a mirror and updates to show that Sally has created a branch containing certain commits in it (see image below).\nAs she continues working on the chapter, Sally writes more commits and pushes them up to the online mirror branch on Github. Eventually, she’s ready for Tom and Adam to review her work. So she creates a Pull Request, which is a Github feature that allows her to explain the changes that her branch makes to the master branch. It also provides an easy place where the co-authors can have a discussion about the branch’s content and request that Sally make any changes necessary before the branch becomes part of the master trunk.\nAfter requesting a few changes, as can be seen above, Tom and Adam are happy with Sally’s branch and decide to merge her work into the master branch on Github. The moment they do this, Sally’s formerly isolated commits, are added to the top of the master branch’s history:\nAt this point, Sally can move to (or “check out”) the master branch on her local machine and pull down the very commits that were previously isolated in a feature branch (the Orc Chapter branch). She’s now back at square one, with an updated master, and from here can proceed to create a new local branch for her next piece of work, helping poor Tom edit his chapter on Goblins. And so, the process would start all over again:\n- Create local branch\n- Write some commits within local branch\n- Push to Github\n- Create Pull Request explaining changes that branch contains\n- Merge to master\n- Pull down new master commits locally\nAs you can see, this is a very smooth workflow, the perfect combination of working in isolation as well as collaboratively. Git — on your local machine — provides a brilliant way to create multiple versions of your work, via a rich annotated history, controlled and curated by you. Github — online — is a fantastic resource for not only storing and providing a clear visualisation of said history but also for collaborating and quality-control.\nIn conclusion, I hope I’ve convinced you to try using Git and Github for any type of project in future. There's no reason why only engineers should benefit from such great tools. The world totally needs more Orcs, after all.\nI’d like to thank the Common Craft for inspiring the doodles and explanation style of this blog post. And also, for saving me from the horror of having to explain Twitter to my mum.\nVersion Control: any system that allows you to understand the history of the file and how it has progressed\nGit: a version control program which allows you to annotate the changes you make to create an easily traversable system history\nCommit: an annotated “snapshot” of the differences made to the system at a given point in time\nLocal: refers to the computer you’re working on this very minute\nRemote: refers to an online location\nRepository (repo): a special folder configured with Git superpowers containing all the files pertaining to your project/system\nGithub: takes your local commit history and hosts it remotely so that you can access it from any computer\nPushing: the action of taking local Git commits (and whatever work these encompass) and putting them online on Github\nPulling: the action of taking online Github commits and bringing them into your local machine\nMaster (branch): the “trunk” of the commit history “tree”; contains all approved content/code\nFeature branch: an isolated location, based off of master, where you can write a new piece of work safely before reincorporating said changes back to master\nPull Request: a Github tool that allows users to easily see the changes (the difference or “diff”) that a feature branch is proposing as well as discuss any tweaks that said branch might require before it is merged into master\nMerging: the action of taking the commits from a feature branch and adding them to the top of master’s history\nChecking out: the action of moving from one branch to another""]"	['<urn:uuid:06c12da4-be01-4f4c-9afd-f81e79b8351c>', '<urn:uuid:cb545a93-b517-4cef-a592-8a1e0b510d77>']	factoid	direct	verbose-and-natural	distant-from-document	three-doc	expert	2025-05-01T23:46:40.222380	32	81	4071
402	How much more expensive are investment fees in other countries compared to the United States for regular mutual funds?	According to a study in the Review of Financial Studies, mutual fund fees in other developed markets were significantly higher than in the U.S. Specifically, expenses for mutual funds were 43% higher in Switzerland, 50% higher in the UK, and 279% higher in Canada compared to the United States.	['American Expat Financial Problem: Should Americans abroad keep their cash and investments in the U.S., country of residence or off-shore?\nAmericans abroad often end up investing through financial institutions in their place of residence or in popular financial centers such as London, Switzerland or Hong Kong. This is especially true when living abroad becomes a permanent or semi-permanent situation. However, when a full accounting is made of all factors that need to be considered, investing through non-U.S. financial institutions is almost always a costly mistake for Americans. Why?\n1) Fees: Whether one chooses to go with a large reputable investment bank headquartered in Switzerland or venture into the world of “off-shore” banking, a large part of an investor’s potential gain will be consumed by the very high fees charged by non-U.S. financial institutions. These fees are high everywhere in the world, but they are still much lower in the U.S. than anywhere else. A recent study in the Review of Financial Studies of mutual fund fees by country found that among 18 developed European, American and Asian markets, fees in the U.S. were by far the lowest. For example, average expenses for mutual funds sold in Switzerland, the UK and Canada were 43%, 50% and 279% higher, respectively, than in the U.S. The numbers are especially striking for money market funds, where returns are very low to begin with: Swiss money market fund expenses average 1.14% while in the U.S. the average was 45% less.1 If an investor goes further afield into the world of “offshore” investing (in places such as Lichtenstein, Cyprus and the Cayman Islands) fees, commissions and transaction cost will be even higher than already costly European investments.\n2) Investment access and liquidity: U.S. financial markets provide greater global investment access and liquidity than any other market in the world. There is virtually no investment anywhere in the world that cannot be bought easily and inexpensively on U.S. markets. For example, almost every publically traded company in the world lists its shares for trade on U.S. exchanges as well as in their home country. The vast and competitive U.S. fund industry makes virtually every global asset class open to investment through U.S. accounts, efficiently and at relatively low cost. Liquidity for investments such as ETFs (Exchange Traded Funds), global stocks, bonds and commodities is higher in the U.S. than other global financial centers. High liquidity reduces transaction costs and raises long-term rates of return on investments.\n3) Taxes: Taxes are the next big reason that Americans should stay away from non-U.S. registered investments. Long-term investors in U.S. securities benefit from a low capital gains tax rate (15-20%). Additionally, taxes are paid on a deferred basis (only when the investment is sold). For U.S. taxable investors, neither of these significant tax advantages apply to investments in mutual funds, hedge funds or other kinds of pooled investments not incorporated in the U.S. Rather, such non- U.S. securities are classified by the IRS as Passive Foreign Investment Companies (PFIC) and are subject to a special, highly punitive tax regime (see box, p. 6). PFIC rules can easily push tax rates on investment income to as high as 60-70%. Furthermore, the new FATCA legislation (see box, p. 9) dramatically increases the ability of the IRS to enforce compliance with these rules and ratchets up penalties for non-compliance.\n4) Reporting: The complexity of the U.S. tax code makes year-end accounting statements provided by U.S. brokerages invaluable. U.S. brokerage firms like Schwab and Fidelity supply their clients with detailed banking activity reports in the required IRS format segregating dividends, qualified dividends, taxable and non-taxable interest income, and short and long-term capital gains, to name only the most important categories, each of which requires distinct tax treatment. Non-U.S. institutions generally do not provide this kind of detailed reporting.\n5) Compliance: If cumulative assets held by an American citizen at financial institutions outside the U.S. at any time exceed $10,000 they must be reported to the U.S. Treasury for that year. In addition, financial assets held at non-U.S. financial institutions exceeding $50,000 ($300,000 for U.S. taxpayers not resident in the U.S.) must now be on annual U.S. tax returns as a result of FATCA. Both the taxpayer and the non-U.S. financial institution must report on assets held by U.S. citizens. Filing the required documentation may increase the likelihood of an IRS audit. Penalties for not filing are severe and IRS resources being directed at enforcement have increased significantly in recent years. (See the corresponding boxes on PFIC (p.6) and FATCA (p.9)).\n6) Safety: Regulatory standards in global banking centers range from very high (Switzerland) to almost non-existent in some of the more exotic off-shore banking locales. FDIC deposit and SIPC investment insurance automatically cover all U.S. accounts, but are unavailable for non-U.S. accounts.\nRecommendation: Keep investment accounts in the U.S. and bank accounts in country of residence\nFor the reasons discussed above, we advise American citizens to maintain investment accounts in the U.S. In addition, Americans abroad should open local bank accounts in their country of residence. Local income and living expenses should be managed through this local account to avoid the expense of constantly converting between currencies. Money allotted for savings and investment, however, should be moved to the U.S. account and invested.\naccounts and the center of most of their financial affairs back in the U.S. Yet, to live abroad, a local bank account is almost always necessary.\nContinue to Currency exposure and global investing\nReturn to the list of topics click here.']	['<urn:uuid:efb167b4-f0e5-4153-8595-bfac33deeb42>']	factoid	direct	verbose-and-natural	distant-from-document	single-doc	novice	2025-05-01T23:46:40.222380	19	49	920
403	How do little tunnels made by worms in the ground help plants and the soil?	The tunnels created by earthworms as they burrow improve soil structure by loosening compacted soil and increasing soil porosity. These tunnels provide pathways for water and air to penetrate the earth, making the soil better able to absorb and retain water and less prone to erosion. Additionally, these tunnels provide channels through which plant roots can easily spread, adding stability and organic material to the soil.	['Earthworms & Soil Formation\nSoil formation is a continuous process, impacted by physical factors including wind, rain and temperature, as well as biological forces such as plants and animals. Earthworms significantly influence the formation of soil, helping to shape soil structure, content and fertility. With thousands of species worldwide, earthworms are found in most temperate and tropical zones around the globe. Although healthy soil can be formed without earthworms, the presence of earthworms is usually an indicator of productive soil. Through their seemingly tireless activity, earthworms benefit soil formation in a number of ways.\nEarthworms play an important role in mixing and aggregating soil. In their quest for food, earthworms continuously rise to the surface and tunnel down again, swallowing bits of soil and organic matter along the way. Earthworms excrete this mixture of minerals and plant materials into the soil in the form of nutrient-dense casts. In the process, they bring soil from the top layer to the lower strata and drag soil from below to the surface. This constant churning action can turn over a half foot of topsoil in approximately 10 to 20 years, according to experts at the Natural Resources Conservation Service.\nAs earthworms burrow through the dirt, they improve soil structure by loosening compacted soil and creating thousands of tunnels below the surface. These tunnels increase soil porosity, providing pathways for water and air to penetrate into the earth. As a result, soil is better able to absorb and retain water and less prone to erosion and water run-off. In addition, these tunnels provide channels into which plant roots can easily spread, adding stability as well as organic material to soil.\nEarthworms contribute to soil formation by assisting in the decomposition and incorporation of organic materials into the soil. Earthworms eat leaves and dead roots found on or near the soil’s surface. They mix this organic material into the soil by tearing off portions of plant material and burying it deep within the earth. As they eat, they grind bits of plant material in their gizzards and excrete the organic matter into the soil through their casts. Earthworm casts also pile up on the surface of the soil, adding to soil content. In addition, earthworms stimulate the activity of beneficial bacteria and fungi. These microorganisms feed on organic material, breaking it down into humus.\nSoil Food Web\nEarthworms are important members of the soil food web, a complex community of organisms that impact the process of soil formation. The soil food web consists of soil-dwelling organisms, ranging from bacteria, algae and fungi to insects, small mammals, reptiles and plants. These organisms affect soil formation by burrowing, breaking down plant and animal materials and eventually contributing their own organic matter to the soil at death. Earthworms are an important food source for many members of this community. In addition, earthworm tunnels and casts help provide the water, nutrition and oxygen needed to create an environment in which these organisms can thrive.\n- University of California Cooperative Extension: Earthworms and Soil Productivity\n- U. S. Department of Agriculture, Natural Resources Conservation Service: Soil Formation and Classification\n- U. S. Department of Agriculture, Natural Resources Conservation Service: Soil Biology: Earthworms\n- University of California, Oak Woodland Management: Earthworm Ecology in California\nBased in the Atlanta area, Charlene Williams has been writing and editing since 1988. She has over 15 years of experience working as a technical writer in the software industry. She has worked as a freelance writer for the past five years, and is a contributing writer for eHow and Answerbag. Williams holds a Bachelor of Arts in English from Kennesaw State University.']	['<urn:uuid:8a0a257f-1b9a-42d2-bfbc-6ccd0b5b9aed>']	factoid	direct	verbose-and-natural	distant-from-document	single-doc	novice	2025-05-01T23:46:40.222380	15	66	606
404	What companies were sued over Woburn's water contamination?	In 1982, lawyer Jan Richard Schlichtmann filed a lawsuit against W.R. Grace & Company, which owned the Cryovac Division manufacturing plant, and Beatrice Foods Company, which had purchased the John Riley Company Tannery. A third company, UniFirst Corporation, which operated an industrial dry-cleaning business, was also involved. The defendants were targeted in part because of their 'deep pockets,' while other industries near the contaminated wells were not included in the complaint.	"['Presentation on theme: ""A Civil Action 1982 – Jan Richard Schlichtmann, a lawyer specialized in medical malpractice cases, filed a lawsuit against two multinational corporations.""— Presentation transcript:\nA Civil Action 1982 – Jan Richard Schlichtmann, a lawyer specialized in medical malpractice cases, filed a lawsuit against two multinational corporations in U.S. District Court in Boston\nPlaintiffs 6 Woburn families, all of whom had a child who had died of leukemia or who was being treated for the illness. The case grew to involve eight families\nDefendants W.R. Grace & Company, which owned and operated the Cryovac Division manufacturing plant at 369 Washington Street, about feet northeast of the wells. The Cryovac plant manufactured equipment for the food packaging industry and used solvents to clean and cool tools, cut grease and dilute paint\nBeatrice Foods Company, which, in 1978, purchased the John Riley Company Tannery, 228 Salem Street, and adjacent 15-acre undeveloped property, from John Riley Jr, and sold them back to him in As a stipulation of Beatrice’s agreement to resell the tannery to Riley in 1983, Beatrice retained legal liability for environmental matters. Northeast of the tannery was the 15 acre parcel, undeveloped land that the tannery had purchased in 1950s for its water supply. Schlichtmann charged that the groundwater beneath the 15 acres had become contaminated through activities at the tannery and by the dumping of chemicals on the surface of the 15 acres.\nUniFirst Corporation, which operated and industrial dry-cleaning business at 15 Olympia Avenue, about 200 feet north of wells G and H. UniFirst used PCE as part of its business and tests on UniFirst Property revealed large quantities of PCE in the soil and groundwater.\nThe site and surroundings Woburn is a city of inhabitants located twelve miles north of Boston. Until 1979 the city’s entire municipal water supply was provided by a number of groundwater wells located within the city limits. Two wells of particular relevance in this proceeding, city Wells G and H were opened in East Woburn in 1964 and 1966, respectively. Wells G and H are located just off the banks of the Aberjona river\nContaminated water wells In May 1979, after water had been drawn from these wells over the course of fifteen years, wells G and H were tested for volatile organic contamination. They were found to have hazardous levels of contaminants and were immediately shut down. In tests for contaminants in 1979, and subsequent tests in 1980 and 1981, wells G and H showed consistently high concentrations of two contaminants: trichloroethylene was identified in concentrations as high as 400 ppb (parts per billion) and tetrachloroethylene was found at 43 ppb\nTrichloroethylene TCE is a potent central nervous system depressant and can cause several neurological symptoms such as dizziness, loss of appetite and loss of motor coordination. It produces liver damage at certain exposure levels and causes cell mutations and cancer\nTetrachloroethylene Tetracholoethylene exhibits adverse effects on the central nervous system and is also a carcinogen. Its effects include depression, nausea, liver dysfunction, chronic bone marrow depression and leukemia\nCauses of action Defendants owe plaintiffs and plaintiffs’ descendents a duty to refrain from action which causes plaintiffs and plaintiffs’ descendents to be unreasonably exposed to chemicals which can cause personal injury, economic harm, illness, or which increases the risk of contracting illnesses. The chemicals described above are ultrahazardous substances, and defendants knew or should have known of the dangerous nature of the substances. Defendants are liable for all harm caused to plaintiffs and plaintiffs’ descendents in the manufacture, use, control, and/or disposal of such chemicals\nDefendants failed to exercise due care in the manufacture, use, control, and/or disposal of such chemicals. Defendants’ failure to exercise such care caused plaintiffs and plaintiffs’ descendents to suffer in mind and body, to contract illness and to suffer the increased risk of contracting illness in the future, emotional distress, and mental anguish, and to suffer the loss of use and enjoyment of the property, and economic and financial harm\nWrongful death Defendants’ conduct constituted gross negligence. Defendants’ failure to exercise such care and gross negligence caused plaintiffs’ descendents to die. Defendants’ failure to exercise such care and gross negligence caused plaintiffs who are entitled to receive such damage, to be deprived of the descendents’ reasonably expected net income, services, protection, care, assistance, society, companionship, comfort, guidance, counsel and advice.\nConscious pain and suffering Defendant’s failure to exercise such care caused plaintiffs’ descendents to consciously suffer pain and mental anguish prior to death\nNuisance The contamination in the ground water from which plaintiffs received their water and which was caused by defendants’ actions constitutes a nuisance which is inimical to plaintiffs’ health and restricts their access to and use of the ground water flowing beneath East Woburn and beneath their property. The continued disposal of hazardous substances on the ground and the continued presence of hazardous substances in the soil of defendants’ property in East Woburn constitutes a further threat to the ground water and is a nuisance which is inimical to plaintiffs’ health and restricts their access to and use of the ground water flowing beneath East Woburn and beneath their property.\nRELIEF Wherefore, plaintiffs pray that court, upon trial and determination of their causes of action, award the following relief: Compensation as provided by law; Order defendants to halt all further disposal of hazardous substances on the ground of their property in East Woburn and to remove from the soil on/or adjacent to their property in East Woburn all hazardous substances placed there by them Order defendants to provide appropriate methods to remove all contamination from the ground water flowing beneath East Woburn and plaintiff’ property and return the ground water to the condition it would be in but for the contamination.', 'Are Companies Responsible for Pollution by Corporate Predecessors?\nOne of the arguments posed by the defense in the Woburn Toxic Trial was whether Beatrice Foods, Inc. and W.R. Grace & Co. were liable for environmental damages, when the Aberjona River valley was historically home to industries known for their negative environmental impacts. The defendants also questioned being singled out by the plaintiffs because of their ""deep pockets"", while other industries near municipal wells G and H that were less able to pay damages were not included in the complaint.\nHistory of Manufacturing in Woburn\nWoburn was one of the first heavy manufacturing areas in the nascent United States. Shortly after the completion of the Merrimack Canal connecting the town with Boston, leather processing became a core business of the Woburn area (Tarr, 1987 (Acrobat (PDF) 3.5MB Jun18 09)). By the mid 1800s Woburn was one of the leading leather producing centers in the country. For more details, see Leather Tanning under Key Issues in the Trial.\nAs the leather industry expanded, production of the specialty chemicals needed by leather manufacturers concentrated in the Woburn area. By World War I, Woburn had a significant chemical industry located north of town in the Aberjona River valley. The industry, which began to support leather processing, soon began manufacturing stock chemicals and finished products such as pesticides, fertilizers, and plastics. A history of the Woburn chemical industry can be found at Chemical Companies in Woburn under Key Issues in the Trial.\nImpact of Environmental Regulations\nPrior to the 1960s there were minimal environmental regulations governing the manufacture and production of hazardous chemicals. The national awareness of the risks from improper handling of hazardous chemicals came to the forefront of of the media in the 1960s. A major hurdle in developing regulations involved identifying the responsible parties. A significant difference between the environmental regulations developed in the late 1970s and those placed enforced in the 1980s was removal of ex post facto provisions, which exposed companies operating on legacy sites to lawsuits for the environmental degradation that existed. A list of some of the landmark environment regulations enacted in the 1960s and 1970s includes:\n- Resource Conservation and Recovery Act - 1976\n- Clean Water Act - 1977\n- Comprehensive Environmental Response and Liability Act - 1980\n- Water Quality Act - 1987\nCorporate Responsibility and the Woburn Toxic Trial\n""Making companies pay"" was a rallying cry from the plaintiffs\' attorneys during the Woburn Toxic Trial. This mantra implied that Beatrice Foods and W.R. Grace, and by analogy any large corporation, who should be accountable for the environmental damage they created. At that time, following on the heels of the environmental damages at Love Canal, New York, and Times Beach, Missouri, there was overwhelming public sentiment agreeing that corporations must be responsible for their impacts to the environment. The defense demonstrated how widespread industrial contamination was in the Aberjona River watershed. From this perspective, the defense questioned why they should be responsible for what was considered normal prior to enactment of Resource Conservation and Recovery Act.\nCorporate Responsibility and a Mock Trial\nThe verdict in the Woburn Toxic Trial demonstrates the difficulty in connecting the practices of Beatrice Foods and W.R. Grace to the health problems of Woburn\'s citizens. Questioning the corporate responsibility companies operating facilities at the source locations of the TCE and PCE contamination can be used as an argument during a mock trial. A consideration would be focusing on the short time that Beatrice actually owned by Riley Tannery, and Beatrice\'s responsibility for the overall contamination on the Riley property (i.e. is it fair to a new corporate owner to absorb such a cost when its contribution may have been minimal).']"	['<urn:uuid:d6d8dc54-0f0c-4a35-93e8-e55391367390>', '<urn:uuid:57564c68-4308-4282-a016-dafb7a76ca25>']	factoid	direct	concise-and-natural	similar-to-document	three-doc	novice	2025-05-01T23:46:40.222380	8	71	1579
406	explain double triple bond electron sharing	A double bond involves two atoms sharing two pairs of electrons (each double bond has 4 electrons) and is shorter and stronger than a single bond. A triple bond involves two atoms sharing three pairs of electrons (each triple bond has 6 electrons) and is shorter and stronger than a double bond.	"[""a continuous color pattern that is separated from a beam of sunlight passing through a prism.\nconsists of electromagnetic radiation of different wavelengths (or frequencies)\nThe amplitude of light determines what?\nBrightness (the larger the amplitude, the brighter the light)\nElectromagnetic radiation can only be emitted or absorbed in small packets of energy called what?\nQuantum or photons\nWhen finding energy of quantum (or photon), what does h stand for?\nPlanck's constant (6.63 x 10-34 J-s\nWhat is the consistant property of the numbers when stating how much evergy is absored or emitted in quantums (or photons)?\nThey are whole-number multiples of hv (Ex: 2 or 3, not 1.67 or 4.98)\nWhen calculating the energy of a photon (quantum), what equation is used to find frequency?\nv = c/λ (frequency = the speed of light / wavelength of radiation\nThe orbit number (n) is found by looking at what?\nThe period (or row) number on the periodic table (1-7, going down)\nWhen an electron is in an orbit further away from the nucleus, it has a(n) _________ energy than when it is in an orbit closer to the nucleus.\nWhen an electron is in an orbit closer to the nucleus, it has a(n) _________ energy than when it is in an orbit further away from the nucleus.\nWhat is the difference between an orbit and an orbital? Which one does an electron follow?\norbit is a direct path of an electron around a specific atom. an orbital is a region where the electron is most likely to be found. All electrons follow an orbital (other than Hydrogen)\nWhen an electron is in the orbit closes to the nucleus, it is said to be in the __________ state.\nAccording to Bohr's explanation of the atomic spectra of Hydrogen, explain the energy absorbed or released when an electron stays in an orbit (ground state or excited state)\nno energy will be emitted\nAccording to Bohr's explanation of the atomic spectra of Hydrogen, explain what happens when an electron jumps from an orbit with a higher energy to an orbit with a lower energy\nenergy will be emitted in the form of electromagnetic radiation\nAccording to Bohr's explanation of the atomic spectra of Hydrogen, what is determined by the energy difference between the final state and the initial state?\nThe frequency (or wavelength) of the electromagnetic radiation\nWhich model best describes how the electrons really exist in an atom: Bohr Model or Quantum Mechanical Model?\nQuantum Mechanical Model. (Bohr's model only holds true for Hydrogen)\nIt is impossible to simultaneously determine the exact ____________ and the exact ___________ of a subatomic particle.\nposition and velocity\nWhy can we only determine probability of the velocity and location of an electron?\nElectrons have wave-like behaviors\nThe four quantum numbers describes what?\nDescribes the electrons and the atomic orbitals that they are in\nWhen determining quantum numbers, what does 'n' stand for?\nPrincipal quantum number - The number of a particular orbitals\nWhen determining quantum numbers, what does principal quantum number (n) determine?\nThe energy and size of the orbital\nWhen determining quantum numbers, what does 'l' stand for and what does it determine?\nAngular Momentum Quantum Number - The shape of the orbitals\nWhen determining the quantum number 'l', what are the orbitals assigned to each possible l value?\n0=s, 1=p, 2=d, 3=f\nHow are the sub-shells found and how do you express them?\nGiven n and l values, sub-shells can be designated with a number and a letter\nThe value of 'ml' is limited by the value of what other quantum number?\n'l' (angular momentum quantum number)\nWhat are the possible values for the 'f' sub-shells?\n+3, +2, +1, 0, -1, -2, -3 (contains 7 orbitals)\nThe value of 'l' is limited by the value of what other quantum number?\n'n' (principal quantum number)\nWhat is the difference between an electron shell and a sub-shell?\nshell is when electrons have same value of 'n', sub-shell is when electrons have same values of 'n' and 'l'\nWhat are the three rules for electron configuration?\n1) electrons occupy lower-energy orbitals first before occupying higher-energy orbitals. 2) (Pauli exclusion principle) no more than two electrons can occupy one orbital and two electrons in the same orbital must have opposite direction of spins. 3) (Hund's Rule) the most stable arrangement of electrons in the same subshell has the largest number of unpaired electrons, all with the same direction of spon\nWhat are the electron configuration designated orbital letters of the periodic table?\nColumns 1 and 2 = s orbital, columns 2 through 8 = p orbital, transition metals = d orbitals\nWhy are Cations smaller than their corresponding neutral atoms?\nBecause neutral atoms lose electrons to form cations\nWhy are Anions larger than their corresponding neutral atoms?\nBecause neutral atoms gain electrons to form anions\nWhat is the formula used to find the formal charge of an atom?\n(# of valence e-) - (# of lone pair e-) - ½(# of bonding electrons)\ntwo atoms sharing two pairs of electrons (each double bond has 4 electrons) - shorter and stronger than single bond\ntwo atoms sharing three pairs of electrons (each triple bond has 6 electrons) - shorter and stronger than double bond""]"	['<urn:uuid:0b3e5d51-ecee-40b3-b1c2-38215895b1ea>']	open-ended	with-premise	short-search-query	distant-from-document	single-doc	expert	2025-05-01T23:46:40.222380	6	52	875
407	rainwater tank install location considerations water harvest	The key considerations for water tank location include council regulations, downpipes position, plumbing and pump requirements, location space, and property aesthetics. Additionally, the catchment area (roof), conveyance system (gutters), and overflow protection must be considered for effective rainwater harvesting.	['If you are planning to purchase a water tank for your home, there are a lot of things that you have to consider. Once this is settled, finding the best location for it is the next thing that you have to worry. Even though it’s a bit of a complicated process, all of it will be worth it once you start enjoying some good changes in your water usage.\nFive Key Considerations For Water Tank Location\nThe tank size will greatly affect the location of the tank on your property. But other than that, there are other things that you have to take into consideration to be able to choose the right spot for your tank before you contact water tank installation specialists:\n- Council Regulations. Before you start looking for a water tank to buy, make sure that you already checked your local council regulations with regards to this. There are local councils that have specific regulations when it comes to the placement as well as the size of the water tank. This can affect the type of tank that you purchase and also the ideal location for installation.\n- The downpipes are the most important thing that you have to look for before the installation. Walk around the outside of your home and take note of the location of these downpipes. The tank does not have to be directly under the roof downpipe but knowing where they are is necessary.\n- Plumbing And Pump. If you are going to have plumbing on your water tank to your property for it to be accessible to any location, consider where you would need water most of the time. Is it for your swimming pool? Your garden? Locating it near these areas would require less plumbing work.\n- Location Space. It is important that you first measure the location space where your water tank is going to be installed before you start buying one. Tanks come in different styles and sizes and your decision would depend on what you need as well as the location space.\n- Property Aesthetic. Where do you want to place your tank? If you are concerned about the aesthetics of your property, then you should make sure the water tank does not look awkward and out of place. In fact, there are different ways that can help blend your rainwater tank into its environment.\nTips In Calculating The Right Size Of Water Tank\nFinding the right water tank size can be confusing, especially if this is a first for you. Buying the right tank size is important because it will affect the location that you have chosen for the installation. Here are some tips to help you find the right water tank size:\n- The Need. The first thing that you have to consider is: how much water do you need? Having more might be a good idea, but as a general rule, just plan for at least 4 weeks of water supply. For example, if you are using around 3,000 liters of water per week, then you should get a 12,000-liter water tank.\n- The Harvest. Another factor to consider is the amount of water that you can harvest from your roof downpipes. As a rule of thumb, each square meter of your roof space can collect around 1 liter of water for every 1mL of rain.\nNow that you have everything covered, choosing the right water tank for your home will not be that difficult anymore. Make sure that you take all of these things into consideration to avoid committing the most common mistakes in choosing a water tank.', 'Believe it or not, rainwater harvesting is the third largest water source in Australia after surface and groundwater. In fact, approximately 1 in 4 Australian homeowners have a rainwater collection tank on their property. For the other 3 out of 4 Australians, we ask, “what are you waiting for?”\nIn this complete inspirational guide, we will fully explain the most frequently asked questions regarding rainwater collection. We’ll take a look at the benefits, methods, and components of rainwater harvesting, as well as 3 large-scale rainwater harvesting examples to help inspire your future installation.\nWhat is Rainwater Harvesting?\nDespite sounding complex, rainwater harvesting is much simpler than most people imagine. Rainwater harvesting can be used to refer to any rain collection system on a property that prevents the water from running off. Most commonly, rainwater is collected on a roof and sent to a large storage container for reuse.\nWhy Harvest Rainwater?\nThere are many benefits of harvesting rainwater, some of which are more obvious than others. Today, Aussies typically harvest rainwater for the following reasons:\n- Lowered water bills in the home\n- Smaller ecological footprint\n- Independence from water mains\n- Control over water quality in a home\n- Provide an ongoing source for clean drinking water\n- Easy, automatic garden watering systems\n- Reducing the negative impacts of stormwater in the area\nIn some cases, local government regulations may actually cause rainwater collection to be a necessity, rather than a luxury. This is especially true in some of Australia’s dryer and more arid climates where rainwater collection is entirely necessary to support ongoing water demand in a remote location (looking at you Southern Australia).\nCommon Issues with Rainwater Harvesting\nDespite all of its incredible benefits and potential, there are many issues that arise when installing and operating a rainwater harvesting tank and system in Australia. While conditions and challenges may vary on a case by case basis, the following are some of the most common hurdles for ongoing rainwater harvesting systems:\n- An expensive upfront cost for materials and labor\n- Combating unpredictable or unreliable rain patterns\n- Ongoing upkeep and continuous maintenance\n- Potentially harmful chemicals in roof paint and other existing building components\n- Adhering to local storage limits and property regulations\n- And individual property challenges (i.e. flat roof or limited space for storage)\nMore often than not, it is easy to overcome challenges and install an effective rainwater collection system. For Australians, there are many local and national resources that help connect property owners with local experts and parts manufacturers to help find ideal, custom solutions.\nDifferent Rainwater Harvesting Methods\nAll rain falls from the sky, however, continuous industry innovations have led to many different methods for harvesting rainwater on a property. Below, we will outline some of the most common rainwater harvesting methods used by Australian homes and buildings today.\nRooftop Rainwater Harvesting\nFirst, rooftop rainwater harvesting is one the most popular and easiest methods to adopt for Australian rainwater collection. On most buildings, rooftops can serve as a large collection area where raindrops are able to land and be directed into a large storage container.\nRooftop rainwater harvesting systems are made up of 3 components:\n- the collection area (the roof)\n- a conveyance system (typically gutters)\n- and a separate storage container (large barrels or reservoirs)\nFrom the highly complex to the relatively simple, rooftop rainwater harvesting systems can be installed and optimized by contractors and DIY enthusiasts alike.\nSurface Runoff Rainwater Harvesting\nNext, surface runoff harvesting is another popular method for most collecting rainwater that is especially useful for large properties. Runoff rainwater collection systems are typically much harder to install than rooftop rainwater systems and are usually reserved for professional contractors or new construction properties.\nThe main difference between surface runoff and rooftop rainwater harvesting is the location of the storage. Surface runoff barrels and wells are usually dug deep into the ground at the lowest elevation point on the property. With this, more infrastructure can be added to direct all of the excess rainwater that hits the property into the in-ground storage.\nDue to the increased likelihood of toxic chemicals, surface runoff rainwater harvesting systems are typically only used for irrigation, rather than drinking. It is also necessary to build and install outflow systems so that the water can be easily used on the property nearby.\nAll-in-one Rainwater Collection Barrels\nLastly, there are also many great all-in-one rainwater harvesting systems that are perfect for first-timers, experimenters, and other small-scale applications. If you are not ready to invest in a full property system, it is possible to purchase one of these small all-in-one systems in order to “dip your toes in the [rain]water.”\nAll-in-one rainwater barrels can be placed overhangs or even in full-exposed areas of the property in order to collect the falling resources. Once filled, the barrel’s reserve can then be used for easy irrigation or other non-drinking purposes.\nThe Basic Components of a Rainwater Harvesting System\nAs we’ve mentioned, rooftop rainwater harvesting systems are by and large the most popular and practical for most Australian properties. Knowing this, we will break down the components of a typical rooftop rainwater harvesting system to showcase how easy and effective they are to install and use.\nImage from https://homesteadandchill.com/wp-content/uploads/2019/12/rainwater-collection-system-schematic.jpg\nFirst, the location of a rainwater harvesting system should be scrutinized prior to installation. To minimize upfront material costs, rooftop rainwater collection systems should be stationed as close to the home as possible. All of the components should also be in a location where it is easy to access, as maintenance may be necessary in order for continued use to be possible.\nThe Catchment / Collection Area\nNext, the catchment (or collection) area is one of the most important features of an effective rainwater collection system. Since the dawn of modern building techniques, sloped roofs of various materials have been installed to whisk water away, which works to the advantage of a rainwater collection system.\nIn short, the larger the roof, the more rainwater it can collect and send into storage. Nearly all roof types are effective, although old roofs with lead-based materials should be replaced or repaired prior to using a rooftop collection system for drinking water in a home.\nConveyance System & Downspout\nAfter hitting the roof, rainwater is then collected in the conveying system and sent through a downspout. Working with gravity, rainwater trickles down the roof and into gutters which are sloped downwards towards the storage container. In most high-quality systems, gutters are covered by a screen to prevent the build-up of dirt and debris.\nScreens & Filters\nThroughout the collection and distribution process, the rainwater is sent through a series of screens and filters to improve water quality and ensure ongoing system operation. Before entering the storage area, water is typically filtered at least twice: once for the big stuff and a second time to weed out bugs and bits of dirt.\nIf you plan on drinking the rainwater that you are collecting, then a whole house water filter is necessary to purify the rain so that it is safe to drink. Although rainwater is typically not very hard, a water softener may also be used within the house to prolong appliance life and minimize damage to tubs, sinks, and more.\nOverflow Protection / First Flush Diversion\nNext, overflow protection is a critical part of any rainwater harvesting system that is often overlooked by first-time experimenters. No matter how large your barrels are, it is often very surprising just how fast your water storage can fill up to capacity during rain storms.\nIn order to prevent damage to the tank and the rest of the system, automatic overflow protection is used to divert excess water capacity from entering the storage unit.\nBeyond this, overflow protection systems are also usually equipped with a first flush diversion to keep water quality high. For those that are unfamiliar, the initial rainwater that runs off a roof is typically much dirtier than the successive flows. With this, smart systems use a “first flush diverter” in order to reject the initial rainwater to save room for cleaner water to be sent to storage.\nAs we’ve alluded to several times, storage is perhaps the most critical component of a rainwater harvesting system. Large tanks can be installed above the ground, below the ground, and even bladder tanks can be used in unused spaces, such as below the deck. Tanks can also be linked together for maximum water storage. Rainwater tanks can be made up of a variety of materials including plastic, wood, metal, and more.\nAlthough there is a lot of wiggle room for creative storage solutions, a few things are necessary to keep stored water safe for use on the property. For one, all plastics should be BPA free. Secondly, containers cannot be clear or see-through, because sunlight may cause stored water to grow algae or other system-damaging lifeforms.\nImage from https://www.texasvox.org/wp-content/uploads/2014/05/Rainwater-Harvesting-Diagram-by-Vanisle-Water.jpg\nSpigots and Outflows\nLastly, your harvested rainwater can only be used with proper spigots and outflows for your water to travel through. Typically, most simple systems have some sort of tap on the exterior of the barrel and room to easily fill a bucket or watering can. Spigots should be installed with some sort of a switch or human control to halt the water from constantly leaking.\nIn full-residential systems, outflows may be triggered simply by the water controls in your kitchen, bathroom, and laundry area. For landscape watering, it is also common to have a system of pipes installed for even distribution of the collected rainwater.\nConsiderations for Rainwater Harvesting Systems\nThe first step to designing a rainwater collection system is evaluating your property’s potential with a full feasibility analysis. In order for a rainwater harvesting system to be effective, the property should receive enough annual rainfall and have ample room for collection and storage. To get started, here are a few things you should determine:\n- Your area’s annual rainfall\n- And your roof’s surface area (potential to collect rainwater)\nBy multiplying your estimated annual rainfall (in mm) with your roof’s surface area (in square mm), you can then calculate your maximum expected rainwater collection in litres. Of course, as we mentioned earlier, annual rainfall collection potential should be lowered slightly to account for first flush diversion and tank overflow.\nOnce you’ve determined your property’s rainwater collection potential, then you can begin to brainstorm the possible uses for your new harvested resource. For small systems, rainwater can be used extremely effectively, even if it never enters the pipes of your home. Simple systems for irrigation and landscape watering can typically be sized to store rainwater all the way through even the driest of dry seasons.\nSecondly, if rainwater harvesting will be used in the home, there are essentially 2 different capacities: limited or potable water. Both limited and potable water systems can dramatically reduce main water consumption and costs in your household, with a few different things to consider.\nLimited rainwater systems – Limited or “grey water” systems can be used in toilets, laundry, hoses, and more. Although it is not made to be safe for drinking, limited rainwater systems are an eco-friendly way to run water-based appliances in your home without having to install over-the-top expensive filters.\nPotable rainwater systems – Potable or “drinking water” systems can be installed so that rainwater can be used in cooking, cleaning, showering, washing food, and more. Although they are more expensive to install upfront, full-home potable rainwater systems allow for a property to be completely “off of the grid.”\nOf course, rainwater harvesting systems cost money to purchase and install. Despite being somewhat expensive upfront, rainwater harvesting is designed to lower costs at home by increasing self-reliance. While most expenses are impossible to avoid, there are also a few things that can be done:\n- Source material and labor from local sources\n- DIY when possible (DIY downspout diverters are one of the easiest)\n- Take advantage of local and national green system incentives and rebates\n- And purchase high-quality components with long system lifetimes\nWhen calculating a “break-even” period it may be hard to approximate rainwater collection and use against mains water costs. While rainwater is completely free, systems may be able to “pay for themselves” for high-water users over a number of years. Beyond this, rainwater collection systems also increase property value, which may provide financial returns when selling a home or building.\nLastly, it is very important to understand that rainwater collection is an ongoing system, rather than a “set it and forget it” home component. Systems must be installed in such a way that all components are easy to access and monitor. Throughout the first few years of a rainwater harvesting system’s lifespan, owners should pay attention to potential system stop-ups and leaks to prevent further, more costly damage from occurring.\nRainwater Harvesting Case Studies\nAlright, before we wrap up, let’s take a look at some real rainwater harvesting case studies from around Australia. Below, we will showcase a few of the most exciting and interactive active rainwater collection systems down under.\nImage source: https://upload.wikimedia.org/wikipedia/commons/thumb/b/b1/Ceres_rainwater_tank_1_Pengo.jpg/1024px-Ceres_rainwater_tank_1_Pengo.jpg\nCERES Community Environment Park in Melbourne\nFirst, Victorian readers may be well aware of the Centre for Education and Research in Environmental Strategies (CERES) Community Environment Park located in Brunswick East, Melbourne. Throughout the 4.5 acres of the urban greenspace, the CERES Environment Park gives visitors the opportunity to participate in or observe a number of sustainable practices including:\n- Beekeeping meetings\n- Community gardens\n- An organic grocery\n- A food nursery\n- A cafe\n- And more\nMost importantly, the CREES Community Environment Park is home to the Urban Water Conservation, Demonstration, and Research Facility which supports many local, sustainable water projects.\nIn the image above, you can see a large rainwater collection barrel that is attached to the gutter systems of multiple park rooves. Scattered around the park, there are many more barrels of various shapes and sizes. Altogether, the collected water is used to aid in the gardens and facilities, typically being cycled back directly to adjacent buildings.\nImage source: https://www.thefifthestate.com.au/wp-content/uploads/2020/01/Marrickville-Library-Day.jpg\nThe Marrickville Library and Pavilion\nHeaded north to Sydney, the new Marrickville Library and Pavilion has made headlines as one of the best new purposefully-built structures in Australia’s most populated city. Remodeled from an old hospital, the Marrickville Library incorporates many cutting-edge design elements to reduce energy consumption and function independently.\nIn the image above, you can see six large rainwater collection barrels installed on the building’s spacious 1,200m² outdoor pavilions and garden. Here, the recycled water is used primarily to keep the low-maintenance plant features alive and well. Beyond rainwater collection, the Marrickville Library also features:\n- Natural ventilation & raised flooring\n- FSC certified timber and recycled building materials\n- Controlled passive solar design\n- And more\nOpen to the public, the Marrickville Library can now officially be added to any eco-tourism vacation to Sydney.\nImage source: https://www.solarquotes.com.au/blog/wp-content/uploads/2021/01/la-trobe-sports-solar.jpg\nLa Trobe University’s Sports Stadium\nLastly, we’d like to head back to Melbourne to feature La Trobe University’s Sports Stadium in the suburb of Bundoora. This massive complex has a “6-star” green energy rating while providing space for an indoor stadium, commercial offices, and educational facilities.\nOn top of the stadium, the roof is the real MVP (most valuable player) for La Trobe University. The school, which has set a goal for carbon neutrality by 2029, has purposefully designed the roof for maximum sustainability. Here are its key features:\n- Sloped and supported by a large rainwater collection system\n- 519 kW of installed solar capacity\n- And white paint to reflect heat\nAlthough this is by far the largest system on the campus, La Trobe University also supports rainwater harvesting in a few smaller instances nearby. The University also plans to expand sustainability features across its regional branch campuses.\nIn conclusion, many Australian properties have the opportunity to reduce monthly costs and increase self-sufficiency with an installed rainwater harvesting system. We hope that this guide has helped clear up some of the most commonly sought after information regarding rainwater collection and has perhaps inspired you to begin your own installation.\nWith rapid adoption across the country, it is now easier than ever to find someone you know that has had their own rainwater harvesting experience to learn about the benefits first-hand. To learn more, feel free to contact us with any of the remaining questions you may have to help you get started.']	['<urn:uuid:aae3951b-0739-4bab-8374-fc5e9c21018d>', '<urn:uuid:645abbd5-eea0-4eb5-beba-dfdba8591a6b>']	factoid	direct	short-search-query	similar-to-document	three-doc	expert	2025-05-01T23:46:40.222380	7	39	3355
408	what factors help learn programming languages effectively and what mental health support exists for programmers in low income areas	For effective programming language learning, having realistic beliefs about learning potential is crucial, avoiding myths like needing perfect mastery before joining teams or requiring side projects to become senior developers. Additionally, hands-on immersive experiences have proven successful for many learners. Regarding mental health support in low-income areas, there are initiatives like the ReSHaPe trial that develops online programs specifically designed to improve recognition and self-help for depression and anxiety symptoms among low-socioeconomic households.	"['What second language acquisition can teach us about learning to code: Part 1\nBy Kristen Foster-Marks\nPart 1: Learner beliefs about language learning\nKnowing how to program computers is a lucrative skill—and arguably more necessary than ever in a world where computer technologies have become ubiquitous across industries and domains. These days, we often hear, “All companies are software companies”, and a quick glance at any job board confirms that indeed, most companies are actively hiring software developers and engineers.\nUnfortunately, the demand for software engineers has outpaced supply for some time now. Despite record numbers of graduates from traditional computer science programs and non-traditional programs like coding boot camps, there are still substantially more programming positions to be filled than qualified applicants to fill them.\nNot only that, but it is increasingly recognized that technology skills degrade rapidly if software developers and engineers do not make a substantial effort to engage in continuous learning and development. In fact, it is estimated that the skills and knowledge an engineer acquires today will be stale a mere two years from now.\nThese factors have forced both individuals and companies to heavily invest in upskilling, and for companies, this has included both their technical and non-technical workforce. This is easier said than done, however. Upskilling an existing cadre of programmers—and training groups of potential programmers—efficiently and successfully depends on institutional support and intention, as well as individual action and persistence.\nThe stakes are enormous: If this upskilling is not done well—if it is not done intentionally and with an awareness of pedagogical principles—the investment is unlikely to pay off at scale.\nThis situation begs the question:\nWhat are the factors that contribute to the rapid and successful acquisition of programming languages and technologies?\nAny tech leader and tech practitioner—whether current or aspiring—should be interested in the answers to this question, and we may be able to provide some of those answers by turning to the scholarly field of second language acquisition.\nWhat is second language acquisition, and what does it have to do with learning to code?\nSecond language acquisition (or SLA) is a sub-discipline of applied linguistics. Its researchers investigate the factors that influence—both positively and negatively—the human ability to learn languages in addition to one’s first/native language. The field burgeoned in the late 1960s following large financial investments by national governments; the military branches of these governments had a huge stake in quickly and effectively teaching their intelligence forces to gain fluency in key target languages in order to achieve goals in espionage and foreign diplomacy.\nSLA’s foundational theories were supplied by the long-established fields of linguistics, psychology, child language acquisition and language education. Today, it is a vast discipline with multiple dedicated academic journals, international conferences and symposiums, and long-running debates about the factors that help and hinder successful language learning.\nMany of the questions and problems that SLA has strived to answer in the domain of human language learning are analogous to those facing learners of computer languages and technologies. Some of the major lines of inquiry in SLA have included:\n• How does knowledge of one’s first/native language affect acquisition of a foreign language?\n• What effect does age have on the learning process and ultimate attainment?\n• Is implicit, incidental learning likely to lead to acquisition—or is focused, formal learning necessary to gain fluency?\n• What learner beliefs help or hinder the language learning process?\nThe stakes that catalyzed SLA’s inception feel as high as the stakes facing companies today as they struggle to keep their technical workforce filled and skilled; the stakes are certainly as high for individual engineers fighting to keep their skills relevant and themselves employable.\nMy personal connection to SLA and coding\nI spent most of my 20s teaching English to English Language Learners (ELLs) first in South Korea, and then at Colorado State University. During this time, I completed a Master’s degree in English with an emphasis in Teaching English as a Second or Foreign Language; SLA was a central topic of study in this program. After all, one of the field’s central objectives is to determine what constitutes effective instruction, and thus language teachers are expected to be well-versed in historical and current thinking about how foreign languages are acquired.\nAs it turns out, few are willing to pay teachers a liveable wage, and so in 2016, I made my own high-stakes decision to learn web development. I believe very strongly that my understanding of SLA has contributed to my success in learning programming languages as an adult—and it has been a fascinating experience to observe and theorize about the applications of SLA research to my own learning experiences.\nThus, the purpose of this article is to share these connections and applications with both individuals hoping to gain or increase their proficiency in programming languages, as well as the leaders and executives who hope to facilitate this technical upskilling.\nThe nine sub-domains of SLA\nThere are many, many aspects of SLA that can provide insight into the acquisition of programming languages—enough to warrant a book-length treatment, in fact. Those sub-domains include:\n• The linguistic environment\n• Learner cognition\n• Learner motivation and affect\n• Developmental sequences\n• Crosslinguistic influence\n• Social dimensions\n• Learner beliefs about language learning\nIn each article of this series, we’ll explore different sub-domains, examining their key questions and findings, as well as how we can apply these findings to the learning and acquisition of programming languages and technologies.\nLet’s begin with examining learner beliefs about language learning and how it connects with learning to code.\nWhat SLA teaches us about language learner beliefs\nSince Elaine Horwitz’s seminal study of language learner beliefs in 1987, thousands have followed suit in investigating language learners’ beliefs and mythologies. Early research focused on cataloging those beliefs, but more recently, researchers have endeavored to understand how learner beliefs help or hinder the language learning process and ultimate acquisition of a language. And while SLA researchers have uncovered a wide array of language learning beliefs and their ramifications, perhaps more important has been the discovery that some learner beliefs are simply not true, in that they have been discredited by scholarly research and the documented testimony of teaching practitioners.\nJust a few of these debunked (yet persistent) myths include:\n• “I can become fluent in Arabic solely by studying vocabulary and grammar out of a textbook.”\n• “I am not technically fluent in Mandarin unless I have flawless, native-like pronunciation.”\n• “I should be able to master German after three to four years of high school study.”\n• “If I speak in class before my pronunciation is perfect, my pronunciation will be incorrect forever.”\n• “I’m too old to learn Spanish. I should have done it back in high school when I had the chance.”\n• “The best way to learn Portuguese is through translating great Portuguese literature.”\nYou’ll be hard pressed to find an SLA researcher who entertains any of the above beliefs. Take the last one, for example. Countless studies have been conducted over the past several decades that show that language teaching methodologies which provide ample opportunities for receiving authentic input (listening) and producing authentic output (speaking) lead to better ultimate acquisition than traditional literature translation exercises. While there is no doubt something to be gained linguistically in translating literary samples of a language, if one’s ultimate goal is to use that language in authentic contexts, then learning Spanish through watching contemporary telenovellas and then discussing them with friends in Spanish is much more effective than translating ""Don Quixote"" in solitude.\nDespite having been discredited through academic investigation, erroneous language learning beliefs remain prevalent in language learning communities across the world (even amongst language instructors), and unfortunately, they have the potential to increase learner anxiety and deplete learner motivation to persist through challenges. It is widely documented in SLA research, for example, that achieving native-speaker-like pronunciation—colloquially referred to as “speaking without an accent”—is nearly impossible for adult learners.\nIn part, this is because accent-less pronunciation is conceptually impossible to define. Just consider the myriad dialects of the English language across cultures and geographies—within the United States, alone, you’ll find multiple ways to pronounce even the seemingly straightforward word “butter.” Further, the critical period hypothesis proposes that after a certain age (likely around two or three years old) it is extremely difficult for our articulatory apparatus to be trained to make sounds not already in its functional repertoire.\nThis is where unrealistic beliefs can prove a hindrance to the learning process: For a language learner who expects to speak a foreign language without an accent, struggling to achieve what is perhaps not even physiologically possible can be extremely demoralizing and lead to eventual abandonment of the learning goal. As a world traveler, former language teacher and tech worker who often works alongside non-native English speakers, I’ve heard countless apologies over “imperfect” English accents. I have emphasized to these folks: No good language teacher would hold a student to the standard of “perfect” pronunciation, and we should regard speaking with an accent as something to be celebrated.\nHow language learner beliefs and myths impact those learning a new programming language\nSo, how is the inquiry into language learner beliefs relevant to learning programming languages and technologies? I strongly believe that findings borne out of the aforementioned research provide insight into the experiences of those who are:\n• Learning to code for the first time\n• Learning a second, third or nth programming language\n• Learning a new technology stack\nHere’s where the analogies are strongest: SLA studies have demonstrated that the more realistic the beliefs language learners hold on the possibility of things like perfect pronunciation and grammatical accuracy, the better their learning outcomes. For this reason, recognizing those beliefs and then analyzing their truth is necessary for both teachers and learners.\nWhen I was a language teacher, I devoted the first class session of each semester to surveying and then deconstructing my students’ beliefs—especially those with no empirical support or outright debunked by the research—so that they could avoid the damaging effects of those beliefs on their motivation and ultimate skill attainment.\nComputer language learners should go through the same exercise. There are innumerable myths (enabling and hampering) that we new and experienced programmers hold about ourselves and the best ways to develop our skills, including:\n• “I need to learn language x really well before I can be on a team that uses language x.”\n• “Asynchronous code reviews are the most effective way to pass knowledge from more experienced developers to newer developers.”\n• “If I’m ever going to be a senior developer, I must be an expert in all of the technologies my team uses.”\n• “I’ll never be a great programmer if I don’t build side projects during my free time.”\n• “As a coding bootcamp graduate, I’ll never be as good of a programmer as my degree-holding colleagues.”\nDo any of these ring true for you or your team? Take a moment to reflect.\nDo you think that outside of your personal experience and mindset, there is strong evidence to support any of these beliefs? Could any of them be baseless and even destructive to your learning process? What other beliefs do you hold that may be helping or hindering you in your acquisition of computer languages and technologies?\nThe steps of identification and reflection have been crucial for me in overcoming those beliefs that have proven impediments to my tech skill development, as well as in harnessing those that have kept me motivated.\nTakeaways for programming learners and their leaders\nDuring my journey in learning how to code, I have discovered that I am in constant possession of beliefs about my individual potential. Sometimes my self-beliefs are positive, and sometimes they are negative. Sometimes, they are informed by external information about the world, and sometimes by my own inner thoughts. They always impact my motivation and persistence.\nFor example, back in 2016 when I began my coding boot camp, I truly believed that through the immersive, hands-on experience that was being replicated by boot camps across the country, I could reach a level of proficiency in six months that would make me employable as a junior developer. The evidence was all around me; the strategy had been proven out time and time again.\nYet, there were people in my social circle who were suspicious, and who even verged on discouraging me through questioning whether this path was realistic, thus suggesting that I might be embarking on an (expensive) mistake.\nThey were wrong, of course. If I had not seen the irrefutable evidence around me, and if I had thus not strongly held the belief that my goal was realistic, it’s easy to see how I might have failed to persevere during those months of intense, twelve-hour days typing away at the keyboard, ignoring the outside world, suffering daily failures in the process of acquiring a really hard skill.\nI have also held the belief, however, that my ultimate potential as a computer programmer is limited by both my nontraditional path into programming, as well as my lack of desire to spend my personal time outside of work tinkering with side projects. And to be honest, I’m still wrestling with these beliefs. I don’t want to hold these beliefs. I understand that at times, they are demoralizing and inhibiting. But as I have continued in my career, I have encountered more and more outstanding engineers who have come from non-traditional backgrounds, and as this evidence accumulates, I am increasingly chipping away at these beliefs.\nIf you’re like me, and want to start drawing inspiration from SLA in order to learn a new language or help your team upskill, I think these takeaways are good starting points:\n- Reflect on your implicit beliefs about the ideal process and conditions for learning computer languages and technologies, as well as yourself as a learner. How are those beliefs helping or hindering you? For those that hinder you, is there any actual evidence that these beliefs are true?\n- As a manager or team lead, begin a conversation with your developers one-on-one to start exploring their beliefs and mythologies around themselves as computer programmers and the process of technology upskilling. You might find that you can unlock your developers’ latent potential by identifying and working through any inhibiting or detrimental beliefs that they hold.\n- When designing an upskilling program for yourself, your team or your company, take the time to understand what current research reveals about the best strategies and processes for doing so. Harness these to accelerate and deepen skill acquisition.\n- When introducing an upskilling program or initiative to your team, take the time to understand and deconstruct their beliefs that have the potential to decrease the effectiveness of the initiative.\nContinuing to draw insights from SLA\nThere are certainly general learning theories that apply to the learning of any skill, domain or process, but I believe the parallels between the acquisition of human languages and programming languages are particularly strong. Over the last several years, I’ve perused academic literature to see if any research agendas or studies have popped up in order to empirically explore the applications of SLA research to the acquisition of computer languages and technologies. Thus far, there’s not much.\nGiven this lack of scholarly treatment, I invite you to join me as I continue to explore these connections between SLA and tech skill development by diving into SLA’s other subdomains in this multi-part blog series.\nIn the meantime, If you’re interested in diving into some SLA research, I recommend reading Patsy Lightbown and Nina Spada’s introductory text ""How Languages are Learned"" for a concise, accessible introduction to and exploration of SLA. If you’re feeling intrepid and want to get lost in the academic literature, check out Lourdes Ortega’s graduate-level textbook ""Understanding Second Language Acquisition,"" and find a way to gain access to a database of scholarly articles so that you can follow the citations!\nBibliography and suggested reading\nBaldwin, L.P., Macredie, R.D. Beginners and programming: insights from second language learning and teaching. Education and Information Technologies 4, 167–179 (1999).\nBluestone, K. (2015). Acculturation, Interpersonal Networks, and the Learner’s Sense of Self: The Effects of Social Relationships on Second Language Learning. Working Papers in Applied Linguistics and TESOL, 9(2), 1–30.\nDubravac, V., & Latić, E. (2019). The Plasticity of Students’ Language Learning Beliefs: The Interplay of Gender, Grade and Educational Level. Journal of Language and Education, 5(4), 36-53.\nHorwitz, E. K. (1987). Surveying student beliefs about language learning. In A. Wenden & J. Rubin (Eds.), Learner strategies in language learning (pp. 110-129). London, UK: Prentice Hall.\nLightbown, Patsy.Spada, Nina Margaret. (2013) How languages are learned. Oxford : Oxford University Press,\nOrtega, L. (2009). Understanding second language acquisition. Hodder Education.\nRobertson, S.A., & Lee, M.P. (1995). The application of second natural language acquisition pedagogy to the teaching of programming languages—a research agenda. SIGCSE Bull. 27, 4 (Dec. 1995), 9–12.\n5 keys to successful organizational design\nHow do you create an organization that is nimble, flexible and takes a fresh view of team structure? These are the keys to creating and maintaining a successful business that will last the test of time.Read more\nWhy your best tech talent quits\nYour best developers and IT pros receive recruiting offers in their InMail and inboxes daily. Because the competition for the top tech talent is so fierce, how do you keep your best employees in house?Read more\nTechnology in 2025: Prepare your workforce\nThe key to surviving this new industrial revolution is leading it. That requires two key elements of agile businesses: awareness of disruptive technology and a plan to develop talent that can make the most of it.Read more', 'The World Federation for Mental Health’s World Mental Health Day 2021 falls on October 10th and researchers are being encouraged to share what they know about mental health inequality and ideas about how to tackle this. Many research studies into the treatment and prevention of mental health conditions are taking place, such that ‘Mental and behavioural disorders’ is the most commonly applied condition category for research registered in the ISRCTN registry.\nThe theme of ‘Mental Health in an Unequal World’ aims to raise awareness of the inequality in access to mental health care, both locally and globally, for marginalised people, particularly for people living in poverty. According to UN 2016 data, “nearly 800,000 persons died every year by suicide, and 79 per cent of global suicides occurred in low- and middle-income countries”.\nThe United Nations has set ensuring healthy lives and promoting mental health and well-being for people as one of its sustainable development goals. The UN sustainable development target 3.4 is to reduce premature mortality from non-communicable diseases, such as mental health conditions, by one-third by 2030 through prevention and treatment and the promotion of mental health and well-being.\nOne such study that is investigating methods to tackle mental health inequality is the ongoing ReSHaPe trial. This study aims to develop an online program that will improve recognition, self-help, and help-seeking for depressive and anxiety symptoms among low-socioeconomic households in Malaysia. The intervention was designed in response to the National Health and Morbidity Survey in Malaysia which showed a high level of mental health issues among the low-income population compared to those with higher incomes.\nSimilarly, a National Mental Health Study in Colombia found high levels of mental distress and illness and poor access to treatment in Colombia’s children and adolescents, including high levels of post-traumatic stress symptoms, following a period of armed conflict. A research study has adapted the DIALOG+ mental health intervention for use in Colombian schools to improve the mental health, resilience, and quality of life of adolescents in post-conflict Colombia during the COVID-19 pandemic.\nPeople living in challenged humanitarian settings such as displaced people, refugees, and those living in conflict/post-conflict situations are at greater risk of mental health difficulties. For children in these settings, their caregivers act as their main protective factors.\nThe Strong Families program was developed specifically for use in low resource settings and was piloted in families living in Afghanistan. The results suggested that this program was effective and feasible in a resource-limited setting and improved child mental health, parenting practices, and family adjustment skills. The effectiveness and acceptability of the Strong Families intervention is now also being evaluated in families living in Iran.\nDue to ongoing political and social conflicts, the number of international refugees has been increasing. Refugees are exposed to severe mental challenges and potentially subject to traumatic experiences so the risk of psychiatric disorders is increased. The REMEX study is investigating the effects of an exercise and sport intervention among refugees living in a Greek refugee camp on mental health.\nOlder people and immigrant groups are both thought to be more likely to experience social isolation and loneliness which can cause worse mental wellbeing. A peer-based intervention using home visits and telephone calls from volunteers to provide emotional support, problem-solving support, and community resource sharing was developed to reduce the social isolation of older Chinese immigrants in Canada.\nThe results of this trial suggested a decrease in loneliness and an increase in resilience in the older people who received the intervention as well as fewer barriers to social participation, fewer depressive symptoms, increased life satisfaction, and happiness.\nSocietal discrimination is likely to have an impact on mental health. Interventions that take into account the specific mental health risks that marginalised communities face, and are designed to meet the needs of these groups, are therefore needed. The Rainbow Mind study uses one such intervention of mindfulness and compassion-based self-care which has been designed for the LGBTQIA+ community in the UK. Additionally, cultural background may play a role in a person’s beliefs about mental illness, their experience of mental illness, and the efficacy of treatment. Researchers are investigating approaches that address this, for example in the ECAT-D trial which aims to evaluate a culturally adapted faith-based treatment approach for Muslim clients with depression in Bradford.\nSimilarly, there are significant mental health related inequalities for the UK Black community as people from Black African and Caribbean backgrounds are four times more likely to be detained under the Mental Health Act, and experience poorer treatment and recovery outcomes in comparison to other ethnic groups. The ON TRAC project aims to address this by developing a mental health awareness and stigma reduction intervention for Black faith communities.\nAccess to mental health care and support is as crucial as ever during the COVID-19 pandemic. The COVID-19 pandemic has highlighted the effects of inequality on health outcomes and has brought additional mental health challenges through infection and illness, bereavement, job loss and insecurity, and social isolation due to physical distancing measures. The COVID-19 pandemic has also led to an increase in using remote methods to deliver care which could allow patients greater access to information and additional support between appointments, but in some resource-limited settings may not be accessible to participants.\nA collection of research compiled by Springer Nature to commemorate World Mental Health Day 2021 can be found on our landing page. You can also find out more about the UN’s sustainable development goals and what we are doing at Springer Nature to support these goals.']"	['<urn:uuid:86dcc2dc-07a5-4a17-9571-eaf4867a4a36>', '<urn:uuid:94af8836-63d1-4932-8987-4d1937bc3b3d>']	factoid	direct	long-search-query	similar-to-document	multi-aspect	novice	2025-05-01T23:46:40.222380	19	73	3887
410	How many protons are needed to make one ATP?	In E. coli, 4 protons are required to generate each ATP molecule. This ratio is calculated from the 12 protons needed for one complete rotation of the c ring rotor, which produces 3 ATP molecules per rotation.	"['The dephosphorylation of adenosine triphosphate (ATP) provides energy for many biochemical reactions. ATP is primarily produced by the enzyme ATP Synthase (ADP + Pi ---> ATP). F-ATP Synthases are found in the inner mitochondrial membranes and the chloroplast thylakoid membranes of eukaryotes, as well as in prokaryotic plasma membranes. ATP synthases are an ancient family of proteins that are highly conserved throughout all kingdoms of life. ATP Synthase functions similarly to the turbines of hydroelectric plants that utilize the kinetic energy of water that flows through dams. In this analogy, a proton gradient is likened to dammed water, and the flow of protons down the gradient is like water driving the turbines of a hydroelectric engine. Like hydroelectric turbines, ATP synthase components rotate in response to the proton flow, and this rotational energy is then coupled to ATP synthesis. These amazing enzymes thus function as molecular engines that harness the energy derived from proton flow to drive phosphorylation of ADP, producing ATP that can be utilized by any number of enzymes to facilitate catalysis of particular biochemical reactions.\nThe F-ATP Synthase includes the Fo rotary motor complex embedded in the membrane, the F1 catalytic complex that synthesizes ATP, and a Stator that connects them and which prevents rotation of the catalytic subunits. The central stalk (axle) is considered part of F1, and its rotation is coupled to that of the membrane rotor (see Figure 1). The Fo rotor spins in response to proton (H+) flow down a concentration gradient across the membrane. This rotation causes the central stalk (axle) to rotate, altering the conformation of components of the F1 base, driving the synthesis of ATP. The synthase can also act as an H+ pump ATPase when its rotations are reversed by ATP hydrolysis.\nShown at left is a partial structure of yeast mitochondrial ATP Synthase with orientation, arrows, and labels corresponding to those of Figure 1 (Dautant, et al., 2010, unpublished -see PDB entry 2WPD). The elegant structure of this molecule allows it to perform its remarkable functions. To understand the functional details linking proton flow, rotation of Fo, and synthesis of ATP by F1, it will be useful to consider the Fo and F1 complexes individually, using the structure of bacterial (E. coli) complexes of Fo as determined by Rastogi and Girvin (1999) and the structure of bovine F1 complexes as determined by Gibbons et al. (2000).\nII. Fo Structure and Function Links Proton Flow to the Fo Rotor\nIn bacteria, the Fo complex contains the subunits a, b and c, in a ratio of 1a:2b:c10-15. The number of c subunits are fixed within a species, but are variable among different species.\nNote: Unless otherwise stated, in the following representations the Fo complex will be either be oriented as in Figure 1, above (sideview), or in a top down view (above the membrane), looking through the Fo channel towards the central stalk and F1 complex.\nIn E. coli, Fo consists of an a subunit, a b Stator unit (not shown), and a ring of 12 identical c subunits. The c ring of Fo rotates, while the other components of the complex do not.\nEach c subunit is a helix-loop-helix, comprising a C-terminal alpha helix and an N-terminal helix. These two helices each span the membrane. Each C-terminal helix contains the important acidic amino acid, Aspartate 61. This residue\'s sidechain, capable of protonation and deprotonation, plays a major role in the rotation of the c ring. As can be seen, only two of the c ring\'s C-terminal alpha helices are in close proximity to the a subunit at any one time. These features are important and will be discussed below.\nThe a subunit contains 4 helices. The helix closest to the c ring contains the basic amino acid, Arginine 210. The sidechain of Arg 210 and other residues provide a hydorophillic environment that promotes the deprotenation of Asp 61 as its helix rotates to contact the a subunit. Note: in this top down view, rotation of the c ring is in the clockwise direction. Deprotenation of Asp 61 causes a profound change in the conformation of the C-terminal helix of the deprotonated subunit: it twists along its axis ~140o relative to the N-terminal helix.\nThe twisting of the C terminal helix in response to deprotenation of Asp 61 can be visualized in a morphed simulation using single NMR structures of protonated and deprotonated c subunits (Rastogi and Girvin,1999) as starting and ending points.This PDB file for this simulation was generated using the Yale Morph Server at the Database of Macromolecular Movements, maintained by the Gerstein lab.\nThe twisting of the C terminal helix just described suggests a model in which local rotation of a single c subunit is a major physical force that spins the entire ring, as in a ""wheels within wheels"" type of mechanism (Rastogi and Girvin,1999). This rotational process of Fo can be visualized in an animation provided by the Girven lab.\nIt is now useful to consider the protonation state of the 12 c subunits in the c ring of Fo. As can be seen, only the Asp 61 of the C-terminal helix that has just rotated into the vicinity of the a subunit\'s Arginine 210 is in a deprotonated state. The remaining 11 Asp 61s in the other C-terminal helices are protonated. Careful inspection shows that only theC-terminal helix containing the deprotonated Asp 61 is in the twisted (deprotonated) conformation. This has an important consequence for the directional rotation of the c ring. Since the deprotonated Asp 61 is negatively charged, counterclockwise rotation of the c ring is thermodynamically unfavorable, since this would place the deprotonated Asp 61 in the hydrophobic environment of the membrane. Clockwise rotation of the ring is favored, however, as the Asp 61 would still be in the hydrophillic vicinity of Arg 210 and other residues of the a subunit.This position allows it to be reprotonated and enter the membrane environment as the c ring spins in the clockwise direction.\nNote that as the Fo c ring rotates, the Fo a subunit remains stationary.\nA side view through a translucently rendered a subunit shows its association with the C-terminal helix containing the deprotonated Asp 61 and the C-terminal helix containing the newly reprotonated Asp 61. The the remaining C-terminal helices are exposed to the hydrophobic membrane. The Arg 210 of the a subunit is seen to reside btween the deprotonated and reprotonated Aspartates.\nThe structure of Fo facilitates the flow of H+ ions down the proton concentration gradient by providing two half-channels for this flow, an entry and an exit channel. These can be visualized in a side view of the c ring through the translucently rendered a subunit:\nThe elegant mechanism for converting the electrical energy of the proton gradient into rotary (kinetic) energy of c ring spinning may be summarized by following the journey of a proton as it flows across the membrane through Fo:\nThe E. coli Fo c ring just described has 12 c subunits. Thus, each proton that moves through Fo rotates the ring in 30o steps relative to the stationary components of ATP synthase (12 c\'s x 30o = 360o).\nIn the next section we will consider how the rotary motion of the Fo c ring powers ATP synthesis in the F1 complex.\nIII. F1 Structure and Function\nShown at left is the F1 complex of the F-ATP synthase from bovine heart mitochondria, oriented with the top pointing toward the membrane bound Fo complex described above (not shown). Also shown is the central stalk (axle), which is linked to the Fo c ring above, and which therefore rotates with that ring. The catalytic F1 complex lies below the central stalk. Unlike the stalk, the catalytic complex is fixed and is prevented from rotating by its binding to the Stator mentioned previously (not shown), which connects to the stationary Fo a subunit (see Figure 1).\nThe central stalk contains the gamma, delta, and epsilon subunits. The catalytic complex is a hexamer alternately packed with three alpha subunits and three beta subunits. Although all subunits of the catalytic complex bind to nucleotides, only the beta subunits are capable of catalyzing the phosphorylation of ADP to produce ATP. The gamma subunit of the stalk is observed to penetrate deep within the catalytic complex, where it engages the beta subunits.\nKeeping in mind the structural features of F1 just presented, it is now possible to understand the Binding-Change Model that explains how the rotational energy of the central stalk is transduced into the production of ATP. In this model, the gamma subunit of the central stalk sequentially engages the beta subunits of F1 as it rotates in sync with the Fo rotor. This interaction induces conformational changes that drive the release of ATP from these catalytic subunits. Each stationary beta subunit transitions between three conformations.\nThe three conformers of the beta subunits are LOOSE, TIGHT, and OPEN and each beta subunit cycles sequentially between them (L --> T--> O), the cycles being orchestrated by the rotating gamma subunit of the central stalk. The LOOSE conformation permits the loose binding of ADP and Pi substrates, but ATP catalysis does not occur until the beta subunit transitions to the TIGHT conformation. The TIGHT conformation produces ATP (ADP + Pi ---> ATP) but is incapable of releasing this catalytic product. Only when the TIGHT to OPEN conformational change is induced can the beta subunit release ATP. The perspective here is from the bottom of the ATP Synthase, looking up toward the membrane. In this bottom-up view, the rotation of the central stalk gamma subunit is counterclockwise. With each rotation of 120o, the gamma subunit engages a stationary beta catalytic subunit, changing its conformational state as described. The result is the production and release of ATP by F1.\nRemembering that each 360o rotation of the Fo rotor is linked to a 360o rotation of the central stalk, a simple calculation reveals the stoichiometry of H+ translocation through Fo and ATP production by F1. If there are 12 c subunits in the c ring of Fo (each carrying a proton), and each 360o rotation of the gamma subunit of the central stalk produces 3 ATPs (one for each F1 beta subunit), then the transport of 4 protons are required to generate every ATP (12 protons/rotation of the c ring rotor / 3 ATPs/rotation of the central stalk). Of course, this ratio depends upon the number of c subunits in the Fo rotor, which can vary depending on the ATP Synthase under consideration.\nClearly, understanding the structure-function relationships of ATP Synthase gives one a deep appreciation of the power of natural selection in fashioning amazing biomolecular machines!\nGibbons, C.; et. All. The Structure of the Central Stock in Bovine F1-ATPase at 2.4 Å resolution. Nature Structural Biology. 2000 Nov;7(11):1002-4.\nRastogi, V.K.; Girvin, M. Structural Changes Linked to Proton translocation by Subunit C of the ATP Synthase. Nature. 1999 Nov 18;402(6759):247, 249.\nLeslie, A.G and Walker, J.E.. Molecular architecture of the\nrotary motor in ATP synthase. Science. 1999 Nov 26;286(5445):1700-5.\nThe format of this web page is modified from a template provided by Dr.\nAngel Herraez, Bioquimica y Biologia Molecular, Universidad de Alcala, E-28871,\nAlcala de Henares (Madrid), Spain.']"	['<urn:uuid:7cb901fe-aa1f-48dc-9759-a718ed10b268>']	factoid	direct	concise-and-natural	distant-from-document	single-doc	expert	2025-05-01T23:46:40.222380	9	37	1873
411	As a maritime archaeologist studying recovery techniques through history, I'm curious how the excavation approaches differed between the Antikythera wreck and the Mary Rose - what can we learn about the artifacts and human remains recovered from each?	The Antikythera wreck has seen multiple excavation phases - first by sponge divers in 1900 who recovered marble statues and the famous Antikythera Mechanism, then by Jacques-Yves Cousteau in 1976 who recovered 300 objects and some skeletal remains, and most recently by modern archaeologists who found additional human remains in good condition despite being underwater for 2,000 years. Modern techniques include 3D imaging to share findings without surface recovery. For the Mary Rose, excavations revealed detailed information about the crew's final moments through the positioning of skeletons, showing how men were trapped by collapsed equipment like the galley's brick oven, a 360-liter copper cauldron, and heavy guns that came loose. The remains also showed how sailors were trapped under anti-boarding netting while trying to escape.	"['An international team of archaeologists excavating the famous Antikythera shipwreck in the Aegean Sea off the coast of Greece have found the remains of a human skeleton among the 2,100-year-old wreckage.\nIf they can extract DNA from the bones, it\'ll help us understand more about the passengers on board the ship when it sank around 65 BC – and could provide vital insight into the mysterious Antikythera Mechanism it was carrying, better known as the world’s first computer.\n""Archaeologists study the human past through the objects our ancestors created,"" said team member Brendan Foley, from the Woods Hole Oceanographic Institution (WHOI) in the US.\n""With the Antikythera Shipwreck, we can now connect directly with this person who sailed and died aboard the Antikythera ship.""\nIn case you’re unfamiliar, the Antikythera shipwreck – which was originally discovered by sponge divers in 1900 – is the largest ancient shipwreck ever found.\nDuring the first excavation by the sponge divers, they managed to pull up a series of marble statues and thousands of other sea-battered artefacts.\nAmong the random assortment of things was the Antikythera Mechanism, a clockwork device that might have been used to predict astronomical events and is widely referred to as the world’s first analogue computer.\nResearchers have dated the device to around 100 or 150 BC, which means that – after it sank – similar technology didn’t pop up around the world until at least the 14th century AD, which makes the device all the more fascinating.\nIn 1976, famed ocean explorer Jacques-Yves Cousteau and his crew returned to wreckage after it laid untouched for nearly 80 years. They were able to pull up some 300 objects, including skeletal remains, though DNA technology wasn\'t available back then to fully analyse them.\nNow, a new team – consisting of researchers from WHOI and the Hellenic Ministry of Culture and Sports – has uncovered more remains beneath shards of pottery, and this time they hope to shed new light on who was on board the ill-fated ship, where they were from, and where they might have been going.\nThe newly found remains were pulled up on 31 August and – after they get released by the Greek government – will be sent to researchers at the Natural History Museum of Denmark in Copenhagen for further analysis.\n""Against all odds, the bones survived over 2,000 years at the bottom of the sea and they appear to be in fairly good condition, which is incredible,"" said DNA expert Hannes Schroeder, from Natural History Museum of Denmark.\nIn addition to finding these incredible remains, the archaeologists working at the site have also started to use 3D imaging to instantly share their findings with other researchers – and the public, too – without even having to pull them to the surface.\nWe\'re still waiting on a peer-reviewed paper to be published about the new find, so right now we\'re taking the researchers\' words for it, but we imagine they\'re going to hold off writing anything up until they have the DNA analysis results.\nThat said, there\'s no guarantee DNA sequencing will work on a skeleton of this age – especially one that\'s been at the bottom of the sea for millennia – but if it does, we could finally have more information on one of the oldest, largest, and most mysterious shipwrecks ever to be found.\nWe love how excited the archaeologists were when they first spotted the remains. We\'re right there with you, guys.', 'Wreck of the Mary Rose\nThe Mary Rose was one of the earliest ships to carry heavy guns.\nShe was a favourite of King Henry VIII and sank off Portsmouth in 1545 during an engagement with a French invasion fleet, in full view of the King, the screams of the men onboard, ringing in his ears.\nOn 19 July 1545, the French galleys advanced on the immobilised English fleet, and initially threatened to destroy a force of 13 small galleys, or ""rowbarges"", the only ships that were able to move against them without a wind. The wind picked up and the sailing ships were able to go on the offensive before the oared vessels were overwhelmed. Two of the largest ships, the Henry Grace Dieu and the Mary Rose, led the attack on the French galleys in the Solent, but early in the battle something went wrong. While engaging the French galleys she suddenly heeled (leaned) heavily over to her starboard (right) side and water rushed in through the open gunports. The crew was powerless to correct the sudden imbalance, and could only scramble for the safety of the upper deck as the ship began to sink rapidly. As she leaned over, equipment, ammunition, supplies and storage containers shifted and came loose, adding to the general chaos. The massive port side brick oven in the galley collapsed completely and the huge 360 litre (90 gallon) copper cauldron was thrown onto the orlop deck above. Heavy guns came free and slammed into the opposite side, impeding escape or crushing men beneath them. For those who were not injured or killed outright by moving objects, there was little time to reach safety, especially for the men who were manning the guns on the main deck or fetching ammunition and supplies in the hold. The companionways that connected the decks with one another would have become bottlenecks for fleeing men, something indicated by the positioning of many of the skeletons recovered from the wreck. What turned the sinking into a major tragedy in terms of lives lost was the anti-boarding netting that covered the upper decks in the waist (the mid-section of the ship) and the sterncastle. With the exception of the men who were stationed in the tops in the masts, most of those who managed to get up from below deck were trapped under the netting; they would have been in view of the surface, and their colleagues above, but with little or no chance to break through, and were dragged down with the ship. Out of a crew of at least 400, fewer than 35 escaped, a catastrophic casualty rate of over 90%.\nOwing to this indiscipline, he [Sir Peter Carew] records that the Mary Rose sank with the loss of nearly 700 men. This figure for the complement is extremely unlikely, no other reference gives such a number, and it seems very likely that the Mary Rose was carrying her normal crew of between four and five hundred men when she sank. Neither the vice-admiral, or the captain, Roger Grenville, were among the survivors. Poor Carew got a rather cursory obituary in a letter from Harvel to Paget in September.']"	['<urn:uuid:1baaeeb3-bad1-4304-84e6-15c58b6cf5b9>', '<urn:uuid:3c5540a2-e57c-4872-a247-6af7fafe05d7>']	open-ended	with-premise	verbose-and-natural	distant-from-document	comparison	expert	2025-05-01T23:46:40.222380	38	125	1111
413	eagle scout project approval steps needed	Before beginning an Eagle Scout Leadership Service Project, a Scout must submit a written plan using the BSA Eagle Scout Leadership Service Project Workbook. This plan requires pre-approval from multiple parties: the benefiting organization, the Scout Leader, the unit committee, and a district representative. After completion, the Scout must update the workbook to document how they demonstrated leadership, any plan changes, and the project's community benefits.	"['- Eagle Scout Leadership Service Project\nThe Eagle Scout Leadership Service Project, known as the Eagle Scout Project or more simply as the Eagle Project, is the opportunity for a\nScoutin the Boy Scouts of America(BSA) to demonstrate leadershipof others while performing a project for the benefit of his community. This is the culmination of the Eagle Scout candidate\'s leadership training, and it requires a significant effort on his part. [cite web | last = | first = | authorlink = | coauthors = | year = | url =http://www.nesa.org/trail/manual.html | title =Eagle Scout Service Project How-to Manual | format = DOC, RTF, or PDF| work =Trail to Eagle | publisher =National Eagle Scout Association | accessdate = 2007-07-26] The project must benefit an organization other than the BSA, but it cannot be performed for an individualor a business, be solely a fundraisingproject, or be commercial in nature.\nA written plan must be submitted using the BSA Eagle Scout Leadership Service Project Workbook and be pre-approved by the benefiting organization, the\nScout Leader, the unit committee, and a district representative, before work on the project can begin. After the project is complete, the Scout will update the workbook where he will discuss the methods in which he gave leadership, ways in which the plan may have had to change and the benefits of the project to the community.\nExamples of Eagle Scout service projects include: constructing\nparkbenches, running a blood drive, constructing a playground, building bat houses for a local park, refurbishing a room at a churchor school, resetting stones at a cemetery, planting grassfor erosioncontrol, or organizing a dinnerand collecting necessities for the homeless. [ [http://www.dosomething.org/node/43610 Do Something | Eagle Scout Leadership Service Project ] ]\nThe merit badges required for Eagle have been a requirement since the inception of the award. A Scout\'s ""record of satisfactory service"" with his troop was first added to the Eagle requirements in 1927. This changed in 1952 to ""do your best to help in your home, school, church or synagogue, and community."" This vague statement was refined to ""plan, develop, and carry out a service project"" in 1965. . In 1972 a leadership component ""give leadership to others"" was added. cite news | first= Robert | last= Peterson| url= http://www.scoutingmagazine.org/issues/0211/d-wwas.html | title= The Way It Was: Evolution of the Eagle Scout Award | publisher=Scouting | date= November - December 2002]\nThe idea for a project may be an original one or one already done by someone else. In either case, the Scout must plan, develop, and lead others in doing the project. There is no numerical minimum amount of time or requirement for the length of time in which the project needs to be completed, but that it be enough to ""demonstrate leadership. cite news | first= Robert | last= Peterson| url= http://www.scoutingmagazine.org/issues/0003/a-trae.html | title= Last Step on the Trail to Eagle | publisher=Scouting | date= March-April 2000] The exact implementation of requirements varies among different districts and councils.\nThe rigorous nature of the required service project is a major step in the completion of the Eagle rank. Very often, the Eagle Project is what highlights the full impact of the Scouting program to the community at-large. [cite web | last =Elson | first = Martha | authorlink = | coauthors = | date= 2008-01-28 | url = http://www.courier-journal.com/apps/pbcs.dll/article?AID=/20080126/NEWS01/801260442/1008| title = Blind-school Scout earns Eagle rank | format =| work = | publisher =\nThe Courier-Journal| accessdate = 2008-01-29] cite news | first= Julia | last= Campbell | url= http://www.hvjournal.com/articles.php?id=2209 | title= Eagle Scout Project to Preserve HHS History | publisher= Hurricane Valley Journal| date= 2005-09-21] cite web | first= Jennae | last= Phillippe | url= http://www.scvhistory.com/scvhistory/sg072601.htm | title= Eagle Scout project makes local history | publisher= Santa Clarita Valley Historical Society| accessdate=2007-04-09]\nEagle Scout (Boy Scouts of America)\nAdvancement and recognition in the Boy Scouts of America\n*cite web | last = | first = | authorlink = | coauthors = | year = | url = http://www.nesa.org | title = National Eagle Scout Association | format = HTML | work = | publisher = | accessdate =\n*cite web | last = | first = | authorlink = | coauthors = | year = | url = http://members.cox.net/scouting179/EagleProjectPacket.rtf | title = Eagle Scout Leadership Service Project Workbook | format = RTF | work = | publisher = | accessdate = 2006-06-19\n*cite web | last = | first = | authorlink = | coauthors = | year = | url = http://www.troop97.net/pdfbin/eagle_app.pdf | title = Eagle Rank Application (for after project is finished) | format = PDF | work = | publisher = | accessdate =\n*cite web | last = | first = | authorlink = | coauthors = | year = | url = http://members.cox.net/scouting179/Eagle%20Distinguished.htm | title = Distinguished Eagle Scouts | format = | work = Troop and Pack 179 | publisher = | accessdate = 2006-06-08\n*cite web | last = | first = | authorlink = | coauthors = | year = | url =http://usscouts.org/eagle.asp | title =Eagle Scouts | format = | work = | publisher =U.S. Scouting Service Project | accessdate = 2006-06-08\n*cite web | last = Smith | first = Randy | authorlink = | coauthors = | year = | url = http://www.flash.net/~smithrc/eagleprj.htm | title = Eagle Scout Leadership Service Project Planning Guide | format = | work = Unofficial, but very helpful guide to planning and carrying out the project | publisher = | accessdate =\n*cite web | last = Everette | first = Randy | authorlink = | coauthors = Kathy Lull | year = 2005 | url = http://members.cox.net/scouting179/Eagle%20Scout%20Resource%20Package.doc | title = Eagle Scout Resource Package | format =DOC | work = An Aide for Life Scouts and Eagle Candidates | publisher = | accessdate = 2006-06-14\nWikimedia Foundation. 2010.']"	['<urn:uuid:f990ce4a-ca37-4772-87dd-2086a6a0d3af>']	open-ended	with-premise	short-search-query	distant-from-document	single-doc	expert	2025-05-01T23:46:40.222380	6	66	974
414	How can Tunisian crochet be worked flat versus in the round?	Tunisian crochet is typically worked flat due to its two-step process of loading loops and working them off. For working in the round, one method uses a double-ended hook with two strands of yarn working in a spiral. Another technique involves using a cabled hook and creating joining loops during the return pass by wrapping yarn around the cable. While flat work is more common and can be seamed later, working in the round can create seamless pieces but may show some gapping at the join point with certain stitches.	['Hey, everyone! This year I’ve decided to make some tutorials for Tunisian crochet. I have fallen in love with Tunisian crochet. It’s so quick and easy to make pieces that look like you spent days knitting them in only a few hours. If you’re like me and love the look of knitting, but don’t actually like knitting, Tunisian crochet is for you!\nIn this tutorial I want to go over the basics of Tunisian crochet. We’ll learn how to make a foundation row and how to do the Tunisian simple stitch (TSS). These are the basic skills you’ll need to make your first Tunisian crochet project.\nTunisian crochet hooks are different from regular crochet hooks. In Tunisian crochet, much like knitting, you’ll pull up several loops on your hook before you finish your stitches. A Tunisian crochet hook is longer than a regular hook, it can be solid like knitting needle, or look like a regular crochet hook with a long cord attached. Both types of Tunisian crochet hooks will have a stopper at the end to prevent the stitches from falling off.\nHere is the exact set of hooks I use for my Tunisian crochet. I have two sets so that I can turn them into double ended hooks for Tunisian crochet in the round.\nKnitter’s Pride Bamboo Interchangeable Tunisian Crochet Hook Set\nCREATING YOUR FOUNDATION ROW\nAs with regular crochet, in order to start most Tunisian crochet projects you will need to make a foundation chain. Unlike regular crochet, we will be working into the back bump of our foundation chain. If you look at the back of your chains, you will see each chain has a bump in the center that your hook can be inserted into, that is where we’ll be working.\nThere are generally two steps to complete Tunisian crochet stitches, the forward pass and the return pass. The forward pass is the first part of making stitches. In this step you will pull up multiple loops on your hook, like you would with knitting. To make our first forward pass insert your hook into the first chain bump and pull up a loop. Instead of yarning over and making a single crochet, like with regular crochet, we’re going to move into the next bump, insert our hook, and pull up another loop. You will need to do that for each chain bump. By the end of the row, you should have the same number of loops on your hook as you had chains to start with. If you started with 10 chains, you should end up with 10 loops on your hook.\nNext, we need to do our return pass. This is where we pull the yarn through the loops to complete the stitches. For the first stitch of your return pass, yarn over and pull through ONE loop. The first stitch of each return pass will always only pull through one loop. For every remaining loop, yarn over and pull through TWO loops. Repeat yarning over and pulling through two loops until you reach the end of the row. Once you’ve reached the end of the row, your foundation row is complete!\nTUNISIAN SIMPLE STITCH (TSS)\nMaking a Tunisian simple stitch is very similar to making your foundation row. If you look at your foundation row, you’ll notice each stitch has a post that connects the rows together, we need to work into the front loop of that post.\nPut your hook through the front post of the second stitch from the hook and pull up a loop (the loop currently on your hook counts as the first stitch for that row). Pull up one loop through the front loop of every post for the row. When you get to the last stitch in the row, there will be no post. Pull out the stitch and you’ll notice a space, that is where we’ll pull up a loop for the last stitch.\nOnce you have pulled up loops through all of the stitches, you can begin your return pass. Remember, the first stitch of the return pass only pulls through one loop, then every subsequent stitch will pull through two loops. Once you reach the end of the row, you’re done with your first row of Tunisian simple stitches. You can repeat this process as many times as you want until your work is as long as you’d like it. When you’re ready to finish off, simply chain one like you would with any regular crochet project!', 'Creating Tunisian puffs, bobbles and popcorns is relatively straight forward. They are an easy way to create texture in Tunisian Crochet. These three stitches all stand off the fabric, but vary in size.\nEssentially this is an approach of working standard crochet within Tunisian. Working the texture stitches on the forward pass.\nTo work a Tunisian Puff Stitch yarn over, insert the hook into the stitch and yarn over and pull through a loop. This is basically working a yarn over before pulling up the loop of whatever Tunisian stitch you are working. (All the photo samples are worked with Tunisian Simple Stitch). Repeat this same technique multiple times in the same space. The last step is to yarn over and pull through all the loops you have worked in this stitch (including the first yarn over).\nCreating a Tunisian Bobble stitch requires a yarn over, insert hook into stitch, yarn over pull up a loop, yarn over and pull through 2 loop. This is much like many incomplete double crochet stitches. The techniques is repeated until the bobble is the desired size, and completed with a yarn over and pull through of all the partially completed stitches in the Tunisian stitch.\nCheck out the traditional crochet Bobble stitch for a comparison.\nWorking a Tunisian Popcorn stitch, as you might expect is like working a traditional crochet Popcorn. However there is a slight difference. Start with a yarn over, and insert the hook into the stitch, yarn over and pull up a loop, yarn over and pull through 2 loops. Repeat this step one more time, then yarn over and pull through the last 3 loops on the hook. (The reason for this is that Tunisian does not typically complete stitches in the forward pass, as such the next adjacent loop on the hook is the loop of the previous stitch). This will complete 2 double crochet stitches together. Work a few more double crochets in this stitch, remove hook from last loop of completed double crochet, insert hook into the top of the 2 double crochets worked together, and pull the loop through.\nAll return passes are worked the same, and the stitches are all pushed toward the front of the fabric. Notice that the texture lines up with the vertical lines of the Simple stitch in the photos. This helps to easily see where the stitches are located.\nTunisian Crochet is a technique that always has something bold to offer. It seems to be a bit cyclical in the design world, making a splash every few years. With every splash creating a great surge in creativity, and the new digital release of The Tunisian Collect from I Like Crochet Magazine is no exception.\nI am fortunate enough to have 2 designs in this publication.\nA Teenager Loved Pillow\nThe Cozy At Home Tunisian Tassel Pillow is one that my teenage son liked enough that he had me make some for his room (this is always a huge reward for my work…that the kids actually like it). It really only uses two Tunisian stitches, a Simple Stitch and a Purl Stitch to create this visual effect. In addition it uses a large hook size, so it works up pretty quickly.\nI like the edging that seams the two sides as you work it,\nand the tassels were a definite highlight for my son, so maybe it is a new\nThis pattern though has a little twist, it is worked in the\nround. Working in the round is not something that is commonly worked in Tunisian\ncrochet, as it is a technique worked by loading up loops on the hook and then\nworking it back off. So you never turn the work, and it is easiest to work flat.\nTo help you celebrate\nNational Crochet Month, I am sharing a technique to help advance your crochet\nskills, and including a free pattern. Today I am sharing how to work Short\nRows, in both traditional and Tunisian Crochet.\nFirst, I would like to thank Crochetville for including me in they blog tour for\nthis month long celebration. Everyday you are introduced to a new designer, or\nhobbyist or teacher, to help inspire a new desire of crochet within you. Don’t\nmiss a day, check out the participants here.\nThere are some terms that can be a bit intimidating the\nfiber arts, short rows can be one of them. However, they really are quite\nWhat Makes it Special\nLearning how to work short rows in crochet will help expand\ncrochet skills by adding subtle shaping in garments and the ability to create\ndramatic effects in just about any work you wish.\nA short row is exactly as it sounds, you work your row\nshort. Meaning you do not finish the row.\nSometimes this is worked by tapering the stitch height, by\nworking shorter and shorter stitches until they are near a slip stitch. The\nwork is turned, and possibly started by tapering the stich height upward, it is\nWorking As A Dart\nIn the case of using short rows as is seen in sewing as if a\ndart, or a point in fabric, you work un-worked stitches. The next row works to\nthe point where two rows below the row was worked short, then it continues to\nthe remained of the stitches not worked three rows below.\nMaking A Wedge…\nIn the case of making a triangular shape, a multiple of\nshort rows are worked, so that there are fewer stiches in each row. I often use\nthis approach in creating shawls, essentially creating triangular wedges that I\nthen build atop one another.\nIt is this last approach that I also use to create\nwashcloths and potholders. I create “wedges” of triangles that work on one\nanother to eventually create a circle.\nStarting Your Circle\nUsing any yarn, with a comparable size hook, these patterns are great for scrap yarns. You can adjust the size by adjusting the number of beginning chains as the foundation. Just remember that this is only half the size of the finished product, and you will remove one stitch per row on the same edge of the fabric. It can be used utilizing either traditional crochet or Tunisian, and I share a quick pattern for both below.\nShort Row Washcloth/Potholder\nRow 1: Ch 16, sc in 2nd ch from hook, sc in each ch across, turn. -15 sc\nRow 2: Sl st in same st, sl st in next st, ch 1, sc in same st, sc in each st across, turn. -14 sc\nRow 3: Ch 1, sc in same st, sc in next 12 sts, leaving last st unworked, turn. -13sc\nRow 4: Sl st in same st, sl st in next st, ch 1, sc in same st, sc in each st across, turn. -12 sc\nYou Should Start Seeing the “Stair Stepping”\nRow 5: Ch 1, sc in same st, sc in next 10 sts, leaving last st unworked, turn. -11sc\nRow 6: Sl st in same st, sl st in next st, ch 1, sc in same st, sc in each st across, turn. -10 sc\nRow 7: Ch 1, sc in same st, sc in next 8 sts, leaving last st unworked, turn. -9sc\nRow 8: Sl st in same st, sl st in next st, ch 1, sc in same st, sc in each st across, turn. -8 sc\nOver Halfway on the First Wedge….\nRow 9: Ch 1, sc in same st, sc in next 6 sts, leaving last st unworked, turn. -7sc\nRow 10: Sl st in same st, sl st in next st, ch 1, sc in same st, sc in each st across, turn. -6 sc\nRow 11: Ch 1, sc in same st, sc in next 4 sts, leaving last st unworked, turn. -5sc\nRow 12: Sl st in same st, sl st in next st, ch 1, sc in same st, sc in each st across, turn. -4 sc\nRow 13: Ch 1, sc in same st, sc in next 2 sts, leaving last st unworked, turn. -3sc\nRow 14: Sl st in same st, sl st in next st, ch 1, sc in same st, sc in each st across, turn. -2 sc\nRow 15: Ch 1, sc in same st, turn. -1 sc\nRow 16: Sl st in same st, turn.\nRow 17: Ch 1, sc in same st, sc in the edge stitch of Rows 15-1 (essentially either the stitch skipped in a row, or the slip stitch after the row is turned), turn. -15 sc\nRow 18-32: Rep Rows 2 through 16 of wedge 1.\nRepeat Second Wedge.\nSeam Wedge 1 to Wedge 8.\nTunisian Short Row Washcloth/Potholder\nThese same principals apply to Tunisian crochet as well.\nRow 1: Ch 15, pick up loops in each ch across. RP. -15 sts\nRow 2: Tss in next 13 sts, leaving last st unworked. RP. -14 tss\nRow 3: Tss in next 12 sts, leaving last st unworked. RP. -13 tss\nRow 4: Tss in next 11 sts, leaving last st unworked. RP. -12 tss\nStill not working the last stitch…\nRow 5: Tss in next 10 sts, leaving last st unworked. RP. -11 tss\nRow 6: Tss in next 9 sts, leaving last st unworked. RP. -10 tss\nRow 7: Tss in next 8 sts, leaving last st unworked. RP. -9 tss\nRow 8: Tss in next 7 sts, leaving last st unworked. RP. -8 tss\nAre you seeing the angle?\nRow 9: Tss in next 6 sts, leaving last st unworked. RP. -7 tss\nRow 10: Tss in next 5 sts, leaving last st unworked. RP. -6 tss\nRow 11: Tss in next 4 sts, leaving last st unworked. RP. -5 tss\nRow 12: Tss in next 3 sts, leaving last st unworked. RP. -4 tss\nAlmost finished the first wedge…\nRow 13: Tss in next 2 sts, leaving last st unworked. RP. -3 tss\nRow 14: Tss in next 1 st, leaving last st unworked. RP. -2 tss\nRow 15: Tss in same st, leaving last st unworked. RP. -1 tss\nRow 16: Pick up loops in each unworked stitch of rows below. RP.-15tss\nTo help you celebrate National Crochet Month, I am sharing a technique to help advance your crochet skills, and including a free pattern. Today I am sharing how to work Tunisian Crochet in the Round.\nFirst, I would like to thank Crochetville for including me in they blog tour for this month long celebration. Everyday you are introduced to a new designer, or hobbyist or teacher, to help inspire a new desire of crochet within you. Don’t miss a day, check out the participants here.\nWhat Makes this Special\nTunisian crochet is an interesting technique that produces a\nfabric that can look woven, or even knitted. It is worked with in a two-step\nprocess. The first step is to load up the hook with loops (Forward Pass), like\ncasting on in knitting, the second step is working all the loops off until only\none remains (Return Pass).\nHere is One Option\nThis back and for of the two-steps, actually can make it a\nbit challenging to work the fabric in the round, so often it is worked flat and\nthen seamed. However, there are a couple of different approaches to working in\nthe round. One is to work with a double ended crochet hook, so you can load\nfrom one end and work off the loops with the other. This process works the\npiece in a spiral and two strands of yarn, it looks nice, but finding double\nended hooks is not exactly an easy task.\nThe Option I like\nThe method I employ more is one that I discovered from Jennifer Hanson, the Stitch Diva. It is a Tunisian Loop Return Pass. It involves using a cabled Tunisian hook, and adding joining loops to the fabric while working the Return Pass. I have tweaked it a bit from what Jennifer has in her video, as it works for me. So let me share my tweaked version.\nHow to Make it Work\nAfter you have completed the Forward Pass of a Round, fold the\ncable of the hook so that the end is next to the hook, the next step for a return\npass is to now yarn over and pull through a loop, you will still do this step\nbut you wrap the yarn around the cable as you are yarning over. Basically I\nhave the cable laying adjacent to the hook so that when I yarn over, the yarn\nis coming over the cable as well, and then I pull through 1 loop.\nKeeping the cable laying adjacent to the hook still, I now yarn over and pull through 2 loops. At this point I have just added 2 loops to the end of the cable.\nFinishing the Join\nI now continue the Return Pass, by yarning over and pulling through 2 loops without working over the cable until 2 loop from the Forward Pass and the 2 added loops remain, (this will be 4 loops on the hook). Yarn over and pull through the last 4 loops.\nWork all subsequent round this way, and the fabric with be\nIn some of the Tunisian stitches there may be some gapping at the join. I have found this with the Tunisian Full Stitch for example, but overall it is satisfactory to me. In addition as the fabric is joined in the Return Pass, during the very first Round the beginning chain is not joined, so when I weave in the ends, I use this opportunity to close this gap.\nTunisian Cup Cozy Pattern\nAny medium weight yarn\nM/N (9 mm) Tunisian cabled crochet hook\nLoop Return Pass (TLRP)–\n*Bring end of cable to working end of hook, bring working yarn to bottom\nof hook and in front of cable, loop working yarn under cable to top of hook,**\nYO, pull through a loop; Rep from * to ** once, YO, pull through 2 loops (2\nloops added at end of row); (Yo, pull through 2 loops) until 4 loops remain on\nhook, YO, pull through 4 loops.\nTunisian Simple Stitch (Tss)—Working from right to left, hold working yarn behind work, insert hook under next vertical bar, yarn over and draw up a loop.\nRnd 1: Ch 23, load hook by inserting hook in next ch, YO, pull up a loop across. TLRP. -23 sts\nRnd 2 & 3: Tss in each stitch. TLRP.\nRnd 4: Sc in each st across. Fasten off. Weave in ends.\nHelp me help local communities by creating blocks\nfor Warm Up America, by making a block for yourself and one for a community project\nwith this free pattern. I will be creating a new block every few weeks and\nsharing it with you, I just ask that make one for donation.\nWarm Up America is a nationwide organization that encourages local\ndonations, but will also except donations to be sent to their office so that\nblocks can be assembled and then blankets can be donated through the United\nEven if you do not want to\nparticipate with Warm Up America, please consider\ncreating blocks, or blankets for your local community. There are various places\nin every community that accept donations.\nThis block is used working Tunisian Crochet. Tunisian Crochet is essentially inserting your hook through your fabric and pulling up a loop, and leaving the loop on the hook, pulling up loops across the row. Then a “return pass” is worked to work each loop off the hook. This creates a fabric that has a similar look to weaving, yet has the same structural characteristics as crochet. There are many different stitches in this technique, but in this block I only use one stitch, the Tunisian Simple stitch. Learn the stitch here.\nChanging color on every forward and return pass, creates a\ndramatic effect. Utilizing only three colors means that I have a color waiting\nfor me when I finish a row and I know exactly which yarn to work next.\nGauge: 7”x9” rectangle\nMedium weight yarn, in 3 colors MC (main color), CC1, CC2\n9 mm Tunisian Crochet hook\nSimple Stitch (tss): Insert\nhook from right to left under next vertical bar, YO, pull up a loop.\nPass (RP) : YO and pull through 1 loop, [YO and pull\nthrough 2 loops] across, until 2 loops remain on hook, using new color for next\nrow’s FP, YO and pull through last 2\nMC Chain 19\n1: With color MC, pull up a loop in second ch from the hook and in\neach ch across. Switch to color CC1, RP. 19 sts\n2: With color CC2, tss across, switch to color MC, RP.\n3: With color CC1, tss across, switch to color CC2, RP.\n4: With color MC, tss across, switch to color CC1, RP.\n5-19: Rep Rows 2-4 five times.\nRnd: With color CC2, sc in each vertical bar across, 3 sc in corner,\nwork evenly sc\naround block working 3 sc in each corner. Finish off.']	['<urn:uuid:4bb18801-3008-4161-af6a-e4f133b3c6d2>', '<urn:uuid:78a6a375-7611-4e34-bed6-397659fb9d12>']	open-ended	with-premise	concise-and-natural	similar-to-document	multi-aspect	expert	2025-05-01T23:46:40.222380	11	90	3613
415	How do ThingSpeak and Azure Event Hubs differ in their capabilities for handling real-time data streaming from IoT devices?	ThingSpeak and Azure Event Hubs have different capabilities for IoT data handling. ThingSpeak is a service that allows up to 4 channels in free accounts, with each channel acting as a data store that can capture specific data points like temperature and humidity at regular intervals. It provides simple graphical visualization and data logging capabilities. Azure Event Hubs, on the other hand, is a big data streaming platform and event ingestion service specifically designed for receiving, transforming, and redirecting fast-arriving streaming data. It can be integrated with other Azure services like Stream Analytics and Cosmos DB to create comprehensive data pipelines for high-velocity data from IoT devices.	['Internet of Things (IoT) is about connecting various devices (sensors, controllers, display units, alarms and any such instrument/equipment) with each other using public internet and may partly run through private network of the end user.\nWith this primary capabaility, IoT opens out many opportunities for systems control, remote data monitoring and to execute commands that carry out various operations based on desired conditions.\nWith improved data connectivity and availability + the reducing prices of electronic devices, IoT is picking up fast and more importantly it is also getting easier for hobbyists and individuals to deploy IoT projects all by themselves.\nBesides the hardware and software to implement any IoT project, what is equally important is a consistent and fairly reliable mechanism to receive and store the data points in a (near) real time manner.\nSetting up such a data store can turn out costly, but there are many such online services available. For industry grade volumes and quality of service/reliability, such data logging services providers offer various plans with different charge structures.\nFor hobbyist and DIY users, most if not all these online services offer a free option but obviously with limited resources granted to the user.\nA few of the popular service providers are listed below, this is just a very small list.\nLet us see how to open an account and create a data logging channel with one of the service providers, namely thingspeak.com\nCreate an account with ThingSpeak\nFrom your computer or mobile phone connected to internet, open the web browser and go to the URL link ThingSpeak SignUp\nEnter your email address and Country and First Name, Last Name on the sign-in page, then click Proceed / Next / Continue button. We recommend using the same personal Google email id as you use on your mobile phone google account.\nIt will warn you about your email address being personal email id. Refer the image below. Please Tick / Select the check box near Use this email… and click Continue button. After this it will display a message mentioning about having sent a link to your email address.\nOpen your e-mail box and find the mail received from ThingSpeak, check if the email has gone into spam folder. Please ask for resending the mail again, if required, by clicking the Send Me the Mail Again link.\nLocate the URL link available in the email that you received and click the link or button or copy paste that URL link in a new browser tab/window. Please keep the previous tab/window of ThingSpeak still open for further use.\nThis new tab/window (not shown here) which you opened from your email by clicking the verification link / button – will show some message like your account/email after successful verification. This is actually a mathworks account which is another website like ThingSpeak, both of which share common authentication and some other such few features.\nAfter this verification is successful, resume in the previous ThingSpeak tab/window, by clicking the Continue button.\nIt will take you to sing-up page where you will be asked to specify your user id and password for ThingSpeak login. Please set a valid user id and password for your ThingSpeak account, this is entirely different and not connected with your email address. Remember and/or note down the user id and password for future use.\nThen proceed to login to ThingSpeak web site or you will be automatically logged into ThingSpeak.\nAt the first login it may ask for some additional information like – what purpose you plan to use ThingSpeak for, (refer next image). Please specify non-commercial/ personal use and click ok.\nA channel is one identifiable register/data store to capture data.\nFor example let us say – a user has 2 different locations where he /she wants to monitor the ambient temperature and humidity at every 5 minutes continuously.\nTo be able to do this the user will setup the needed sensors at the respective locations and data acquired by the sensors will have to be posted to some internet based URL. This URL will receive the data values and store them for later use and analysis.\nFor this example, the user needs to have two different registers or data stores one per location and each register needs to support at least three fields (namely timestamp, Temperature in deg C., Humidity in %).\nSo it is like two readings one each for the two locations, comprising of 3 field values each will be received and saved every 5 minutes. That is 576 readings per day and over 2 years it will be around 0.42 million or 420000 readings. Each reading is about 40 bytes say, so just 16 MB of data over 2 years. The data volume for these two datastores is not really that high, but it is important that the datastore has to provide a reliable and continously available mechanism of data logging.\nWhen translated in the terminology of ThingSpeak, this means two channels one each with 3 fields of data are necessary to be created.\nThingspeak allows upto 4 channels to be created by every user having a free account.\nSo let us see how to create a channel.\nAfter the ThingSpeak login account has been created and successfully logged in, it is required that a new channel be created in the page shown below.\nClick the New Channel button, the website will take you to next page.\nOn this page specify a channel name and select / tick against all the 8 fields shown in the page. Then click Save Channel button. There are other two buttons provided as below\n- Clear Channel – This clears the old data that may have been captured so far in this channel. It is recommended to not clear the channel unless you are sure that you want to lose the data forever.\n- Delete Channel – This deletes the channel altogether. It is strongly recommend to not click this ever, especially after any of the field device is using the channel.\nImportant Parameters of the Channel\nPlease note down the Channel Id, Name and Read and Write API Keys, as it shows in the web page in the API Keys tab. Once the channel is created the Keys and Channel Id can be used by any device/software so that the data to be collected by any field sensor or device can be posted to the channel. These values can be altered any-time by the the user login who created the channel, but if the channel keys are setup in any IoT device as a part of one time configuration then the altered values (especially the Read and Write API keys) need to be updated in all the devices and programs where the old keys were used.\nVerifying the channel\nOnce the channel is created it can be tested by executing below commands in browser address bar.\nWrite to Channel\nThe above comamnd submits and saves one data point with values of two fields to the respective thingspeak channel with matching WRITE_KEY.\nThis comamnd retrieves 20 data point from the thingspeak channel specified by the CHANNEL_ID\nView the data graphically\nThingspeak provides a nice and simple way to view the datapoints. It would be a good activity to explore this part in details to understand what options it gives to view the data, i.e. various types of graph, number of datapoints to be viewed etc.', 'Build real-time data pipelines with Azure Event Hub, Stream Analytics and Cosmos DB\nAzure Cosmos DB is a low-latency, highly available and globally distributed NoSQL database, that Microsoft recommends as a database platform for high-velocity data from IoT devices. However, real-time data ingestion requires services like Azure Event Hubs, Azure IoT Hubs to serve as a gateway for streaming data. How do you build a real-time data ingestion pipeline from Azure Event Hubs into Azure Cosmos DB, with minimal coding?\nOverview of Azure Cosmos DB, Azure Event Hubs and Azure Stream Analytics\nAzure Cosmos DB is Microsoft’s managed NoSQL service, which supports non-tabular data models, like JSON, key-value, graph, and column-family type documents. It provides globally distributed, scalable, and low-latency data service that can serve high-concurrency and fast applications. Azure Cosmos DB guarantees low-latency read and writes, which allows building flexible near-real-time applications, based on the network of connected databases around the world (you can read more about Azure Cosmos DB here).\nAzure Event Hubs is a big data streaming platform and event ingestion service. It’s one of the recommended services to receive, transform and redirect fast-arriving streaming data (see here for more details). Although Event Hubs can direct its output into few Azure services, Azure Cosmos DB is not among its outputs. Therefore, some intermediate service needs to be built, to serve as a bridge between these two services, and Azure Stream Analytics can be used in this role. What makes Azure Stream Analytics attractive as the integration component for the streaming data, is its powerful SQL-based query engine and its ability to write into multiple Azure services, including Azure Cosmos DB, Azure Synapse Analytics, Azure SQL DB, storage, etc. (see this article for more details).\nIn this tip, we will build a solution that ingests the Twitter feeds from Twitter API’s into Azure Event Hubs, and then deliver them into Azure Cosmos DB, using Azure Stream Analytics.\nCreate a data ingestion pipeline into Azure Event Hubs\nI’ll use the TwitterClientCore application, described in this Microsoft article to ingest data into Azure Event Hubs. This application listens to the Twitter feeds related to a configurable list of keywords, like Microsoft, Azure, Skype, etc.\nPlease create the Azure Cosmos DB, Event Hubs, Azure Stream Analytics and Twitter accounts and follow the steps in this Microsoft article, to configure, compile and start the TwitterClientCore application.\nOnce the application started, it will receive the feeds and display the number of events sent to the Event Hubs, as follows:\nAt this point, we will be able to observe incoming traffic on Event Hubs’ dashboards:\nConfigure Azure Cosmos DB container\nOpen your Azure Cosmos DB account and add a container, using the Add Container button:\nProvide the database and container names and partitioning field. Notice that the partitioning field should include the name of the existing column from the data source (I have selected the lang column, which is part of Twitter feed payloads). Select the Analytical store option, which would allow us to analyze the data from Synapse Analytics in future (see Explore Azure Cosmos Databases with Azure Synapse Analytics for more info on this option). Here is the screenshot with the container settings:\nConfigure Azure Stream Analytics\nThe Azure Stream Analytics job requires an input, an output, and a SQL query to transform the data.\nLet us start by creating an Event Hub input. Open the Azure Stream Analytics account, navigate to the Inputs tab, and add a new Event Hub input:\nProvide the input name (twitter-eh in my example), select Event Hub namespace/name and the policy with the Send privileges. Ensure that the GZip option is selected, as the compression method. Here is the screenshot:\nNext, navigate to the Outputs tab, add the Cosmos DB output:\nSelect the Cosmos DB account name, database and provide the container name we created earlier, as follows:\nNext, navigate to the Query tab, add the following query (replace the input/output names, to match your endpoint names):\nSELECT * INTO [cosmosdb-output] FROM [twitter-eh] PARTITION BY [lang]\nNotice that we have included a partitioning column, as the Cosmos DB container requires this parameter. The Input preview table in the center of the screen, will show a sample data from the Event Hub:\nTest the query and save it, using the buttons, illustrated in Figure 9.\nNext, navigate to the Overview page, and start the job:\nThe job status will be shown, under the Start button. It will take a few minutes for the job to move from the Starting stage to the Running stage and after that, you will be able to see the execution stats in the Monitoring pane charts, as follows:\nNow we can check the data in Cosmos DB container. Let us navigate to the Data Explorer tab on the Cosmos DB account page, expand the database/container names and review some of the recently uploaded items:\n- Read: Welcome to Azure Cosmos DB\n- Read: Quickstart: Create a Stream Analytics job by using the Azure portal\n- Read: Azure Cosmos DB output from Azure Stream Analytics\nAbout the author\nView all my tips\nArticle Last Updated: 2021-03-23']	['<urn:uuid:0981a5cc-afcc-4388-a791-2eb7a0a26849>', '<urn:uuid:e459b088-6753-4916-a33f-56e5f244c883>']	open-ended	direct	verbose-and-natural	distant-from-document	comparison	expert	2025-05-01T23:46:40.222380	19	107	2091
417	I'm interested in early childhood development programs. Which organization is leading the coordination center for the ECCS CoIIN project and what years is it running?	NICHQ is leading the Coordinating Center for ECCS CoIIN, and the project runs from August 2016 to August 2021.	"['Early Childhood Comprehensive Systems Collaborative Improvement and Innovation Network (ECCS CoIIN)\nA multiyear initiative to improve early childhood service systems in 12 states to increase age-appropriate developmental skills among 3-year-old children and reduce developmental disparities.\nKeep scrolling, or use these quick links, to learn more.\nAugust 2016 - August 2021\n- Who: Twelve states and their respective communities (see map), which will be comprised of community leaders, researchers, healthcare providers and family partners.\n- Funder: Health Resources and Services Administration Maternal and Child Health Bureau. Partners on the project include: ZERO to THREE (ZTT), Applied Engineering Management Corporation (AEM), the Association of Maternal and Child Health Programs (AMCHP) and the Institute for Healthcare Improvement (IHI).\n- Our Role: Lead the NICHQ Coordinating Center for ECCS CoIIN to support state teams through quality improvement and innovation, using collaboration and rapid cycle testing to create new approaches that will enhance early childhood systems.\nTeams are provided technical assistance and an online collaborative workplace (NICHQ\'s Collaboratory) to promote continuous communication, and a data dashboard to capture shared measures and track progress toward the common agenda. Click on the map below to see a list of participating communities in the 12 ""Impact Grantee"" states.\n- Norton Sound\n- New Castle and Wilmington\n- Western Sussex\n- Western New York\n- Choctaw County\n- McCurtain County\n- Pushmataha County\n- Geary County\n- Montgomery County\n- San Juan\n- South Salt Lake\nProject Aim: Thriving at Three\nEquity Action Lens\nNICHQ is infusing its focus on health equity into the ECCS CoIIN initiative. This graphic, which we call the Equity Action Lens, shows the fusion of three perspectives essential to foster health equity: social determinants of health, life course perspective, and the social ecological model, which include multiple levels and sectors of social influence and support. The Equity Action Lens helped to guide the design of the theory of change for this initiative.\nJoin Our Virtual Community\nThe ECCS CoIIN Collaboratory (CoLab) is a virtual place where ECCS CoIIN participants and stakeholders can share ideas and best practices, ask questions, and uncover useful tips to advance their change efforts.\nAlready a member?\nWant to join? Fill out this form to request access.\nWe\'ve curated several resources for those working on early childhood health:\n- The Integration of Early Childhood Data\nState profiles and a report from the U.S. Department of Health and Human Services and the U.S. Department of Education\n- Implementation of Young Child Wellness Strategies in a Unique Cohort of Local Communities\nA report of lessons learned from Project LAUNCH (Linking Actions for Unmet Needs in Children’s Health.\n- The Guide to Community Preventive Services\nA collection of evidence-based findings from the Community Preventive Services Task Force to improve health and prevent disease.\n- Achieving the Promise of a Bright Future\nA policy brief from ZERO to THREE outlining recommended developmental screening of infants and toddlers.\n- From the Ground Up: Establishing Strong Core Policies for Infants, Toddlers and Families\nThis resource describes the rationale for investing in programs that support children’s development in the earliest years of life.\n- Infant-Toddler State Self-Assessment Toolkit\nThis toolkit is intended to help state policy leaders and advocates assess the current status of services for infants, toddlers and their families, and to set priorities for improvement.\nTaking A Two-Generation Approach to Children’s Health\nFrom infancy, children rely on their parents to learn about and cultivate the habits and skills that will ensure their health. So when a parent struggles, children’s health may suffer. In this interview with NICHQ CEO Scott D. Berns, we discuss why the two-generation approach is essential for children’s health, and how we can use it to drive systems-level change.\nMastering the Planning Stage of PDSAs\nIf you’ve completed PDSA cycles but are having difficulty identifying changes that lead to improvement, it’s time to take a step back and review your PDSA process, starting with the “P.” The planning stage sets the foundation of your PDSA cycle, which means mastering it is essential. Click in for tips on improving each element of your planning stage.\nFrom 50th in the Nation to a National Success. Delaware Improves Early Childhood Outcomes\nRight now, more than 15 percent of children miss out on early developmental screenings and risk their future health. Find out what Delaware is doing to prioritize screenings and make sure Delaware children start school healthy and prepared.\nNICHQ’s New Clinical Director of Early Childhood Initiatives Has a Plan for Improvement\nAs NICHQ’s new Clinical Director of Early Childhood Initiatives, Jill Sells, MD, FAAP, is invested in improving early childhood systems on a national scale. Keep reading to find out more about her goals and learn what gets her up in the morning ready to drive change in early childhood systems.\nImproving Children’s Vision in Your State: Three Teams Share Lessons Learned\nEarly childhood eye care can drastically change a child’s health and well-being. For the past two years, improvement teams in Arizona, Ohio and Wyoming have been working to increase screenings and identify measures that can be spread to other states and communities. Here are some of their key lessons-learned.\nWhat 2018 Means for Children’s Health\nWe recently sat down with NICHQ President and CEO Scott D. Berns, MD, MPH, FAAP, who shared his thoughts on building on 2017’s successes, the biggest opportunities in 2018 and how NICHQ can drive change in children’s health outcomes. Check out a short video and then read on to uncover what Berns is prioritizing in 2018.']"	['<urn:uuid:ad881792-fb66-4b2d-9e10-73cbe0cdd6e7>']	factoid	with-premise	verbose-and-natural	similar-to-document	single-doc	novice	2025-05-01T23:46:40.222380	25	19	919
418	As someone interested in education reform, I'd like to know how modern schools evaluate student progress beyond traditional grades and test scores. What different assessment methods are being used?	Modern schools employ diverse assessment approaches beyond traditional grading. For instance, some schools use a Pass/No Credit system, with a Pass with Honors designation for exceptional achievement, rather than numerical grades. They avoid competitive measures like grade point averages or class rank, instead focusing on non-competitive evaluation. Students receive frequent detailed evaluations describing their information mastery, skills development, and behavioral expectations. These evaluations specifically outline achievements and areas for improvement. The future ready framework emphasizes ongoing assessment processes to evaluate whether students have mastered specific skills within subject areas. This includes evaluating students' ability to learn in various ways - visual, written, auditory, and kinesthetic - as well as their capacity for independent and collaborative work, critical thinking, and effective communication.	['The Community School’s program blends college preparatory academics with applied learning, often in multidisciplinary topics. Many classes apply lessons to real problems on the school’s 310-acre farm or in the surrounding community. Learning to do community service or to participate in weekly School Meeting are as important as mastering traditional academic subjects. Long term projects such as restoring the school’s fields to productive use may involve the entire school and a variety of disciplines.\nThe program includes three elements: academics, essential skills, and projects.\nStudents must obtain 21.25 credits to earn graduation. These follow fairly standard requirements for college entrance: 4 credits in English; 3 credits each in math, science and social studies; 2 credits in a foreign language; 1 credit each in vocational/home economics, physical education; ½ credit in technology and the arts; and ¼ credit in health. In addition, students must complete 120 hours, one full credit, of community service and 120 hours of work on an independent senior project.\nEssential Skills include topics we think are necessary for success in the 21st century: problem solving, leadership,understanding of democratic process; appreciation of cultural diversity; facility with maps and geographic information; experience with creative and inventive thinking; skill in teamwork and problem solving. Resources in our program include the immediate school, the Doris L. Benz library, our shop, kitchen, computer studio, 234-acre working forest, and 4-acre organic vegetable garden. The program also visits private forests, state and federal forests and wild lands, nearby communities, Boston, New York, and Washington, DC. Our comparative forestry program has taken students to Monteverde, Costa Rica, and the northern Bohemia town of Litvinov in the Czech Republic.\nProjects involve students and groups of students in long term applications of their learning. Students help manage our white pine forest and have tracked its health for more than 10 years in a University of New Hampshire air pollution study. Students have literally changed the face of the earth in our gardens, turning barren fallow fields into extensive vegetable, herb, and flower gardens. Students have developed our geographic information systems program into a series of maps for school and community use.\nHistory, social studies, biology, chemistry, environmental studies, physics, philosophy, technology and land use are presented in a block schedule. Blocks vary in length from 2 – 8 weeks and may integrate more than one subject, offering partial credit in several areas. The block allows for laboratory work, field trips and problem solving.\nStudents build skills in English, math, and foreign language classes, scheduled four to five days each week. The work done in these classes helps to enhance skills developed in block time, cover core information in essential subjects, and develop year-long relationships with teachers.\nEnglish classes are assigned according to skill level. These courses teach and reinforce basic reading, writing, listening, speaking, and viewing skills, allow students to immerse themselves in literature, provide opportunities for revision, and give students a consistent forum for their writing.\nMath courses include: pre-algebra, algebra I, geometry, algebra II/trigonometry, advanced math/precalculus, and calculus.\nForeign Language classes include Spanish I, II, III, and IV.\nTCS trip weeks have traditionally augmented themes being studied in our block classes and can range from wilderness experiences to city travel, community service to historical and scientific exploration. This year we offer two exciting all-school trips.\n- Our September 2012 trip to Bath, Maine will allow a study of salt-water ecology (oceanography). Our historical/cultural focus will be on the role of Blacks and Women in 20th century New England.\n- Our May 2012 trip to Prince Edward Island will give us an opportunity to study immigration, music in culture, and sustainable agricultural practices.\nStewardship classes are held once a week, lasting 1-8 sessions. These enrichment classes offer opportunities for vocational, technology, health, and Phys Ed credit, as well as time for science-related project work, and art and music electives. Community members and students may occasionally be invited to lead a stewardship class.\nIn addition to block, core, and stewardship classes, all students are involved in various classes designed to expand their ability for personal artistic expression. In the past, students have enjoyed a wide range of offering from music history and choral singing, to drawing and painting, ceramics, and drama. In addition to an exciting collaborative boat-building course, art classes this year will focus on expanding skills in theater and woodworking.\nGrading at the Community School is done on a Pass/No Credit basis. A Pass with Honors grade indicates exceptional commitment or major learning breakthroughs.\nThe Community School does not compute grade point averages or class rank. Students are graded non-competitively. Multi-aged classes allow students to progress at their own speed. Frequent evaluations describe the information, skills and behavioral expectations of the course and specifics as to the student’s achievements and needs. Copies of these are presented in the college application.\nClasses at The Community School range from 8 to 12 students in size. A lively mix of full and part time teachers provide expertise in every facet of the curriculum with support from our farm manager, staff, and administrative specialists. Each student chooses a teacher as an advisor. Advisory groups meet daily to talk, do daily chores, and plan group activities.\nExtensive travel, numerous field trips and long workshop classes are designed for students who are highly motivated and self-disciplined. The school does not provide any special services. Tutoring is sometimes arranged on a private basis.\nUnique features of our program include study of place, contemplation of nature, community-based learning, and art education for all.\nLearning is the doorway to the wonders of culture, the natural world and community. Every student should hear the poetry of the ancients. Each one should trace the routes of the first explorers and learn the names of a dozen trees. These experiences in youth are the tinder that kindles a lifelong curiosity and delight in learning.\nThe Community School faculty strives to help every student learn to speak articulately, to write clearly, to read voraciously. We want every student to feel capable in math and science. Every youngster will be familiar with the U.S. Constitution, its history and its role in a modern democracy. Every student will be well schooled in world geography, cultures, literature and art. In addition to a strong foundation in traditional academics, Community School students explore in other essential ways. Every student, for example, performs 120 hours of community service. Students travel extensively, learning how to learn anywhere in any condition. Classes call on students to work as a team, to think creatively, and to solve real problems in their communities. A weekly School Meeting teaches students how democracy works and how they may participate effectively in a democratic society.', 'Future Ready School Fundamentals\nThe future ready school fundamentals are a set of standards to help schools across the country prepare students for success in a rapidly changing world. The fundamentals are designed to provide schools with a framework that will help them meet the needs of today’s students and be ready for tomorrow’s challenges. Here are a few fundamentals future ready schools should focus on.\nIn order to be future ready, students need to be able to learn in a variety of ways. They should be able to learn from visual materials, written materials, auditory materials, and kinesthetic materials. Students should also be able to learn independently and collaboratively. They should be able to work with others in small or large groups, depending on the situation. Students need to be able to organise their thoughts and ideas so that they can communicate them effectively. They should also be able to think critically about what they are learning and how it relates to other things they have learned.\nFuture Ready Schools emphasise the use of modern technologies such as virtual reality headsets, augmented reality glasses, and 3D printers. They also use traditional tools like whiteboards, projectors, computers, and tablets. Each student is provided with his/her Chromebook laptop computer so they can access content anytime from anywhere in order to complete assignments or collaborate with other classmates.\nImportant Skills for Students\nFRS allows students to explore their interests and develop skills they will use throughout their lives. Students learn to problem-solve, collaborate with others, think critically, and practice self-reflection. The program also helps students develop an understanding of their strengths and weaknesses and how those affect their learning.\nStudents will have access to various resources, including project-based activities that allow them to practice the skills they are learning in school. They will also have an opportunity to work on projects requiring them to collaborate with classmates and other community members.\nLeading Future Ready Schools\nThese are schools that are doing an excellent job of preparing students for a future where they will be responsible for their learning and development. These schools have demonstrated success in helping students reach their full potential and understand the value of lifelong learning.\nThe future ready framework is a set of standards, benchmarks, and behaviours that describe what students need to know and be able to do to thrive in the future. It provides a common language for educators and other stakeholders to talk about what’s important for students to learn now and in the future.\nThis framework offers a unique opportunity for schools, districts, and states to align their efforts around the skills needed for tomorrow’s economy while meeting state-level standards. It also helps educators identify key areas where they can collaborate with employers and business leaders on career pathways that prepare students for college and careers.\nEducation is a very important part of our lives and plays a vital role in shaping our future. The education system should be such that it prepares the students for future challenges, but at the same time, it should also provide them with an opportunity to explore their creativity. The future ready framework in education provides a platform for creating such opportunities. The future ready framework in education has three components:\nThe curriculum is the plan for what students will learn in a given grade level. The curriculum includes the content and the process of teaching that content. Curriculum decisions are made by educators, administrators, parents, and community members.\nA curriculum is often divided into two categories: academic curriculum and behavioural curriculum. The academic curriculum includes subjects like reading, writing, science, social studies, and mathematics. Behavioural curriculum includes topics such as bullying prevention or character education.\nInstruction refers to the process of teaching students what they need to know to be successful in school and life after graduation. Teachers are responsible for delivering instruction to students in a manner that promotes learning and achievement. Teacher-student interaction ensures that students have access to quality information to make informed decisions about their future careers or educations.\nAssessment is the process of evaluating whether students have learned what they were supposed to learn during a specific time period or unit of study. Educators design assessments to determine whether an individual has mastered a specific skill or set of skills within a subject area, such as math or English language arts (ELA).\nHow Does It Help Students?\nFuture ready framework provides a road map for creating a culture of innovation that helps all students develop the skills they need to succeed in today’s world. Here is how students can benefit from this framework.\nEnhancing the Quality of Learning\nThis framework helps students to improve their productivity, creativity, and analytical skills. They are able to develop these skills by using technology such as projectors, computers, and tablets.\nMaking Students Aware of Themselves\nStudents learn how they can use these tools effectively while learning. They also learn how they can use these tools for other purposes like communicating with others, creating websites, etc.\nEmbracing a Growth Mindset\nThe future ready framework encourages students to embrace a growth mindset where they believe they can learn anything no matter their age or experience.\nEncouraging Collaboration and Team Work\nStudents are encouraged to work together on projects and assignments. This helps them learn about working together as a team, which is an important skill in the workplace. Students will also learn how to communicate effectively with each other so they can achieve their goals as a group.\nDeveloping an Adaptive Mindset\nThis component focuses on cultivating students’ ability to think critically, solve problems creatively, and learn continuously. It includes teaching students how to learn new things and adapt to change by providing opportunities to work collaboratively.\nThe Use of Technology in Future Ready Schools\nThe use of technology in FRS is crucial to the success of tomorrow’s students. It is important that we prepare our students with the knowledge and skills they will need to be successful in a world where technology is constantly evolving.\nTechnology can be used in many different ways, but it all depends on how effectively it can be integrated into the curriculum. Technology can be used for instruction, assessment, and collaboration with other students and teachers.\nTypes of Technology Used\nTechnology has been a part of the educational system for decades. However, with the advent of new technologies, many more options are now available to educators and students. Here are some of the most common types of technology used in FRS.\nInteractive whiteboards and displays\nInteractive whiteboards are fit for future education because they allow students to interact with their teachers using touchscreens or stylus pens to draw on the board. Students can also use them as an alternative way to take notes during lectures or presentations.\nStudents can listen to lectures, podcasts, and other educational material on their smartphones or earbuds. They can also engage in virtual meetings and discussions with teachers, parents, and other students through Skype, Google Hangouts, or other programs.\nVideo conferencing platform\nThis enables students to interact with experts worldwide, providing access to information and knowledge that would otherwise be unavailable to them.\nThese textbooks are available as e-books or apps for smartphones and tablets so students can access them wherever they go. They often contain multimedia elements such as videos, images, and audio clips, making them more engaging than traditional textbooks.\nBenefits of Using Technology in the Learning Process\nTechnology has become an essential part of our lives. It can help us to learn, work, and play. There are many benefits of using technology in future ready education. Technology has made our lives easier and learning more fun and interactive for students. The following are some of the benefits of using technology in the learning process:\nIt helps students to take control over their learning process by allowing them to choose how they want to learn a certain topic or concept.\nIt makes learning more interesting by allowing students to use different types of media, such as videos, animations, pictures, etc., which makes it easier for them to understand concepts better.\nIt also provides flexibility in choosing one’s schedule and time while studying a particular topic or concept as it allows them to study on their own time, which is very convenient for many people who have busy schedules due to work and other commitments such as sports games.\nTechnology also helps teachers in delivering their lectures easily without having to worry about losing their voice or getting tired easily because they can record their lectures using technology and play them back anytime they want during class time without having to repeat themselves too many times due to fatigue or illness.\nFuture Ready Librarians Framework\nThe Future Ready Librarians Framework (FRL) is a set of principles that can be applied to any library type. It offers a way to think strategically about the future while also providing guidance on how to create and implement change within your organisation.\nThe FRL helps leaders envision the future of their libraries and provides them with tools to anticipate change and prepare for it. It offers guidance on creating a culture that welcomes innovation and experimentation while supporting stability and consistency.\nFuture Ready Schools FAQ\nQuestions about FRS? Here are answers to the most frequently asked questions.\nWhat Does a Future Ready School Look Like?\nA future ready school is a learning environment that is personalised to each student, where they are the centre of their learning experience. FRS empowers students to take action and solve problems by providing them with the knowledge, skills, and experiences they need to be successful in college, career, and life.\nWhat Is a Future Ready Curriculum?\nA Future Ready Curriculum is one that is aligned with the new learning standards (Common Core), provides rich content that is relevant and engaging and develops 21st-century skills through a variety of instructional methods.\nWhat Is Future Ready in Blended Learning?\nBlended learning refers to using digital tools alongside traditional classroom instruction to enhance teaching and learning. This could mean using online videos or online textbooks alongside classroom instruction — or it could mean using online tools such as blogs or wikis for collaboration between students.\nWhat Are Future Ready Schools?\nFuture Ready Schools is a national initiative that is part of the U.S. Department of Education’s vision for preparing students for success in college, career, and life. The initiative focuses on helping schools develop and implement continuous improvement plans that ensure all students graduate ready for college and career success.\nWhat Is the Future Ready Initiative?\nThe Future Ready Initiative is guided by a set of principles outlined in the Future Ready Framework. The framework guides creating an optimal learning environment for all students, regardless of background or circumstance.\nWhat Is the Goal of Future Ready Schools?\nFRS is a national initiative that aims to prepare all students for success in college, career, and life. The program provides schools with resources and support to help them develop and implement plans that meet the needs of their students.\nHow Do Students Become Future Ready?\nStudents become Future Ready by building a foundation of knowledge and skills in three areas: STEM (science, technology, engineering, and math), social studies, and language arts/literacy. FRS is one way to ensure that these foundational skills are taught in every classroom in every school at every grade level.\nThere are many ways to help make classrooms future ready, but there are especially some smart steps that districts can take to ensure they’re moving at a swift pace. More schools are implementing these strategies every year, leading the charge in providing that students learn in the most modern ways possible.']	['<urn:uuid:da0135f5-784d-4fb6-8a60-c2147f1c6b54>', '<urn:uuid:61cdfe84-bfc1-4186-ac71-42d2e6235b5c>']	open-ended	with-premise	verbose-and-natural	distant-from-document	three-doc	novice	2025-05-01T23:46:40.222380	29	121	3070
419	How did John Cassavetes and Andrei Tarkovsky approach working with studios?	John Cassavetes and Andrei Tarkovsky had different relationships with the studio system. Cassavetes deliberately worked outside the studio system, financing his first film Shadows himself for $40,000 and using handheld cameras and unpaid actors to maintain artistic freedom. While he briefly worked with Paramount for two films, he preferred independent filmmaking. In contrast, Tarkovsky worked within the Soviet system until his relationship with authorities deteriorated - after making Stalker, Soviet authorities made it impossible for him to work in the USSR, with some former KGB agents later claiming they poisoned him during the film's production.	"[""Watch: 'Father of Independent Cinema' John Cassavetes Shares His Philosophy on Film\nJohn Cassavetes started his career as an actor, most notably in Rosemary's Baby, but ended up becoming one of the catalysts for independent filmmaking -- a director who had his finger on the pulse of artists who wanted to create something outside of the predictability of the studio system. His films didn't contain big funds, big stars, and big sets, but the absence of these things gave Cassavetes enough space to tell his beautiful stories about the raw human experience, making him a legend in not only independent film, but in all of cinema. Check out a portion of the French documentary Cineaste de notre temps that captures the acclaimed director behind the scenes, talking about working outside of the system.\nMost known for his films Shadows, Faces, A Woman Under the Influence, and The Killing of a Chinese Bookie, Cassavetes' films consist of exposing the human condition as truthfully as possible. It wasn't all glitz and glamor, idealizing a scenario so that it'd be easier to digest for an audience. He shied away from themes like politics or religion, instead making films that dealt with love, isolation, and trust. Cassavetes once said:\nLife is men and women. Life isn't, say, politics. Politicians are only bad actors grubbing around for power -- In my opinion, these people and these small feelings are the greatest political force there is.\nHis first film, Shadows, which he made in 1959, was financed by Cassavetes for $40,000, and because of its limited release, didn't find much of an audience. However, it did catch the eye of some critics, which helped him cash in on a Venice Film Festival Critics Prize for the film. Studios also began showing interest, and Cassavetes signed with Paramount to do Too Late Blues and A Child Is Waiting.\nThe documentary, an episode of a French documentary series called Cinéastes de notre temps (Filmmakers of Our Time,) which originally aired in 1969, reveals Cassavetes great passion for filmmaking, as well as artistic free expression. For him, it wasn't just about making films, it was about making films that allowed him to say what he wanted to say. He didn't need a big budget or known actors. In fact, he chose to work mostly with handheld cameras, and with his friends and people he knew, casting many of them in roles often times without compensation.\nHowever, his desire wasn't to slight his cast and crew, but to allow them to get involved in a project they cared about and had a vested interest in. He also let his actors do quite a bit of improvisation in his films, although the claim that his films were largely unscripted has been exaggerated. Rather, they were scripted, but Cassavetes allowed the actors to interpret the scene and dialog for themselves.\nHe sums up his approach to filmmaking in the documentary when he says:\nWe decided we'd come up with a great idea, that we would buy all of our film equipment, but they wouldn't give us any credit. So, we started our film without any money, and we just used people that would help us to make the film only because of their idealistic attitudes toward filmmaking, which is, in America, a business not an art. So, we're saying [sound] with your business, and we'll try to make it some kind of an art -- art meaning that we will enjoy ourselves and express ourselves freely.\nJohn Cassavetes is one of those filmmakers that speaks to you on a level of humanity that is only reached when you're a teenager listening to music in your room. His films find the root of what being a human is all about, shines a light on it, and hits record. He's raw and honest, but is also enthusiastic and passionate. His philosophy on filmmaking is pure -- making films for the sheer love of film.\nNobody expresses this sentiment more effectively than director Jim Jarmusch, who recently wrote in an open letter to Cassavetes:\nThe enlightenment I anticipated from you is being replaced by another. This one doesn’t invite analysis or dissection, only observation and intuition. Instead of insights into, say, the construction of a scene, I’m becoming enlightened by the sly nuances of human nature.\nHe goes on to say:\nYeah, you are a great filmmaker, one of my favorites. But what your films illuminate most poignantly is that celluloid is one thing and the beauty, strangeness and complexity of human experience is another.\nWhat do you think of John Cassavetes' filmmaking style? What's your experience watching a Cassavete's film like? Share your thoughts in the comments below."", 'Few directors command as much respect from their peers as the late Andrei Tarkovsky. Ingmar Bergman famously called him “the greatest [director] of them all.” Three of his films appear in the Sight & Sound Top 50 Greatest Films of All Time poll, a feat surpassed only by Jean-Luc Godard.\nOne of those films, his 1979 feature Stalker, is out in a gorgeous new 2K restoration by Mosfilm.\nA surreal and sprawling sci-fi meditation, Stalker is set in a dystopian future society whose fabric is forever altered by the appearance of “The Zone,” a mysterious geographic space of seemingly otherworldly origins.\nDespite government efforts to prevent human entry via a militarized perimeter, a class of people known as “stalkers” have learned to navigate “The Zone,” which is governed not by the laws of physics but by the thoughts and emotions of those who enter it.\nFor a fee, stalkers will escort visitors into “The Zone” and help them navigate its terrain of existential booby traps to find the supernatural rewards it’s purported to contain. The film follows one such stalker (Alexander Kaidanovsky) as he leads a writer (Tarkovsky regular Anatoli Solonitsyn) and a professor (Nikolai Grinko) through the sentient landscape.\nLike Tarkovsky’s Solaris, Stalker is a loose and abstract adaptation of a much more cerebral sci-fi novel.\nWhile the original authors examine the political and metaphysical ramifications of sci-fi scenarios, Tarkovsky is interested in the spiritual ramifications of these phenomena. His source material tells us about “The Zone,” while Tarkovsky asks what “The Zone” can tell us about ourselves.\nFew filmmakers ask such questions better than Tarkovsky. More than presenting a sci-fi setting or scenario, “The Zone” places the viewer in an unsettling headspace that necessitates a radical change in perspective. Needing to interpret a world purely through emotion, discarding reality’s iron-clad laws, forces the viewer to reconsider the prism through which they view their own life in addition to the fiction.\nWhen the writer and the professor give their reasons for wanting to visit “The Zone,” both answers feel incomplete or deceptive. Whether they’re trying to deceive each other, themselves or the viewer is a complex knot that the film only partially untangles. Only by examining their own attitudes can the viewer begin to answer those questions, and like these characters, they might not like what they see when looking inward.\nTarkovsky and cinematographer Alexander Knyazhinsky present these quandaries with a quiet that masks the film’s visual gusto. The film begins outside “The Zone” in sepia tones, transitioning to colour as the characters leave their dystopia behind.\nThe parallel to The Wizard of Oz is obvious, but that’s less a statement than a further question to the audience. What did that colour scheme say about Depression-era America in Oz, and what does it say about Tarkovsky’s contemporary Soviet Union?\nWhatever it said wasn’t liked by Soviet authorities, who made it impossible for Tarkovsky to work in the USSR after this film. In the 1990s, former KGB agents who purported to have had a role in Tarkovsky’s death claimed that the poison which caused his fatal cancer was administered on the set of Stalker.\nStalker plays at Cinematheque Sept. 23-29.']"	['<urn:uuid:7bf19972-16ed-41d5-94de-14aa8375205f>', '<urn:uuid:10477b4b-c959-4e10-8b39-0d9f094994f0>']	open-ended	direct	concise-and-natural	distant-from-document	comparison	novice	2025-05-01T23:46:40.222380	11	95	1314
421	Which worked with concrete more: Riccardo Morandi or Cate Adams?	Riccardo Morandi worked more extensively with concrete, particularly developing innovative prestressed concrete designs for bridges throughout his career. While Cate Adams was an architect who worked on various domestic projects, there is no specific mention of her specializing in concrete construction.	['Ethel Day is RIBA’s annual event that celebrates the contribution of women to the architecture profession, named after Ethel Mary Charles; the first woman to become an RIBA member in 1898. To celebrate Ethel Day each year RIBA share stories of inspirational women in architecture and this year, on Thursday 5th July, we are delighted that they have chosen to feature Cate Adams. Cate was mother to Rob Adams, co-founder and architectural director of Adams+Collingwood Architects, and grandmother to Rob’s daughter Tamsin Bryant; architect and co-director of the practice.\nCate was a direct inspiration to both Rob and Tamsin who now successfully run their practice together. However – as a woman in architecture of her generation – her architectural achievements were not widely acknowledged during her lifetime and we welcome this opportunity to celebrate her career and contribution to architecture.\nCatherine (Cate) Campbell Taylor Adams (nee Elder) 1925 – 2015\nCate was from a large family and she, along with her brothers and sisters, went to Bedales, a progressive school in Hampshire renowned for its liberal ethos and where girls and boys were treated equally. Bedales considered design, art and ‘making things with your hands’ very important and after developing an early talent for woodwork and model making, Cate went onto Hornsey School of Art, then enrolled at the AA at the age of 17. Her architecture training coincided with WWII and one of her classmates recalls that girls outnumbered boys in their class, perhaps unsurprising for the time. Rob is in no doubt that his mother’s architectural talent was nurtured by her unusual childhood upbringing and she often told him that the Ernest Gimson Library at Bedales was a major inspiration to her.\nAfter graduating Cate married Beak Lemesle Adams FRIBA, also an architect and artist who went onto have a well-documented architectural career. Cate and Beak together were members of the post-war generation of architects tasked with the huge job of rebuilding Britain. Cate’s professional career included working for Erno Goldfinger, Sir Geoffrey Jellicoe the landscape designer, and Max Fry Architects. She also worked on the Festival of Britain. These were jobs with the cream of progressive architectural talent and she was well respected by her peers at the time, with Rob recalling his mother being warmly embraced by the likes of Peter Shepherd, Gabbi Epstein, Ian Baker, Tervor Dannatt, Kenneth Rowntree, Neville Conder, Sir Hugh Casson, and Peter Koralek.\nIn 1950 Cate’s career changed with the arrival of Rob’s eldest sister Carola, followed by Briony and Rob. For the next 45 years Cate worked from home on mostly domestic projects, whilst raising a family and supporting her husband’s career as an architect and painter. Her decision to pursue her own practice was very unusual for the time and frowned upon by some, although most definitely not her clients. Rob recalls that Cate became famous for her ability to make spaces in impossible places and gain planning permission against the odds. Her work included their own family home in Chiswick and new three garage and studio accommodation at Strand on Green on the bank of the Thames. She was involved in many house extensions and studio buildings along Strand on the Green and her architectural work was recently deemed a ‘vernacular feature’ of the area by local planners.\nRob writes of his mother’s architectural career; ‘Cate specialised in creating wonderful spaces for people to live in, in places that she loved. She helped create communities. Even though her work is modest and she did not have a famous career, there is no doubt that she was an architect of great skill and a credit to the profession.’\nIn later years, Tamsin recalls that her grandmother took her on lots of excursions, often to help Tamsin’s homework while she was studying architecture. Tamsin has fond memories of visiting all the Henry Moore sculptures in London and later the Henry Moore Museum; they took a trip to 2 Willow Road in Highgate – Cate’s first architectural job for Erno Goldfinger; and went for tea with a contemporary of Cate’s who lived in Highpoint, which allowed Tamsin an invaluable insight into Lubetkin’s interior design. Every year they would go to the Serpentine Gallery to see the summer installation, which Tamsin now realises is one of the best examples of how Cate introduced Tamsin – along with Cate’s other grandchildren – into the art, architecture and culture scene as their way of life; a tradition and a shared family interest.\nCate Adams was a well-loved and talented architect working against the odds to pursue her career. She was also a mentor to her husband and a significant creative influence on her children and grandchildren, with many going on to pursue successful careers in the arts and architecture. Her architectural legacy is well worth celebrating and we look forward to raising a glass to her on Ethel Day.\nFind out more about RIBA’s #EthelDay events and read other stories celebrating women in architecture here: Ethel Day 2018\nRead more about Cate Adam’s incredible life and legacy in this family memoir: The Life of Cate Adams', 'Born on 1 September 1902, Riccardo Morandi is very much in the news even though he passed away on 25 December 1989. Renowned as a groundbreaking figure in bridge engineering throughout his career, the collapse of the Genoa Bridge (official name Ponte Morandi) in 2018 cast a dark shadow across his reputation. While it is unfortunate that the Genoa Bridge collapse will take centre stage for many years to come, the life and times of Riccardo Morandi was never straightforward.\nEarly career of Riccardo Morandi\nRiccardo Morandi was born in Rome and passed away in his home city. His revolutionary use of prestressed concrete in his various bridge designs can be traced back to his early days, working with reinforced concrete in earthquake ravaged regions of the world. He began his journey in this field after his 1927 graduation when he visited Calabria.\nHis fascination for creating innovative structures continued as he opened his own office in Rome coming up with groundbreaking designs for cinemas and bridges, all involving prestressed concrete. He was appointed professor of bridge design for both the University of Rome and the University of Florence. The current focus may be on his Genoa Bridge design, and the subsequent collapse, but he also designed the General Rafael Urdaneta Bridge in Venezuela which also experienced a partial collapse in April 1964.\nStructures designed by Riccardo Morandi\nBetween 1953 and 1974 the record books show that Riccardo Morandi was involved in at least 11 bridge structures around the world. The list includes:\n- Ponte Morandi (Toscana) (it), Italy\n- Paul Sauer Bridge, Eastern Cape, South Africa\n- Ponte Amerigo Vespucci, Florence, Italy\n- Fiumarella Viaduct, Catanzaro, Italy\n- Kinnaird Bridge, Castlegar, Canada\n- General Rafael Urdaneta Bridge Lago de Maracaibo, Venezuela\n- Ponte Morandi, part of the Polcevera Viaduct, Genoa, Italy\n- Puente de la Unidad Nacional, Guayas River, Guayaquil, Ecuador\n- Wadi el Kuf Bridge, Libya\n- Carpineto Bridge, Potenza, Italy\n- Pumarejo Bridge, Magdalena River, Barranquilla, Colombia\nWhile this is not the complete list, it does give you an idea of the esteem with which he was held around the world designing bridges from Canada to Libya, Ecuador to South Africa. Riccardo Morandi was also involved in a number of other structures including airport designs but it will be his specific style of bridge which he will be forever associated with.\nRiccardo Morandi’s individual style\nBridges designed by Riccardo Morandi stand out because of specific characteristics, which few other bridge designers adopted. While cable stayed bridges were fairly common back in the 1960s and 1970s, designs by Riccardo Morandi featured as little as two stays per span. This was unheard of at the time and rather than using traditional steel cables his designs incorporated prestressed concrete reinforced stays. While these designs may be extremely impressive on the eye, the cost of maintenance and damage from general wear and tear has proved to be significant over the years.\nWe live in an era where every dollar needs to be accounted for with many bridges designed by Morandi now costing more to maintain than they did to build. When you consider that the Ponte Morandi structure was finished back in 1967 we are looking at a lifespan of just under 50 years. The decision not to follow in Riccardo Morandi’s design footsteps has been vindicated as the life expectancy of a bridge is generally perceived to be a minimum of 100 years.\nRiccardo Morandi criticised his own work\nSince the Genoa Bridge collapse on 14 August, killing in excess of 40 people, a significant amount of surprising information has emerged. While engineers today have been critical of the initial design of the bridge, with constant maintenance required since 1970, Riccardo Morandi published his own report in 1979 recommending “constant maintenance of the structure”.\nIt would appear that the renowned designer was concerned that the “well-known loss of superficial chemical resistance of the concrete” caused by pollution from a nearby steel plant and the sea air would eventually need addressing. He proposed using an epoxy resin which would be super-resistant to the air pollution, which together with the removal of rust from the stays and addition use of filler would return the bridge to good health. The constant maintenance of the bridge continued until that fateful day on 14 August 2018, with work improving the foundations of the bridge ongoing as the structure gave way.\nUnfortunately, Riccardo Morandi will be forever remembered as the designer of the Genoa Bridge which collapsed in 2018. The fact that he oversaw the design of many more structures around the world, the majority of which still stand today, would appear to have been forgotten. While we await the conclusion of investigations into the Genoa Bridge collapse it would appear that fatal flaws in the initial design, requiring ongoing maintenance effectively since day one, were at least a contributing factor.\nUnbeknown at the time, the use of prestressed concrete stays has proven to be the downfall of Riccardo Morandi’s individual style of bridge. The fact that the Genoa Bridge has lasted just less than half of its expected lifespan is something which the revolutionary designer will forever be associated with.\nMore about bridges:\n- Types of Bridges. The 7 Main Types\n- Top 25 Most Famous Bridges in the World\n- Taiwan Bridge Collapse: A Recent Disaster That Could Have Been Avoided\n- World’s Longest | Danyang Kunshan Grand Bridge\n- Hong Kong-Zhuhai-Macau Bridge – the world’s longest\n- Why did the Urdaneta Bridge collapse in 1964?\n- Genoa Bridge collapse 2018 – how did it happen, could it have been avoided?\n- Main Parts of a Bridge – Explained\n- Designing and building the Queensferry Crossing\n- Engineering Disasters: Tacoma Narrows Bridge Collapse (1940)\n- Engineering Disasters: 25 of the Worst Engineering Failures on Record!\n- Top 10 Great Engineering Feats']	['<urn:uuid:68509000-a3ad-4b09-b9d4-439e3cb5fba6>', '<urn:uuid:e3ffbb8f-3650-4014-8b01-381edd128469>']	factoid	with-premise	concise-and-natural	distant-from-document	comparison	novice	2025-05-01T23:46:40.222380	10	41	1829
423	I'm worried about my premature baby in the NICU - what kind of tests and nursing care will they need to check their brain development?	Premature babies require careful monitoring of their brain development through various tests and specialized nursing care. Nursing interventions must be done with minimal handling during the critical first 72 hours of life, as this can significantly affect brain oxygenation. Doctors will use several types of neuroimaging tests: 1) Cranial ultrasound, which is ideal for premature babies as it can detect bleeding in the brain and is less intrusive, 2) MRI scans, which provide the clearest brain images but may require careful sedation, and 3) CT scans, though these are used more cautiously due to radiation exposure. Additionally, your baby will receive routine newborn screening tests, including APGAR scores to assess heart and respiratory health. Throughout this process, specialized neonatal nurses will provide expert care while monitoring your baby's cerebral oxygenation and development.	['- About Us\n- Continuing Nursing Education CNE - Goodfellow Unit\n- Continuing Nursing Education (CNE) Template\n- Endorsement Application Form\n- Guidelines and Professional Position statements\n- Health Central\n- Healthy People Healthy Planet\n- Interim Report of the Health & Disability System Review\n- Links of Interest\n- Managing Bullying & Fostering Health Work In Nursing\n- National Nursing Consortium\n- National Nursing Organisations Leaders Group Repository\n- Ngā aratohu maimoa hauwarea | Frailty care guides\n- Nursing Praxis in NZ\n- Professional Support Guides\n- Self Employment\n- Te Puawai - Read Online\n- Te Puawai Archives\n- NPNZ Conference 2019\n- Meet the Executive\n- Social Media\n- Terms of Reference\n- Members List\n- NPNZ Forum\n- NPNZ Executive Forum\n- What is a NP?\n- Do you want to become an NP in New Zealand?\n- Information for Employers\n- Supervisors for NP Interns Resource Toolkit\n- Examples of NP Job Descriptions & Business Case Proposals\n- NP Resources\n- Frequently Asked Questions for NPs\n- NPNZ Minutes -members only\n- NPNZ Useful Documents\n- Job Vacancies\n- Conferences & Events\n- Join NPNZ\nPlease click on each speakers photo to see their bio.\nKaren Bennington NP Neonatal\nKaren Bennington NP Neonatal\nI have been employed in Neonatal nursing since 2002, working in an advanced practice role from 2012 and as a Neonatal Nurse Practitioner (NNP) since 2016. Neonatal nursing in NZ remains an exciting and dynamic field which I am proud to be a part of. I endeavor to bring my nursing expertise as well as medical complexities to all areas of neonatal care, both clinically and with a strong involvement in research. I take pride in my ability to communicate effectively across a multidisciplinary forum and to this end, I am involved in a few select perinatal working groups and committees with the goal of improving the way we provide care to neonates and their families/whanau.\nTitle: Effects of Nursing Care on Cerebral Regional Oxygenation of Extremely Preterm Infants\nKaren Bennington, NNP1, Paula Dellabarca, NNP1, Fiona Dineen, NNP1, Maria Saito- Benz, BMBCh MSc1,2,3, Mary Judith Berry, MBBS PhD1,2,3\n- Neonatal Intensive Care Unit, Wellington Regional Hospital, NZ\n- Department of Paediatrics and Child Health, University of Otago, Wellington, NZ\n- Centre for Translational Physiology, University of Otago, Wellington, NZ\nBackground: Significant advances in the care of preterm infants has reduced morbidity and mortality.1,2 However, despite these advances, rates of neurodevelopmental disabilities remain a major concern.1 It has been proposed that neurovascular instability, and resultant variation in brain perfusion and oxygenation during the critical phase of transition plays a significant role in the pathophysiology of preterm-associated brain injuries.3 We hypothesized that common nursing care interventions can significantly influence the brain oxygenation of extremely preterm infants in the first 3 days of life.\nAim: The current study aims to characterize the effects of common nursing care interventions on the cerebral regional oxygenation (crSO2) during the first 72hrs of life in extreme preterm and low birthweight infants.\nConclusions: Minimal handling of extremely preterm infants during the critical transition period after birth has been advocated as a key guiding principle for neonatal nursing care.4 To date the physiological effects of common nursing care interventions on the vital organ oxygenation of extreme preterm infants has not been fully understood. Preliminary results of our current study suggests that cerebral oxygenation may be significantly influenced by nursing care.\n- Vohr BR. Neurodevelopmental outcomes of extremely preterm infants. Clin Perinatol. 2014; 41: 241-55\n- Berry MJ, Saito-Benz M, Gray C, Dyson RE, Dellabarca P, Ebmeier S, Foley D, Elder DE, Richardson VF. Outcomes of 23- and 24-weeks gestation infants in Wellington, New Zealand: A single centre experience. Scientific Reports. 2017; 7: 12769\n- Andersen CC, Hodyl NA, Kirpalani HM, Start MJ. A Theoretical and Practical Approach to Defining ‘Adequate Oxygenation’ in the Preterm Newborn. Pediatrics. 2017; 139: e20161117\n- Langers Minimal handling protocol for the intensive care nursery. Neonatal Netw. 1990; 9: 23-7', 'One aspect of the diagnostic process a parent will likely need to prepare a child for is the number of medical exams, evaluations and laboratory tests that can take place to determine whether or not a child has Cerebral Palsy. Though time waiting for a diagnosis is stressful, these tests and assessments allow a parent to come to terms with an eventual diagnosis, and begin early interventions.\nWhat types of evaluations are used to diagnose Cerebral Palsy?\nUnfortunately, no single test or screen will definitively confirm Cerebral Palsy. In severe cases, or under specific circumstances, a child may be diagnosed shortly after birth. In the majority of cases, however, medical practitioners will most likely observe, screen, and test the child over the first one to five years of development and growth. During this time, doctors are able to rule out conditions, including Cerebral Palsy.\nIf at all possible, it is suggested parents establish reproductive health prior to conception. Parents should become aware of risk factors that heighten the likelihood a child may develop birth defects, including Cerebral Palsy. During pregnancy, the expectant mother should immediately disclose to her doctor any exposure to risk factors and new health developments. The doctor will then attempt to properly treat, prevent, and prepare for contingencies.\nAfter a baby is born, he or she is screened for health conditions. Screens are performed on newborns, according to state guidelines or when a doctor may have cause for concern. Each state has its own guidelines detailing the types of screens standard for every newborn child. Additional screens or tests may be ordered if the medical practitioner detects a cause for concern.\nScreens are different than diagnostic tests. Screens are used to indicate a possible concern, whereas diagnostic tests are more extensive and conclusive. Infants, toddlers and children require numerous well-baby care visits in the months following birth and into school-aged years. A child is clinically monitored for growth, development, and health during this time, and parents are urged to share any concerns or noticeable differences they observe in the child. School representatives are also trained to assess age-appropriate development and growth.\nIf a child does not meet established growth standards, developmental milestones, or is having difficulty with mobility, a physician is likely to perform detailed examinations, order additional tests, or refer the child to other medical specialists. These steps are taken to rule out, or reveal, medical conditions. A compilation of test results may be required to formally diagnose Cerebral Palsy; proper identification of the condition can be a lengthy process.\nMost will agree, however, that early diagnosis is beneficial. Doctors believe parents need time to bond with their child, and they, as medical professionals, need to observe the child over time. Doctors are also concerned with properly identifying conditions in order to avoid misdiagnosis.\nOn the other hand, unwarranted delay in diagnosis should be avoided, as well. Early diagnosis allows parents not only the peace-of-mind that comes with knowing the child’s condition, but also allows the opportunity for early intervention, which can optimize the child’s development. Government benefits, funding sources, lifetime benefits, and special education offerings can be pursued after a formal diagnosis is made.\nScreens, tests and evaluations which may aid in the diagnosis of Cerebral Palsy include:\nThese screens, tests and evaluations are detailed below.\nEstablishing Reproductive Health\nPlanning a family, or learning that you’re about to start one, can be an exciting time. It is also a crucial time to begin providing for the safety of the child. Before pregnancy it is extremely valuable to consult a doctor. In the initial stages of pregnancy, a series of visits to the doctor are essential.\nMany risk factors are known to increase the likelihood of a child developing Cerebral Palsy or other conditions. Awareness is the best way to reduce risk; it’s also a good idea to know what actions to take if exposure to risks does occur.\nWhile risk factors are a significant concern during pregnancy, the threat of potential harm from exposure to those factors exists even prior to conception. Smoking, infections, exposure to toxins – everyday products, in some cases – prescription drugs, parental age, and blood type incompatibility are a few factors that can greatly impact the development of a child in the womb.\nBy visiting a doctor during family planning; assessing health status; and talking about past and current habits, risk factors can be identified.\nEstablishing reproductive health involves:\n- Reproductive Health Analysis\n- Preconception Health Check\n- Blood Compatibility Testing\nAssessing health factors and addressing any concerns will lay the ground work for a healthy pregnancy for mother and baby.\nScreens for Cerebral Palsy\nScreens are tests performed on all newborns to discover possible hidden complications in seemingly-healthy children. Tests, on the other hand, are ordered for specific infants and children, and are used to help make a diagnosis, either by confirming or ruling out possibilities.\nMany serious conditions have no visible effects on newborns, and only appear as the child grows. The goal of screening is to catch potential issues before symptoms appear. For screening, a few drops of blood are taken from the newborn’s heel and tested. Usually, parents are contacted only if lab results reveal areas for further monitoring or testing.\nNewborn screening is regulated by individual state governments; the type of screens a child receives will vary depending on which state he or she was born in. Details about the various screens required in any given state are available at the National Newborn Screening & Genetics Resource Center.\nNewborn screens administered in all states include:\n- PKU (phenylketonuria) – a condition in which the body can’t process a certain protein found in most foods, and results in cognitive impairment or brain damage\n- Sickle cell disease – a blood disorder\n- Hypothyroidism – a condition where the thyroid doesn’t produce enough hormones\n- Galactosemia – a condition in which the body can’t process the sugar galactose found in milk\nOther screens not automatically administered in all states include:\n- Hearing impairments\n- Organic acid metabolism disorders\n- Fatty acid oxidations disorders\n- Amino acid metabolism disorders\n- Hemoglobinopathies (a group of blood disorders)\nAPGAR Score. One standard screen for most all newborns in the United States is the APGAR (activity, pulse, grimace, appearance, and respiration) score. The APGAR, a standard medical test used to gauge a newborn’s heart and respiratory health, is usually recorded at one minute after birth (to assess how the baby tolerated birth) and again at five minutes (to determine how well the baby is adapting after birth).\nAPGAR does not definitively identify Cerebral Palsy, but a low APGAR score can indicate areas for concern for many medical conditions, including Cerebral Palsy. Screens are not used to diagnose Cerebral Palsy, but can be used to determine whether further tests are necessary.\nFor more information, see APGAR Score.\nTests for Cerebral Palsy\nTests are used to determine or rule out various conditions. They are more extensive and conclusive than screens. Since there is no test for Cerebral Palsy, most tests performed on children who may have Cerebral Palsy are used to either rule out other possibilities or to determine the cause, location, extent and severity of impairment. Certain tests, such as determining the presence of reflexes, can be performed during an office visit. Other tests – those of a neurological nature, for example – often require referral to a medical specialist and specialized tests.\nNeuroimaging tests are commonly used in diagnosis of Cerebral Palsy. Since impairment results from damage to the brain, neuroimaging – pictures of the brain by noninvasive techniques, essentially – allows doctors to see the actual injury. The scans, however, cannot predict the effect an injury will have on the child.\nSometimes children with an apparent injury will have no impairment, while other children with no obvious damage will develop Cerebral Palsy. Still, neuroimaging is a powerful and dependable tool in diagnosing Cerebral Palsy.\nThree Types of Neuroimaging\nCranial ultrasound/ultrasonography uses sound waves to capture an image of the brain. The cranial ultrasound is painless and the least intrusive of the possible techniques, but does not produce the same quality of results as an MRI or a CT scan. Still, results can show abnormalities, cysts, and structures in the brain.\nThe cranial ultrasound can only be used on an infant before the cranial bones are fully formed or after a fully formed skull is surgically opened, as the sound waves cannot pass through bones. The cranial ultrasound is deemed valuable on infants from birth to age 18 months that have difficulty remaining still for the 30 minutes required to perform an MRI or CT scan.\nThe cranial ultrasound is commonly performed on premature babies where bleeding in the brain, such as intraventricular hemorrhage (IVH) or periventricular leukomalacia (PVL) is suspected. IVH and PVL are two of the four causes of brain damage that may lead to Cerebral Palsy. IVH commonly develops within the first week of birth, whereas PVL may take several weeks detect. In severe cases, a cranial ultrasound may be performed one week after deliver for IVH, and again at 4 and 8 weeks of delivery if PVL is suspected.\nThe cranial ultrasound may also be used to rule out other conditions such as infections in and around the brain (encephalitis or meningitis), evaluate large or increasing head size, or screen for a build-up of excess cerebrospinal fluid in the brain at birth (congenital hydocephalus).\nMRI (magnetic resonance imaging) uses a combination of magnetic fields and radio waves to capture an image of the brain or spine. It is the preferred neuroimaging method and achieves the clearest results. The child needs to remain still for the length of the exam, which lasts around 30 to 45 minutes. It is also a very loud process which, although completely painless, can be extremely uncomfortable for children. Sedation may be necessary if this is difficult for the child. Two types of MRIs may be valuable in diagnosing Cerebral Palsy:\n- MRI of the brain is thought to define brain structure and abnormality more accurately than CT Scans or ultrasound.\n- MRI of the spinal cord is useful in detecting abnormalities of the spinal cord for children with leg spasticity, bowel complications, and improper bladder functioning. The condition may be related to Cerebral Palsy, or a co-mitigating factor.\nSedation has been used during MRIs to minimize infant movement as movement can prolong the examination and exposure. Sedation is not without risk to infants. Respiratory depression by apnea, hypoventilation, or hypoxemia is a common side effect of sedation. It is recommended that procedural sedation be administered by anesthesia department staff who are properly trained and credentialed NICU clinicians. Infants must be properly monitored for cardiac, respiratory, pulse, blood pressure and carbon dioxide measures prior and during the procedure. Staff members administer sedation, manage adverse reactions to sedation, and recover infants from sedation. It is recommended a sedation scoring tool be used to evaluate the level of sedation.\nAn alternative to sedation is to conduct the MRI during natural sleep patterns which usually follow feeding. In this scenario, an effort to reduce noise and light, while avoiding stimulation is recommended. The baby should be warm, swaddled and positioned to minimize movement. Although less risky, this option may require additional time and planning.\nCT scan (computer temography scan, sometimes referred to as computerized axial tomography, or CAT scan) combines X-rays taken from numerous angles to provide cross-sectional views of a child’s brain. The results are better than cranial ultrasounds, but not as conclusive as MRIs. The test can take 30 minutes or more. Sedation may be necessary for children who find it difficult to remain still.\nResearchers in Sweden have warned some in the medical community about the use of high doses of ionising radiation on developing brains. The study of 3,000 men who had scans before 18 months of age found the men developed learning difficulties. Similar studies, like one performed at the Karolinska Institute in Stockholm, questioned whether lower doses of radiation would decrease risk. Their study conducted on 3,094 men who received radiation as toddlers found a correlation between the intensity and learning problems. They concluded the higher the dose, the higher the likelihood an individual develops learning problems.\nBoth studies suggest new guidelines to ensure doctors do not use CT scans on young infants. CT scans use high levels of ionising radiation. If a doctor is considering this options, the parent of the child should ask the doctor about this risk.\nEKG’s, EEG’s and EMG’s\nElectroencephalography (EEG) and Electromyography (EMG) are similar tests that are performed to gain insight into how the nervous system is functioning. Both use special electrodes placed on the skin that can detect the electrical impulses created by the brain and the central nervous systems. Both tests produce line-tracings that show the “peaks and valleys” of the electricity generated.\nElectroencephalography (EEG) is not used to detect Cerebral Palsy, but instead is used to diagnose seizure disorders. Epilepsy is a condition commonly associated Cerebral Palsy. An EEG is ordered when doctors find evidence of seizures. With an EEG, electrodes are attached to a child’s scalp to detect brain activity. The procedure is painless.\nElectromyography (EMG) is used to detect nerve impulses relating to muscle activity. Nerves “fire” by sending electric impulses along their length. Before a muscle can flex, nerves need to stimulate the contraction. An EMG detects the nerve impulses sent to the muscles. Like an EEG, special electrodes are placed on the skin. EMGs are painless.\nNerve Conduction Studies (NCS) are used to detect damage in the nerves leading away from the central nervous system.\nX-Radiation (X-Rays) uses electromagnetic energy to detect density of body tissue and transfers the image to film.\nLaboratory Tests for Cerebral Palsy\nLab studies are performed when samples are taken and sent to the laboratory for analysis. The laboratory can be on or off-site. Blood work, urinalysis, and genetic testing are common examples of “lab work.” Like all tests, lab work can be used to identify or rule out conditions other than Cerebral Palsy. Common lab work uses blood or urine to discover a multitude of conditions.\nBlood tests include many different tests that help in detecting hereditary and other conditions.\n- Chemistry panels are routine tests performed on blood to gauge a person’s overall health. They are useful in analyzing major body organs.\n- Plasma screens can detect various conditions that can appear as Cerebral Palsy, for instance, plasma ammonia.\n- Chromosome analysis may detect hereditary conditions that are the cause of impairment.\n- Creatine phosphokinase (CPK) isoenzymes tests can detect injury in the heart, brain, and skeletal muscles. The type and amount of CPK isoenzymes found indicate what is injured. High levels of CPK-3 are a sign of muscle injury, or stress, and may be a factor in diagnosing Cerebral Palsy\nUrine tests are similar to blood tests in that there are many kinds of urine tests which can help to diagnose (or rule out) various conditions. Tandem mass spectrometry (MS/MS) is often used to examine the chemical contents of urine. High levels of amino acids, organic acids, or other molecules can identify various disorders. Early detection is crucial. These tests are often utilized in the newborn screening process.\nEvaluations for Cerebral Palsy\nAs part of the diagnosis process, doctors will perform evaluations of the child to judge whether impairments exist and what those impairments are. They will also evaluate extent and location of impairment. A child’s growth is measured against medical industry standards to gauge developmental delay. Age and weight appropriate mobility is assessed. Parental input on observations, concerns, or risk exposure is encourage to be shared with the medical practitioners.\nIf Cerebral Palsy is suspected, associated conditions like seizure activity, hearing, speech, sight, and learning are also explored. These evaluations may help in the diagnosis of Cerebral Palsy, as well as determine the types of tests to be performed next.\n- Mobility and orthopedic evaluation – orthopedic evaluation to ascertain reflexes, motor development, muscle tone, balance, posture, fine motor skills, and gross motor skills\n- Gait analysis – usually performed as part of orthopedic evaluation for children to ascertain difficulties with walking\n- Speech and language evaluation – oral motor analysis\n- Hearing tests – auditory analysis\n- Vision evaluation – ophthalmic analysis\n- Feeding and digestion – gastroenterologic evaluation\n- Cognitive analysis – neurologic evaluation to determine intellectual and cognitive impairment\n- Rehabilitative evaluations – to ascertain therapy and assistive technology needs\nTests and Screens\nFor other sources with general information on tests and screens for cerebral palsy, MyChild™ recommends the following:\nCenters for Disease Control and Prevention CDC\nMarch of Dimes']	['<urn:uuid:7f0cdd58-1a79-44f8-a7e2-7edf4bd666a6>', '<urn:uuid:9d822bd3-ed9f-45d5-b83a-dbbff1d229cc>']	open-ended	with-premise	verbose-and-natural	similar-to-document	three-doc	novice	2025-05-01T23:46:40.222380	25	132	3449
424	middle east religious institutions compare modern christian advocacy muslim healthcare legacy	Today's Christian institutions like the U.S. Conference of Catholic Bishops focus on advocacy and support for persecuted Middle Eastern religious communities, while the Muslim legacy in healthcare continues through their historical contributions to medical institutions, surgical techniques, and traditional treatments that are still in use today.	"[""- Prayer and Worship\n- Beliefs and Teachings\n- Issues and Action\n- Catholic Giving\n- About USCCB\nwas born in the Middle East, and churches have long made important\ncontributions to Middle East culture. But today, Christianity is under\nthreat in the land of its birth. Learn more about Middle East\nChristians and efforts to support them.\nTake Action Now! Help Persecuted Christians/Religious Minorities in the Middle East\nRead the bishops' statement on how our nation can take action in the Middle East\nLearn more about the Syrian refugee\nPray for peace in the Middle East\nSign up to be part of our advocacy network and let our elected leaders hear the voice of the Catholic community!\nVisit To Go Forth, the blog by the Department of Justice, Peace & Human Development!\nPersecuted and Forgotten? A report on Christians oppressed for their Faith 2015-17\nAid to the Church in Need\nWe must not resign\nourselves to thinking of a Middle East without Christians, who for 2,000 years\nhave confessed the name of Jesus, and have been fully integrated as citizens\ninto the social, cultural and religious life of the nations to which they\n-Pope Francis, 21 November 2013\nThe Christian presence in the Holy Lands traces its roots to the earliest days of Christianity. These small, diverse communities have historically contributed to the vibrant social fabric of their societies in the fields of science, medicine, and philosophy. Their fraternity with the diversity of Churches and other religious groups helps to foster greater interreligious dialogue, unity, and peace in the Middle East.\nIn the midst of the turbulence in the Middle East, the U.S. Conference of Catholic Bishops expresses solidarity with Christians and all those who suffer from the conflict and persecutionin the region. The Church stands at the service of all people in the Middle East, both Christians and Muslims.\nVideo: Religious Freedom and Christians in the Middle East\nChristianity was born in the Middle East, and churches have long made important contributions to Middle East culture. But today, Christianity is under threat in the land of its birth. Learn more about Middle East Christians and efforts to support them.\nLetter to Senators Corker and Cardin in Support of the Iraq and Syria Genocide Emergency Relief and Accountability Act\nBishop Oscar Cantú, June 9, 2017\nEncounter in Egypt: Trip Highlights One of Pope's Key Teachings\nCatholic News Service, May 4, 2017\nSolidarity at the Service of All People in the Middle East\nStatement expressing solidarity with Christians and all those who suffer in the Middle East.\nFebruary 10, 2017\nLetter to Representatives Smith and Eshoo Commending the Introduction of Iraq and Syria Genocide Emergency Relief and Accountability Act of 2017\nBishop Oscar Cantú and Bishop Joe S. Vásquez, January 30, 2017\nBy accepting this message, you will be leaving the website of the\nUnited States Conference of Catholic Bishops. This link is provided\nsolely for the user's convenience. By providing this link, the United\nStates Conference of Catholic Bishops assumes no responsibility for,\nnor does it necessarily endorse, the website, its content, or"", 'By: Adline A Ghani\nAlthough health and wellness may be on everyone’s minds these days, attention to wellbeing is by no means a new concept. People have been searching for ways to ‘stay in the pink’ since the dawn of civilisation. In the Islamic world, early Muslim scientists and physicians played an essential role in developing healthcare practices, tools and ethics that continue to affect our lives to this day. Among the most significant developments in healthcare brought forth by the Islamic world was the introduction of hospitals. In the 8th century, Al-Walid bin Abd Al-Malik, a Caliph (chief Muslim civil and religious ruler) of the Umayyad Caliphate (Islamic system of government of the 7th and 8th centuries ruled by Prophet Muhammad’s descendants, the Umayyad dynasty), was the first to construct a purpose-built health institution, called the . Derived from the Persian words ‘bimar’, meaning disease, and ‘stan’, meaning place, such institutions not only looked after the sick; they also actively pioneered diagnosis, cures and preventive medicines.\nHealthcare for All\nThe Middle East and North Africa had a large number of bimaristans, which were sometimes mobile and would often fulfil the role of medical schools and libraries. Among the most esteemed were Bimaristan Al-Nouri in Damascus, built in 1154 by Sultan Nour Aldeen Zanki; Bimaristan Marrakesh in Marrakesh, built in 1190 by Caliph Al-Mansur Ya’qub Ibn-Yusuf; and Bimaristan Al-Mansouri in Cairo, built in 1248 by Sultan Saif ad-Din Qalawun as-Salihi. These bimaristans were known to open their doors 24 hours a day and had hundreds of beds to receive patients, regardless of race, religion or background. Some were even known to provide patients with special attire: one kind for winter and another for summer. They not only offered their services free of charge, but also gave money to patients when they were discharged, to help make up for the wages they had lost while in hospital – a concept completely unheard of today.\nThe field of medicine would not have gone far in the Islamic world without the dedication of Muslim scholars who made numerous advances and discoveries that have enhanced our understanding of healthcare. Muslim physicians, for example, were among the first to differentiate between smallpox and measles, as well as diagnose the plague, diphtheria, leprosy, rabies, baker’s cyst, diabetes, gout and haemophilia. While Europe still believed that epilepsy was caused by demonic possession, Muslim doctors had already found a scientific explanation for it. Muslim surgeons were also pioneers in performing amputations and cauterisations. They also discovered the circulation of blood, the use of animal gut for sutures and the use of alcohol as an antiseptic. Other Muslim innovations include surgical instruments and glass retorts, as well as the use of corrosive sublimate, arsenic, copper sulphate, iron sulphate, saltpetre and borax in the treatment of diseases.\nAt the forefront of Muslim discoveries in medicine was Ibn Sina. His discovery that tuberculosis was contagious and could be transmitted through the air earned him a position as one of the greatest physicians of all time. Even to this day, the quarantine methods he introduced have helped to limit the spread of infectious diseases. The one thing that Muslim doctors did want to spread, however, was their knowledge, which is why manuscripts became so important. Illustrated in colour and sometimes illuminated in gold, manuscripts served as a fascinating visual record that provided useful information about the human anatomy, including the skeletal system, nervous system, veins, arteries, intestines, organs and muscular system.\nScribes would copy these treatises on medicine and healthcare, including ones on botany and traditional medicines. They would then be disseminated far and wide, including to Southeast Asia. It is obvious that these manuscripts were used extensively. Many show signs of considerable wear and tear, as well as extensive margin notes that demonstrate interactivity between the book and user. In this part of the world, people who studied and acquired knowledge of plants and their uses were sometimes described as the bomoh (traditional physician) or bidan (midwife). As experts on ubat akar kayu, or medicines made of herbs, roots, bark and other natural products, they would prescribe their home-brewed remedies to patients, often in the form of ready-made tablets known as jamu or majun.\nSuch time-honoured knowledge of herbs and natural ingredients has now been revitalised via biotechnology, as modern consumers looking for natural and alternative ways to maintain their wellness are increasingly turning to traditional treatments. In other parts of the Islamic world, the dispensing of remedies was often carried out by apothecaries. They were medical professionals who formulated and dispensed medicines to physicians and patients, very much like today’s pharmacists. Among the tools of their trade were apothecary boxes, which went beyond their medical utility. Often beautifully decorated with floral motifs and sometimes featuring Qur’anic verses, they frequently contained the practical components of weights and balances.\nApothecaries and Aromatherapy\nApothecaries used medicine jars called albarelli (singular: albarello) to store dry drugs and medicines that were an essential part of the treatments they practised. The jars were sealed with a piece of parchment or leather tied with a piece of cord, and the waisted shape of the vessel made removal and replacement from crowded shelves easy. Originally devised in the Islamic world, the albarello was enthusiastically adopted by apothecaries throughout Europe, often paying tribute to its origins with Islamic designs.\nMuslims were early adopters of aromatherapy as a form of alternative medicine and to promote wellbeing. Although the ancient Babylonians, Greeks and Egyptians had carried out early forms of distillation, it was Muslim chemists of the Abbassid caliphate who eventually perfected the process of pure distillation. The process was employed to purify chemical substances and also to develop attars, or perfumed oils. Incidentally, it is while distilling roses for attar that Muslim chemists discovered rose water, which is now used extensively throughout the Islamic world in religious ceremonies and in cuisine. The underlying factor behind the use of perfumed oils and rose water among Muslim communities is the appreciation that aromatic compounds can, in fact, positively affect one’s mind, mood, spirit and even health.\nWe have certainly come a long way in terms of healthcare. But in many ways, much has not changed. Viruses are becoming more resistant, toxins continue to be the scourge of modern living and each generation seems to develop eating habits even unhealthier than the one before. One thing on our side, however, is awareness – arguably the most important factor in health and wellness. Without it we would simply be ignorant. Let’s take a page from the Muslim scholars and physicians of yore and share what we know about living better and healthier lives in mind, body and spirit. As Ibn Sina once said, ‘Absence of understanding does not warrant absence of existence.’\nThis article was originally published on muslimvillage.comon September 2nd, 2014.']"	['<urn:uuid:c16c7f11-0502-4ff2-9372-9adaeee33274>', '<urn:uuid:ee47d522-8da2-431a-9f4d-d5bea64275ab>']	factoid	direct	long-search-query	similar-to-document	comparison	novice	2025-05-01T23:46:40.222380	11	46	1652
425	what material piano soundboard made of and how it works	Piano soundboards are made of solid spruce panels joined together to form one large panel. Spruce is used because it transmits sound well due to its large open cell structures and high strength to weight ratio. The soundboard works by transmitting the vibrations of the strings to the air via treble and bass bridges.	['A short compilation of basic & simple terminology and definitions for parts commonly used in the rebuilding process.\nAction: The playing mechanism(s) of the piano.\nAgraffe: A guide (usually brass) in which unison strings pass through to make a termination point at the end of the string toward the front of the piano. Agraffes are screwed into the cast iron plate, (or harp) and acts as a physical anchor for and also regulate the height of the string unison.\nBackcheck: A suede, leather or felt covered catcher which is fastened to the end of the piano key via a wire post. The backcheck “catches” and holds the piano hammer just after it has rebounded from striking the string and while the action below the hammer is preparing for another repetition of the note.\nBelly: The piano soundboard area. Included in the generic term for the belly “area” may be the soundboard, bridges, belly rail, dampers, plate (harp) tuning pins and pinblock.\nBridge: Treble and Bass: Long shaped and carved hardwood rails usually maple or other hardwood, which span across the soundboard and guide strings to transfer vibration from strings to the bearing surfaces of the bridge to the soundboard. Bridges are sometimes capped, are notched and are pinned for unison groupings of strings.\nBridge Pins: Steel, chrome, nickel, brass or copper plated pins seated into the bridge (either treble or bass) to exert side bearing to strings upon the bridges and align strings for proper spacing at the bridges.\nCapstan: A threaded brass nut with polished top cap that is inserted into the top of the back end of the piano key. The whippen is raised via the piano key when depressed in order to begin the process of parts rotation and deliver the piano hammer to the string.\nFlange: a part which is fastened to and enables other major components to travel. Flanges found within the action such as the whippen flange or hammer flange allow those major components to travel in an arc. Flanges have tiny pivot holes drilled through them and are attached to their respective major component via a center pin.\nHammer: A felted mallet which is driven to the strings by the piano action to participate in producing piano sound. Piano hammers have a spring like action due to two present forces: tension and compression. Highly compressed felt is formed around a wood core under tremendous pressure to make piano hammers.\nHammer shank & flange: A hardwood dowel which connects the hammer to the hammer flange. Also shown is the knuckle which is attached to the underside of the hammershank.\nKey: A dual lever arm which pivots at the balance rail. Piano keys are made of soft wood (conifer) varieties including sugar pine, basswood and sometimes spruce. The back end of the piano key raises the whippen via the capstan which consequently raises the hammer toward the string. The piano key is in itself a complex mechanism which includes weights for control of touch weight, the key- top, button, capstan, backcheck and two mortises for felt bushings.\nKeytop: A key covering of ivory in the case of older pianos, or synthetic plastic in more modern pianos which covers only the top and front surfaces as a veneer to the key. Shown in this picture is a synthetic covering.\nKey Button: A felt bushed wooden plate installed at the top of the piano key to add strength, and help guide the key during travel.\nKey Bushing(s): Felt inserts at the key front and balance mortises which help to align and guide key travel during play. Key bushings are carefully regulated for minimum resistance or friction during play.\nDamper: Soft block or triangular shaped felts which are timed to stop the vibration of the piano strings at a carefully calculated point. Therefore, dampers silence vibrating strings when they are rested upon them. This either occurs at the release of the piano key or when the right or “sustain” pedal is released and no notes are held by contact with the piano keys.\nIvory (ies): Traditional (older) key coverings made from elephant and other mammal tusk material.\nKeybed: The structure upon which the keyframe, keys and action rest inside the piano.\nKeyframe: A wooden frame consisting of slats and rails which holds the keys and action. The keyframe has two rails with complete sets of keypins for guiding key travel, glides which are incorporated into the underside of the keyframe for bedding purposes and to reduce friction at the shift position of the una-corde pedal. Three rails which are the front, balance and back rails are all felted for different function of key travel and rest.\nKeypin: A nickel plated steel pin found at the front and center rails of the keyframe for key alignment and travel purposes.\nNatural(s): White keys or keys that are not “sharps”.\nPedals & Pedal Lyre: Levers which the feet control to either sustain notes being played (right or sustain pedal), soften tone from piano by shifting the action to change hammer contact with strings (the left or una-corde pedal, or to sustain individual notes being played (the middle or sostenuto pedal).\nPinBlock: Sometimes also called the “wrest-plank”, the pinblock is a large thick multi layered block of hard wood (often hard rock maple) used to anchor tuning pins. The block is fastened to a shelf at either end of the piano’s inner rim with dowels and screws. The purpose of the pin block is to provide resistance to tuning pin torque which is required to keep individual strings and notes at “pitch”.\nRegulation: A term used to describe the physical adjustments necessary to allow the complex mechanisms of the piano action to cycle properly and therefore to optimize touch, response and tone. Regulating a piano requires many steps which include:\n- Keyframe bedding to keybed\n- Necessary repairs to the action\n- Friction reduction\n- Key rebushing\n- Key height, square and leveling\n- Parts alignment\n- Repetition spring adjustment\n- Jack and repetition lever alignments\n- Let off and drop regulations\n- Jack tail and drop screw to contact points timing and synch\n- Backcheck alignment and adjustments\n- Damper timing and regulations\n- Voicing of piano hammers\nPiano Tuning: Piano Tuning is a process and procedure which ultimately alters the pitch and timbre of our instrument. We use tuning as a means to positively change the intonation of the piano to best suit our standard of equal temperament and compliment the diatonic scale.\nBecause it has been determined that the equal tempered scale is the most acceptable configuration for our musical traditions, we have long designed our pianos to work best with this standard.\nPiano tuning is therefore the physical manipulation and movement of the approximately 209 tuning pins which will in turn alter the tension of the wire which is attached to each tuning pin, in order to alter pitch, either higher (sharp) or lower (flat). Each note is “set” at a place which contributes to an overall formula for the distribution of frequencies and beat rates that we find most pleasing to our ear.\nSharp(s): Another term for black keys.\nSoundboard: is an arched wood panel covering the entire area under or behind the piano strings within the inner rim of the piano which transmits the vibrations of the strings to the air. This is done via treble and bass bridges. High quality piano soundboards are made of solid spruce panels similar to the width of the hand and joined together to form one large panel. Spruce varieties transmit sound well and are suitable for this difficult and critical task due to large open cell structures and a very high strength to weight ratio.\nTuning Pin: Threaded steel “peg” around which the piano wire around which every string is wound. Commonly approximately 2 ½ inches long, each tuning pin is seated by pounding approximately 1 ½ “ into a laminated wooden wrest-plank or pin block made of maple in order to keep strings in tune.\nWippen (Repetition): is a central combination component of the piano action. Also known as the “repetition”, wippens or repetitions facilitate parts rotation(s) which occur between the piano key and the piano hammer. Via a complex series of interactions and motions each note is capable of playing, repeating and becoming ready to play again in large part due to the individual components encompassed within, and the overall function of the whippen. The whippen is housed above and on top of the piano key and below the piano hammer.\nWire, Bass String(s): Heavy gauge strings which are found in the bass and sometimes tenor sections of the scale, bass strings are steel core with copper windings of differing diameters depending on their position in the scale.\nWire, Piano (Treble): Steel wire of differing diameters found in sections other than the bass of the piano scale.']	['<urn:uuid:ecc6a7c3-4935-45bb-9d0b-7c7ec27b02bd>']	factoid	direct	long-search-query	similar-to-document	single-doc	novice	2025-05-01T23:46:40.222380	10	54	1480
426	international export procedures hazardous goods regulations workplace safety precautions	For international shipments, specific permits and licenses are required based on material nature, origin, destination, and final use, with costs ranging $750-$1,100 through shipping agents. Additionally, businesses must maintain a GHS compliant environment by following established protocols and displaying appropriate warning labels to avoid workplace injuries and legal consequences.	['DO NOT SHIP BIOLOGICALS, CHEMICALS OR RADIOACTIVE MATERIALS WITHOUT READING THIS PAGE FIRST!\nYou should be aware that shipping research materials within the United States and Internationally has become a highly regulated process.\nThe shipping of hazardous materials can pose a serious danger to human health, property and the environment if the materials are improperly packaged and labeled and release their contents during transportation. For example, an incorrect package can be easily crushed and the containers broken resulting in liquid or solids leaking from the package contaminating handlers and anything in the area. The legal, regulatory and clean-up costs can be in tens of thousands of $$. The US Department of Transportation and the Federal Aviation Administration can and has imposed large fines ($$$$) and possible jail time for persons who knowingly or unknowingly violate these regulations.\nBottom line: Contact Tufts Environmental Health and Safety and ask for advice on shipping chemicals and biologicals.\nTufts University does not operate a centralized shipping service on any of its campuses. Hence, each employee is responsible for packaging, shipping and documenting hazardous materials shipments.\nThe rules for shipping biologicals are complex however the Biosafety Program at Tufts offers a training program on a scheduled basis for persons who need to ship biological materials: human blood, human or primate cell lines, preserved biologicals, microbial agents. In addition, these shipments may involve ethanol, formaldehyde, dry ice or liquid nitrogen which are all hazardous chemicals and have to be shipped as hazardous chemicals. Please see Tufts EHS trainings for “IATA/DOT Regulations for the Shipment of 6.2 Biologicals, Infectious Substances and Class 9, Dry Ice Dangerous Goods Training.”\nThe rules for shipping chemicals are complex however the Chemical Safety Program offers a training program for individuals who need to ship chemicals routinely as part of the their job. Please see Tufts EHS trainings for “IATA/DOT Regulations for the Shipment of Chemicals, Hazardous Materials and Dangerous Goods Training.”\nAll of EHS trainings can be found at:\nInternational shipping regulations vary widely from country to country. Tufts University EHS is not expert in the specific shipping regulations for all foreign countries. Also, some goods may require an export license, such as CITES (fish and wildlife) material, some pesticides and materials that are controlled under anti-terrorism and warfare laws. The 4 US agencies which may require an import/export permit are: USDA, CDC, Department of Commerce and Fish & Wildlife.\nThe license/permitting requirements will depend upon the following criteria:\n- Nature of the material\n- Country of origin\n- Country of destination\n- Final use\nEach of these factors will affect which regulatory agencies are concerned with the consignment and consequently what licenses and/or documents will be required.\nFor international shipments we strongly recommend the hiring of a customs broker or shipping agent to guide you through this complex process. Shipping agents are listed below:\nWorld Courier: http://worldcourier.com/\nUtilizing one of these vendors will cost between $300-$500 for a domestic shipment and $750-$1,100 for an international shipment which includes the vendor completing various permits, licenses and custom’s paperwork.\nIf you wish to proceed to ship the package yourself, have the recipient of the shipment check for any necessary import permits needed in order to bring materials into the destination country. Each country has specific requirements. If appropriate paperwork is not received by the customs official in the destination country, the material will not be allowed entrance. In some instances, the customs office may contact you and the paperwork will be rushed and in other cases the package will be destroyed. Therefore, it is highly imperative to work out paperwork requirements before sending the package to an international location. A good starting point to determine US export/import requirements is to contact the National Center for Import/Export (NCIE) at 301-851-3300.\nQuestions regarding country-specific requirements are usually best answered by officials at the receiving country’s embassy. Contact information can be found on the Embassy.org website. http://www.embassy.org/embassies/\nAlways contact the country’s customs office before planning an import, especially in the beginning when learning the international shipping procedures of a country.\nPlease note: In 2007 the Department of Commerce issued a $100,000 fine to a local university for exporting equipment to Pakistan without first obtaining the proper license.\nIn 2011, the FAA issued a $175,000 fine to another local university for shipping lithium batteries without proper labels and documentation.', 'GHS pictograms, workplace hazard warnings and warning labels can provide essential safety information for employees and associates of organisations and businesses that utilize or transport potentially hazardous materials. Failing to maintain a GHS compliant working environment can become a serious issue, one which may increase the risk of a workplace accident or injury. Signs and labels designed to warm employees regarding the potential health and safety risks of hazardous materials play a vital role in workplace safety and can be especially important in day to day operations that involve transporting dangerous goods or working with industrial chemicals.\nCreating and Maintaining a Safe Workplace\nWorkplace safety is a concern that no business owner, employer or management professional can afford to overlook. Failing to display appropriate warning labels and GHS pictograms that provide essential safety information can drastically increase the risks of a workplace injury. Businesses that fail to maintain a GHS compliant environment by posting clearly marked workplace hazard warnings and ensuring that all employees take proper precautions and follow establish protocols when working with or transporting dangerous goods may find themselves facing steep fines and penalties. Failing to create and maintain a safe working environment often means that businesses are more likely to be faced with legal action resulting from a preventable accident or injury.\nRegulations Governing Workplace Hazard Warnings\nThere are numerous regulations pertaining to the signage and warning labels that must be displayed in environments that contain potentially hazardous materials. Businesses are legally required to utilize the Hazardous Materials Identification System, GHS pictograms and Material Safety Data Sheets whenever working with or transporting dangerous goods, industrial chemicals and hazardous materials. Maintaining a GHS compliant working environment involves understanding and following numerous regulations and guidelines in order to ensure workers and bystanders are not being placed at greater risk.\nThe Globally Harmonized System is a set of guidelines established to ensure the safe manufacture, handling, transport and disposal of materials that may pose a potential health and safety risk. GHS pictograms are designed to be universal and easily understood in order to reduce the potential confusion caused by language barriers. GHS regulations require businesses and organisations to display specific pictograms, HAZMAT diamond placards and other specially designed warning labels when working with or transporting hazardous materials. Violating GHS regulations or failing to comply with established rules, guidelines and protocols can result in numerous legal consequences that may include fines, financial penalties and even loos of certain business licences.\nEnsuring all working environments, transport operations and workflow process are GHS compliant can be of paramount importance. Transporting dangerous goods in an improper manner or failing to display the correct workplace hazard warnings is a serious OSHA violation, one that may result in greater instances of work-related accidents or even place the health and safety of bystanders at risk. Businesses who fail to make workplace safety a top priority are far more likely to be charged with compliance violations that can result in fees, fines and even legal action.Back to top']	['<urn:uuid:07034cad-83c9-4c1f-ad3b-ad033de07935>', '<urn:uuid:031871cb-39ca-4caa-b449-ec9af22d7fbc>']	factoid	direct	long-search-query	distant-from-document	multi-aspect	expert	2025-05-01T23:46:40.222380	9	49	1223
427	I'm a workshop owner and I've been thinking about getting a band saw. What features make it good for different types of cuts, and what safety measures should I keep in mind to prevent injuries?	Band saws are versatile for both straight cuts and irregular shapes. They can cut tenons, rabbits, rip small pieces and resaw thin strips. For curved cuts, a vertical band saw is ideal as the workpiece moves through a stationary blade. For straight cuts, horizontal band saws work well as the blade swings down through stationary material. Regarding safety, proper machine guarding is essential - guards must provide physical barriers to hazardous areas, be secure and strong, and prevent operator tampering while not obstructing view. The guards must be properly affixed to the machine and not create additional hazards. For optimal safety, replacement guard materials must meet or exceed manufacturer's original specifications, as demonstrated by a fatality case where weaker plexiglass replacements failed to stop projectile parts.	"['The Band Saw – One of the Most Versatile Power Tools Today\nBand saws are one of the most common power tools used today and can be found in the workshop of serious and amateur woodworkers and metalworkers alike. A standard band saw consists of a serrated blade or continuous band of small metal teeth, that forms a continuous loop. The blade is extended over two pulleys, one of which remains idle and the other which is driven by an electric motor.\nThe most common use for the band saw is to cut irregular shapes and curves in materials, even in thick lumber and durable metal. However, it is capable of a lot more such as cutting tenons and smaller rabbits, as well as ripping small pieces of stock and resawing thin strips of wood.\nThose in the woodworking and metalworking industries rely on the band saw for a lot of their work, however, they’re also useful for cutting a range of other materials as well. Due to the fact that they can perform straight cuts or irregular ones, they’re an extremely versatile power tool to have on hand.\nThe History of the Band Saw\nBand saws have had quite a slow-moving progression from their very first form many years ago. Invented around 1809, an Englishman named William Newberry received a patent for the idea of the first band saw the prototype. However, due to the constant flexing of the band saw blade over its turning, it was largely impractical as it caused the material of the joint to fall.\nCommonly mistaken for the original invention of the band saw, in 1846 a Frenchwoman named Anne Paulin Crepin devised a method whereby a welded band saw blade meant that the machine could endure the harshness of sawing and bending that occurred around the band saw wheels.\nIn 1933, Mr. Wilkie who developed the first practical metal cutting band saw.\nFollowing this amendment to the machine, many more were made which lead us to the modern band saw we know today. With continual improvements in technology, the band saw will be set to make further advancements that improve its overall efficiency and functionality.\nThe Parts of A Band Saw\nA band saw has many parts, and these can vary greatly depending on the type of band saw. Some functions may be purely for safety, others are to assist in a precise cutting action, but all are as important as the last in constructing this versatile power tool.\nIt’s fair to say that without the blade, this machine’s cutting capability wouldn’t exist. The blade of a band saw is formed in one continuous loop, consisting of smaller teeth that make up its serrated edge. Blades are interchangeable depending on the project and material at hand and give this machine the ability to provide a range of different cuts.\nThe table of a band saw is where you place your workpiece, usually held in place with a vise. Many users prefer to build their own custom table to suit their workspace, either by adding on or constructing a new one altogether. Some tables can be connected to existing band saws to allow them to switch between horizontal and vertical cutting capabilities which give the user a greater range of cutting capabilities than just a singular type.\nThe wheel cover’s primary purpose is to protect the user from the blade, and it can be lifted to make adjustments to the blade or to change the blade over. The wheel cover protects the majority of the belt from exposure and leaves only the part of the blade exposed that will perform cuts.\nThe electric motor is one of the band saw parts that dictates how much power your machine will have. While a larger motor is more powerful, it can make the machine harder to maneuver. Likewise, if you’re using a portable band saw, you may find the power lacking as it needs to be easily transported and lightweight.\nThe upper wheels on a band saw have two important functions. Firstly, they provide blade tension or the release of tension for when you need to change blades. Secondly, they allow you to adjust the wheel’s angle so that the saw blades track correctly.\nDust collectors may not be available on all models, but they’re an extremely useful accessory for your band saw to have. Sawdust from woodworking and dust from other materials can be extremely dangerous for your health as it enters your respiratory system or eyes, and slippery sawdust on the floor of a workshop can contribute to slips and trips. A dust collector simply vacuums up any unwanted material as you work and keeps your work station clean.\nGuides are one of the most important band saw parts, with two present on each machine. These guides are responsible for stabilizing the blade so that the cuts are accurate. Due to their importance, these guides require constant attention and alignment. Each guide has three components, including a thrust bearing, and one block on each side of the blade. The thrust bearing stops the blade from being pushed to the back when cutting.\nA Step By Step Guide to Using Your Band Saw\nEach band saw is unique, so you should always consult the manufacturer’s manual before operation. These are some common steps for using a benchtop band saw that will ensure your safety and a precise cut.\n1. Choose the Correct Machine\nThere are so many factors to consider when selecting a band saw, some of which include cutting speed, blade length, safety measures, and capacity. Try to keep in mind what the main priority of your work will be before looking at the options.\n2. Assemble Your Machine\nBand saws for home use require construction so they can be adjusted to meet your personal specifications. Consult the manufacturer’s handbook that comes with your band saw for any specific information. Ensure you are working at the correct height, there is sufficient light in your workshop, and your machine is fastened to the benchtop correctly if working with this type of machine.Select your blade\n3. Select Your Blade\nAgain, this will change according to the project you’re working on. When considering the blade, you’ll need to look at the blade width and teeth per inch. Each blade will give you either a wide or narrow cut, and a smooth or rough finish.\n4. Adjust Blade Tension\nAlways remove the band saw from its power source before you do this, as this is known to cause many injuries. To test the tightness of the blade, raise the blade guide to maximum height, and press sideward against the blade. If required, adjust the blade tension according to the manufacturer’s manual.\n5. Check the Blade Tracking\nRemove the wheel cover and turn the upper wheel by hand, keeping an eye on the blade’s position. If its runs in the center of the wheel without wobbling for at least 20 revolutions, it’s safe to use.\n6. Set the Blade Guides\nIf you’re using a benchtop saw, chances are it has a movable blade guide. Move the guide so that it’s close to the wood stock you’re cutting, but without the possibility of binding or jamming the material.\n7. Adjust the Table\nTest this with a square piece of stock to see how well it aligns for a square cut. Some saws are automatically preset to zero on an angle indicator, so use the 0 or 90-degree mark to perform this.\n8. Set Miter Guides\nIf using a miter guide to make a straight cut, ensure it has been set correctly. This will allow it to hold the stock in line when performing a straight line cut.\n9. Mark Your Cut\nUsing a lead pencil, mark your wood or other material where you intend to cut it. This will allow for a precise cut and leave no room for errors.\n10. Check Clearances\nBefore you make your cut, be sure that your stock will be able to turn and move freely when required, otherwise, it will become stuck midway through.\n11. Make Your Cut\nNow it’s safe to turn the machine back on and perform your cut. Let the blade come up to speed, and keeping your fingers as far away as possible, feed the material into the blade.\nTypes of Band Saw & Their Uses\nBand saws have branched out to cover a wide range of purposes and users, from amateur carpenters to commercial timber yards. The advancements that band saws have made since their invention in the 19th century have allowed this power tool to stay relevant and useful in modern workshops.\nMetal Band Saw\nA metal band saw is the ideal choice for tasks that require a smooth cut through metal. These band saws come in either horizontal or vertical varieties, depending on the type of cut you’re after.\nFor a straight cut through metal or to bring the stock down to size, the horizontal saw is ideal. However, if you’re looking to perform more precise jobs such as filing, polishing, and creative cuts, a vertical band saw is best.\nMeat Band Saw\nFavored by professional and at home butchers, the meat band saw makes light work of cutting through meat and bones. They’re crafted with stainless steel, making them easy to keep clean, and ideal for easily cutting portions of meat for commercial sale or private consumption.\nWood Band Saw\nThe wood band saw is one of the most common types, hailed for its versatility with woodworkers. Both amateur and professionals rely on their band saw to perform curved cuts through wood, or to cut stock down to size.\nSmaller wood band saws are generally found in workshops, where the larger scale models are employed by timber mills for their ability to rip lumber quickly and easily. Unlike other tools, the wood band saw is able to work with large pieces of timber which makes it ideal for commercial grade ripping.\nVertical Band Saw\nA vertical band saw remains stationary as the workpiece moves through the blade, making it unique to the horizontal band saw method. This allows the saw to create intricate cuts and curved lines, as well as standard straight ones.\nVertical band saws also come with an inbuilt welder, allowing the user to create their own blades for custom jobs, or repaired old and damaged blades.\nHorizontal Band Saw\nThe horizontal band saw operates slightly different to the vertical in how the blade cuts through the workpiece. Your material is held down in a stationary position while the blade of the band saw swings down through the cut.\nThese machines are ideal for ripping timber and performing straight and precise cuts, but not able to create any complicated curves or shapes.\nPortable Band Saw\nPortable band saws are a handy invention that lets you take your machine with you. A portable band saw might suit professional carpenters who visit different sites for their work, or simply the home carpenter who needs a bit of freedom with their tool.\nA portable hand saw can do anything the other styles can do, including straight edge cuts, curvaceous lines, and irregular shapes. They also have the added bonus of a battery pack meaning you don’t always need a direct power source to operate them.\nThanks to their movability, these saws can be taken into nature and used to cut railroad ties or even metal poles and can work with the body of a larger workpiece that might not be easy to transport to the workshop.\nDifferent Band Saw Blades\nThe band saw blades come in such a wide variety due to each one’s specific ability to handle a workpiece. Never ideal to have just one style of blade for your band saw, you should have a variety of blades available that can suit various projects and various band saw prices.\nThe band saw blades also need to be chosen according to your workpiece. If you’re performing metal cutting there is an entirely different set of guidelines to follow than wood cutting. According to Super Cut, manufacturers of the band saw blades, there are three main steps to finding the right blade for your project:\n1. Choose the Band Saw: What type of band saw are you using?\nDepending on what type of band saw you’ll using, each has a preferred blade.\nFor metal cutting band saws, a carbon tool steel or bimetal blade is best. Carbon blades are ideal for home workshops as they’re economical and ideal for cutting mild steel. Bimetal blades suit those band saws being used in a production setting as they offer a longer life and durability. A bimetal blade is costly but can last 10 times longer than a carbon one, so they suit commercial use more, and they’re capable of cutting harder metals such as stainless steel.\nFor wood cutting, opt for carbon tool steel, premium gold carbide or specialty resaw blades. Premium gold carbide blades are long lasting and fast cutting, ideal for serious woodworkers. Carbon tool steel is versatile and can be used for both wood and metal, but are better suited for wood or very light materials.\n2. Choose A Width: How tight do you need to turn?\nBand saw blades will be determined also by whether you’re using a horizontal or vertical band saw. For a horizontal band saw, you’ll only ever need one width of blade as this is all they’re designed to use. Vertical band saws, however, can use a number of widths depending on your desired range. Check the minimum turning diameter for each specific blade before using.\n3. Choose the Tooth Pattern: What are you cutting?\nAgain, this will depend on the material you’re cutting, as both wood cutting and metal cutting band saws have their own guidelines to achieve different cuts.\nWood cutting band saws generally follow the rule that the fewer teeth per inch you have, the faster and rougher cut you’ll have. Alternatively, the more teeth per inch will give you a smoother, but slower cut. It all depends on your project at hand and the type of workpiece.\nMetal cutting band saws determine their tooth pattern by the thickness of the material you’re working with. Go with band saw blades that have fewer teeth per inch for thicker materials, and more teeth per inch when cutting thin materials.\nBest Brands of Band Saw\nWith so many band saws on the market, it can be hard to pick the good from the bad. For the purpose of this guide we’ve compiled a list of the three best band saws for woodworking, metal working, and portable machines, all within the standard range of band saw prices.\nBest Wood Working Band Saw\nThe Grizzly G0555LX band saw is ideal for woodworking projects. It has a solid cast iron frame that reduces any vibration, giving you a smooth cut every time. This band saw includes a rip fence, dust port, and re-sawing attachment as well, so there’s no need to make your own. It has a minimal setup out of the box and is already pre-aligned for ease of use.\nIdeal for: This band saw would suit first time users looking for a quality machine that is easy to use. Its ability to perform superbly smooth cuts through wood make it a carpenter’s best friend, whether you’re just a beginner or have years of experience.\nPrice guide: For the Grizzly G0555LX you’re looking at roughly $800 – $900, plus shipping. While it might seem more expensive than comparable brands, its guaranteed quality means this machine will last for years.\nBest Metal Working Band Saw\nAlthough many band saws claim to be safe for both wood and metal cutting, it’s best to stick to a specially designed metal cutting band saw to ensure a quality cut. The Shop Fox W1715 3/4 HP Metal Cutting Band Saw features a 4-inch dust hood inbuilt, cast iron handwheels and extension wings, and a blade that can tilt to 45 degrees right.\nIdeal for: Metalworking band saws are great for a variety of jobs involving sturdy materials. This machine also features a vertical cutting attachment, meaning it can perform straight cuts or trickier more intricate curves.\nPrice guide: Generally priced at around $450 plus postage, this sits well within the average price guide for a quality metal cutting band saw.\nBest Portable Band Saw\nThe Milwaukee 6238-20 AC/DC Deep Cut Portable Two-Speed Band Saw is our pick for best portable band saw, thanks to its powerful 11-amp motor. It features two distinct speeds for versatility and comes from one of the most reputable manufacturers of power tools on the market. It’s amazingly quiet and offers an extremely accurate cut for a portable machine.\nIdeal for: This portable band saw is so diverse that it would suit not only mechanics and construction workers but also woodworkers and carpenters. It’s ideal for those users on the move and comes with a battery operated option, however, the battery must be purchased separately.\nPrice guide: This machine is excellent value for money at $$$ – $$$$, including shipping.', 'Enforcement citations FY 2018: 1,700\nNumber of inspections: 1,567\nProposed penalties: $10,407,511\nMost frequently cited industries\n- Wholesale trade\n- Retail trade\n- Waste management and remediation\n- Accommodation and food services\n- Public administration\nEnforcement case study\nOn January 24, 2018, OSHA cited Supplyside USA, a pallet manufacturer, for machine safety violations after an employee was injured while conducting maintenance on equipment. The company faces $91,832 in proposed penalties for two repeated, six serious, and three other-than-serious violations.\nOSHA inspectors found Supplyside USA, which operates as Prime Woodcraft Inc., failed to install adequate machine guards, implement energy control procedures to prevent equipment from unintentional operation, and train workers about noise hazards; and allowed combustible dust to accumulate on surfaces.\n“Too often, employees are injured because companies lack adequate machine safety procedures and safeguards,” said OSHA Chicago South Area Office Director Kathy Webb. “Employers have a responsibility to evaluate their workplaces for hazards, and ensure safe operations.”\nFatality case study\nOSHA’s Denver Regional Office reported a fatality caused by the installation of transparent replacement guarding material having a lower impact resistance than the manufacturer\'s original guard for the machine.\nThe fatality involved the use of plexiglass as the machine guarding window for a lathe. The fatality occurred when the bell casting on a lathe became loose while the lathe was turning and subsequently struck an employee in the head and neck as he was looking through the window. The bell casting was propelled through two, 1/2 -inch-thick plexiglass material windows. The plexiglass material windows were installed as a replacement for the manufacturer\'s original composite window on the machine\'s door frame.\nThe manufacturer\'s original observation window was made of a 1/4-inch-thick laminated glass plate with a 1/2-inch-thick polycarbonate window, separated by an approximately 1/4-inch air space. The original window was replaced with plexiglass material that had a lower impact resistance than the polycarbonate shield originally supplied by the machine manufacturer.\nVarious polycarbonates have different impact-resistance characteristics for different thicknesses and/or surface areas. It is important to note that increasing the thickness beyond a certain level does not always improve or increase the impact resistance characteristics.\nReplacement machine guard windows must meet or exceed the manufacturer\'s original design specifications.\nWhen replacing original equipment parts, OSHA recommended employers review the specifications and ensure that the specifications of replacement materials meet or exceed the original design specifications.\nMoving machine parts have the potential to cause severe workplace injuries, such as crushed fingers or hands, amputations, burns, or blindness. Safeguards are essential for protecting workers from these preventable injuries. Any machine part, function, or process that may cause injury must be safeguarded. When operation of a machine or accidental contact injures the operator or others in the vicinity, the hazards must be eliminated or controlled.\nAmputations occur to fingers, hands, feet and other body parts, mostly through compression, crushing, or by getting caught between or struck by objects. Most amputations involve fingertips. Employers must workers protect from amputation hazards through adequate guarding and employee training.\nMachine safeguarding is the best way to prevent amputations. Guards provide physical barriers to hazardous areas. They should be secure and strong, and workers should not be able to by-pass, remove or tamper with them. Guards should not obstruct the operator’s view or prevent others from working.\nDevices help prevent contact with points of operation and may replace or supplement guards. Devices can interrupt the normal cycle of the machine when the operator’s hands are at the point of operation\nKey Machine Guard standard takeaways\n- The standard covers woodworking machinery, abrasive wheel machinery, mechanical power presses, and other specific machinery. For the construction industry, the standard covers hand tools, power-operated hand tools, abrasive wheels and tools, woodworking tools, jacks-lever and ratchet, screw and hydraulic, air receivers and mechanical power-transmission apparatus\n- Types of guarding. One or more methods of machine guarding shall be provided to protect the operator and other employees in the machine area from hazards such as those created by point of operation, ingoing nip points, rotating parts, flying chips and sparks. Examples of guarding methods are-barrier guards, two-hand tripping devices, electronic safety devices, etc.\n- General requirements for machine guards. Guards shall be affixed to the machine where possible and secured elsewhere if for any reason attachment to the machine is not possible. The guard shall be such that it does not offer an accident hazard in itself.\n- Point of operation guarding. Point of operation is the area on a machine where work is actually performed upon the material being processed.\nThe point of operation for machines whose operation exposes an employee to injury shall be guarded. The guarding device shall be in conformity with any appropriate standards therefor, or, in the absence of applicable specific standards, shall be so designed and constructed as to prevent the operator from having any part of his body in the danger zone during the operating cycle.\nSpecial hand tools for placing and removing material shall be such as to permit easy handling of material without the operator placing a hand in the danger zone. Such tools shall not be in lieu of other guarding required by this section, but can only be used to supplement protection provided.\nThe following are some of the machines which usually require point of operation guarding:\n- Guillotine cutters\n- Alligator shears\n- Power presses\n- Milling machines\n- Power saws\n- Portable power tools\n- Forming rolls and calendars\n- Revolving drums, barrels, and containers shall be guarded by an enclosure which is interlocked with the drive mechanism, so that the barrel, drum, or container cannot revolve unless the guard enclosure is in place.\n- When the periphery of the blades of a fan is less than seven (7) feet above the floor or working level, the blades shall be guarded. The guard shall have openings no larger than one-half (1/2) inch.\n- Machines designed for a fixed location shall be securely anchored to prevent walking or moving.\nThe following references aid in recognizing hazards from ineffective machine guarding.\n- Machine Guarding. OSHA eTool. Focuses on recognizing and controlling common amputation hazards associated with the operation and use of certain types of machines.\n- Machine Guarding: Horizontal Injection-Molding Machines - Interactive Safety Tour. Allows user to take a virtual tour of an injection-molding machine.\n- Amputations. OSHA Fact Sheet, (2002). Provides a general overview of amputations in the workplace.\n- Potential Hazards Associated with the Use of Replacement Materials for Machine Guarding (PDF). OSHA Hazard Information Bulletin (HIB). Clarifies that replacement machine guard windows must meet or exceed the manufacturer\'s original design specifications.\n- 29 CFR 1910.217(g) Mechanical Power Press Point of Operation Injury Reports: 8/1994-12/2000. OSHA. Summarizes ""point of operation"" injuries from mechanical power presses.']"	['<urn:uuid:d2e2fdd9-9525-454e-8828-6440190ef398>', '<urn:uuid:b77280bf-732d-4c5a-b38f-57c7dacc0870>']	factoid	with-premise	verbose-and-natural	distant-from-document	multi-aspect	novice	2025-05-01T23:46:40.222380	35	126	3981
428	I've noticed my sprouts sometimes ferment when I'm rinsing them - what's the proper rinsing technique to prevent fermentation during the sprouting process?	To prevent fermentation, you should rinse the seeds two to three times daily with cool, fresh water. The crucial step is to completely pour off all water in the jar after each rinse, as seeds will easily ferment if they remain soaked. Proper air circulation is also important, so if storing the jar in a cabinet, leave the door slightly open.	"['Two things you\'ll need when you\'re learning how to grow sprout are a glass jar and some sort of strainer to cover it.\nPHOTO: MOTHER EARTH NEWS STAFF\nJust in case you\'ve wanted to know how to grow sprouts but have never tried, here\'s a quick refresher course in the basic technique.\nThe most common method of germinating seeds for the table requires a wide-mouthed quart jar. Measure about 1/2 cup of dry beans, or 2 to 3 tablespoons of tiny seeds, into the glass container, and then half-fill it with water. You\'ll need to fit some kind of sieve over the jar to allow water — but not seeds — to pass through. It\'s possible to use a piece of cheesecloth or old nylon stocking with a rubber band around the rim to hold it securely, or to buy a screw-on ring with stainless or plastic mesh already attached. (The screened lids come with various sizes of holes to accommodate many different types of seeds. They\'re available in any health food store.)\nLet the seeds soak overnight, and then pour off the water ... which will probably have clouded up just a bit. (That liquid, by the way, makes a wonderful fertilizer for your houseplants, since it\'s loaded with minerals that were leached away from the seeds.) Rinse the kernels with cool, fresh water, and lay the jar on its side in a dark place to drain.\nRemember that germinating seeds need both air circulation and moisture, so make sure your sprouts-to-be have plenty of each. If you place the jar in a cabinet, leave the door slightly open. Rinse the seeds two or three times daily ... making sure that you completely pour off all the water in the jar each time, since the seeds will easily ferment if they remain soaked.\nThe sprouting kernels are also sensitive to heat (they\'re quite difficult to grow in extremely hot and humid weather) and cold: Some varieties may not even germinate when your house gets overly chilly on winter nights. (If this becomes a problem, you can wrap the sprouting jar in a towel or flannel shirt and place it near a burning light bulb.)\nIf all goes well, you\'ll probably see the seed cases pop open and send out tiny shoots within 48 hours. Most types of sprouted seeds will be ready to eat in three or four days. Once they\'re fully developed, you may want to place the shoots in the sunlight for several hours so their leaves can ""green up"" to a healthy color. Then remove the sprouts from the jar and store them in the refrigerator in a closed container or plastic bag, where the crisp young delicacies will keep for as long as one week\nSome seeds will also sprout when treated to the paper-towel-and-draining-rack technique: Simply cover a rack or tray with a double thickness of damp towels, sprinkle the pre-soaked seeds out evenly over the paper, and then cover them with a top layer of damp toweling. Place the assembly in a dark cupboard and keep the seeds\' atmosphere moist by resoaking and wringing out the top towels whenever necessary.\nSmall, gelatinous seeds — such as chia, cress, radish, and buckwheat — shouldn\'t be soaked overnight since they might absorb too much liquid and turn into a mucilaginous mass. Instead, such water-retaining kernels may be kept barely moist in the saucer of an unglazed clay flower pot. Wash and thoroughly soak the porous dish (so that it won\'t steal moisture from the thirsty kernels), and measure into it equal quantities of seeds and water. Let everything stand undisturbed until all the liquid is absorbed by the seeds, then set the saucer in a larger dish with water in the bottom, and keep the environment dark by placing a plate over the assembly. If the water in the bowl is kept at a constant level, the seeds will absorb whatever moisture they need through the clay ... and sprout within a few days.\nFinally, it\'s very important to keep your sprouting equipment clean, because bacteria may develop if the seeds happen to ferment. So, after you harvest each crop of sprouts, sterilize the glass jar — or wash and scrub the clay saucer — you used.\nBy following the simple tips in this article, you ought to be able to satisfy your ""snowbound"" green thumb and provide healthful, delicious greens for your table at the same time. So get out those jars, saucers, and paper towels, and set out on a sprouting adventure!']"	['<urn:uuid:c6d65194-57b4-45ad-bd36-8ead1a4fe5eb>']	open-ended	with-premise	verbose-and-natural	similar-to-document	single-doc	expert	2025-05-01T23:46:40.222380	23	61	759
429	What's the legal threshold for media restrictions on children, and how does online harm manifest?	The law requires proof of a high measure of harm to restrict media coverage of children, with courts balancing freedom of expression against child welfare. In the online context, harm manifests through cyberbullying via social networks, chat rooms, and messaging apps, with signs including withdrawal, nervousness when receiving messages, and unwillingness to use devices.	"['Medway Council v British Broadcasting Corporation (2001)\n 1 FLR 104\nAn application for an injunction to prevent the broadcast of an interview of a child subject to both an anti-social behaviour and an interim care order was refused. There was a balancing exercise between freedom of expression and the welfare of the child, and the law required proof of a high measure of harm.\nApplication by a local authority for leave to apply for an injunction to restrain the BBC from broadcasting any part of an interview it conducted with a 13-year-old boy and his mother. By the time of the application the boy was in the care of the local authority. He was subject to an anti-social behaviour order under s.1 Crime and Disorder Act 1998. Publicity of the order was not prohibited despite the boy’s age. On 4 April 2001 the BBC conducted a filmed interview of the boy and his mother. On 26 April the boy was made subject to an interim care order. The local authority indicated its opposition to the broadcast of any part of the interview. There was extensive publicity of the anti-social behaviour order in local and national newspapers and on local television. The local authority’s application was supported by the boy’s mother, who regretted having consented to the interview, the boy’s father, and the boy himself. The BBC submitted that the court had no jurisdiction to make the injunction sought and relied on In re R (Wardship : Restrictions on Publication) (1994) 3 All ER 658. The local authority submitted that the court was determining a question concerning the boy’s upbringing and therefore, pursuant to s.1(1) Children Act 1989, his welfare was its paramount consideration. The BBC disputed that any question of the boy’s upbringing arose for determination at all and relied on In re H-S (Minors) (Protection of Identity) (1994) 1 WLR 1141 to argue that the freedom of the media was at issue. The father submitted that the interview was clearly concerned with the boy’s upbringing. The boy submitted that the broadcast would have an effect on his upbringing.\nHELD: (1) The proposed injunction was to be made under the court’s inherent jurisdiction. Under s.100(3) of the 1989 Act, the local authority needed leave to apply. Under s.100(4)(b) leave could not be granted unless the court was satisfied that there was reasonable cause to believe that in the absence of the injunction the boy would be likely to suffer significant harm. (2) The power to make anti-social behaviour orders was introduced by s.1 of the 1998 Act and exercisable in civil proceedings in the magistrates’ court. The youth court had no jurisdiction to entertain the application, so the automatic restrictions on reporting in s.49 Children and Young Persons Act 1933 did not apply. The magistrates’ court could, under s.39 of the 1933 Act, make a direction that no identifying material relating to any child concerned in proceedings before it should be reported. In most cases it would be inappropriate for the court thus to inhibit identification of a child who was subject to an anti-social behaviour order. In this case, no order restricting publicity had been made. (3) In Re R (supra) was distinguished on its facts. (4) The jurisdiction to restrain the proposed broadcast was potentially available for exercise. (5) In In re Z (A Minor) (Identification : Restrictions on Publication) (1996) 2 WLR 88, Ward LJ concluded that the inherent jurisdiction was potentially available for exercise where the proposed publicity was directed at the child or to an aspect of the child’s upbringing by his parents or others who cared for him where that publicity was inimical to his welfare. The child’s welfare was paramount, but had to be balanced against the public interest in freedom of publication. In Re Z (supra) was clear authority for the proposition that s.1(1) of the 1989 Act could apply to an injunction against the media. (6) In s.1(1) the focus was on the question the court was determining. It did not follow that in this case the boy’s upbringing was the subject of the question that the court was determining. The central issue before the court did not relate to how the boy was being reared, but to whether a filmed interview should be broadcast. (7) This application fell to be decided by reference to the balancing exercise between freedom of expression and the welfare of the child. Re X (A Child) (Injunctions Restraining Publication) (2001) 1 FCR 541 and Venables & Anor v News Group Newspapers Ltd & Ors (2001) 2 WLR 1038 applied. (8) The law required proof of a high measure of harm. The absence of evidence that the boy had suffered any adverse effect from the publicity already given remained highly significant, as did the undisputed right of the BBC to revive that publicity. (9) The proposed broadcast was intended to be a serious and responsible piece upon a matter well worth discussing. The BBC was free to transmit whatever part of the material it chose. The local authority made out no case for restriction of this freedom. There was no ground for the suggested injunction.', ""When today's parents and grandparents were growing up bullying was restricted to real-life situations, but online bullying - or cyberbullying - can happen at any time, even away from school.\nWe've answered some of the main questions around cyberbullying below, along with advice on what to do if your child becomes a victim. For more information we recommend Internet Matters, a not-for-profit organisation dedicated to helping keep children safe online.\nWhat is cyberbullying mean?\nCyberbullying is a type of online bullying that occurs on social networks, chat rooms, emails, messaging apps or on forums. It can be private, or public so that other people can see it and potentially join in. The perpetrators can be known to the victim, but very often they hide behind the anonymity the internet provides.\n- Posting private pictures online without permission\n- Making offensive or threating comments about someone on social networks\n- Excluding someone from online games\n- Sending abusive or threatening text messages\nSadly cyberbullying is on the increase. One in eight children aged 12-15 said they had been bullied on social media, nine percent through messaging apps or texts, a rise from 5% in 2017.*\nHow does cyberbullying differ to real-world bullying?\nBullying happens in all spheres of children’s lives: in the real world, such as the playground, park, youth club and street, but also in the virtual world of social networks, internet chat rooms and online gaming.\nThe main difference is that cyberbullying is hard to get away from, it’s something that can take place in the victim’s home – in their bedroom, front room or wherever they go online. Although your child might not be in physical danger, they are vulnerable to emotional damage.\nCyberbullying can reach a large audience. A post on Facebook (for example) can be seen by all the friends of both participants, and (depending on privacy settings) the general public, and be easily shared. This can be incredibly embarrassing for the victim.\nHow can I tell if my child is being cyberbullied?\nAccording to Internet Matters, children who are being cyberbullied don’t always tell their parents. The signs of cyberbullying are similar to that of real-life bullying, along with a change in attitude towards technology:\n- Avoiding school or going out with friends\n- Unwillingness to use a computer/tablet\n- Nervousness when receiving a text message or email\n- Unhappiness or negative behaviour after using a computer/tablet\n- Becoming withdrawn\nWhat to do if you think your child is being cyberbullied\n1: Talk about it. Your child might find it difficult to talk – they might be embarrassed or worry what you’ll think of them and it might be hard for you to hear what they say. Try to listen calmly, without getting angry and interrupting. Let them know it’s not their fault. Ask honest questions about what they’ve been doing online and the messages they’ve had. Don’t judge them. Let them know you are there to help and they aren’t alone.\n2: Don’t contact the bully or anyone else involved, and tell your child not to reply. It might be tricky, but very often the bully is looking for a response. It makes him or her feel powerful and they may continue bullying.\n3: Block the perpetrators so they can’t continue to bully. The method for doing this varies slightly between social networks, so visit online help pages to find out. If they play games online you may need to set restrictions.\n4: Keep the evidence. Take screenshots of any messages and photographs. Print out emails and save texts. Take a note of any phone numbers or email addresses used.\n5: Visit your child’s school and talk to their teachers. They need to be aware that it is happening and should be able to help.\n7: Don’t take away your child’s gadgets, regulate their use of technology. It’s tempting, but many children don’t report cyberbullying because they are worried their phones, tablets or laptops will be taken away as a result. Instead, regulate their use of technology and try to encourage them to use their devices in the same room as you.\nHow BT Parental Controls can help keep your child safe\nIf your child is being sent links to age-inappropriate content, BT's parental controls can stop them seeing the offending web pages. For instance the Strict filter blocks content around pornography, drugs and self-harm, saving them from seeing potentially distressing images or video.\nYou can set similar filters blocking access to social media, meaning they won't be exposed to inappropriate content on services like Twitter, Facebook, Snapchat or Instagram.\nParental controls include timers for online access, so your child won't be able to go online during certain periods of time. This is designed to carve out dedicated homework time, but useful if you want to monitor when they are using the internet.\nOur parental controls work with every device that connects to your home wi-fi, be it a smartphone, tablet, desktop or laptop.""]"	['<urn:uuid:3083a303-10ac-4777-90a5-90c8ee3ebdf5>', '<urn:uuid:27557cc6-3def-4c39-ba21-a5d7160aac50>']	factoid	with-premise	concise-and-natural	similar-to-document	multi-aspect	expert	2025-05-01T23:46:40.222380	15	54	1689
430	world first jet military aircraft name	The Gloster Meteor became the world's first operational jet fighter	"['... from Rugeley to near StourActon , in Cheshire . Its total length is bridge , and\nfrom east to west , from 39 miles . The Dudley and the Stour- Walsall to\nWolverhampton — its greatest bridge canals have been already noticed length\nbeing about ...\nThe most important movable bridge in Britain , however , is Tower Bridge where\ntwo bascules can be lifted to allow ships to enter the Pool of London ; at first the ...\nNext to our own , the Roman civilization was the greatest bridge - building ...\nMany of the losses were sustained in attacks on bridges over the Somme, across\nwhich the Germans were retreating in considerable confusion; the tragedy was\nthat not one of the bridges was hit. It was not until the afternoon of 9 August that a\nAuthor: Robert Jackson\nPublisher: Pen and Sword\nDuring the last century the British aircraft industry created and produced many outstanding aeroplanes. These aircraft were world leaders in advanced technology, utilizing inventions by British engineers and scientists such as radar, the jet engine, the ejector seat and vertical take-off and landing. This book describes the design-history, development and operational careers of twenty-two legendary military and civil aeroplanes. Each one has played a significant part in aviation history.Sopwith Camel, SE.5, Bristol F2B Fighter and the Airco DH4 were all great successes in the relatively early days of flight. In the thirties the Bristol Bulldog fighter was an outstanding export success and the Short \'C\' Class flying boat, later to become the Sunderland of World War II fame, pioneered the long-distance routes to the Empire. The pugnacious foreign policy of Hitler\'s Reich rung sudden alarm bells, rapid advances in fighting aircraft for the RAF became a premium objective. The brilliant Geodic construction of the Vickers Wellington bomber helped it survive terrible punishment throughout World War II, both the Hawker Hurricane and the Supermarine Spitfire saved England from invasion and the Bristol Beaufighter, de Havilland Mosquito and Avro Lancaster took the war to enemy soil. The Gloster Meteor became the word\'s first operational jet fighter and the English Electric Canberra became the RAF\'s first jet bomber and was manufactured under licence in the USA as the Martin B-57. In post-war years the Vickers Viscount became the world\'s first turboprop airliner and eventually became Britain\'s best selling commercial aircraft, whilst the de Havilland Comet became the world\'s first jet airliner. Despite Britain\'s recessionary years in the 50s and early 60s, military success came with the beautiful Hawker Hunter, the super-sonic Fairey Delta experimental aircraft that broke the World Air Speed Record and the Vickers Valiant that pioneered the operational techniques to deliver Britain\'s nuclear deterrent. Later, there followed the Mach 2 English Electric Lightning and the ill-fated TSR-2, the cancellation of which is still regarded as one of the greatest mistakes ever made in British aviation history. Finally, the Harrier, the world\'s first vertical take-off and landing jet fighter that is still in service and now only being built in the USA.Finally the Harrier, the world\'s first vertical take-off and landing jet fighter, still in service and now being further developed in the USA.\nLondon. The world-famous Tower Bridge Reason for inclusion: • Considered to\nbe the best-known bridge in the world Tower Bridge is more than just a bridge; it\nis a feat of engineering, an icon, a landmark and the essence of Victorian Britain.\nAuthor: Chris Peacock\nPublisher: Andrews UK Limited\nThis quick-read guide introduces the reader to ten of the most amazing bridges in the world. Including photographs of every bridge and a brief description of the history of the structure, this ebook has been specially formatted for today\'s e-readers.\nThe Trunk Road \' s bridge over the Kedah was at Alor Star , and through this\nbottle - neck most of the force would have to pass . A rearguard comprising two 2\n/ 9th Gurkha companies took up a position to cover the retreat . An overturned ...\nAuthor: Alan Warren\nPublisher: A&C Black\nNew in paperback, The pre-eminent history of a military disaster. A masterful analysis of events.\nIt had to be crossed to reach the coal mining region of Arauco, and so the\ncompany was faced by “the delightful difficulty of constructing one of the greatest bridges in the world” and embarked on “one of the finest engineering works of the\nAuthor: W. Edmundson\nCategory: Social Science\nThis book sets out to narrate the contributions to and influence on the history of Chile that British visitors and immigrants have had, not as bystanders but as key players, starting in 1554 with the English Queen \'Bloody Mary\' becoming Queen of Chile, and ending with the decline of British influence following the Second World War.\nINDIA : Death of Sir Fazl - i - Husain : One of the Empire\'s Greatest Bridges :\nCollapse of the de Havilland Arch . Simla , July 14 . Howrah Bridge . The decision\nof the Calcutta Port Commissioners to A Great Muhammadan . accept the tender\n... strong fortifications, large hospitals, and publick buildings; with the greatest bridge, and the greatest city in the world, made famous by the opulence of its\nmerchants, the encrease and extensiveness of its commerce; by its invincible\nAuthor: Daniel Defoe\nPublisher: Delphi Classics\nThis eBook features the unabridged text of ‘A Tour Thro’ the Whole Island of Great Britain by Daniel Defoe - Delphi Classics (Illustrated)’ from the bestselling edition of ‘The Complete Works of Daniel Defoe’. Having established their name as the leading publisher of classic literature and art, Delphi Classics produce publications that are individually crafted with superior formatting, while introducing many rare texts for the first time in digital print. The Delphi Classics edition of Defoe includes original annotations and illustrations relating to the life and works of the author, as well as individual tables of contents, allowing you to navigate eBooks quickly and easily. eBook features: * The complete unabridged text of ‘A Tour Thro’ the Whole Island of Great Britain by Daniel Defoe - Delphi Classics (Illustrated)’ * Beautifully illustrated with images related to Defoe’s works * Individual contents table, allowing easy navigation around the eBook * Excellent formatting of the textPlease visit www.delphiclassics.com to learn more about our wide range of titles\nAuthor: Great Britain. Army. Royal EngineersPublish On: 1891\nOccasional papers Great Britain. Army. Royal Engineers. interesting bridges ,\nfrom my point of view , are the Empress bridge , over the Sutlej , at Adamwahan ,\nthe Kaiser - i - Hind bridge , over the same river , at Ferozepur , and the Sher\nAuthor: Great Britain. Army. Royal Engineers\nCategory: Civil engineering\nAnnual re-issue of the Royal Engineer Institute\'s Occasional papers, issued quarterly.\nAuthor: Concrete and constructional engineeringPublish On: 1945\nBRIDGES IN CORNWALL THREE interesting bridges are being built stresses\ndue to shrinkage , keyways are to by the Cornwall County Council , two on be left\nat 3 ft . 6 in . from each abutment the road diversion at Lostwithiel and one and\nThe flat contradictions of the existing British policy are not foolishness ; they are ,\nfor the first time , open and undisguised ... Madras and Calcutta ; built some of the\nworld \' s greatest bridges and trunk roads ; developed modern power systems ...\nAuthor: Great Britain. Parliament. House of LordsPublish On: 1879\nGreat Britain. Parliament. House of Lords. Mr. Penrose . 10th July 1879 . because\nit would leave the bridge itself in some degree ... Would you go so far as to say it\nfully rivals any of the greatest bridges , either in England or on the Continent ?\n... RAILWAYS - 74 XII . RAILWAYS IN AUSTRALIA AND NEW ZEALAND 79\nPAGE 85 91 102 107 III CHAPTER XIII . THE. THE FORTH BRIDGE . BRITAIN\'S GREATEST BRIDGE A BELGIAN RAILWAY BY THE SEA ROCKET ""\nJames Bryce, later British Ambassador to the United 3tates, called the Panama\nCanal ""the greatest liberty man ever took ... that it compared in size with the\nlargest bridge previously built in Great Britain as a Grenadier Guardsman\nPopular Science gives our readers the information and tools to improve their technology and their world. The core belief that Popular Science and our readers share: The future is going to be better, and science and technology are the driving forces that will help make it better.\nA few months later Hodgson was back in Dunfermline telling the promoters that\nhis engineer had abandoned the ferry idea in favour of the greatest bridge in the\nworld which he was proposing to throw across the Firth . It would be 3 miles long\nAuthor: Great Britain. Army. Educational and Training Establishments. School of Military Engineering, ChathamPublish On: 1870\nGreat Britain. Army. Educational and Training Establishments. School of Military\nEngineering, Chatham. 270-271 . ... is to create in a comparatively short time the greatest bridges . obstacle in the shape of a breach , impassable , till by spars or\nAuthor: Great Britain. Army. Educational and Training Establishments. School of Military Engineering, Chatham\nSome of the greatest bridges of modern graphical works , Mr. Smiles chose a\nsubject times — such as those orer the Sone near Patidentified with the progress\nof the age . The na , and ... Although Great Britain , first in the tion . This country\nSome of the greatest bridges of modern graphical works , Mr. Smiles chose a\nsubject times — such as those over the Sone near Patidentified with the progress\nof the age . The na , and ... Although Great Britain , first in the tion . This country ...\nAuthor: Henry Mills Alden\nCategory: American literature\nHarper\'s informs a diverse body of readers of cultural, business, political, literary and scientific affairs.']"	['<urn:uuid:c23031f3-fbc2-448f-864d-4d76bfe89dfd>']	factoid	with-premise	short-search-query	distant-from-document	single-doc	expert	2025-05-01T23:46:40.222380	6	10	1637
431	mental health trans youth empowerment barriers outcomes	Research shows that transgender and gender diverse youth face severe mental health challenges, with 80% experiencing self-harm (compared to 11% of non-trans youth) and over 50% attempting suicide (20 times higher than non-trans peers). Gender norms and barriers in under-resourced communities particularly affect these outcomes. Studies indicate that 75% are diagnosed with depression and 72% with anxiety (both 10 times higher than non-trans youth). However, challenging rigid gender codes and implementing gender transformative programming can lead to improved outcomes. Programs that address gendered attitudes, beliefs, and practices, rather than just providing basic support, have been found to be more effective in supporting these populations.	"['Rigid, narrow codes of tradition masculinity and femininity drive lower reproductive health, homophobic and gender-based violence, and poorer education outcomes. This is especially true in under-resourced communities, where gender codes are apt to be particularly narrow or harsh. This is our round-up on some of the best reports–including our own–on the challenge, implications, and improved outcomes that result from implementing programs and policies with a strong gender focus.\n|Table of Contents|\n|Anti-Transgender Violence (2015)|\n|Economic Security & Gender Norms: Why the ""Empowerment Model” Won’t Work (2015)|\n|Gender Norms: A Key to Improving Life Outcomes in At-Risk Populations (2012)|\n|Gender Norms & Youth Development (2017)|\n|Gender Transformative Philanthropy: A Case for More Effective Giving (2015)|\n|Jewish Girls and Gender Norms (2015)|\n|Jewish Girls Empowered Together Curriculum Overview (2015)|\n|STEM & Feminine Norms (2015)|\n|Teen Suicide, Homophobic Bullying & Gender Norms (2015)|\n|Young Black Men and Masculinity (with ABFE) (2015)|\n|Young Latinas and Feminine Norms (with HIP) (2017)|\n|Anti-Transgender Violence (2015) |\nFor two decades, activists and advocates have been quietly highlighting and documenting a murderous wave of violence that regularly claims the lives of gender non-conforming and transgender Americans. Although these assaults are often extreme, they seldom surface in mainstream and as a result are largely absent from this dialogue. This report provides a lot about how transgender women are perceived, what is believed about them, and key attitudes that appear to be driving attack towards them. It also highlights key points that could be adopted for messaging and creating interventions.\n|Economic Security and Gender Norms (2015) |\nHigh rates of poverty among US women and children make it imperative for funders to continue seeking out, and supporting, new and innovative pathways out of poverty. However, funding models are based on a set of tacit assumptions which are seldom made explicit, collectively called the ""Empowerment Model.” Studies have found that programs that address and look beyond providing funding, information and opportunities to challenge gendered attitudes, beliefs and practices that hold women and girls back will be more effective than those that ignore them. This report suggests six ways to adopt gender transformative funding.\n| Gender Norms: A Key to Improving Health & Wellness Among Black Girls (2013) |\nBlack adolescent girls and young women face barriers related to both race and gender, which have immense effects of their health, achievement and life outcomes. This is especially the case for low-income Black girls, who have added challenges associated with poverty. This report, produced by TrueChild with support from The Heinz Endowments, illustrates the small but growing body of empirical research devoted to Black girls and gender norms and focuses on three problem areas where that research base is both broad and well-accepted: basic health and wellness, reproductive and sexual health, and intimate relationships and partner violence.\n| Gender Norms & Youth Development (2017)|\nThe George Family Foundation has been a leader among a small but growing core of funders that recognize and uphold the importance of gender norms in youth development work. Beginning in 2014, the Foundation launched a muti-faceted, multi-year effort to help bring gender norms into broader recognition among Minnesota\'s youth-serving foundations and non-profits. As a further step in this effort, the George Family Foundation and the Women\'s Foundation of Minnesota commissioned dozens of interviews with local funders and a select number if community-based youth development organizations to better understand the state of knowledge about gender norms in Minnesota philanthropy and programmatic efforts. This white report is the result. It first explains what gender norms are and how they work, and then explores the implications for Minnesotans and for Minnesota\'s funders.\n|Gender Transformative Philanthropy: A Case for More Effective Giving (2015)|\nWhy should donors support gender transformative programming? This report makes the case that support for gender transformative programming is crucial to effective giving. Gender transformative approaches are a low-risk, high-return opportunity to address gender inequality in greater depth and with more comprehensive solutions.\n| Jewish Girls and Gender Norms (2015) |\nLearning to negotiate gender norms and expectations is a central development task for nearly every adolescent girl. This task is made all more challenging because the girls, including Jewish girls get very mixed messages about feminine expectations and how to meet them. Despite these and other known impacts and the vulnerability gender norms create, Jewish women and girls are almost totally absent from the academic literature on gender norms, and more studies and data are greatly needed.\n| Jewish Girls Empowered Together Curriculum Overview (2015) |\nLearning to conform to feminine ideals is a rite of passage - perhaps the central rite of passage- for nearly every adolescent girl. Yet girls also get very mixed messages about feminine expectations and how to meet them, including Jewish girls. While many communities go out of their way to encourage girls to become leaders, there are also long-standing patriarchal traditions at home, in school, and in synagogue that make clear the cultural and religious primacy and centrality of males. This curriculum overview will provide an understanding of the differences between sex and gender, how gender norms influence the lives, health, and relationships of Jewish girls.\n| STEM & Feminine Norms (2015) |\nScience, technology, engineering, and math - the ""STEM"" subjects are an important focus of philanthropic institutions trying to address educational and economic disparities between girls and boys. STEM-related fields account for an increasing number of new, and high-paying, positions being created in the knowledge economy. Especially for young women of color or in low-income communities, who already face additional social barriers in finding new and well-paid jobs, a strong STEM background can be a stepping stone to a better career. Yet historically so many girls have dropped out of STEM courses by middle school there was even name for it - the ""leaky pipeline."" This report will look at how gender norms are a significant variable, and one at which researchers, practitioners, and philanthropic institutions must look more closely if we are to continue improving STEM interest and participation.\n|Teen Suicide, Homophobic Bullying & Gender Norms (2015) |\nEfforts to address homophobic and transphobic bullying in middle school have acquired an new urgency in light of the recent wave of teen suicides. To better understand connections between gender non-conformity, middle-school bullying and teen suicides, the Bruce W. Bastin Foundation provided support for a series of focus groups and in-depth interviews with LGBTQ students in Salt Lake City, which has had one of the highest rates of teen suicide linked to homophobic attacks. The project concludes that adults need to recognize gender intolerance as more of a pervasive atmosphere of general hostility and ostracism, one which targets students because go gender non-conformity and s often shared by teachers and staff. The report provides five suggestions for action to address homophobic and transphobic bullying and teen suicide.\n|Young Black Men & Masculinity (with ABFE) (2015) |\nBlack adolescent boys and young men face barriers related to both race and gender, which have immense effects of their health, achievement and life outcomes. This is especially the case for low-income Black men, who have added challenges associated with poverty. This report, produced by TrueChild with Association of Black Foundation Executives\nand Frontline Solutions\n, illustrates the small but growing body of empirical research devoted to Black men and gender norms.\n| Young Latinas & Feminine Norms (with HIP) (2017) |\nDecades of research has found that when young women and men internalize ideals of femininity and masculinity, they have markedly lower life outcomes in a cluster of related areas that include health, education, reproductive health, and economic security. Yet few program officers and grantees are challenged to do innovative work around gender like they are race and class. This report, prepared in partnership with Hispanics in Philanthropy\n(HIP) and Frontlines Solutions\n, will help funders understand what gender norms are, how they impact young Latinas, and how to adopt an intersectional approach that connects race, class, and gender to increase the social return on their philanthropic investment.', 'What is Gender Diversity? It can be seen as an umbrella term that is used to describe gender identities that demonstrate a diversity in expression, beyond the binary framework of male and female.\nHow children and teenagers express gender?\nGender expression is how your child shows their gender. This might be through their name, clothes, behaviours, hairstyle and voice. Almost all children begin expressing their gender identity from around 2 to 3 years old. They do this in the way they talk about themselves and through the clothes they choose. Children can be very firm about their gender from an early age.\nMany gender diverse children also express their gender identity around the same age and can be very firm and get upset, angry or annoyed, when people refer to them as a boy or a girl. They may refuse to wear particular clothes and say they are a different gender. But as everyone is different, some children may start talking about their gender in primary school, at puberty… There is no rule.\nWhat is Gender Diversity?\nGender diversity refers to gender non-conformity with or without gender dysphoria and includes aspects of gender identity, expression or behaviour that do not conform to societal gender expectations based on birth anatomy.\nWhat is Gender Dysphoria?\nGender dysphoria is ‘’a marked incongruence between one’s experienced/expressed gender and assigned gender, of a least 6 months duration’’. In children, the desire to be of the other gender must be present, verbalised and cause clinically significant distress or impairment in social, occupational, or other important areas of functioning.\nGender dysphoria is not a psychiatric disorder/diagnosis. However, it is frequently associated with psychological distress such as anxiety, depression etc. Gender dysphoria is when a child feels distressed (the level of distress can range from manageable to debilitating) because their gender identity differs from their sex given at birth. Not all gender diverse people have gender dysphoria.\nGender diversity is not a psychiatric disorder. It is not pathological.\nStatistics on Gender Diversity and Mental Health\nHere are some mental health statistics from a 2017 Australian study with young people aged 14 to 25 and identifying as trans or gender diverse: (you will find more information by clicking on this link trans-pathways-report.pdf (telethonkids.org.au)\nStrauss, P., Cook, A., Winter, S., Watson, V., Wright Toussaint, D., Lin, A. (2017) Trans Pathways: the mental health experience and care pathways of trans young people. Summary of result. Telethon Kids Institute, Perth, Australia.\nMental health difficulties for Gender Diverse Youth\n- 80% have self-harmed\n- compared to 11% of non-trans\n- Over 50% attempt suicide\n- that is 20 times higher than non-trans\n- 75% are diagnosed with depression\n- which is 10 times higher than non-trans\n- 72% have anxiety\n- which is 10 times higher than non-trans\n- 23% have been diagnosed with an eating disorder\n- 25% have been diagnosed with PTSD\n- Robust finding of a connection between gender non-conforming and ASD\n- ASD children are 7 times more likely to be gender non-conforming\n- Children and adolescents attending gender clinics are 6-15 times more likely to have ASD\nProtective factors identified in that survey:\nFig 5 page 67\nWhen working with gender diverse children and teenagers, my role as a psychologist is to support the young person and their family with things such as peer/friendship difficulties, bullying, discrimination, abuse, humiliation, lack of understanding from school, the use of the correct pronoun, low mood… and so much more. So what is gender diversity?..it is never a pathology.\nHere are some websites you may also find useful:\nAuthor: Meggy Delaunay, PG Dip Psych Practice, PG Dip Dev Psych, M Genetic Psych, B Psych, MAPS.\nMeggy Delaunay is a psychologist who primarily works with children, adolescents and young adults. She is a registered Psychologist in Australia, New Zealand and France, and can provide therapy sessions in English and French.\nTo make an appointment try Online Booking. Alternatively, you can call Vision Psychology Brisbane on (07) 3088 5422.\nStrauss, P., Cook, A., Winter, S., Watson, V., Wright Toussaint, D., Lin, A. (2017). Trans Pathways: the mental health experiences and care pathways of trans young people. Summary of results. Telethon Kids Institute, Perth, Australia.']"	['<urn:uuid:a792e954-913a-42ed-9442-203217c5ad74>', '<urn:uuid:10c07be4-d57f-4233-824d-4a4be0f4678b>']	open-ended	with-premise	short-search-query	distant-from-document	multi-aspect	expert	2025-05-01T23:46:40.222380	7	104	2034
432	Do modern baby showers still exclude men from attending?	No, times have changed from when only women were invited. These days, many baby showers invite everyone including the dad-to-be, grandpa-to-be, uncles and other male guests.	"['How to Plan A Baby Shower\nGetting ready to host a baby shower or gender reveal party? Need some help? We\'ve got everything right here to help you get organized: checklists and guest lists ready to print out, even a gift tracking form to help with those very important after-shower thank-you notes and ideas for party entertainment for all ages.\nGetting Started Planning a Baby Party\nOur first bit of baby shower planning advice? Set aside four weeks for getting organized, planning, sending invitations, and purchasing the babyshower party supplies, decorations and favors.\nBack in my pregnancy days, showers were thrown by friends, not relatives ... and men were never invited to partake in the festivities! It\'s the 21st century and times have changed - many parents-to-be, family members and friends are throwing baby showers, and everyone\'s invited - sometimes even children!\nBaby parties are a celebration of life and family, and in fact, these days it\'s not uncommon to have more than one party, especially if the parents-to-be have a large family or several close friends, or if they have friends and family in widely separated spaces that make travel hard or expensive for a large number of guests.\nFunny Baby Shower Games\n4 Week Shower Planning Guide\nTo help you make sure you host the best baby shower ever, we\'ve put together a four-week baby shower planning guide with steps to take for each week up to the big day of the baby shower.\nHere\'s how your work plan will break down over the 4 weeks leading up to the day of the party:\n- Week 1: Organizing the Shower or Gender Reveal Party\n- Weeks 2 & 3: Invitations and Entertainment Planning\n- Week 4: Final Details, Decorating, Shopping\n- Day Of the Shower: Time to Celebrate!\nWeek 1: Organizing A Baby Shower / Gender Reveal Party\nYou\'re throwing a baby party! How exciting. There are several decisions you\'ll need to make in the early stages of planning, so we\'ll walk you through each one and provide a ton of tips and hints to help out. To get started, here is a sample schedule you can use for your baby party bash:\nOf course you can throw in some more games, mix things up, leave things out, it\'s all up to you!\nPutting Together the Baby Shower Guest List\nWhen our parents were young, the hostess would invite only women to a baby shower: ladies from both sides of the family, the mom-to-be\'s girlfriends, and of course, the mom-to-be. Times have changed however, and potential invitees could be the dad-to-be, grandpa-to-be, uncles and anyone else!\nThe first decision you need to make is what kind of baby shower do you want to host? Do you want to invite women only? Will the parents-to-be have another baby shower for family members only? If so, you might consider hosting a friends-only baby shower. Another popular trend is to host a co-ed couples baby shower. And another trend is to hold a baby shower for co-workers of the mom- or dad-to-be (whichever one works at the same office as you).\nKids or No Kids?\nWhether or not to invite children is another decision you need to make right up front. If the baby-to-be already has a brother or sister, then inviting other kids would be a great way to get them involved in celebrating their new sibling.\nDepending on how old the older children are, they might be able to lead other kids in activities designed just for youngsters. Seven years old is about the right age child to invite to a baby shower. They\'ll feel as though they are included in hosting responsibilities and are part of the big event - which they are. For younger kids, or if the situation doesn\'t present opportunities for inviting children to a baby shower, you might consider hiring a babysitter to entertain the kids during the event.\nPicking a Baby Shower Location\nOnce you make a guest list and have a general idea of the number of guests, start researching local venues for the party.\nTraditionally, baby showers were held in the home of the hostess, but more recently restaurants and social halls have become popular places to throw a baby shower. Consider a restaurant or church social hall, a park picnic pavilion, a reception hall, or even a day at the spa with a catered lunch.\nWeeks 2 & 3: Shower Invitations & Entertainment\nAfter the guest list is set and you know where you\'re going to host the baby shower, it\'s time to pick a baby shower theme and send the invitations out!\nBaby Shower Themes\nBaby shower themes serve as inspiration for decorations and games, invitations, favors and even the food. Themes can be as simple as choosing a color scheme like blue and white if you know the parents-to-be are having a boy, or pink and white for a girl. A theme makes shopping for supplies a breeze!\nClick the link to see one of a selection of favorite party kits with Unique Baby Shower Themes. There are many different baby shower theme ideas to help get you started.\nFor example, if you are using a Rubber Duckies theme, select baby shower invitations with ducks, then buy cute duck decorations, a baby bath centerpiece filled with water and floating rubber ducks, small rubber duck favors, and yellow foods.\nSee how much fun baby shower themes can be?\nLet\'s Play Some Games\nBaby Shower party games are best when you have a group of people who may not know each other very well and you need to relax everyone before the party gets going.\nIce-breaker games set the mood for your shower and get people talking and laughing - this is a happy and fun occasion, so the more laughter, the better. If you\'re planning a theme baby shower, the party games can relate to the theme. Plan and choose about 3 games for a 2-hour shower.\nBaby Shower Invitations\nOnce you have the guest list settled and have all the address information, you\'re ready to mail the invitations. You need to allow your guests plenty of time to plan their schedule and find just the right gift. Invitations are a guest\'s first clue as to the style and/or theme of the party.\nYou can design custom printed baby shower invitations, buy preprinted cards, or design and print your own invitations, name tags and favor cards.\nIt\'s easy to use make your own invites: pick a front cover image and enter the details then print the invitations out on 8 1/2"" x 11"" paper, fold the cards into quarters and send them to your guests! The benefit of making your own invitations is that you have unlimited printouts.\nIf you make a mistake on one, no problem, just print out another. If you discover you have last minute additions to your guest list, you can easily print additional baby shower invitations on demand.\nGift Ideas for Mom-to-Be, Big Sister, Big Brother, Dad\nGive a personalized, unique gift to every member of baby-to-be\'s family.\nMenu and Beverages\nStart thinking about what you are going to serve. You don\'t need to finalize everything as you make your initial food plan, but you do want to have an idea of what you want to serve to your guests besides cake, coffee and tea.\nNeed suggestions? Finger foods work great and if you arrange them in several areas around the room it will encourage guests to mingle. Use food to reinforce the party theme. If your guest of honor has a favorite color, or if the shower theme revolves around a color, choose foods with the same color.\nThe time of day can help you decide what to serve. For a mid-morning baby shower, you could serve coffee and tea with pastries. For an afternoon baby shower affair you can serve a light lunch with cake and punch for dessert, or go lighter with finger foods or mini-sandwiches. A party held later in the afternoon could include chips and dip or vegetables and hummus along with a sweet finishing tidbit.\nTime to Go Shopping!\nThere are two rounds of shopping for baby shower planning. First you need to select and pick up invitations (or card stock to print your own), party favors and decorations. You can also print your own party ware from printables or by using clip art and designing your own!\nIn the week before the actual baby shower date you\'ll need to shop for food and beverages.\nNeed ideas for baby shower favors? One of our favorites are tealights personalized with the date of the baby shower. These cute, brushed aluminum 24-hour tea lights can be personalized in black, gold or silver ink. Another fun idea is to give out personalized bud vases. Both of these items make great keepsakes without breaking the bank.\nYou should also pick up a few items to use as prizes for the winners of your Baby Shower games - picture frames, compact mirrors, candles, journal notebooks or small jewelry boxes work well as prizes.\nWeek 4: Final Shower Details\nAfter 3 weeks of planning and organizing, shopping and preparing the favors, the last week means there are just a few days left until the big day.\nFinalize Menu and Go Shopping\nIn the final week before the shower you should finalize your menu plan for what you are going to serve at the baby shower. Write down all the ingredients, beverages, serving pieces and table ware you\'ll need, then take inventory on what you have on hand versus what you need to by for supplies. Need any extra film or decorations that may have been left out on the first round of shopping?\nConfirm Venue Reservations\nIf you have made reservations at a special venue for your baby shower party, call to re-confirm your reservation and also ensure they have enough chairs, tables and dishes. Also make sure you can get in early enough to set up the decorations and arrange the room how you want it for the shower.\nDay Of the Baby Shower - It\'s Time to Celebrate!\nThere are always a few loose ends to tie up on the day of the party, so the best thing to do is make a list and, yes, check it twice. Put a reminder to pick up flowers, balloons and last minute decorations on your day-of-the-event checklist.\n- Designate a photographer and/or videographer to capture the event for the parents-to-be and guests.\n- Take a photo of each guest with the parents-to-be as they leave the baby shower, and then get prints made so the parents can include a copy of the photo with each thank you note\n- Create a gift tracker and designate a gift recorder to write down gifts and givers so the mom-to-be will know who to send each thank you card to.\n- Provide a comfy chair, a small back pillow and footstool for the mother-to-be\n- Enlist a cleanup crew ahead of time so you don\'t get stuck with all the tidying up after the party\'s over\n- Bring along storage totes or boxes to organize the gifts and make them easier for the mom-to-be to transport them home. Designate a team to pack them up and deliver them or load them into the car after the shower.']"	['<urn:uuid:eef26c87-6d5a-4647-a593-af582ebfe9a9>']	factoid	with-premise	concise-and-natural	distant-from-document	single-doc	novice	2025-05-01T23:46:40.222380	9	26	1900
433	I'm curious about how companies measure if they have a good workplace environment - what are some concrete ways they track this?	Companies use several measurable indicators to track their cultural health, including: staff turnover rates, customer satisfaction levels, health and safety records, compliance with competition rules, regulatory sanctions, qualified audit reports, and whistle-blowing statistics. Additionally, they monitor employee morale through performance management systems and evaluate the effectiveness of their compensation schemes in attracting and retaining qualified professionals.	"['Press release by the International Corporate Governance Network et al. – High levels of corporate stress, flawed remuneration policies, complex legal structures, a tendency for takeovers to proliferate, and lax financial discipline are all potential signs of a poor corporate culture, according to a report issued today by the International Corporate Governance Network (ICGN), ICSA: The Governance Institute, and the Institute of Business Ethics.\nThe report represents the conclusions of a workshop of senior regulators, company directors and executives and investors convened by the three organisations last December to explore ways of identifying early warning signs of a weak culture.\n""We have observed a failure of culture not just in the banks, but in other recent corporate crises, including Tesco, Toshiba and VW. It is in everybody’s interest to understand the warning signs and help companies develop a strong culture which reduces unnecessary risks,"" said Peter Montagnon, the report’s author. Mr Montagnon is Associate Director of the IBE and Chair of the ICGN Business Ethics Committee.\nThe workshop found that a major source of corporate stress was when corporate leaderships imposed short-term targets which staff found difficult to meet. This could exacerbate a rift between staff and management. In such cases the board was often unable to get an accurate picture of what was going on.\nThe report concluded that good governance was critical, but there should be a broader definition of what this means. Governance was not just a matter of board processes, but should run through all areas of the company. More attention should be paid to the role of human resource departments which are often charged with the task of embedding culture, and to internal audit, which is well placed to detect when culture is slipping.\nFinally transparency and openness matter. A good culture means being able to discuss difficult issues.\nHow well do you really know your competitors?\nAccess the most comprehensive Company Profiles on the market, powered by GlobalData. Save hours of research. Gain competitive edge.\nYour download email will arrive shortly\nNot ready to buy yet? Download a free sample\nWe are confident about the unique quality of our Company Profiles. However, we want you to make the most beneficial decision for your business, so we offer a free sample that you can download by submitting the below formBy GlobalData\n""Corporate culture is one of the least explored areas of corporate governance and yet it is pivotal to the ultimate success of companies. ICGN has made the ‘soft’ governance factors of culture, ethics and behaviour a key Policy Priority in 2015-16. By bringing companies, investors and regulators together, we aim to create a better understanding around how these factors can reduce risk leading to more stable and sustainable companies,"" said Kerrie Waring, Executive Director of ICGN.\nPeter Swabey, Policy and Research Director at ICSA: The Governance Institute added that ""The UK Corporate Governance Code has been a major success over the years since its introduction, but codes and regulation can only go so far. Much more important is the way in which people implement those codes and regulations, and this comes down to the culture of the organisation and the behaviours that this fosters in individual employees. We have been delighted to work this year with the Financial Reporting Council in their culture coalition project and with the IBE and ICGN on this very helpful analysis of some of the key indicators of poor corporate culture.""\nThe report pointed to some measurable indicators of culture, including: staff turnover, customer satisfaction, health and safety record, public commitment to values by leadership, competition rules infringements, regulatory sanctions, qualified audit reports and speak-up or whistle-blowing statistics.', 'Company culture or organizational culture is one of the determinants of failure or success of any organization. Also known as business culture, company culture can be defined as the proper way to behave or act within an organization and encompasses both management and employees. As the people in charge of recruiting, training, hiring and firing company staff, HR managers play a very important role in the shaping, changing or reinforcement of company culture. Their actions can have either positive or negative effects on the company culture as discusseffecthe below section.\nAn organization’s pay structure, usually developed by the HR department, is one of the key drivers of organizational culture. A poorly designed pay structure that does not take into account the skills and qualifications of workers will affect the culture in a negative way. This is especially true when the pay is lower than the average in the same business.\nOn the other hand, a well-designed and competitive compensation scheme is bound to attract highly qualified professionals who will be happier, more motivated and loyal to the business. This will have a positive impact on their behavior within the organization and their interpersonal relationships.\nTraining and development\nHR can achieve a positive business culture by incorporating training programs that stress on the importance of employees behaving or acting in the proper way. Training can be internal or external. HR managers the employees, the in-house experts, and the external consultants who visit the organization for internal training.\nExternal training can be in form of sponsored workshops, seminars or even approved self-development training such as part time or online degree programs. Whatever the training program, it should stress to the employee the need to think, behave and act in a way that is acceptable to the company rules and culture.\nHR managers are very much like a bridge between the executive level management and the employees. They do job advertisements, carry out interviews, hire, and determines the job description and remuneration for the employees. As such, the interaction between the employees and HR office has a very big effect on the overall company culture from the very start of their employment tenure.\nHaving in place effective conflict resolution processes, open lines of communication and clear chains of command are some of the ways in which the HR office can improve the employee-employer relationship and consequently the organizational culture.\nBased on the nature of their relationship with the employees, HR managers are typically the most influential workplace leaders. The HR office delegates responsibilities, set employees rules and guidelines and supervises performance and behavior. Thus, the conduct of HR managers in their leadership roles can have a negative or positive impact on the employee morale.\nHR conduct will affect the company culture. Positive results can be achieved by having communication channels that allow for open talks and exchange of feedback. HR can also improve the culture by criticizing their employees constructively when they go wrong and rewarding them when they perform above expectations.\nThere are currently tons of performance management tools that may be useful to HR in their quest for a great business culture. A proper performance management system will put emphasis on working smarter, instead of the usual pattern of working harder or longer. It will also focus on equipping employees with the necessary technological tools to aid them in various roles.\nThe human resource department is one of the most important units in any company. While dealing with the management of the employee affairs it has a significant effect on monitoring and injecting competency in the culture. A well-designed system that actually works will go a long way in creating a culture that stresses on high performance, with a positive impact on productivity and business profits.']"	['<urn:uuid:b8c1c20c-4daa-49fe-b782-8ecc67f913df>', '<urn:uuid:05c23e62-0657-4d99-b24b-5331134eabf0>']	factoid	with-premise	verbose-and-natural	distant-from-document	three-doc	novice	2025-05-01T23:46:40.222380	22	56	1234
434	As a plant physiologist studying nitrogen metabolism, I'm curious about how silicon-containing mixes affect plant nutrient uptake during stress, and what role does ammonium toxicity play in this nutrient balance?	Silicon-containing mixes significantly impact nutrient balance in plants under stress conditions. When silicon-containing mixes like calcium silicate are applied, there is an increase in nitrogen, potassium, phosphorus, and calcium content in plant leaves. This helps maintain nutrient balance during stress conditions. However, high ammonium (NH4+) concentrations can disrupt this balance - when NH4+ levels are excessive, it inhibits the absorption of potassium, magnesium and calcium ions, causing ion disorders in plants. The toxicity occurs because NH4+ assimilation requires large amounts of carbon skeleton as substrate, leading to insufficient carbon resources in roots and eventual toxicity symptoms.	['Nutritional elements content, growth and development dynamics of plants of the genus Rosa L. ‘Duc de Constantine’ (Soupert & Notting, 1857) variety and Monarda didyma L. under the conditions of greenhouse and open air growing at affection by the agent of Erysiphales and the presence of silicon-containing mixes are analyzed. It was established that the use of silicon-containing mixes accelerates growth processes, supports a longer flowering period, decreases the spread of the disease and reduces the intensity of plant damage by powdery mildew micromycetes. Under conditions of pathogenesis, the increase of nitrogen and manganese content in the leaves of plants, and an essential decrease of phosphorus, potassium, calcium, magnesium and iron content were observed. There was an increase of nitrogen, potassium, phosphorus and calcium content in the leaves at the application of calcium silicate and lignin, modified with silicic acid.\nKeywords: Erysiphales, micromycetes, silicon-containing mixes, nutrients, plant resistance\nFull text and supplemented materialsFree full text: PDF\n1. Kramarev, S.M., Polianchikov, S.P. & Covbel, A.I. Silicon and plant protection against stress: theory, practice, perspectives. Retrieved from http://quantum.ua/ua/articles/ art_06.pdf [in Russian].\n2. Epstein, E. (2009). Silicon: its manifold roles in plants. Annals of Applied Biology, USA, Iss. 2, pp. 155-160. https://doi.org/10.1111/j.1744-7348.2009.00343.x\n3. Rodrigues, F.A. & Datnoff, L.E. (2015). Silicon and plant diseases. Springer. Retrieved from https://books.google.com.ua/books?id=8I_DCgAAQBAJ&dq=silva+et+al+2010+ The+effect+of+silicon&hl=ru&source=gbs_navlinks_s https://doi.org/10.1007/978-3-319-22930-0\n4. Ma, J.F. & Yamaji, N. (2006). Silicon uptake and accumulation in higher plants. Trends Plant Sci., Iss. 11 (8), pp. 392-397. https://doi.org/10.1016/j.tplants.2006.06.007\n5. Alyoshin, N.E. (1996). Siliceous of rice (Unpublished doctoral thesis). Krasnodar [in Russian].\n6. Voronkov, M.G., Zelchan, G.I. & Lukevits, E.Ya. (1978). Silicon and life. Biochemistry, pharmacology and toxicologists of silicon compounds, Iss. 2 (588 p.), Riga, Zinatne [in Russian].\n7. Emadian, S.F. & Newton, R.J. (1989). Growth enhancement of Loblolly pine (Pinus taeda L.) seedlings by silicon. Plant Physiol., Iss., 134, pp. 98-103. Retrieved from https://www.sciencedirect.com/science/article/pii/S0176161789802093?via%3Dihub. https://doi.org/10.1016/S0176-1617(89)80209-3\n8. Heath, M.C. (1979). Partial characterization of the electron opaque deposits formed in the non-host plant, French bean, after cowpea rust infection. Physiol. Plant Pathol., No. 15, pp. 141-148. https://doi.org/10.1016/0048-4059(79)90062-6\n9. Matychenkov, V.V. (2008). The role of mobile silicon compounds in plant and system soil-plant (Unpublished doctoral thesis). Pushchino. Retrieved from http://www.dissercat.com/content/rol-podvizhnykh-soedinenii-kremniya-v-rasteniyakh-i-sisteme-pochva-rastenie [in Russian]\n10. Kemecheva, M.Ch. (2003). The role of silicon fertilizers in increasing rice productivity on the left bank of River Cuban (Unpublished candidate thesis). Maicop [in Russian].\n11. Liang, Y., Sun, W., Zhu, Y.-G. & Christie, P. (2007). Mechanisms of silicon-mediated alleviation of abiotic stresses in higher plants: a review. Environmental Pollution, No. 147, pp. 422-428. https://doi.org/10.1016/j.envpol.2006.06.008\n12. Currie, H.A. & Perry, C.C. (2007). Silica in Plants: Biological, Biochemical and Chemical Studies. Ann Bot., Iss. 100 (7), pp. 1383-1389. https://doi.org/10.1093/aob/mcm247\n13. Index fungorum. doi: http://www.indexfungorum.org.\n14. Tribel, S.O. ( Ed.), Sigaryova, D.D., Secun, M.P. & Ivashchenko, O.O. (2001). Methods of testing and application of pesticides. Kyiv: Svit [in Ukrainian].\n15. Kriva, O.I. (2014). The influence of transport on morphology and influence of transport pollution on morphology and development of fruiting bodies Sawadea bicornis (Erysiphaceae) in city Lviv. Modern Phytomorphology, No. 6, pp. 349-352.\n16. Heluta, V.P. & Dudka, I.A. (Ed.) (1989). The Flore of Ukraine fungus. Powdery mildew. Akad. nauk USSR. M.G. Kholodny Institute of Botany. Kyiv: Nauk. dumka [in Russian].\n17. Rinkis, G.Ya. & Hollendorf, V.F. (1982). Balanced nutrition of plants by macro- and micronutrients. Riga: Zinatne.', 'Toxicity NH4+ in the plant ( Pampered little Musang King )\nThis is a typical problem of Musang king, “leaves burning” …\nAfter plants absorb nutrients, they may not immediately use them. Before plants use these nutrients, they will be deposited in the cells of the leaves. If they do not use the nutrients immediately, they will begin to accumulate in these cells, nitrate-N (NO3-) can be safely stored in plant cells at high levels, but the accumulation of ammonium-N (NH4+) can damage plant cells.\nNitrogen is assimilated in both roots and leaves of crops (Marschner, 1995). When absorbing nitrate, 70% to 90% of nitrogen is transported to plant leaves in the form of nitrate (van Beusichem et al., 1988). In plant leaves, nitrate nitrogen is converted to ammonia. The toxic effects of ammonia on plant leaves are prevented when nitrogen combines with sugars in leaves to produce amino acids (usually glutamate) (Marschner, 1995), and the plant cells where sugars are produced are very close to being poisoned by ammonia. However, when ammonium enters the crop root system, all ammonium nitrogen is utilized by the metabolism of the crop root system, and the consumed sugar is transported to the crop root by phloem flow (Marschner, 1995). In crop roots, sugar serves 2 purposes: (i) cellular respiration and (ii) ammonium metabolism. However, when the temperature of the roots increased, the cellular respiration of the roots was enhanced, and the sugar concentration of the roots decreased. When the concentration of sugar in plant roots is reduced to an insufficient level for ammonium metabolism, free ammonia accumulates in root cells and poisoning root respiration , followed by plant root death (Ganmore-Newman and Kafkafi, 1985).\nMany agricultural companies introduce high-efficiency fertilizers by adding nitrification inhibitors (dimethylpyrazole phosphate, DMPP). Nitrification inhibitors refer to chemicals that can inhibit the biological conversion process of ammonium-N into nitrate-N. They can selectively inhibit the activity of nitrifying bacteria in the soil, thereby retarding the reaction speed of ammonium-N in the soil into nitrate-N. Ammonium-N can be absorbed by soil colloids and is not easy to leach.\nDMPP reduces N leaching for a period of 4 to 10 weeks, depending on soil temperature and soil humidity, the transformation of ammonium to nitrate is delayed. N availability is further adapted to the plants’ requirements. But, however, ammonium-N in soil (NH4+), the accumulation is a lethal factor, killing many crops in the forest. As far as I am concerned, nitrification inhibitors (equal to suicide) are not suitable for durian fertilizer management programs.\nNH4+ is not only an important nitrogen source necessary for plant growth, but also a wide range of intermediate products existing in plant metabolism. However, when the external NH4+ concentration is too high, it can inhibit the growth of most higher plants. In this article, we discussed the susceptibility of different species to NH4+, and the symptoms of NH4+ poisoned plants, especially the mechanism of NH4+ poisoning and the methods to alleviate NH4+ poisoning. Different plants have different sensitivity to NH4+ poisoning. The growth of plants damaged by NH4+ poisoning is significantly inhibited. However, applying mixed nitrogen sources and increasing the K+ concentration in the culture conditions can reduce the degree of NH4+ poisoning.\nNH4+ in plants can be directly absorbed from the soil through roots, and it is also the product of deamination of some organic compounds in plants during certain pathways such as protein degradation, photorespiration, and biosynthesis of lignin. High concentration of NH4+ can inhibit the growth of plants. In some land, the concentration of NH4+ can reach 40 mmol/Lt (720ppm). When NH4+ is the only nitrogen source, it can produce NH4+ toxicity to plants. In addition, in the soil using urea as fertilizer, due to the action of bacterial urease, urea is converted into NH4+ and CO2 in a large amount, which greatly increases the NH4+ concentration in the soil, which can cause NH4+ poisoning of plants. In addition, many abiotic stresses can also cause the hyperaccumulation of NH4+ in plants. If NH4+ cannot be assimilated effectively, it can also produce NH4+ poisoning symptoms. And recent studies have found that the accumulation of excessive NH4+ is considered a factor in the extinction of plant species in various ecosystems. Therefore, the in-depth understanding of the NH4+ toxicity mechanism and the exploration of methods to alleviate the NH4+ toxicity are of great significance.\n1 Classification of NH4+ sensitive species and NH4+ resistant species\nThe phenomenon of NH4+ poisoning is very common, but different plant species have different thresholds for responding to it. In mature plants, the symptoms of ammonium poisoning usually appear first on the lower old leaves, while the young plants appear first on the new leaves. Domesticated plants that are sensitive to NH4+ ion toxicity include tomatoes, potatoes, barley, peas, castor, mustard, beets, strawberries and citrus. In the soil of many natural ecosystems, NH4+ has increasingly become the main form of N source. Wild-type herbaceous plants Arnica and thistle parsley and Cistanche cistanche are also particularly sensitive to NH4+ toxicity.\nExisting plants that are more resistant to NH4+ toxicity include rice and onions among domesticated species. Wild plants include heather, Ulagrass, Proteas and some temperate quilt trees. Even species that are highly resistant to NH4+ toxicity, when a sufficient amount of NH4+ is applied to them, they can also show toxic properties. For example, under the treatment of excessive NH4+, rice showed a phenotype of yellowing leaves and inhibited growth, especially under low potassium conditions. The deposition of a high degree of NH4+ can cause a large number of deaths of the red spruce in the forest, which is considered to be highly resistant to NH4+. The resistance to NH4+ poisoning varies with the species and the growth period.\nNH4+ poisoning can change the morphology of plants. The concentration of exogenous NH4+ that can produce NH4+ poisoning is generally 0.1~0.5mmol/L. Barley is a plant that is sensitive to NH4+. Studies on it have shown that NH4+ toxicity can cause yellowing of barley leaves and inhibit plant growth, especially root elongation. In addition, NH4+ poisoning can also cause other visible symptoms, such as lowering the root/leaf ratio and reducing yield. More importantly, NH4+ poisoning can also inhibit the germination and seedling establishment of seeds, and it can cause the extinction of certain seed plants in nature. The accumulation of excessive NH4+ in plants can also affect the absorption of certain nutrient elements and the balance of hormones, and can lead to a decrease in the concentration of soluble carbonic acid. At the same time, it can increase the concentration of amino acids. In addition, NH4+ stress can also induce a large amount of ROS (reactive oxygen species) in plants, including superoxide radicals O2- and H2O2. Although the absorption of inorganic cations is reduced under NH4+ poisoning conditions, the total amount of NH4+ absorbed is still very large, resulting in that the cation concentration in the plant is still higher than the anion concentration. At the same time, plants poisoned by NH4+ can acidify the environment around the root system. The possible reason for this phenomenon is to balance the charge disorder in the plant, and a large number of protons flow out from the plant. However, plants cultivated under nitrate nitrogen conditions can cause alkalization of the surrounding environment.\n3 Mechanism of excessive NH4+ toxicity\nMany researchers have speculated on the principle of the phenomenon that excessive NH4+ can be harmful to plants. Most people believe that a large amount of NH4+ in plants leads to a decrease in the absorption of K+, Mg2+ and Ca2+, thereby causing ion disorders in plants. The rapid assimilation of NH4+ in roots requires a large amount of carbon skeleton as a substrate to complete the assimilation of NH4+ into amino acids This process leads to insufficient carbon skeletons in the roots of plants, and eventually causes toxicity. The assimilation of NH4+ can also lead to the release of H+, and further cause decarboxylation reaction, which is a decrease in the concentration of carbonic acid in the cell. The decrease in the concentration of carbonic acid caused by the decarboxylation of the root further leads to the lack of the carbon skeleton in the root, which causes an increase in the absorption of anions to balance the intracellular charge. Some researchers believe that NH4+ toxicity is related to the hormone disorder in plants. The phenomenon of plant main root growth inhibition caused by excessive NH4+ is believed to be related to auxin transport or signal pathways, and ethylene production is found in the leaves of plants with higher NH4+ concentration. In addition, some researchers believe that NH4+ toxicity is related to the reduction of light sum rate. In addition, some researchers believe that NH4+ toxicity is related to the decrease of light sum rate. The results of recent research on barley show that under high NH4+ concentration, the growth of barley is inhibited due to the waste of energy caused by NH4+ passing through the plasma membrane. Excessive NH4+ in the cell is transported out of the cell by an unknown transporter at the expense of energy. The high respiration rate in the roots and the energy requirement for NH4+ excretion suggest that this may be the essential reason for the damage of high concentrations of exogenous NH4+ to plants. In plant cells, excessive accumulation of NH4+ results in excessive transport of NH4+ across the plasma membrane, thereby forming NH4+ toxicity. Many bacteria in the environment of low concentration of K+ and high concentration of NH4+ ions, due to the transport of excess NH4+ across the plasma membrane, resulting in enhanced respiration. The latest research found that GDP-mannose pyrophosphorylase (GMPase) is related to NH4+ sensitivity in Arabidopsis roots. In this study, the decrease in GMPase activity caused defects in the N-glycosylation process of proteins, which is considered to be an important molecular level downstream step involved in the phenomenon of NH4+ inhibiting root growth. N-glycan activation is necessary for the correct folding of proteins, and plays an important role in initiating protein folding, cellulose synthesis, cell wall stability and maintaining cell viability. GDP-mannose is very important for the correct N-glycosinification process of protein in Arabidopsis and the synthesis of ascorbic acid. cty1 is a mutant with nonsense mutations in GMPase. GMPase is a key enzyme in the synthesis of GDP-mannose. This mutant exhibits an embryonic lethal phenotype. vtc1 and hsn1 are homologous genes of GMPase. Under normal conditions, the phenotypes of these two mutant strains are not different from those of the wild type, but when in a high NH4+ environment, the root length of the mutant strain is obviously suppressed. The embryonic lethality shown in cty1 and the phenotype that the root lengths of vtc1 and hsn1 are sensitive to NH4+ are all caused by the defect of N-glucose activation. However, the question of whether the glycostimulation of protein is related to the process of NH4+ transport across the plasma membrane remains to be further studied.\nThe harm caused by NH4+ toxicity is great, but we can alleviate it by certain means. Increasing the pH of the solution can alleviate the degree of NH4+ toxicity to a certain extent. In addition, optimizing the light intensity can also alleviate the NH4+ toxicity symptoms of plants grown on the medium with NH4+ as the sole nitrogen source. Because NH4+ poisoning can affect the absorption of nutrient elements by plants, enhancing the concentration of nutrient elements in the environment, especially the concentration of nutrient cations, can also alleviate NH4+ poisoning to a certain extent. Either in the culture medium or in the field, increasing the K+ concentration can alleviate the NH4+ toxicity.\nWhen NH4+ is used as the only nitrogen source, it can form obvious NH4+ poisoning, but when it is used as a nitrogen source with nitrate, the symptoms of NH4+ poisoning can be significantly improved. Moreover, the mixed nitrogen sources can form a kind of synergistic growth, and the total growth rate exceeds the growth of the two nitrogen sources alone. More interestingly, this kind of synergistic growth has also been observed in the growth of conifers. There are two possible explanations for this phenomenon: one is that when nitrogen sources are mixed, it can increase the synthesis of cytokinin; the other is that the absorption of nitrate by plants can cause the alkalinization of plant roots, thereby alleviating the plant roots caused by NH4+ poisoning. The acidification process of the roots.\nFor NH4+-sensitive species, excessive NH4+ has a serious inhibitory effect on their growth and yield. Many crops are sensitive to NH4+, and their yield is greatly affected by NH4+ poisoning. In addition, NH4+ poisoning has a significant impact on ecology. A more effective way to alleviate NH4+ toxicity is based on the understanding of NH4+ toxicity mechanism. The use of a mixed medium of nitrate and ammonium nitrogen and increasing the K+ concentration in the culture conditions to alleviate the NH4+ toxicity are successful application examples. However, because the symptoms of NH4+ poisoning are diverse, and it may be related to multiple metabolisms, the mechanism of the poisoning may not be single, which increases the difficulty of studying the NH4+ poisoning mechanism. Considering the degree of harm caused by NH4+ poisoning, more research is needed in the future to better reveal the mechanism of NH4+ poisoning.\nPlease download “Salt Washing” for countermeasure (the improvement of saline soil can use drainage or salt washing method to eliminate excessive salt)']	['<urn:uuid:65341046-fbcf-439b-a97f-88deace10914>', '<urn:uuid:8bad37bb-aa36-4cde-81da-56d39912b771>']	open-ended	with-premise	verbose-and-natural	similar-to-document	multi-aspect	expert	2025-05-01T23:46:40.222380	30	96	2787
435	historical development acoustic wave theories ancient modern scientific understanding	The understanding of waves began with acoustics studies by ancient Greek philosophers who hypothesized a connection between waves and sound. Pythagoras observed in 550 BCE that vibrating strings produced sound and studied mathematical relationships in harmonious tones. Scientific wave theories advanced in the 17th Century with Galileo linking vibrating bodies to sound production. Robert Boyle proved in 1660 that sound cannot travel through vacuum, and Newton provided mathematical descriptions in 1686. In the 18th Century, d'Alembert derived the wave equation, establishing foundations for future wave phenomena studies.	"['On July 17, 1998, three huge waves – ""tsunamis"" – up to 15 meters high struck the north coast of Papua New Guinea, killing at least 2,200 people. A major earthquake, itself consisting of waves traveling through the Earth, triggered an underwater landslide that created the tsunamis. Radio stations reported the disaster by transmitting electromagnetic radio waves to listeners around the world. Listeners were able to hear the news transported by sound waves created by their radios.\nWaves of one form or another can be found in an amazingly diverse range of physical applications, from the oceans to the science of sound. Put simply, a wave is a traveling disturbance. Ocean waves travel for thousands of kilometers through the water. Earthquake waves travel through the Earth, sometimes bouncing off the core of the Earth and making it all the way back to the surface. Sound waves travel through the air to our ears, where we process the disturbances and interpret them.\nAncient wave theories\nMuch of our current understanding of wave motion has come from the study of acoustics. Ancient Greek philosophers, many of whom were interested in music, hypothesized that there was a connection between waves and sound, and that vibrations, or disturbances, must be responsible for sounds. Pythagoras observed in 550 BCE that vibrating strings produced sound, and worked to determine the mathematical relationships between the lengths of strings that made harmonious tones.\nScientific theories of wave propagation became more prominent in the 17th Century CE, when Galileo Galilei (1564-1642) published a clear statement of the connection between vibrating bodies and the sounds they produce. Robert Boyle, in a classic experiment from 1660, proved that sound cannot travel through a vacuum. Isaac Newton published a mathematical description of how sound travels in his work Principia (1686). In the 18th Century, French mathematician and scientist Jean Le Rond d\'Alembert derived the wave equation, a thorough and general mathematical description of waves, which laid the foundation for generations of scientists to study and describe wave phenomena.\nOur understanding of wave motion began with the study of\nWaves can take many forms, but there are two fundamental types of waves: ""longitudinal"" and ""transverse"" (see Figures 1 and 2). Both of these wave types are traveling disturbances, but they are different because of the way that they travel. As a wave travels through a medium, the particles that make up the medium are disturbed from their resting, or ""equilibrium"" positions. In a longitudinal wave, the particles are disturbed in a direction parallel to the direction that the wave propagates. A longitudinal wave consists of ""compressions"" and ""rarefactions"" where particles are bunched together and spread out, respectively (see Figure 1). For another view of this type of wave, take a look at the longitudinal wave video clip below. In a transverse wave, the particles are disturbed in a direction perpendicular to the direction that the wave propagates. The transverse wave video clip below provides a dynamic visualization of this type of wave. After either type of wave passes through a medium, the particles return to their equilibrium positions. Thus, waves travel through a medium with no net displacement of the particles in the medium.\nSound waves are examples of longitudinal waves: the individual particles (air molecules) vibrate back and forth in the direction that the sound is traveling. An example of a transverse wave is the classic sports arena phenomenon known as ""The Wave."" As the wave travels around the stadium, each spectator stands up and sits down. Thus, the displacement of the ""particles"" is perpendicular to the direction the wave travels. Many other waves, such as ocean waves or Rayleigh Surface Waves are combinations of longitudinal and transverse wave motion.\nParticles bunch together and spread out in _____ waves.\nThe waves we described above are all examples of \'periodic waves,\' in that they involve a cyclical pattern of motion. Waves travel through space and time, and can be described in terms of their characteristics in both of these dimensions. Imagine a Slinky®, a toy that consists solely of a long, loosely coiled piece of metal or plastic. By shaking one end of the Slinky® up and down in a periodic fashion, it is possible to produce a transverse wave, as shown in the figures below.\nAmplitude and wavelength\nFigure 3 represents a snapshot of a Slinky®, such as the one in the transverse wave video clip, as it is vibrating. The vertical axis represents the vertical position of the Slinky®, and the horizontal axis represents its horizontal position. As indicated in the figure, the amplitude (A) of the wave is the maximum displacement of a particle from its equilibrium position – or the height of the wave. The length of the wave is the wavelength (λ), and is simply the length of one cycle of the wave. In the figure, the wavelength is shown as the distance between two successive wave crests. The wavelength can also be measured between successive troughs, or between any two equivalent points on the wave. Both the amplitude and the wavelength of a wave are commonly measured in meters.\nThe height of a wave is know as its\nFigure 4 is a graph of the displacement of one point on the Slinky® as a function of time. The amplitude of the wave is still the same measurement as before – the maximum displacement of the point from its equilibrium position. The wave period (T) is the time (measured in seconds) required for the point to complete one full cycle of its motion, from its highest point to its lowest and back again.\nThe frequency of a wave (f) (not indicated in the figure) is a measure of how frequently the point completes one cycle of its motion. In other words, the frequency is the number of wave cycles completed by one point along the wave in a given time period. The frequency of a wave is related to the period of a wave by the following equation:\nWhere f is the frequency and T is the wave period. The frequency is measured in cycles per second, or hertz (Hz). If the wave period is 10 seconds (that is, it takes 10 seconds for the wave to complete one cycle), then the frequency is 0.1 Hz. In other words, the wave completes 0.1 cycles every second.\nA frequency of 0.1 Hz means that a wave completes _____ cycles every second.\nRemember that a wave is a traveling disturbance. Wave speed is a description of how fast a wave travels. The speed of a wave (v) is related to the frequency, wave period, and wavelength by the following simple equations:\nwhere v is the wave speed, λ is the wavelength, T is the wave period, and f is the frequency. Wave speed is commonly measured in units of meters per second (m/s). For example, the musical note ""A"" is a sound wave with a frequency of 440 Hz. The wavelength of the wave is 78.4 cm. What is the speed of the sound wave?\nThis value (345 m/s) is the approximate value of the speed of sound in air. Interestingly, the speed of sound in air depends on temperature and pressure. A musician who plays a wind instrument, such as a trumpet, could tune her trumpet at the base of a mountain, hike up the mountain to where the air pressure is lower, and find that her trumpet is no longer in tune. Similarly, a change in air temperature could also change the tuning of the instrument.\nAs the example above illustrates, waves are all around us in everyday life. The Ancient Greeks began their study of waves by thinking about music, but now almost every branch of physics involves waves in one way or another.\nWaves have been of interest to philosophers and scientists alike for thousands of years. This module introduces the history of wave theory and offers basic explanations of longitudinal and transverse waves. Wave periods are described in terms of amplitude and length. Wave motion and the concepts of wave speed and frequency are also explored.\nThe study of waves dates back to the ancient Greeks who observed how the vibrating strings of musical instruments would generate sound.\nWhile there are two fundamental types of waves - longitudinal and transverse - waves can take many forms (e.g., light, sound, and physical waves).\nWaves can be described by their exhibited properties: frequency, speed, amplitude, and wavelength.']"	['<urn:uuid:3d8529e2-5613-4a1a-8bee-0d53c1cd9014>']	open-ended	direct	long-search-query	distant-from-document	single-doc	expert	2025-05-01T23:46:40.222380	9	87	1410
436	What makes leather production better for the environment in developed countries?	Leather production in developed countries is typically more environmentally beneficial due to stricter environmental rules and regulations. In France, for example, the industry has adopted standards including waste sorting systems, water pollution control with separate sewer systems, and air pollution control through aqueous formulas. These measures have led to significant improvements, such as reducing water consumption by 60% and emissions of organic solvents by 90%.	"['Bio leather - Organic leather\n""Bio"" does not have a clear definition. It generally describes a ""green"" ideal of a product that is made in as environmentally-friendly a way as possible, does not harm the consumer and can be disposed of without damaging the environment. An exact ruling on how and when a product can be called ""bio"", ""biological"" or ""organic"" is not available.\nBio-Leather - Tanning methods\nThe term bio leather is usually associated with vegetable-tanned leather. This is because ""vegetable"" sounds ecological and therefore suggests that a product has been manufactured ecologically. However, when comparing chrome tanning with plant-based vegetable tanning, the entire production process should be taken into account and not just the source of the tanning agents.\nA scientific investigation concluded that both these tanning methods were more or less identical in terms of resource-conserving and/or resource-sparing. The disadvantages of the chemical content of chrome tanning must be compared with those of vegetable tanning. These are:\n- Vegetable tanning agents must be extracted in distant countries (cutting trees, tannin production).\n- Delivering the tannins to the tanneries involves long sea voyages and high fuel consumption.\n- The consumption weight of plant tannins per tanned skin is significantly higher than with chrome tanning agents.\n- The sewage water contamination resulting from the considerably higher number of tanning baths, which the leather has to go through, is much higher in vegetable tanning than with chrome tanning.\nCriteria for bio leather\nLeather production basically involves the tannery converting a waste product into a durable, natural material. This involves various production stages. Depending on environmental requirements and regulations, tanneries across the world are subject to varying rules. In developed countries, it can be assumed that these rules are much more stringent. But most of world production does not take place in developed countries. It can be assumed that leather production in developed countries will be more beneficial to the environment. Accordingly, leather prices are higher. In any case, fulfilling these requirements is not sufficient for labelling as ""bio-leather"".\nThe following aspects play a role in the naming of a leather as ""bio leather"":\nComplete traceability of the animal skin:\n- Where was the animal kept throughout its life cycle? Free-range? Barn or cage? Other living conditions?\n- What drugs have been administered? Permanent vaccinations and preventative antibiotic care etc.?\n- How was the animal fed? Fresh food? Recycled wastes from other food production processes? Pesticide-containing? Genetic manipulation? Sustainable?\n- How was the animal slaughtered?\n- Types and quantities of chemicals with complete traceability through the production chains (tannins, dyes, binders, pigments, oils and much more).\n- For vegetable tanning: Sustainable? Renewable resources? Transport routes? Often bio leather is advertised with ""vegetable tanned"". This does not mean that vegetable tanning itself was biologically carried out (it can be worked with great environmental damage) and it does not say that the leather could not be contaminated with chromium or with other pollutant chemicals.\n- Minimum wages, social standards etc. in the tannery.\n- Handling of production waste including re-use.\n- Treatment of polluted sewage.\n- Resource conservation, sustainability\n- Work safety\n- Social standards and remuneration\nThe sum of the factors to consider is very long and whether any leather deserves the title of ""bio-leather"" - or not - should only be decided by the customer. The term ""bio leather"" is not protected and the certificates established by the industry do not always consider all points. The perfect organic leather can also never be mass produced. But there are leather producing companies that pay more attention to the environment than others.\n- Eco leather\n- Vegan leather\n- Leather quality\n- Vegetable-tanned leather\n- Chrome tanned\n- Chrome-free leather - FOC = Free of Chrome\n- PeTA - People for the Ethical Treatment of Animals\n- Ecological leather care - Eco leather care', 'The French tanning industry employs production techniques designed to protect the environment and consumer health.\nEnvironmental standards – sustainable development\nThe French tanning industry has adopted environmental standards and developed technologies that show consideration for the natural environment:\nWith the introduction of waste sorting, disposal and recovery systems.\nWater pollution control\nWith separate sewer systems and appropriate treatments.\nIn recent decades, science has helped the leather industry to reduce its water consumption by more than 60%, thanks to the development of new cleaning techniques, to the use of batch processing techniques based on clean technology, in place of rinsing, and to more efficient water management.\nMost leather production – approximately 80% – now uses chromium III tanning methods. This produces a supple and soft leather that can be dyed in a wide variety of colours.\nBy reducing the quantity of chromium III to the exact quantities required to guarantee the quality that consumers expect of an article made of leather, the quantity of chromium discharged into the water used for the tanning process has been reduced by more than 90%.\nAir pollution control\nWith the development of aqueous formulas to reduce emissions.\nScience has enabled the leather industry to reduce emissions of organic solvents into the air by 90% for most types of leather. This reduction is due to the introduction of better systems, combined with new, more environmentally-friendly finishes.\nThere is ongoing investment in enhanced industrial plant and processes, with a view to reducing the environmental impact of the tanning industry.\nThanks to their ongoing efforts, a number of tanners have obtained the Entreprise Responsable et Durable [‘Responsible and Sustainable Company’] accreditation, which is awarded by the French Industrial Risk Centre (CNRI).\nIt should also be borne in mind that the tanning industry is first and foremost an activity based on recycling and recovering thousands of tonnes of hides and skins generated on a daily basis by slaughtering animals for their meat. What environmental impact would all this waste material have if it was not recycled by the tanning industry?\nProtecting human health\nEnsuring French leather safety is one of the industry’s main preoccupations\nFrench and European standards governing chemical substances are strictly adhered to and monitored: correct proportioning of water and volatile matter; extractable matter, soluble matter and soluble mineral matter contained in leathers; and chloride ion content, to limit any adverse effects on consumer health.\nThe French leather industry prescribes a series of good practices to avoid generating allergenic substances and recommends the use of harmless substances such as basic chromium sulphate or vegetable tannins.\nMonitoring is carried out by accredited bodies – notably CTC, Comité Professionnel de Development Economique Cuir Chaussure Maroquinerie [‘Economic Development Committee for the Footwear, Leather and Leather Goods Industry’] – using extremely high-tech tools, which can measure very low concentration levels of chemical substances – of the order of ppm (parts per million or mg per kg of leather).\nBusinesses are bound by French and European legislation governing installations classified on environmental protection grounds, and are supervised by the DREAL (French Regional Directorates of the Environment, Land Use and Housing) and by the Ministries of Labour, Employment, Vocational Training, Social Dialogue, Social Affairs and Health.\nFor mineral tanning, the French tanning industry uses chromium sulphate, also known as trivalent chromium or chromium III, which is totally harmless and poses no risk to consumers’ health. Chromium III should not be confused with chromium VI or hexavalent chromium.\nCorporate social responsibility (CSR)\nThe French leather industry is the only one at international level to have been working for the past two years on its commitments in terms of being a good corporate citizen, within the framework of ISO standard 26000, which relates to CSR.\nThe Fédération Française de la Tannerie Mégisserie is working on this subject via two committees:\nA Technical Committee, where the French Tanners Federation works with CTC, notably on the area of environment watch.\nAn Industry-Wide Committee covering the entire French leather industry, from upstream processing to downstream activities, with the aim of creating a set of CSR standards for the leather industry.\nFor further information on ISO standard 26000, please go to: http://www.iso.org/iso/home/news_index/news_archive/news.htm?refid=Ref1366']"	['<urn:uuid:2cdbe9fa-1959-4290-87f6-39c95c52e276>', '<urn:uuid:b519fbdb-afc7-4a91-a950-6b6c8f5ca2a2>']	factoid	with-premise	concise-and-natural	similar-to-document	three-doc	novice	2025-05-01T23:46:40.222380	11	65	1334
438	behavior specialist need know principle making rewards effective change behavior	For rewards to be effective in behavior change, they must be frequent when first learning the behavior and can become less frequent to maintain it. The magnitude of the reward should closely correspond with the degree of behavior change, and one's ability to delay gratification must be considered when first establishing rewards.	['Behavior Therapy: Why Resolutions Fail\nA basic understanding of the theory and practice of behavior modification will greatly increase your chances of success with resolutions made on New Year’s Eve or attempts to change habits at any time of the year. Many of the principles of behavior therapy are based on learning theory. Habits, good or bad, can be learned or un-learned.\nThere are two main types of conditioning that form the basis of all learned behavior. When any behavior is modified as a result of the consequences, positive or negative, this is the result of operant conditioning. The basic theory of this type of conditioning is logical and simple: rewards will increase the desired behavior, absence of reinforcement will slowly extinguish the behavior, and any punishment will decrease the behavior.\nThis formula makes operant conditioning an ideal way to modify any behavior and have more success with New Year’s resolutions. In order to modify a behavior using operant conditioning, it is important to first identify precisely not only the target behavior, but also the reward & punishment. It is crucial that rewards & punishments be implemented consistently, and they should ideally be related to the goal behavior.\nBoth accountability and support can be subtle types of reinforcement and verbal or written commitments can also provide some help with motivation. Rewards need not be monetary and may be even occur naturally—sometimes a sense of pride and praise from others is enough reinforcement. And, disappointment & shame are two natural consequences that can be punishing.\nAll rewards should be frequent in order to learn the behavior and then can be less frequent in order to maintain the behavior. One’s ability to delay gratification must be considered when you are first establishing rewards. Also, the magnitude of the reward should closely correspond with the degree of behavior change.\nRewards always work better than any punishments. A negative consequence should only be used when there is also the possibility of an equally significant positive consequence. The reward & punishment need not be of the same currency, just of the same magnitude.\nIt’s always easier to add a behavior than it is to stop a behavior. Try to set a goal that involves doing something differently, rather than not doing something that has become a habit. You will have a greater chance of success.\nChanging habits and other behaviors can be hard but behavior change can be gradual. Though a long range goal may be difficult, each short term goal should be a little challenging but achievable.\nIn a process known as shaping, small changes are reinforced and expectations are gradually increased: then behavior is only reinforced if it is a closer approximation of the ideal behavior.\nFailure at New Year’s resolutions is most often the result of poorly planned & poorly implemented behavior modification. Other factors which can impact success or failure with implementing a behavior change may include untreated psychological or medical conditions, addictions and strong familial or cultural expectations. Sometimes unconscious psychological conflicts can interfere with our thoughts and actions, and hence they become obstacles to success. A well formulated behavioral plan must address these issues as well in order to produce lasting changes.']	['<urn:uuid:3a930fc6-c8d0-4225-bd54-eb8c8a167cc9>']	factoid	with-premise	long-search-query	similar-to-document	single-doc	expert	2025-05-01T23:46:40.222380	10	52	533
439	erp compliance security data protection steps	ERP compliance and data protection involves multiple key steps: conducting regular security audits to identify cyber threats and protect data, ensuring encryption of data at rest with cryptographically-strong passwords, and maintaining PCI DSS compliance for all system components including network elements, servers and applications. This comprehensive approach safeguards business continuity while protecting sensitive information across the enterprise.	"['How to Conduct an ERP Audit – The Complete Checklist\nImplementing ERP software can be a highly labour-intensive process, with dozens of deployment and testing hurdles to overcome before the system is primed for go-live. But what comes after that? And how can you ensure your software is operating as well as it should?\nIn this post, we’re taking an in-depth look at one of the most crucial elements of maintaining an ERP system – auditing. From best-practice tips to a checklist of things to remember, our guide can help you conduct a successful ERP audit and ensure the software is working hard for your business.\n- What is an ERP Audit and Why Are They Necessary?\n- Different Types of ERP Audits Explained\n- ERP Audit Checklist: 5 Steps to Auditing Success\nWhat is an ERP Audit and Why Are They Necessary?\nERP auditing is the process of testing and reviewing enterprise resource planning functions to ensure they’re working as efficiently as possible. The objective is to determine how adequately individual ERP modules are solving problems and streamlining workflows, with a view to make improvements and sure-up the system.\nImplementation is only the first step in the ongoing task of managing and refining ERP software. Following go-live, regular maintenance and auditing are essential in ensuring that the system continues to deliver tangible solutions and results for your operation.\nCarrying out an ERP audit is essential for the following reasons:\n- Ensures data accuracy – are your ERP modules gathering and segmenting accurate data? Or can improvements be made to safeguard against aggregation anomalies which might harm parts of your business?\n- Safeguards compliance – if you operate within a regulation-heavy industry, regular auditing will ensure that your ERP suite continues to adhere to rules and regs, for cross-supply chain compliance and peace of mind.\n- Bolsters security – don’t let individual modules of your ERP software jeopardise the security of your supply chain; keeping the system up to date is critical in maintaining the safety of your data and assets.\n- Error avoidance – as your ERP suite beds in and is taken up by the wider business, consider the likelihood of errors; errors which could inadvertently result in a drop in productivity along your supply chain. An audit will highlight these mistakes before they become systemic issues, giving you the opportunity to put them right.\n- Consistent ROI – cost-cutting is one of the key reasons why many invest in ERP solutions. But how can you make sure your system is delivering consistent ROI? Regular auditing is the key, giving you the peace of mind that each process and application is supporting your bottom line.\nDifferent Types of ERP Audits Explained\nThere’s no one-size-fits-all solution to ERP auditing. Instead, the tests, assessments and reviews you carry out will depend on your software, applications and unique business objectives.\nAs such, several tactical ERP auditing strategies have emerged in recent years, as businesses look to assess the core framework of their system. Let’s take a look at some of the different types of ERP audits and what they’re used for.\nThis type of auditing looks at processes and workflows throughout your supply chain, assessing their efficiency, necessity and performance. It’s an effective means of identifying bottlenecks and project halt points, so you can take the appropriate streamlining measures.\nAs the name suggests, this form of ERP auditing is all about ensuring compliance. If regulations hold sway in your industry, making sure your processes and procedures align with these legal requirements is critical from a business continuity standpoint.\nSystem auditing focuses on the technical requirements of the software; for this reason, it’s normally carried out by IT personnel or a trusted third-party vendor. Here, you’re looking to reaffirm that your ERP applications have the appropriate hardware and networking capacity to function at their optimum.\nAgain, the clue’s in the name; this type of auditing focuses on assessing the security provision of your ERP system. Which applications are most at risk from cyber threats, and what measures are in place to deal with the risk of data loss or corruption?\nA waste audit seeks to identify the unnecessary elements within your ERP framework. From overproduction to process wait times, a lot of variables can be defined as ‘waste’, so getting these in hand can drive efficiency and reduce costs.\nERP Audit Checklist: 5 Steps to Auditing Success\nRegardless of the auditing measures you plan to execute, a checklist of strategic actions can ensure the assessment aligns with the ‘what’ and the ‘why’ of your auditing activity.\nHere are five steps to consider when planning an ERP audit.\nStep 1: Identify Your Objectives\nWhat is the purpose of the audit, and what do you hope to achieve? Pinning down key objectives which align with your business goals is imperative to the success of your auditing project.\nLet’s take a look at a couple of examples of typical ERP auditing objectives:\n- “This waste audit will look to identify overproduction weaknesses in the supply chain”\n- “The aim of this security audit is to identify and plug holes in the security of individual ERP applications”\n- “The planned system audit will establish if the current network is adequately supporting the ERP software”\nStep 2: Assemble Your Audit Team\nAssigning auditors to the project is a crucial step, and one you’ll need to think carefully about. Who in your organisation is best placed to test and review the software in line with your key project objectives?\nWhen assigning auditing roles, look to include as broad a range of disciplines as possible. Sure, IT and engineering personnel may be a must, but other day-to-day users can provide invaluable insight into how the system works on an everyday level.\nStep 3: Create a Simple Issue Flagging Process\nHow easily can your auditors flag issues for review and approval? Developing a simple, transparent process for raising and reviewing auditing outcomes is a crucial step before you launch headlong into the project.\nDepending on the scope of the audit, this could be as simple as a shared Google sheet, but to ensure full collaboration, transparency and effective audit management, we’d recommend a Kanban-style process board.\nStep 4: Accurate Issue Recording\nAfter you’ve determined where to log system issues, you need to outline the type of information which should be recorded. While this will depend on the type of audit in question, typical issue-related logs should include:\n- A brief description of the problem\n- An outline of the risk should it go unresolved\n- Details of the auditor who found the problem\n- The date and time when the issue was identified\nStep 5: Prioritise and Execute Changes\nWhen the audit is complete, it’s important to prioritise issues by severity, before delegating key improvement tasks to the relevant personnel. This is the time to make your auditing activity count, so invest the appropriate time and resources into making the necessary improvements.\nWe hope you’ve found the above guide to ERP auditing useful. If you need help implementing, managing or auditing an ERP system, the expert team at JS3 Global can help. With years of combined experience in overseeing ERP integration projects, we have the know-how to deliver practical solutions for your business. For more information or to discuss your requirements call us today on +44(0)161 503 0866 or email us at email@example.com.', 'Encryption, Compliance, and Disaster Planning\nCommon data encryption rules are a requirement and represent interoperability when developing your backup strategy for your disaster recovery business continuity plan.?When enterprise protect data at rest such as when a USB drive is unplugged, or when a laptop is powered down, or when an administrator pulls a drive from a server, it cannot be brought back up and read without first giving a cryptographically-strong password. If you do not have that, the media is a brick and you cannot even sell it on eBay.\nFor enterprises rolling out security across PCs, laptops and servers, standardized hardware encryption translates into minimum-security configuration at installation, along with higher performance with low overhead. The specifications enable support for strong access control and, once set at the management level, the encryption cannot be turned off by end-users.\nThe PCI DSS security requirements apply to all ""system components."" A system component is defined as any network component, server, or application that is included in or connected to the cardholder data environment. The cardholder data environment is that part of the network that possesses cardholder data or sensitive authentication data. Network components include but are not limited to firewalls, switches, routers, wireless access points, network appliances, and other security appliances. Server types include, but are not limited to the following: web, database, authentication, mail, proxy, network time protocol (NTP), and domain name server (DNS). Applications include all purchased and custom applications, including internal and external (internet) applications.\nThe PCI-DSS Compliance Kit comes in three versions;\n- Silver - Contains the e-Commerce, Wireless, and Internet Job Descriptions in WORD and PDF format, the Security Audit Program in WORD format, and the PCI Audit Program in WORD and PDF format.\n- Gold - Contains the e-Commerce, Wireless, and Internet Job Descriptions in WORD and PDF format, the Security Audit Program in WORD format, the PCI Audit Program in WORD and PDF format, and Network Event Viewer - Unlimited which allows you to monitor an unlimited number of PCs Security.\n- Platinum -?Contains the e-Commerce, Wireless, and Internet Job Descriptions in WORD and PDF format, the Security Audit Program in WORD format, the PCI Audit Program in WORD and PDF format, the Network Event Viewer - Unlimited which allows you to monitor an unlimited number of PCs Security, and the Security Manual Template in WORD format\nIT Infrastructure is a Foundation Block That Management Rests\nPCI-DSS compliance drives CIOs to get back to basics\nComputers today are an integral part of day-to-day business, commerce, and personal life. E-mail and instant messages are heavily used for communications. Enterprise administrative business processes depend upon computer automation, record keeping, and dependable, confidential, and quick access to reliable information. The enterprise operational processes make use of computers for communication with employees, vendors, supplies, and customers.\nEveryone has a stake in ensuring that the computing infrastructure continues to operate reliably and that it preserves the confidentiality and integrity of the information it handles - both our own and that of those we serve. Between PDAs, SmartPhones, laptop computers, and desktop computer many of our users have up five devices each that they use. Each device contributes to our network\'s security. Each operator of those devices has a necessary and important part in preserving the integrity of the network, just as every citizen has a necessary and important part in preserving a society.\nWith the explosion of technology into every facet of the day-to-day business environment there is a need to define an effective infrastructure to support operating environment; have a strategy for the deployment and technology; and clearly define responsibilities and accountabilities for the use and application of technology.?']"	['<urn:uuid:8c5cbc3c-a194-40d4-b744-46db9aad3d90>', '<urn:uuid:1dc665c9-95b3-4da6-991a-44865d434208>']	factoid	direct	short-search-query	distant-from-document	three-doc	expert	2025-05-01T23:46:40.222380	6	57	1844
440	What are the key differences between how a Property and Financial Affairs LPA and a conservator handle someone's financial matters?	A Property and Financial Affairs LPA can manage finances and property including buying and selling property, managing investments, paying bills, and collecting benefits, based on the authority granted by the donor. A conservator has more specific and court-regulated powers - they can perform many financial tasks without court authorization (like investing funds, depositing money, making repairs, and paying taxes), but need prior court authorization for certain actions like operating a business or disposing of real estate. Additionally, conservators must file an inventory within 90 days of appointment and provide accountings to the court at least every three years, while LPAs don't have these specific reporting requirements.	['What is a Lasting Power of Attorney?\nA Lasting Power of Attorney allows your loved ones to take care of you and your finances if you become unable to do so yourself.\nThere are two types of LPA:\n- A “Property and Financial Affairs” Lasting Power of Attorney gives your Attorney the authority to deal with buying and selling your property, your bills, bank accounts and investments.\n- A “Health and Welfare” Lasting Power of Attorney covers decisions about health and care and even deciding where someone is to live. This can only be used if someone is incapable of dealing with such matters themselves.\nAn LPA ensures that, should you be unable to manage your own affairs, the people you have appointed can manage your financial life on your behalf. This can save a great deal of money and distress, and will ensure that, as a vulnerable person, your affairs will be handled correctly and quickly.\nIf you lose mental capacity without an LPA in place, it will be necessary for your family to apply to the Court of Protection to have a deputy appointed to deal with everyday financial matters. This is a slow and very expensive process, costing thousands of pounds.\nJoint bank, building society and business accounts can be severely restricted if ONE of the account holders loses mental capacity and there is no registered LPA in place. The 2013 British Bank Association booklet entitled “Guidance for People Wanting to Manage a Bank Account for Someone Else”, states: ‘If one joint account holder loses mental capacity, banks and building societies can decide whether or not to temporarily restrict the use of the account to essential transactions only’ .\nThe restricting of a joint account has severe implications as the joint owner cannot freely withdraw what is their own money without an order from the Court of Protection. This could be devastating, especially if the joint owner has their only form of income, such as their pension, paid into this joint account.\nWhat can we help you with?\n- Property sale\n- Paying bills\n- Benefit or income collections\n- Dealing with financial affairs on your behalf\n- Providing care in the event of an accident\nIn addition to power of attorney, we can provide legal advice regarding probate laws and trusts.\nWho can be your power of attorney?\nAs we grow older, we become prone to illness and need a power of attorney to handle our financial matters efficiently. You can choose your close friend, relative or a legal professional as your lasting power of attorney. It’s important that you choose your power of attorney very carefully because he or she will act on your behalf regarding your financial and personal welfare matters.\nLasting Powers Of Attorney\nThere may be a time when you may need someone to help you manage your property and affairs or personal welfare. This could be due to age, ill health or a loss of capacity.\nAn LPA is a legal document that lets you (the Donor – also known as ‘the person giving this Lasting Power of Attorney’) choose a person/persons (Attorney/Attorneys) that you trust to make decisions on your behalf at a future time when you may not be able to make such decisions due to mental incapacity or simply no longer wish to make such decisions.\nYou can create two types of LPA:\n• Property and Financial Affairs LPA\n• Health and Welfare LPA\nProperty & Financial Affairs LPA\nThis allows the Donor to appoint an Attorney to manage their finances and property. An appointed Attorney can make any decision the Donor could make about his or her property and affairs such as buying and selling property, managing investments, paying bills, collecting benefits or other income – unless restrictions are included to the contrary.\nThese are also useful documents for business owners who are sole traders, partners and also sole directors/shareholders.\nHealth & Welfare LPA\nThis allows the Donor to appoint an Attorney to make decisions about personal welfare. This document can only be used when the Donor has lost mental capacity. Unless restrictions are included, the Attorney can do anything the Donor would have done regarding personal welfare, for example:\n• Where you should live and who with\n• Day to day care\n• Consenting and refusing medical treatment\n• Arranging treatments such as dentists, doctors etc\n• Life sustaining treatment decisions can also be given to the Attorney, but only if the Donor directs\nWho Can Make An LPA?\nAnyone aged 18 years or over with capacity.\nWho Can Act As My Attorney(s)?\nAnyone can be appointed as a person’s Attorney so long as they are over the age of 18 years, have capacity and are not bankrupt. You can appoint more than one person to act. If you choose to appoint more than one then you have to decide how to appoint them. You can also appoint a substitute just in case something happens to an Attorney in your lifetime.\nAttorneys should be trustworthy and have a duty to act in your best interests and consider your needs and wishes so far as this is possible.\nWhat Happens If I Don’t Have An LPA?\nIf you lose the capacity to be able to manage your affairs for whatever reason without a valid LPA then your personal affairs will become the responsibility of the Office of the Public Guardian. In these cases a person’s affairs are placed under the jurisdiction of the Court who appoints a Deputy to act on your behalf and the Deputy is therefore answerable to the Court.\nThis can be an expensive route as Court approval is required for any act to be carried out, accounts have to be submitted to the Court every 12 months and financial decisions are not carried out by close family or friends.', 'Conservators and Guardians\nWhat is a Conservator?\nA person who is appointed by the court to manage the property of a minor or incapacitated person.\nWho is an incapacitated person?\nA person who is unable to manage property and business affairs because of:\n- Mental Illness\n- Mental Deficiency\n- Physical Illness\n- Infirmities accompanying advanced Age\n- Chronic Use of Drugs\n- Chronic Intoxication\n- Detention by Foreign Power\nWho can serve as a conservator?\nA family member or any interested person with the priorities as follows:\n- A conservator appointed in another jurisdiction\n- A person designated by the incapacitated person\n- A person designated by an incapacitated person’s power of attorney\n- Adult Child\n- Relative with whom ward has lived for the last six months\n- Nominee of a person caring for an incapacitated person\n- General guardian or sheriff\nWhen can a Conservator be appointed?\nA conservator may be appointed when an incapacitated person meets the following criteria:\n- Is unable to manage property and business affairs\n- Has property that will be wasted without proper management (or) Funds are needed to support the incapacitated person or one entitled to support from the incapacitated person.\nWhat are the powers and duties of a conservator?\nWithout court authorization the conservator may:\n- Invest and reinvest funds\n- Retain assets\n- Receive additions\n- Acquire undivided interest\n- Deposit funds in financial institutions\n- Acquire property\n- Dispose of personal property\n- Make repairs to a building\n- Enter leases up to 5 years\n- Enter mineral leases\n- Grant options up to one year\n- Vote securities\n- Pay assessments\n- Sell or exercise stock options\n- Deposit stocks and bonds\n- Consent to reorganization, a merger of a business\n- Insure assets\n- Borrow to protect estate\n- Settle claims\n- Pay reasonable annual compensation to the conservator\n- Pay taxes and expenses\n- Allocate expenses to income\n- Pay sum for benefit of the protected person or his family\n- Employ attorneys, auditors\n- Prosecute or defend claims\n- Execute and deliver appropriate instruments\n- Hold securities (court may limit powers of a conservator)\nWith prior court authorization the conservator may:\n- Continue or participate in operating business\n- Demolish improvements\n- Dispose of real estate\n- Subdivide, dedicate land\n- Leases greater than 5 years\n- Grant an option for more than one year\n- Take an option to acquire property\nAm I required to have a Lawyer?\nThe legal complexity of guardianships and conservatorships normally necessitates having an attorney since the Probate Judge cannot advise you of the law or provide you with forms.\nWhat is the difference between a guardian and a conservator?\nThe guardian looks after the person and their welfare while a conservator looks after their estate.\nWhat are the steps followed in appointing a guardian or conservator for an adult?\n- Petition filed\n- Appointment of guardian ad litem\n- Examination by physician\n- Appointment of court’s representative\n- A jury at hearing if demanded\n- Bond for conservator\n- Order granting petition\n- Letters of guardianship and/or conservatorship\n- Inventory of property for the conservator\nIs a bond required?\nYes, a bond is required for conservatorships unless the bond requirement was waived in a Will or Power of Attorney.\nIs an inventory required?\nEach conservator must complete an inventory of the estate immediately and file it with the court within 90 days after the appointment.\nAre accountings required?\nYes, a conservator must give an accounting to the court at least every three years. The court may order an accounting more frequently. Accounting is also required upon the resignation or removal of the conservator.\nWhat is a Guardian?\nThe parent of a minor or someone who has been appointed by the court to be responsible for the personal care of an individual.\nWhat is a Ward?\nThe legal name for a person for whom a guardian has been appointed.\nWho can be a Guardian for an adult?\n- The person named in a durable power of attorney\n- Spouse or spouse’s nominee\n- Adult Child\n- Parent or parent’s nominee\n- Relative with whom person has lived the prior 6 months\n- Nominee of caretaker of a person\nWho can be a Guardian for a child?\nThe court may appoint any person who will be in the best interest of the minor. However, if the minor is 14 years old or older, the minor’s nominee must be appointed unless the appointment is contrary to the minor’s best interest. Parental nomination has priority.\nCan a parent appoint a Guardian?\nYes, in a Will or other document properly signed and witnessed, a parent may appoint a guardian for a minor child or an unmarried incapacitated child.\nCan a spouse appoint a Guardian?\nYes, in a Will or other document properly signed and witnessed, a person may appoint a guardian for his or her incapacitated spouse.\nWhat are the powers of a Guardian?\n- Must assume responsibilities of a parent regarding support, care, and education\n- Must become personally acquainted with ward\n- Must take reasonable care of ward’s personal effects\n- Must apply available money for current needs or health, support, education, and maintenance\n- Must conserve excess money\n- Must report the condition of the ward to the court\n- May receive limited funds for the support of ward\n- May take custody of the ward and establish a home\n- May compel payment of support\n- May consent to medical care\n- May consent to marriage or adoption\n- May delegate certain responsibilities to the ward for the decision making\n- The court may limit powers of guardianship\nWhen does a Guardianship end?\n- Upon the death of a ward\n- Upon the resignation of the guardian\n- Upon adoption of the minor\n- Upon the marriage of the minor\n- Upon minor becoming an adult\n- When the ward’s incapacity is terminated\nTHIS INFORMATION, WHICH IS BASED ON ALABAMA LAW, IS TO INFORM AND NOT TO ADVISE. NO PERSON SHOULD EVER APPLY OR INTERPRET ANY LAW WITHOUT THE AID OF A LAWYER WHO ANALYZES THE FACTS, BECAUSE THE FACTS MAY CHANGE THE APPLICATION OF THE LAW.']	['<urn:uuid:538802ec-7d67-4789-ab82-fda9166a4c02>', '<urn:uuid:fc5c4c74-2925-4887-a12a-5d38499a038f>']	open-ended	direct	verbose-and-natural	similar-to-document	comparison	novice	2025-05-01T23:46:40.222380	20	106	2015
442	tooth decay causes prevention benefits establishing dental home	Tooth decay is the second most prevalent human disease that can cause pain and tooth loss. While it affects over 25% of children aged 2-5 and 50% of those aged 12-15, it can be prevented through good oral hygiene, regular cleanings, and establishing a dental home. A dental home provides complete preventive care, builds trust between dental team and family, helps lessen anxiety, and saves money through early intervention. The American Dental Association recommends establishing a dental home no later than 12 months of age.	"[""Tooth Decay Prevention\nOnline Dental Education Library\nOur team of dental specialists and staff strive to improve the overall health of our patients by focusing on preventing, diagnosing and treating conditions associated with your teeth and gums. Please use our dental library to learn more about dental problems and treatments available. If you have questions or need to schedule an appointment, contact us.\nAir abrasion - is a drill-less technique that is being used by some dentists to remove tooth decay and for other applications\nAmalgam - Material made from mercury and other alloy mixtures used to restore a drilled portion of a tooth.\nAnesthesia - Medications used to relieve pain.\nAnterior teeth - Front teeth. Also called incisors and cuspids.\nArch - The upper or lower jaw.\nBaby bottle tooth decay - Caused by sugary substances in breast milk and some juices, which combine with saliva to form pools inside the baby's mouth.\nBicuspids -Back teeth used for chewing.\nBitewings - X-rays that help a dentist diagnose cavities.\nBonding - Application of tooth-colored resin materials to the surface of the teeth.\nBridge - A fixed or removable appliance that replaces lost teeth.\nBruxism - Teeth grinding.\nCAD/CAM dentistry, (Computer-Aided Design and Computer-Aided Manufacturing in dentistry), is an area of dentistry utilizing CAD/CAM technologies to produce different types of dental restorations, including crowns, crownlays, veneers, inlays and onlays, fixed bridges, dental implant restorations and orthodontic appliances.\nCalculus (tartar)- Calculus is hardened plaque (a sticky substance) that has been left on the tooth for some time and is now firmly attached to the tooth surface. Calculus forms above and below the gum line and can only be removed with special dental instruments.\nCanal - The narrow chamber inside the tooth's root.\nCanines - Also called cuspids.\nCanker sore - One that occurs on the delicate tissues inside your mouth. A canker sore is usually light-colored at its base and can have a red exterior border.\nCaries - Another term for decay, which causes cavities.\nCold sore - Usually occurs on the outside of the mouth, usually on or near the nose or lips. A cold sore is contagious because it is caused by the herpes simplex virus, and it is usually painful and filled with fluid.\nComposite filling - Tooth colored restorations, also known as resin fillings.\nComposite resin - A tooth colored resin combined with silica or porcelain and used as a restoration material.\nContouring - The process of reshaping teeth.\nCrown - An artificial cover that is placed on the top of a tooth following restoration.\nCusps - The pointed parts on top of the back teeth's chewing surface.\nCuspids - Front teeth that typically have a protruding edge.\nDentin - The tooth layer underneath the enamel.\nDenture - A removable set of teeth.\nEndodontics - A form of dentistry that addresses problems affecting the tooth's root or nerve.\nFluoride - A naturally occurring substance added to water, toothpastes and some rinses and used for strengthening the tooth's enamel.\nFluorosis - A harmless over-exposure to fluoride and resulting sometimes in tooth discoloration.\nGingiva - Another word for gum tissue.\nGingivitis - A minor disease of the gums caused by plaque.\nGum disease - An infection of the gum tissues. Also called periodontal disease.\nImpacted teeth - A condition in which a tooth fails to erupt or only partially erupts.\nImplant - A permanent appliance used to replace a missing tooth.\nIncisor - Front teeth with cutting edges; located in the center or on the sides near the front.\nInlay - An indirect artificial filling made of various materials, including porcelain, resin, or gold. fitted to a cavity in a tooth and cemented into place.\nIntracoronal - situated or made within the crown of a tooth\nLaminate veneer - A shell that is bonded to the enamel of a front tooth. The shell is usually thin and made from porcelain resin.\nMalocclusion - Bad bite relationship\nMandible - The lower jaw\nMaxilla - The upper jaw\nMolar - Usually the largest teeth, near the rear of the mouth. Molars have large chewing surfaces\nNightguard - Night mouth guards are bite pads that are worn at night as you sleep. There are also used as mouth guards for day use. These guards are made of high-grade plastic and are custom fit to the mouth. This device keeps the upper teeth from grinding with the lower teeth, offering an instant solution to teeth clenching problems.\nNeuromuscular Dentistry - Are more than the aches and pains felt in and around the neck and head that are associated with your teeth and jaw.\nOnlay - An indirect artificial filling made of various materials, including porcelain, resin, or gold; fitted to a cavity in a tooth and cemented into place. It is designed to protect the chewing surface of a tooth by extending to replace a cusp.\nOrthodontics - A field of dentistry that deals with tooth and jaw alignment.\nOverdenture - A non-fixed dental appliance applied to a small number of natural teeth or implants.\nPalate - Roof of the mouth.\nPartial denture - A removable appliance that replaces teeth. Also called a bridge.\nPedodontics - A field of dentistry that deals with children's teeth.\nPerio pocket - An opening formed by receding gums.\nPeriodontal disease - Infection of the gum tissues. Also called gum disease.\nPeriodontist - A dentist who treats diseases of the gums.\nPermanent teeth - The teeth that erupt after primary teeth. Also called adult teeth.\nPlaque -Plaque is a sticky, colorless, almost invisible film or substance that forms on the teeth after sleep or periods between brushing. It is a growing colony of living bacteria, food debris, and saliva.\nPosterior teeth - The bicuspids and molars. Also called the back teeth.\nPrimary teeth - A person's first set of teeth. Also called baby teeth or temporary teeth.\nProphylaxis - The act of cleaning the teeth.\nProsthodontics - The field of dentistry that deals with artificial dental appliances.\nPulp - The inner tissues of the tooth containing blood, nerves and connective tissue.\nRadiographs - Diagnostic X-rays essential for detection of decay, tumors, cysts, and bone loss. X-rays also help determine tooth and root positions.\nReceding gum - A condition in which the gums separate from the tooth, allowing bacteria and other substances to attack the tooth's enamel and surrounding bone.\nResin filling - An artificial filling used to restore teeth. Also called a composite filling.\nRoot canal - A procedure in which a tooth's nerve is removed and an inner canal cleansed and later filled.\nRoot planing - Scraping or cleansing of teeth to remove heavy buildup of tartar below the gum line.\nSealant - A synthetic material placed on the tooth's surface that protects the enamel and chewing surfaces.\nTartar - A hardened substance (also called calculus) that sticks to the tooth's surface.\nTooth decay – Tooth decay occurs when the acids found in plaque erode the natural enamel found on the teeth. This phenomenon can easily be prevented by using proper home hygiene methods. Tooth decay is one of the leading causes of tooth loss, and its treatment often requires complex dental procedures.Teeth polishing: Removal of stain and plaque that is not otherwise removed during tooth brushing and scaling.\nTMD - Temporomandibular joint disorder. Health problems related to the jaw joint just in front of the ear.\nVeneer - A laminate applied or bonded to the tooth.\nWhitening - A process that employs special bleaching agents for restoring the color of teeth.\nWisdom tooth - Third set of molars that erupt last in adolescence.\nTooth decay is often called the second most prevalent human disease, after the common cold. Without effective treatment (as was the case through most of history) it can lead to pain, tooth loss, and sometimes worse illnesses. Even today, it's estimated to affect over a quarter of U.S children from ages two to five, and half of those aged 12-15. But it doesn't necessarily have to! You can take steps to prevent tooth decay from harming your teeth — or those of your loved ones.\nThere's one important fact you should understand up front: No single “magic bullet” can stop tooth decay in every case. Instead, fighting decay should be viewed as a process of preventive maintenance, like taking care of your car — except that (unlike a car) your natural teeth, with proper care, can last a whole lifetime. The basic aspects of this process are practicing good oral hygiene at home, and coming in to the dental office for regular cleanings and checkups.\nIf you've been in the dental office for routine visits, you're probably already familiar with the special tools dentists use to remove buildups of plaque (a bacterial biofilm) and tartar (a hardened deposit, also called calculus) from your teeth. Hand-held instruments, ultrasonic scalers, or both may be used to give your teeth a thorough cleaning. Afterwards, your teeth are thoroughly checked for decay, and cavities are treated when necessary.\nYet there's still more that can be done to prevent tooth decay. Could your diet be a contributing factor? Is your brushing technique adequate? Could you benefit from additional preventive treatments? Today, with our increased understanding of what causes tooth decay and how to treat it, it is possible to focus on what decay prevention tactics would work best in your particular case. In fact, it's now possible to assess each individual's risk factors for decay, and concentrate on doing what's most effective for you.\nHow Does Decay Start?\nIt's useful to think of the mouth as a dynamically balanced ecosystem, in which living organisms, including helpful and harmful bacteria, are constantly interacting. When conditions are right — namely, in the presence of certain sugars — some pathogenic (harmful) bacteria produce acids that cause teeth to lose minerals and begin breaking down. Even a diet having excessive acidic foods can influence deminerialization of your teeth. But in more favorable conditions, the damage these pathogens do is undone by the body's own healing mechanisms — which includes your healthy saliva.\nA major goal in decay prevention is to tip the balance in favor of the beneficial processes. Keeping up a regular habit of brushing and flossing, getting adequate fluoride, and a diet with limited acidic foods is certainly helpful. Yet even with these measures, some individuals will be more prone to tooth decay than others, and may need extra help and guidance.\nAdditional Steps to Prevent Tooth Decay\nIf you're one of these individuals, it may help you to learn effective brushing techniques and practice other measures at home — for example, using special toothpastes or mouthrinses. When necessary, in-office treatments such as topical fluoride applications are available. If you aren't getting enough fluoride through drinking water or other sources, this treatment can help prevent tooth decay. Anti-bacterial treatments may also be beneficial in some cases, as is nutritional counseling.\nFinally, if your child's teeth are susceptible to tooth decay, consider having a dental sealant applied. This is a practically invisible layer of plastic resin that is placed on the top (chewing) surfaces of the back teeth. It's a painless procedure that fills in the natural pits and folds of the tooth, making them much more resistant to bacterial damage.\nSo, don't think that tooth decay is inevitable — instead, find out what you can do to help prevent this disease from affecting you or your loved ones.\nTooth Decay — A Preventable Disease Tooth decay is the number one reason children and adults lose teeth during their lifetime. Yet many people don't realize that it is a preventable infection. This article explores the causes of tooth decay, its prevention, and the relationship to bacteria, sugars, and acids... Read Article\nTooth Decay – How To Assess Your Risk Don't wait for cavities to occur and then have them fixed — stop them before they start. Modern dentistry is moving towards an approach to managing tooth decay that is evidence-based — on years of accumulated, systematic, and valid scientific research. This article discusses what you need to know to assess your risk and change the conditions that lead to decay... Read Article\nDentistry and Oral Health for Children Dear Doctor magazine brings you this wide-ranging overview of milestones and transitions in your child's dental development. Learn how to protect your children from tooth decay, dental injuries, and unhealthy habits while getting them started on the road to a lifetime of oral health and general well-being... Read Article"", 'Tooth decay, if left untreated can have a serious impact on a child’s health and well-being. It can cause pain and infections which can affect a child’s ability to eat, speak, play, and learn (CDC).\nRoutine dental visits and recommended dental care is important for children, however taking a child to their routine dental visit can be a challenge for some parents and caregivers. Here are a few barriers:\n- A child’s and parent’s anxiety of seeing the dentist.\n- A parent’s work schedule.\n- Finding a local dentist parents and caregivers can trust with their child’s dental care.\n- Lack of transportation.\n- Cost of dental services.\nSome parents may even delay taking their child to the dentist at an early age thinking baby teeth will fall out eventually. They may not be aware of how important it is to keep baby teeth in good health, as they are a guide for adult teeth.\nEstablishing a dental home early can help prevent tooth decay in children by receiving preventive and routine dental care. Parents and caregivers can also receive proper dental care guidance for their children’s age. Moreover, it helps build a positive relationship between families and dental staff.\nWhat is a dental home?\nAccording to the American Dental Association (ADA), a dental home is inclusive of all aspects of oral health care delivered in a complete, accessible, coordinated, and family-centered way:\n- Complete – Preventive and full dental care services in one place.\n- Accessible – Dental care services provided in the child’s community. The dental home is close to home and easy to get to.\n- Coordinated – Families are provided with referrals to dental specialists when needed and linked to community services.\n- Family-centered – Families and dental staff work together in the best interest of the child and family. The dental home meets the child’s and family’s oral health needs.\nWhy is a dental home beneficial for my family?\nEstablishing a dental home can build a trusting relationship between the dental team, child, family, and/or caregiver. It can lessen anxiety when seeing the dentist. A child who is taken to their dental visits from an early age is more likely to feel comfortable being seen by the dentist than a child that begins their routine visits at a later age.\nHaving a dental home helps families save money. Dental treatment can be costly. Tooth decay in infants, young children, and school-age children is preventable. Preventive dental visits at an early age can teach children the importance of oral health which can carry on as they grow into teens and adults.\nIf your child has special needs, it is important to find a dental home that will provide specialized dental care and guidance to help your child as they grow.\nWhen is the best time to establish a dental home?\nThe ADA recommends establishing a dental home for children no later than 12 months of age. Waiting for a child to be older may be too late, resulting in dental treatment during the first visit. Some families have begun to discuss a dental home with their dental provider during their pregnancy and post-partum dental visits.\nHow to choose a dental home?\nChoosing a dental home that you can trust a dental team with your child’s oral health is an important decision. A dental office that can provide you with a safe and comfortable place for regular visits, dental procedures, or a dental emergency is a great place to start. Here are a few basics to consider when selecting a dental home from the ADA.\n- Find a dental home you and your child are happy with. Choose a dental home that provides caring and friendly service. Select a home where the dental team can explain ways to help you prevent dental health problems and provide dental care instruction in a courteous, helpful manner. You can inquire if translation or interpreter services are offered, if needed.\n- Choose a dental home with convenient office ours. Some dental offices offer extended hours and weekend appointments to help families meet their dental care needs.\n- Choose a dental home that accepts your dental plan. If you have dental benefits, make sure the dentist is in your network. If you do not have dental benefits or have trouble affording dental services, visit a community dental/health center. These centers provide quality dental care for persons who have Medi-Cal, other insurance, are uninsured, or cannot afford care. Click here for a list of community health centers in Orange County. Click here to find a Medi-Cal Dental Provider near you.\n- Check with a trusted friend or relative. Many people trust a referral to a dental home from a friend or family member that has experienced a positive dental visit. If a friend says she loves her dental home, check them out!']"	['<urn:uuid:125ceba8-8ab0-4046-b891-6f9ecb7b7bf6>', '<urn:uuid:219cadab-6b95-4d6f-8f69-0876e4165151>']	factoid	direct	long-search-query	similar-to-document	multi-aspect	expert	2025-05-01T23:46:40.222380	8	85	2894
443	What is John Kutsch's background in developing different versions of the Integral Molten Salt Reactor?	John Kutsch led the Technical Design of all variations of the Integral Molten Salt Reactor (IMSR), including versions at 25, 250, 600, 80, 400 and all variations of each. He has 23 years of experience developing materials, mechanisms, and products for industrial, energy, and medical clients.	"[""Coupling Integral Molten Salt Reactor Technology with Hybrid Nuclear/Renewable Energy Systems\nJanuary 26, 2018\nME Lecture hall\nMr. John Kutsch\nV.P. Conceptual Development, Thorium Energy Alliance /Terrestrial Energy USA,\nLoyola University of Chicago\nThe Integral Molten Salt Reactor (IMSR) represents a clean energy alternative to fossil fuel combustion for industrial heat and provision, which is compact, efficient, and cost-competitive with fossil fuels. The IMSR is a Gen 4 reactor and a successor of the very effective Molten Salt Reactor Experiment work of Oak Ridge National Lab.\nTerrestrial Energy USA is now working with Idaho National Laboratory to couple the IMSR to advanced industrial systems. Several systems have been designed and proposed. These can serve energy-intensive industries with stable heat and power for clean H2, O2 production, and by extension ammonia and methanol production. Desalination is also a very significant market sector for the IMSR heat and power.\nIMSR has the potential to be a truly transformative energy technology, and when coupled to advanced industrial systems, IMSR enables new, truly transformative clean industries. The IMSR demonstrates that power generation systems designed explicitly for electricity generation are no longer a necessary constraint. Nuclear energy can provide new opportunities for variable renewable energy systems by allowing them to contribute to a common reservoir of thermal battery storage without stressing the grid system. The IMSR enables the idealized deep decarbonization desperately sought after by climate-conscious industrialists, such as Google.org.\nIn the Google.org experiment, the conclusion was finally drawn that carbon-free electricity was an exceedingly small fraction, compared to the behemoth fossil fuel power for transportation and industrial processes. The IMSR provides a new deployable system for low-cost carbon-free process heat energy, which can be used to produce a broad array of energy services, including electric power; hydrogen as an input for industrial chemicals production; steel, cement, and other primary materials; or synthetic fuels for the transportation sector. All of this can be achieved cost-competitively with fossil fuels, and at the lowest life cycle emissions rating of any power source.\nMr. John Kutsch is the Executive Director for the Thorium Energy Alliance. He has spent 23 years developing materials, mechanisms, and products for industrial, energy, and medical clients. He is noted for leading the Technical Design of all the variations on the Integral Molten Salt Reactor (IMSR), from 25, 250, 600, 80, 400 and all variations of each. He is also a Design Engineer who runs Whole World LLC, an engineering consultancy in Harvard, Illinois. Whole World specializes in energy engineering and utility integration with successful projects in Run-of-river hydroelectricity, Dye-activated solar cell development, organic Light Emitting Diode research, Waste-to-energy system design, Landfill Gas Collection and Energy Generation, Optimizing Ethanol Production, Up-Rating of existing small scale generation facilities, and with many project services for mechanical and production engineering provided to the National Renewable Energy Lab.\nHe provides his clients with world class innovation and engineering project management. He is an expert in CAD and Project Life Cycle Management. Other areas of expertise are in Fabrication, Materials Selection, Prototype Production, Casting, Forming, Rapid prototyping and computer visualization of a CAD models, stress analysis, Quality Function Deployment and performance modeling to ensure client receives the design they envisioned. He never forgets that someone's life, livelihood and investment depends on every project.\nMr. Kutsch became a founding member of the Thorium Energy Alliance, a 501(c)3 organization, in 2006 after spending several years researching thorium applications and reactors for an industrial client. Within four years of the Thorium Energy Alliance founding, eight conferences with international participation have been organized. He has recently given commentary in support of uranium 233 preservation, Rare Earth Refining and Thorium Energy Research to the Blue Ribbon Commission on the Future of Nuclear Energy. He has also made scores of trips to Federal and State Legislatures promoting changes in federal policy regarding uses and storage of thorium and rare earth elements.\nMr. Kutsch earned his BA from Southern Illinois University, his MBA from Loyola University Chicago, and completed the Baxter Executive Program, Parametric Technologies Certified Expert.\nDr. Daniel A. Nussbaum\nNaval Postgraduate School\nPrincipal, Energy Academic Group\nMonterey CA 93943""]"	['<urn:uuid:2a91791c-0616-4a83-9d70-388686a3aee0>']	factoid	direct	verbose-and-natural	distant-from-document	single-doc	expert	2025-05-01T23:46:40.222380	15	46	685
444	chemical enzyme requirements digestion process linked unlinked sugar molecules	The digestion of sucrose requires a specialized enzyme called sucrase. This enzyme must break the bond linking glucose and fructose in sugar before these molecules can enter the bloodstream for metabolism. However, sucrase is not required when glucose or fructose is molecularly free (not bonded).	['Sugar – Understanding the Difference a Bond Makes\nThe Food and Drug Administration (FDA) defines sugar as sucrose obtained from sugar cane or sugar beets. The FDA further specifies that the glucose and the fructose in sucrose are molecularly bonded (linked together).\nThe digestion of sucrose requires the action of a specialized enzyme – sucrase. The bond linking the glucose and fructose in sugar must first be broken by sucrase before the freed fructose and freed glucose can enter the human bloodstream for subsequent metabolism. Sucrase is not required when glucose or fructose is molecularly free (not bonded).\nHow sucrase influences metabolism is an intensely debated scientific topic. It is unknown if sucrase modifies how the glucose and fructose in sucrose enter the bloodstream. It is also unknown if the molecular bond in sugar causes variations in the metabolism of glucose and fructose.\nResults of a recent study provide insight into understanding the biological influence of the molecular bond in sugar. Equivalent amounts of sucrose and a 50/50 mixture of glucose and fructose were fed to rats for 16 weeks. Sugar and a 50/50 mixture of glucose and fructose are each half glucose and half fructose. The only difference is the presence of the molecular bond – glucose and fructose are linked in sugar but are unlinked in the 50/50 mixture.\nSucrose and the 50/50 mixture represented 60 percent of the calories throughout the study. Feeding an excessive amount of a nutrient – sucrose or the 50/50 mixture in this case – is a common design used in animal studies to shorten the time where the expected metabolic results can be observed. This design strategy also permits earlier detection of metabolic differences when nutrients – sucrose and the 50/50 mixture in this case – are compared. Another justification for conducting initial feeding experiments with animals is the ability to know exactly what and how much each animal eats.\nThe international team of scientists compared the effects of sucrose and a 50/50 mixture of free glucose and free fructose on the production of uric acid, triglycerides and fat buildup in the liver. Uric acid was measured because it is a well-recognized indicator of hypertension and its associated maladies. Differences in triglyceride levels were determined since elevated triglycerides is a recognized predictor of increased risk of heart disease. Increased fat buildup in the liver is the leading cause of non-alcoholic liver disease.\nThe 50/50 mixture of free glucose and free fructose generated meaningfully greater levels of liver uric acid, triglycerides and fat accumulation. For example, liver triglycerides were 1.5-times higher with the 50/50 mixture midway (eight weeks) through the study than they were with sucrose. By the end (sixteen weeks) of the study, liver triglycerides were 170 percent higher with the 50/50 mixture of free glucose and free fructose.\nSignificance – This study is the first to provide evidence that the molecular bond between glucose and fructose makes sugar biologically distinct from a mixture containing the same relative amounts of unbonded glucose and unbonded fructose. These findings suggest the presence (sugar) or absence (50/50 mixture) of a molecular bond between glucose and fructose determines metabolic outcome. Molecularly bonded glucose and fructose differ from molecularly free glucose and fructose, even when the relative amounts of glucose and fructose are the same.\nCitation: “Comparison of free fructose and glucose to sucrose in the ability to cause fatty liver.” LG Sanchez-Lozada, W Mu, C Roncal, YY Sautin, et al. European Journal of Nutrition, January 2010Print']	['<urn:uuid:7a18c78e-172f-47c3-8f1c-3dfef372d3e7>']	factoid	direct	long-search-query	distant-from-document	single-doc	expert	2025-05-01T23:46:40.222380	9	45	580
445	How does the approach to risk management differ between Afghan and American forces, and what lessons about supply chain vulnerabilities can be learned from their contrasting methods?	Afghan forces demonstrate greater risk tolerance, willingly putting troops in danger when missions require it and using field expedient methods, while American forces tend to overcorrect and make mission success secondary to following established rules. This connects to supply chain management lessons, where poor risk management often results from resource scarcity and ineffective processes - just as Afghan forces innovate with limited resources, organizations need to balance security with operational efficiency. According to recent reports, nearly two-thirds of companies report supply chain breaches, with risks occurring at all stages from design through disposal.	['Among advisors to Afghan units, one phrase often heard is “Afghan good enough,” usually as a disparaging comment. It means, ”They’ll never be as good as Americans, but they’re good enough to get by in this country.” It is true that the ANSF will never be able to project land-, sea-, and airpower anywhere in the world. But, in the world the Afghans live in, they bring assets to the table that most American forces do not. People wishing to sound insightful about Afghanistan’s history often remark on how its fighters have made it the “graveyard of empires.” Forgotten is the fact that many of those fighters are on our side, and that there is much they can teach us. While there are wide disparities in the quality and motivation of ANSF, the best are able to achieve more with fewer resources than any Western military could. Applying that same level of resourcefulness and agility to a Western military that already has high quality equipment and training would create a remarkable force.\nIn 1988, Robert Fulghum wrote a book called “Everything I Really Need to Know I Learned in Kindergarten.” The simple, homespun wisdom borne of the basics we teach children was a publishing sensation at the time. Its advice, such as “Play fair” and “Don’t hit people,” is as true at age 55 as it is at 5. Of course, there are some things one needs to know that are not taught in kindergarten—driving and sex education come to mind. The book’s point is that much of what we really need to know to be successful is really just the basics that we learn early on. Just as adults forget the simple lessons of childhood in favor of the complexities of adulthood, often to their detriment, so do militaries. In our sole-superpower, globe-spanning dominance, we have lost much of our former speed, flexibility, and mental agility. Just as adults can learn from children, so Americans can learn from Afghans. Some of what makes Afghans effective are traits that Americans lost in the course of industrializing warfare.\nAn Afghan commander once told my advisor team a story about two frogs. He said that Afghans are like a frog at the bottom of a well. That frog there does not know that there is anything in the world beyond the space from one side of the well to the other. Then another frog falls into the well and tells the incredulous first frog about how big the world really is. That second frog is an American. The Afghan CO meant the story as a compliment to Americans and our broad-ranging experiences. While that CO did not mention it, there is a caveat to the story in regards to the American frog. That frog brings a lot of knowledge to the table, but he does not know the inside of the well like the first frog, and if they are both going to succeed inside the well, they need to learn from each other. The Afghan already knows he has much to learn from the American. Americans are often too intellectually arrogant to admit they have several things that they can learn from Afghans.\n1. There is such a thing as too much planning. Sometimes things really are as simple as they look. Afghans with no formal education and only the most basic military training can execute vehicle checkpoints, airborne interdictions, HVI snatches, and most of the basics of counterinsurgency without a single PowerPoint slide. If Afghans can successfully do these missions on a moment’s notice, why can’t Americans? Americans frequently get sucked down rabbit holes planning to counter every contingency and mitigate every risk. While we pride ourselves on detailed planning, COA development, wargaming, and so on, sometimes we forget that sometimes a simple mission is just that. While there are missions that require lengthy and detailed planning, many do not. Americans often plan operations for so long that the situation that necessitated an operation in the first place has long since passed by the time we are ready to act. In our zeal to answer every question we often paralyze ourselves with inaction.\n2. Risk is part of war. Afghans are consistently willing to put themselves and their troops in danger when the mission requires it. Among other things, they are encouraged to use field expedient methods in order to complete the mission in a timely fashion. While clearly some specific Afghan techniques are unsound, Americans have overcorrected, eliminating risk to the point which the mission becomes secondary to adherence to rules established at higher echelons. In many AORs, “Rules of the Road” and other guidance has been established to the point which small-unit leaders are not allowed to make judgment calls about the composition and conduct of patrols. Lives and equipment are valuable, and should not be spent lightly. However, at least at this point of the war in Afghanistan, it often seems as if our actions are guided by John Kerry’s words of 1971,”How do you ask a man to be the last man to die for a mistake?” It may be someone else’s country, and we may be leaving it soon, but as long as we are in a fight, we need to act with a sense of commitment to fighting, not just to avoiding losses. Running out the clock may work in athletic contests, but is not the way to victory in war.\n3.Speed and mobility can be force protection. Afghan troops wear little body armor, and most of their vehicles are unarmored. While body armor and armored vehicles may be necessary in high-kinetic environments, much of the time they cripple the mobility and agility of the forces using them. On partnered operations, Afghans greatly outpace ISAF troops, both on foot and mounted. Their vehicles can go where ISAF’s cannot and can travel at much greater speed. American MRAP vehicles do only one thing well—survive explosive blasts. In every other regard, they are deficient. They are lumbering, difficult to enter or exit, and the armored cocoon saps the situational awareness of the entire crew. They are largely roadbound—even the MATV, designed for all-terrain use, loses most of its off-road capability when encumbered with a mineroller. In most environments, IEDs are best countered by simply staying off roads and trails, which American vehicles are unable to do. If engaged, the ability to displace rapidly can be more valuable than additional armored protection. The same holds true for PPE. Regardless of the mission, conventional American troops are required to wear a minimum of 40 pounds of gear, even before accounting for sustainment. This makes them unable to move at any pace faster than a quick shuffle, rendering them immobile in terms of covering any significant distance or to maneuver against a threat. This immobility is often more dangerous than any lack of protection would be.\n4.Minimize logistical requirements. Afghans are well-known for having a poor logistics system. While this has continued to hamper ANSF’s development into a more capable force, it has also fostered innovation and required commanders to get by with less. As Americans, we have a tendency to bring everything but the kitchen sink with us, just in case we need it. This cripples our ability to act quickly by increasing equipment requirements, which increases planning time and further decreases tactical mobility. While Americans will never be able to live off the land as Afghans do, drinking from streams and resupplying from bazaars, emphasizing travelling light increases operational tempo. We often find ourselves in an escalating spiral of requirements. We bring extra vehicles in case the primary vehicles fail, which necessitates more recovery assets, which requires more fuel, which requires vehicles to carry the fuel, which requires more vehicles to escort the fuel vehicles, and so forth. The Afghan mindset is often closer to the expeditionary mindset we should be trying to achieve. Keeping things as simple as possible and reducing logistical footprints can reduce risk.\n5.Aggressiveness can make up for a lack of skill. In initial military training, Americans are hammered with truisms about such things as “speed, surprise, and violence of action.” Later in careers, the importance of these in warfare receives only lip service. When one has only his rifle and his comrades to rely on, the only thing that keeps one going towards the sound of battle is his determination to close with and destroy the enemy. Every day, Afghans push through dangers that would stop American units in their tracks. Americans will not drive across an Afghan street without minerollers and ECM equipment. American units stop even administrative movements when air support is unavailable. Afghan troops execute virtually all of their operations operating under what Americans would consider “no-go” criteria. While restraint and discretion certainly have their places in military operations, leaders should never emphasize them to the detriment of aggressiveness and a bias towards action.\n6.Sometimes the appearance of being outgunned is an advantage. Americans roll through the Afghan countryside armed to the teeth and armored like medieval knights, then wonder why the enemy never shows himself. Afghans have no choice but to go out, even when they do not have the advantage, and unsurprisingly, the enemy frequently shows up. One cannot fight the enemy one cannot find. Letting the enemy think he has a chance can be a useful tactic in counterinsurgency. Unlike Afghans, Americans have airpower to bring down destruction upon the enemy once he presents himself. The enemy will never show if he believes himself to be outgunned from the start.\n7.Don’t be afraid to leave a subordinate in charge. While it is true that the Afghans lack a professional NCO corps, and this continues to be a huge weakness, in certain other regards they are more decentralized than some American units. Many leaders in the American military are afraid to allow subordinates to make decisions in their absence. Often, they insist on receiving updates on even routine matters while they are gone. On the other hand, Afghan unit leaders are often gone for days or even weeks at a time, leaving subordinates completely on their own. This is in a land where communication technology is lacking, so subordinates are truly working without nets. While this situation is partially due other systemic problems, the result is frequently the development of trusted subordinates who have the ability to run a unit on their own. Few Americans are willing to delegate more than symbolic authority to subordinates, for fear that those subordinates will make mistakes. In reality, while they may make some errors, the errors are rarely catastrophic, and the subordinates learn in the process. Subordinates usually rise to the challenge and become better leaders themselves.\n8.Uneducated does not mean stupid. Americans value education greatly, and it is indeed very important, especially in a technologically advanced force. We tend to look down on those who do not have formal knowledge. The average Afghan spends his entire life living in conditions that most Americans would consider military-caliber survival training. He continuously has to improvise solutions to problems. Once one realizes the value of this type of learning, it prompts two revelations. One, never underestimate the capability of a man who has grown up in such an environment. There is a reason that some Afghans, having never taken a chemistry class, can turn ingredients found in a typical hardware store into bombs capable of throwing 30,000lb vehicles into the air. Two, it shows us that just because a procedure is nowhere in any manual does not make it invalid—Afghans devise effective solutions that are not found in manuals because they can’t read the manuals. Americans need to know when to use the manual, and when they need to pretend it doesn’t exist.\n9.No better friend. No worse enemy. Reward those who cooperate with you. In counterinsurgency, one’s friends have to know that there are advantages to cooperation. It is often better to live with a little evil if that allows one to defeat the bigger evil. As long as one knows what the ultimate goal is, he can ignore smaller infractions as long as progress continues towards the larger goal. In Afghanistan, one can see this in the government-led eradication programs. While some areas are indeed so corrupt that major traffickers own the entire area, in other areas selective enforcement can be a viable tool. If the government can’t eradicate all the poppy harvest, then at least the farmers who don’t harbor the enemy should be left alone. If someone is not cooperating, make his life hard. In the parts of Afghanistan where law enforcement is more effective, that means known bad actors get searched, get treated roughly, their poppies get destroyed, and their equipment gets confiscated. If enough fence-sitters see the upside of cooperation and the downside of opposing the government, an area can begin to turn.\n10.Always make time for tea. In the end, armed forces are bands of brothers who put their lives in one another’s hands. Afghans always greet every individual warmly and will take the time to sit down and discuss any issue, whether business or social. Personal interaction is what makes everything happen. Personal relationships are often an afterthought in American forces, especially in garrison. Training is done via computer. People e-mail instead of calling or walking down a hall. Whether it is over a cup of Afghan sheen chai, or over an American Budweiser, troops need to have the time and opportunity to form those bonds that let them trust one another when the chips are down. Beyond that, Americans neglect the value of face-to-face interaction. Giving an informal class can be more effective than death-by-PowerPoint. Stopping by someone’s office is usually more effective than sending an e-mail.\nAs individual military leaders progress through their careers, they pick and choose attributes from other leaders that they try to emulate. The same should apply for militaries. While there are certainly many qualities of ANSF not worth copying, there are certain things at which they excel, and Americans need to have the institutional humility to learn from them. The US military will not keep its premier status unless it has the moral courage to examine itself critically, to identify better ways of doing things, and to take risks in implementing those changes.', 'Maintaining a secure supply chain can be a challenge. Within a supply chain, numerous people, companies, third-party suppliers, and nations are likely involved, which can lead to serious security issues in logistics.\nMany companies depend on their own resources as well as industry standards to fight security issues. Depending on the industry, companies can be subject to security issues in logistics such as cyberattacks, theft, fraud, terrorism, sabotage, and more. A 2018 Ponemon Institute report found that 56% of companies suffered a breach caused by one of their third-party vendors. Although breaches in a supply chain are common, many companies remain unprepared.\nWhy is supply chain security important?\nAttacks to the supply chain are twofold. The first is usually meant to disrupt or cripple actual supply chains logistics. The second is to use supply chains as a channel to attack potentially thousands of connected partners and suppliers. By finding and exploiting weak links within the supply chain, attackers can jump between linked systems, stealing data and sabotaging businesses.\nTech, defense, financial services, and energy are favorable targets for hackers, but no industry is immune. In fact, there are now what experts call “island hoppers” who aren’t just attacking one organization, but instead multiple.\nA security issue within the supply chain should be a high priority for companies considering any incident or breach could greatly damage or disrupt operations; vulnerabilities could lead to unintended costs, inefficient delivery schedules, and a loss of intellectual property.\nThreats to supply chain security are on the rise across all industries, with nearly two-thirds of companies reporting a breach—spiking 78% last year-over-year. The top threat: cyberattacks. In fact, a recent report found that 56% of respondents have experienced a cybersecurity breach from a third-party supplier. But risks can occur at all stages—design, development and production, distribution, acquisition and deployment, maintenance, and disposal.\nOnce an attack occurs and disrupts the supply chain, a company’s reputation can be damaged. From that point on, it can sow doubt into consumers’ minds about reliability, productivity, and their security, including financial and personal information.\nHow can companies protect themselves from security issues in logistics?\nCompanies must be proactive in developing defense protocols and standards for supply chains. To ensure your company supply chain is secure, the proper management and safety regulations need to be put in place. For the majority of organizations, poor risk management is often a result of resource scarcity and ineffective processes.\nAs most breaches are caused by third parties, third party risk assessments—along with an efficient vetting software for suppliers—can reduce the threat of security breaches in a supply chain. Organizations should identify and categorize suppliers who either have direct access to their internal network or access to critical enterprise data.\nSegregating third-party vendors according to their functional role can also help organizations better understand who these contributors are, the type of information they have access to, and how they are connected to the company framework.\nAdditionally, companies need to define specific data ownership requirements for every vendor. All the stakeholders across the value chain need to be clear as to who maintains the ownership of data being shared and the acceptable use of that data—doing so can greatly improve security issues in logistics.']	['<urn:uuid:e4593038-40f5-4fe7-987f-a2a75105792a>', '<urn:uuid:17e41b2a-b79c-4a5e-a244-7b4e4d21da41>']	factoid	direct	verbose-and-natural	distant-from-document	multi-aspect	expert	2025-05-01T23:46:40.222380	27	93	2923
447	which body parts does osteoarthritis affect most	Osteoarthritis most commonly occurs in the knees, hips, hands, and spine	['About Osteoarthritis Treatment Abroad\nAbout Osteoarthritis Treatment\nOsteoarthritis treatment aims to alleviate symptoms of osteoarthritis, a condition that causes pain, swelling, and stiffness in joints in the body. The condition is caused by a breakdown of cartilage, which is a buffer between the joints and the bone and protects the joints. Cartilage wears down overtime and the body is usually able to repair the damage and continue protecting the joints, however, when it does not repair the cartilage, friction between the bone and joint occurs. The joint may deteriorate, causing pain and stiffness.\nOsteoarthritis is not a curable condition, however treatment can help to relieve and manage symptoms. Many patients with the condition may experience limited motion with the affected joints, due to the stiffness caused by the breakdown of the cartilage. While the condition can affect any joint in the body, it most commonly occurs in the knees, hips, hands, and spine. It is a degenerative condition, meaning it will worsen as time goes on, which is why it is important to seek treatment once symptoms start to show, in order to try and slow down the process and relieve symptoms.\nThe condition is more likely to occur in older age, with most patients experiencing symptoms from the age of 45 or older, and it is more likely to affect women more than men. There are a number of factors which can increase the chances of osteoarthritis occurring and these include family history, obesity, and if the patient already has arthritis.\nTreatment options include medication for managing pain and inflammation, lifestyle changes, physical therapy, and in some cases surgery may be an option. Surgical treatments include joint replacement and osteotomy.\nOsteoarthritis mainly affects the hands, hips, and knees.\nOsteoarthritis mainly affects the hands, hips, and knees.\nHow to find quality treatment abroad\n200000Patients who used MEDIGO\n1200Clinics across 35 countries\n195Countries represented by MEDIGO patients\n20Languages spoken at MEDIGO\nBefore Osteoarthritis Treatment abroad\nPatient will have a consultation with a rheumatologist or an orthopedic specialist, to discuss the treatment plan for managing their condition. Patients should raise any questions or concerns that they may have and explain to the doctor the symptoms they have and for how long they have been experiencing pain, stiffness or swelling.\nThe doctor will take a full medical history of the patient and may run some tests such as blood tests, order an X-ray or MRI (magnetic resonance imaging) in order to help with making a treatment plan, if such tests have not already been performed.\nIf undergoing surgery, the patient will usually be advised to refrain from eating and drinking in the hours preceding surgery, in order to prepare for the general anesthetic.\nPatients with complex conditions may benefit from seeking a second opinion before beginning a treatment plan. A second opinion means that another doctor, usually an expert with a lot of experience, will review the patient’s medical history, symptoms, scans, test results, and other important information, in order to provide a diagnosis and treatment plan. When asked, 45% of US residents who received a second opinion said that they had a different diagnosis, prognosis, or treatment plan. Click here to learn more about how to get a second opinion.\nHow is it performed\nOsteoarthritis can be managed with medication such as nonsteroidal anti-inflammatory drugs (NSAIDs) to help treat the inflammation and pain in the joints. Some NSAIDs that are used are often non-prescription medication such as ibuprofen which the doctor may recommend, while others may be prescription medication that may have side effects.\nPhysical therapy may be recommended to the patient, and this will need to be attended on a regular basis in order to experience consistent relief. The patient will perform certain exercises and movements, in order to improve the strength of their muscles and to help with regaining motion in their joints.\nSome patients may be given injections such as cortisone or lubrication injections to relieve pain in the joints. This involves injecting medication into the joint using a needle.\nDepending on the area of the affected joint and severity of the condition, surgery may be an option to help treat osteoarthritis. Patients who have osteoarthritis in their knees or hips, may be eligible to have knee or hip replacement surgery. This type of surgery involves making an incision in the knee or hip, removing the old and damaged joint, and replacing it with a new joint made of plastic or metal. Once the new joint is in pace, the incision site is then closed.\nFor patients who are relatively young, a knee replacement is not always an option as the replaced joint can wear down a lot quicker in patients under the age of 55, in comparison to older patients. For these patients, an osteotomy may be performed. This is a surgical procedure performed to remove or add part of a bone in the leg to alleviate pressure put on the knee. This is generally seen as a temporary solution as these patients will usually require knee replacement surgery in the years preceding this procedure.\nGeneral anesthetic (if undergoing surgery).\nThe Osteoarthritis Treatment takes 1 to 3 hours.\nThe procedure duration depends on the type of surgery being performed.\nWhat to expect after Osteoarthritis TreatmentPost procedure care\nShould the patient experience any side effects from taking any medication recommended to them or prescribed by the doctor, they should let the doctor know as the medication may need to be changed.\nImportant things to know about Osteoarthritis TreatmentPotential risks\n- Side effects from medication\nAn X-ray is a procedure which involves taking images of the internal components of the body, in particular the bones.\nA hip replacement is a surgical procedure to replace the surfaces of the hip joint with a prosthetic implant.\nA knee replacement is a surgical procedure in which damaged surfaces in the knee joint are replaced with metal and plastic components.']	['<urn:uuid:20e57fab-85d3-40cd-a5c3-19e94e62c01b>']	factoid	with-premise	short-search-query	similar-to-document	single-doc	novice	2025-05-01T23:46:40.222380	7	11	986
448	Can humans travel to Mars, and what makes the trip hard?	Humans could potentially travel to Mars within the next 20 years using ion propulsion technology. The trip is challenging because of the vast distances involved - Mars can be anywhere from 40 million to 140 million miles from Earth, with radio communications taking between 4.5 to 22 minutes to reach the planet.	"['Editor\'s note: This story contains spoilers on the new space epic ""The Martian."" [So consider yourself warned. If anyone is going to spoil ""The Martian"" for you, it might as well be the film\'s director, right?]\nIn ""The Martian,"" stranded astronaut Mark Watney must use his knowledge of science to survive for several years alone on the Red Planet, in a classic castaway scenario created by book author Andy Weir. The film of the same name is directed by Sir Ridley Scott, who began his screen career production-designing the BBC television series ""Doctor Who"" (1963) and directing the episodic police drama ""Z Cars"" (1965). Scott gained worldwide attention upon directing the movie ""Alien"" (1979), and solidified his sci-fi reputation with ""Blade Runner"" (1982). Scott has since directed 26 feature films and produced more than 100 movies, television series, documentaries and commercials, including the iconic ""Apple Mac 1984"" TV spot.\nSpace.com\'s Dave Brody spoke with Scott about the many filmmaking challenges of ""The Martian,"" which premiered Sept. 14 at the Toronto International Film Festival. [""The Martian"" and NASA: See Our Full Coverage]\nSpace.com: At the premiere of ""The Martian,"" you told us that the script — as written on the page — completely intimidated you. But, if I may, Sir, you\'re Ridley Scott! How can any film script scare you?\nSir Ridley Scott: Well, it\'s actually the science. I wasn\'t very good at it in school. I was disastrous at mathematics, algebra, trigonometry and geometry — anything academic, in fact. I wasn\'t stupid. I just couldn\'t retain anything. I just had a block. At Grangefield Secondary School, class of 1952, I was in position 31 out of a class of 31.\nI think it had something to do with the fact that I was a ""war baby"" and my dad became Army. So I was charging around schools. I did no less than 10 schools; most people do two. So I was totally ""gaga."" I was out to lunch by the time I\'d done my 10th school. I ""clock-watched"" for five years. I kept getting my head slapped. In those days, parents didn\'t pay attention like they do today. [Surviving ""The Martian"": How to Not Die on Mars (Infographic)]\nBut what helps me is — I\'m a bit like a caveman, you know — I draw everything.\nSpace.com: You predominantly think visually?\nScott: Yeah. I can really draw. I had seven years of art school. So I can literally do a very, very good storyboard. I will sit down and draw the thing out and make decisions. It\'s not stick men; it\'s really drawing — wide shots, medium shots, close shots, detail, and on and on.\nIt makes me understand something, or makes me prepare the scene. I\'m pre-filming it on boards. My boards are thick stacks on every film, especially on a film like this, where so much is done long after principal photography.\nSpace.com: So you were doing pre-visualization before animatics and other previsual techniques existed?\nScott: Oh yeah — for a long time, and every time! I do pre-visualizations all the time! I do it before I start principal photography. It\'s great because every morning, going in, there\'s a reappraisal of what I\'ve done for that day for those scenes. And then they\'re printed and redistributed to the first A.D. [first assistant director], lighting, cameraman, production designer — and they know what we\'re in for that day.\nSpace.com: Do you think of yourself as an orchestrator?\nScott: Yeah, yeah! Totally. You\'re completely accurate.\nSpace.com: How do you go about convincing a studio executive that you can put butts in theater seats by making a smart movie?\nScott: Well, I\'ve always gotten away with smart movies, really. Some of them have played well. Some haven\'t. And at the end of the day, I\'ve got to get off the thing of saying I\'m going to go for something I really love. Smart or not so smart, the thing has to entertain. I\'ve gotten my head slapped a few times when they didn\'t.\nSpace.com: Would you have made ""The Martian"" if Alfonso Cuarón hadn\'t been successful with ""Gravity""?\nScott: Oh yeah, sure! Yes, definitely. I thought ""Gravity"" was a great film. It was visually very engaging. Particularly with Sandra [Bullock], who was able to hold the screen by herself for all that kind of time. It was also a marvelous orchestration of visual effects.\nBut I think what we\'ve got [with ""The Martian""] may be an even bigger palette, bigger vista. You\'ve got all four quadrants, really, don\'t you? We\'ve got great drama. You\'ve got a lot of humor — which comes out of the drama, out of the reality of the situation. We\'ve got truthful machines and technologies. And I think we\'ve got pretty good visuals.\nSpace.com: Which of the machines and technologies in ""The Martian"" gave you the most concern?\nScott: Well, it was really only the computer code bit, because it\'s like math. That has always been a block to me. And, therefore, when I had to shoot the sequence about ASCII [American Standard Code for Information Interchange, a coding scheme], I went: ""Whaaat?! How am I going to show this?""\nI was much more into the physical aspects of what the character Rich Purnell, ""steel-eyed missile man,"" [played by Donald Glover in the film] was doing, which was saying, ""Don\'t slow down"" as you approach Earth. Instead, use it [orbital velocity] as a slingshot; use the gravity and shoot back out [to Mars] after you\'ve picked up the supplies. I got all that. [Watch this Rich Purnell scene from ""The Martian""]\nBut ASCII code, fundamentally, I couldn\'t get my head around easily. So we just blocked it out the way the book had it.\nSpace.com: Andy Weir\'s book is such an engineering manual of how you survive on Mars that I imagine suspending the audience\'s disbelief was not your problem, was it?\nSpace.com: But did you have the opposite challenge? Did you have to work against the ""geek factor"" to make this entertaining?\nScott: No! I LOVED the ""geek factor."" Andy is a very amusing man. His entire book is rooted in a tongue-in-cheek reality. The whole bloody thing is funny! The engine of it is humor. That\'s what I saw. And Drew Goddard, the screenwriter, kept that integral to the story.\nSpace.com: Plus, you have Matt Damon, who, while not known for being a comedic actor, has incredible comedic timing and wit.\nScott: Yeah, he\'s great! The funniest stuff came from keeping him in the moment. He knows how to play against the drama. And, you know, the best humor comes from straight. And the ""straight"" is reacting against the present conditions of the person, the difficulties they\'re actually dealing with. Finding out about all the obstacles — that\'s where the humor lies. [Video: Matt Damon on ""The Martian"" and Education]\nSpace.com: You have Matt Damon\'s character talking to the camera a lot and also a bit of ""Blade Runner""-style voiceovers.\nScott: Oh, the GoPro. You\'ve got to have the GoPro. To me, it\'s the ""black box."" It\'s his companion, his man Friday [the human companion of protagonist Robinson Crusoe in Daniel Dafoe\'s classic novel, published in 1719]. In a real human Mars mission, you\'d have a GoPro everywhere. If he died on the spot, you\'d want to know why, how and what blew.\nAnd the other thing is, we have him talking straight to the camera when he\'s doing his log.\nSpace.com: Mr. Damon told me that a lot of acting is actually reacting to the other actor. Did you go in with a game plan for directing him through these long stretches when there\'s no other person in the scene?\nScott: No, just basic blocking [the filmmaking technique of pre-arranging the locations of certain action and dialogue, usually by director and actor stepping through a scene]. You\'ve got to rely on your intuition and his. Just make a choice as you see it. As a director, any decision is better than no decision. Later on, alone in your trailer, you tremble in terror that you\'ve got it wrong. But Matt completely understood the character and nailed him perfectly. [Watch Space.com\'s exclusive interview with Matt Damon about ""The Martian.""]\nSpace.com: Years ago, I spoke with director Ron Howard just before his ""Apollo 13"" premiered, and he said it was a challenge to make a movie with no sex, no violence and no villains. You don\'t really have a human baddie in ""The Martian"" either, do you? Is the villain of this movie Mars itself?\nScott: Yes! Mars is the monster that can kill you in a heartbeat! It just doesn\'t care. It\'s a majestic monster, though. I wanted to make Mars out to be very, very beautiful, if only because we really don\'t know yet what it\'s like for people.\nSpace.com: Author Andy Weir says he left a lot of landscape description out of the book because it\'s boring for the reader. So he was especially excited to learn that you were directing; he loves your penchant for panorama and establishing a strong sense of place.\nScott: We shot exteriors at Wadi Rum [in Jordan]. To me, it\'s the Eighth Wonder of the World. It\'s incredible. It\'s only about 100 square miles [259 square kilometers]. And I didn\'t do anything but shoot it at the right time, from the right positions, then added a bit of red dust to everything. So our film world looks pretty accurate — at least I\'m hoping Mars looks a little like that.\nBut there must be massive rocks there. You\'ve got one dormant Mars volcano [Olympus Mons] that is 59,000 feet [18,000 meters] tall. That\'s 20,000 feet [6,000 m] higher than Everest! So I thought we\'d be OK going to Wadi Rum to film.You know, what we see of Mars from [NASA rovers\'] pictures sent back looks pretty boring: flat ground, reddish tundra, dust … That\'s because you\'re not going to land a piece of equipment in a rough mountain region. You couldn\'t bloody move! And you might have it go into a crevasse and — bang — a couple billion dollars is out the window. So you\'ve got to start, at least, on pretty boring ground, right?\nI cheated a bit on the skies. On Mars, they are not H2O skies; they are not condensation skies. They are dry particles. What you\'ve got a lot of on Mars is dust! You haven\'t got a lot of high winds, because there\'s very little atmosphere — so we cheated on a lot of that. But we needed to drive the story. [Watch this scene from ""The Martian""]\nOn Mars, there\'s dust on the move constantly, spiraling dust all the time. Twisters, I think they\'re called?\nSpace.com: Dust devils. They actually help sweep the dust off the solar panels on NASA\'s real Mars rovers.\nScott: Right! They\'re not truly dangerous. The atmosphere is too thin to carry much force. But besides not being able to breathe, the truly treacherous thing on Mars — I\'ve learned from the guys at NASA — is temperature: When you hit dark, you\'re at minus 90 degrees Fahrenheit [minus 68 degrees Celsius] at the surface. You go up top, you\'re at minus 150 F [minus 101 C]. Either way, you\'re dead. That, too, is because of the thin atmosphere. [The AstroCritic: What ""The Martian"" Gets Right About Astronauts]\nSpace.com: And the plot depends on that thin atmosphere, especially in getting Watney off of Mars, yes?\nScott: Yeah, where there\'s an argument within NASA near the film\'s end, where Watney will be asked to take the nose off the MAV [Mars Ascent Vehicle] to lighten it — because it weighs 400 lbs. [181 kilograms] or something, and they need to make every ounce of fuel count. So what are they going to do? He\'ll put a canvas over it. So they\'re going to fly him up to orbit in a convertible!\nSpace.com: It\'s a very cute scene. But could the pilot onboard the orbiting mother ship actually control Watney\'s MAV from the ground up?\nScott: NASA [the real NASA] said, ""Yes, if they leave the right components in the ship."" So Watney dismantles a lot of the ship, but leaves the communications in there so they can fly him up.\nWe tried to be authentic wherever we could. I kept in the docking just the way it\'s really done. We modeled the ports on the way ESA [the European Space Agency] delivers to the International Space Station.\nSpace.com: Mars is a risky place to be. Do you think humanity has become too risk-averse to actually send people there?\nScott: No, I don\'t think it\'s entirely down to the risk. It\'s also the cost. There are plenty of people who are lunatic enough to go up there. Why? I wouldn\'t go up there, particularly as we can probably reconstruct it.\nScott: Many say space travel will be ""the thing."" But incredibly detailed digital reconstruction is probably what\'s going to happen. We got probes with sensors.\nWe got one vehicle that\'s been on the move since 1977 [Voyager 1], and others that send back incredible pictures [Curiosity]. They\'re not film photographs. They\'re radio data, which NASA then takes, reconstructs and conforms into a digital picture. And the images are fantastic, but they\'re not artistic — it\'s real.\nSpace.com: But do you think we\'re going to send people back to the moon, to the asteroids, to Mars, maybe to the moons of Jupiter?\nScott: It\'s a hard thing. They\'ve got to do so much on their own. The moon is close, like three days\' travel; beyond that is tough. Mars — if you go by radio signals at the speed of light — at its closest position to Earth takes about four and half minutes. At the longest position — because Earth overtakes Mars orbiting around the sun — it takes about 22 minutes [for radio communications, travelling at the speed of light]. The distance ranges from about 40 million miles [64 million km] to over 140 million miles [225 million km]. And that\'s just a heartbeat — just a blink — in comparison to everywhere else!\nThat means you\'ve got to look very closely at whether we\'re going to be able to ""hypersleep,"" or essentially hibernate. And most of all, how the hell are we going to be able to approach light speed?!\nSpace.com: Speaking of light speed and beyond, earlier, you referenced that scene near the end of ""The Martian,"" where Watney is violently blasting off in the MAV. And you have his head shuttering and bouncing around inside his helmet. Was that a knowing homage to [filmmaker Stanley] Kubrick and [character] Dave Bowman [of ""2001 - A Space Odyssey""] going through that psychedelic space-time transition? Or was that just vintage Ridley Scott fast-shutter-speed, strobe-y ""staccato"" camera technique?\nScott: (Laughs) I wish I\'d thought about it that much! Actually, what happened is that the lights went wrong! But I liked it. In the physical vibration [put onto Damon], they started to lose the light. And I thought, ""Wow, that looks terrific!"" So I used the take where the shot went simply wrong.\nAnd the final touch was, I used all the nuts and bolts that must have come loose or been left during demolition. So now, they\'re in their own orbit, floating around his helmet.\nSpace.com: So it\'s a way of saying, ""He\'s back in space. He made it clear of ""Mars, the monster""?\nCheck out Space.com\'s full coverage of ""The Martian"" Ridley Scott\'s sci-fi film, based on the novel by Andy Weir, which opens October 2.', 'NASA’s new X3 thruster, which is being developed by researchers at the University of Michigan in collaboration with the agency and the US Air Force, has broken records in recent test. It’s hoped that the technology could be used to ferry humans to Mars. The X3 is a type of Hall thruster, a design that uses a stream of ions to propel a spacecraft.\nPlasma is expelled to generate thrust, producing far greater speeds than are possible with chemical propulsion rockets, according to NASA. A chemical rocket tops out at around five kilometers per second (1.86 miles/sec), while a Hall thruster can reach speeds of up to 40 kilometers per second (25 miles/sec). This kind of increase is particularly relevant to long-distance space travel, like a prospective voyage to Mars.\nIn fact, project team leaders project that ion propulsion technology such as this could take humans to the Red Planet within the next 20 years. Ion engines are also more efficient than their chemical-powered counterparts, requiring much less propellant to transport a similar amount of crew and equipment over large distances. Alec Gallimore, the project lead, stated that ionic propulsion can go around ten times farther using a similar amount of fuel in an interview with Space.com.\nThere are of course many other forms of deep-space travel on the table. The flaw of chemical-based designs is the need to bring the chemical fuel with them into space, which adds more mass that needs more fuel to lift into space, and so on. A Bussard ramjet, which is a type of fusion rocket, collects diffuse hydrogen in space with a huge scoop, which means, since its fuel is picked up en route, that it could approach light speed.\nSci-fi fans would recognize faster-than-light theoretical forms like the warp drive. General relativity stipulates that nothing can travel faster than the speed of light in the universe. However, if we could compact and expand the fabric of spacetime ahead of and behind us, respectively, we could technically be moving faster than the speed of light. However, the scientific consensus so far is that we’re nowhere near this kind of technology.\nRecent tests demonstrated that the X3 thruster can operate at over 100kW of power, generating 5.4 Newtons of thrust — the highest of any ionic plasma thruster to date. It also broke records for maximum power output and operating current.\nThe technology is apparently on track to take humans to Mars sometime in the next twenty years. However, it’s not without its limitations.Compared to chemical rockets, the ionic alternative is capable of a very small amount of thrust. This means that it would have to operate for a very long time to reach the same level of acceleration as a chemical system, and as a result it’s not currently suitable for the launch process.\nHowever, engineers are attempting to mitigate these issues with the X3 design. Multiple channels of plasma are being used rather than just one, but the current challenge is producing an engine that’s sufficiently powerful as well as being relatively compact. While most Hall thrusters can be picked up and carried around a lab with relative ease, the X3 needs to be moved with a crane.In 2018, the team will continue to put the X3 through its paces with a test that will see it run continuously for 100 hours. A shielding system is also being developed that would prevent plasma from damaging the walls of the thruster, allowing it to operate for even longer, perhaps even several years at a time.']"	['<urn:uuid:a31c0da5-3cf2-4200-9e82-9fec1a0a5f1f>', '<urn:uuid:258ef5c6-5656-4db6-b670-47202a9ffae1>']	factoid	direct	concise-and-natural	distant-from-document	multi-aspect	novice	2025-05-01T23:46:40.222380	11	52	3201
449	Could you explain in detail how the fact section of a case brief should be structured and what specific categories of legally relevant information need to be included?	The facts section of a case brief should only include legally relevant facts that impact the case outcome, organized into specific categories: the cause of action, which identifies the reason for the case in a single sentence; the statement of relevant law, which identifies which laws were broken; identification of opposing parties, including their names and relationships; the complaint, which summarizes relevant points and reasons for filing; and court holdings, which explains the procedural history in lower courts regarding the case.	"['How To Write a Case Brief in 7 Steps (With Tips and Example)\nUpdated December 21, 2022\nOne of the main responsibilities of legal professionals is to produce legal documents for their cases. Each document adheres to a court system\'s specific format and standards to present case arguments as effectively as possible. If you\'re interested in working in the legal system, knowing the steps necessary for producing a professional and informative case brief can be beneficial and help you decide if this task and others typical of the job fit your career interests and goals.\nIn this article, we define what a case brief is, list which elements to include in one, provide a step-by-step guide on how to write a case brief, offer brief-writing tips along with an example you can reference when producing your own case brief.\nWhat is a case brief?\nA case brief is an analysis summary of a legal argument. This document, which legal professionals sometimes refer to as a case summary or legal brief, states a party\'s legal argument in a court case in a comprehensible way. Mostly, this document is for one\'s own reference.\nIn appellate courts, however, each side of a case presents its own brief to the court as a way of briefly stating a specific argument using case law precedents, statistics and policy arguments to help the judge make a decision. The petitioner usually files their brief first, and the respondent has a specified amount of time to file a reply brief. These documents are often public record, making them accessible to anyone who wishes to search for it.\nRelated: Learn About Being an Attorney\nWhat to include in a case brief\nWhile each case has its own unique details—and uses varied versions of this outline—a brief should include only the most important points of your case and stay within 600 words before concurrences and dissents, using the following headings:\nTitle and citation\nRule of law\nHolding and reasoning\nHow to write a case brief\nHere are some steps you can follow when writing a case brief:\n1. Choose the right case brief format\nThere are several similar formats you might choose for your legal case. Most include the same general information but might use slightly different terminology. While each court might have slightly different formats they use to describe the case, the most effective protocol is to use the format that is most useful or appropriate for your specific case.\n2. Start with the title, citation and author\nA case brief can start with the title of the case, citation and author. The title names the two opposing sides of the argument. The name of the person or party who initiated legal action, either the petitioner or plaintiff, appears first, followed by the respondent, or defendant.\nThe citation provides the contact details of the case reporter. A case report is a publication that includes legal cases in a particular jurisdiction and provides a way to research the case details if necessary. The author is the party writing the document.\n3. State the facts of the case\nNext, state the facts that are legally relevant to the case. A fact is only legally relevant if it impacts the outcome of the case, and you can organize them into the following categories:\nCause of action: This is a single sentence identifying the reason for the case, whether it\'s for breach of contract, an eviction, foreclosure or other conflicts between people or entities.\nStatement of relevant law: This identifies which laws the defendant broke if applicable.\nIdentification of the opposing parties: This includes the names of the plaintiff(s) and defendant(s) in the case and the relationship between them, which can be buyer/seller, employer/employee or tenant/landlord, for example.\nComplaint: This summarizes the relevant points of the complaint and the reason for the case\'s filing.\nCourt holdings: This explains the procedural history in lower courts regarding this case, if applicable, which may include previous convictions, granting of a writ when a higher court agrees to hear a case and formally acknowledges this to the lower court or other actions.\n4. Declare the legal issue\nThe legal issue is your argument and may include the facts and questions you pose to the court. The legal issue in question should not include details specific to the current case. Instead, you can state the issue as a legal question that someone can answer with a yes or no without ambiguity. If the case involves constitutional rights, you may need to outline all relevant points of interest related to the United States Constitution.\nRelated: What Is a Bailiff?\n5. Outline the rule of law\nThe rule of law states the legal principle(s) upon which the court based its final decision. While a legal opinion may apply more than one legal principle, your objective in this section is to identify the rule of law pertinent to the case and present it in plain terms in a single sentence.\nThe rule of law is supposed to answer the question you propose in the legal issue section of the case, typically as a restatement of the question in answer form. This section can also include a statement of policy or the reasons behind the laws mentioned here.\n6. Explain the holding and reasoning\nThis section is where you can explain the reasons behind a court decision in legal terms. The specific format in which this section uses the conclusion, rule, explanation, application and conclusion (CREAC) method. This is where you can make sure you\'ve clearly explained all relevant legal rules and rationales.\n7. Concurrences and dissents\nIf a judge hearing a case doesn\'t wholly agree with the majority decision, they write a dissenting opinion to be included in the case file. If a second judge agrees with the majority decision but not with the reasoning behind it, that judge writes a concurring opinion.\nConcurrences and dissents in the casebook are short, so your summary can be even shorter and include the reasons the judges disagreed with the majority opinion. It\'s possible for a judge to both concur and dissent in part, and when this is the case, you can note it in your brief as ""concurrence/dissent.""\nTips for writing a case brief\nBefore writing a case brief, consider the following tips:\nUse active voice whenever possible.\nUse pronouns sparingly and unambiguously.\nKeep it succinct.\nUse the correct homophones.\nBe careful to avoid nominalization, which includes using verbs as nouns.\nProofread your work multiple times before submitting.\nRelated: 16 Technical Writing Tips\nCase brief example\nHere\'s an example of a case brief for reference:\nTitle and citation:\nHailey Stone, Plaintiff, v. Forest Co., L.L.C., Defendant\n0:00-CV-01011 (C.D. Ill.)\nAugust 3, 2022, Decided\nForest Co, LLC. is a company that offers full-time, hourly non-exempt positions to employees who are below management level. The Plaintiff alleges that Forest Co. violated California state by denying meal and rest break periods (California wage and hour Law) governing: (1) meal periods were not given after five hours during an 8-hour workday, and (2) work was still conducted and required when the plaintiff was clocked-out for meal and rest periods.\nDoes the plaintiff have sufficient documentation of violation of the California Labor Code Section 512 to hold the LLC responsible in state jurisdiction?\nDo violations of the wage and hour law protections against ""missed meal periods and denial of pay for time worked during meal periods"" indicate that the meal period was not waived by mutual consent of both the plaintiff and defendant?\nRule of law:\nThe IWC Order 12-2001, Section 11(A) authorizes Plaintiff to bring actions against an LLC when a non-exempt employee has been denied or not provided with an uninterrupted meal break within 5 hours of employable hours.\nSusan v. Sumpter and Brothers, Inc., 2012 WL 00099999, at 5-7 (N.D. Ill. September 23, 2012) states that ""In any event, section 512 establishes substantive, not procedural, rights that non-exempt employees have the right to 30-minute meal breaks within 5 hours of their 8-hour workday and two 30-minute breaks within a 10-hour workday. Both history and the judgment of Congress suggest that violation of this substantive right is sufficient to constitute a concrete, de facto injury.\nHolding and reasoning:\nYes. The Court entered a judgment in favor of the Plaintiff, Hailey Stone, against Defendant Forest Co. LLC. The Court awarded civil penalties and statutory damages in favor of the Plaintiff Hailey Stone against Defendant Forest Co. in Counts I, II, III, X of the Labor Code, California Wage and Hour Law in the total sum of $30,000.00.\nThis Court has jurisdiction to hear Hailey Stone\'s claims in Counts I-IV pursuant to 00 U.S.C. §§ 000, 00000(a), 1113, and 1112. This Court has jurisdiction to hear the Plaintiff\'s Labor Law claims in Counts V & VI pursuant to 00 U.S.C. §§ 1113, and 1112; and exclusive jurisdiction pursuant to CLL, 11 U.S.C. § 000(g)(2).\nSulley, J., Commissioner, concurring: IWC Orders except Orders 12, 14, 15 and 16-2001 gave the commission a deliberative reason for examining suspected incipient or policy violations of California wage and hour laws, and provided remedial measures dedicated more to protecting non-exempt employees.\nAlthough the Agency has not ignored its Congressional mandate entirely, we need to build on this foundation, further develop this aspect of our enforcement responsibility and use all the arrows in our jurisdictional quiver to ensure that corporations are fair and just regarding employment.\nMiller, Circuit Judge, dissenting: In holding that the 2012 Letter from the Division of Labor standards states that each non-exempt employee can clock out or leave of their own free will. But the pride of our legal system is its evenhandedness and fairness to all who come before it.\nPlus the issue here is not whether the Commission can regulate California wage and hour laws. It is only whether the Commission must own up to the regulatory actions it has set in motion, and whether those who are told to close up shop and discharge their employees have entitlement first to a day in court.\nIn my view, if the law requires us to treat the 2012 Division Letter and its business-ending consequences as just some informal, take-it-or-leave-it staff suggestion, the law is being stingy with reality. I respectfully dissent.\nExplore more articles\n- 7 Types of Business Structures (Plus How To Choose One)\n- 12 Techniques for Requirement Gathering\n- Parts of a Business Letter: Examples of the 7 Components\n- How To Send an Effective Email in 7 Steps (With Tips)\n- Kinesthetic Learning: Benefits and How To Partake in It\n- How To Divide In Excel: 6 Methods and Useful Formulas\n- How To Add a Vertical Line in an Excel Graph (Plus Benefits)\n- Trade School vs. College: Key Differences and Benefits of Each\n- External Analysis: Definition, Benefits and Examples\n- How To Create a Vertical Line in an Excel Graph in 8 Steps\n- Vocational Training: Definition and Different Types\n- 45 Different Email Greetings To Use at Work']"	['<urn:uuid:6f1f2077-f14f-49eb-918f-9736783f5304>']	open-ended	direct	verbose-and-natural	similar-to-document	single-doc	expert	2025-05-01T23:46:40.222380	28	81	1837
450	How does the U.S.-Japan Okinawa Reversion Agreement of 1969 handle the issue of nuclear weapons in Okinawa, and what special provisions were included?	Under the U.S.-Japan Okinawa Reversion Agreement of 1969, all nuclear weapons were required to be removed from Okinawa when it reverted to Japanese sovereignty in 1972. However, a 'secret understanding' that accompanied the Reversion Agreement permits the United States to bring nuclear weapons back to Okinawa during a 'great emergency,' which can be determined unilaterally by the U.S. This provision effectively excludes Okinawa from the non-nuclear policies that apply to the rest of Japan.	['Submitted by Steve Rabson\nProfessor Emeritus, Brown University\nVeteran, United States Army, 137th Ordnance Company, Henoko, Okinawa (1967-68)\nTranslator of Okinawan literature and author of books and articles about Okinawa, including The Okinawan Diaspora in Japan: Crossing the Borders Within (University of Hawaii Press, 2012)\nThree U.S. Army veterans of a nuclear weapons base in Okinawa have filed claims with the Veterans Administration for cancers associated with radiation exposure. Since January, 2020, the Japanese Defense Ministry has been removing a large swath of soil from the former nuclear weapons storage area in Henoko Village, but has refused a request from the local Diet representative from Okinawa to test it for radioactive contamination. This threatens the safety of local residents, and denies important information to the veterans filing VA claims.\nThree Army veterans stationed at a nuclear weapons storage base in Okinawa during the late 1960’s have contracted cancers associated with radiation exposure, and filed compensation claims with the Veterans Administration. After initial denials, they have submitted appeals. One lost an eye to melanoma, another died in 2015, a few weeks before his appeal hearing was scheduled.\nThe 137th Ordnance Company in Henoko, Okinawa stored and maintained the warheads for Nike-Hercules anti-aircraft missiles, Honest John and Little John rockets, and Atomic Demolition Munitions (nuclear landmines). Under the U.S.-Japan Okinawa Reversion Agreement of 1969, all nuclear weapons were removed from Okinawa when it reverted to Japanese sovereignty in 1972 after prolonged U.S. military occupation (1945-1972). However, a “secret understanding” (since made public) that accompanied the Reversion Agreement permits the U.S. to bring them back during a “great emergency” to be determined unilaterally by the U.S. The former nuclear weapons storage area at the base has remained intact. (See “Nuclear Hawks in Tokyo Call for Stronger US Nuclear Posture in Japan and Okinawa,” Gregory Kulacki with commentary by Steve Rabson, Asia-Pacific Journal, June 1, 2018, Volume 16 | Issue 11 | Number 1)\nThe Japanese Defense Ministry has begun upgrading work on and around the sod-covered, steel-reinforced igloos previously storing nuclear weapons (see photos). This has raised suspicions among Okinawans and the Union of Concerned Scientists that they are being prepared for the return of nuclear weapons to the base in conjunction with the on-going, though much-delayed, construction of a U. S. military airbase next to it. (See Kulacki article, cited above.) Though Okinawa comprises less than 2% of the nation’s land area and about 1% of its population, this small island prefecture already bears 70% of the U.S. military presence in all of Japan. Local residents and the prefectural government continue vigorously to oppose the airbase by denying construction permits, filing lawsuits, and mounting daily protests at the construction site, but the national government insists that it will be built despite the many legal and environmental obstacles.\nAlan Caraway, one of the three veterans to file a claim with the V.A., has been watching the upgrading work inside the former nuclear weapons storage area from satellite photos on googlemaps.com. In recent weeks, he has noticed a wide swath of dredging there by bulldozers with the soil being removed by trucks. He suspects the soil is contaminated with radiation.\nJapanese Diet Representative Akamine Seiken from Okinawa forwarded the satellite photo to the Japanese Defense Ministry requesting that the soil be tested for radioactive contamination. This information, in addition to being critical for local residents, would be important for the veterans who have filed VA claims. This is the correspondence between Representative Akamine and the Defense Ministry. (author’s translation):\nQuestion to Defense Ministry from Lower House Representative Akamine Seiken of Okinawa:\nIn regard to the reclamation work proceeding at the Henoko Ordnance Storage Depot, are tests for radioactive contamination being conducted? Are decontamination measures being implemented? If so, please indicate what specific actions have been taken, and the results.\nReply from the Defense Ministry:\nIn regard to the construction work in question, no tests for radioactive contamination or decontamination measures have been carried out.\nThe reclamation work at the Henoko Ordnance Storage Depot is being carried out according to the construction regulations of Japanese law. As there is no legal requirement to conduct the radiation tests or the implement decontamination measures you request, there is no necessity to carry them out.\nThe likely reason that no law requires the testing of soil from former nuclear weapons sites in Japan is that, before Okinawa reverted to Japanese sovereignty in 1972, there were no nuclear weapons storage sites in Japan. This would violate long-standing policy adopted by the National Diet prohibiting their “manufacture, possession, or introduction.” The Japanese government’s refusal to test the soil of a former nuclear weapons storage area now located in a Japanese prefecture is yet one more example of its discriminatory policy toward Okinawa. Another example is the “secret understanding” accompanying the 1969 reversion agreement that permits the U.S. to bring nuclear weapons back to Okinawa, excluding this one prefecture from the non-nuclear policies applying to the rest of the country.\nAccording to the U.S. Environmental Protection Agency,\n“Over 1,000 . . . locations, including both operational and abandoned sites, are contaminated with radiation. These sites range in size from small corners in laboratories to massive nuclear weapons facilities. The contamination may be found in the air, water, and soil, as well as equipment in buildings.”\nSuch likely contamination continues to endanger the health and safety, not only of the U.S. military personnel stationed at the former nuclear weapons storage base, but also Henoko residents and those of nearby communities.\nClick to Subscribe to the Civilian Exposure Newsletter for Latest News & Updates Today!']	['<urn:uuid:604728c4-d437-4488-9f7d-566d199eb39c>']	open-ended	direct	verbose-and-natural	similar-to-document	single-doc	expert	2025-05-01T23:46:40.222380	23	74	932
452	online payments safety betting fraud prevention	For online payment safety, operators must conduct payments through formal documented processes accurately and timely, with customer funds managed separately from operator accounts. They must also implement anti-money laundering policies and proper customer verification processes. To prevent fraud, it's essential to use up-to-date antivirus software, verify site security through HTTPS and lock icons, avoid clicking suspicious links, and regularly check accounts for unusual behavior. Additionally, operators must protect customer data against unauthorized disclosure through proper control measures.	"[""What is responsible gambling?\nResponsible gambling means staying in control of how much time and money we spend gambling.\nShared responsibility for generating awareness of the risks associated with gambling.\nCreating and promoting environments that prevent or minimise problem gambling.\nBeing responsive to community concerns around gambling.\nWhether you are placing a bet, buying a lottery ticket or scratch-card, playing poker or bingo, or playing on a gambling machine or casino game, gambling responsibly means treating the activity as just one form of entertainment in a balanced lifestyle.\nJust like with other forms of entertainment, gambling is a form of expenditure, and responsible gambling means not spending more money or time than we can reasonably afford, keeping in mind all our other responsibilities in life.\nUnderage customers are not allowed to gamble. In Uganda, all people below 18 years are not supposed to engage in betting/gambling activities.\nFraudulent and criminal behaviour are prohibited in betting. Operators are required to implement anti-money laundering policies and procedures. This involves implementing effective know your customer processes when taking on new customers and tracking and reporting any suspicious transactions.\nCustomer's information must be private. Protection of customer data and records against unauthorised or unnecessary disclosure is a must. Operators are required to implement policies that ensure controls and measures are in place to prevent unauthorised disclosure and use of customer information. Customer information typically relates to data such as name, address, age, telephone number and email address.\nOperators must ensure that payments to and from customer accounts must be conducted according to formal and documented processes in an accurate and timely manner. Operators typically ensure that customer funds are managed separately from their own accounts and that they have sufficient cleared funds to pay all player prize wins and outstanding player balances.\nAll gaming products should be tested to ensure they are fair and random and that they adhere to the rules of that game. Testing to ensure fair gaming is increasingly carried out by independent organisations.\nOperators should comply with the relevant regulatory advertising codes of practice which typically ensure that advertisements are factually correct and do not target underage or vulnerable gamblers, such as players who have self-excluded themselves from gambling. It is also expected that operators should seek permission from the customer prior to engaging in direct marketing through use of the customer’s personal details.\nCustomers should be able to freely make comments or complaints to operators and expect operators to have in place adequate processes and procedures to deal with complaints, either internally or via an independent third-party. For example, ecogra.org provides a mediation service for disputes between players and operators.\nSecure, safe and reliable operating environment\nOperators are required to demonstrate internal controls and processes that adhere to the licensing conditions as stipulated by the regulatory jurisdiction that issues gaming and gambling licenses. Internal controls should also be implemented to ensure that all operational, payment and technical systems and processes operate securely and effectively. In addition, operators need to demonstrate adequate business continuity management procedures to ensure that operations can continue in the event of unforeseen circumstances or disasters."", 'Do phishing scams have you paranoid about surfing the Web? They should not, as they can be stopped, and this article will tell you how.\nWe previously covered the topic of phishing by giving you a basic definition of what it is. To review, phishing is basically an instance where a potential victim is contacted, usually by email or telephone, by a party posing as a legitimate institution in order to trick the target into handing over sensitive information.\nIn addition to offering a basic overview of what phishing is, we also told you the different ways to detect a phishing scam. In particular, we discussed the telltale signs that are commonly found in phishing emails. Among these characteristics are a sense of urgency, an offer that is too good to be true, randomly generated names, poor grammar and spelling, and malicious links to infected websites.\nWith a basic understanding of phishing scams and how to detect them, now is the time to learn how to stop them or prevent them from creating chaos not only for your computer, but also your personal life. After all, these scams happen for a reason, and many times that reason is to pad the pockets of cybercriminals with your hard-earned money.\nSo, let us now take a look at how you can not only stop phishing scams, but also report them to help keep them from affecting new victims.\nWhether you are an expert Web surfer or a complete newbie, you will come across a phishing scam at one point or another during your online time. Some of these scams are very crafty and well-designed, so they might catch you if you are not paying attention. To help you out, here are tips that you can implement to your everyday surfing activities to avoid these scams.\nUse trusted up-to-date antivirus software and a firewall to provide a barrier between you and cybercriminals.\nUpdates, Updates, Updates\nWhether it is antivirus software, your browser, operating system, or applications, you need to keep everything updated. Vendors send out patches to fix detected vulnerabilities that hackers can exploit. It may be annoying, but updating is essential to your online protection against phishing and other cyber crime.\nLeverage the Power of Nifty Toolbars\nMany popular browsers now offer the extended functionality of toolbars that can detect phishing sites. The toolbars check the site you are visiting against a blacklist of known phishing sites to tell you if you are safe.\nCheck Site Security\nWhenever you are entering in personal information, such as a password, banking information, credit card information, and the like, you want to make sure the site is properly secured so your information will not be leaked to others. There are a few things to look for to determine this. First, make sure that the “https” prefix is in the URL. Second, look for a little icon of a closed lock that means your connection is encrypted. Depending on your browser, you can click on the icon to see the site’s security details.\nManage Popups Properly\nPopups are not only irritating, but they can also be dangerous. Some come in the form of scareware that tricks you into thinking your computer is infected. Others offer phony rewards if you fill out phishing forms with your personal information. Use a popup blocker in your browser to keep popups at a minimum. If one does appear, avoid clicking options like “OK” or “Cancel” as these could just lead you into a phishing scheme or infected site. Either close out your browser, or click the X in the top right corner to exit the popup.\nWatch Where You Click\nIt may be tempting to click a lot of links when you surf the Web, but it is not a very good habit to have. Creators of phishing and other scams know what tempts users, and they leverage this knowledge to devise schemes to get you to click links that lead to sites that try to phish your information. Clicking links on a trusted site is fine, but clicking them on an unknown site, in email, or in instant messages could land you in trouble. Remember to always hover over a link to see exactly where it leads you, as some links will be disguised and will actually take you to a different site than promised.\nKeep Your Information to Yourself\nDo you want to make sure phishing attacks never compromise your personal information? If so, keep it to yourself, especially when wandering into unknown territory. If you do not disclose any personal information on the internet, you do not have to worry about anyone getting their hands on it. This goes for telephone calls as well. You never know who is on the other end. It is better off to call an institution directly or visit their official website and do your business from there. Never, ever disclose information via email, instant messaging, etc.\nRead Up on New Phishing Trends\nAs internet security companies and users out certain phishing scams, it becomes time for cybercriminals to change up their game plans. A stale scam has less of a chance to be successful as a new one, so new scams are constantly popping up around the online community. You can keep yourself educated on new phishing scams by doing periodic checks for news on the topic. A simple search in Google News for the term “phishing” should bring up plenty of news articles that detail newly detected scams. By being educated on the subject, you will be able to spot phishing scams easily and stop them from tricking you.\nPerform Account Maintenance\nAccount maintenance means checking your online accounts periodically to look for any unusual behavior. This mostly pertains to financial accounts (banking, credit cards, PayPal, etc.), but you should also do it for email accounts and social networking to make sure they are not compromised and being used to send out spam. A solid maintenance practice is to change your passwords frequently to keep hackers at bay. Do not use the same password on multiple sites, however.\nUse Common Sense\nNobody is going to give you free electronics and lottery prizes just for surfing the Web. Avoid these offers. If it seems too good to be true, it probably is. Use your instincts when surfing online just as you would in the real world.\nReport Phishing Scams\nIf you come across a phishing scam, report it and do your part to derail these scammers from affecting more victims. Some email services allow you to mark messages as phishing scams, such as Hotmail. You can also report phishing scams to certain websites dedicated to stopping them. Here are two links to do so:\nUnited States Computer Emergency Readiness Team - http://www.us-cert.gov/nav/report_phishing.html\nAnti-Phishing Working Group - http://www.antiphishing.org/report_phishing.html\n| DISCLAIMER: The content provided in this article is not warranted or guaranteed by Developer Shed, Inc. The content provided is intended for entertainment and/or educational purposes in order to introduce to the reader key ideas, concepts, and/or product reviews. As such it is incumbent upon the reader to employ real-world tactics for security and implementation of best practices. We are not liable for any negative consequences that may result from implementing any information covered in our articles or tutorials. If this is a hardware review, it is not recommended to open and/or modify your hardware. |\nMore Web Hosting Security Articles\nMore By wubayou']"	['<urn:uuid:e5dbe377-2390-47d4-ac04-954600955c60>', '<urn:uuid:e725b5d7-8f6f-417b-9679-ff62dc8599d8>']	open-ended	direct	short-search-query	distant-from-document	multi-aspect	expert	2025-05-01T23:55:16.606337	6	77	1761
453	compare infrastructure design trends north america privacy requirements implementation methods	In North America, infrastructure engineering demands primarily focus on upgrading projects to extend existing asset life and green sustainability projects. This infrastructure work must incorporate both Security by Design (SbD) and Privacy by Design (PbD) principles, particularly following regulations like GDPR and CCPA. The implementation requires a methodical approach using frameworks such as NIST 800-160 for security and OASIS PMRM for privacy, with both principles needing to be built into processes by default through documented procedures and guidelines.	"['ARC Advisory Group’s research on the Engineering Design Software and Building Information Modeling (EDS/BIM) market includes engineering design, analysis, and project management software and associated services used for the design and construction of physical plants and infrastructure. The EDS portion of the report includes power, process, and marine industries. The BIM market includes infrastructure. The market had surprisingly strong growth in 2021, considering the impact of the pandemic on the overall economy. After 2021, it is expected to continue to experience high market growth globally. Suppliers of EDS/BIM software have for the most part, converted from selling upfront perpetual licenses to subscription services. Despite the pandemic, the EDS/BIM market added new users in 2021. Subscription services have many benefits to the user, including converting CapEx to OpEx, nearly eliminating dependencies on IT support, no more upgrades, and reducing the first-year acquisition cost (including the servers) by over 60 percent.\n""Compared with the total cost of a project including construction, the cost of design is small. Many EPCs and AECs continued the design process while delaying construction during the pandemic, helping the EDS and BIM market to sustain itself. Developed regions are looking to EDS for innovative approaches to manage infrastructure assets as well as design and build new assets or retrofit legacy infrastructure components. Infrastructure engineering demands in North America primarily stem from upgrading projects for extending the life of existing infrastructure assets. Green and sustainability-focused projects are also drivers for the North American market,"" according to Ralph Rio, Vice President, Enterprise Software and key author of ARC\'s Engineering Design Software & Building Information Management Market Research Report.\nLeading Suppliers to the Engineering Design Software Market Identified\nIn addition to providing specific market data and industry trends, this ARC market research also identifies and positions the leading suppliers to this market and provides and summarizes their relevant offerings. An alphabetical list of key suppliers covered in this analysis includes: Autodesk, Bentley Systems, Hexagon, Nemetschek AG, Trimble.\nAbout the Engineering Design Software & Building Information Management Research\nThe Engineering Design Software & Building Information Management report explores the current and future market performance and related technology and business trends and identifies leading technology suppliers. This new research is based on ARC’s industry-leading market research database, extensive primary and secondary research, and proprietary economic modeling techniques. The research includes competitive analysis, plus five-year market forecasts and up to 5 years of historical analysis segmented by Revenue Category, Sales Channel, World Region, Customer Type, Service Revenues by Type, Deployment Model, Software Revenues by Type, Engineering Tools, Market Sector, Infrastructure & AEC/BIM, Plant Design.\nThis new research is available in a variety of formats to meet the specific research and budgetary requirements of a wide variety of organizations. These include:\n- Market Intelligence Workbook (Excel Power Pivot): A standard Workbook includes the base year market data and a five-year market forecast. This workbook enables licensed users to freely manipulate the data to make it easier to analyze the latest data for business intelligence and generate custom reports. Available with up to 5 years of historical analysis.\n- Concise Market Analysis Report (PDF): This wide-screen presentation format makes it much easier to find detailed information on a market. This new format provides executives, business unit managers, and other authorized users with immediate access to in-depth market analysis, including analysis associated with every market data chart and figure. Included is an executive-level summary of the current market dynamics, five-year market forecast, and competitive analysis, plus an overview of strategic issues. The PDF is available with a comprehensive set of charts with associated analysis.\nFor more information on this and other available ARC market research, please visit our Market Data & Studies section.', 'Security & Privacy By Design\nWith the European Union General Data Protection Regulation (EU GDPR) effective in mid-2018 and the California Consumer Privacy Act (CCPA) on the near-horizon for 2020, companies have an obligation to demonstrate they implement both Security by Design (SbD) and Privacy by Design (PbD). Unfortunately, most businesses lack the knowledge and experience to undertake such documentation efforts. That means businesses are faced to either outsource the work to expensive consultants or they ignore the requirement and hope they do not get in trouble for being non-compliant with this compliance requirement. In either situation, it is not a good place to be. The good news is that ComplianceForge developed a viable cybersecurity and privacy program that is based on NIST 800-160 guidance for security by design and OASIS for privacy by design.\nProfessionally-Written, Editable NIST 800-160 & OASIS PMRM-Based Cybersecurity For Privacy by Design (C4P) Program\nThe Security & Privacy By Design (SPBD) product is designed to support your company’s existing policies and standards. Our solution is focused at the procedural and guideline levels.\nProduct Example - Security & Privacy By Design (SPBD)\nThe SPBD addresses program-level guidance on HOW to actually manage cybersecurity and privacy principles, so that secure processes are designed and implemented by default. Policies & standards are absolutely necessary to an organization, but they fail to describe HOW privacy and security principles are actually planned and managed. The SPBD provides this middle ground between high-level policies and the actual procedures of how developers, PMs, system integrators and system admins do their jobs to design, implement and maintain technology solutions.\n|Watch Our Product Walkthrough Video||View Product Example|\nCost Savings Estimate - Security & Privacy By Design (SPBD)\nWhen you look at the costs associated with either (1) hiring an external consultant to write cybersecurity documentation for you or (2) tasking your internal staff to write it, the cost comparisons paint a clear picture that buying from ComplianceForge is the logical option. Compared to hiring a consultant, you can save months of wait time and tens of thousands of dollars. Whereas, compared to writing your own documentation, you can potentially save hundreds of work hours and the associated cost of lost productivity. Purchasing the SPBD from ComplianceForge offers these fundamental advantages when compared to the other options for obtaining quality cybersecurity documentation:\n- For your internal staff to generate comparable documentation, it would take them an estimated 250 internal staff work hours, which equates to a cost of approximately $18,750 in staff-related expenses. This is about 4-8 months of development time where your staff would be diverted from other work.\n- If you hire a consultant to generate this documentation, it would take them an estimated 160 consultant work hours, which equates to a cost of approximately $48,000. This is about 3-4 months of development time for a contractor to provide you with the deliverable.\n- The SPBD is approximately 7% of the cost for a consultant or 17% of the cost of your internal staff to generate equivalent documentation.\n- We process most orders the same business day so you can potentially start working with the SPBD the same day you place your order.\nThe process of writing cybersecurity documentation can take an internal team many months and it involves pulling your most senior and experienced cybersecurity experts away from operational duties to assist in the process, which is generally not the most efficient use of their time. In addition to the immense cost of hiring a cybersecurity consultant at $300/hr+ to write this documentation for you, the time to schedule a consultant, provide guidance and get the deliverable product can take months. Even when you bring in a consultant, this also requires involvement from your internal team for quality control and answering questions, so the impact is not limited to just the consultant\'s time being consumed.\nCybersecurity & Privacy By Design - Program Level Privacy & Security Documentation\nThe SPBD can serve as a foundational element in your organization\'s privacy program. It can stand alone or be paired with other specialized products we offer.\nCybersecurity and privacy do not need to be hard. The Security & Privacy By Design (SPBD) document is meant to simplify how security and privacy can be operationalized in a “paint by numbers” approach. This product is comprised of editable Microsoft Word and Excel documentation so you can customize it for your specific needs.\nPlease keep in mind that security & privacy engineering principles are widely expected activities:\nWhat Is The Security & Privacy by Design (SPBD)?\nOur products are one-time purchases with no software to install - you are buying Microsoft Office-based documentation templates that you can edit for your specific needs. If you can use Microsoft Office or OpenOffice, you can use this product! The SPBD comes in both editable Microsoft Word and Excel formats. The SPBD is capable of scaling for any sized company.\n- The SPBD is an editable Microsoft Word document that providers program-level guidance to directly supports your company\'s policies and standards for ensuring secure engineering and privacy principles are operationalized.\n- This product addresses the “how?” questions for how your company ensures both security and privacy principles are operationalized.\n- It is a reality that most companies have either weak or non-existent guidance on how security or privacy principles are implemented.\n- The lack of operationalized security & privacy principles can lead to compliance deficiencies with many statutory, regulatory and contractual obligations.\n- NIST 800-160 is the ""gold standard"" on how to build security into the System Development Life Cycle (SDLC)\n- The concept of “secure engineering” is mandatory in numerous statutory, regulatory and contractual requirements.\n- The SPBD provides a “paint by numbers” approach to ensure your company has evidence of both due care and due diligence for operationalizing security and privacy principles.\n- The CIRP is based on numerous frameworks, but the core principles are based on NIST 800-160 and the Generally Accepted Privacy Principles (GAPP) which are the de facto standards on security and privacy design principles.\nWhat Problem Does The SPBD Solve?\n- Lack of In House Security Experience - Writing cybersecurity & privacy documentation is a skill that most cybersecurity professionals simply are not proficient at and avoid the task at all cost. Tasking your security analysts and engineers to write comprehensive procedure documentation means you are actively taking them away from protecting and defending your network, which is not a wise use of their time. The SPBD is an efficient method to obtain comprehensive guidance documentation to implement cybersecurity and privacy principles within your organization!\n- Compliance Requirements - EU GDPR requires companies that store, process or transmit the personal information of EU citizens to ensure that both cybersecurity and privacy principles are built into processes by default. Can you prove how cybersecurity & privacy principles are implemented?\n- Audit Failures - Security documentation does not age gracefully like a fine wine. Outdated documentation leads to gaps that expose organizations to audit failures and system compromises. The SPBD provide mapping to leading security and privacy frameworks to show you exactly what is required to both stay secure and compliant.\n- Vendor Requirements - It is very common for clients and partners to request evidence of a security program and this includes policies, standards and procedures. With EU GDPR, vendors and other partners will be expected to demonstrate evidence of compliance with the EU GDPR.\nHow Does The SPBD Solve It?\n- Clear Documentation - The SPBD provides a comprehensive approach to operationalizing both cybersecurity and privacy principles. This equates to a time saving of hundreds of hours and tens of thousands of dollars in staff and consultant expenses!\n- Time Savings - The SPBD can provide your organization with a templated solution that requires minimal resources to fine tune for your organization\'s specific cybersecurity and privacy needs.\n- Alignment With Leading Practices - The SPBD is written to support leading cybersecurity and privacy frameworks!\nReducing Risk Through Cybersecurity For Privacy by Design (C4P)\nThe Security & Privacy By Design (SPBD) document supports your company’s existing policies and standards. Our solution is focused at the procedural and guideline levels. The SPBD document is focused on understanding risk associated with cybersecurity and privacy so that risk can be:\n- Transferred; or\nImplementing both Security by Design (SbD) and Privacy by Design (PbD) principles is a systematic way to find and address weaknesses, flaws and risks to your company.\n- Repeatable, methodical processes that seek out both security and privacy risk reduces the chance of surprises.\n- Addressing security issues in an orderly manner gives your company a better assurance that gaps have been closed properly and as quickly as possible.\nWork Smarter! Leverage Common Touch Points Between Cybersecurity & Privacy\nSystems security engineering delivers systems deemed adequately secure by stakeholders. The fundamental relationships among assets, an asset-dependent interpretation of loss, and the corresponding loss consequences are central to any discussion of system security.\nThis is where aligning your company’s Security by Design (SbD) efforts with the Risk Management Framework (RMF) (e.g., NIST 800-37) can be very beneficial, since the RMF provides a well-established format to securely engineer and maintain systems throughout the entire life cycle of the asset. Utilizing common linkages, Privacy by Design (PbD) is incorporated into the RMF cycle.\nPaint By Numbers - Cybersecurity & Privacy Requirements\nWhat we\'ve done is take on the heavy lifting to integrate security and privacy controls into standard project management processes. This allows your teams to have a ""paint by numbers"" approach to demonstrating that both cybersecurity and privacy principles are baked into the process! We identified the stages where both cybersecurity and privacy requirements are expected as part of project development. This can enable your teams to work more effectively together and reduce the negative effect of teams working in silos.\nAll too often, when projects are commenced, involvement from key stakeholders is siloed, as compared to operating as a cohesive team. We want to help your company avoid the following security & privacy pitfalls where:\n- Project / application teams work in a vacuum, unaware of security or privacy concerns;\n- Privacy and security conduct their own assessments without any information sharing or collaboration; and\n- Security involvement is viewed as a final hurdle to overcome, just prior to “go live” for the project.\nThe SPBD Excel checklists provide a wealth of experience to bake in security and privacy principles by establishing methodical and repeatable processes.\n- Logically-organized phases\n- Task focus (How tasks support the lifecycle phases)\n- Task #\n- Activity Description\n- Reasonable Task Deliverables\n- Mapping to leading practices:\n- NIST 800-160\n- NIST 800-53\n- ISO 27002\n- OASIS PMRM\n- Level of Effort (expectation for basics or enhanced requirements)\n- Stakeholder RACI Matrix (Responsible, Accountable, Consulted, Informed)\nIn addition to logically organizing steps, we went the extra mile by calling out the deliverables expected and tied it to task #:\n- Proposed solution is documented that captures security-relevant criteria and tentative requirements.\n- Listing of applicable statutory, regulatory and contractual requirements are defined.\n- Business & technical constraints are identified and documented.\n- Data classification is identified.\n- System criticality is identified.\n- Data protection requirements are defined (e.g., controls) based on docuemented data classification and system criticality.\n- ""Best practices"" are defined to be used in the design & implementation of systems, applications and services (e.g., OWASP, NIST, DISA STIGs, etc.).\n- System hardening baselines (e.g., configuration management requirements) are defined and documented.\n- Security Concept of Operations (CONOPS) are defined and documented.\n- is defined and documented.\n- Standardized Operating Procedures (SOP) are documented.\n- Service Level Agreement(s) (SLAs) are defined and documented\n- Tentative life cycle is identified.\n- Roles and responsibilities for security requirements are assigned and documented.\n- Risk Assessment is conducted and a Risk Register (RR) is used to document findings.\n- Business Impact Analysis (BIA) is conducted and documented.\n- Privacy Impact Assessment (PIA) is conducted or modified.\n- Project stakeholder list is defined and documented (strategic personnel, business units and third parties).\n- Threat assessment is conducted and documented.\n- List of constraints (facts & assumptions) is defined.\n- Listing of expected systems and services that will be required to support the proposed solution is defined.\n- System Security Plan (SSP) is documented or modified.\n- Change Control Board (CCB) change request(s).\n- High Level Diagram (HLD) is documented.\n- Low Level Diagram (LLD) is documented.\n- Data Flow Diagram (DFD) is documented.\n- Plan of Action & Milestones (POA&M) is documented or modified.\n- End user training material is developed.\n- Security awareness training is provided.\n- Information Assurance (IA) testing (certification &accreditation) is commenced.\n- Key Performance Indicators (KPIs) are identified.\n- Authorization is granted (e.g., Authority To Operate (ATO) , Interim Authority To Operate (IATO) or Denied Authority To Operate (DATO)).\n- User Acceptance Testing (UAT) is conducted and documented.\nUnderstanding Privacy & Security Starts With Defining Requirements\nUnderstanding the requirements for both Security by Design (SbD) and Privacy by Design (PbD) principles involves a simple process of distilling expectations. This process is all part of documenting reasonable expectations to right-size the approach, since every organization is unique:\nSecurity by Design (SbD)\nPrivacy by Design (PbD)\nSecurity by Design (SbD) requirements come from numerous sources. In this context, the most important are:\nPrivacy by Design (PbD) requirements come from numerous sources. In this context, the most important are:\nData-Centric Security (DCS) = Defense-In-Depth Approach To Security\nThinking in terms of data, or information, it is your company’s most valuable asset. Therefore, being ""data-centric"" is how we approach our defense-in-depth concept. When you look at the diagram below, if you envision data protection as a set of concentric rings, at the center of the protection is your data.\nZone-Based Approach To Secure Engineering\nFrom a secure engineering and architecture perspective, it is worthwhile to take a zone-based approach to scoping an environment for secure systems engineering. This effort is meant to focus on particular systems of interest, while taking into account the systems elements and enabling systems that compose the system of interest. This supports the concept of Data-Centric Security (DCS), since the focus encompasses everything that either stores, processes or transmits the data in question, as well as the supporting infrastructure and services.\nFrom this perspective, assets can be logically grouped into three (3) overlapping zones:\nZone 1 – The asset is a system of interest;\nZone 2 – The asset exists within the immediate operating environment of a system of interest; or\nZone 3 – The asset exists outside of the operating environment but influences the system of interest.\nMethodical Approach To Privacy By Design (PbD)\nThe OASIS Privacy Management Reference Model and Methodology (PMRM) is a privacy framework that assists in operationalizing Privacy by Design. Thee PMRM identifies eight (8) privacy services that are needed to operate at a functional level. These services are meant to clarify the “architectural” relationships and can be logically grouped into three (3) categories: Core policy services, Privacy assurance services; and Presentation & lifecycle services.\nThe Security & Privacy By Design (SPBD) includes an editable checklist for PMRM controls. This is tied to the security controls, so it is easy to link both cybersecurity and privacy requirements. This allows for a more cohesive assessment and encourages information sharing. The end product is a more comprehensive assessment of risk to both privacy and security.']"	['<urn:uuid:b0bb6464-3b89-4b43-83f6-96114d2abffc>', '<urn:uuid:bdbcf3b8-e46b-434a-a8b8-6058e7cc719c>']	open-ended	with-premise	long-search-query	distant-from-document	multi-aspect	expert	2025-05-01T23:55:16.606337	10	78	3195
456	looking for gardening method that uses wood what is hugelkultur raised bed and how does it compare to french intensive garden	Hugelkultur is a raised bed system that uses timber and branches as a base, covered with grass sods and topsoil. It creates different microclimates, retains water better, and releases nutrients slowly over several years. In contrast, the French Intensive Gardening method involves creating wide beds (5ft) by digging 12 inches deep, turning soil another 12 inches, and mixing with compost. Both methods aim to increase growing capacity, but through different approaches - Hugelkultur through wood decomposition and French Intensive through deep soil preparation.	"[""Hugelkultur is a special form of raised bed with wood as a base acting as a sponge for water and nutrients.\nIf you are not familiar with the term 'Hugelkultur' you might think I am making up words! But I am not.\nHugelkutur is a German word and it basically means ‘hilled culture’. The term I think was coined by Sepp Holzer, a farmer with creative and unconventional methods of food production in the Austrian Alps. Look him up on youtube. You will be impressed by his methods and ideas of food production in the harsh environment of high altitudes.\nWhat Is Hugelkultur?\nHuegelkultur is a form of raised bed with timber, branches or\nshrubs as the core. The Wood then is covered by grass sods and top soil.\nThe height and size can be varied due to ones need.\nSo Why Should You Consider These Types Of Raised Beds?\nThe beds create different microclimates and conditions suitable for the\nvaried needs of different plants. The side facing the sun can be used\nfor heat and sun loving plants for example.\nThe soil warms up quicker in the spring allowing for an earlier start of growth.\nThey retain water better reducing the need for watering. The wood acts like a sponge and balances moisture levels.\nThe soil is loose and well aerated. This slows freezing of the soil in cold areas.\nThe decomposition of the wood inside creates heat which helps the growth and germination of seeds, particularly in the spring.\nnutrients locked up in the wood get released slowly over a period of\nseveral years. Even vegetables with a high demand of nutrients can be\ngrown without the use of additional fertilizer.\nThe method of hilling\nor sloping the raised bed increased the surface area allowing more area\nfor growing. This is particularly in small gardens with limited space.\nHow To Build A Hugel\nFirst dig out the area where you will have your bed. Remove the sod and\nsome soil and put it aside. You will need it again later. Keep the sod\nand the top soil separate.\nPut in your timber, branches, old tree roots, shrubs, etc.. If you use a\nlot of branches it might be a good idea to walk over them to crush and\ncompact them a bit.\nCover them with the grass sod face down. It is important to face the sod with the grass down or might grow through again.\nThe cover everything with the top soil you put aside earlier. Don’t compact it. The soil should be loose.\nIdeally plant or sow your beds immediately to avoid too many\ncompeting weeds. If you are not planning on planting right away you can\nsow a green manure mixture to suppress the weeds and further improve the\nsoil. This will also help to avoid soil erosion by rain or wind.\nDo You Want To Offset Your Carbon footprint And Make A Difference For The Climate?\nDownload our FREE Gardening4Climate guide and learn how to do just that in your own backyard with permaculture gardening!\nDon’t make the mistake to use any kind of tree or shrub that will regrow\neasily from just the timber or a branch. A prime example for this would\nbe willows or alder. As long as the willow is green it will regrow and you will\nend up with a willow plantation instead of bed suitable for growing\nvegetables! Once the willows have dried and are truly dead they can be\nused for this purpose.\nAvoid any wood that is slow to break down\nlike for example cedar. Also, trees that are allopathic (inhibit the\ngrowth of other plants) like walnut should probably be avoided.\nWatch this short video to get a better idea about the whole process of building hugelculture beds.\nWhat Can You Grow In These Beds?\nYou can grow any kind of vegetable, fruit or herb in these beds that you can grow in your area. A hugel is great for polycultures. That means you grow a variety of different vegetables or herbs side by side. This much more natural system helps to avoid pests and diseases. You can also grow perennial vegetables like asparagus, artichokes or rhubarb in these beds. Depending on the size of your bed you can also include fruit bushes like currants, raspberries or blueberries into your mix."", 'Photo: Via Pinterest\nKeyhole Gardening was introduced in Africa by the Consortium for Southern Africa Food Security Emergency (C-SAFE) to help ailing and frail Africans grow their own produce with minimum effort by means of a specialized raised bed. The bed, which is waist high and in the shape of a keyhole, allows for standing and leaning for long periods and is built using stacked rocks, bricks, wood or pieces of concrete. A compost bin is placed in the center of the bed and as material breaks down, the resulting composted nutrients are added to the soil. The gardening principle is to grow produce with little water on top of a bed of compost which provides a steady supply of nutrients to the plants.\nPhoto: Via Pinterest\nHügelkultur (a German word for hill mound) is a growing method that is believed to have originated from Eastern Europe thousands of years ago. Widely utilized in permaculture enthusiasts, it is based on the concept of natural occurring decomposition of plant material in forests; ergo fallen trees, branches and other plant material which over time has decayed and created a healthy bio mass of rich hummus. The process of layered debris is continuous thus creating an organic, lush, green ecosystem teaming with beneficial life. Overall, this method will not only create healthy, growing plants due to the constant source of warming compost, it benefits the environment as a whole. When creating beds in the home garden, the beginning layering ratio from top to bottom, would comprise of logs, branches, large twigs, dead leaves, straw, hay, grass clippings, green leaves, compost and topsoil.\nPhoto: Via Pixabay.com\nThe French Intensive Gardening method was re-established in a two acre garden plot just outside of Paris in the late 1800’s. The purpose was to grow an abundance of vegetables year round in a several mid-sized growing beds for the home and markets. Generally, a wide bed (5ft in width) is dug approximately 12 inches in depth. The soil from this bed is placed to the side. At the bottom of the trench, the soil is turned another 12 inches and then loosened with a sturdy garden fork and 1/3 yard of compost added. An additional bed is dug utilizing this same technique. After this is done, put the reserved soil from the first bed is placed back into the trench and mixed with 1/2 yard of compost (or manure). Narrow foot paths no more than 6 inches should be added between the beds to control the plants growing process thermally. The methodology is to create wide and higher elevated beds to increase root stimulation and to employ close quarter plantings to increase yields and weed retention.\nThe Deep Mulch Gardening method was made popular by gardening expert Ruth Stout in the 1960’s, offers a low maintenance-no work philosophy. Garden beds are covered in large amounts of hay, straw, leaves, pine needles, sawdust and vegetable waste periodically to create a barrier to deter weeds and enriching existing soil underneath as it gradually decomposes. When starting a new bed, it is recommended to mulch at least 8 inches thick over a planting area. The mulch would need to be reapplied generously as needed. It would take a few years to obtain nutrient rich soil but once established, can generate copious amounts of produce with little effort. However, you can plant directly in the bed. Just brush aside the mulch until you see soil and then plant your seed or seedlings.\nThe Lasagna Gardening movement was conceived by Patricia Lanza and is a method of layering compostable material on top of a planting area to form a large mound which, over time, will decompose into viable and loamy soil and compost. The material normally used for layering is wet newspapers, peat moss, sand, compost, grass clippings, shredded leaves and wood ash. This natural act of decomposition mimics the evolution life on forest floors.']"	['<urn:uuid:a84a05fb-b7ea-4d3d-8da3-ce9ae80b8d6d>', '<urn:uuid:06c714b4-0ee6-44fa-a526-f11c95642c6d>']	factoid	with-premise	long-search-query	similar-to-document	multi-aspect	novice	2025-05-01T23:55:16.606337	21	83	1379
457	As a sports medicine researcher, I'm interested in understanding how modern technology can help prevent heat-related injuries in athletes. What are the key technological tools available for monitoring athletes' conditions, and what are the essential physiological indicators we need to track?	There are several technological tools and physiological indicators crucial for preventing heat-related injuries. Modern wearable devices like fitness trackers and smart clothing with embedded sensors can monitor vital signs, heart rate, and muscle activity in real-time. These can be complemented with GPS tracking devices to monitor performance metrics. For physiological monitoring, key indicators include: body weight (where a 2% loss is significant), urine color (deep yellow to brown indicates dehydration), and core temperature (above 104°F indicates heat stroke). Athletes should be monitored for trouble signs including nausea, incoherence, fatigue, weakness, vomiting, cramps, weak rapid pulse, flushed appearance, visual disturbances, and unsteadiness. Data analytics tools can also help predict injury likelihood and optimize training regimens based on these measurements.	"['Heat injuries are a serious issue, particularly for athletes.\nLet\'s look at some key facts:\n- ""There\'s no excuse for any number of heat stroke deaths, since they are all preventable with the proper precautions."" ( )\n- ""The most important factor in the treatment of EHS [exertional heat stroke] is the timeliness of rapid cooling, preferably performed on site by whatever means available."" ( )\n- Acclimate to the heat over a two-week period. Note: being acclimated does not mean being conditioned (fit for playing sports). Conditioning is a separate process that takes months.\n- The athlete must be weighed at the beginning and end of each day of training. Greater than a 2% bodyweight loss is significant, and each pound lost must be replaced by 16-24 ounces of water.\n- Pay attention to urine color. Deep yellow to brown indicates probable dehydration.\n- Trouble signs of heat illness include nausea, incoherence, fatigue, weakness, vomiting, cramps, weak rapid pulse, flushed appearance, visual disturbances and unsteadiness.\n- Create an athlete buddy system to report any suspected heat issues.\n- An ice bath and ice packs must be field side.\n- The organization must have a heat plan for revising practices/games based on the use of a Wet Bulb Globe Thermometer (preferred) or the Heat Index.\n- All stakeholders please be familiar with the National Athletic Trainers\' Association Position Statement:\nThe sad case of Jordan McNair, the Maryland offensive lineman who died of heatstroke over the summer, has put a spotlight on playing and practicing in the heat.\nWhat does a parent, coach and administrator need to know to properly manage a heat illness and prevent them? ""The identification of symptoms related to heat injury is crucial. Once symptoms have been identified, treatment is relatively straightforward"" ().\nIn heat illness, there are two major issues—dehydration and increased body heat or hyperthermia. They may occur together or independently.\nWhat Is Dehydration?\n""Dehydration is a condition that occurs when the loss of body fluids exceeds the amount of fluids taken in and disrupts the balance of minerals in body fluids."" Greater than a 2% bodyweight loss can impair performance () and lead to dangerous health consequences.\nA recommended way to monitor hydration is called the WUT method ().\n- W = Weight. Did I gain or lose weight? Maintain a day-to-day stable body weight by weighing yourself first thing every morning.\n- U = Urine. Is my morning urine dark yellow? A reduced daily urine frequency and darkening of urine color in a sample taken during the first urination of the morning may be an indication of dehydration.\n- T = Thirst. Am I thirsty? The absence of thirst does not indicate the absence of dehydration. However, the presence of thirst is an indication of dehydration and the need to drink. Therefore, if thirst is present, combine that with urine or body weight information to be more certain.\nWhat is Hyperthermia?\nHyperthermia is when the body\'s core temperature rises. A body core temperature greater than 104 degrees Fahrenheit is considered heat stroke or what the medical literature calls exertional heat stroke. This is a medical emergency.\nContrary to popular belief, heat illnesses do not necessarily exist on a continuum. You do not need to have heat cramps or faint before you have heat exhaustion or heat stroke.\nHeat illnesses consist of:\n- Heat Cramps\n- Heat Rash\n- Heat Syncope (fainting)\n- Heat Exhaustion\n- Heat Stroke\nA cramp is involuntary contraction of a muscle. The original theory (1904) was that these cramps were caused by dehydration and electrolyte imbalance due to exercise. A new theory (1997) proposed that training leading to muscular overload and then fatigue caused the cramp. Which theory is correct? We are not quite sure, so both issues must be addressed when treating heat cramps.\nHeat Rash is caused by blockage of the sweat ducts, which results in the leakage of eccrine sweat into the epidermis or dermis. Small, pinkish pimples are usually found on body areas covered by clothing. These pimples can develop within minutes or hours after the stimulation of sweating and typically resolve within one hour of cooling down. Individuals with heat rash are at particularly high risk for heat exhaustion during exertion in hot weather, because their ability to dissipate heat by means of sweat evaporation is impaired.\nHeat fainting usually occurs in ""unfit or heat-unacclimatized persons who stand/exercise for a long period of time in the heat or during sudden changes in posture in the heat."" (Ref)\nHeat exhaustion is the inability to exercise effectively. Signs and symptoms include an elevated body temperature (greater than 104 degrees Fahrenheit), dehydration, profuse sweating, loss of coordination, dizziness, fainting, GI/muscle cramps, headache, nausea/vomiting, diarrhea and weakness.\nThe most important skill for a parent, coach or administrator is observation. Look for the ""trouble signs"" of heat illness: ""nausea, incoherence, fatigue, weakness, vomiting, cramps, weak rapid pulse, flushed appearance, visual disturbances, and unsteadiness."" An important point is that an athlete with heat stroke may be sweating profusely. ()\nThere is no excuse for lack of preparedness for heat illnesses. Here are three sets of guidelines and consensus statements that go into great detail:\n1. Get a thorough sports physical. Answer the questions in.\n2. Get acclimated to the heat. Spend at least two weeks outside performing physical activity BEFORE the first sports practice.\n3. Get fit. How long does it take to get fit? How out of shape is the athlete? It can take several months to develop a good sports fitness baseline.\n4. Weigh yourself twice per day. If you see more than 2 percent bodyweight loss, report this to the organization and make sure you rehydrate properly. In other words, stay hydrated all the time.\n1. Make sure your athlete gets a thorough sports physical.\n2. Understand heat illnesses and what your athlete must do to prepare.\n3. Check with the organization to make sure there is a complete emergency action plan in place, that the coaches are trained, and that an ice tub is field-side. If not, are you going to allow your athlete to participate with this organization?\n4. Weigh your athlete twice per day. If you see a more than 2 percent bodyweight loss, report this to the organization and make sure your athlete rehydrates properly.\n1. Take theCourse. You say it is not required? Take it anyway. It\'s free and it is just that important.\n2. Make sure you have an ice and an ice tub field-side.\n3. Pay attention to your athletes.\n4. Monitor the heat using either a Wet Bulb Globe Thermometer or the Heat Index.\n1. Preparticipation physicals for athletes\n2. NFHS Heat Illness Prevention course for all coaches\n3. Ice tubs on the sidelines\n4. A heat plan for practice/game revisions based on Wet Bulb Globe Thermometer (preferable) or Heat Index readings.\n5. Athletic Trainer at games and practices is the best case scenario.\n6. A safety system designed to educate coaches and parents as well as document and communicate on-field injuries with an oversight plan for administrators. TeamSafeSports.\nPhoto Credit: skynesher/iStock\n- The Dangers of Heat Stress for Athletes\n- How to Stay Hydrated When It\'s Hot and Humid\n- How to Prepare Your Body for Hot Weather Training', 'Technology has permeated every aspect of modern life, and the world of sports is no exception. From enhancing athletic performance to revolutionizing the spectator experience, technology has fundamentally changed the way we engage with sports. In this article, we will explore the significant impact of technology on sports, from wearable devices to virtual reality.\nWearable Technology and Performance Enhancement\n- Fitness Trackers: Wearable fitness trackers like Fitbit and Apple Watch have become ubiquitous, allowing athletes and enthusiasts to monitor their physical activity, heart rate, and sleep patterns. These devices provide valuable data for tracking progress and optimizing training routines.\n- Smart Clothing: Advances in smart textiles have given rise to clothing with embedded sensors that monitor vital signs, body movement, and muscle activity. Athletes can wear these garments to gain real-time insights into their performance and reduce the risk of injury.\n- GPS and Tracking Devices: GPS technology enables athletes to track their routes, speed, and distance accurately. This data is particularly valuable in sports like running, cycling, and soccer, where precise performance metrics are crucial.\nData Analytics and Performance Optimization\n- Data-Driven Coaching: Coaches and athletes now have networthhive access to sophisticated data analytics tools that analyze performance metrics, biomechanics, and game statistics. This data-driven approach allows for more precise coaching and training regimens.\n- Predictive Analytics: Predictive analytics algorithms can forecast an athlete’s likelihood of injury based on data, helping teams implement preventive measures and reduce the risk of injuries.\n- Performance Simulation: Technology enables athletes to simulate game scenarios and practice under various conditions. This is particularly valuable in team sports where tactical preparation is critical.\nVirtual Reality (VR) and Augmented Reality (AR)\n- Training and Simulation: Virtual reality and augmented reality are used to create immersive training environments, allowing athletes to practice in realistic scenarios. This is particularly beneficial in sports like golf, where players can practice on virtual courses.\n- Fan Engagement: AR enhances the fan experience by overlaying digital information and graphics onto the live sports broadcast. Viewers can access player statistics, replays, and additional data in real time.\nInnovations in Sports Equipment\n- Advanced Materials: Sports equipment manufacturers are developing materials that are lighter, more durable, and designed to optimize performance. This includes carbon fiber in tennis rackets and aerodynamic designs in cycling.\n- Biometric Equipment: Athletes use biometric devices, such as heart rate monitors and muscle oxygenation sensors, to fine-tune their training and racing strategies.\nInstant Replay and Referee Assistance\n- Video Review: Video replay technology allows referees and officials to review key moments in a game, ensuring accurate decisions in real time.\n- Goal-Line Technology: In soccer and other sports, goal-line technology determines whether a ball has crossed the goal line, eliminating controversy over disputed goals.\nFan Engagement and Virtual Stadiums\n- Virtual Stadiums: With the advent of virtual stadiums and 360-degree camera views, fans can enjoy an immersive experience from the comfort of their homes.\n- Interactive Apps: Sports apps provide real-time updates, live streaming, and interactive features like virtual cheers and fan engagement polls.\nChallenges and Ethical Considerations\nWhile technology offers many benefits, it also presents challenges, including data privacy concerns, potential overreliance on technology, and issues related to equitable access to advanced equipment and training methods.\nThe impact of technology on sports is profound, influencing athlete performance, coaching methods, fan engagement, and the overall sports experience. As technology continues to evolve, the boundary between sports and innovation will blur further, providing new opportunities and challenges for athletes, fans, and sports organizations alike. Whether it’s wearables that help athletes monitor their health or virtual reality that immerses fans in the action, technology is shaping the future of sports in exciting and transformative ways.']"	['<urn:uuid:2b59e128-5fa8-4dab-a865-39233d938cfc>', '<urn:uuid:4054d352-5490-4b79-adcf-c360469da7ff>']	open-ended	with-premise	verbose-and-natural	similar-to-document	multi-aspect	expert	2025-05-01T23:55:16.606337	41	118	1825
458	Being an expert in bridge architecture, I'm wondering how do the total lengths of the Burlington-Bristol Bridge and the Veterans Memorial Bridge compare to each other?	The Burlington-Bristol Bridge has a total length of 2,301 feet, while the Veterans Memorial Bridge is significantly longer at 6,657 feet including spans over land.	"['By Paul K. Nolan, PE\nThe Burlington-Bristol Bridge is a steel-member, truss bridge with a vertical lift span. It crosses the Delaware River via Route 413 connecting the City of Burlington in New Jersey to the Borough of Bristol on the Pennsylvania side. Built in May 1931, the bridge is situated between the Tacony-Palmyra Bridge (downstream) and the Delaware River-Turnpike Toll Bridge which sits upstream. Constructed of steel, the total length of the bridge is 2,301 feet (701.3 m), 20 feet (6.1 m) wide, and the longest span is 540 feet (165 m). The lift span is 61 ft. high when closed at mean high water and raises to 135 ft to allow large vessels to navigate the Delaware River.\nAs part of the Burlington County Bridge Commission’s (BCBC) five-year capital improvement plan, the deck structure (viaduct) leading to the bridge span on the New Jersey side of the bridge was scheduled for replacement. The Bridge is a 2-lane crossing. In a perfect world, closing both lanes and working only at night, the estimated time for repairs was about 30 overnight closures. However, due to weather or other unforeseen conditions, those 30 nights might not occur in succession, which could extend the project timeline. Closing only one lane would have subjected the steel-framed viaduct structure to vibrations caused by passing trucks which could also slow down the process. Working within these parameters with live traffic is the norm for roadway workers and comes with a mitigated risk. In addition, every time a work crew enters or exits a traffic zone to perform the work, including the set-up and break-down of traffic protection, it poses additional risk to their safety.\nLighter than usual traffic patterns caused by the COVID-19 pandemic and the New Jersey Governor’s executive order mandating citizens to stay-at-home created a unique window of opportunity for the BCBC to rethink the project program. Taking full advantage of the situation, the BCBC approved completely closing-down the bridge for the shortest amount of time possible. This decision would maintain project continuity and increase worker safety while causing the least amount of traffic disruption and inconvenience to the travelling public. On Thursday night June 18, 2020 the Bridge was closed for four consecutive days and nights. This time envelope also had a better potential success rate because projected weather reports for only four consecutive days are more reliable than scoping out longer periods. The construction would continue through Sunday June 21st, with a scheduled re-opening on Monday morning.\nDeck-off, Deck-on Staging\nFaced with new parameters, the Contractor Cornell & Company Inc., BCBC and Maser Consulting Engineers, hired to oversee the construction inspection and administration process, collaborated to completely re-think and coordinate the project orchestration. The overall program consisted of the removal of all the 40 ft deck sections on the viaduct on the south side bridge approach. The existing decks were methodically removed from the beginning of the viaduct in a south to north direction, toward the bridge tower span. Once the deck removal process was far enough ahead to create a pre-established safety zone big enough for two cranes to safely function independently, the new deck installation commenced following the same south to north path. This staging enabled two separate operational zones to function simultaneously, lifting decks on and lifting decks off, both toward the same goal. Once this tempo was established, the job progressed like clockwork.\nAssembled off-site, the new prefabricated steel-member decks were surfaced with a pre-cast concrete to create a sub-flooring prepared to accept the eventual asphalt layer. Once moved to the job site, the decks were systematically stored and placed in unison next to the bridge where rebar and sidewalks were installed. Once lifted, positioned and secured on the viaduct, steel side rails were installed, and concrete was applied to the non-expanding joints to keep the slabs together. After all decks were in place, a tack coat to make the asphalt adhere better was installed and the roadway surface. The asphalt was laid in tandem echelon formation and completed with traffic striping.\nAs a result of a previous drone inspection using high-resolution imagery flown by Maser Consulting’s UAS Division, while the deck structure was open, other repairs were made to the upper and lower sections of Pier 8, one of the main bridge supports and the cleaning and painting of all existing steel members.\nAs most people freely drive over a bridge any time during the day or night, they aren’t thinking about the immeasurable effort it takes to keep our critical infrastructure safe and viable for everyone to use. Which is exactly as it should be. While the COVID pandemic wreaked havoc on the health and welfare of our global populations, it conversely created a window of opportunity for the Bridge Commission to make some timely, proactive determinations to facilitate this project’s timeline that proved to be in everyone’s best interest.\nNot only was the project’s progression seamless, it was completed ahead of the anticipated timeframe by half-a-day and the Bridge was completely re-opened by about 6 p.m. Sunday evening.', '|Veterans Memorial Bridge\nLooking west over the Susquehanna River\n|Official name||Veterans Memorial Bridge|\n|Carries||2 lanes of PA 462|\n|Locale||Wrightsville, Pennsylvania and Columbia, Pennsylvania|\n|Design||concrete deck arch bridge|\n|Total length||6,657 feet (2,029 m)|\n|Width||48 feet (15 m)|\n|Longest span||185 feet (56 m)|\n|Opened||September 30, 1930|\n|Toll||was $0.25 for cars when opened; toll no longer collected|\n|Daily traffic||10,350 (2004)|\nThe Columbia–Wrightsville Bridge, officially the Veterans Memorial Bridge, spans the Susquehanna River between Columbia and Wrightsville, Pennsylvania, and carries Pennsylvania Route 462. Built originally as the Lancaster-York Intercounty Bridge, construction began in 1929, and the bridge opened September 30, 1930. On November 11, 1980, it was officially dedicated as Veterans Memorial Bridge, though it is still referenced locally as the Columbia–Wrightsville Bridge.\nDesigned by James B. Long and built by Glen Wiley and Glenway Maxon (Wiley-Maxon Construction Company), it cost $2,484,000 (equal to $35,067,944 today) plus $56,400 (equal to $796,229 today) paid as an early completion bonus. Constructed of reinforced concrete, the 5,183-foot (1,580 m)-long bridge (6,657 feet (2,029 m) including spans over land) has 27 river piers, 22 approach piers, a 38-foot (12 m)-wide two-lane roadway, and a 6-foot (1.8 m)-wide sidewalk. 100,000 cubic yards (76,000 m3) of concrete and 8 million pounds of steel reinforcing rods were used, and coffer dams were built to aid in construction. Each span consists of three separate concrete ribs connected at five points by horizontal concrete struts, with the longest span measuring 185 feet (56 m).\nIn nominating the present Columbia–Wrightsville Bridge as an engineering landmark, the Pennsylvania section of the American Society of Civil Engineers noted that it is ""a splendid example of the graceful multiple-span, reinforced-concrete arched form popular in early 20th Century highway bridges in the United States."" The bridge is designated State Route 462 and is listed on the National Register of Historic Places, and is also a Historic Civil Engineering Landmark. Instead of being replaced by a name such as the Old Lincoln Highway, its name is a kept part of the historic Lincoln Highway in local naming, (meaning it\'d previously carried U.S. Route 30 (US 30) which as a modern four-lane highway runs parallel to this older earlier road and lead to the two lane stretch being renamed Route 462 as it is today), the nation\'s first transcontinental highway, connecting a series of local highways and stretching from New York City to San Francisco. The opening in 1940 of the cross-state Pennsylvania Turnpike, a part of Interstate 76, subsequently provided faster passage.\nTolls of 25 cents per vehicle (equal to $3.53 today) were charged when the bridge first opened and ended on January 31, 1943, when the bond issue was retired. Some time after World War II, the original bridge lights were replaced with newer lighting. Two of the original bronze light fixtures can still be seen on the front lawn of the Frank Sahd Salvage Center along Route 462 in Columbia.\nIn the 1970s, the state considered closing the bridge permanently due to the recently constructed Wright\'s Ferry Bridge nearby, but local residents objected. In the mid-1970s, it was given a major overhaul instead, and was closed only temporarily. A few years later, the bridge was once again closed briefly so that a weather-resistant coating could be applied to the roadway. Today, the bridge is maintained by PennDOT and is still considered the world’s longest concrete multiple-arch bridge. Its annual average daily traffic (AADT) was 10,350 as of 2004. It is the fifth bridge to span the river at this general location.\nThe other present-day Columbia-Wrightsville bridge is the Wright\'s Ferry Bridge, the sixth bridge to cross the river between the two towns. Also known as the Route 30 bridge, it stands about half a mile north of the Veterans Memorial Bridge. (Wright\'s Ferry was one of the original names of Columbia.) G.A. & F.C. Wagman, Inc. began its construction in March 1969, and the bridge opened on November 21, 1972. It was commissioned by the Commonwealth of Pennsylvania in the 1960s to relocate Route 30 and bypass the river towns of Wrightsville and Columbia. Costing $12 million (equal to $67,656,325 today), it is constructed of reinforced concrete and steel and has 46 equal sections on 45 piers. US 30 crosses it as a divided two-lane roadway, and there is no walkway. Tolls were never collected on this bridge. About a year after its opening, the bridge was shut down briefly so that an experimental weather-resistant coating could be applied to its roadway.\nConstruction of the first Columbia–Wrightsville Bridge was begun in 1812 and completed December 5, 1814, by J. Wolcott, H. Slaymaker, S. Slaymaker at a total cost of $231,771 (equal to $2,607,240 today), which was underwritten by the newly formed Columbia Bank and Bridge Company. The bridge was 5,690 feet (1,730 m) long and 30 feet (9.1 m) wide and had 54 piers and twin carriageways. Constructed of wood and stone, the covered bridge also included a wooden roof, a whitewashed interior and openings in its wooden sides to view the river and surrounding areas. It stood immediately south of the present-day Wright’s Ferry Bridge along Route 30. Tolls were $1.50 for a wagon and six horses (equal to $19.33 today), and six cents for pedestrians (equal to $0.77 today). It was considered the longest covered bridge in the world at the time. The bridge accommodated east-west traffic across the Susquehanna River for 14 years before being destroyed by ice, high water and severe weather on February 5, 1832.\nConstruction of the second Columbia–Wrightsville Bridge, another covered bridge, started mid-1832 and was completed in 1834 (opening on July 8, 1834) by James Moore and John Evans at a cost of $157,300 (equal to $3,715,950 today). It was 5,620 feet (1,710 m) long and 28 feet (8.5 m) wide and also enjoyed the distinction of being the world’s longest covered bridge. The wood and stone structure had 27 piers, a carriageway, walkway, and two towpaths to guide canal traffic across the river. Tolls were $1.00 for a wagon and 6 horses (equal to $23.62 today), and 6 cents per pedestrian (equal to $1.44 today). Much of the mostly oak timber used in its construction was salvaged from the previous bridge. Its roof was covered with shingles, its sides with weatherboard, and its interior was whitewashed.\nThe structure was modified in 1840 by the Canal Company at a cost of $40,000 (equal to $944,933 today) concurrent with the construction of the Wrightsville Dam. Towpaths of different levels and with sidewalls were added to prevent horses from falling into river, as happened several times when the river flooded. The roof of the lower path formed the floor of upper path. In this way, canal boats were towed across the river from the Pennsylvania Canal on the Columbia side to the Susquehanna and Tidewater Canal at Wrightsville.\nSometime after 1846, a double-track railway was added, linking the Philadelphia and Columbia Railroad to the Northern Central Railway. Due to fear of fire caused by locomotives, rail cars were pulled across the bridge by teams of mules or horses.\nThe second bridge\'s role during the Civil War\nTo prevent the advance of Confederate troops across the river from the Wrightsville (York County) side during the Civil War, the bridge was burned by Union militia under Maj. Granville O. Haller and Col. Jacob G. Frick on June 28, 1863. Civilian volunteers from Columbia had mined the bridge at the fourth span from the Wrightsville side, originally hoping to drop the whole 200-foot (61 m) span into the river, but when the charges were detonated, only small portions of the support arch splintered, leaving the span passable. As Confederates advanced onto the bridge, Union forces set fire to it near the Wrightsville side. Earlier they had saturated the structure with crude oil from a Columbia refinery.\nThe entire structure soon caught fire and completely burned in six hours. Confederate generals Jubal A. Early and John B. Gordon had originally planned to save the bridge despite orders from General Robert E. Lee to burn it, and Union forces under the command of Colonel Jacob G. Frick had burned the bridge, originally hoping to defend and save it. Afterwards, the Columbia Bank and Bridge Company appealed to the federal government for reimbursement for damages incurred from the bridge burning, but none were ever paid. Conservative estimates put the cost of damages with interest today at well over $170 million.\nIn 1864, the bank sold all interest in the bridge and bridge piers to the Pennsylvania Railroad for $57,000 (equal to $859,487 today). The bank eventually went out of business, although the original building is now being renovated into a museum at Second and Locust Streets.\nConstruction of the third Columbia-Wrightsville bridge was started in 1868 by the Pennsylvania Railroad. The covered bridge (5,390 feet long) was completed later that year at a cost of $400,000 (equal to $7,087,000 today). Built of stone, wood, and steel, it included 27 piers, a carriageway, railway, and walkway. It was destroyed September 30, 1896 by a hurricane.\nConstruction of the fourth Columbia-Wrightsville bridge, known as the Pennsylvania Railroad “Iron Bridge,” started April 16, 1897, and was completed May 11, and was considered the fastest bridge-building job in the world at the time. A steel truss bridge made of 200-foot (61 m) long prefabricated sections, it was designed to be resistant to fire, ice, water and wind, elements that had destroyed previous wooden structures. Like the previous bridges, tolls were collected to recover a portion of the half-million dollar investment, equal to $14,174,000 today. Built on the same 27 piers as the previous two bridges, it opened June 7, 1897. The iron and prefabricated steel structure had a railway to carry rail traffic for the York Branch of the Pennsylvania Railroad, and twin carriageways that were shared with pedestrians. Tolls were 20 cents (equal to $5.67 today) for vehicles and four cents per passenger (equal to $1.13 today), and three cents for pedestrians (equal to $0.85 today).\nThe bridge remained uncompleted because a planned upper deck was never built. With the completion of the Lincoln Highway in 1925, vehicular traffic routinely jammed in the late 1920s when vehicles had to wait for trains to pass before crossing the bridge, since the bridge was shared with rail traffic. A fifth bridge (Veterans’ Memorial Bridge) was planned and erected to accommodate vehicular and pedestrian traffic. The “Iron Bridge” carried passenger trains until 1954 and freight traffic until March 13, 1958, and was dismantled for scrap starting in 1963 and ending in November 1964. Its stone piers, dating to pre-Civil War times, still stand today, running parallel to the north side of the Veterans’ Memorial Bridge.\n- List of bridges documented by the Historic American Engineering Record in Pennsylvania\n- List of crossings of the Susquehanna River\n- Semmer, Blythe (August 1997). ""Columbia–Wrightsville Bridge"". Historic American Engineering Record. Washington, D.C.: Library of Congress. p. 3. Retrieved February 1, 2014.\n- Jackson, Donald C. (1996). Great American Bridges and Dams. New York: John Wiley & Sons. ISBN 0-471-14385-5.\n- ""Columbia-Wrightsville Bridge"". History and Heritage of Civil Engineering. Reston, VA: American Society of Civil Engineers.\n- McClure, James (2003). East of Gettysburg, A Gray Shadow Crosses York County, PA. York, PA: York Daily Record/York County Heritage Trust. ISBN 0-9710416-4-4.\n- Sheldon, George (2006). Fire on the River, The Defense of the World’s Longest Covered Bridge and How It Changed the Battle of Gettysburg. Lancaster, PA: Quaker Hills Press, Inc. ISBN 978-0-9779315-0-7.\n- Town historical markers and plaques provided by Columbia Borough and Rivertownes PA USA\n- Historic American Engineering Record (HAER) No. PA-473, ""Columbia-Wrightsville Bridge, Spanning Susquehanna River at Lincoln Highway (State Route 462), Columbia, Lancaster County, PA"", 13 photos, 1 color transparency, 16 data pages, 2 photo caption pages\n- Veteran\'s Memorial Bridge at Structurae\n- Vital statistics, fifth bridge: http://www.yorkblog.com/yorktownsquare/2005/11/columbiawrightsville-bridge-ce']"	['<urn:uuid:38fe7b65-f229-435e-ae08-666d2138e435>', '<urn:uuid:1ebff28c-b552-45f1-a696-ad0b5da0d427>']	factoid	with-premise	verbose-and-natural	similar-to-document	comparison	expert	2025-05-01T23:55:16.606337	26	25	2820
460	aquarium expert curious about differences between siamese flying fox vs algae eater distinctive features	While the Siamese algae eater and Siamese flying fox look similar, they can be distinguished by their black stripes. The Siamese algae eater has a longer black stripe that extends all the way to the end of its tail fin. In contrast, the Siamese flying fox has a smoother black stripe that ends before the tail fin begins. Additionally, the Siamese flying fox has distinctive flaps near the corner of its mouth that are not present in the algae eater.	['The algae eater is the quintessential addition to any aquarium tank. While you may find yourself getting caught up in the sheer number and choices available to you as you begin your fishkeeping journey, one thing is obvious: you need a way to keep your aquarium clean and healthy for years to come.\nThe easy solution? An algae eater. These delightful creatures fill an important role in your tank’s environment, helping to tidy up tanks by munching on algae wherever they happen to spot it.\nThese fish are active and social, performing well in large groups as well as when housed by themselves. They are easy to feed and will eat just about anything that you put in your tank – but they especially love algae of all kinds!\nAlgae eaters are peaceful and will get along with most fish in a community aquarium. The Siamese algae eater in particular is easy to care for and is a great choice for beginner and expert aquarium hobbyists alike.\n- Siamese Algae Eater Background\n- Siamese Algae Eater Appearance And Behavior\n- Siamese Algae Eater Tank And Water Requirements\n- Decorating A Siamese Algae Eater Tank\n- What Do Siamese Algae Eaters Eat?\n- Siamese Algae Eater Tank Mates\n- Common Siamese Algae Eater Diseases\n- Breeding And Life Spans Of Siamese Algae Eaters\n- Is A Siamese Algae Eater For You?\nSiamese Algae Eater Background\nThe Siamese algae eater, also known as Crossocheilus oblongus, is a freshwater fish species from the Cyprinidae family. This family also contains carp, and so they are close relatives of each other.\nThese fish originated in southeast Asia, hailing from the wilds of Malaysia and Thailand. However, you can now find Siamese algae eaters in just about every country in the world as they are bred prolifically for the aquarium trade. These fish are some of the best algae eaters you can find. They move around frequently and can clean your entire tank in a matter of minutes.\nIn the wild, Siamese algae eaters are found in densely vegetated streams and large rivers. They live nearby and in the same fashion as Asian carp. The tropical waters in which they are found are usually somewhat acidic, and tend to have a very slow-moving current. They hang out among rocks, logs, and plants. They will spend their time among these shelters, alternately hiding and scouring the surfaces for food.\nIn their native environments, Siamese algae eaters will mostly consume algae, but they will eat anything that sinks to the river bottom. They don’t like to roam and instead will stay around familiar shelters, rarely venturing up to the surface of the water.\nYou can find Siamese algae eaters at just about any pet store. They are so popular that they are very easy to find. They are also incredibly affordable, with prices starting at just $3 to $5 per fish. The Siamese algae eater is an excellent choice for a beginner, as it can keep your tank clean and presents minimal disruptive behaviors to your tank environment. Keep in mind, though, that like other fish, Siamese algae eaters do produce a significant amount of waste. You’ll want to avoid overcrowding for this very reason.\nThese fish are often confused with a similar species, the Siamese flying fox. Although they look similar, they are different species with different care requirements. The Siamese algae eater will have a longer black stripe that stretches to the end of its tail fin. While the Siamese flying fox also has a black stripe, it is smoother and ends right before the start of the tail fin. The Siamese flying fox will also have flaps near the corner of its mouth.\nSiamese Algae Eater Appearance And Behavior\nThis species of fish has a unique appearance that distinguishes it from other algae eaters. It has a long, slender body that can span up to six inches in length. They can be either a light gold or gray color, but all fish will have a thick black stripe that reaches from the head to the tail.\nThis stripe sometimes fades. Most of the time, it is nothing to worry about, as it could simply be a mating display of courting. However, these stripes sometimes fade as a result of stress or illness, which you will need to minimize in the tank. Very rarely, the stripe will fade as the fish tries to camouflage itself – this is not very common in the aquarium setting but happens frequently in the wild.\nThere is little sexual dimorphism (or difference) between males and females. You usually will not notice these differences until they are about three or four years of age. Then, the only difference exists in the difference between the sizes of the fish – females will be somewhat larger than the males and may also have abdomens that are slightly more rounded.\nSiamese algae eaters are bottom feeders, and so they will spend most of their time hanging out at the bottom of your tank. Very rarely will they rise to the middle or the top of the water column. Instead, they will swim around near the bottom sections of your tank until they happen upon a spot covered in algae. They will stay there until the algae is mostly gone.\nIf you keep several Siamese algae eaters together, they will form dense, close knit groups. They will feed together in the same area, even if there isn’t exactly enough algae to sustain them all!\nThese fish are very rarely aggressive, but they are extremely energetic. They like to dart around the tank in quick, rapid movements, and so while they won’t necessarily attack other fish, their presence can be disturbing to some calmer species.\nSiamese Algae Eater Tank And Water Requirements\nYou should do your best to mimic the natural environment of the Siamese algae eater when you are setting up your tank. Remember that the water should be slightly acidic, and that you should include plenty of plants to keep the water clean and oxygenated.\nTry to use a substrate that is fine and soft, such as sand, as this will make it safer to swim around near the bottom of the tank. Because Siamese algae eaters spend so much of their time at the bottom of the tank, there is a good chance that they can scratch their sensitive bodies or damage their barbels if you use a harsher, sharper substrate.\nThe water of your tank should be kept fairly warm. You will need a heater to keep temperatures within the ideal range, which is between 75 and 79 degrees Fahrenheit. The water hardness should be between 5 and 20 dH. These fish prefer slightly acidic waters, with a pH between 6.5 and 7.0, but they can tolerate a range. Try to keep it between 6.0 and 8.0 to ensure the health of your fish.\nThere are no specific requirements of this fish in regards to water flow or current, which may be astonishing as they are naturally found in rivers. While they prefer slower moving waters (the weaker the better), Siamese algae eaters really can adapt to most levels of flow within your tank.\nThe bigger the tank, the better when it comes to your Siamese algae eater. You can keep one fish per 20 gallon tank, but you should add an extra 10 gallons of space per every fish that you add.\nDecorating A Siamese Algae Eater Tank\nPlants and other decorations are critical in a Siamese algae eater tank for multiple reasons. The first is that they help to keep the water clean, but the second (and arguably most important) is that plants and other structures provide your fish with places to hide. This will help your fish feel safe and at home in your aquarium tank.\nYour fish may start nibbling at plants if they are hungry. You can prevent them from doing this by maintaining an adequate feeding schedule, but you can also choose healthy and hardy live plants that will be able to hold up to the constant stress of the nibbling. Consider species that are quick to grow and rejuvenate, like hornwort, anacharis, or Java fern.\nProviding plenty of structures in which your Siamese algae eaters can hide is also important. They need places to escape their tank mates, particularly if there are other bottom dwellers or somewhat aggressive fish. You can create caves around the tank, which will give your fish somewhere to escape. The Siamese algae eater is not territorial, so you shouldn’t have to worry about any fights related to these hiding places.\nSiamese algae eaters can jump and are very active. While you might not notice or observe this behavior on a regular basis, there is always the potential for your Siamese algae eater to jump out of the tank. As a result, you should always keep a tight-fitting lid on the tank. This will ensure that you don’t have to deal with an escape artist – which could be potentially fatal for your fish.\nWhat Do Siamese Algae Eaters Eat?\nAs the name implies, Siamese algae eaters mostly eat – you guessed it – algae! However, in the wild these creatures eat a variety of foods. You might find Siamese algae eaters consuming vegetation, plant matter, and algae, as well as other items they find, like dead fish and insects. They are true omnivores, eating anything they come across or are able to scavenge.\nAs a result, they are easy to take care of in the aquarium. They are not picky eaters and will eat just about anything you choose to give them. Good choices include flake and pellet foods, as well live foods and algae wafers. While they can tolerate most live food options, good choices include brine shrimp and bloodworms. In addition to fresh live foods, you can also feed frozen food.\nWhen you are feeding your Siamese algae eaters, remember that sinking foods tend to work best. They will fall past other fish that are hanging out closer to the top of the tank and will be able to make their way down to your bottom-dwelling algae eaters.\nIt can be tough to find a balance between over- and underfeeding your Siamese algae eaters. They will already be consuming algae and plants in the tank before feeding time, and it can be tough to tell how much they’ve actually eating. If you feed your fish too much, they will stop eating algae in favor of the foods you’re giving them.\nThese fish will gladly eat all day if you allow them, so try to limit feeding to just the amount that they can finish in a couple of minutes. You only need to feed them once a day, but you may need to feed your other fish more often than that. Keep that in mind as you develop a feeding schedule that will hopefully work for everybody in your aquarium.\nSiamese Algae Eater Tank Mates\nSiamese algae eaters are friendly fish that get along with most other community fish. Since they spend most of their time at the bottom of a tank, you must consider who else will be living there. Some bottom dwellers can be aggressive or downright mean, so you will want to avoid fish like red tail sharks. These fish tend to harass and bully others in order to protect their territory – even members of their own species. Because algae eaters are more shy and not prone to conflict, they will spend most of their time swimming away and hiding from these aggressive species.\nOtherwise, Siamese algae eaters are great candidates for community tanks because they are so peaceful and easygoing. You can choose peaceful bottom-dwellers like the Corydoras catfish, or you can select fish species that prefer to swim in the other areas of the tank. This will reduce the potential for any territorial disputes or problems.\nTry to avoid adding fish that have a reputation for being aggressive, as they will attack or even try to eat your algae eaters. This is especially true when it comes to Siamese algae eaters that are young or are new to the tank. Avoid cichlids, who really should be kept in species-only tanks as it is, as well as other aggressive species like oscars.\nSome fish species that have good potential for being members of a Siamese algae eater-friendly community include guppies, tetras, and danios. These fish are small and not aggressive. Other good choices include barbs and gouramis, who are large but do not behave aggressively.\nYou can even include non-fish species like cherry, amano, or ghost shrimp. You could even try out nerite snails. These organisms all eat algae, too, so you may have the opportunity to witness various algae eating behaviors as the animals interact with each other. They will add diversity and interest to your tank, while at the same time helping to keep it clean.\nYou can keep multiple Siamese algae eaters in the tank. These fish are unique in that they tend to school, so groups of four to six are best if you want to witness this schooling behavior. Just remember to increase the size of your tank when you add more fish, however, or you could have an issue of overcrowding on your hands.\nThat being sad, Siamese algae eaters do not have to be kept with other members of their species. You can keep them in pairs or as singles, which gives you plenty of options when it comes to how you want to populate your fish tank.\nKeep in mind that one mistake people frequently make when raising Siamese algae eaters (particularly in multiples or in the presence of other algae eater) is that they assume that they do not need to clean the tank – ever. Remember, just because you have algae-eating species in the tank doesn’t mean they can handle the entire bioload themselves! They are still contributing waste and you will still need to put in an effort to keep your fish tank clean.\nCommon Siamese Algae Eater Diseases\nThere are few diseases to which Siamese algae eaters alone are prone, but they can be affected by the same diseases that habitually affect freshwater tank species. Most diseases will give off clear symptoms so that you can treat them quickly, but others may present more hidden symptoms that can be harder to detect. Checking your fish on a daily basis can help you catch any problems early on – before they become life-threatening.\nIch is one of the most common disease in freshwater aquariums. This illness is caused by a parasite that creates small white dots around the body. You may notice your fish rubbing itself against items in your tank as it attempts to “itch” itself. This can be prevented by conducted regular water changes. Dirty water is to fish as polluted air is to humans- it does their health no good. Clean your tank once every two weeks to reduce the likelihood of toxins building up in the water and making your fish sick.\nWhile you can purchase treatments to heal conditions like ich as well as other common bacterial, viral, and parasitic conditions, there is often no reason to – preventative care can be more effective than the most expensive medications. Keep your tank clean and only feed high-quality foods. Cheap foods – or foods that are fed at irregular intervals – can cause constipation and bloating. These issues can lead to organ dysfunction, too.\nBe careful what (or who!) you add to your tank. Some decorations can carry toxins, and if you introduce water from other tanks (including the water from when you purchase new fish), this can also be dangerous. Whenever you add new fish to your tank, make sure you quarantine them first. This will help you to determine whether they are healthy before potentially introducing new diseases to your tank.\nBreeding And Life Spans Of Siamese Algae Eaters\nSiamese algae eater can be bred in the home aquarium, but it’s incredibly difficult to do. In order to be successful, you will need to use hormones, which is what the commercial farms do in order to supply pet stores with a steady supply of these fish.\nSexing the fish is particularly hard, as differences in the genders generally don’t appear until later in life. Although females are larger than males, they are only slightly larger, and this takes a keen eye to detect.\nYou can encourage spawning by altering water conditions to those they would experience in the wild during their breeding season. Besides this, there is little you can do to encourage breeding – and there is little information available about individuals who have been successful in this attempt in the past.']	['<urn:uuid:291d6d61-fcdb-4fc7-9b0b-d948014e16cf>']	open-ended	with-premise	long-search-query	distant-from-document	single-doc	expert	2025-05-01T23:55:16.606337	14	80	2807
461	What activities does the Gravitas Senior Center offer?	The Gravitas Senior Center offers several programs including: 'Young Forever' for exercise activities like dance classes and chair yoga; 'Games for Brains' featuring computer games, trivia, and board games; 'Lecture Me Now' with presentations by aging experts and entertainment performances; and 'Meals for Life' which provides hot breakfast and lunch following federal nutrition standards.	"['Sample In-Kind Donation Letter Request\nWhat Constitutes a Gift In-Kind?\nIn-kind donations, usually a part of a nonprofit\'s overall funding plan, include contributions of goods or services. They are not donations of cash. Examples include:\n- Goods, such as computers, software, office furniture, or equipment.\n- Services, such as the use of a venue for a meeting or event, copying and mail service, and accounting services.\n- Expertise, such as tax advice, legal services, development of marketing materials or a website, and strategic planning.\n- Equivalents of cash, such as bonds, mutual funds, or stocks.\nIn-kind donations can come from individuals but are most likely from corporations and businesses.\nHow Does a Nonprofit Ask For an In-Kind Gift?\nAlthough you may want to simply make a phone call to make your request, corporations may prefer a letter, but not usually a formal proposal such as you would likely send to a foundation. The letter should be short and spell out precisely what you need.\nSome corporations do have online application forms, so check to see if this is the case. A call to the corporate office that handles corporate giving will do to get this information or a visit to the business website.\nBelow is a fictional sample letter to a corporation requesting a gift-in-kind, based on a format recommended by Beverly A. Browning, author of Grant Writing for Dummies.\nNotice that, even though this request is a letter, it is concrete. It describes the work of the organization in detail and spells out exactly what it needs from this company. The more specific you can be, the easier it is for the company to say yes.\nBesides the details of your request, include a story that will touch even a corporation. In this letter, the postscript contains that story.\nAugust 26, 2015\nThe Gravitas Neighborhood Senior Center\n90123 S. Lindenwood Lane\nMonsoon, IA 14399-5678\nMs. Lauren M. Funder\nSenior Vice President and Corporate Giving Officer\nCooper Restaurant Equipment Corporation\n10903 Birdseye Terrace\nMonsoon, IA 28281-7777\nDear Ms. Funder:\nTwo hundred of the 425 people over the age of 65 who use our senior Center are considered to be living below the state poverty level. Most of those receive their morning and noon meals through our meals program on-site.\nIn the past two years, the number of older adults living below the poverty level in Butler County, District 9, has risen 10 percent annually. Many of those have found their way to our Senior Center and to our daily meals program, where we serve nearly 300 breakfasts and lunches daily for a sliding fee based on income.\nThe neighborhoods surrounding our senior Center contain primarily lower-middle-class families, the working poor, and older people living on modest fixed incomes in their small homes, senior apartments, or with their adult children. The Senior Center is the only possible safe environment for most, outside their homes, and they come nearly daily for companionship, recreation, and warm meals.\nLocated in Monsoon, Iowa, The Gravitas Senior Center was founded in 1985 by the Butler County Council on Aging, which serves a large senior population throughout the county\'s 75 square miles.\nThe Gravitas Neighborhood Senior Center\'s mission is to provide a safe and nurturing environment to support the social, physical, and health needs of the neighborhood\'s older adults.\nOver 100 volunteers and four full-time staff assist in the Center\'s daily programs and activities throughout the year. The Center offers several outstanding programs such as:\n- Young Forever: An exercise program with subgroups of differing physical abilities. The groups include dance classes, chair yoga, an outdoor walking program, using a 1/2 mile track on the Center\'s grounds, and water aerobics, in the Center\'s indoor pool.\n- Games for Brains: A program of games for varied interests and abilities encompassing computer games, trivia, and puzzles to chess, checkers, and other board games. Several reading groups are included in this program as well as the Brain Olympics program delivered by faculty and students from the University of Iowa.\n- Lecture Me Now: A series of presentations by experts in longevity and aging, as well as entertainment ranging from films and staged performances by the Community Theater of Monsoon, to visits by groups of school children who sing, dance, and perform.\n- Meals for Life: Serving a hot breakfast and a hot lunch that follow federal standards for age appropriate nutrition. In any given week, we provide approximately 800 meals.\nAccording to the May 2015 issue of the American Journal of Gerontology, older adults are 89 percent more likely to be physically and mentally active if they have a safe and attractive place to get together, and if they receive at least one nutritious meal daily.\nThe seniors in our community would not have these advantages were it not for the work of the Gravitas Community Senior Center. Many, who live at or below the poverty level, would never receive a nutritious meal, much less two in one day.\nIn fact, many of the neighborhood\'s elders would find themselves isolated and without safe opportunities to exercise, to socialize, or to invigorate their brains if it were not for our facility.\nThe Center is open six days per week from 8 a.m. until 6 p.m. It feeds, provides social opportunities and exercise of mind and body to the otherwise underserved senior population of our neighborhood.\nThe warmth and laughter within the Center\'s walls attest to the pleasure and health provided by the Senior Center to our community.\nUnfortunately, our meals program has dilapidated and outdated appliances. As the Center\'s Executive Director, I am writing to you to request a gift in kind of a commercial stove and refrigerator manufactured by your company.\nNot only is your business located in Monsoon, Iowa, not far from our Senior Center in the Gravitas neighborhood, but your commercial kitchen equipment is also known for its durability and functionality. I know because I\'ve done extensive research on kitchen equipment, and your company\'s products stand out.\nI have been particularly impressed by your Model 68B2 commercial stove and oven, as well by your 98 cubic foot, model 583J refrigerator. Both of these appliances would work well for our Center considering the number of meals we prepare and the people we serve.\nIf your company chooses to help our Center, you will contribute more than just equipment. You will be a key partner in providing a healthy life for more than 400 older adults each week.\nThe result of your help and our services means that our seniors, many of whom are poor, can live engaged, alert, and physically active lives as long as possible. These elders should never be considered excess baggage but valued members of our community as long as they live.\nThank you so much for taking the time to read this proposal, and please do not hesitate to contact me at 485-312-4890 with any questions about this request. We are badly in need of new kitchen equipment and hope to begin the new year with it in place.\nHoping for your partnership,\nJanice Head, M.A.\nGravitas Neighborhood Senior Center\nEnclosures: annual report, program brochure, and letter from the City of Monsoon\nP.S. As I was writing this letter to you, I received a call from the family of a senior woman, desperate to find a safe place where their mother, recently arrived from New York, could find other people her age to meet in her new community.\nI was able to assure them that their mother would find a welcoming community right here at the Center, as well as many programs that would keep her healthy, active, and alert. I could hear the relief in their voices as they made an appointment to bring their mother to the Center on Monday morning for introductions and a tour.\nGrantspace. ""How can I find sources of in-kind gifts?."" Accessed Jan. 27, 2020.\nGuidestar. ""Corporate Philanthropy Program #7: In-Kind Donations."" Accessed Jan. 28, 2020.\nBrowning, Beverly A. ""Grant Writing For Dummies."" 2016. Consumer Dummies.\nGrantspace. ""How to Use Storytelling for Nonprofits to Get More Grants."" Accessed Jan. 27, 2020.']"	['<urn:uuid:342844e1-d3b2-4617-8736-c4c43d000063>']	open-ended	direct	concise-and-natural	similar-to-document	single-doc	novice	2025-05-01T23:55:16.606337	8	54	1352
462	How do skeptical approaches impact both educational development and industrial energy innovations?	In education, skepticism requires finding a balance between accepting new information and maintaining a questioning attitude - as Shermer explains, it means being 'curious but cautious' and applying rigorous science and reason to test claims. Similarly in industrial settings, this balanced skepticism is crucial when implementing energy efficiency measures. While evidence shows that improved efficiency can deliver benefits across the whole economy and impact GDP, companies often perceive efficiency measures as risky because they require changing processes. This requires careful evaluation of both benefits and risks rather than blind acceptance or rejection.	"['Critical Thinking, Exactly, What Is This?\nThere are two recent articles on Huffington Post that talk about critical thinking: ""Our Orientation Towards Belief"" by Dr. Art Markman and ""What Is Skepticism, Anyway?"" by Dr. Michael Shermer. Markman\'s article was inspired by Shermer\'s TED talk:\nBoth articles emphasize that learning how to think critically is quite different from learning to read. Developing critical thinking goes against an element in our nature. Markman writes:\n""When other people tell us things with great conviction, we are wired to believe what we hear. We cannot maintain a skeptical stance to every new thing we are told, because that would get in the way of our need to learn.""Critical thinking sometimes goes against our desire to learn or survive. Markman uses an example from nature to highlight a difference between animal and human learning:\nMy neighborhood in Austin, Texas is overrun with deer. Several years ago, a baby deer was born in my back yard. Soon after it was born, it was walking around and within a day it had skipped off with its mother. In some ways, this is amazing. My kids didn\'t start walking for months after they were born. They are teenagers and they are still in school working toward becoming productive members of society.\nOf course, the deer in my neighborhood are not well-adapted to life in the modern world. Cars on the streets routinely have to slow down to avoid hitting them. The deer are not quite sure what to do as they wander through a suburban neighborhood. By the time my kids finish their schooling, though, they will be completely integrated into the modern world with expertise in all of the latest technology. They will be prepared to step into jobs at the leading edge of their fields.Still, even with these differences, the two are similar at some level, humans (especially children) learn from each other. ""Monkey see, monkey do"", ""Children see, children do"" illustrate that we do share a lot in common. If grade school children were quick to dismiss or question everything a teacher says, learning in primary school would grind to a halt.\nSo what is critical thinking really? Shermer\'s answer is as follows:\nThere is also a popular notion that skeptics are closed-minded. Some even call us cynics. In principle, skeptics are neither closed-minded nor cynical. We are curious but cautious.\nOr, I often hear, ""Oh, you\'re a skeptic, so you don\'t believe anything?"" No, I believe lots of things, as long as there is reason and evidence to believe. For example:\n• I believe in the germ theory of disease.\n• I believe that vaccines are good for societal health.\n• I believe that fluoridated water reduces cavities.\n• I believe in the Big Bang theory of the universe.\n• I believe that the theory of evolution best explains life.\n• I believe that the theory of plate tectonics best explains the the continents.\n• I believe that the periodic table of elements best explains chemistry.\n• I believe that JFK was assassinated by a lone gunman named Lee Harvey Oswald.\n• I believe aliens are probably out there somewhere but that they have not visited Earth.\nBeing a skeptic just means being rational and empirical: thinking and seeing before believing. The Oxford English Dictionary gives this historical usage of the word Skeptic:\n""One who doubts the validity of what claims to be knowledge in some particular department of inquiry; one who maintains a doubting attitude with reference to some particular question or statement."" And: ""A seeker after truth; an inquirer who has not yet arrived at definite convictions.""\nSkepticism is not ""seek and ye shall find,"" but ""seek and keep an open mind."" But what does it mean to have an open mind? It is to find the essential balance between orthodoxy and heresy, between a total commitment to the status quo and the blind pursuit of new ideas, between being open-minded enough to accept radical new ideas and so open-minded that your brains fall out. Skepticism is about finding that balance. Here is a definition of skepticism:\nSkepticism is the rigorous application of science and reason to test the validity of any and all claims.', 'It is always important to get different perspectives on the importance of improving energy efficiency. While there has never been more pressure for industry to use less energy, energy efficiency measures are sometimes perceived as a greater risk than the rewards they can bring. Jukka Tolvanen, ABB’s energy efficiency expert, explains the benefits on the IEN Europe website.\nThe Many Benefits of Energy Efficiency\nEnergy efficiency is a major area of focus and its importance was highlighted at COP 22 in Marrakesh, when the World Energy Council published ‘Energy Efficiency: A straight path towards energy sustainability’. This report highlighted that there is still much progress to be made for energy efficiency in helping to reduce global energy emissions as agreed at COP21 in 2015.\nOne challenge is that growing economies don’t often have the resources to spare to develop energy efficient solutions. The truth is, seen from a purely economic perspective, some companies perceive energy efficiency measures as an increased risk. This is because of a need to change processes or replace process equipment.\nHowever, energy efficiency can deliver value beyond energy savings, as explained in the International Energy Agency (IEA) publication “Capturing the Multiple Benefits of Energy Efficiency”. Benefits include macroeconomic development; public budgets; health and well-being; industrial productivity; and energy delivery.\nWhy energy efficiency is important\nEnergy efficiency measures output against energy consumed. Evidence shows that improved energy efficiency can deliver benefits across the whole economy, impacting GDP, employment, trade balances and energy prices. Not only does it reduce energy demand and costs but it can also contribute to improved industrial productivity.\nFrom my own experience of installing ABB drive technology at an engine factory in the UK, employees reported that they enjoyed their work environment more. Not only did the drives reduce overall energy demand but they also eliminated other negative side effects of energy loss like heat and noise. This led to an overall increase in the factory’s productivity.\nFirst fuel and the rebound effect\nSeen from the context of sustainability targets, energy efficiency is a major energy resource. Whereas it was previously viewed as a ‘hidden fuel’, or a negative quantity of energy not used, it is increasingly being recognized as a ‘first fuel’.\nThis has led energy efficiency to become a major energy resource. In 2010, energy efficiency achieved a milestone when it became the largest single energy source for IEA countries, exceeding oil, gas, coal and electricity.\nHowever, there is often a ‘rebound effect’ where savings can result in growing demand that counteracts the energy efficiency measures. While this can be seen as a persistent challenge to energy efficiency, rebound can also be positive. One example is a South African farmer who gained 40 percent energy savings from installing variable speed drives in his irrigation system. He then went on to reinvest his savings in more variable speed drives.\nEnergy efficiency in industry\nIndustry accounts for one-third of the global final energy demand – so any improvement in energy efficiency has great potential to contribute to the bottom line. By investing in energy efficiency, industrial operators gain benefits of enhanced competitiveness and profitability, reduced resource use and pollution, improved production, product quality and working environment, and reduced operational and maintenance costs. These represent improved productivity and contribute to wider political objectives such as combatting climate change and promoting economic development.\nWhen making the case for investment, quantifying the benefits can be complex as energy efficiency crosses multiple process steps, each of which have their own energy needs. Operators often make decisions based on simple payback time. However, the expected annual profit can be better than payback as a way to evaluate investment.\nA bright future for energy efficiency\nIn spite of huge investment in renewable energy, many millions of tons of fossil fuels are still burned to generate electricity, releasing carbon dioxide into the atmosphere. By using energy more efficiently, we could deliver half the cuts in emissions needed to slow climate change over the next 25 years. To give a sense of what can be achieved, the most efficient economies generate 16 times more GDP with the same amount of energy than the least efficient.\nEnergy efficiency can deliver tangible social and economic improvements but communicating its value is a challenge. Talking about what improved energy efficiency actually delivers can help stakeholders grasp its impact and value.\nIndustrial motors use 45 percent of all electricity and the ideal scenario for energy efficiency is for all motors to be the highest efficiency class and controlled by variable speed drives. However, new investments are often expensive, leaving operators with a choice. We typically find that operators find greatest energy efficiency savings by focusing on the installations that enable operators to gain small savings over a long annual running time rather than large savings on their investment motor with low annual running hours. The wider benefits of energy efficiency have enabled manufacturers to optimize their consumption of raw materials, improve working conditions and enhance reliability and throughput times. However, there is still a significant challenge in demonstrating what can be achieved before investing in energy efficiency.']"	['<urn:uuid:1a4020ea-3e99-4f6c-bded-4f549096ec04>', '<urn:uuid:c8a714d0-11fd-4dc7-93d0-7f84a60597bb>']	factoid	direct	verbose-and-natural	distant-from-document	multi-aspect	expert	2025-05-01T23:55:16.606337	12	92	1554
463	my mother has trouble breathing need to know if breathing problems due to infection or muscle weakness similarities differences	To determine if breathing problems are due to infection or muscle weakness, several key differences can be observed. In cases of muscle weakness like ALS, the primary signs include becoming conscious of breathing, increased fatigue from breathing effort, and difficulty coughing or clearing secretions due to weakened respiratory muscles. In contrast, infectious causes like those seen in asthma and COPD exacerbations are characterized by inflammation in the bronchi (bronchitis) and can be identified through specific markers in sputum cell counts. While both conditions can cause respiratory distress, muscle weakness cases require ventilatory support, while infectious cases require treatment of the underlying infection and inflammation. Medical tests can help distinguish between these causes - for muscle weakness, doctors measure forced vital capacity (FVC), while for infections, they analyze sputum samples and inflammatory markers.	"['How does ALS affect breathing?\nThe role of the respiratory therapist\nTypes of ventilation and equipment\nDiaphragm stimulation (pacing)\nCoughing and clearing secretions\nRespiratory problems are perhaps the most serious of medical complications in ALS. Breathing difficulties occur from the gradual deterioration of muscles involved with breathing: the diaphragm and the intercostals.\nThe diaphragm is an arched muscle located just beneath the lungs that moves up and down and allows air to come in and move out. The intercostals are muscles between the ribs that contract and relax and also assist with air movement.\nAs ALS weakens these muscles, you’ll become conscious of the act of breathing, which is normally automatic, and it will consume additional energy.\nWeakening respiratory muscles may increase your fatigue levels and deplete your energy. The effort to breathe, when these muscles aren’t functioning well, is hard work.\nAs your respiratory muscles weaken, your neurologist may refer you to you a pulmonologist, a doctor who specializes in issues related to the lungs and respiratory system. Be sure this specialist understands that your breathing problems aren’t caused by problems with your lungs; they’re caused by weakness of the muscles that operate the lungs. Treatments for these two types of conditions are quite different.\nWeakening of the respiratory muscles can also challenge your ability to respond to the stresses of colds, flu or pneumonia — illnesses that are caused by bacterial or viral infections. Pneumonia also may be caused by aspiration of food or fluid into the lungs, which can be caused by weakened muscles.\nBut, as in many other areas, new knowledge and technology make it possible for you to work, travel and continue with normal activities while obtaining the help you need with breathing.\nMDA health care experts recommend that people with ALS get a flu vaccine in the fall, get a pneumonia vaccine, and be familiar with the symptoms of pneumonia:\nPeople who are having difficulty with liquids (choking or coughing) should use a thickener (such as ThickIT or SimplyThick) in their diets to prevent aspiration of fluids into the lungs.\nYour best approach is to have your ALS physician communicate with the pulmonary specialist, and to work closely with a respiratory therapist who’s familiar with ALS.\nThe respiratory therapist on your ALS health care team is responsible for obtaining measurements of your respiratory function and instructing you and your family in the use of therapeutic measures and equipment prescribed by the pulmonary specialist. The importance of careful monitoring of respiratory function and proper instruction in therapeutic measures is essential in the overall care of people with ALS.\nYour RT or pulmonary specialist will measure the forced vital capacity (FVC) (total amount of air that can be moved in or out of the lung). This can easily be accomplished by exhaling into a spiro-meter. The FVC is easy to perform and is a meaningful indicator of changing respiratory status in the person with ALS.\nEvidence of respiratory involvement might include:\nIf any of these symptoms occur frequently, you need a medical examination of your respiratory status.\nThe RT assists in the instruction of therapeutic measures ordered by the pulmonary specialist such as incentive spirometry, assistive coughing and breathing exercises, suctioning, intermittent positive pressure breathing, and postural drainage.\nThe therapy of respiratory dysfunction in ALS is primarily aimed at general supportive measures. Considerations may include ventilatory maneuvers (voluntary or positive pressure) to prevent atelectasis (lung collapse), a cessation of smoking program, instruction in maintaining nutrition and prevention of aspiration, flu vaccinations, and medications to decrease the work of breathing.\nIf oral or pharyngeal secretions (from the mouth or nose) become excessive, drugs that decrease saliva production or suction devices to remove secretions may be beneficial. If low blood oxygen levels are documented, supplemental oxygen may be given. All infections should be promptly treated.\nBreathing, meaning the exchange of oxygen and carbon dioxide that normally occurs, may become less effective for you in advanced stages of ALS. The result may be respiratory distress, which has many symptoms:\nBefore these respiratory complications emerge, your doctor will probably begin to discuss various methods and steps of respiratory support — ventilation. There are more options for assisted breathing today than ever before, some that can prolong life for several years.\nSome experts say that assisted ventilation is the single most significant factor in the increased life expectancy of people with ALS in recent years.\nIt’s wise to think ahead about your choices and needs for respiratory help. Without planning, you could experience a respiratory crisis and have to make important decisions in an emergency situation.\nYou should give the question of ventilatory support serious thought in advance and put your wishes in writing so they’ll be known to your caregivers and medical team if you have a respiratory emergency. You may want to state your wishes formally in a medical directive; you can alter this document any time you change your mind.\nVentilators are now small, portable and quiet, but maintaining a person with one at home can be very expensive and taxing on caregivers.\nRemember that your health care team and other professionals at the MDA clinic are there to help you understand your options and answer your questions as you make difficult decisions about ventilation.\nBe sure to discuss this subject in detail, including the options described here, so you can make your choices clear to your doctor and loved ones.\nThis form of ventilation has seen several advances and wider use in recent years. Noninvasive devices don’t involve surgical invasion of the body. Many times, ventilators can be used for several hours a day or just during sleeping hours. People with ALS whose bulbar (mouth and throat) muscles are extensively weakened, however, may need more extensive ventilation solutions.\nThere are several forms of noninvasive ventilation. One is pressure-cycled vent machines, which deliver air at a set pressure level with a variable volume of air on a timed cycle.\nA CPAP (continuous positive airway pressure) machine is not indicated in ALS. CPAP increases the work of breathing by forcing the user to exhale against resistance. This can be dangerous for those with ALS.\nA BiPAP machine, on the other hand, is often prescribed in ALS. BiPAP (the trademark name of a machine distributed by Respironics) is short for bilevel positive airway pressure and delivers air at two pressures, one for inspiration and one for expiration (inhalation and exhalation). A number of nasal or face masks and attachments are available, and can be customized for the best fit.\nVolume-cycled ventilators deliver a pre-set amount of air. Volume vents can deliver air in far greater pressures and volumes than pressure vents can. Although these machines were traditionally used only with invasive interfaces (such as a tracheostomy, see below), some doctors now prescribe them for use with a mouthpiece, nasal or face mask.\nAnother noninvasive form of ventilation uses negative pressure through a corset-like device that wraps around the chest and creates negative pressure, allowing the lungs to expand. With negative pressure applied on a timed cycle, the lungs inflate and deflate alternately, as in regular breathing. This is the same technique that was used years ago in “iron lungs.”\nInvasive ventilation is delivered via a tracheostomy, a surgically created hole in the trachea (windpipe) through which air is forced. The tube through which the air is delivered also is called a tracheostomy (trach) tube.\nA ventilator delivers air on a timed cycle through the trach, and ensures that you’ll take a minimum number of breaths per minute. Many ventilators can then be adjusted to respond to the person’s own efforts to breathe, or to completely override these efforts. The decision to start tracheostomy-delivered ventilation is often a permanent one because it’s usually impossible for people with ALS to recover the ability to breathe on their own.\nMany people with ALS ultimately need a trach because of the weakness of the mouth and throat (bulbar) muscles. Invasive ventilation is thought to be a more reliable means of delivering air to the lungs when the disease is advanced. But one important drawback of a trach is that it interferes with the body’s normal mechanisms for clearing the respiratory tract of mucus. Various solutions can combat this problem.\nNot everyone with ALS will need or choose to have a tracheostomy, but there may come a time when it’s necessary for continued breathing.\nIn addition, most people relying on invasive ventilation will need humidification because the nose, through which air is normally moisturized, has been bypassed.\nIn 2011, the U.S. Food and Drug Administration (FDA) approved as a ""humanitarian use device"" a new method of respiratory assistance for people with ALS-caused breathing difficulties but with adequate preservation of the diaphragm muscle and the phrenic nerves, which stimulate it.\nA humanitarian use device is one that the FDA has determined does not pose an unreasonable risk of illness or injury and for which the probable benefit to health outweighs the risk of illness or injury from its use.\nDiaphragm stimulation, or pacing, involves a rhythmic stimulation of the major breathing muscle through electrodes, which must be surgically implanted into the diaphragm. The electrodes send signals to the diaphragm muscle, causing it to contract and assist breathing efforts.\nThe NeuRx Diaphragm Pacing System (DPS), by Synapse Biomedical, can be used in conjunction with noninvasive ventilation (e.g., BiPAP) or by itself. The DPS doesn’t slow or stop the progression of ALS, but it may delay the need for tracheostomy ventilation in some people with ALS, and may improve sleep and quality of life.\nCoughing and clearing secretions from the lungs are activities that most people do automatically. Normally, the lungs constantly move excess mucus and inhaled particles up toward the mouth to a spot where they can be coughed up.\nAs ALS advances you may eventually have difficulty coughing and clearing your throat because of weakened abdominal and throat muscles. Material that would normally be coughed up instead will fall back down into your lungs where it can cause respiratory irritation and infection. This may occur whether or not you’re using assisted ventilation.\nCertain techniques and medical equipment can enable you and your caregivers to create or assist a cough, and then clear mucus secretions from your airway. Talk with your doctor and your RT about these interventions.\nAn RT can show you this technique, which involves closing the throat after each breath taken in through a mouthpiece, and then coughing.\nCaregivers can be taught how to increase coughing efficiency by pressing on your abdomen.\nAssisted coughing devices\nAn In-Exsufflator machine delivers a large volume of air into the lungs and then quickly reverses the air flow to pull out secretions, just as a cough would.\nAn example is the CoughAssist. Used with a facemask, with a mouthpiece or with an adapter to a patient’s endotracheal or tracheostomy tube, this machine can be used to clear your airway as needed. This type of machine is often recommended for use in conjunction with invasive ventilation, and can be demonstrated by your RT.\nAnother option that’s been recently studied for its effectiveness for people with ALS is The Vest. This system uses a technology called high-frequency chest wall oscillation. During therapy, The Vest inflates and deflates rapidly, applying gentle pressure to the chest wall. This loosens and thins mucus and moves it toward the larger airways, where it can be cleared by coughing or suctioning.\nPortable or stationary suction machines can provide appropriate suction for removing the lungs’ mucus secretions.\nCaregivers must be instructed in sterile techniques for suctioning, which usually involves inserting a tiny tube (catheter) several inches into the trachea via a trach tube. In the absence of a trach, suction devices similar to those seen in dentists’ offices can be directly inserted into the mouth. Others can be inserted through the nose via atube with a soft catheter tip. The tube is attached to a suction machine.\nIn addition, most people relying on suction machines will need humidification because the nose, through which air is normally moisturized, has been bypassed.\nOximeters are electronic devices about the size of a small cell phone that measure the amount of oxygen in the blood through a painless sensor that can be clipped to a finger or earlobe. If your RT or pulmonologist finds that your oxygen level is normal (at least 95 percent saturation”) without any supplemental oxygen, it’s likely that air exchange (of oxygen for carbon dioxide) is adequate.\nIf saturation levels dip below normal, you and your doctor have to decide whether the problem is chronic underventilation because air exchange isn’t adequate, or whether there’s mucus plugging the airways.\nThese medications, such as those commonly used to treat asthma (albuterol, Proventil, etc.), dilate (open) the airway and are sometimes prescribed for people with ALS. However, many doctors don’t think this type of drug is helpful because it won’t improve the muscle weakness that’s the source of respiratory problems in ALS.\nThis type of drug, commonly found in some over-the-counter cough medicines, can thin secretions and make them easier to cough up. Doctors sometimes prescribe them for people with ALS, as well as recommend an increase in fluid intake.\nWeakened breathing muscles, along with weaker muscles in the mouth, in ALS may result in drooling or sialorrhea. This isn’t a case of excessive saliva production; it occurs when you’re unable to swallow saliva as well as before. There are several medications and other treatments that your physician may suggest to control drooling.\n|Spotlight on Feeding Tubes|\nInsertion of a percutaneous endoscopic gastrostomy tube, commonly called a PEG tube or a feeding tube, sometimes coincides with respiratory support in ALS. This intervention may be necessary to prevent choking episodes and to enhance the ease of feeding if swallowing problems are present. A PEG tube delivers food directly into the stomach from the outside and not down the throat.\nAs a result of bypassing the mouth, a PEG tube can reduce, but may not eliminate completely, the danger of aspirating food or liquid into the lungs. With better nutrition and less energy used for eating, weight loss may stabilize, or even partially reverse, and respiratory function often improves. Ideally, such a tube should be placed before serious respiratory complications arise, and some doctors insist that it’s “never too early” to consider a PEG tube in ALS.\nPlacement of a PEG tube is another personal and important decision that should be made with the help of your ALS health care team. For resources on the topic, see below.\nSome doctors advocate proactive placement of a feeding tube to prevent any weight loss, choking episodes or nutritional deficits.\nFor more detailed information about nutrition in ALS, see Chapter 5 of the MDA ALS Caregiver’s Guide.\nBreathe Easy: A Respiratory Guide for People Living with Neuromuscular Diseases and Breath of Life\nManaging Mucus Plugs, MDA/ALS Newsmagazine, June 2009\nNot Enough ZZZzzzs? Quest, March-April 2008\nNIV Masks: Finding the One That’s Just Right, Quest, March-April 2008\nThinking Outside the Ventilation Box, MDA/ALS Newsmagazine, September 2007\nTruth, Lies and Tracheostomies, Quest, July-August 2007\nMaking the Switch (feeding tubes), MDA/ALS Newsmagazine, September 2006\nIt\'s Still Eating (feeding tubes), MDA/ALS Newsmagazine, September 2006\nSafe Harbor: Rediscovering Life on a Vent, MDA/ALS Newsmagazine, July 2005\nThe Great Trach Escape: Is it For You, Quest, September-October 2003\nA Tale of Two Vent Choices, MDA/ALS Newsmagazine, August 2003\nNoninvasive Ventilation Prolongs Life if Used Right, MDA/ALS Newsmagazine, September 2002\nRespiratory Issues in ALS, MDA/ALS Newsmagazine, February 2002\nManaging Saliva in ALS, MDA/ALS Newsmagazine, October 2001\nWhat Everyone with ALS Should Know About Breathing, MDA/ALS Newsmagazine, August 2000\nFeeding Tubes Are Nothing to Fear, Says MDA Clinic Director, MDA/ALS Newsmagazine, October 1999\nHard to Swallow, Quest, August 1999\nManagement of Patients with Neuromuscular Disease, by John R. Bach, M.D., 2003. Hanley & Belfus (purchased by Elsevier), (800) 545-2522, or try a medical library.', ""Causes, Characteristics and Mechanisms of Infective Exacerbations in Subjects With Asthma and Chronic Obstructive Pulmonary Disease (COPD)\n|ClinicalTrials.gov Identifier: NCT00512954|\nRecruitment Status : Completed\nFirst Posted : August 8, 2007\nLast Update Posted : January 19, 2011\nDiseases of the airways (bronchi) of the lungs include asthma and chronic obstructive pulmonary disease (COPD), which are leading causes of reduced quality of life, loss of work, hospital admissions and deaths and result in a major economic burden to the patient and society. Worsening (exacerbation) of these conditions is common and is frequently due to viral or bacterial infection, which causes inflammation in the bronchi, i.e. bronchitis. Ways to objectively measure the inflammation are needed to improve diagnosis, cause and severity and to guide treatment. The investigators also need to understand changes in the body's defense (immune) mechanisms that make some patients have more frequent infective bronchitis.\nAt present, sputum cell counts are able to identify different types of bronchitis, their severity and may be able to differentiate viral from bacterial infection. Other measurements in sputum, exhaled breath, blood and urine are also available to measure this inflammation. Measurement of immune cells in the blood gives us an idea about the working capacity of the immune system of the body.\nThe investigators plan to study patients with asthma or COPD at the time of worsening of their condition to identify,\n- To what extent viral or bacterial bronchitis can be diagnosed from tests of inflammation?\n- How clearing of infection relates to clearing of inflammation?\n- What are the changes in the body's defense mechanisms that make a patient more prone to frequent infective bronchitis?\n- How do the measurements in sputum, exhaled breath, blood and urine relate to viral and bacterial bronchitis?\n- What are the differences in the measurements in sputum, exhaled breath, blood and urine in asthma and COPD?\n|Condition or disease|\nExacerbations of asthma and COPD are a major cause of morbidity, mortality and economic burden to the patient and society. Exacerbations are usually associated with worsening of airway inflammation which, as identified by quantitative sputum cell counts, can be neutrophilic, eosinophilic, combined eosinophilic and neutrophilic or neither, a result of different causes. The commonest cause of exacerbations is infection. Neutrophilic exacerbations are common and are usually associated with bacterial and non-bacterial infections but eosinophilic exacerbations might also predict viral infections. However the investigators are still unsure whether aspects of neutrophilic inflammation can differentiate viral from bacterial infections. Also the exact relationship between etiology, mechanisms of susceptibility to infection, inflammation and airway responsiveness during an exacerbation is poorly understood. As a result, the physician assumes that clinical improvement from an exacerbation corresponds to resolution of infection and underlying inflammation of airways at the same time. However, inflammation of the airways may persist beyond the resolution of infection, which may contribute to the morbidity and mortality of the disease.\nThe primary objective of this study is to better understand the correlation between the different types of inflammation and infection of the airways during exacerbations. Secondary objectives are to understand the susceptibility to infections and methods to assess the inflammatory response and airway responsiveness during infections. To attain these objectives we will compare the total cells, percentage of neutrophils, percentage of eosinophils in sputum and nasal secretions, sputum fibrinogen, sputum total lactate dehydrogenase, microbial load in sputum and nasal secretions, exhaled nitric oxide, p H of exhaled breath condensate, serum procalcitonin, intensity of urinary 3-bromotyrosine, 3-chlorotyrosine, 3, 5- dibromotyrosine and dityrosine, symptom score, FEV1 and Mannitol PD15 at different time points during an exacerbation, compare the activity of toll like receptors (2,4,7,9) and natural killer T cells during the stable phase of disease with the number of infective exacerbations during the course of one year and test the feasibility of mannitol challenge testing as a method to induce sputum and measure airway hyperresponsiveness. Our approach will be to identify 100 patients with variable (asthma) or chronic airflow limitation (COPD), reporting within 2 to 5 days of the onset of an exacerbation during the course of one year. The clinical, physiological, inflammatory, microbiological and immunological parameters will be assessed on the day of presentation (day 0), day 7, 14 and at 6 to 8 weeks. The information collected at 6 to 8 weeks will serve as baseline data, if the patient is clinically stable at this point in time. If the patient has a next exacerbation during the course of the trial, then the same procedure will be followed.\nThis work will enhance the knowledge of issues needed to improve diagnosis of exacerbations of airways disease, their causes, the mechanisms involved and the most appropriate treatment. The results may lead to future randomized controlled trials, in which treatment of exacerbations will be based on the most appropriate measurements that will eventually lead to better management of airway diseases, reduce the overall cost of therapy and improve the quality of life of these patients.\n|Study Type :||Observational|\n|Estimated Enrollment :||100 participants|\n|Official Title:||A Prospective One Year Study of the Causes, Characteristics, Mechanisms and Kinetics of Exacerbations in Subjects With Asthma|\n|Study Start Date :||April 2007|\n|Actual Primary Completion Date :||December 2009|\n|Actual Study Completion Date :||July 2010|\nPlease refer to this study by its ClinicalTrials.gov identifier (NCT number): NCT00512954\n|Firestone Institute for Respiratory Health, St. Joseph's Healthcare|\n|Hamilton, Ontario, Canada, L8N 4A6|\n|Principal Investigator:||Parameswaran K Nair, MD, PhD||Firestone Institute for Respiratory Health, St. Joseph's Healthcare, Hamilton, Ontario|\n|Principal Investigator:||Frederick E Hargreave, MD||Firestone Institute for Respiratory Health, St. Joseph's Healthcare, Hamilton, Ontario|""]"	['<urn:uuid:de0ff86f-9243-4689-8627-cf7e602d67e2>', '<urn:uuid:0198494d-df50-4466-9a29-965c23fce550>']	open-ended	with-premise	long-search-query	distant-from-document	comparison	novice	2025-05-01T23:55:16.606337	19	132	3571
465	how did medieval renaissance poets and tagore view relationship between earthly divine love	Medieval and Renaissance poets, as exemplified by John Donne, viewed love as either a heavenly gift or diabolic curse, creating a balance between material and transcendent features. In 'The Canonization', Donne believed that genuine earthly feelings could transcend into ethereal experience. Similarly, Tagore attempted to reach the infinite world while being in the limited world, as evidenced by his poems that describe heavenly figures. Both writers saw divine love as intertwined with human love, with Tagore following the tradition of Indian literature that connected divine and human love, as seen in his songs about Radha-Krishna.	"[""The theme of love prevailed in the Medieval and Renaissance poetry, which was mainly written in the form of lyrics and sonnets. It's captivating to explore it in the light of these eras because the-then poets created a brilliant equilibrium between the material and transcendent features of love. They believed that this feeling is either a heavenly gift or a diabolic curse (they didn't view it from the perspective of chemistry, which made their creations incredibly romantic). The leitmotif related to these sacred feelings was often presented in a pastoral setting, which created the atmosphere of innocence and benevolent intentions. An English poet John Donne created some vivid examples of the Medieval poetry. Though the most celebrated representative of the poetic realm of the Renaissance is William Shakespeare, you shouldn't underestimate the significance of Christopher Marlowe's works as he influenced the author of “Romeo and Juliet”. The three poets wrote an abundance of sonnets, lyricizing the theme of love.\nThe Medieval times were highly religious and prejudicial, but when you start analyzing the theme of love in the poetry of this era, it's curious to observe that the poets embodied contradictory feelings: their motives are on the verge of carnal and spiritual. While promoting innocence, they confessed their hidden desires. John Donne's poetry exemplifies the main elements of this era, such as sin, confession, and redemption. His series of nineteen metaphysical poems called “The Holy Sonnets” expose the theme of divine love and the author's fear not to be accepted in Heaven by the beloved God. On the contrary, his passionate and frank poem “The Canonization” turns earthly feelings into the ethereal experience. Donne believes that genuine feelings are able to canonize mortal people; lovers that are truly devoted to each other can transcend the boundaries of a perishable world because their union is sacramental. Such thoughts are extremely rebellious if to consider the exaggerated morality of the Medieval era.\nWhen writing his love sonnets, John Donne extensively employed the imagery and vocabulary typical of an Italian poet Francesco Petrarcha. For example, you can find such metaphors as “miraculous ladies” and “deaths for love”. The main feature of his figurative language is an inevitability of tragedy that leads to a lover's desolation and anguish. Donne also liked to use the motive of disillusion, which helped to create those excellent contrasts: he depicted human love as impeccable and then abrogated this idea, showing that his romantic heroes will never achieve pure heavenly love.\nChristopher Marlowe's poem “The Passionate Shepherd to His Love”, written in a tetrameter style, epitomizes a pastoral poem of the 16th century. Human feelings are interrelated with the inspiring surrounding nature, which intensifies the romantic atmosphere. The shepherd symbolizes sincerity and simplicity: even the voluptuous intentions of the hero appear to be na?ve. He just invites his sweetheart to enjoy nature and modest pleasures of the countryside together.\nIf you studied literature attentively, you probably read William Shakespeare's “Sonnet 130”. The main figurative approach in this sonnet is a peculiar backhanded comparison as the author compares his mistress's physical features to the sun, snow, coral, roses, perfumes, and music, implying that she is not as perfect as these elements of nature. Anyway, the last lines of the sonnet reveal that his love is sane and objective: though her lips are not as red as corals and her voice is not as tender as music, she is still the rarest human being for him. Love has been perceived imaginatively and philosophically through the ages. It was personified by godlike creatures in ancient mythologies, and then prodigious artists embodied Love in their creations ?“ recollect all those paintings and sculptures with cupids and Aphrodite. Such an eloquent feeling definitely had to be perpetuated in poetry."", 'This line from Donne’s The Canonization is found in the lips of Tagore’s hero Amit in Sesher Kobita. And question arises why out of so many poets Tagore choose Donne’s line, when Tagore has once claimed that of all English poets John Keats has influenced him the most. But it can be assumed that the idea of ‘platonic love’ is the reason behind it.\nJohn Donne and Rabindranath Tagore both belong to two different ages but there are certain things in both Tagore and Donne which make their writings similar in thoughts. In my paper I want to discuss mainly about the similarity that they share. But they are dissimilar too, mainly in their style of writing, and my paper also focuses on those dissimilarities. Love, to them is something or someone who is a divine entity who is being loved or rather who crave for love. In Donne’s poetry and in Tagore’s song and in writings one found this tension. This research will also show how the words of the Vedanta1 and Sri Krishna’s2 words in Bhagvat Geeta3 get mingled with the words of Donne and obviously with the words of Tagore. Not only that this paper of mine will also show have that Sufism4 and the mysticism that is there is Sufism also had a great recurrence in their work. The research also questions that why the great poets like Tagore and Donne have a definite positive attitude to the question of death.\nIn this paper of mine I have used the theories of Is Upanishad5 and have also taken the help of the Vedanta; especially the analysis of the Vedanta made by Swami Vivekananda. In this project theories of Sufism too helped me a lot. Jaidev’s Vaishnav Padavalli 6 helped med to understand this theme of divine love. Helen Gardner’s essay on Metaphysical Poets was also of great help to me. And finally, Rabindranath Tagore and European Romanticism by Bikash Chakravarty and Rabindra-Sarani by Promothonath Bishi helped me to rediscover Rabindranath once more.\nThe connection and the love between the divine and the human is an old tradition of Indian or rather Bengali literature. In Jaidev’s Vaishnav Padavalli we see the love between the divine and the human. The love of Sri Krishna and his beloved Radha7. This same kind of love or this Radha- Krishna is also been reflected in Rabindranath Tagore’s song, that were written by him in his youth in the Brajabuli language. The collection of these songs together is known as Bhanushingher Padaballi. But Bhanushingher Padaballi is just a pebble in a vast ocean. There are many Tagore’s song and poem which talks about the same divine and the human love. In an essay on Rabindranath, Promothonath Bishi had said that Tagore’s poems in Kori and Komol had created a sensation during that age. The reason behind this was that, the poems describe heavenly women figures (like Urvasi) in a very sensuous manner. But Promothonath Bishi disagrees with the contemporary criticism. According to him through these poems the poet has tried to reach the infinite world while being in the limited world. Thus the poet says:\n“Eki durashar swapno hai go Ishwar\nToma chara a milan ache konkhane” [What a dream sans hope hey almighty it is/without you this meet thus always cease] [Purnamilan]\nHere we hear in Tagore, the plea to get united with the Almighty God. And if Tagore wanted to get united with the divine then Donne asks this divine:\n“Take mee to you, imprison mee, for I\nExcept you enthrall me, never shall be free.”\nMen are born Immortal, or according to the Vedanta Men (and also women) are born from the Amrit. And not only humans but every one in this Earth is born form that Immortal, so none of the creature neither have any beginning, nor any decay and nor any death. According to the Vedanta Man’s aim in life should be the manifestation of the divine in the self. Bhagvat Geeta on the other hand had said that, human body is like the old cloths, and it is not a human entity. Souls are the owner of this body and when the soul wants it can leave one body and be the owner of the other body. These basic thoughts get reflected in the works of Donne and Tagore. Both of them had believed in the union of the souls and not in the union of the bodies. And thus bodily beauty never attracts any of them.\n“For he who colour loves and skinne\nLoves but their oldest clothes”\nThese lines clearly ring in mind the words of Bhagvat Geeta where a body of a human being is being compared to old and torn cloths. And to Rabindranath eternal beauty is the beauty is the beauty that one should love and so we find his hero Aruneshwar saying:\n“Aami rupe tomay bholab na\nAami haat diye dwar khulbo na\nGaan diye dwar kholab” [I won’t woo you with my beauty/I will woo you with my love/ I will not open these doors with my hands/ I will through music open these doors]\nInterestingly, Aruneshwar (The Sun God) getting married to Komolika, in Shapmochan, [The Curse Redeemed] is symbolic of a marriage between two souls as because here Komolika first gets married with Aruneshwar Veena. This Veena is symbolic of the musical qualities that are being possessed by Aruneshwar. It is in a way the soul of Aruneshwar because Aruneshwar in his previous life was a musician. And in his after life he has just two things from his previous life; his efficiency in music and his unknown and uncanny feeling towards princess Komolika (who in the previous life was his wife). In this dance drama the Veena is responsible for the union of Aruneshwar and Komolika. Like the flea, in Donne’s poem Flea is responsible for the marriage of the two lovers and for that matter in their union. In both Tagore and Donne’s poetry we find a disregard for sexual and physical love. But at the same time it is also true that both did not denied the existence of the body and thus Tagore says in his poem, Deher Milan:\n“Hriday lukono ache deher sayar a\nChirodin tire bosi kori go krondon” [The heart is hidden beneath this body/ I weep my all through my life sitting at the shore]\nThis poem actually speaks of that prize moment when the speaker did not understand that the body is actually preserving the heart or the souls, he like Donne is asking:\n“Our bodies why doe wee forebear?”\nAnd the answer that he is rceiving is also can be said through Donne’s these lines:\n“They are ours, though they are not wee, Wee are\nTh’intelligences, they the Spheares” [Extasie]\nIn Tagore there is an assimilation of the ‘Jiban’ (Visible real life) and the ‘Arup’ (the idealized unseen). To understand the idea of ‘Arup’, one has to understand the Is Upanishad. In Is Upanishad the character of divine is ‘Shunya’, it neither have any form, any shape or any quality. That is why it is called the ‘Nirgun’ (without any quality) and ‘Nirakar’ (without any shape). The essence of ‘Nirgun’ and ‘Nirakar’ is the very essence of the divine in Is Upanishad. This essence in Sufism is known as the Dhat (Zat) and this essence leads to Sankarcharya’s theory of Non-dualism, or “Adwatiyabad”. This means that there is no ‘you’ and no ‘me’; both ‘you’ and ‘me’ mingle in one self. From dualism raises a love that contains fear, but from non-dualism love devoid of fear is being raised. In Donne’s word:\n“And dare love that, and say so too\nAnd forget the Hee and Shee” [The Undertaking]\nAnd according to the Vedanta it is reaching to an assertion through negation. This is vividly found in Tagore’s poem Premer Abhishek, where he describes the beauty of the dancer of the heaven, Urvasi, and says:\n“Noh mata, noh kanya, noh bondhu, sundari rupasi” [Nor mother, nor daughter, nor betrothed, hey beautiful].\nThus by negating the qualities that a woman possesses, that of a mother, daughter and wife, Tagore is celebrating the womanhood. Thus through negation Tagore is trying to reach to an assertion.\nWe, the human beings comes from the infinite therefore finite goals cannot satiate the infinite human desire. Therefore Tagore, according to Promothonath Bishi, neither searched for the infinite nor for the finite. He remained in this finite world and tried to make a connection with the infinite. To Rabindranath ‘facts’ are decaying death and ‘truth’ is the everlasting life of the youth. This thought of Rabindranath gets reflected in his dance drama Falguni. Thus Donne says:\n“All other things, to their destruction draw\nOnly our love hath no decay” [The Anniversary].\nIn the explanation of the Vedanta, made by Swami Vivekananda, we find a reference to ‘Rahasya’. ‘Rahasya’ is a portion of Vedanta and it says that religion has got rid of all external formalities. According to ‘Rahasya’, spiritual things are told in the language of spirits. ‘Rahasya’ is bold, brave and is definitely beyond the concept of the present age. In this respect if we observe Donne style of writing then we will find that his style of writing is bold, brave and is definitely from the conception that used to persist in his age. According to Helen Gardner he tried to establish a ‘relationship between the spirit and the senses.’ Rabindranath too is his relationship with God was different from the poet of his age and in his poetry we find a surrender of his self to the Almighty God.\nAnother important feature of Vedanta is ‘Maya’. According to Vivekananda ‘Maya’ makes millions of being distinguishable. Soul, which in the Vedanta has been called the ‘atman’, is caught up in this ‘Maya’. And this ‘Maya’ gives water the name of the “ocean” and the “waves”. But after the wave subside what is left is water. So if we let Maya alone, and let form and names go, then all these varieties vanish forever. And we find the true self in us; this whole concept in one word is called the ‘Maya.’ We find a reference to this ‘Maya’ in many Tagore’s dance drama, poems and also in many of his novels. For instance, in Sesher Kobita, we find Jogomaya saying:\n“Se jeno bujlum tumi Amit er kache chirokal ei Maya rupe thakbe”\nBut Jogomaya was not really right in the sense that, not for a few moments, but Labnya remains as ‘Maya’ to Amit till the end of the novel. It is Labnya’s presence that makes Amit’s character distinguishable from that of Labnya. Amit’s soul was caught up in Labnya’s ‘Maya’. In Bhagvat Geeta, one found that Sri Krishna is telling Arjun that he should not lament about the fact that the war of Krukshetra is going to take the lives of his relatives. According to Sri Krishna the relations that a Man (or a woman) made in this Earth is nothing but ‘Maya.’ It just makes us different from the other person and does not allow us to have, the true knowledge of who we really are. Thus in George Herbert’s (another metaphysical poet), The Collar that a God gives a Man is the only true collar, and from this freedom is never gain. But the other collars, that one feel that one is wearing, is nothing but illusion. This ‘bani’ of Sri Krishna to Arjun8, about the ‘Maya’ allows Arjun to be strong and mature enough to experience the death of his very dear ones.\nDeath and its pain have also been experienced by Donne and Rabindranath. But their attitude towards death can be said in the words of Vedanta as\n“Sad Chidananda Swaroop”\nThis means that this world is all about the flow of joy without any attachments. Thus we see that after the death of Mrinalini Devi, Tagore wrote”\n“Hriday amar nache re aji k mayur rer moto nache” [Like a peacock feathers so the same way swings my heart]\nAnd in another song he puts the rhythm of life and death and wrote:\n“Nache janam, nache mrityu, pache pache” [Birth swings beneath and so does death].\nIf Rabindranath has related death eternal joy, then Donne has asked “Death” to not to be “proud”; and had said:\n“One short sleepe past, wee wake eternally\nAnd death shall be no more, Death thou shalt die”\nThis ring back in minds the same old teachings of Vedanta that we are Infinite and at the same time born from the Immortal and is thus Immortal. Thus we have neither any beginning, nor decay, and neither an end. We have one life and in this one life we neither have the knowledge of the previous life and neither have we had, the knowledge of the after life. This whole complicated matter in Tagore is described in a very simple line by Tagore:\n“Notun name dakbe more a, bandhbe notun bahu dore a, asbo jabo chirodin er sei ami” [I’ll be called by different names, bound by relation new, yet I’ll coming back to you]\nThus a life after death will wake up with a new name, and get him or her tied up in relations; but the life will be that same eternal life.\nAccording to Tagore in the connection between the ‘incomplete’ Visible Real and the ‘fulfilled’ Idealized Unseen, lies the success of poetry. Both Donne and Tagore has idealized the Idealized Unseen because the Visible Real is prone to decay and destruction. So, love for them is ‘Platonic’, they can eliminate the self, the notion of You and me. And if the idealized Unseen is the divine, then both of them love that Idealized Unseen. And love it in such a way that one feels that the love is between the lover and the beloved. It is like the eternal life of Radha and Krishna. That is why in Tagore’s Sesher Kobita we find Donne’s dramatic line:\n“For godsake hold your tongue and let me love”,\nrepeated again and again and again. After al Amit and Labnya’s love is indeed an example of Platonic love. Thus while or after reading Donne if we say:\n“…………..;though I bid farewell,\nThine, in mine hearts, where my soul dwels, shall dwell”\nAnd after reading Rabindranath if we say:\n“Nayan er Sammukhe tumi nei\nNayan er maje tumi niyecho je thei”\nThen we are actually referring to the same thought in a different language.\n- Vedanta- A collection of Hindu texts that talks about the foundation of Hinduism. There are four texts; and among them AtharvVed was the last to be written down. This is the ‘Ant’ or the last among the four Vedas. Thus it is known as Vedanta.\n- Sri Krishna- The seventh son of Devaki and Basudev, who was the King of Mathura, a place in India. He played a vital role in the battle of Krukshetra, reference found in the Indian epic Mahabharata, fought between the Kaurav and Pandav.\n- Bhagvat Geeta- In the battle of Krukshetra Lord Krishna gives a speech to his friend Arjun, who was de-motivated by this knowledge that he is fighting against his own family, to motivate him to fight the battle. Not only that Arjun have can see the whole universe in his mouth; and thus gained knowledge about this universe and of his self.\n- Sufism- An Islamic mysticism where a person tried gets connected with the God by going through the passage of elimination of the self.\n- Is Upanishad- A text that gives us the structure of not only Hinduism, but at the same time it connects with Buddhism and Jainism\n- Vaishnav Padavalli- An old Bengali literature that talks about the eternal love of Lord Krishna and his beloved Radha.\n- Radha- The wife of Ayan Ghosh but is renowned as the true lover of the Lord Krishna. She was worshipped together, in India, with Lord Krishna. But interestingly, Sri Krishna and Radha never got married they are still referred as lovers and not as husband and wife.\n- Arjun- The son of Pandu, once the King of Hastinapur, according to the epic Mahabharata. He is renowned in the world because of his efficiency in archery. He was third among the five sons of Pandu.\nThe Metaphysical Poets; Selected and edited by Helen Gardner\nUpanyas Samagra by Sri Rabindranath Tagore; Ed: Kalyanbrata Dutta Geeta; Ed: Subodhchandra Majumdar, Pub: Dev Sahatiya Kutir\nRabindranath Tagore and European Romanticism, by Bikash Chakravarty; Pub: Punascha. Rabindra-Sarani, by Promothonath Bishi.']"	['<urn:uuid:c02f9ace-94b0-4d8a-8430-a349a3874134>', '<urn:uuid:43789b4b-25de-4285-8c16-3611b27f2791>']	factoid	direct	long-search-query	distant-from-document	comparison	novice	2025-05-01T23:55:16.606337	13	95	3389
467	racial representation ballet dance performance conventional roles evolution	Traditional ballet roles have historically been restricted by race, but efforts are being made to challenge these conventions. In the UK, Céline Gittens became the first woman of color to dance the leading role in Swan Lake in 2012. Similarly, Nimbus Dance Works actively works to break stereotypes in casting, including casting dancers of color in traditionally white roles like the prima ballerina in 'The Nutcracker'. The impact of such diverse casting was demonstrated when a young girl remarked to a black dancer, 'I've never seen a black prince before' after a Nutcracker performance.	"['Wandsworth celebrates Black History Month 2021\nWe’ve put together a round up of brilliant activities, events and content being produced in the borough to mark this year’s Black History Month. We will continue to add to this list as more events are announced. Please get in touch with us at [email protected] if you’re hosting your own arts and heritage event or programme, and we’ll make sure to promote it.\nBlack History Month Gala Luncheon for Wandsworth’s Windrush Elders\nBlack Heroes Foundation | Battersea Arts Centre | 1 October\nBlack Heroes Foundation is opening Black History Month with a Gala celebrating the life and achievements of John Archer at Battersea Arts Centre, in the former Battersea Town Hall building.\nWandsworth’s Windrush Elders from local community centres are invited to a free luncheon on Fri 1 Oct. The awesome Black Heroes Foundation Exhibition will be on display, together together with activities celebrating the contributions made by society by the Windrush Generation and African Diaspora, plus a performance of The Story of John Archer.\nBlack History Month Gala Luncheon for Wandsworth’s Windrush Elders FREE Tickets, Tue 2 Nov 2021 at 12:30 | Eventbrite\nThe Story of John Archer\nBlack Heroes Foundation | Battersea Arts Centre | 1 October | 7pm\nThe Story of John Archer is a short play written by Joyce Fraser and Jennifer Farmer. John Archer, born in Liverpool, became the Mayor of Battersea in 1913 and was the first Black Mayor in London.\nStarring Patrick Mackenzie and Vivienne Rochester. Directed by Dr Anni Domingo, with sound design by Vamva Sound Design, this play was first performed on 2 Jul 2021 at Wandsworth Arts Fringe. For those who missed it, this is your chance to enjoy, learn and celebrate!\n“It was a wonderful journey through the life of John Archer and what he did for the good people of Battersea in Wandsworth. It was a terrific piece of acting and I thoroughly enjoyed it….The cast and the organisation need to be congratulated on a wonderful production”Mayor of Wandsworth\nTickets: £5 | Book tickets here\nJoin Black Heroes Foundation every Thursday to celebrate black heroes in song, music, dance and gentle exercise.\nWho’s your local hero? Come and meet new people, share and celebrate with us during this weekly community event taking place in your living room!\nA Black Heroes Foundation project, developing cultural awareness, promoting a world where Black Heroes are acknowledged, respected and celebrated.\nA Black History Month event that runs throughout the year! Every month is a Black History Month.\n12.30pm – 1.30pm | Online | Register here\nVirtual Soul Food Cafe\nFeed your Soul every Friday evening with a free online event that you, your friends and family can enjoy.\nSinging, Dancing, Exercise, Old School Video, Black History, Books, Spoken Word, Open Mic, Guest Celebrity Artists and YOU.\n7.30pm – 9pm | Online | Register here\nHeather Ayepong’s The Body Remembers\nThe body is an archive. It remembers everything – even the things that the head forgets.\nHeather Agyepong’s powerful new solo performance The Body Remembers explores how trauma lives in the body, particularly for Black British women across different generations. Through a unique and compelling relationship between the audience and artist, it creates a cathartic experience.\nCreated & performed by multidisciplinary artist & actor Heather Agyepong, The Body Remembers draws on interviews of Black British women in trauma recovery. The performance is inspired by the therapeutic practice of Authentic Movement with Agyepong as The Mover and the audience as The Witness. Featuring dynamic projections and an immersive soundscape which help the audience to re-discover the power of self-reflection as the start of recovery and healing. Co-created by Imogen Knight (movement) and Gail Babb (dramaturgy), The Body Remembers creates a space for audience and artist to attend to themselves and each other.\nPart of BAC’s OverCome autumn season #OverCome2021\n20 Oct – 4 Nov 2021 | Battersea Arts Centre | Pay What You Can | Tickets here\nUbuntu Museum: Recycled arts and crafts workshop\nJoin Ubuntu Museum for a recycled arts and craft workshop with a mini exhibition, for all ages.\nWith inspiration from the artwork of Yuroba artist Romuald Hazoumè who uses old jerry cans and other found objects to tell stories, you can tell your story using recycled materials too.\nHazoume’s masks do not carry the significance assigned to more sacred traditional ones, but he has his own point to make and it touches on social issues like the pervasive reach and impact of Western-generated consumer culture on African countries.\nDate: Monday 25th October\nTime: 14:30 – 16:00 hrs\nContact: Roehampton Library to book a space\nTel: 020 8246 6979\nEmail: [email protected]\nAddress: 2 Danebury Avenue, London SW15 4HD\nDate: Friday 8th October\nTime: 16:00 – 16:45 hrs\nContact: Balham Library to book a space\nTel: 020 8673 1129\nEmail: [email protected]\nAddress: 16 Ramsden Road, London SW12 8QY\nBallet Soul’s Othello21\nArtistic Director Ben Love gives Shakespeare’s brutal and gripping tragedy the Ballet Soul treatment in this edgy and evocative reimagining, with a dazzling original score by British jazz legend Julian Joseph.\nThe film transports us to modern Britain, where high flying media man Othello is taking London by storm. He is a passionate and powerful African man, married to the love of his life – Desdemona.\nIn a dream he is left a blood red scarf by the spirit of his mother. A token of his past and a symbol of his love, their present and future, Othello gives the scarf to Desdemona. A decision that may come back to haunt him.\nMaking Othello21 (2020)\nFollow the Ballet Soul dancers as they emerge out of lockdown and back into rehearsal to prepare for Othello21.\nComposer James Joseph and Ben Love: In Conversation\nBlack History Month at Royal Academy of Dance\nRAD are marking Black History Month by looking at Black and Brown dancers who have made history and those who are still making it. Over the course of October (and beyond), they’ll be sharing their stories here and on social media to celebrate their contribution to the art of dance.\n7 Iconic Black Women Who Changed The Course Of Ballet History\nRefinery29 celebrate Misty Copeland and the black ballet dancers who paved the way for her success.\nRAD podcast: Céline Gittens\nBorn in Trinidad and later moving to Canada, Céline is now a Principal at Birmingham Royal Ballet, where in 2012 she became the first woman of colour in the UK to dance the leading role in Swan Lake.\n15 Black Dancers who Changed American Dance\nDance Informa magazine celebrates some famous (and some not so famous) names from US dance history.\nBlack Dance Stories\nMeet Black dancers LauREN Beharie, Namron, and Akua Acheampong.\nAfrican Movement and Technique with Tavaziva (for age 13-16)\nThe RAD are delighted to be collaborating with Tavaziva to deliver an African Movement and Technique workshop to dance students, as they tour their latest work, BOY’S KHAYA.\n17 October 2021 | 10.00 – 13.00 | Book here | £16+ booking fee\nGuest Lecture Series Event: In Conversation with Gerard Samuel\nProfessor Gerard Samuel (University of Cape Town, RSA). will be in conversation with Dr Kathrina Farrugia-Kriel. Samuel will speak about ballet in South Africa and the rise of black artists in post-apartheid South Africa and in contemporary times. This event will be of interest to those invested in the black ballet histories and South African contemporary ballet.\n20 October 2021 | 18:00 | Book here', '""I dance not to entertain but to help people better understand each other. Because through dance I have experienced the wordless joy of freedom, I seek it more fully now for my people and for all people everywhere.”\nThis quote, from dancer, choreographer and anthropologist Pearl Primus, set the stage for a thought-provoking discussion about the intersection of dance and social justice at Manhattan Country School Tuesday evening. Part of the Black Lives Matter Week of Action in Schools, the program, titled “Perspectives: Dance & Social Justice,” featured diverse viewpoints from members of the dance community.\nThe evening began with a dramatic rendition of “Strange Fruit (1945),” a Primus-choreographed piece about lynching based on Lewis Allan’s poem of the same name, performed by Brandy White and Justin Perez of Nimbus Dance Works. Steven Melendez, a 2001 graduate of MCS and principal dancer with New York Theatre Ballet, served as emcee for the evening. In his opening remarks he made the case for dance as a way to open minds and effect change. He presented archival footage of Alvin Ailey dancers’ 1960s visit to Malaysia in which the black American dancers and their Malay hosts connected through movement. The Malays taught the Ailey representatives some of their cultural dances and the Ailey dancers shared a bit of black American culture through performances of “Revelations” and “Wade in the Water.”\nLèo Holder, son of dancer and Alvin Ailey company co-creator Carmen de Lavallade and dancer, choreographer and actor Geoffrey Holder, joined Steven to share his insights about his parents and their life’s work. He told the story of how his parents met (performing in the 1950s musical “House of Flowers”) and shared some of the experiences they faced as black dancers. The couple’s performance in a Lester Horton production, which received critical acclaim but drew no audience, is just one example of the prejudice they faced.\nAnother of the evening’s presenters, Gus Solomons jr, faced a different type of prejudice. A dancer, choreographer, actor and writer raised in a predominantly white neighborhood of Boston, Solomons was drawn to crafting abstract, non-objective dances that weren’t born of oppression. “When curators were sent the programs, the white ones categorized me as a black choreographer, and so excluded my work,” said Gus, “and the black ones were puzzled by the notion of pure abstraction and so they [thought] my work appealed to white audiences.” When asked about being a black choreographer, Gus said his standard response is “I’m black, but my dances aren’t about that.”\nFollowing Gus’ presentation, Steven screened film footage of Agnes deMille’s “The Four Marys,” based on the libretto “The Ballad of Mary Hamilton.” In this ballet, performed at the Metropolitan Opera House, a black woman gives birth to an illegitimate child with a white man. She subsequently drowns the baby and is hanged for murder. With “The Four Marys,” deMille, known for the cheerier choreography of musicals such as “Oklahoma,” “Carousel” and “Brigadoon,” explored the darker side of society through a tale of miscegenation during the era of slavery.\nFor the next portion of the program, Steven welcomed Samuel Pott, a 1990 MCS graduate. Samuel explained how his time at MCS and the school’s focus on social justice, diversity and equity influenced his work as a dancer and as founding artistic director of Jersey City, New Jersey-based Nimbus Dance Works. He said he makes a conscious effort to ensure that he has a multiracial group of dancers in his company and his works often tackle social justice issues. He is the founder of the School of Nimbus Dance Works, which approaches dance as a meeting point for diverse communities and makes high-quality dance training available to children in Jersey City regardless of their financial background.\nHannah Weeks and Devon Louis, members of Nimbus Dance Works, performed “Fractured Time,” a work in progress choreographed by Darshan Singh Bhuller, which imagines the experience of an interracial couple in middle America in 1968. Following this performance, the presenters engaged in Q&A, with a focus on the role of race in casting. Samuel said he tries to break stereotypes whenever possible. The role of the prima ballerina in “The Nutcracker” is just one example. Traditionally performed by a white woman, Samuel has cast dancers of color in this role. Steven provided an example of the impact diverse casting can have on young, impressionable audiences. After a performance in Fresno, California where Steven played the Cavalier in “The Nutcracker,” he said a little girl told him, “I’ve never seen a black prince before.” Breaking casting traditions can challenge stereotypes and present that world as full of opportunity for future generations.\nMCS Director Michèle Solá closed the evening by reflecting on the importance of cultivating these types of conversations. Discussions continued at the post-event wine and cheese reception and are sure to endure in the days, weeks and years to come.']"	['<urn:uuid:7f53bb0c-1333-465c-a034-ad4a6bc9e581>', '<urn:uuid:c59dbfbc-2ef0-4289-b78b-4fa63be9b1fa>']	factoid	direct	long-search-query	distant-from-document	multi-aspect	expert	2025-05-01T23:55:16.606337	8	94	2061
468	comparison permanent temporary facial injectables	Facial injectables can be divided into temporary and permanent solutions. The BCAM recommends temporary solutions as they have fewer problems and side effects. For example, hyaluronic acid fillers like Restylane and Juvederm are temporary and last 6-9 months on average, while more permanent options like Sculptra can last up to 2 years. Botulinum toxin is another temporary option lasting 3-6 months.	['Dermal fillers is a term which refers to a wide variety of different things, many of which have been used or are used to fill out lines and reshape the face.\nFat transfer was first used over one hundred years ago, and a much refined version is available today. It is still a fairly time consuming and complex procedure with a fairly high failure rate but in the right hands can give good long lasting results. Liquid paraffin and silicone have both been used in the past but caused a lot of problems and thus they are not recommended any more.\nCollagen injections were first used in 1976 and are still widely used. However, collagen is derived from the skin of cattle so there is a significant demand for alternatives that are non animal sourced and longer lasting.\nProducts containing hyaluronic acid such as Restylane, Perlane, Juvederm, Belotero and many others have become available over the last 5-6 years and have proved highly popular. Be wary of new fillers – The regulations at present are not very demanding so a product can be promoted after minimal testing.\nResults depend on:\n- The part of the face which is treated\n- How much movement there is in the treated area\n- The condition of the skin\n- The experience and skill of the person performing the treatment. (This is the most important).\nDermal fillers should be administered only by doctors and nurses. It is a simple procedure, done in the doctor’s office, and not usually requiring time off work.\nDermal fillers can be used to improve:\n- Acne scars\n- Depressions or pockmarks in the skin due to injury or disease, for example, chickenpox marks\n- Unevenness in the skin after surgery or skin grafting\n- Deep ‘smile lines’ which run from the side of the nose to the corners of the mouth\n- ‘Crows feet’ at the corner of the eyes\n- ‘Frown lines’ between the eyebrows\n- ‘Smokers lines’ which are vertical lines on the top lip\n- ‘Marionette lines’ at the corner of the mouth\n- ‘Worry lines’ which run across the forehead\n- The definition of the lip border\n- Other facial lines.\nSome defects can be difficult to improve with the first treatment and although you may notice some improvement, more treatments may be needed to get best results.\nTreatment with dermal fillers is not going to be successful for every person, and results and duration are variable. For some people wanting treatment for deep facial fines other treatment may be required first, followed by ‘fine tuning’ with dermal fillers.\nThere are now over 60 dermal fillers on the UK market. The most obvious division between them being that some are temporary and some more long lasting. The BCAM would always recommend the more temporary solutions as they do have less problems and side effects. Please ensure that the doctor explains in full his choice of filler and it’s expected duration and side effects.\nBelow are three of the more common treatments.\nRestylane and Perlane\nHow does Restylane work?\nRestylane adds volume and fullness to the skin to correct moderate to severe facial wrinkles and folds, such as the lines from your nose to the corners of your mouth (nasolabial folds). Restylane works immediately by adding volume to smooth away wrinkles. A clear gel formulation of hyaluronic acid, Restylane is specifically formulated to act like your body’s own hyaluronic acid. So, you can use Restylane to visibly reduce moderate to severe facial wrinkles and folds.\nBiocompatible with the human body, Restylane is eventually broken down naturally to water and carbon dioxide.\nHow does Perlane work?\nJust like Restylane, Perlane adds volume and fullness to the skin to correct moderate to severe facial wrinkles and folds. Like Restylane, Perlane is a clear gel formulation of hyaluronic acid that is specifically formulated to add fullness like your body’s own hyaluronic acid.\nWhat makes Perlane different is the average size of the particles and the depth of injection. On average, the gel particles in Perlane are larger than those in Restylane, which makes Perlane a good choice for wrinkles that benefit from a deeper injection into the skin.\nIn three clinical studies of 150 patients each, on average 70% of patients maintained improvement for six months after just one Perlane treatment. Most patients will require a treatment roughly every 6 to 9 months.\nThere are 6 different formulations of Restylane for different areas and results. Restylane is available with added lignocaine to reduce injection discomfort.\nRestylane has an intermediate gel particle size that makes it suitable for moderate wrinkles and lip enhancement. It is recommended that it is injected into the middle part of the dermis (middle layer of skin).\n- Restylane Touch\nPerlane has a larger gel particle size and is used for deep lines, facial contouring, and lip enhancement and is injected into the deep layer of the dermis.\nTouch is the smallest gel particle size in the Q-med range and is used for the correction of very thin superficial lines. It is injected into the upper part of the dermis.\n- Restylane Lipp\nLipp has been specially designed and formulated for injecting into the lips for enhancement and contouring of thin looking lips, the cupid’s bow, or to simply add fullness. It claims to be structured to withstand the range of mouth movements and strains – like talking, smiling, laughing and kissing – that characterise the lip area and therefore the effects should last longer.\n- Restylane SubQ\nSubQ has the largest gel particle size in the range and is used to replace fat loss in the face and create or restore a more defined facial contour. The procedure requires a larger needle and deeper injections below the skin layers. This product is promoted as an alternative to fat transfer. As a result, you will find fewer practitioners who are adequately trained to use SubQ.\n- Restylane Vital and Vital Light\nVital is aimed at a whole new approach to skin rejuvenation, using mesotherapy, (sometimes called biorevitalisation) techniques. It is targeted at a broad range of treatment areas including the face, neck, décolletage (the area between the neck and breasts) and hands; designed to replenish the hyaluronic acid lost through ageing, hence hydrating the skin and improving its elasticity and tone.\nMuch like Restylane Juvéderm® is available in various formats to be used in different parts of the face. These variations alter the depth of injection, the consistency and the duration of the product along with the suitable target areas.\nJuvéderm® 3 and 4 are most equivalent to Restylane and Perlane and the same things described above apply.\nJuvéderm® VOLUMA® is the equivalent of Restylane SubQ. Both can be used for facial volume.\nWhy is Facial Volume so important?\nA youthful face is characterised by smooth, round contours, high cheekbones, hollow jowls and a thin, well-defined jawline. These features together comprise the “triangle of beauty” or “heart of face”, with its base at the top and summit below. As we age, facial fat loss, gravity, and loss of the skin’s natural elasticity conspire to reverse this triangle’s composition, leading to a narrower, less youthful forehead and temple area, and a wider, heavier jawline.\nJuvéderm® VOLUMA® can restore the face’s balance and heart-shaped proportions, revolumising facial hollows and lost volume and recontouring the cheeks, cheekbones, and nose for a fuller, softer, more youthful appearance. Juvéderm® VOLUMA® helps recapture the facial volume that age and weight loss can diminish.\nWhat is Juvéderm® VOLUMA®?\nJuvéderm® VOLUMA® is an injectable hyaluronic volumiser that provides long-lasting restoration for facial volumes through injection. The results are immediate, even, and very natural looking.\nJuvéderm® VOLUMA® restores youthful volume to cheeks, cheekbones, and chin that have become hollow or thin due to weight loss or age-related facial fat loss. It can also rejuvenate the effects of a sagging facelift.\nWhat exactly is hyaluronic acid?\nHyaluronic acid (HA) is a naturally occurring substance found in the body that helps to hydrate and add volume to our skin. Natural hyaluronic acid is broken down by the body in one or two days so is constantly replaced. As we age this replacement mechanism diminishes so the moisturising and plumping effects of hyaluronic acid decrease. The hyaluronic acid used in Voluma® is stabilised and cross linked to achieve safe, long lasting results.\nAt what age should I start treatment with Juvéderm® VOLUMA®?\nJuvéderm® VOLUMA® is intended for use by adults. It is the ideal implant for remodelling facial volume and correcting a receding chin.\nHow long will the effects of treatment with Juvéderm® VOLUMA® last?\nThe average effect of treatment with Juvéderm® VOLUMA® lasts about 18 months. It may sometimes be shorter or longer depending on:\n- your age\n- your physiology\n- your lifestyle (smoking and exposure to sun or UV rays may shorten the effect)\n- the amount injected and the practitioner’s technique.\nWill the treatment hurt?\nMost Aesthetic doctor use the latest techniques to minimise any discomfort. These can include ice packs and skin vibration. Patients do not need local anaesthetics and after the treatment any discomfort usually settles very quickly.\nWhy Juvéderm® VOLUMA® and not a wrinkle filler?\nJuvéderm® VOLUMA® has been specifically developed to restore lost facial volume e.g. in the cheeks, cheekbones, and chin. While wrinkle fillers like Juvéderm® ULTRA offer excellent results when applied to fine lines and wrinkles around the mouth, nose, and eyes, Juvéderm® 4 and Juvéderm® VOLUMA® are often better suited to larger scale facial volumising.\nWhen can I return to work and resume my social life?\nThe aesthetic results are immediate and very natural looking. You can return to work and resume your social life immediately.\nAre there any side effects?\nFollowing injection, you may experience redness, slight swelling, or bruising at the injected area. Your doctor will inform you about this. These side effects will not last and can easily be covered up with your usual makeup.\nWhat about contraindications?\nThese do exist. They are not specifically related to Juvéderm® VOLUMA®, but to this type of treatment. This is why it is important to tell your doctor about any previous history of pathologies such as auto-immune diseases, allergies, known hypersensitivity to hyaluronic acid, any tendency to develop hypertrophic scars, immunotherapeutic treatment, inflammatory or infectious complaints (acne or cold sores) at injection sites, if you are pregnant or breast-feeding, any previous aesthetic treatment, particularly the use of permanent products.\nIs there anything I should know before I have the treatment?\nDo not take aspirin for at least three days before the injection session. During the injection, risk of bruising (haematoma) and swelling will be higher for patients under anti-coagulant treatment or taking aspirin.\nAre there any recommendations I should follow after treatment?\nYou are advised not to apply pressure to or massage the injection site during the first days following injection session. In the first week following treatment, the injected product may feel unduly firm as it settles into the surrounding tissue. This is normal and your Voluma® will feel soft and natural just like your own fatty pads.\nSculptra® is a synthetic injectable material known as “poly-L-lactic acid.” Poly-L-lactic acid is biocompatible (a material that does not harm the body) and biodegradable (able to be broken down by the body). Poly-L-lactic acid has been widely used for many years in dissolvable stitches, soft tissue implants, and other types of implants.\nHow does Sculptra® work?\nSculptra® is injected below the surface of the skin in the area of fat loss. Sculptra® provides a gradual increase in skin thickness. Visible results appear within the first few treatment sessions. Sculptra® will not correct the underlying cause of the facial fat loss, but will help improve the appearance by increasing skin thickness in the treated area. No skin testing is required prior to use.\nAre the results from Sculptra® immediate?\nNo. At your first treatment visit, it may appear that Sculptra® worked immediately because of swelling from the injections and the water used to dilute Sculptra®. In a few days, when the swelling goes down and the water is absorbed by your body, you may look as you did before your treatment. Sculptra® takes time to gradually correct the depression in your skin.\nHow many treatments are required?\nYour Aesthetic doctor will decide the appropriate number of treatment sessions and the amount of Sculptra® you will need at each session (average 4 to 6 vials). Patients with greater facial fat loss may require 6 to 8 vials.\nHow long do treatment results last?\nTreatment results will differ for each person. In a clinical study, the treatment results lasted for up to 2 years after the first treatment session, in most patients. Touch-up treatments may be needed to maintain the desired effect.\nDo injections of Sculptra® hurt?\nAs with any injection, injections with Sculptra® may be uncomfortable. This is minimised by judicious use of topical anaesthesia.\nWhat can I expect to happen at a treatment session?\n- Your Aesthetic doctor will answer all of your questions and prepare you for the treatment\n- Anaesthesia for the treatment area will be provided\n- The area where the injections will be given will be cleaned with an antiseptic\n- Sculptra® will be injected in small amounts into the skin using a very fine needle\n- Multiple injections will be needed\n- An ice pack should be applied to the treatment area to help reduce swelling.\nAfter the treatment session, the area should be thoroughly massaged to distribute the product evenly.\nWhat can I expect after treatment?\nImmediately following a treatment session with Sculptra®, redness, swelling, tenderness, bruising or all of these signs can happen in the treatment area. These signs usually go away in a few hours to a few days, but occasionally last longer. You should massage the treated area (a few times each day) for several days after the treatment session and an ice pack may be applied for a few minutes at a time to the treatment area to help reduce swelling. Avoid excessive sun and UV lamp exposure until any initial swelling and redness has resolved.\nMost patients feel comfortable going back to their normal activities following treatment. Make-up may be applied a few hours after treatment if no complications are present (for example, open wounds or bleeding).\nWhat are the possible side effects of treatment with Sculptra®?\nThe most common side effects with the use of Sculptra® include injection-related side effects at the site of the injection such as bleeding, tenderness or pain, redness, bruising, or swelling. These side effects generally last, on average, 3 to 17 days.\nPossible delayed side effect with Sculptra® can be small bumps under the skin in the treated area. These small bumps may not be visible, and you may notice them only when you press on the treated skin. These bumps tend to happen within the first 6 to 12 months after the first treatment.\nOccasionally, these bumps go away on their own. Visible bumps, sometimes with redness or colour change to the treated area, have also been reported. As with all procedures that involve an injection through the skin, there is a risk of infection.\nQuestions you should ask your doctor prior to any dermal filler treatment.\n- What are your qualifications? (the BCAM would always recommend an experienced doctor for your treatment)\n- How long have you been doing fillers?\n- How many patients have you treated?\n- Which fillers do you use and why?\n- Are there any alternatives that I should consider?\n- How often have your patients had “problems”?\n- Is the is filler dangerous?\n- What problems can occur?\n- Do you audit your results and patient satisfaction?\n- What do I do if there is a problem with my treatment?\n- Do you routinely follow up the result?\n- Do you have any patients who you have previously treated whom I could speak to?\n- How much does it cost? (this is the least important question).', 'WORDS HANNAH MAY-LEE WONG\nDr William Hoo\nBotulinum toxin injections and dermal fillers may seem similar, but they are two very different things. Although they are both injectable cosmetic treatments performed by aesthetic physicians, that’s pretty much where their similarities end. An expert in the field answers some frequently asked questions and tells us all we need to know about these two popular non-invasive procedures.\nTell us about the Botulinum toxin.\nBotulinum toxin (BTX) is a type of protein produced by the bacterium Clostridium botulinum. There are many different types and brand names of BTX that are registered as medication and are approved by the Ministry of Health (MOH).\nIn the medical field, BTX can be used to treat chronic migraines, muscle spasms (e.g. in children with cerebral palsy or in stroke patients who have lost control of their muscle movement), hyperhidrosis (excessive sweating) and more. In the medical aesthetic industry however, BTX is mainly used to reduce wrinkles.\nHow is it used in the beauty industry?\nBTX can be used to reduce dynamic wrinkles, which are wrinkles caused by repeated muscle movement associated with facial expressions, e.g. squinting, frowning and smiling. Common areas for injection are the glabella (frown lines), crow’s feet and forehead lines.\nA popular procedure in Asia is using BTX for face reshaping—for example, reshaping a square face to a more feminine oval face via size reduction of the masseter muscle. With special injection techniques, BTX can also be used for face lifting.\nBTX can help reduce the appearance of a “gummy smile”—a smile that shows gum excessively. This is done by weakening the muscles that strongly pulls up the upper lip. For men, many get BTX injections at the frown lines to get a more approachable, refreshing and “less angry” look.\nDoes it hurt?\nThe needles used for BTX injections are very fine. Additionally, the doctor may apply ice packs or numbing cream beforehand, so that you may only feel minimal discomfort during the injection.\nHowever, after the treatment, you might feel a bit heavy in the injected muscle area. BTX works by blocking nerve signals in the muscles where it was injected. As a result, the injected muscle would be temporarily relaxed or “asleep”. Extra effort is needed to move the affected muscle, so that area might feel heavy. Don’t worry, the sensation only lasts about 1 to 2 weeks, and then you’ll adapt to it.\n“BTX can be used to reduce dynamic wrinkles, which are wrinkles caused by repeated muscle movement”\nWhat is the after-care like?\nThere will be a needle injection mark at the injected site, therefore the goal is to prevent contamination and infection in the area. After treatment, avoid swimming and going for sauna sessions or massages. Don’t drink excessive amounts of alcohol, as alcohol causes vasodilation (the dilation of blood vessels). Avoid going for laser or facial treatments for about 3 days.\nHow long do the effects last?\nThe effects of BTX lasts around 3 to 6 months.\nWhat are the risks and possible complications?\nThe toxin effect of BTX may spread. If BTX is injected over the forehead, there is a small chance that the toxin may spread downwards and cause the eyelids to droop (ptosis) or cause the patient to have double vision. There are medications available to treat this if it happens.\nSome patients may experience headaches after treatment. BTX can also cause breathing difficulty or difficulty in pronouncing certain words when it is injected around the mouth area.\nIf the doctor injects unequal doses on the left and right side of the face, it may cause asymmetry, which can become obvious when a person is making expressions. Not to worry, you may go back to your doctor to correct the asymmetry; these effects are temporary and can be reversed after a period of time.\nWho should NOT get this treatment?\nPregnant women, those who are allergic or those who have had adverse reactions to BTX before.\nCan it become addictive?\nBTX in itself is not addictive, but people can get addicted to the beauty effects of BTX. The communication between the patient and the doctor is very important. The doctor needs to know when to advise the patient to stop, as too much BTX may make facial features and expressions to become unnatural (stiff or mask-like).\nWhat are fillers and how are they different from BTX injections?\nFillers are substances used to restore volume loss, whereas BTX is used to weaken the muscles that cause wrinkles. They are entirely different.\nThere are different types of fillers: hyaluronic acid fillers, synthetic fillers (e.g. calcium hydroxylapatite, silicone, etc.) and autologous fillers (i.e. fat transfer) which is a method of using fats from other parts of the body for reinjecting over the face. Hyaluronic acid fillers tend to be a popular choice in the aesthetic industry because it is the only type of filler which has an antidote, called hyaluronidase. If anything goes wrong during the treatment, it can be reversed quickly by the antidote.\nWhere in the face are fillers typically injected?\nPreviously, fillers were mainly used to restore volume, especially in the sunken under-eye area and in the lips. Nowadays, we use fillers for much more than that; fillers can be used to correct certain features on the face.\nAs we age, our features tend to sag and look tired. Many women experience volume loss in the under-eye area. The corners of the mouth and the lateral canthus of the eyes also tend to point downwards as a person gets older, which may make a woman look angry or sad all the time. Fillers can be used to plump up and restore volume in these areas, and it will overall result in the woman looking refreshed, and more feminine and youthful.\nCommon areas for filler injections are over the cheeks; under the eyes; at the temples; on the chin and on the lips. Some people who are allergic to BTX can opt for fillers too, as fillers can limit muscle movement and reduce the appearance of wrinkles—we call this myomodulation. Lastly, fillers can also be used to reduce the appearance of acne scars.\nHow long do the effects last?\nSome fillers produce effects, which last around 6 to 9 months, while others for up to 24 months. It all depends on the brand, the method of preparation and the concentration of fillers used.\nIt’s worth noting that if you get fillers for the second or third time, the amount of fillers needed will be less than before, and the effects will probably last longer. This is because when fillers are injected into an area, it stimulates collagen production.\nWhat are the risks?\nThe skill of the medical professional performing this treatment is a very important factor. Sometimes, fillers can cause asymmetry if the dose injected is not equal on both sides. Filler injections can cause lumps and bumps in the skin if the level of injection is too superficial. Sometimes, after getting fillers, some people might have redness, rashes, bruising or swelling over the treated area.\nThe more serious complications arise when the fillers are accidentally injected into a blood vessel—it can cause skin necrosis (cell death) or blindness.\nThe probability of risk also depends on the type of fillers being injected. Fillers are riskier if injected on the central area of the face—there are more blood vessels connected to the eyes, brain and nerves in the central area of the face. Hyaluronic acid fillers are more popular because it has an antidote to reverse the adverse effects, in case anything goes wrong.\nIt is highly advisable to consult a trained and certified medical professional from a reputable clinic, which uses good quality products. Regulation by the MOH requires the doctor to have a license to perform these procedures, and the clinic must also have an aesthetics treatment license. Lastly, all products used must be registered and approved by the MOH. HT\nIf you like this article, do subscribe here.']	['<urn:uuid:d4d618d0-919b-48b5-a6ab-ca29a3d63384>', '<urn:uuid:4de2914f-b5fc-4a57-8d8d-dc9f74365c59>']	factoid	direct	short-search-query	distant-from-document	three-doc	expert	2025-05-01T23:55:16.606337	5	61	4005
470	I'm doing research for my college assignment and was wondering what's the main difference between how old school scientists and modern researchers think about their own influence on what they study?	While positivists believe that the researcher and the researched person are independent of each other, postpositivists accept that theories, background, knowledge and values of the researcher can influence what is observed. However, postpositivists still pursue objectivity by recognizing the possible effects of biases.	"[""Individual differences |\nMethods | Statistics | Clinical | Educational | Industrial | Professional items | World psychology |\nPhilosophy Index: Aesthetics · Epistemology · Ethics · Logic · Metaphysics · Consciousness · Philosophy of Language · Philosophy of Mind · Philosophy of Science · Social and Political philosophy · Philosophies · Philosophers · List of lists\nIn philosophy and models of scientific inquiry, postpositivism (also called postempiricism) is a metatheoretical stance that critiques and amends positivism. While positivists believe that the researcher and the researched person are independent of each other, postpositivists accept that theories, background, knowledge and values of the researcher can influence what is observed. However, like positivists, postpositivists pursue objectivity by recognizing the possible effects of biases.\nPostpositivists believe that human knowledge is based not on unchallengeable, rock-solid foundations, but rather upon human conjectures. As human knowledge is thus unavoidably conjectural, the assertion of these conjectures is warranted, or more specifically, justified by a set of warrants, which can be modified or withdrawn in the light of further investigation. However, postpositivism is not a form of relativism, and generally retains the idea of objective truth.\nPostpositivists believe that a reality exists, like positivists do, though they hold that it can be known only imperfectly and probabilistically.\nOne of the first thinkers to criticize logical positivism was Sir Karl Popper. He advanced falsification in lieu of the logical positivist idea of verifiability. Falsificationism argues that it is impossible to verify that a belief is true, though it is possible to reject false beliefs if they are phrased in a way amenable to falsification. Thomas Kuhn's idea of paradigm shifts offers a broader critique of logical positivism, arguing that it is not simply individual theories but whole worldviews that must occasionally shift in response to evidence.\nPostpositivism is an amendment to positivism that recognizes these and other critiques against logical positivism. It is not a rejection of the scientific method, but rather a reformation of positivism to meet these critiques. It reintroduces the basic assumptions of positivism: ontological realism, the possibility and desirability of objective truth, and the use of experimental methodology. The work of philosophers Nancy Cartwright and Ian Hacking are representative of these ideas. Postpositivism of this type is common in the social sciences (especially sociology) for both practical and conceptual reasons.\nThere is an open controversy as to whether the work which best represents the origins of Postpositivism is that of Thomas Kuhn or that of Karl Popper. Whereas the work of those following Kuhn has led to a sociology of scientific knowledge, the work of those following Popper pursue classical problems of methodology and epistemology.\n- Logical Positivism\n- Models of scientific inquiry\n- Philosophy of science\n- Scientific method\n- Sociology of scientific knowledge\n- Robson, Colin (2002). Real World Research. A Resource for Social Scientists and Practitioner-Researchers (Second Edition), 624, Malden: Blackwell.\n- Alexander, J.C. (1995), Fin De Siecle Social Theory: Relativism, Reductionism and The Problem of Reason, London; Verso.\n- D.C. Philips & Nicholas C. Burbules (2000): Postpositivism and Educational Research. Lanham & Boulder: Rowman & Littlefield Publishers.\n- John H. Zammito (2004): A Nice Derangement of Epistemes. Post-positivism in the study of Science from Quine to Latour. Chicago & London: The University of Chicago Press.\n- Popper, K. (1963), Conjectures and Refutations: The Growth of Scientific Knowledge, London; Routledge.\n- Moore, R. (2009), Towards the Sociology of Truth, London; Continuum.\n- Karl Popper (1934) Logik der Forschung, rewritten in English as The Logic of Scientific Discovery (1959)\n- Thomas Kuhn (1962) The Structure of Scientific Revolutions\n- Karl Popper (1963) Conjectures and Refutations\n- Ian Hacking (1983) Representing and Intervening\n- Andrew Pickering (1984) Constructing Quarks\n- Peter Galison (1987) How Experiments End\n- Nancy Cartwright (1989) Nature's Capacities and Their Measurement""]"	['<urn:uuid:8f8b1b02-6afb-4f48-952f-d67817fa2c8e>']	factoid	with-premise	verbose-and-natural	distant-from-document	single-doc	novice	2025-05-01T23:55:16.606337	31	43	632
471	mortality timeline ash trees younger than ten years infected with chalara	Trees under 10 years of age are likely to die from Chalara fraxinea in 2-10 years.	"[""The Government's Chief Scientific Adviser, Sir John Beddington, established an expert group to advise on the scientific evidence and approach.\nChalara dieback of ash is a disease of ash trees caused by the fungus Chalara fraxinea  . The disease causes leaf loss and crown dieback in affected trees, and it may lead to tree death. Ash trees suffering from symptoms likely to be caused by Chalara fraxinea (C. fraxinea) are increasingly being found across Europe. These have included forest trees, trees in urban areas, and young trees in nurseries. C. fraxinea is a quarantine pest under national emergency measures.\nConfidence ratings as used below:\nHigh – supported by experimental evidence and repeated observations which have been published in peer-reviewed scientific literature.\nModerate – supported by long-term observation or multiple observations from reputable sources that come to the same conclusion, or by comparative analysis of related species.\nLow – supported by a few observations or many observations from reputable sources that are not suggesting a consistent pattern, or an accumulation of anecdotal evidence that suggests a consistent pattern.\nWhat is Chalara dieback of ash?\n1. Chalara dieback of ash is a disease of ash trees caused by the fungus Chalara fraxinea (Kowalski, 2006). The disease causes loss of leaves, dieback of the crown of the tree, and can lead to tree death (Kowalski and Holdenrieder, 2009). (High confidence)\n2. C. fraxinea has infected many species of ash, but with differing intensities (Forest Research, 2012). As some ash species show very few symptoms after infection, they may act as undetected carriers. There is evidence of low susceptibility to disease in some Asian ash trees (Drenkhan and Hanso, 2010). (Moderate confidence)\n3. Common ash (Fraxinus excelsior) is the most severely affected species. Young trees are particularly vulnerable to C. fraxinea and succumb to disease rapidly. (Kowalski, 2006; Forest Research, 2012). (High confidence)\n4. Chalara dieback has seriously affected a high percentage of ash trees in continental Europe (Forest Research, 2012; Bakys et al., 2009; Engesser et al., 2009; Halmschlager and Kirisits, 2008; Ioos et al., 2009; Kowalski and Holdenrieder, 2008; Lygis et al., 2005; Ogris et al., 2010; Szabo, 2009; Talgo et al., 2009), most notably in Scandinavia (including Denmark, which has an estimated 90 per cent of ash trees infected) and Baltic States. (High confidence)\n5. There is no evidence that C. fraxinea can spread to tree species other than ash or that it is harmful to the health of people or animals. (High confidence)\nHow does infection happen?\n6. Infection is via spores from fruit bodies on leaf litter. Spore production (in fruit bodies) occurs on infected fallen leaves and shoot material in the growing season after infection; trees are likely to need a high dose of spores to become infected (Timmermann et al., 2011). (High confidence)\n7. C. fraxinea infection starts primarily on leaves, and is progressive over time, with dieback and stem lesions usually manifesting in the next growing season. Leaf symptoms can be detected within two months of infection (experience from Denmark). (Moderate confidence)\n8. C. fraxinea causes infection from June – October, mainly in July – August (Timmermann et al., 2011; Kirisits and Cech, 2009; Kowalski and Holdenreider, 2009). Moist conditions favour production of the fruiting bodies. (High confidence)\nHow is infection likely to spread?\n9. Spores are produced on Chalara fruit bodies formed on fallen leaves and shoots the year following infection. Natural spread is by wind-blown spores (ascospores) from these fruiting bodies (Kowalski, 2006; Kirisits et al.2009; Kowalski and Holdenrieder, 2009; Queloz et al., 2010). (High confidence)\n10. Wind-blown spores cause the disease to spread up to 20-30 km per year (Solheim, 2009; Solheim, et al., 2011). On occasions, spores may disperse much further on the wind. Longer-distance spread occurs via infected plants or potentially via wood products (Husson et al, 2012; EPPO, 2010; Prokrym and Neeley, 2009). (High confidence on wind dispersal; Moderate confidence on untreated wood products).\n11. There is low probability of dispersal on clothing and footwear or via animals and birds. (High confidence). Transmission by routes other than wind and planting material are likely to pose a comparatively low risk, but the risk cannot be ruled out.\n12. C. fraxinea is found in seeds (Cleary M., et al. 2012), and this is reflected in the legislation, which restricts the movement of plants and seeds.\n13. There is a lower risk of C. fraxinea spreading over the winter because there is now a ban on ash plant and seed imports into the UK, restrictions on plant movements through Statutory Plant Health Notices, and spore production is not expected to resume until June 2013. (High confidence)\nWhat are the consequences of infection for ash tree health?\n14. Trees cannot recover from infection, but larger trees can survive infection for a considerable time and some might not die. (Current experience from Denmark). (High confidence)\n15. The impact of C. fraxinea infection depends on tree age, location, weather conditions and co-presence of honey fungus (Armillaria) or other secondary pathogenic / opportunistic organisms. Trees in forests are more susceptible because of the greater prevalence of honey fungus. Timber trees are generally felled before they are killed by honey fungus.\n- Trees under 10 years of age are likely to die from C. fraxinea in 2-10 years.\n- Trees under 40 years old will die in 3-5 years if also infected with honey fungus, and likely more rapidly if the tree is already debilitated.\n- For mature trees more than 40 years old, there is no direct evidence of tree deaths just from C. fraxinea to date, but there is little comprehensive survey data from Europe on which to base firm conclusions.\nFurther evidence would be helpful to strengthen the development of management options to minimise the environmental, economic and social impacts of Chalara fraxinea, including:\n- improving detection of Chalara;\n- iproving knowledge of the aetiology, pathology and epidemiology of Chalara;\n- uderstanding the nature and scale of the environmental, economic and social impacts of Chalara;\n- asessing how to mitigate the risks of Chalara; and\n- asessing ways to adapt to the presence of Chalara.\nBakys R, Vasaitis R, Barklund P, Ihrmark K and Stenlid J (2009). Investigations concerning the role of Chalara fraxinea in declining Fraxinus excelsior. Plant Pathology 58, 284-292.\nCleary M, Arhipova N, Gaitnieks, T Stenlid J and Vasaitis, R (2012) Natural infection of Fraxinus excelsior seeds by Chalara fraxinea Forest Pathology: 1-8\nEngesser R, Queloz V, Meier F, Kowalski T and Holdenrieder O (2009). Das Triebsterben der Esche in der Schweiz. Wald u. Holz 6, 24–27.\nEPPO (2010). Workshop on Chalara fraxinea, Oslo, Norway, 30 June to 2 July 2010.\nForest Research (2012). Rapid assessment of the need for a detailed Pest Risk Analysis for Chalara fraxinea\nHalmschlager E and Kirisits T (2008). First report of the ash dieback pathogen Chalara fraxinea on Fraxinus excelsior in Austria. New Disease Reports 17.\nHusson C, Caël O, Grandjean J-P, Nageleisen L-M and Marçais B (2012). Occurrence of Hymenoscyphus pseudoalbidus on infected ash logs. Plant Pathology 61: 889-895.\nIoos R, Kowalski T, Husson C and Holdenrieder O (2009). Rapid in planta detection of Chalara fraxinea by a real-time PCR assay using a dual-labeled probe. European Journal of Plant Patholology 125, 329-335.\nKirisits T and Cech TL (2009). Zurücksterben der Esche in Österreich: Ursachen, Verlauf, Auswirkungen und mögliche Forstschutz- und Erhaltungsmaßnahmen.\nKirisits T, Matlakova M, Mottinger-Kroupa S, Cech TL and Halmschlager E. (2009). The current situation of ash dieback caused by Chalara fraxinea in Austria. In: Proceedings of the Conference of IUFRO Working Party 7.02.02, Eg? irdir, Turkey, 11–16 May 2009. (Ed. by Dogmus-Lehtija T.) SDU Faculty of Forestry Journal, ISSN: 1302-7085, Serial: A, Special Issue: pp. 97–119.\nKowalski T (2006). Chalara fraxinea sp. nov. associated with dieback of ash (Fraxinus excelsior) in Poland. Forest Pathology 36, 264-270.\nKowalski T and Holdenrieder O (2008). A new fungal disease of ash in Europe. Schweiz. Z. Forstwes 159, 45–50.\nKowalski T and Holdenrieder O (2009). Pathogenicity of Chalara fraxinea. Forest Pathology 39, 1–7.\nLygis V, Vasiliauskas R, Larson K-H and Stenlid J (2005). Wood-inhabiting fungi in stems of Fraxinus excelsior in declining ash stands of northern Lithuania, with particular reference to Armillaria cepistipes. Scandinavian Journal of Forest Research 20, 337-346.\nOgris N, Hauptman T, Floreancig V, Marsich F and Montecchio L (2010). First report of Chalara fraxinea on common ash in Italy. Plant Disease 94(1): 133. DOI: 10.1094/PDIS-94-1-0133A.\nQueloz V, Grünig CR, Berndt R, Kowalski T, Sieber TN and Holdenrieder O (2010). Cryptic speciation in Hymenoscyphus albidus. Forest Pathology. doi: 10.1111/j.1439-0329.2010.00645.x.\nProkrym DR and Neeley AD (2009). NPAG Report. Chalara fraxinea (T. Kowalski): Ash dieback. Ascomycetes / Incertae sedis. ET Approval Date: 03/13/2009. New Pest Advisory Group (NPAG) Plant Epidemiology and Risk Analysis Laboratory Center for Plant Health Science & Technology.\nSzabo I (2009). First report of Chalara fraxinea affecting common ash in Hungary. Plant Pathology 58, 797.\nSolheim H (2009). Bekymringsfull økning i askeskuddsjuka: Trær ser ut til å dø. Skogeieren 96 (7-8): 24-25.\nSolheim H, Timmermann V, Børja I & Hietala AM (2011). Yggdrasils helsetilstand - Askeskuddsjuke er på frammarsj. Skogeieren 96 (1): 34-36.\nTalgo V, Sletten A, Brurberg MB, Solheim H, and Stensvand A (2009). Chalara fraxinea isolated from diseased ash in Norway. Plant Disease 93(5): 548. DOI: 10.1094/PDIS-93-5-0548A.\nTimmermann V, Børja I, Hietaka AM, Kirisits T and Solheim H (2011). Ash dieback: pathogen spread and diurnal patterns of ascospore dispersal, with special emphasis on Norway. EPPO Bulletin, 41: 14-20. doi: 10.1111/j.1365-2338.2010.02429.x\n[Version 2 - updated 09.11.12 to reflect emerging knowledge – point 4 and point 10 have been modified.]\n Chalara fraxinea is the asexual form (anamorph) of Hymenoscyphus pseudoalbidus, responsible for the current ash dieback epidemic in Europe (Kowalski, 2006; Queloz et al., 2010). For ease of reference, Chalara fraxinea is used as the common term in this document.""]"	['<urn:uuid:516e197d-cb93-4fd1-8274-c306b38481cb>']	factoid	direct	long-search-query	distant-from-document	single-doc	expert	2025-05-01T23:55:16.606337	11	16	1636
472	What benefits do companies see when workers are more engaged?	According to research, organizations with engaged employees see multiple benefits: 41% lower absenteeism, 17% higher productivity, 40% fewer defects in work quality, 21% higher profitability, and 20% higher sales. They also experience 58% fewer patient safety incidents, 70% fewer general safety incidents, and higher customer ratings. Additionally, these organizations outperform competitors, have higher earnings per share, and recover more quickly after financial setbacks.	['Employee Engagement is a fundamental concept used in an effort to understand and describe, both qualitatively and quantitatively, the nature of the relationship between an organization and its employees. Employee engagement in the corporate world is directly related to good corporate governance and not solely focusing on the bottom line and revenues of the organisation. Successful organizations are value-driven with employee-centric cultures. It stands in an unspecified relationship to earlier constructs such as morale and job satisfaction. A conventional focus on employees in accordance with the goals of the organisation will lead to precipitous gains as well as the well-being of the employees.\nAn apotheosis of the pivotal concept can be witnessed through an example of the United Kingdom. In culmination of lack of employee engagement, recent revisions have been made in UK Corporate Governance code which will be applicable by 1st Jan 2019. Most salient changes are:\n• For engagement with the workforce, the Code recommends one of three employee engagement mechanisms: (i) a director appointment from the workforce; (ii) a formal workforce advisory panel; or (iii) a designated non-executive director. The FRC (Financial Reporting Council) leaves it up to individual companies to choose the right mechanism or combination of mechanisms, or to choose an alternative arrangement.\n• In a change from the proposals, the board (rather than the remuneration committee) will now have the responsibility of overseeing workforce policies and practices. The remuneration committee will have responsibility only for remuneration-related matters and will be responsible for reviewing workforce remuneration and related policies.\nThis will not only lead to better corporate governance, namely, transparency, integrity, ethics, fairness. But, at the same time will attract larger investments in the long term considering the wider horizon of opportunities.\nMany would ask the question that “How can focusing on employees bolster the organisational goals?”. The answer to which can be given by considering the exact opposing case of lack of focus.\nStudies show a dramatic increase in both worker and business performance when an organization effectively sets and closely ties individual employee goals to the company’s overall strategy. Yet amazingly, a mere 7% of employees today fully understand their company’s business goals and strategies and what’s expected of them in order to help achieve organisational goals due to the lack of opportunities given to employees in the decision making processes.\nTop airline companies like Air India, Jet Airways and Vistara have constantly tackled with operational disruptions due to well-orchestrated strikes by their cabin crew. This clearly indicates serious lapses on the levels of employee satisfaction within the organisations. That said, such cases aren’t just limited to the aviation industry, many others like hotels, real estate, media, medical etc. have witnessed a tremendous volume of similar cases where employees weren’t taken into consideration resulting in severe outcomes like bankruptcy, decline in share value and several other decrees of organizational paralysis.\nIn a recent survey conducted by Times Jobs across various Industries, HR managers have boldly stated that during the disengagement phase with their employees, the management had seen 40% higher absenteeism, 50% more accidental cases, and 75% more errors and defects in the daily tasks. Besides these organisations have also experienced lower productivity, lower profitability and lower job growth in the same period. Interestingly, with improvement in engagement levels, the same organisations have enjoyed a rise of over 50% in productivity and 30-50% in job applications, reported 75% organisations in the survey. Organizations with an engaged workforce outperform their competition. They have higher earnings per share (EPS) and recover more quickly after recessions and financial setbacks. Hence, employee engagement is a key differentiator when it comes to growth and innovation.\nFurthermore, for any Industry or business to thrive in the longer run, the organisational goals will not only need to be smarter, they will be required to be more cohesive, more productive than its larger competitors and also be more focused towards their employees as well as shareholders to have close ties with them. To be effective, goals must serve both the needs of the company and those of its employees and other stakeholders. For the company, goals must be fed by both short and long-term business strategies. For the employees, goals must be clear, objective, and understandable or they will quickly become disengaged.', 'What is Employee Engagement?\nEmployee engagement is a measure of how committed and involved an employee is at work, and is a key part of the employee’s relationship with the organization they work for. The number one driver of engagement is when an employee feels like their manager and leaders care about them.\nBut engagement is not the same as employee satisfaction, which is a measure of how content an employee is at work and with their organization. This term has become a common area of interest for organizations as it relates to many other important factors to business success, including employee retention, productivity, and even workplace safety.\nWhy Employee Engagement Matters\nEmployee engagement is important for many reasons. Unfortunately, most organizations misunderstand its importance and focus solely on engagement when they should also focus on things like employee access, employee experience, and employee satisfaction. These three other factors are key influences on how engaged an employee is at work.\nBut employee engagement matters because it indicates when an employee is actively engaged in their work or workplace culture. Although it is equally as important to focus on an employee’s job performance, engaged employees also actively participate in company culture and help drive culture. Research from Gallup has also shown that it is tied to many other critical business outcomes that clearly demonstrate the return on investment (ROI) of increased engagement.\nGallup Research on Employee Engagement\nGallup has conducted extensive research on this topic and its impacts on a company. In Gallup’s Employee Engagement Meta-Analysis, they found that when engagement improves, this results in improved employee performance. They found that better engagement led to 41% lower absenteeism, 17% higher productivity, 58% fewer patient safety incidents, and 70% fewer safety incidents. Improved employee experience also leads to an increase in quality with 40% fewer defects and 10% higher customer ratings. Employee engagement is positively correlated with profit as well with 21% higher profitability and 20% higher sales when employees are engaged. And highly engaged employees turnover less often.\nHow Do You Measure Employee Engagement?\nMeasuring employee engagement is often a difficult task because there are many different definitions of what it is. Many organizations use an annual employee engagement survey to measure engagement. These surveys are often composed of questions that help the organization measure eNPS (or employee net promoter score), employee satisfaction, and employee commitment to the organization.\nBut there are more ways to measure engagement. Many internal communications professionals will track engagement on internal messages. This includes tracking likes, comments, social shares, and general channel usage (e.g. logins and session duration). This helps understand which employees are using tools regularly and who are willing to go out of their way to engage on a message. That said, just because an employee doesn’t engage with content does not necessarily mean they are disengaged employees. Measuring content engagement is just one input that can be analyzed when assessing employee engagement.\nHow Do You Improve Employee Engagement?\nImproving staff engagement requires a strategy that looks beyond vanity metrics like content engagement. To improve this metric, you have to do more than improve content quality. A common trend in the workplace is to look to improve culture and engage employees with things like pool tables, events, or other workplace perks. But the truth is, that improving engagement requires holistically improving the employee experience. Here’s why.\nWhen you improve employee experience, you increase employee satisfaction. When employees are satisfied and have a supportive, inclusive, and positive work experience, employee engagement will go up.\nSo, how do you improve the employee experience? It starts with an employee listening strategy to collect employee feedback through things like employee surveys or focus groups. We also recommend measuring regularly and conducting employee engagement surveys to keep a finger on the pulse at your organization. To improve employee experience, you need to go beyond wants like fun workplace perks and focus on employee needs. What tools or information are they lacking to get their jobs done? Are their managers effective communicators and coaches? Are you providing them with a basic living wage and benefits package? Do employees feel connected to one another and respected? Tackling some of these basic needs are key to improving both employee experience and engagement.\nHow is Employee Engagement Tied to Employee Experience?\nEmployee engagement is intrinsically linked to employee experience. If employee experience is poor at your organization, it is likely that engagement will also be low.\nEmployee Engagement Trends\nEmployee engagement has remained fairly consistent over the last decade. Thirty years ago, 70% of employees were not engaged at work. In 2019, that number had barely changed; 69% of employees were actively disengaged.\nDuring the 2020 COVID-19 Pandemic, however, we did see some slight increases in engagement. Despite some gains in workplace engagement, there are additional challenges we tracked in 2020. With 61% of American workers working remotely full time in 2020, this increased the need for connection, collaboration, and communication. And we see these same wants and needs among the deskless workforce.\nTo increase these three key areas of an employee’s experience will require a strong partnership between internal communications and human resources. It will also require a need to improve frontline manager communication by helping them to conduct daily or weekly team huddles (also called: team standups, pre-shift meetings, post-shift meetings). And internal communications professionals will need to focus on focus groups to keep a finger on the pulse of the employee body.\nAnother key employee engagement trend will be the importance of senior leaders to be transparent, authentic, and open. And this will create a great opportunity for internal communications professionals to demonstrate to executive leadership that they are strategic advisors.\nAnd last, one of the biggest trends is the importance of building an amazing workplace culture. Often high performing employees churn because of dysfunctional cultures and poor management, and great cultures attract top talent.\nHow Effective Communication Boosts Employee Engagement\nWhen an organization has effective internal communication, there is a positive impact on employee engagement. This is because an all-inclusive communication strategy gives all employees access to the information they need to do their job and feel supported. Without access to communication, or the ability to comment or provide feedback, it is difficult for employees to feel included and, therefore, to engage.\nHow Does theEMPLOYEEapp Help Improve Employee Engagement?\ntheEMPLOYEEapp improves employee engagement by giving all employees—from the office to the frontline—access to communication, resources, and senior leadership.\nOur mobile internal communications app also gives administrators the ability to target and personalize content to specific employee groups, which makes content more relevant to the intended audience. When content is more relevant, an employee will feel more included and important to the organization, in addition to feeling like the organization understands their role, their needs, and their wants.\ntheEMPLOYEEapp also is set up with many ways to engage, including likes, comments, social sharing, survey integrations, an employee directory, and a calendar. This gives employees a way to ask questions, provide feedback, get in touch with the right people or departments, and participate in company events.\nLearn more about how we can help:']	['<urn:uuid:59c417f6-2d0c-44c3-9d7b-8da2af33624e>', '<urn:uuid:57a0d88c-48ba-4c63-937e-060fefc09097>']	factoid	direct	concise-and-natural	distant-from-document	three-doc	expert	2025-05-01T23:55:16.606337	10	63	1903
473	expert botanist seeking differences stinging nettle hemp seeds safety consumption preparation methods	Stinging nettle and hemp seeds have different safety considerations and preparation requirements. Fresh stinging nettle leaves have hair-like barbs that can cause burning, itching, redness and swelling upon contact, so they must be processed (dried, freeze-dried or cooked) before consumption. Once processed, nettle can be safely used in soups, stews, smoothies, or as tea. In contrast, hemp seeds can be safely consumed raw, with no processing required. They can be eaten as is, roasted, used to make milk or cheese substitutes, or cold-pressed for oil. Hemp seeds contain negligible amounts of THC (0.001%) and won't cause psychoactive effects. Both plants require caution in specific circumstances - nettle may interact with blood thinners and diabetes medications, while hemp seeds may interact with anticoagulants and are not recommended during pregnancy.	"['Stinging nettle (Urtica dioica) has been a staple in herbal medicine since ancient times.\nAncient Egyptians used stinging nettle to treat arthritis and lower back pain, while Roman troops rubbed it on themselves to help stay warm (1).\nIts scientific name, Urtica dioica, comes from the Latin word uro, which means “to burn,” because its leaves can cause a temporary burning sensation upon contact.\nThe leaves have hair-like structures that sting and also produce itching, redness and swelling (\nHowever, once it is processed into a supplement, dried, freeze-dried or cooked, stinging nettle can be safely consumed. Studies link it to a number of potential health benefits.\nHere are 6 evidence-based benefits of stinging nettle.\nStinging nettle’s leaves and root provide a wide variety of nutrients, including (1):\n- Vitamins: Vitamins A, C and K, as well as several B vitamins\n- Minerals: Calcium, iron, magnesium, phosphorus, potassium and sodium\n- Fats: Linoleic acid, linolenic acid, palmitic acid, stearic acid and oleic acid\n- Amino acids: All of the essential amino acids\n- Polyphenols: Kaempferol, quercetin, caffeic acid, coumarins and other flavonoids\n- Pigments: Beta-carotene, lutein, luteoxanthin and other carotenoids\nWhat’s more, many of these nutrients act as antioxidants inside your body.\nAntioxidants are molecules that help defend your cells against damage from free radicals. Damage caused by free radicals is linked to aging, as well as cancer and other harmful diseases (\nSummary Stinging nettle offers a variety of vitamins, minerals, fatty acids, amino acids, polyphenols and pigments — many of which also act as antioxidants inside your body.\nInflammation is your body’s way of healing itself and fighting infections.\nHowever, chronic inflammation can inflict significant harm (\nStinging nettle harbors a variety of compounds that may reduce inflammation.\nIn human studies, applying a stinging nettle cream or consuming stinging nettle products appears to relieve inflammatory conditions, such as arthritis.\nFor instance, in one 27-person study, applying a stinging nettle cream onto arthritis-affected areas significantly reduced pain, compared to a placebo treatment (\nIn another study, taking a supplement that contained stinging nettle extract significantly reduced arthritis pain. Additionally, participants felt they could reduce their dose of anti-inflammatory pain relievers because of this capsule (\nThat said, research is insufficient to recommend stinging nettle as an anti-inflammatory treatment. More human studies are needed.\nSummary Stinging nettle may help suppress inflammation, which in turn could aid inflammatory conditions, including arthritis, but more research is needed.\nUp to 50% of men aged 51 and older have an enlarged prostate gland (\nAn enlarged prostate is commonly called benign prostatic hyperplasia (BPH). Scientists aren’t sure what causes BPH, but it can lead to significant discomfort during urination.\nInterestingly, a few studies suggest that stinging nettle may help treat BPH.\nStopping this conversion can help reduce prostate size (\nHowever, it’s unclear how effective stinging nettle is compared to conventional treatments.\nSummary Stinging nettle may help reduce prostate size and treat symptoms of an enlarged prostate gland in men with BPH.\nHay fever is an allergy that involves inflammation in the lining of your nose.\nStinging nettle is viewed as a promising natural treatment for hay fever.\nTest-tube research shows that stinging nettle extracts can inhibit inflammation that can trigger seasonal allergies (\nThis includes blocking histamine receptors and stopping immune cells from releasing chemicals that trigger allergy symptoms (\nWhile this plant may prove a promising natural remedy for hay fever symptoms, more long-term human studies are needed.\nSummary Stinging nettle may reduce hay fever symptoms. Yet, some research indicates that it may not be much more effective than a placebo. More studies are needed on stinging nettle’s effects on hay fever.\nApproximately one in three American adults has high blood pressure (\nHigh blood pressure is a serious health concern because it puts you at risk of heart disease and strokes, which are among the leading causes of death worldwide (\nStinging nettle was traditionally used to treat high blood pressure (\nAnimal and test-tube studies illustrate that it may help lower blood pressure in several ways.\nHowever, stinging nettle’s effects on blood pressure in humans are still unclear. Additional human studies are needed before recommendations can be made.\nSummary Stinging nettle may help lower blood pressure by allowing your blood vessels to relax and reducing the force of your heart’s contractions. Yet, more human studies are needed to confirm these effects.\nIn a three-month study in 46 people, taking 500 mg of stinging nettle extract three times daily significantly lowered blood sugar levels compared to a placebo (\nDespite promising findings, there are still far too few human studies on stinging nettle and blood sugar control. More research is necessary.\nSummary While stinging nettle may help lower blood sugar levels, more human studies are crucial before recommendations can be made.\nStinging nettle may offer other potential health benefits, including:\n- Reduced bleeding: Medicines containing stinging nettle extract have been found to reduce excessive bleeding, especially after surgery (\n- Liver health: Nettle’s antioxidant properties may protect your liver against damage by toxins, heavy metals and inflammation (\n- Natural diuretic: This plant may help your body shed excess salt and water, which in turn could lower blood pressure temporarily. Keep in mind that these findings are from animal studies (\n- Wound and burn healing: Applying stinging nettle creams may support wound healing, including burn wounds (\n37, 38, 39).\nSummary Stinging nettle’s other potential health benefits include lessened bleeding, boosted liver health and wound healing.\nConsuming dried or cooked stinging nettle is generally safe. There are few, if any, side effects.\nHowever, be careful when handling fresh stinging nettle leaves, as their hair-like barbs can harm your skin.\n- Formic acid\nThese compounds can cause rashes, bumps, hives and itchiness.\nIn rare cases, people may have a severe allergic reaction, which can be life-threatening.\nHowever, these chemicals diminish as the leaves are processed, meaning that you shouldn’t experience mouth or stomach irritation when eating dried or cooked stinging nettle (1).\nSpeak to your doctor before consuming stinging nettle if you’re taking one of the following:\n- Blood thinners\n- Blood pressure medication\n- Diuretics (water pills)\n- Diabetes medication\nStinging nettle could interact with these medications. For instance, the plant’s potential diuretic effect may strengthen the impact of diuretics, which can raise your risk of dehydration.\nSummary Dried or cooked stinging nettle is safe to eat for most people. However, you shouldn’t eat fresh leaves, as they may cause irritation.\nStinging nettle is incredibly easy to add to your daily routine.\nIt can be purchased in many health food stores, but you can also grow it yourself.\nYou can buy dried/freeze-dried leaves, capsules, tinctures and creams. Stinging nettle ointments are often used to ease osteoarthritis symptoms.\nThe dried leaves and flowers can be steeped to make a delicious herbal tea, while its leaves, stem and roots can be cooked and added to soups, stews, smoothies and stir-frys. However, avoid eating fresh leaves, as their barbs can cause irritation.\nCurrently, there is no recommended dosage for stinging nettle products.\n- Enlarged prostate gland: 360 mg of root extract per day\n- Allergies: 600 mg of freeze-dried leaves per day\nIf you buy a stinging nettle supplement, it’s best to speak to your doctor before trying it and to follow the instructions that come with it.\nSummary Stinging nettle is very versatile. It can be cooked in stews and soups, brewed as an herbal tea, applied as an ointment and taken as a supplement.\nStinging nettle is a nutritious plant popular in Western herbal medicine.\nStudies suggest that it may reduce inflammation, hay fever symptoms, blood pressure and blood sugar levels — among other benefits.\nWhile fresh stinging nettle may cause irritation, cooked, dried or freeze-dried stinging nettle is generally safe to consume.\nIf you’re curious, try adding this leafy green to your diet today.', ""Everything You Need to Know About How to Eat Hemp Seeds\nManitoba Harvest Hemp Foods\nAs far as the nut and seed world goes, hemp seeds are like the straight-A student who’s also captain of the football team. A couple of spoonfuls of hemp seeds packs a serious amount of essential nutrients, they’re easy to eat and cook with, and they have a pleasantly nutty taste, like a cross between a sunflower seed and a pine nut. And no, they won’t get you remotely high. Here’s everything you need to know about how to buy and eat these little seeds.\nAlthough hemp and marijuana are members of the same species, Cannabis sativa, they’re in effect completely different plants. There are about a dozen varieties of hemp plants that are grown for food, and all of them contain about 0.001 percent Tetrahydrocannabinol, or THC, the main psychoactive ingredient in marijuana. This means you can eat as much hemp as you want and you’ll never have to worry about getting high or failing a drug test. Although certain states have begun to legalize the cultivation of industrial hemp in the last couple of years, the hemp seeds you can find at your grocery or health food store were likely grown in Canada or China.\nHemp plants grow brown popcorn kernel-sized hard seeds. Inside these hard seeds lie soft, white or light green inner kernels that are packed with essential amino acids, protein, and omega-3 fatty acids. You can’t really derive a lot of nutritional value from the unhulled seeds, so when you see a bag at the store labeled “hemp seeds,” what you’re actually buying is those soft inner kernels, also known as hemp hearts. Hemp hearts can be pressed to make hemp seed oil, leaving behind a byproduct that can be turned into hemp protein powder. You can find all of these hemp products at health food stores, or a well-stocked grocery store like Whole Foods.\nEating shelled hemp seeds, or hemp hearts, is as simple as sprinkling a spoonful or two into smoothies or on top of cereal, salads, or yogurt, says Kelly Saunderson of Manitoba Harvest Hemp Foods, the world’s largest hemp foods manufacturer. People with gluten sensitivity can use hemp seeds as a substitute for breadcrumbs to coat chicken or fish. Just like you can blend almonds and water to make almond milk, you can do the same with hemp seeds for hemp seed milk, which you can use as an alternative to dairy milk in drinks and recipes. And because of its nutty flavor, hemp seeds make a great substitute for people with nut allergies—you can dry-toast them over low heat to bring out even more of that nuttiness.\nHemp seed oil should be used as a finishing oil, rather than a cooking or frying oil, since the delicate omega fatty acids will break down during the cooking process, stripping the oil of its nutritional benefits. Instead, use it to make salad dressings, or drizzle over pasta, grilled veggies, or popcorn.\nHemp seeds are considered one of the most valuable plant-based proteins out there. Here's what you need to know about how to eat them.\nHemp Seeds: Are They Good for You?\nIn this Article\nIn this Article\nIn this Article\n- Nutrition Information\n- Potential Health Benefits of Hemp Seeds\n- Potential Risks of Hemp Seeds\nHemp seeds are a rich source of nutrients. Part of the hemp plant, these seeds are technically a nut that can be eaten raw or used to make milk, oil, cheese substitutes, or protein powder.\nWhile related to the cannabis plant, hemp seeds have little to none of the psychoactive compound THC found in marijuana. For centuries the seeds have been used for oral and topical applications to treat and prevent certain health issues. A growing body of modern clinical research is backing up many of these claims.\nHemp seeds’ nutty flavor and versatility also make them a great substitute for the levels of protein, essential fatty acids, and other nutritional benefits found in meat and dairy products.\nHemp seeds can be:\n- Eaten raw, roasted, or cooked\n- Shelled as hemp hearts\n- Cold-pressed to produce hemp seed oil\n- Used for non-dairy hemp milk and hemp cheese\nA 30 gram serving (three-tablespoons) of raw hemp seeds contains:\n- Calories: 166\n- Protein: 9.47 grams\n- Fat: 14.6 grams\n- Carbohydrates: 2.6 grams\n- Fiber: 1.2 grams\n- Sugar: 0.45 grams\nHemp seeds are also good source of:\nHemp seeds also contain high levels of omega-3 and omega-6 essential fatty acids.\nStudies have shown that the ideal ratio for the fatty acids in hemp seeds is 3 to 1. At this ratio, these fatty acids help to support healthy cholesterol levels, immune system function, and may help regulate your metabolism.\nPotential Health Benefits of Hemp Seeds\nHemp seeds are an excellent source of plant-based protein. They contain all nine essential amino acids, and research suggests that hemp’s protein content is well-absorbed by our bodies.\nIn addition to this protein load, hemp seeds history is tied to their potential health benefits. Many modern studies have backed up several of these claims.\nHemp seeds’ health benefits include:\nHemp seeds are a great source of magnesium, which helps regulate your heartbeat and is linked to the prevention of coronary heart disease. They also contain Linoleic acid, which one study found reduced participants’ cholesterol levels by 15% and may act to reduce blood pressure.\nOne of the omega-6 fatty acids in hemp seeds is gamma-linolenic acid (GLA,) which may have anti-inflammatory effects similar to drugs like ibuprofen. One study found a 75% reduction in arthritis-associated pain in participants after nine months of GLA supplementation.\nHemp oil can be used in cooking to add nutritional benefits to your meal, and it can also be applied topically to the skin. Studies have found that hemp seed oil can relieve the symptoms of eczema and improve dry or itchy skin.\nResearch is ongoing, but hemp seed oil’s antimicrobial and anti-inflammatory effects may also help to treat acne.\nThe ratio of omega-6 to omega-3 fatty acids in hemp seeds is the optimal level for nutritional benefit. This balance supports both heart and cognitive health and is often lacking in most diets..\nHemp seeds also contain plant compounds called terpenes. While research is ongoing, studies suggest that terpenes may help protect the brain and prevent tumor growth.\nPotential Risks of Hemp Seeds\nWhile the fat content in hemp seeds comes primarily from its healthy essential fatty acids, eat them in moderation to meet your recommended daily consumption of fat. High fat intake can also cause nausea or diarrhea.\nOther things to consider before adding hemp seeds to your diet include:\nHemp seeds may interact with certain medications including anticoagulants.\nStudies have shown that hemp seeds reduce blood clotting, which can interact with blood-thinner prescriptions.\nThere is not enough clinical research to show that hemp is safe either orally or topically for women who are pregnant or breastfeeding, so it is not recommended.\nHemp seed shells can contain trace amounts of THC, the active psychoactive compound in marijuana. People with a previous dependence on cannabis may consider looking for an alternative.\nThe fiber content in hemp seeds can cause digestive discomfort like bloating, nausea, or constipation in large amounts. Make sure to drink plenty of water when eating hemp seeds to help avoid gut problems.\nCannabis and Cannabinoid Research. “Cannabis sativa (Hemp) Seeds, Δ9-Tetrahydrocannabinol, and Potential Overdose.”\nBiochemical Education: “The action of vitamin K and coumarin anticoagulants.”\nJournal of Agricultural and Food Chemistry: “Evaluating the Quality of Protein From Hemp Seed (Cannabis sativa L.) Products Through the Use of the Protein Digestibility-Corrected Amino Acid Score Method.”\nJournal of Dermatological Treatment: “Efficacy of dietary hempseed oil in patients with atopic dermatitis.”\nJournal of Thrombosis and Haemostatis: “Dietary hempseed reduces platelet aggregation.”\nOilseeds and fats, Crops and Lipids:“A short review on sources and health benefits of GLA, The GOOD omega-6.”\nMayo Clinic. Dietary fiber: Essential for a healthy diet.”\nNutrients: “Dietary Magnesium and Cardiovascular Disease: A Review with Emphasis in Epidemiological Studies.”\nNutrition & Metabolism: “The cardiac and haemostatic effects of dietary hempseed.”\nPlant Science: “Terpenes in Cannabis sativa – From plant genome to humans.”\nPLOS One: “The ameliorative effect of hemp seed hexane extracts on the Propionibacterium acnes-induced inflammation and lipogenesis in sebocytes.”>\nThe British Medical Journal (BMJ): “The importance of a balanced ω-6 to ω-3 ratio in the prevention and management of obesity.”\nThe Brown University Child and Adolescent Behaviour Letter: “FDA on CBD in pregnancy and breastfeeding”\nUSDA FoodData Central: “Seeds, hemp seed, hulled.”\nFind out what the research says about hemp seeds, who should have them, and how they may affect your health.""]"	['<urn:uuid:c31004e9-2294-4388-b58b-47dca5332759>', '<urn:uuid:90f872e9-1d37-4157-b349-fb3a11e970bf>']	open-ended	with-premise	long-search-query	distant-from-document	comparison	expert	2025-05-01T23:55:16.606337	12	128	2770
475	When did Lu Xun shift Chinese literature away from aristocratic writing?	Lu Xun effected this shift in Chinese letters in the early twentieth century, moving from ornate, obsequious literature of aristocrats to plain, expressive literature of the masses.	"['The History of chinese language Philosophy is a finished and authoritative exam of the routine and thinkers that experience formed chinese language philosophy over the past 3 thousand years. a superb group of foreign members supply seventeen available entries organised into 5 transparent components:\nIdentity of chinese language Philosophy\nClassical chinese language Philosophy (I): Pre-Han Period\nClassical chinese language Philosophy (II): From Han via Tang\nClassical chinese language Philosophy (III): From Song Through Early Qing\nModern chinese language Philosophy: From overdue Qing Through twenty first Century\nThis extraordinary assortment is key examining for college kids of chinese language philosophy, and may be of curiosity to these trying to discover the lasting value this wealthy and complicated philosophical culture.\nThe tale of the search for a real-life Shangri-La within the darkest center of the Himalayas– a century-long obsession to arrive the sacred hidden middle of 1 of the world\'s final uncharted realms.\nAt the a long way japanese finish of the Himalayas in Tibet lies the Tsangpo River Gorge, referred to as “the nice romance of geography” through the 19th century\'s golden age of exploration. the following the strong Tsangpo funnels into an impenetrable canyon 3 miles deep, walled off from the surface international by means of twenty-five thousand foot peaks. just like the earthly paradise of Shangri-La immortalized in James Hilton\'s vintage 1933 novel Lost Horizon, the Tsangpo River Gorge is a shelter respected for hundreds of years by way of Tibetan Buddhists–and later in Western imagination–as a sanctuary in instances of strife in addition to a gateway to nirvana.\nThe Siege of Shangri-La tells the tale of this fabled land\'s exploration as either a geographical and non secular destination–and chronicles the invention on the finish of the final millennium of the reality in the back of the myths and rumors approximately it. Veteran journalist Michael McRae strains the gorge\'s exploratory heritage from the clandestine missions of surveyor-spies known as pundits and botanical expeditions of naturalists within the early 20th century to the new investigations of students, adventurers, and pilgrims looking the ""Hidden Falls,"" of the Tsangpo, which purportedly opponents Niagara in dimension and serves because the gateway to paradise. every one explorer\'s narrative offers expanding facts of why the gorge has been mythologized in japanese and Western lore as one of many world\'s such a lot attractive blanks at the map–and a ultimate try of human will.\nTaking readers on a guided travel of the gorge\'s panorama, actual and metaphysical, McRae provides an insightful examine the pursuit of glory and enlightenment that has performed out during this mysterious land with occasionally disastrous outcomes. The Siege of Shangri-La is an engaging trip throughout the internal recesses of a distant, mystical global and the minds of these who\'ve tried to arrive it.\nThe acclaimed translation of the whole fiction of the daddy of recent chinese language literature\nLu Xun is likely one of the founding figures of contemporary Chiense literature. within the early 20th century, as China got here up opposed to the realities of the fashionable international, Lu Xun effected a shift in chinese language letters clear of the ornate, obsequious literature of the aristocrats to the obvious, expressive literature of the hundreds. His celebrated brief tales gather a powerfully unsettling portrait of the superstition, poverty, and complacency that he perceived in overdue imperial China and within the progressive republic that toppled the final dynasty in 1911. This quantity offers Lu Xun\'s whole fiction in bracing new translations and contains such recognized works as ""The actual tale of Ah-q,"" ""Diary of a Madman,"" and ""The Divorce."" jointly they reveal a contradictory legacy of cosmopolitan independence, polemical fractiousness, and concerned patriotism that keeps to resonate in chinese language highbrow existence today.\nFor greater than seventy years, Penguin has been the top writer of vintage literature within the English-speaking international. With greater than 1,700 titles, Penguin Classics represents a world bookshelf of the easiest works all through heritage and throughout genres and disciplines. Readers belief the sequence to supply authoritative texts more advantageous through introductions and notes through uncommon students and modern authors, in addition to updated translations by means of award-winning translators.\nNo nation on the earth has suffered a extra sour historical past nowa days than China. within the moment half the 19th century, it was once considered as doomed to extinction. Its imperial rulers, heading an anachronistic regime, have been introduced low through huge, immense revolts, transferring social strength styles, republican revolutionaries, Western incursions to ""split the chinese language melon"" and a disastrous defeat by way of Japan.\nThe presence of predatory foreigners has usually been blamed for China\'s problems, however the a lot larger reason got here from inside of China itself. within the early 20th century, the empire was once succeeded through warlordism on an important scale, inner divisions, incompetent rule, savage battling among the govt. and the Communists, and a fourteen-year invasion from Japan. 4 years of civil warfare after 1945 resulted in the Maoist period, with its purges and repression; the disastrous nice step forward; a famine that killed millions; and the Cultural Revolution.\nYet from this lengthy trauma, China has emerged amazingly within the final 3 a long time as an monetary powerhouse set to play an important international political function, its destiny posing one of many nice questions for the twenty-first century because it grapples with huge, immense inner demanding situations. knowing how that transformation took place and what China constitutes at the present time capability knowing its epic trip in view that 1850 and spotting how the prior affects the current.\nJonathan Fenby tells this turbulent tale with brilliance and perception, spanning a distinct old landscape, with a unprecedented forged of characters and a succession of big occasions. As Confucius stated, to determine the longer term, one needs to snatch the past.\nBy Alison Lurie\nWINNER OF THE PULITZER PRIZE\nVirginia Miner, a fifty-something, single tenured professor, is in London to paintings on her new ebook approximately children’s folks rhymes. regardless of sporting a U.S. passport, Vinnie feels primarily English and really appears to be like down on her fellow americans. yet even with that, she is drawn right into a mortifying and oddly enjoyable affair with an Oklahoman vacationer who clothes extra Bronco Billy than Beau Brummel.\nAlso in London is Vinnie’s colleague Fred Turner, a good-looking, flat broke, newly separated, and carefully depressing younger guy attempting to specialise in his personal examine. as an alternative, he\'s distracted by means of a gorgeous and unpredictable English actress and the realm she belongs to.\nBoth American, either overseas, and either achingly lonely, Vinnie and Fred play out their pressured alienation and dizzying romantic liaisons in Alison Lurie’s Pulitzer Prize-winning novel. well written, poignant, and witty, Foreign Affairs is still an everlasting comedian masterpiece.\n“A greatest comedy, very shiny, brilliantly written in a convinced and unique demeanour. the easiest booklet through one in all our most interesting writers.”\n“There isn\'t any American author i\'ve got learn with extra consistent excitement and sympathy. . . . Foreign Affairs earns an analogous shelf as Henry James and Edith Wharton.”\n“If you have the capacity to learn just a couple of reliable novels a yr, make this one among them.”\n“An creative, touching book.”\n“A perfect jewel.”\nBy Iris Chang\nThe Horse That Leaps Through Clouds: A Tale of Espionage, the Silk Road, and the Rise of Modern China\nBy Eric Enno Tamm\nOn July 6, 2006, author Eric Enno Tamm forums that very same educate, purpose on following in Mannerheim’s footsteps. at the start banned from China, Tamm devises a canopy and retraces Mannerheim’s path around the Silk highway, learning either eerie similarities and seismic variations among the center Kingdoms of a century in the past and today.\nAlong the best way, Tamm deals piercing insights into China’s earlier that elevate troubling questions about its destiny. Can the Communist get together really open China to the surface international but maintain Western rules equivalent to democracy and freedom at bay, simply as Qing officers mistakenly believed? What can reform in the course of the past due Qing Dynasty train us in regards to the awesome transformation of China at the present time? As Confucius as soon as wrote, “Study the prior when you might divine the future,” and that\'s accurately what Tamm does in The Horse That Leaps via Clouds.\nBy Bruce J. Dickson\nIn Wealth into strength, Bruce Dickson demanding situations the concept that monetary improvement is resulting in political switch in China, or that China\'s inner most marketers are supporting to advertise democratization. as a substitute, they\'ve got turn into companions with the ruling chinese language Communist celebration to advertise financial progress whereas conserving the political established order. Dickson\'s learn illuminates the Communist Party\'s technique for incorporating China\'s capitalists into the political procedure and the way the shared pursuits, own ties, and customary perspectives of the get together and the non-public quarter are making a kind of \'crony communism\'. instead of being power brokers of swap, China\'s marketers may perhaps turn out to be a key resource of help for the party\'s schedule. in response to years of study and unique survey information, this publication may be of curiosity to all these drawn to China\'s political destiny and within the courting among financial wealth and political energy.\nBy Tang Bao Lin\nChen Duxiu used to be the prime determine within the New tradition flow and the co-founder of the chinese language Communist celebration. The get together, in spite of the fact that, basically stated his contribution on the early level of the party’s improvement whereas negating his later accomplishments.\nHaving spent 30 years in learning and writing approximately Chen Duxiu, Tang Baolin, the writer of this encyclopaedic maserpiece showcased the lifestyles and occasions of Chen Duxiu – his particular character, his complex courting with the occasion and China’s revolution. It provides readers a well-rounded Chen Duxiu.']"	['<urn:uuid:eea94643-cc68-4e91-9aec-0534e29b6d86>']	factoid	direct	concise-and-natural	similar-to-document	single-doc	expert	2025-05-01T23:55:16.606337	11	27	1652
476	I'm managing a team and want to know - what are the benefits of having employees who fit well with the company culture, and what are some effective ways to keep them from leaving?	When employees fit well with company culture, they communicate more effectively with co-workers, can better predict each other's behavior, like each other more, and feel more trust in the team. These benefits lead to better performance and lower turnover rates. Research across 172 employee datasets confirms that culturally aligned employees perform better and are less likely to leave their roles. As for retention strategies, several approaches are effective: providing meaningful training opportunities, implementing incentive programs, organizing team activities like company picnics and employee appreciation events, and creating a positive work environment. Managers play a crucial role by developing a motivating team culture, focusing on employees' future careers, providing coaching, and creating a motivational environment. It's important to note that while pay and benefits matter, employees often rank praise for good work, appreciation, and working in a close-knit team as more important motivational factors.	['By better understanding cultural alignment between employee and employer, you can ensure a win-win relationship for both.\nby Daniel Stein\nJuly 12, 2022\nDid you know employees who have high cultural alignment with their organization are more productive and less likely to leave? If you “click” with a coworker or unintentionally act “in sync” with your team, you and your employer might be benefiting from cultural alignment. Employers that measure it and incorporate those measurements into their hiring process experience a better Quality of Hire (QoH, a metric used to measure the impact a person is having on an organization).\nHow can forward-thinking organizations measure this seemingly intangible feeling? Thankfully, cultural alignment has been the topic of substantial empirical research. In fact, the world knows a lot about cultural alignment – such as how to define, measure and improve it – thanks to more than 40 years of study in organizational psychology. This impressive body of research has methodologically examined everything HR and people leaders need to know about cultural alignment. So, what do these experts tell us about cultural alignment, why does it matter and how can you measure it?\nWhat is cultural alignment and how does it occur?\nCultural alignment is the degree to which an individual’s values match the values of the organization. For instance, imagine an organization has a culture defined by collaboration, taking risks and giving direct feedback. An employee that also values collaboration, taking risks and giving direct feedback has high cultural alignment while an employee that values self-reliance, predictability and aversion to direct feedback has low cultural alignment.\nCultural alignment can be achieved through recruiting and selecting new employees that organically align with the values of the organization or by socializing new employees to adopt the organization’s values. Research suggests it’s a lot easier to recruit and select for cultural alignment rather than socializing employees to match the values. That’s why including cultural alignment measurements in the hiring process can produce significant benefits.\nBenefits and measurement\nWhen employees are culturally aligned, they experience immediate psychological benefits that influence day-to-day interactions with co-workers. According to research by the University of North Carolina at Chapel Hill, cultural alignment leads co-workers to communicate more effectively, predict each other’s behavior, like each other more and feel more trust in a team. For example, when co-workers share the same values, there’s a reduced chance of misunderstanding. When they have similar motives and goals, it promotes confidence in how others will act, which can build trust and streamline work processes.\nAll these day-to-day psychological benefits of value alignment – such as communication, predictability, liking and trust – lead to better outcomes. Research of more than 172 employee datasets found when employees’ values are aligned with their organizations’, they perform better and are less likely to leave their roles. Thus, when organizations hire for value alignment, they hire more effective performers, resulting in a higher QoH score.\nThe next obvious question is, how can you measure cultural alignment and factor it into hiring decisions? Jennifer Chatman, associate dean for academic affairs at UC Berkeley, founded the field of cultural alignment in organizational psychology research. Her 1989 dissertation established that most organizational culture values can be deduced (or simplified) into six fundamental dimensions:\n- Innovation – Is the applicant willing to experiment, move fast, and take risks (innovative), or do they tend to prefer predictable working conditions, following rules and being careful (structured)?\n- Feedback – Does the applicant confront conflict directly or do they prefer to avoid conflict?\n- Collaboration – Does the applicant work in collaboration with others and exhibit a team orientation, or does the applicant prefer to work alone and exhibit a competitive orientation (i.e., self-reliant)?\n- Results oriented – Does the applicant favor working for an organization with high expectations of performance and achievement, or do they favor working for an organization that offers security of employment and aims to maximize employee well-being?\n- Customer focused – Does the applicant prefer work that benefits customers or work that is enjoyable or intrinsically rewarding for the self?\n- Attention to detail – Does the applicant pay attention to details or is the applicant a “big picture” thinker?\nWhen looking to measure an individual’s cultural alignment, these six dimensions form a great foundation. To measure them, organizations should ask the individual and their prior managers and colleagues (research has also shown that input from these people is valuable in measuring a candidate’s behavioral traits and soft skills accurately) to answer a series of questions that rate the individual on each dimension (perhaps with a slider question). Then they can compare the applicant’s culture profile with the organizations to determine alignment.\nNote that an individual does not need to be 100 percent aligned with the organization’s culture to be a good hire. The new candidate might have some behavioral traits that complement the existing team. For example, hiring a person with closer attention to detail than average might help a team struggling with missing deadlines perform better. The hiring team can also provide data on a new hire’s cultural alignment with their manager to help with onboarding them. Ways in which the new hire is not aligned with the organization can be managed if everyone is aware of them and able to account for them.\nIn 2021, more than 68 million people left their jobs. Organizations that are looking to reduce mis-hires and place high-performing talent care about cultural alignment and use it when measuring QoH.', 'Literature Review: Employee Retention\nEmployee retention is also referred to as employee turnover. This topic is of great importance because it is an issue that affects virtually all organizations in different fields. The turnover cost greatly adds to organizational expenses. Loss of company knowledge is another point worth noting. Employees who leave an organization leave with knowledge concerning the organization, its customers, past history and even the organization’s current projects. Therefore employee retention is of great importance. Employers are always determined to find out some of the reasons why employees leave or quit their jobs. The major reason is so that they can employ or find effective strategies to increase employee retention. Losing talented employees negatively affects an organization in terms of costs and performance. Information presented in this paper was sourced from e-books and academic journals. The search was mainly restricted to employee retention, causes of employee turnover and the strategies that can be employed to increase employee retention rate. Therefore, a literature review on employee retention will be presented below.\nOverview of Employee Retention\nEmployee retention can be defined as the ability of an organization to retain its employees, especially the most talented ones. Employee retention has become a significant concern issue. Some shocking statistics confronting every employer are presented in workforce demographics. More than 13% of employees in the\nPorter (2011) notes that employee turnover can cost an organization significant amount of money in terms of recruiting, interviewing, downtimes, training, orientation and ramp-up time. An entry –level position can cost a company from fifty to one hundred percent of the employee’s salary. While cost is certainly not a vital factor to take into consideration while evaluating employee turnover, there are other business factors that are crucial. Turnover can negatively affect quality and customer service (Curtis & Wright, 2001). When customer service and quality fails, competitive advantage can be compromised. Consequently, possibilities of contracts in janitorial industry and customer relationships are affected.\nAccording to Armstrong (2006), turnover is essential for organizational growth. While in some cases, turnover may be positive, it may be negative in other cases. For instance, a positive impact may be caused when a non-productive employee quits. In this case, the risk of terminating does not exist. The change could also aggravate opportunities for other employees and open up a position for existing employees.\nCauses of Employee Turnover\nPrior to putting in place measures to improve employee-retention record, it is essential for organizations to know why people are leaving. There are several reasons that might prompt employees to quit their jobs. However, there is a tendency for some reasons to be more significant compared to others and in specific organizations. Additionally, there are different forms of departures, occurring in different patterns depending on the prevailing organizational culture, circumstances, competitive position and management orientation. Employees who are given fewer reasons for feel insecure, uncommitted or dissatisfied have a less likelihood of quitting their jobs. The extent of attractive alternative job opportunities is another major variable that need to be taken into consideration. A greater number of alternatives mean that employees are more likely to quit their jobs and take up the alternatives (Hutton, 2009).\nAccording to Wiley (2011), it is essential for managers who wish to increase the rates of employee retention to take adequate time in understanding the actual turnover drivers in different parts of their organizations. This will ensure that effective and targeted interventions are developed. These interventions are also likely to succeed. Hutton (2009) identified different tools that can be used to identify the real causes of employee turnover. Majority or organizations either do not keep a record of why people leave or do so in an unsophisticated manner and hence fail to provide a significant platform for building strong employee retention practices. A typical approach that employers can use is talking formally and briefly to their departing employees to find out why they are leaving and if possible, identify their new employer. This strategy is often referred to as the use of exit interviews.\nThe first category is the pull-type factor which arises when positive attraction of alternative employment is the major cause of employee turnover. Although employees might be filly content and happy with their existing job, they may choose to move on in an effort to look for better opportunities. Where the major causes of employee turnover are pull factors, an organization that employs job satisfaction enhancement as a means of reducing the rate of departures would gain little. The best strategy to adopt would entail fining out what employees really value and what they look for in their careers. In this way, it will be possible for the organization to fully meet the needs of employees and increase the retention rates (Jones & George, 2003).\nPush factors represent the second category. In this case, the perception that something is wrong with the existing employer is the major underlying cause of resignations. Examples of push factors that can be identified include disapproval of changed structured, dislike of prevailing organizational structure and personality clashes with colleagues. It is therefore clear that resistance to organizational change can be classified as a push factor for employee turnover (Porter, 2011). Organizational response to push factors is addressing the root causes or reasons underlying dissatisfaction. This may entail careful selection of supervisors, better training and effective appraisal with respect to their supervisory skills. Employees should be given a voice. This means that they should be given a chance to air out their grievances, which should be addressed effectively (Jones, 2003).\nUnavoidable turnover is the third category. This category entails reasons that are beyond organizational control. In this case employees do not resign because of dissatisfaction or alternative options. Instead, they reasons because of reasons that are not directly connected to work. Retirement is the most common reason, which affects virtually every employee at some point. Another reason is illness, where an employee or a close relative who needs caring is incapacitated. Maternity is another reason, where women prefer not to return to the same job after taking a leave. Relocation is another reason worth noting. In this case, an employee quits job so as to follow a partner or spouse. The desire to take a career break is yet another reason. In this case, an employee may choose to quit job in order to pursue some other interest, re-enter full-time education or travel (Savage, 2010).\nOften, organizations come to a conclusion that there is nothing that can be done to minimize this category of turnover. This is partly true since in most situations the employee quitting a job for unavoidable reason may choose to go on working in the same job if they want. People choose to take a career break, choose not to return after taking a maternity leave and choose to retire. This may imply that such employees may choose to stay if the job was more attractive and valued. On a similar note, when tow people decide to set up a home together in a specific location, a choice should be made on the partner who is going to relocate. Practically, the decision is mostly based on work-related factors. The partner who quits the job and relocates is usually the one who is least satisfied with their job (Porter, 2011).\nThe final category is involuntary turnover. These are departures that are initiated by the organization and involuntary. In this case, the employee is required or asked to leave the organization. Examples of causes that fall under this category include ending of fixed-term contracts, short-term layoffs, redundancies and other forms of dismissals. Despite the fact that such turnover can at times be grouped as functional and not dysfunctional, there are costs involved, and should therefore be avoided if possible. Preventing situations which cause it to happen from arising in the first place should be the main aim. Measures can be taken to minimize the incidence of involuntary turnover, except in the case of some dismissals on the grounds of illness. These measures mainly emphasize on selection and recruitment practices, with the major aim being to make sure that there is a large pool of potential candidates as well as avoidance of poor decisions when recruiting candidates (Curtis, 2001).\nJob embeddedness and employee turnover\nJob embeddedness is a term that is used to describe the links of employees, their fit as well as the sacrifice they would make to leave their jobs. The links of employees to their colleagues or co-workers involve external activities, or shared values and experiences. Employees may share a passion for travel, outdoors, or sports teams. Hence, the links may be financial, psychological and social. Employees’ fit refer to their perceived comfort or compatibility with an organization. A better fit means that the employee has a higher likelihood of feeling personally and professionally connected to an organization. The community dimension, which entails cultural opportunities and outdoor activities, should also fit in order to promote job embeddedness (Wiley, 2011).\nSacrifice refers to the psychological or material benefit that an employee may forfeit by quitting a job. Although compensation is included in the benefits, job embeddedness also tries to take into consideration the intangible benefits. Such benefits may include expected advancement, job stability, opportunities for interesting subjects, status among peers, sabbaticals and many other advantages. In situations where an employee has to relocate, community sacrifices are also included (Jones, 2003).\nMitchell, Holtom, Lee, Sablynski, and Erez (2001) showed a negative relationship between job embeddedness and the intent to leave. After other factors such as job satisfaction and commitment were controlled, the relationships remained significant, but small in effect. Lee, Mitchell, Sablynski,\nThe likelihood of employees responding adaptively to adverse events at work might be increased by job embeddedness. According to\nGenerally, limited job embeddedness resulted to an inverse relationship between musing about leaving after adverse events and organizational citizenship behavior and job performance. Contrary elevated job embeddedness meant a positive relationship between musings about leaving after adverse events and organizational citizenship behavior and job performance. (Lee, at al, 2004) agreed with the finding by noting that employees feeling embedded in a job might initially pose questions as to why they should maintain loyalty. They usually decide to stay because they feel embedded. Such employees may try as much as possible to avoid occurrence of adverse events. Enhancement of performance is one way that they can use to avoid the adverse events. They employees might also choose to increase their organizational commitment, which may eventually lead to escalation of positive features of the organization.\nStrategies for reducing employee turnover\nEmployee retention is greatly enhanced by effective training. This is especially the case when employees learn what they require in order to succeed in their jobs. Data certification is an example of a training program that can be employed in order to increase employee retention. In addition to training Savage (2010) emphasizes on the essence of effective motivational factors as companies attempt to overcome harsh economic times. Many companies experience employee lay offs and freezing of salaries during slow economic times. Pay and benefits are not the most essential motivational factors for employees, although employees may not be pleased about not receiving a pay rise on an annual basis. More important factors as ranked by employees include praise for a job well done, appreciation and desire to work in a close-knit team (Savage, 2010). A strategy that can be used to reduce employee turnover during difficult times include implementation of incentives that serve in keeping employees interested in the organization instead of feeling stagnated in their positions.\nGawali (2009) gives some of the ideas that can help in keeping employee turnover low and increasing motivation. Among the major ideas is considering the future. For example, employers can ask their employees the training and skills that they might have interest in so as to meet the short-term goals and eventually help in meeting the long-term goals. Another essential idea is promoting a positive work environment. Employees tend to emulate positive behavior. Hence, managers who are good leaders and portray positive behavior are likely to have low turnover rate and increased employee motivation. Team activities can also go a long way in lowering turnover and increasing employee motivation. Managers are encouraged to schedule company picnics and employee appreciation events as examples.\nArmstrong (2006) adds that team leaders and managers play a fundamental role in employee retention. Team leaders and managers can reduce employee turnover rate by developing a motivating team culture as well as improving relationships among and with members of the team. Some of the strategies that they can employ include focusing on future careers of their employees, providing coaching, and standing up for the entire team, delegation and creation of a motivational environment. This clearly shows that managers and organizational leaders have a vital role to play in ensuring that top talent is retained in the organization.\nIt is therefore evident that employee turnover is a major concern issues. Some of the causes of employee turnover include pull factors such as better alternatives, push factors such as job dissatisfaction, unavoidable factors such as retirements and factors that are beyond organizational control. It is essential for employers to identify the root causes of employee departure so that they can effectively address them. The common strategies used to reduced turnover include increasing employee motivation by providing them with incentives and organizing team activities. Increasing employee retention can go a long way in increasing organizational performance, productivity and profitability.\nArmstrong, M. (2006) A handbook of human resource management (10th Ed),\nCurtis, S., & Wright, D. (2001) Retaining employees- the fast track to commitment. Management Research News, 24(8/9), 56-60\nGawali, V. (2009) Effectiveness of employee cross-training as a motivational technique. ASBM Journal of Management, 2(2), 138-146\nHutton, P. (2009) How to generate more valuable employee feedback, Strategic Communication Management, 13(92), 32-35\nJones, G. & George, J. (2003) Contemporary Management (3rd Ed),\nLee, T., Mitchell, T. Sablynski, C.,\nMitchell, T., Holtom, B., Lee, T., Sablynski, C., & Erez, M. (2001) Why people stay: Using Job embeddedness to predict voluntary turnover.\nPorter, J. (2011) Attract and Retain Top Talent. Strategic Finance, 92(12), 56-60\nSavage, R. (2010) No raises this year? Secrets to employee retention in difficult times. Supervision, 71(7), 25-26\nWiley, S. (2011) Building morale: the key to firm growth, CPA Management Forum, 7(2), 12, 19']	['<urn:uuid:74c4a3d5-012f-40a3-b38b-a1d8d722b2d9>', '<urn:uuid:224b988e-d8ff-42b8-b5a5-1d97d59be248>']	open-ended	with-premise	verbose-and-natural	distant-from-document	multi-aspect	novice	2025-05-01T23:55:16.606337	34	143	3313
478	error ellipse vs pca axis meaning difference	In error ellipses, the axes represent confidence intervals for normally distributed data, with the major and minor axes determined by eigenvalues and scaled according to desired confidence levels (e.g., 95% confidence corresponds to s=5.991). In contrast, PCA axes (principal components) represent directions of maximum variance in the data, with the first principal component accounting for the largest possible variance, and subsequent components accounting for decreasing amounts of remaining variance while maintaining orthogonality to previous components.	"['How to draw a covariance error ellipse?\nIn this post, I will show how to draw an error ellipse, a.k.a. confidence ellipse, for 2D normally distributed data. The error ellipse represents an iso-contour of the Gaussian distribution, and allows you to visualize a 2D confidence interval. The following figure shows a 95% confidence ellipse for a set of 2D normally distributed data samples. This confidence ellipse defines the region that contains 95% of all samples that can be drawn from the underlying Gaussian distribution.\nIn the next sections we will discuss how to obtain confidence ellipses for different confidence values (e.g. 99% confidence interval), and we will show how to plot these ellipses using Matlab or C++ code.\nAxis-aligned confidence ellipses\nBefore deriving a general methodology to obtain an error ellipse, let’s have a look at the special case where the major axis of the ellipse is aligned with the X-axis, as shown by the following figure:\nThe above figure illustrates that the angle of the ellipse is determined by the covariance of the data. In this case, the covariance is zero, such that the data is uncorrelated, resulting in an axis-aligned error ellipse.\nFurthermore, it is clear that the magnitudes of the ellipse axes depend on the variance of the data. In our case, the largest variance is in the direction of the X-axis, whereas the smallest variance lies in the direction of the Y-axis.\nIn general, the equation of an axis-aligned ellipse with a major axis of length and a minor axis of length , centered at the origin, is defined by the following equation:\nwhere defines the scale of the ellipse and could be any arbitrary number (e.g. s=1). The question is now how to choose , such that the scale of the resulting ellipse represents a chosen confidence level (e.g. a 95% confidence level corresponds to s=5.991).\nOur 2D data is sampled from a multivariate Gaussian with zero covariance. This means that both the x-values and the y-values are normally distributed too. Therefore, the left hand side of equation (2) actually represents the sum of squares of independent normally distributed data samples. The sum of squared Gaussian data points is known to be distributed according to a so called Chi-Square distribution. A Chi-Square distribution is defined in terms of ‘degrees of freedom’, which represent the number of unknowns. In our case there are two unknowns, and therefore two degrees of freedom.\nTherefore, we can easily obtain the probability that the above sum, and thus equals a specific value by calculating the Chi-Square likelihood. In fact, since we are interested in a confidence interval, we are looking for the probability that is less then or equal to a specific value which can easily be obtained using the cumulative Chi-Square distribution. As statisticians are lazy people, we usually don’t try to calculate this probability, but simply look it up in a probability table: https://people.richland.edu/james/lecture/m170/tbl-chi.html.\nFor example, using this probability table we can easily find that, in the 2-degrees of freedom case:\nTherefore, a 95% confidence interval corresponds to s=5.991. In other words, 95% of the data will fall inside the ellipse defined as:\nSimilarly, a 99% confidence interval corresponds to s=9.210 and a 90% confidence interval corresponds to s=4.605.\nThe error ellipse show by figure 2 can therefore be drawn as an ellipse with a major axis length equal to and the minor axis length to .\nArbitrary confidence ellipses\nIn cases where the data is not uncorrelated, such that a covariance exists, the resulting error ellipse will not be axis aligned. In this case, the reasoning of the above paragraph only holds if we temporarily define a new coordinate system such that the ellipse becomes axis-aligned, and then rotate the resulting ellipse afterwards.\nIn other words, whereas we calculated the variances and parallel to the x-axis and y-axis earlier, we now need to calculate these variances parallel to what will become the major and minor axis of the confidence ellipse. The directions in which these variances need to be calculated are illustrated by a pink and a green arrow in figure 1.\nThese directions are actually the directions in which the data varies the most, and are defined by the covariance matrix. The covariance matrix can be considered as a matrix that linearly transformed some original data to obtain the currently observed data. In a previous article about eigenvectors and eigenvalues we showed that the direction vectors along such a linear transformation are the eigenvectors of the transformation matrix. Indeed, the vectors shown by pink and green arrows in figure 1, are the eigenvectors of the covariance matrix of the data, whereas the length of the vectors corresponds to the eigenvalues.\nThe eigenvalues therefore represent the spread of the data in the direction of the eigenvectors. In other words, the eigenvalues represent the variance of the data in the direction of the eigenvectors. In the case of axis aligned error ellipses, i.e. when the covariance equals zero, the eigenvalues equal the variances of the covariance matrix and the eigenvectors are equal to the definition of the x-axis and y-axis. In the case of arbitrary correlated data, the eigenvectors represent the direction of the largest spread of the data, whereas the eigenvalues define how large this spread really is.\nThus, the 95% confidence ellipse can be defined similarly to the axis-aligned case, with the major axis of length and the minor axis of length , where and represent the eigenvalues of the covariance matrix.\nTo obtain the orientation of the ellipse, we simply calculate the angle of the largest eigenvector towards the x-axis:\nwhere is the eigenvector of the covariance matrix that corresponds to the largest eigenvalue.\nBased on the minor and major axis lengths and the angle between the major axis and the x-axis, it becomes trivial to plot the confidence ellipse. Figure 3 shows error ellipses for several confidence values:\nIn this article we showed how to obtain the error ellipse for 2D normally distributed data, according to a chosen confidence value. This is often useful when visualizing or analyzing data and will be of interest in a future article about PCA.\nFurthermore, source code samples were provided for Matlab and C++.\nIf you’re new to this blog, don’t forget to subscribe, or follow me on twitter!', 'PCA with Python | Principal Component Analysis Machine Learning | KGP Talkie\nPrincipal Component Analysis(PCA)\nAccording to Wikipedia, PCA is a statistical procedure that uses an\northogonal transformation to convert a set of observations of possibly\ncorrelated variables (entities each of which takes on various numerical values) into a set of values of linearly uncorrelated variables called\nThese are the new axes that descibe the\nvariation in the data.\n- Principal component 1: The axis which spans the\nmost variationof the data.\n- Principal component 2: The axis which spans the\nsecond most variationof the data.\n- Principal component 3: The axis which spans the\nthird most variationof the data and so on.\nWhen to use PCA\nWe can use PCA in the following cases:\n- Data Visualization.\n- It is used to find\ninter-relationbetween variables in the data.\nSpeedingMachine Learning (ML) Algorithm.\n- It’s often used to visualize\n- As number of variables are\ndecreasingit makes further analysis simpler.\nObjectives of PCA\nThe main objectives of the PCA are:\n- It is basically a\nnon-dependentprocedure in which it reduces attribute space from a large number of variables to a smaller number of factors.\nPCAis basically a\ndimension reductionprocess but there is no guarantee that the\n- Main task in this\nPCAis to select a subset of variables from a larger set, based on which original variables have the highest\ncorrelationwith the principal amount.\nHow to do PCA\nAs there are as many\nprincipal components as there are variables in the data, principal components are constructed in such a manner that the first principal component accounts for the largest possible\nvariance in the data set .\nThe second principal component is calculated in the same way, with the condition that it is\nuncorrelated with (i.e., perpendicular to) the first principal component and that it accounts for the next\nOnce fit, the\neigenvalues and principal components can be accessed on the PCA class via the\nPrincipal Axis Method\nPCA will search a\nlinear combination of variables so that we can extract\nmaximum variance from the variables. Once this process completes it will remove it and search for another\nlinear combination which will give an explanation about the maximum proportion of remaining\nvariance which basically leads to\northogonal factors. In this method, we analyze total\nFrom the following figure, I will make you understand how\nPCA works in a nutshell.\nThere are few steps, Let’s see one after other:\nIn the first step we have a\ncorrelated high dimenasion data. And then we calculate the\ncenter of the points and calculate\nvariance of the data by using\ncovariance matrix of the data and with this matrix we calculate\neigen vectors and\nAfter calculating these, we pick the value of\nm such that less than original dimension.\nThen after we will project\n` data points into thoseeigen vectors\nand we do the inverse transform so we will getuncorrelated low dimensional` data.\nThough mathematically it looks little bit complex but fortunately in python we have\nsklearn library there we have\nPCA package just we call\nPCA() and then call\npca.fit() as usual we do in ML algorithms.\nImporting required libraries\nimport pandas as pd import numpy as np import seaborn as sns import matplotlib.pyplot as plt\nLoading the training data set\nfrom sklearn import datasets, metrics from sklearn.model_selection import train_test_split\ncancer = datasets.load_breast_cancer()\nLet’s go ahead and get the description the\nbreast cancer data set.\n.. _breast_cancer_dataset: Breast cancer wisconsin (diagnostic) dataset -------------------------------------------- **Data Set Characteristics:** :Number of Instances: 569 :Number of Attributes: 30 numeric, predictive attributes and the class :Attribute Information: - radius (mean of distances from center to points on the perimeter) - texture (standard deviation of gray-scale values) - perimeter - area - smoothness (local variation in radius lengths) - compactness (perimeter^2 / area - 1.0) - concavity (severity of concave portions of the contour) - concave points (number of concave portions of the contour) - symmetry - fractal dimension (""coastline approximation"" - 1) The mean, standard error, and ""worst"" or largest (mean of the three worst/largest values) of these features were computed for each image, resulting in 30 features. For instance, field 0 is Mean Radius, field 10 is Radius SE, field 20 is Worst Radius. - class: - WDBC-Malignant - WDBC-Benign :Summary Statistics: ===================================== ====== ====== Min Max ===================================== ====== ====== radius (mean): 6.981 28.11 texture (mean): 9.71 39.28 perimeter (mean): 43.79 188.5 area (mean): 143.5 2501.0 smoothness (mean): 0.053 0.163 compactness (mean): 0.019 0.345 concavity (mean): 0.0 0.427 concave points (mean): 0.0 0.201 symmetry (mean): 0.106 0.304 fractal dimension (mean): 0.05 0.097 radius (standard error): 0.112 2.873 texture (standard error): 0.36 4.885 perimeter (standard error): 0.757 21.98 area (standard error): 6.802 542.2 smoothness (standard error): 0.002 0.031 compactness (standard error): 0.002 0.135 concavity (standard error): 0.0 0.396 concave points (standard error): 0.0 0.053 symmetry (standard error): 0.008 0.079 fractal dimension (standard error): 0.001 0.03 radius (worst): 7.93 36.04 texture (worst): 12.02 49.54 perimeter (worst): 50.41 251.2 area (worst): 185.2 4254.0 smoothness (worst): 0.071 0.223 compactness (worst): 0.027 1.058 concavity (worst): 0.0 1.252 concave points (worst): 0.0 0.291 symmetry (worst): 0.156 0.664 fractal dimension (worst): 0.055 0.208 ===================================== ====== ====== :Missing Attribute Values: None :Class Distribution: 212 - Malignant, 357 - Benign :Creator: Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian :Donor: Nick Street :Date: November, 1995 This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets. https://goo.gl/U2Uwz2 Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image. Separating plane described above was obtained using Multisurface Method-Tree (MSM-T) [K. P. Bennett, ""Decision Tree Construction Via Linear Programming."" Proceedings of the 4th Midwest Artificial Intelligence and Cognitive Science Society, pp. 97-101, 1992], a classification method which uses linear programming to construct a decision tree. Relevant features were selected using an exhaustive search in the space of 1-4 features and 1-3 separating planes. The actual linear program used to obtain the separating plane in the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: ""Robust Linear Programming Discrimination of Two Linearly Inseparable Sets"", Optimization Methods and Software 1, 1992, 23-34]. This database is also available through the UW CS ftp server: ftp ftp.cs.wisc.edu cd math-prog/cpo-dataset/machine-learn/WDBC/\nThis data has\n30-dimensions that is\n30 features. Let’s visualize the data set with\ndf = pd.DataFrame(cancer.data, columns=cancer.feature_names) df.head()\n|mean radius||mean texture||mean perimeter||mean area||mean smoothness||mean compactness||mean concavity||mean concave points||mean symmetry||mean fractal dimension||…||worst radius||worst texture||worst perimeter||worst area||worst smoothness||worst compactness||worst concavity||worst concave points||worst symmetry||worst fractal dimension|\n5 rows × 30 columns\nIf we see here scale of the each feature is different that is dome features are in the range\n10s some are in\n100s. It is better to\nstandardize our data for better visualization.\nLet’s see the below code:\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler() X_scaled = scaler.fit_transform(df) X_scaled[: 2\narray([[ 1.09706398e+00, -2.07333501e+00, 1.26993369e+00, 9.84374905e-01, 1.56846633e+00, 3.28351467e+00, 2.65287398e+00, 2.53247522e+00, 2.21751501e+00, 2.25574689e+00, 2.48973393e+00, -5.65265059e-01, 2.83303087e+00, 2.48757756e+00, -2.14001647e-01, 1.31686157e+00, 7.24026158e-01, 6.60819941e-01, 1.14875667e+00, 9.07083081e-01, 1.88668963e+00, -1.35929347e+00, 2.30360062e+00, 2.00123749e+00, 1.30768627e+00, 2.61666502e+00, 2.10952635e+00, 2.29607613e+00, 2.75062224e+00, 1.93701461e+00], [ 1.82982061e+00, -3.53632408e-01, 1.68595471e+00, 1.90870825e+00, -8.26962447e-01, -4.87071673e-01, -2.38458552e-02, 5.48144156e-01, 1.39236330e-03, -8.68652457e-01, 4.99254601e-01, -8.76243603e-01, 2.63326966e-01, 7.42401948e-01, -6.05350847e-01, -6.92926270e-01, -4.40780058e-01, 2.60162067e-01, -8.05450380e-01, -9.94437403e-02, 1.80592744e+00, -3.69203222e-01, 1.53512599e+00, 1.89048899e+00, -3.75611957e-01, -4.30444219e-01, -1.46748968e-01, 1.08708430e+00, -2.43889668e-01, 2.81189987e-01]])\nPrincipal Component Analysis\nLinear dimensionality reduction using\nSingular Value Decomposition of the data to project it to a lower dimensional space. The input data is centered but not scaled for each feature before applying the\nPCA() function into training and testing set for analysis.\nLet’s discuss some important paameters of the function\nIt is a int, float, None or str.\nNumber of componentsto keep.\nIt is to pass an\nintfor reproducible results across multiple function calls.\nIt is provide the amount of\nvarianceexplained by each of the selected components.\nIt helps to fit the model with X and apply the\ndimensionality reductionon X.\nIt transforms data\nWe need to have\n2-dimensional data set so\nn_component is equal to\n2 and we can get same result\nrandom_state if we use same\nPCA function into training and testing set for analysis look at the following code:\nFit the model X_scaled by using\nfrom sklearn.decomposition import PCA\npca = PCA(n_components=2, random_state=42) pca.fit(X_scaled) PCA(n_components=2, random_state=42)\nTraining has been done now let’s go ahead to transform it with\nX_pca = pca.transform(X_scaled)\nSo we transformed the data into\nLet’s check the\nshape of both data sets:\n((569, 30), (569, 2))\nHere we can observe shape of default data is\n30 and after transformation it reduced to\nNow we will try to plot the\nscattering points for the second principal component and first principal component by using\nLet’s look into the following script:\nplt.figure(figsize=(12,8)) plt.scatter(X_pca[:, 0], X_pca[:, 1], c = cancer.target, cmap = \'viridis\') plt.xlabel(\'First Principal Component\') plt.ylabel(\'Second Principal Component\') plt.title(\'Scatter plot for Second principal component and First principal component\') plt.show()\nFrom the above plot we can observe, first principal component has\nhigh variance compared to second principal component.\nNow we will observe the respective\nvariances for the components by using bar graph.\nSee the following plot:\npca = PCA(n_components=20, random_state=42) X_pca = pca.fit_transform(X_scaled) variance = pca.explained_variance_ratio_ plt.ylabel(\'Variance\') plt.xlabel(\'Principal components\') plt.title(\'Bar graph for variances of the componets \') plt.bar(x = range(1, len(variance)+1), height=variance, width=0.7) plt.show()\narray([0.44272026, 0.18971182, 0.09393163, 0.06602135, 0.05495768,\n0.04024522, 0.02250734, 0.01588724, 0.01389649, 0.01168978,\n0.00979719, 0.00870538, 0.00804525, 0.00523366, 0.00313783,\n0.00266209, 0.00197997, 0.00175396, 0.00164925, 0.00103865])']"	['<urn:uuid:264e06c7-1262-4b96-a2b6-426d16f85d73>', '<urn:uuid:7a82674f-b040-4f42-8190-2739c9a9f79f>']	open-ended	with-premise	short-search-query	distant-from-document	comparison	novice	2025-05-01T23:55:16.606337	7	75	2611
479	working voice actor benefits creative freedom risks equipment damage	Voice acting offers creative freedom through improvisation and character versatility - actors can create multiple voices and add spontaneous elements during 'crazy passes'. However, there are equipment risks: microphones can be damaged by drops, especially with handheld transmitters, and lavalier microphone cables can fail from repeated flexing and sharp bends, affecting sound quality and performance.	"['The actors adjust immediately, producing a higher level of henlike shock. It\'s just one highlight of this particular voiceover session, in which the cast is recording various sections of Back at the Barnyard\'s latest script. Although animated-series ensembles don\'t always get to record together, Paulsen, for one, prefers it to knocking out his lines solo. ""I have both [kinds of sessions] that I do with great regularity,"" he says. ""As clever and funny as I\'d like to think I am on my own, good actors make me better.""\nBetween takes, the actors banter, sometimes in character, though saying things that probably wouldn\'t make the cut on a family-oriented television show. Paulsen chuckles as he recalls a few of the more off-color remarks. This, he says, is another reason recording as a cast is better than going it alone. ""You can tell how much fun we have,"" he says.\nOn Barnyard, Paulsen plays Peck, a skittish rooster. At this session, he\'s also portraying a rather unappealing-sounding human known simply as Snotty Boy, who is usually voiced by Barnyard creator–executive producer Steve Oedekerk. ""It\'s very common for actors to fill in for others who aren\'t at the recording session, to help the actors who are present keep the flow of the script intact,"" explains Paulsen. Oedekerk will record his lines later; in the meantime, Paulsen\'s reads also help the animators with the timing of the episode.\nStill, the two voices are night and day. Peck is fast, nervous, and slightly high-pitched. Snotty Boy goes into the deeper register and constantly sounds like he needs to blow his nose. ""If you\'re going to be a voiceover actor, [voicing multiple characters] is a skill you must possess,"" says voiceover director and casting director Dawn Hershey. ""You have to be versatile. The budget of the cartoon depends on your versatility. Nine times out of 10, unless it\'s a celebrity, we\'re not going to hire you for one voice; we\'re going to hire you for three.""\nPaulsen, an Emmy-winning voiceover veteran, switches back and forth with admirable ease. He broke into the business about 25 years ago when his agent, Rita Vennari of Sutton, Barth & Vennari, landed him a general audition with Hanna-Barbera, and he has been voicing characters on shows like Animaniacs, Teenage Mutant Ninja Turtles, and The Adventures of Jimmy Neutron: Boy Genius ever since. One thing that helps with the transitions, he notes, is that each character is fully fleshed out, in his head and on the page. ""When [I\'m] doing Snotty Boy, I have this view in my head of this really disgusting, horrible human—and of course, they\'ve animated him to look pretty disgusting,"" he says, chuckling. ""And then when I\'m talking like Peck, I\'ve just got this ingenuous kind of \'Uh, I don\'t think it\'s such a good idea\' thing. But definitely, what\'s going on in my brain is completely different. One doesn\'t overlap the other. It\'s a real clear delineation.""\nAs Paulsen moves from Peck to Snotty Boy and back again, his physicality changes as well. When he\'s Peck, he goes all wide-eyed with wonder and neuroses. Moving into Snotty Boy, he becomes more hunched over, emanating boorishness. Though some may labor under the misconception that voice acting is about simply pitching the vocal cords one way or another, watching a session like this would clear that up pretty quickly: The performers throw themselves into their roles, as any good actor does.\n""My best actors aren\'t acting from nose to chin; they\'re acting from head to toe,"" says voiceover actor-director-coach Rick Zieff. ""Even the physical placement of where the voice comes from—if you\'ve got one deep kind of gargoyle-y guy and your other guy\'s a nerdy guy and he\'s placed way up in the nasal passages, you not only have to change your emotional placement of \'What am I thinking, what am I feeling, what am I saying?\' but [also] \'Who am I, what do I look like, how big am I?\' ""\nA cold, dimly lit recording booth might not be the most inspiring place, but voiceover actor-director-teacher Susan Blu says you have to use your imagination to fill your environment. ""[Actors on stage] have their atmosphere, their props, all of that stuff around them,"" she says. ""But with voice acting, you are in a studio, and you\'ve got a microphone in front of you, and that\'s basically all you have. You\'ve got to use your body, and you\'ve got to bring the atmospheres. Are you in a castle? Are you in outer space? Are you on a farm? You\'ve got to build your stage in your own mind.""\nAfter a few takes of the first sequence in the script, Spingarn says what appear to be the magic words: ""Crazy pass."" This time, the actors put their own spin on the sequence: an improvised line here, a slightly different character read there. They bounce off one another with ease, their chemistry more than evident. During the crazy pass, notes Spingarn, anything goes: ""You can digress from the script or speak Portuguese or say anything you want, basically. We\'re kind of blessed with a group of actors who are very funny people in their own right. I make sure to get an as-written read always, and then the final take is always the crazy pass. It\'s usually 90 percent filth and inside jokes, but really almost every crazy pass yields something that I\'ll end up using—a line or two.""\nThe term crazy pass may be unique to Barnyard, but improv is often a key component of animated voiceover sessions. Says Zieff, ""Having improv skills keeps people very open and in the moment, very spontaneous, and those are qualities that are very valuable"" in voiceover.\nThat doesn\'t mean improv is always welcome. ""Some scripts are going to be really tight and cannot go off the page,"" says voiceover actor and coach Steve Harris. ""Now, when they do let you do a little improv, that\'s a fantastic opportunity to really stand up and show them that you have that ability, to shine and make yourself very attractive to a creative team.""\nIn the case of Barnyard, improv is encouraged. A few of the actors even take the opportunity to pitch jokes or adjustments that improve upon the script. Chris Hardwick, who plays a goofy cow named Otis, proposes a bit that ends up being one of the session\'s funniest: an impromptu song that goes over a minimontage of Otis and his male barnyard friends when they disguise themselves as human girls (""It\'s not weird/Okay, maybe just a little bit""). Unfortunately, the engineers inform Spingarn that Hardwick\'s ""p\'s popped"" during the take.\n""Essentially [it\'s] a wind issue, where you would hear the technical glitch of too much wind on the mike, and it would be a distraction watching the show,"" explains Spingarn. ""That\'s always an interesting quandary, because when you capture lightning in a bottle and then the engineer tells you that it teched, it\'s pretty rare that you\'re gonna get the same magic to happen again on cue."" Hardwick tries in vain to record the song again, but he can\'t recall the lyrics he improvised so brilliantly the first time around. Luckily, the engineers come up with a solution: They\'ll graft a p from another take onto the first hilarious recording.\n""Every now and then, something comes out [of improvising during a session], and the end result is you\'ve got a great bit in the show or even a better show all the way around,"" says Paulsen.\nAs Paulsen dives into a particularly heinous Snotty Boy passage, Spingarn offers a few adjustments: ""Make it a little more insulting."" ""More disgusting!"" ""Ruder."" Paulsen clenches his voice, screws his face into a snarl, and enunciates his lines more clearly, his cadences dripping with condescension. Once the take is in the can, he starts chuckling. ""Snotty, when he gets mad, sounds like Al Pacino,"" he says.\nThroughout the session, Spingarn offers the actors various redirects such as these, suggesting the occasional mood change or tone shift. For the most part, they respond immediately, giving him exactly what he wants. ""I find that voice actors, the good ones, are very, I say, \'dialable,\' "" he says. ""You can give them a very nuanced suggestion or try to change a small nuance in what they\'re doing, and they know exactly what you\'re talking about and are able to accommodate it.""\nPaulsen, who is especially good at subtle adjustments, says taking redirection successfully is mostly a matter of listening. ""I don\'t think there\'s any magic bullet,"" he says. ""I think it\'s just a question of listening to what Jed says, and actors are supposed to be trained to listen anyway. You\'re supposed to pay attention to what\'s being said.""\nThis is also an area in which voiceover training—which many pros consider essential if you want to make a career of it—may come in handy. ""There\'s no substitute for training,"" says Harris. ""That\'s one of the hardest aspects of voiceovers: going in, reading something, and then having a director redirect you and then saying, \'Oh yeah, sure,\' and trying it. Often what happens early on in careers is the person says, \'Not a problem,\' just out of fear, and then they do another take, and it\'s exactly the same. It might be slightly faster, it might be slightly slower, [but] it\'s usually the same attitude, same intention, same inflection, because they just don\'t get that change. The craft, the skill, is in being able to forget what you just did and hear in your head a completely different melodic, rhythmic intention that you can execute.""\nZieff notes two types of redirection a voice actor might receive: a simple line reading (""Say it this way"") or a description of the character\'s ""emotional truth."" He prefers the latter. ""First and foremost, I\'m an actor,"" he says. ""Whether I\'m playing a chicken or an armadillo or a robot or just a dad, I have a truth. If you tell me what that truth is, then I will organically be able to react and respond and live that moment. If you direct me in that way—\'Oh, this person is very excited about this\' or \'They\'re very nervous about what\'s about to happen\'—then the line is liable to come out more truthfully."" This is also the style Spingarn prefers to use as a director: ""If all else fails, I don\'t think it\'s a sin to [give a line reading] if there\'s mutual respect between the actor and director. But it\'s definitely the last resort for me.""\nAs the actors near the end of their scripts, a few smaller characters pop up: waiters and announcers and the like, bit parts with a handful of lines each. Spingarn casts these on the spot, choosing from his available actors. ""Half the calculation is who you think fits that role best, and the other half is more of a production consideration, because after an actor does two voices, they can start charging more for the third voice and then exponentially more for a fourth voice,"" he notes. ""So if someone is at three voices already in the show, I usually will avoid using them again. But that\'s why we hire actors who do multiple voices—like Rob, for example. So when you have a waiter voice and it\'s just a little walk-on part, you can say, \'Oh, Rob does Hervé Villechaize,\' and you can have him do the waiter as Hervé Villechaize, and suddenly a part that was a nonentity, practically, is, like, a highlight of the show.""\nIn one of the script\'s final sequences, Paulsen is cast as a snack vendor at a wrestling match. He instantly pulls out a pitch-perfect character—a kindly, old-fashioned seller of popcorn and slushies—and nails it. ""Little things like that, I have [ideas] that pop into my head,"" says Paulsen. ""I don\'t have a picture to look at, so I don\'t know exactly what the guy looks like. Sometimes I like to throw a curve in there. Every now and then, I try to throw in an impression of an actor that might be fun or something that\'s completely unexpected.""\nIn such instances, says Paulsen, it\'s important for actors to be fearless. You can\'t hesitate when given this sort of opportunity; you have to trust your instincts. ""The thing that\'s not good and that happens every now and then is, if someone is not confident in their ability, the director will say, \'Hey, we got a vendor here on Page 3; he\'s got three lines. Would you go ahead and do that?\' And you can see the actor go, \'What do you want me to do?\' "" he says. ""They\'re losing an opportunity to shine, to do something right there, right on the spur of the moment. Whatever pops into your head, try it. The worst thing [the director] is going to say is, \'What else you got?\' ""\nThat general sense of creativity and spontaneity is key during the Barnyard session. The actors remain in good spirits throughout, and their energy is infectious, making for an atmosphere that\'s highly collaborative. ""Animation is a really fun and gracious group of people,"" says Zieff. ""Sometimes people get rambunctious, and I think that sort of fun, comic energy actually suits the environment, because you\'ve got people, human beings, adults, acting like a weird assortment of things.""\nThe recording process, notes Spingarn, also moves a lot faster than it does in on-camera work. ""An 11-minute show might take two hours to get,"" he says. ""[The actors] definitely have to be accommodating to other actors, because you\'re in a very small room with five or six other people, potentially. And especially in the animation world, it\'s a machine. You go in and you get it done. There\'s no craft services. There\'s no makeup table. You go in and you do your craft.""\nAnd really, says Paulsen, that\'s the fun of it: the craft. Changing on a dime from voice to voice during a session, using his creativity as an actor—these are the things he cherishes about the profession. ""Being an average-looking guy with a SAG card, I\'m not limited by the fact that I\'m an average-looking white guy with a SAG card,"" he says. ""No one cares that I\'m tall, thin, short, fat, white, black, orange, green. They just care that I can deliver and come up with different characters.""', 'Using Microphones With Wireless\nAlthough modern microphones are rugged and reliable, they can fail if abused, mishandled or subjected to damaging conditions. In addition, heavy use and the accumulated effects of normal wear and tear will eventually result in performance loss or failures. With reasonable care and some simple precautions, the useful life of a microphone can be greatly extended.\nBecause of the way that they are used, handheld transmitters are subject to being dropped. Their shape also allows them to roll off of tables and desks, increasing the chances that they will eventually suffer a fall. Both the microphone element and the transmitter electronics can be damaged by a fall, but electronic failures tend to occur slightly more often than element failures. Although a short drop is not likely to cause failure, drops from greater heights will increase the chances of damage.\nEven if the microphone element does not fail, repeated drops can eventually affect sound quality. The shock caused by drops can also disturb the adjustments in the transmitter electronics, possibly resulting in reduced range or poor audio quality. After a handheld transmitter has suffered a hard drop, it is wise to listen carefully to the wireless system to make certain that the sound quality has not been affected. A range test is also worthwhile.\nBecause of their shape and the way they are typically used, wireless body-pack transmitters are less likely to be dropped. Their lower weight also tends to reduce the chances that a drop will result in a failure. Hard drops, however, can sometimes damage the microphone connector, especially if the drop occurs while the microphone is plugged in. The lavalier microphones themselves are very light and are almost never damaged by being dropped.\nThe miniature cables used with lavalier microphones can be damaged by pulling, stretching, sharp bends and repeated flexing. Most cable failures occur where the cable enters the connector or the microphone body. Generally, a cable break near the connector can be repaired by shortening the cable by 2 inches (5 cm) or so, at least until the cable becomes too short to be usable. Extra care in avoiding sharp bends and excessive flexing, especially near the microphone itself, will pay off in longer life and fewer problems. Eventually, however, a microphone cable simply wears out and can no longer be used.\nIn certain applications, such as aerobics instruction and the musical theater, it is unavoidable that the microphone cable is subjected to constant flexing. In these circumstances, selecting a microphone with a slightly larger and stronger cable should be considered. It is always a sensible idea to have a spare microphone on hand, especially for applications of this type. In addition, microphone life will inevitably be shorter than for less stressful uses, and the cost of replacement microphones should be factored into the budget.\nUnless appearance is of prime concern, the use of foam windscreens is advised for handheld wireless transmitters. Although the foam does not offer much protection from drops, it does greatly reduce wind noise and voice ""pops."" The foam also helps protect the microphone element from moisture and keeps the metal grille windscreen clean. Foam windscreens are less necessary for lavalier microphones unless wind noise is a problem or conditions are very wet.\nFoam windscreens should be washed frequently and air dried. When it is no longer possible to wash the foam clean, the windscreen should be discarded and a new one installed. Unless a foam windscreen is always used, the metal windscreens on handheld microphones should be inspected frequently and washed when necessary. Lipstick, makeup and dried saliva tend to clog up metal windscreens, as well as the internal foam windscreen, if one is used. Over time, the output and sound quality of vocal microphones can gradually degrade unless the windscreen is kept clean.\nSeverely dented metal windscreens should be replaced. The dents can allow the mouth to come too close to the microphone element, increasing pop noise and changing the sound of the microphone. The internal foam windscreen, when one is used, can also be pushed into the element, muffling the sound and affecting microphone performance.\nMicrophones and wireless transmitters and receivers should be protected from moisture. Although modern microphones are not particularly sensitive to the environment, moisture or excessively high humidity can cause corrosion and other problems, affecting both microphone elements and electronic circuits. Unless necessary to protect from high humidity, microphones and transmitters should not be stored in plastic bags or sealed enclosures after use, at least until completely dry. Always air-dry the equipment after use to allow water, perspiration and saliva to evaporate, rather than trapping it inside the equipment.\nCondenser microphones should be protected from excessive humidity and long term exposure to high temperatures. Either can permanently degrade sensitivity and sound quality over a period of time. Perspiration is particularly damaging because it is corrosive, leaves harmful chemical residues and attacks condenser microphone elements with moisture. When performers perspire freely, it is highly advisable to protect the microphones from direct exposure by using foam windscreens or protective plastic covers.\nBack to Contents']"	['<urn:uuid:0e30e818-dffe-447a-bdf6-e3e1606f1d36>', '<urn:uuid:d5533b94-9217-4b97-b469-d02373f0dc73>']	factoid	with-premise	long-search-query	distant-from-document	multi-aspect	novice	2025-05-01T23:55:16.606337	9	55	3254
480	raw spinach preparation steps before eating	To prepare raw spinach, wash leaves in cold water, gently pat them dry using tissue or soft cloth, and trim away tough stems. The leaves can then be chopped or used whole in various recipes.	['What is Spinach?\nSpinach (Spinacia oleracea) is one of wonderful green-leafy vegetable often recognized as one of the functional foods for its wholesome nutritional, antioxidants and anti-cancer composition.\nIts tender, crispy, dark-green leaves are one of the favorite ingredients of chefs all around the planet. Spinacia plant grows to about 1 foot in height. Although it can be grown year round, its fresh greens are best available soon after the winter season from March through May in the Northern hemisphere, and from September until November in the South of the equatorial line.\nHealth Benefits of Spinach\nHealthy skin and hair: Spinach is high in vitamin A, which is necessary for sebum production to keep hair moisturized. Vitamin A is also necessary for the growth of all bodily tissues, including skin and hair. Spinach and other leafy greens high in vitamin C are imperative for the building and maintenance of collagen, which provides structure to skin and hair.\nIron-deficiency is a common cause of hair loss, which can be prevented by an adequate intake of iron-rich foods, like spinach.\nAsthma prevention: The risks for developing asthma are lower in people who consume a high amount of certain nutrients. One of these nutrients is beta-carotene, of which spinach is an excellent source.\nImproves Complexion: Being rich in vitamin K and folate, spinach gives you a clear complexion by minimizing acne, bruising on the skin and dark circles. The bounty of vitamin and minerals in this vegetable give you quick relief from dry itchy skin, thus providing you with a radiant complexion.\nBone health: Low intakes of vitamin K have been associated with a higher risk for bone fracture. Adequate vitamin K consumption is important for good health, as it acts as a modifier of bone matrix proteins, improves calcium absorption and may reduce urinary excretion of calcium.\nPromotes regularity: Spinach is high in fiber and water content, both of which help to prevent constipation and promote a healthy digestive tract.\nUses of Spinach\nDue to its excellent taste and nutritional value, spinach is a popular leaf all over the world.\nWash leaves in cold water before use. Gently pat them dry using tissue or soft cloth. Trim away tough stems. Raw leaves can be either chopped, or used as they are in variety of recipes.\nFresh, tender spinach leaves (baby spinach) can be eaten raw either in salad and vegetable burgers or as juice. Antioxidant properties may decrease significantly on steaming, frying and boiling for longer periods.\nAlong with other vegetables, its leaves are used in the preparation of noodles, pie, pasta, pulov, and soups as well as in the preparation of baby-foods.\nNutritional value of Spinach\nThis green leafy vegetable also contains good amounts of many B-complex vitamins such as vitamin-B6 (pyridoxine), thiamin (vitamin B-1), riboflavin, folates and niacin. Folates help prevent neural tube defects in the offspring.\nSpinach is also an excellent source of vitamin K, vitamin A, vitamin C and folic acid as well as being a good source of manganese, magnesium, iron and vitamin B2. Vitamin K is important for maintaining bone health and it is difficult to find vegetables richer in vitamin K than spinach. Spinach also contains fiber, phosphorus and thiamine.']	['<urn:uuid:175b81dd-b201-4dc3-9088-37a43c684d3e>']	factoid	with-premise	short-search-query	similar-to-document	single-doc	expert	2025-05-01T23:55:16.606337	6	35	535
483	domestic abuse victim workplace rights nyc	It is unlawful for an employer to discriminate against you in the workplace based on your status as a victim of domestic violence. Depending on where you live, additional protections may exist, including protections for victims of sexual assault or stalking, that can help you keep or leave your job while addressing the abuse.	['Guidance for women and advocates in New York State.\nWomen continue to be undervalued and are regularly subjected to unfair treatment in the workplace. While women often accept these conditions as inevitable, it is important to remember that it doesn’t have to be this way. ALL women—regardless of economic situation or immigration status—have certain legal rights.\nThis Toolkit provides guidance to women and advocates in New York State on 13 core issues that relate to women’s economic equality, including ways to assert those rights. Download the full Toolkit here or see our Checklist below.\nNote that this Toolkit is for informational purposes and is not intended to provide legal advice.\nTable of Contents\nLegal Checklist for Women’s Economic Equality\nThis Checklist provides a synopsis of the 13 rights, protections, and benefits covered in this Legal Toolkit. Some of these rights overlap—but the Toolkit is divided into 13 core areas for ease of reference.\n1. Sex & Gender Discrimination\nYou have the right not to be discriminated against at work on the basis of your sex or gender. This right is fundamental and encompasses many of the specific protections below. The law also protects you based on your gender identity, sexual orientation, and familial status.\n2. Sexual Harassment\nYou have the right to a workplace free of sexual harassment and abuse. Sexual harassment is a form of sex discrimination. All workers should be free to come forward to report abuse regardless of identity or immigration status.\n3. Equal Pay\nThe law prohibits employers from paying you less because of your sex or gender. This type of treatment is a form of sex discrimination. Your employer is also prohibited from punishing you for discussing or disclosing rates of pay with your colleagues, and, depending on where you work, an employer may be prohibited from asking about or relying on your prior salary to set your new salary.\n4. Minimum Wage & Fair Wage Practices\nYou have the right to be paid for your work. It is illegal for your employer to steal your wages, pay you below the state minimum wage, or force you to work for no wages.\n5. Economic Opportunity\nIt is unlawful for a lender or financial institution to deny you a loan or financing based on your sex or gender. Resources are available to help you find a job; improve your finances; start a business; and obtain education, language, and skills trainings to get a job, including jobs in higher paying fields\n6. A Safe Workplace & Fair Working Conditions\nYou have the right to a safe workplace free from hazards that could cause you serious harm and free from coercive working conditions. Depending on your circumstances, you may also be entitled to certain fair work practices such as breaks, days of rest, sick time, leave, and fair scheduling.\n7. Domestic Violence, Sexual Assaults & Stalking\nIt is unlawful for an employer to discriminate against you in the workplace based on your status as a victim of domestic violence. Depending on where you live, additional protections may exist, including protections for victims of sexual assault or stalking, that can help you keep or leave your job while addressing the abuse.\n8. Reproductive & Maternal Health\nYou have the right to a safe and confidential abo tion until your 24th week of pregnancy or at any point medically necessary to protect your life or health. If you receive Medicaid or have health insurance, your provider must cover critical family planning services, including contraception and abortion services at no additional cost.\n9. Pregnancy, Childbirth & Breastfeeding\nIt is unlawful for an employer to treat you less favorably in the workplace on the basis of pregnancy, childbirth, or a related medical condition. This type of treatment is a form of sex discrimination. An employer is also prohibited from discriminating against workers for pumping breast milk at work and you have the right to take breaks to do so. Depending on your situation, you may have the right to additional workplace protections to adjust your working conditions or to take paid or unpaid leave if needed.\n10. Paid Family Leave\nIf you have worked enough days and hours, you have the right to paid, job-protected leave to care for a newborn, a newly adopted child, or a sick family member, or to address certain family needs that result from military deployment. You may also have the right to other forms of leave to assist you with caring for yourself and your family.\n11. Child Care Assistance & Protections for Caregivers\nIt is unlawful for an employer to discriminate against you because you have children. Based on your income, you may be eligible for child care assistance to help you get or keep a job.\n12. Public Benefits\nBased on your income, you may be eligible for critical public benefits, including cash assistance, food assistance, free healthcare, and housing assistance. If your benefits are denied or terminated, you must be informed in advance and have an opportunity to contest the determination. if you do not speak English and need assistance, you can request language assistance (translation and interpretation).\n13. Protecting Our Rights Together\nYou may have certain rights and opportunities to organize, join a union, and take action with other workers to improve your pay and working conditions without being punished by your employer.\nA list of additional resources to help you: find out if you have certain rights, determine if your rights have been violated, figure out how to assert your rights, or decide if you need legal representation.']	['<urn:uuid:454ff2cb-be15-4d5f-aad7-d4b3ea831265>']	open-ended	with-premise	short-search-query	distant-from-document	single-doc	expert	2025-05-01T23:55:16.606337	6	54	927
485	grilled fish recipes with flowers herbs	Both salmon dishes combine well with herbs and flowers. The Native Style Salmon Bake uses lemon juice and butter for basting, while the Grilled Salmon with Nasturtium Vinaigrette features a dressing made with sherry vinegar, shallots, tarragon, chives, and nasturtium flowers, which add a mild peppery bite. The salmon is grilled until barely cooked through and served over mixed greens with the vinaigrette.	"[""Native Style Salmon Bake\n1 whole salmon (6 to 8 lb.), book filleted; (see notes)\n1 cup rock salt\n1 cup firmly packed brown sugar\n3/4 teaspoon white pepper\nframe (see instructions below)\n2 tablespoons butter or margarine, melted\n2 tablespoons lemon juice\nThe tradition of the Indian salmon bake has deep roots in the Northwest.For centuries, Native Americans such as the Makah and S'Klallam have cooked salmon on a wood frame before an open fire. The practice is so widespread that no individual tribe lays claim to the technique, but typically, a straight, strong branch of cedar or ironwood is split lengthwise at one end, then the boned salmon is fitted into the split. To hold the fish flat so it will cook evenly, additional sticks are woven over and under the salmon at right angles to the branch. Notes: Order salmon with head, tail, and back fin trimmed. Also have salmon butterflied from stomach side without separating fillets along the back, then boned (but not skinned). Any white membrane from belly area of fish should be trimmed. (All of this can be done at the market.) This shape is called a book fillet.\n1.Rinse salmon and pat dry. Mix rock salt, brown sugar, and white pepper. Spread half of the mixture over bottom of a 12- by 17-inch pan lined with plastic wrap. Lay fish, skin down, on salt mixture. Pat remaining mixture over salmon. Cover and chill 2 to 4 hours. Lift fish from pan, rinse thoroughly, and pat dry. 2. Meanwhile, select site (A, below), work out frame support (B), and start fire (C). 3. Load salmon onto soaked frame (steps 1 through 7 below). 4. When fire is ready, secure salmon at proper angle over the glowing coals with flesh toward the fire and wide end of fish 11/2 to 2 feet from heat (A, below). Check temperature by placing the back of your hand against the fish at the top and the bottom; you should be able to hold your hand in place for only 5 to 6 seconds. Adjust by pushing coals away from fish if too hot, closer if too cool. (To use a gas grill, turn heat to high, tip lid open, position frame over heat, and use your hand to judge cooking temperature. Move fish closer for more heat; turn down gas for less.) 5. Mix butter with lemon juice. Baste fish several times with butter mixture as it cooks. Check heat often. If wood frame starts to smolder, squirt or brush with water. 6. Cook fish until surface turns evenly opaque, 20 to 30 minutes. 7. Handling frame gently (cooked fish breaks up easily), rotate salmon so skin side faces the heat. Secure frame and continue to cook just until fish feels firm to touch, 20 to 30 minutes more, basting several times. 8. Gently lay salmon in frame, skin down, on a large board or platter. Snip wires and gently pull wood frame from fish. Serve salmon hot or cool. Lift fish pieces off the skin and season with juice from lemon wedges. Putting the salmon on the frame Purchase frame parts: At a lumberyard, have wood cut to specific lengths. You will need two pine 1-by-1s (each 6 to 7 ft. long), five pieces of 1/4- by 1/2-inch pine screen mold (each 18 in. long), and 2 feet of 22-gauge (or heavier)wire. Fireproof wood: Soak frame pieces in water at least two hours. If you don't have a container long enough to immerse the wood, wrap the parts of the long stakes that will be exposed to fire in a thick layer of wet towels, seal with foil or plastic wrap, and saturate towels as needed. 1. To start, gather the soaked frame pieces, salad oil and a brush, wire, wire cutters, pliers, and fish. 2. Lightly brush salad oil onto a 24-inch section of one side of each of the long stakes, starting at one end. Lightly oil one side of each short wood piece. 3. Lay one long stake on a table, oiled side up. Starting about 5 inches from the end of the oiled part of the stake, lay three short pieces, oiled side up, about 5 inches apart across it.4. Center salmon, skin down, on frame, wide end pointed toward middle of stake. Adjust short wood pieces so fish overlaps frame by 2 to 3 inches on each end.5. Lay the two remaining short wood pieces, oiled side down, across the salmon between the short pieces under it--in effect weaving the fish in place.6. Place second long stake, oiled side down, directly over the one beneath the salmon. Wrap wire around top ends of stakes and twist tightly to secure.7. Wrap wire around stakes at the other end of the fish. Twist wire tightly to secure.\nThe site, frame support, and fire A. Select a site that is protected from the wind. Set frame at a 45° to 60° angle over the fire, sticking stake ends into a hole to hold it (or lean frame against the barbecue). B. Use rocks, concrete building blocks, bricks, or bagged sand to brace frame base securely. C. Build fire (see photo at top of page) in a portable barbecue (20 to 22 in. wide) with a firegrate, vents open: About 21/2 hours before serving time, ignite four or five seasoned, split logs (each 4 to 5 in. wide, 12 to 14 in. long) on firegrate. Let wood burn down to medium glowing coals, 1 to 11/2 hours; a few low flames are fine. Judge heat by holding your hand where fish will be. When you can barely hold your hand in this spot for five to six seconds, the fire's ready for cooking.\nYield: 12 to 16 servin\nPreparation Time: 3 hours"", 'Edible flowers add beautiful color and floral flavors to both savory and sweet dishes. Flowers, like herbs, have been used in cooking for centuries. Of course not all flowers are edible, but the ones that are lend the adventurous cook a lovely myriad of dishes to brighten up the family meals. Here are four floral-enhanced recipes you can serve while fresh flowers are in season.\nEdible flower recipes\nIf you have never eaten or cooked with edible flowers, you might be surprised that some of the flowers in your yard can star in some of your favorite dishes. Pansies, violets, nasturtiums, and\ncalendula flowers are just a few of the many floral edibles you can add to your meals.\nHowever, before you go flower picking, read Edible flowers: Beautiful, fragrant and flavorful for more information. And regardless of the\nflowers you choose, make sure they are free of pesticides and other chemicals (organic flowers are your best bet).\nSit back and enjoy a tall glass of iced lavendar-kissed lemonade\n1 tablespoon fresh lavender buds\n1 cup boiling water\n6 cups fresh squeezed lemonade\nSprigs of fresh lavender\n1. Place lavender buds in a large glass and add boiling water. Cover and let steep for 5 minutes. Pour mixture through a fine mesh sieve into a 2-quart pitcher. Discard lavender buds.\n2. Stir lemonade into mixture in pitcher. Cover and chill several hours or overnight. To serve, pour lemonade mixture over ice cubes in stemmed goblets. Garnish each with a lemon slice and fresh\nsprig of lavender.\nRosemary Flower Biscuits\nRosemary bushes produce tiny purple flowers that can liven up biscuits, quickbreads and salad dressings. They also make a lovely garnish for finished dishes. Serve these tasty biscuits with\nand roasted asparagus for a savory satisfying meal.\n2 cups all-purpose flour\n4 teaspoons baking powder\n1/2 teaspoon salt\n1/4 cup (1/2 stick) plus 2 tablespoons butter, cut into tiny pieces\n2 tablespoons fresh rosemary flowers\n3/4 cup milk\n1. Preheat oven to 450 degrees F. In a large bowl, mix flour, baking powder and salt together in a bowl.\n2. Cut in 1/4 cup butter with a pastry cutter or two knives until mixture is a coarse meal. Stir in rosemary flowers. Stir in the milk until ingredients are moistened.\n3. Turn dough out onto a floured board. Shape and knead just until dough forms a square shape about 1-1/2 Inches thick. Transfer dough to a heavy cookie sheet. With a sharp knife, cut dough into 8\nsquares. Dot squares with remaining 2 tablespoons butter. Bake for 10 to 12 minutes or until lightly browned.\nPansy Herb Salad\nWith their beautiful array of colors and mild lettuce-like flavor, pansies brighten any dish. For this salad, only lemon juice is used as a dressing. The walnuts and feta add quite enough flavor.\n4 cups mixed greens\n1/4 cup fresh sprigs of dill\n1/4 cup fresh flat-leaf parsley leaves\n4 large basil leaves, rolled up and thinly sliced crosswise\n1 large lemon, halved\nPinch of salt\nFresh ground black pepper to taste\n1 cup toasted walnuts\n3/4 cup crumbled feta\n1 cup fresh pansy flowers\nToss salad greens and herbs in a large bowl. Squeeze lemon juice (without the seeds) over the greens and season with salt and pepper. Toss again. Add walnuts and feta and toss\nwell. Divide salad and pansies among four serving plates and serve.\nGrilled Salmon with Nasturtium Vinaigrette\nNasturtiums add a mild peppery bite and beautiful color to this dish. The agave nectar\nor honey lends a lovely sweetness that is countered by the rich flavor of the salmon. For a change, grill mahi mahi or tuna steaks and substitute other fresh herbs for the vinaigrette.\n1/4 cup sherry vinegar\n1/4 cup minced shallots\n1 tablespoon agave nectar or honey\nSalt and freshly ground black pepper to taste\n1/2 cup plus 2 tablespoons extra virgin olive oil\n1 tablespoon minced fresh tarragon\n1 tablespoon minced fresh chives\n1/2 cup finely chopped fresh nasturtiums\n4 (5 ounces each) boneless, skinless salmon fillets\n6 cups mixed greens\nWhole nasturtiums for garnish\n1. Preheat grill to medium-high heat. In a food processor or blender, combine vinegar, shallots, honey or agave nectar, salt and black pepper. Slowly add 1/2 cup oil until emulsified. Pour dressing\ninto a cruet or mason jar. Shake or stir in tarragon and chives. Refrigerate until ready to serve.\n2. Lightly coat salmon with remaining olive oil, salt and black pepper and grill until just barely cooked through. Toss half of the vinaigrette with the greens and mound on individual plates. Place\nsalmon on top of greens, drizzle with vinaigrette and garnish with whole nasturtiums. Serve immediately.']"	['<urn:uuid:5aaeba8c-7d0c-4d36-8972-08174719b511>', '<urn:uuid:75639d8b-413c-47f9-b115-bdf860ea1cc2>']	factoid	with-premise	short-search-query	distant-from-document	three-doc	novice	2025-05-01T23:55:16.606337	6	63	1745
486	What should I feed mailed catfish in my aquarium?	Mailed catfishes can be fed all usual proprietary foods, including dry, frozen, and live foods. Dead leaves from Sea Almond, Beech, Oak, Alder, or Birch should be provided as supplementary food, as this is similar to their natural diet. While they are often kept as scavengers, it's essential to ensure they get enough food.	['Mailed catfishes are members of the family Callichthyidae. They are characterised by a combination of the following features: the body is enclosed in bony plates; the first ray of the dorsal and pectoral fins is spinous; the mouth is toothless and surrounded by barbels. The family is divided into two subfamilies: the subfamily Corydoradinae, which is very important in the aquarium hobby and comprises the genera Aspidoras, Brochis, Corydoras, and Scleromystax, and the subfamily Callichthyinae, whose members are only rarely maintained in the aquarium and consist of the genera Callichthys, Dianema, Hoplosternum, Lepthoplosternum, and Megalechis. While the Callichthyinae include only about a dozen species, the true mailed catfishes (Corydoradinae) are very species-rich: some 160 species are known to science, and about the same number again have not yet been scientifically described and are known in the aquarium hobby by C- or CW-numbers. All mailed catfishes originate from South America.\nApart from a few exceptions, mailed catfishes are bottom-dwelling species, which means that the arrangement of the bottom third of the tank is of primary importance. Part of the aquarium bottom should be covered with fine river sand (never builder’s sand!), in which the fishes can grub for food. An excess of rocks and bogwood should be avoided.\nMailed catfishes are sociable creatures and should be kept in a group of at least 6-8 individuals, though it is relatively unimportant whether or not this group consists of one or several different species.\nThe chemical composition of the aquarium water is unimportant when it comes to maintenance, but it should be born in mind that species with a striking metallic spot on the nape originate from so-called black water. This water is very soft and acid, such that few bacteria can survive there. The chemical composition of the water is, however, physiologically unimportant for mailed catfishes; good water quality is much more critical, as manifested above all by the bacterial population of the water. Mailed catfishes from blackwater biotopes require well-maintained, germ-poor water. This can be achieved by efficient biological filtration, the addition of humic substances using peat, Alder cones, or dead leaves from trees (there are also suitable liquid preparations), as good a plant growth as possible (many aquatic plants produce antibiotic substances that have a limiting effect on bacterial growth), and regular extensive partial water changes (see below).\nBy contrast the mailed catfish species most commonly maintained in the aquarium, the Peppered Catfish (Corydoras paleatus) and the Bronze Catfish (Corydoras aeneus) are completely undemanding and also occur in heavily polluted (with organics and bacteria) waters in the wild, which means that they have an enormous tolerance for living conditions that are hostile for other fishes.\nThe appropriate water temperature for the long-term maintenance of all species is generally between 22 and 26 °C, but almost all mailed catfishes can also survive temperatures of up to 30 °C for short periods (a few days to weeks) and almost all species will tolerate a short-term drop (a few days to weeks) to 18 °C. In the case of species of southern provenance (Uruguay, Paraguay) the temperature can sometimes drop as low as 14 °C.\nIn the wild mailed catfishes feed mainly on so-called detritus, the decaying remains of plant and animal wastes. In the aquarium they can be fed without problem on all the usual proprietary foods (dry, frozen, and live) for ornamental fishes. Mailed catfishes are popularly maintained as scavengers in the aquarium, but it is essential to ensure they get enough food! Dead leaves (of Sea Almond, Beech, Oak, Alder, Birch) should be provided as a supplementary food for all species, and are very similar to food of the fishes in the natural habitat.\nThe blackwater mailed catfishes are sensitive to a high germ count in the water and high levels of nitrogenous compounds. For this reason regular large partial water changes are the most important element of maintenance. Ideally 1/3 – 2/3 of the water should be changed every week, refilling with conditioned, fresh water of the same chemistry; at the same time the difference in temperature between the new water and the aquarium water should be as small as possible and never more than 2-3 °C. In aquaria with a low fish density, minimal germ population, and good biological filtration, water changes can be reduced to 1/5 of the total volume every 14 days. Longer intervals should not be employed in the long term.\nIn line with the natural habitat, these fishes should always have access to secondary plant material. Dead leaves (of Sea Almond, Beech, Oak, or Walnut), Alder cones, or peat can be utilised, or special liquid preparations added at every water change.\nThe remaining species can be maintained using the normal water-changing regime for all aquarium fishes, namely around 1/5 of the total volume every 14 days. A very large water change of around 80% of the tank volume with cooler water (around 10 °C colder than the aquarium water) is a trigger for spawning in numerous species, without which they won’t lay eggs. If there is no intention to breed then this sort of radical water change is best avoided out of respect for other tank occupants, who may not tolerate this treatment well if at all.\nAquarium and tankmates\nMailed catfishes are peaceful but active swimmers. The minimum aquarium length should be 5-10 times body length and the width 3-5 times body length. The aquarium depth is of secondary importance for all but two species, as mailed catfishes are bottom-dwellers. The exceptions are the Pygmy Corydoras (Corydoras pygmaeus) and the Tailspot Pygmy Cory (Corydoras hastatus), which grow to only 2-3 cm long and have adopted a free-swimming lifestyle. These species should be maintained like barbs or characins of comparable size.\nIn the wild the majority of mailed catfishes probably live for just one season, in the aquarium, however, they are regarded as long-lived. Even the smallest species live for several years, and the larger ones even longer, sometimes even 10 years or more.\nMailed catfishes grow quickly and usually attain sexual maturity at the age of 4-6 months. From then on growth is relatively slow, although mailed catfishes, like the majority of fishes, continue growing throughout their lives; however, because maximum length is significantly less than 8 cm in 95% of the known species, this is of little importance. Only Brochis species and the majority of the Callichthyinae grow to any size, with 8-20 cm in length to be expected, depending on the species.\nBecause of the huge distribution and the enormous variety of species, please note the exact scientific name of any species that interests you, along with the precise maintenance conditions required, above all the water temperature and the pH tolerance, as stated on the label on the sales aquarium. While blackwater species can generally be kept without problem in harder water and at a higher pH than in the wild, other species may tolerate very low pH values very badly.']	['<urn:uuid:294cafdc-ef95-4946-b548-98b7da363ff7>']	open-ended	direct	concise-and-natural	similar-to-document	single-doc	novice	2025-05-01T23:55:16.606337	9	54	1160
487	How does the library handle late returns and damaged books?	For physical books, borrowers must pay a fine of Rs. 2 per day for each overdue book. If a book is lost, damaged or defaced, the borrower must either replace it or pay triple its cost. For eBooks, there are no late fines since they automatically expire after the loan period, and they have Digital Rights Management controls that limit copying and printing to 5-10% of the content.	"['The college library is the knowledge repository centre and is strategically placed occupying a major portion of the ground floor of the premises. Keeping pace with the rapid expansion of student strength, the volume of books has been proportionately increased. Likewise having added various other courses like LL.B. (Degree), LL.B(Hons), LL.M., D.L.L. & W. and other certificate courses conducted time to time, the library has seen enrichment of its collection of reference books, journals, reports, etc. and has automated its house-keeping operations with NewGenLib (A Library Automation Software).\n8:00 AM TO 4:45 PM (MONDAY TO SATURDAY)\nNOTE: LIBRARY IS CLOSED ON ALL PUBLIC HOLIDAYS\nStatistical Data of the Library\nTotal Number books in the library – 15957\nTotal Number of Journals subscribed – 34\nTotal Number of Bound Volumes – 500\nSubscribed Online Database – 1 (Manupatra Online Database)\nNewspapers subscribed in the library – 15\nOffline databases / CDs – 10\n- Three books are issued for 14 days to each of the LL.B. Degree , B.A.LL.B. and LL.M. students on the production of borrowers ticket/College I-card.\n- Other than lending books on borrowers tickets, LL.B. Degree and B.A.LL.B. students have Book Bank Facility wherein for each subject of that semester one standard textbook is provided to the students. These textbooks are required to be returned within 10 days after the end of each term examination.\n- Research Scholar are entitled to borrow Five books on borrowers ticket/College I-card for 14 days.\n- Borrower has to pay a Fine of Rs. 2 per day on each book after the due date.\n- Borrower has to replace or to pay thrice the cost of the book if the book is lost, damaged or defaced.\n- Reference books are not issued outside of the library\nServices Offered by the Library\n- LENDING SERVICES\n- ONLINE PUBLIC ACCESS CATALOGUE (OPAC)\n- INTERNET BROWSING\n- ACCESS TO ONLINE AND OFFLINE LEGAL DATABASE\n- ISSUING TABLETS WITH INTERNET CONNECTIVITY\n- EXCLUSIVE APP OF VVM TO BROWSE OFFLINE SCHOLARLY CONTENT\n- NEWSPAPERS CLIPPING\n- REFERENCE AND REFERRAL SERVICE\n- READING ROOM\nLibrary Committee Members\n- Dr. Saba V.M. Da Silva -Principal (Chairperson)\n- Mr. C.J.F. Prasanna Kumar -Senior Faculty Member\n- Mr. Shreeharsha N. Inavalli -IQAC Coordinator\n- Adv. Cleofato Coutinho -Member\n- Shri. A.R. Salve -Librarian\nLinks to Website which will be helpful to the Students in their Academic Pursuit\nCase Law Sites:\nIt consists of the Judgments of the Supreme court of India and several High Courts.\nAccess to Judgments / Search is free, you only pay for Bonus features. It also features LATEST SUPREME COURT JUDGEMENTS.\nSupreme Court of India Decisions arranged – year-wise & Alphabetically through ‘liiofindia.org’\nSTPL-The Law Website – Reportable Judgment of Supreme Court of India – From September 2009.\nSupreme Court Reports: Official Journal of Reportable Supreme Court Decisions\nCauselists – are scheduling of cases to be heard by the courts on following day.\nIndLaw.com – Case Status : Disposed and pending cases status.\nCentral Information Commission of India – Decisions arranged Alphabetically and year-wise.\nIndian Cyber Appellate Tribunal – Decisions are based on data obtained from the Department of Information Technology , Ministry of Information & Technology, GOI.\nIndian Central Administrative Tribunal – Decisions are based on Judgement Information System (JUDIS) through ‘liiofindia.org’\nForeign Court Judgments ( which includes the database of Australia, Canada, European Union, Indonesia, Ireland, Malaysia, New Zealand, Pakistan, Philippines, Scotland, Singapore, South Africa, United Kingdom, United States)\nWorldLII : The World Legal Information Institute is a free, Independent and non-profit global legal research facility which comprises database, catalog and Websearch.\nLawCite – like other case citators, is essentially useful in the context of a particular legal decision or law journal article. It will help you to finding a decisions, Finding out how a decision has been subsequently treated, Finding Parallel Citations, Finding Journal Articles and other related materials.\nOpen Access Legal Articles\nOpen Access Legal Books\nOpen Access Online Bare Acts/Bills/Rules\nPRSIndia.org / Bill Track : for latest Bill Status in the Indian Parliament. Even you can find ‘summaries’ of the bills from ‘Indian Parliamentary Research Service Legislative Summaries’ provided by Parliamentary Research Service (PRS). including Bills.\nThe Constitution(Amendment) Acts (India) including Statement of Object and Reasons.\nGoa Government Regulations – through ‘liiofindia.org”\nIndia Code : contains all Central Acts of Parliament right from 1836 onwards.\nIndian Central Legislations -Alphabetically and Year-wise arranged through ‘lliofindia.org’\nAdvocate Khoj-Bare Acts : Contains Central Acts-An online collection of bare acts passed by the Indian Parliament ever since 1834 is listed here with free access to the full-text.\nAdvocate Khoj – Rules: An online digest of the major rules framed under the acts is listed here with free access to the full-text.\nGoa Schemes -Database contains Schemes of Goa alphabetically and yearwise arranged through ‘liiofindia.org’\nOpen Access Legal Online Journal on Law\nGNLU-Journal of Law, Developments and Politics – published by Gujarat National Law University.\nILI Law Review – published by LL.M. students of Indian Law Institute.\nIndia Law Journal (Online Journal)\nIndian Journal of Arbitration Law – Biannual, Student reviewed e-journal launched by the Centre for Advanced Research and Training in Arbitration Law of National Law University, Jodhpur.\nIndian Journal of Constitutional Law : published by Constitutional Law Society in conjunction with M.K. Nambyar at NALSAR University of Law, Hyderabad\nIndian Journal of Intellectual Property Law -published by the NALSAR University of Law, Hyderabad through LLI of India\nIndian Journal of Law and Economics – Published by NALSAR University of Law, Hyderabad.\nIndian Journal of Law and Technology – published by the Student Bar Association of the National Law School of India University, Bangalore through LLI.\nIndian Journal of Legal Philosophy – The Articles in the Journals are from various fields of Law and cover several contemporary issues.\nJournal of Legal Analysis and Research (JLAR) – Student edited, peer reviewed quarterly publication which focuses on all aspects of Law.\nLEAD -Law, Environment & Development – publication based on New Delhi and London managed by the school of Law of the Oriental and African Studies (SOAS), University of London and International Environmental Law Research Centre (IELRC).\nNALSAR Environmental Law and Practice Review – Published by NALSAR University of Law, Hyderabad.\nNALSAR Law Review – Published by NALSAR University of Law, Hyderabad.\nNALSAR Media Law Review – Published by NALSAR University of Law, Hyderabad.\nNALSAR Student Law Review – Published by NALSAR University of Law, Hyderabad.\nASEAN Agreements and Conventions – based on the data obtained from the ASEAN website through ‘asianlii.org’.\nCanadian Treaty Series – based on the data obtained from Canada treaty Information Website through ‘commonlii.org’.\nCouncil of Europe Treaty Series – based on the data obtained from the Council of Europe Website through ‘worldlii.org’.\nEuropean Treaties – Legal texts on which the European Union and the European Communities are founded.\nLeague of Nations Treaty Series -based on the data obtained from the United Nations Website through ‘worldlii.org’.\nSAARC Agreements and Conventions – based on data obtained from SAARC website through ‘asianlli.org’.\nUnited Nations Treaty Series – based on the data obtained from the United Nations Website through ‘worldlii.org’\nIndian Treaties Series – Database contains Indian Bilateral treaties and is based on the data obtained from Ministry of External Affair Website through ‘liiofindia.org’.\nMoot Court Competitions/Seminar and Conferences\nLexceter@ : Moot Announcements\nConference Alerts/Law : Upcoming law conferences worldwide\nOnline Moot Court Competition Memorials\nShodhganga -Repository of Indian Ph.D. Thesis in electronic form.\nShodhgangotri – Repository of Indian Research in Progress-Electronic version of approved synopsis submitted by research scholars to the university. Initiated by INFLIBNET\nGlobal News and Events on Law\nBar & Bench: – Legal Journalism. Unique platform aimed at connecting India’s Legal fraternity, bringing to you the latest in news and issues affecting the legal domain.\nLegal-News at LegalIndia.com\nE-Newspapers (Goa State(India))\nNavhind Times (English)\nNational and Other State E-Newspapers\nHindustan Times (English)\nThe Indian Express (English)\nIllustration of Legal Maxim\nOpen Law Dictionaries/Encyclopedia\nFree Legal Aid Cells\nOpen Access Gazattes\n- Goa Government E-Gazettes\nNational Eligibility Test (NET)\nState Eligibility Test (SET) for Maharashtra And Goa\nLegal Opinion Sites\nhttp://www.lawguru.com/ – Ask Free Legal Questions, Answered by Attorney\nForest Case Update (http://forestcaseindia.org) – Information Dissemination Service on Forest and Wildlife Cases in the Supreme Court and National Green Tribunal)\nhttp://indlegal.com : A Comprehensive Legal Search tool which collates , organizes a user friendly collection of links of various national and international legal sites.\nGOI Web Directory : A one-point source to access all Indian Government Websites.\nIndia.gov.in : National Portal of India to enable a single window access to information and services provided by Government Entities.\nLegallyIndia : is a news and community portal for Indian lawyers, covering Indian law firms, LPOs and law schools and students.\nCentral Bureau of India (CBI) : Official Site\nManupatra Online Legal Database:\n(Paid Subscription to access)\nContent: Supreme Court and High Court Cases, Tribunal and Commissions, Notifications and Circulars, Bare Acts, Bills, Draft Ordinances, Commentaries, Articles, Books, e-journals, etc.\n(Paid Subscription to access)\nAn Initiative of Ministry of Human Resource Development (MHRD) Under the NME-ICT now funded by UGC, as college component under UGCINFONET Digital Library Consortium.\nContent: The Consortium subscribes under N-LIST Programme are available from the publisher’s Web site which contains e-journals and e-books on all subject areas.\nStudents have access the OPAC to search/check the availability of the books in the library to issue/refer in the campus through LAN/Wireless LAN.\nList of Journals/Reporters Subscribed\n- All India Reporter\n- AIR Bombay High Court Reports (Civil)\n- AIR Bombay High Court Reports (Criminal)\n- Bombay Cases Reporter (Monthly)\n- Bombay Cases Reporter (Criminal)\n- Bombay Law Reporter\n- Civil and Military Law Journal\n- Criminal Law Journal\n- Current Indian Statutes\n- Consumer Protection Reporter\n- Goa Law Reporter\n- Journal of Indian Law Institute\n- Indian Bar Review\n- Indian Journal of International Law\n- Labour Law Journal\n- Legal Views and News\n- Maharashtra Law Journal\n- Social Action\n- Supreme Court Cases Weekly\n- Third Concept\nList of Magazines Subscribed\n- Careers 360\n- Competition Success Review\n- Economic and Political Weekly\n- Employment News\n- Down to Earth\n- Goa Today\n- India Today\n- Lawyers Update\n- University News\nList of Newspapers Subscribed\n- Economic Times (English)\n- Goa Doot (Marathi)\n- Gomantak (Marathi)\n- Gomantak Times (English)\n- Herald (English)\n- Hindu (English)\n- Indian Express (English)\n- Lokmat (Marathi)\n- Loksatta (Marathi)\n- Maharashtra Times (Marathi)\n- Navhind Times (English)\n- Navprabha (Marathi)\n- Sunaparant (Konkani)\n- Tarun Bharat (Marathi)\n- Times of India (English)\nNew Arrival (Books)\n|1||Agarwal, S.K.||Indian Easement Act|\n|2||Agrahari, Gunjan||Law relating to Dowry Prohibition, Cruelty and Harassment|\n|3||Ahmad, Aqil||Text Book of Mohammedan Law|\n|4||Ahmed, Aquil||Equity, Trust, Mortgage and Specific Relief Act|\n|5||Ahuja, V.K.||Law Relating to Intellectual Property Rights|\n|6||Arora, Manish||Universal’s Guide to CLAT and LLB Entrance Examination|\n|7||Avadhani S.R.||Law of Civil Wrongs|\n|8||Awasthi, S.K.||Goa Law Digest (2003 to 2007)|\n|9||Awasthi, S.K.||Goa Law Digest (2008 go 2012)|\n|10||Awasthi, S.K.||Commentary on Goa Daman and Diu Agricultural Tenancy Act|\n|13||Bangia, R.K.||Law of torts|\n|14||Bansal Ashwini Kumar||International Commercial Arbitration|\n|16||Bhashyam and Adiga||The Negotiable Instruments Act|\n|17||Bhattacharya, T.||The indian penal code with exhaustive comments and case law|\n|18||Bhattacharyya, T.||The Interpretation of Statutes|\n|19||Bindra, N.S.||Interpretation of Statutes|\n|20||Broadway||Family and Succession Law in Portuguese Civil Code of 1857: A 21st Century Approach|\n|21||Chaturvedi, R.G.||Law of Writs and Other Constitutional Remedies Vol.-I|\n|22||Chaudhary, V.R.||The Code of Civil Procedure|\n|23||Chopra, D.S.||Interpretation of Statutes|\n|24||Choudhry, R.N.||Law of Forests in India|\n|25||Dhingra Sehgal, Sangita||Commentary on the Legal Services Authorities Act|\n|26||Dighe, S.D.||Criminal Manual|\n|27||Doabia, H.S.||Law of Elections and Election Petitions vol.-1 & 2|\n|28||Ganguy. D.K.||Pleading, Drafting and Conveyancing|\n|29||Goswami, V.G.||Labour and Industrial Laws Vol.-2|\n|30||Gupta, G.S.||Law of Injunction|\n|31||Gupta, Karn||Introduction to Company law|\n|32||Gupta, S.P.||Professional Ethics, Accountancy for Lawyers Bench-Bar Relations|\n|33||Gupta, V.K.||Universal’s Multiple Choice Questions for Judicial Service Examinations|\n|34||Gupte, A.K.||Civil Manual|\n|35||hargopal||Legal Draftsman ( Vol. 1 & 2)|\n|36||Jadhav, Amol P.||Law relating to Postmortem|\n|37||Jain, D.K.||Guide to NRI and PIOs|\n|38||Jain, Pawan K.||Hindu Undivided Family : Formation Management and Taxation|\n|39||Kanga and Palkhiwala||The Law and practice of Income Tax ( Vol.-1 & 2)|\n|40||Kant, Neelam||Law relating to Protection of Women from Domestic Violence|\n|41||Kapoor, S.K.||Human rights under international law and indian law|\n|42||Kapoor, S.K.||International Law & Human Rights|\n|43||Kataria, R.P.||Medico-Legal Dictionary under Civil and Criminal Law|\n|44||Kathuria, R.P.||Supreme Court on Criminal Law (1950-2013) (Set of Seven Volumes)|\n|45||Kathuria, R.P.||Law and Crimes and Criminology Vol.-1 to 4|\n|46||kaur, Harpreet||Business and Corporate Law|\n|47||Khare, R.C.||Private International Law|\n|48||Krishnan, K.||Pleading and Practice|\n|49||Kulkarni, P.K.||Seth’s Bankong Regulation Act|\n|51||Lal, Batuk||The Law of Evidence in India, Pakistan, Bangladesh, Sri Lanka and Malaysia Vol. 1 & 2|\n|52||LexisNexis||The Companies Act, 2013 with Rules and Forms|\n|53||LexisNexis||Short Notes and Multiple Choice Questions : The Constitution of India|\n|54||Majumdar, R.K.||Law of Consumer Protection in India Vol.-1 & 2|\n|55||Malik, Krishna Pal||Law and Social Transformation|\n|56||Malik, P.L.||Handbook of Labour and Industrial Law|\n|57||Mani Tripathi, B.N.||Hindu Law|\n|58||Mathur, D.N.||All India Bar Examination Guide|\n|59||Mishra, O.P.||Law Relating to Women and Child|\n|60||Mitter, V.||Police Diaries : Statement Reports Invvestigation Vol.-1|\n|61||Mulla and Kannan||Te Sale of Goods Act and the Indian partnership|\n|62||Myneni, S.R.||Drafting, Pleading and Conveyancing|\n|64||Myneni, S.R.||Law of Intellectual property Law|\n|65||Naqvi, S.K.||Law Relating to Wakfts in India|\n|66||Narayan Reddy, K.S.||Medical Jurisprudence and Toxicology|\n|67||Narayan, P.S.||Law relating to Lok Adalats : (Legal Services Authorities Act, 1987)as amended by Act 37 of 2002|\n|68||Narayana, P.S.||Suuits : Law Practice and Procedure|\n|69||Narayana, P.S.||Intellectual property Law in India|\n|70||Pal Singh, Mahendra||Constitution of India|\n|71||Pandey, D.N.R.||Limitation Act (16th ed)|\n|72||Pandey, J.N.||The Constitutional Law of India|\n|73||Paranjape N.V.||The code of criminal procedure:along with juvenile justice act & probation of offenders act|\n|74||Paranjape N.V.||Studies in Jurisprudence and legal theory|\n|75||Paranjape N.V.||Public interest litigation legal and services, lok adalats and para legal services|\n|76||Paranjape, N.V.||Law Relating to Arbitration and Conciliation in India|\n|77||Paranjape, N.V.||New Company Law|\n|78||Paranjape, N.V.||Environmental Law|\n|79||Paranjape, N.V.||Right to Information|\n|80||Pathak, Akhileshwar||Law Relating to Special Contracts|\n|81||Paul, Santosh||Choosing Hammurabi : Debates on Judicial Appointments|\n|82||Pinto||Practice Traffick yoga|\n|83||Polock and Mulla||The Specific Relief Act|\n|84||Prasad, Kamakshya||Law of Scam|\n|86||Rai, Suman||Law Relating to Plea Bargaining|\n|87||Rashid, M.A.||Ultimate Guide to Judicial Services Examinations 214|\n|88||Ratanlal and Dhirajlal||Law of Evidence|\n|89||Ratanlal and Dhirajlal||The Law of Evidence (Hard Bound)|\n|90||Rathna Swamy, P.||Handbook on Election Law|\n|91||Reis, Miguel||Portuguese Citizenship of Persons born in the Earstwhile Estado De India and of their desendants|\n|92||Rosedar, S.R.A.||Family Law-I|\n|93||Rosedar, S.R.A.||Constitutional Law-I|\n|94||Sarkar, S.C.||The Code of Civil Procedure Code Vol.-1 & 2|\n|95||Sarkar, S.C.||The Code of Criminal Procedure vol.-1 & 2|\n|96||Sarkar, S.C.||Law and Procedure of Departmental Enquiries, WrongfulDismissals and Disciplinary Actions Vol.-1 &2|\n|97||Sarkar, Sunil Kumar||Marriage and Divorce Laws|\n|98||Sarkar, Sunil Kumar||Law of Protection of Women from Domestic Violence|\n|99||Saxena Poonam Pradhan||Property Law|\n|100||Saxena Poonam Pradhan||Family Law-II|\n|101||Sen Gupta, S.P.||Commentaries on the Protection of Women from Domestic Violence Act, 2005|\n|102||Seth, Karnika||Computers Internet and new Technology Law|\n|103||Sharma, Kirti and Shukla, Vedant||Intellectual property Rights|\n|104||Sharma, Meenakshi Dev||Principles of Economics|\n|105||Sharma, Prashant Tyagi||Offences by Companies|\n|106||Sharma, S.S.||Legal Services, Public Interest Litigations and Para-Legal Services|\n|107||Shrinivasan, Anand G.||Accounts Audit and Auditors|\n|108||Singh, Avtar||Introduction to Interpretation of Statutes|\n|109||Singh, Avtar||Law of Evidence|\n|110||Singh, Bhuvaneshwar||Law of attachment of Property|\n|111||Singh, G.P.||Principles of Statutory Interpretations|\n|112||Singh, G.P.||Priniciples of Equity with Special Reference to Trust and Specific Relief Alongwith Fiduciary Relations and Mortgages|\n|114||Srivastava||Securitisation of Debt Recovery vol.-1 & 2|\n|115||Srivastava, K.K.||The Law of Pleadings, Drafting and Conveyancing|\n|116||Srivastava, S.S.||Right to Information|\n|117||Srivastava,S.C.||Criminology, Penology and Victimology|\n|118||Subba Rao||Lectures on Political Science|\n|119||Subba Rao||Family Law in India|\n|120||Subba Rao||Hindu Law|\n|121||Subba Rao||Family Law in India|\n|122||Subba Rao||Family Law in India|\n|123||Tannan, M.L.||Banking Law and practice in India Vol.-1 9 3 vol.-1 Set)|\n|124||Thacker, C.K.||Supreme Court on Civil Law ( 5 Vol.- Set)|\n|125||Tiwari, G.S.||A Text Book of Jurisprudence|\n|126||Tyagi, S.P.||Criminal Trial vol.1& 2|\n|127||Universal Law Publishing||The Code of Criminal procedure Code|\n|128||Universal Law Publishing||Universal’s Banking and Financial Institutions|\n|129||university of Lisbon||Family and Succession Law in Portuguese Civil Code of 1857: A 21st Century Approach|\n|130||Varshini,D.P.||How to frame charge under Penal Code and Criminal Major Acts|', ""eBooks are electronic versions of the printed books that you might find on the shelf in the library. The benefits of eBooks are that:\nyou can read them online, print and download them, 24 hours a day, 7 days a week, on or off campus\nyou do not get fines and you do not have to queue to access them\nyou can search within the text for keyword/s\nyou can access them from your mobile device\nMost of eBooks services (see Dawsonera below) are compatible with browsers on the University desktops, Adobe Acrobat reader software is required to print, copy and download eBooks.\neBooks are subject to the same restrictions as print books, individuals are permitted to download up to one chapter or 5% from an eBook. The publisher may also have their restrictions, often referred to as Digital Rights Management (DRM) controls, which allows them to control and manage usage, such as the number of concurrent users and the number of pages a user can copy, print or download.\nAs with most of our other eResources, to access an eBook of campus you need your University username and password.\nWe have eBooks from a range of suppliers. We have eBooks from a range of suppliers which are listed below. There are links to access the books, plus links to printed and video guides for many of these.\nThis ia a multidisciplinary collection of books, and mostly allows unlimited concurrent access. You can copy between 5-10% of text and print between 5-10% but you can only print one page at a time. You can download a title for offline reading for 3 days but you cannot print from saved copy, once the download period has expired you can download the book again.\nPlease note: there is a bug in Internet Explorer (IE) 9 which means that the download and read online options do not work correctly with Dawsonera books. To overcome this you must set compatibility view when viewing a Dawsonera book (select Tools>Compatibility view on the IE9 toolbar). Alternatively you may find it easier to use a different web browser such as Firefox or Google Chrome.\nContains 30,000+ eBooks, covering all subject areas, and allows unlimited concurrent users. You can search the entire collection by keyword, subject, publisher etc, print pages or copy and paste search results.\nGuides to using ebrary®\nCovering most subjects, and reflecting current learning and teaching, there is no concurrency and only allows one user at a time. You can view online or download.\nForensic Science, Law Enforcement and Criminal Justice ebooks, with a searchable interface. Individual chapters can be viewed, printed and downloaded to a desktop/laptop PC.\nIncludes titles available in fields such as computer science, artificial intelligence, information theory, computer programming, information technology and electrical engineering. A fantastic eBook resource for computing, engineering and technology based students. The link will take you through to the main IEEEXplore site and you can choose to search the whole IEEE digital library or just view the eBooks individually by clicking on the 'Books and eBooks' link.\nDatabase of over 30,000 chapters from over 2,000 books published by the American Psychological Association. Chapters can be viewed online and downloaded to a desk/laptop PC and mobile devices.\nCollection of 21 Philosophy ebooks from Palgrave Macmillan. Plus free Open Access content.\nThe eReference library for programmers and IT professionals. Covering the latest in IT, computing, e-commerce and many of the new technologies, Safari Tech Books also contains user guides for popular types of software.\nThis collection includes books on web design, mobile applications and design software. Book PDFs can be downloaded for the purpose of individual educational use.\nASME Press is an imprint of the American Society of Mechanical Engineers (ASME), established to publish books and now eBooks beyond the Society’s traditional programs of publications sponsored by ASME’s technical divisions. The ASME Digital Collection currently contains over 120 new and classic eBooks.\nA database of quality reference resources for students and scholars, featuring Wiley-Blackwell’s companions, handbooks, dictionaries and guides from across the social sciences and humanities.\nBringing together 2 million digitized entries across Oxford’s Dictionaries, Companions and Encyclopedias.\nIf you experience a problem using any of the eBook services please contact email@example.com and give details of the eBook services you are using together with details of the book.""]"	['<urn:uuid:1c59a09c-ffe6-4db1-89bb-8e05fb7465da>', '<urn:uuid:1fc850fd-9810-4fc2-8538-1383e0423293>']	factoid	with-premise	concise-and-natural	distant-from-document	multi-aspect	novice	2025-05-01T23:55:16.606337	10	68	3371
489	amino acid residue preferences inner outer cell membrane proteins	The propensity of positively charged residues is higher in the non-transmembrane segments on the inner part of the cell, while a high propensity of tyrosine and tryptophan indicates the outer part of the cell.	"[""Protein Structure Prediction\nActive from 1997 to 1999\nMembrane proteins are involved in a wide range of essential functions, including the communication between cells and the transport of nutrients, ions, and waste products across biological membranes. These proteins, that are estimated to constitute 25% of proteins at a genomic scale, play key roles in an equally wide range of diseases like diabete, hypertension, depression, arthritis and cancer. They are also common drug targets (for over 75% of pharmaceuticals in use today). Determining membrane protein structures is essential for the understanding of how drugs interfere with cellular communication and regulation. However, current knowledge about the detailed 3D structures of membrane proteins is limited, because such protein structures are difficult to study by traditional experimental methods.\nThe idea is to use computational techniques to enhance our knowledge about membrane proteins. However, developing algorithms that are capable of predicting the three-dimensional structure of proteins at atomic detail is a very difficult task. Instead of tertiary structure determination, we focused our research on two complementary aspects: the structural classification of proteins, which allows to identify potential membrane proteins, and the prediction of transmembrane alpha-helices in membrane proteins.\nStructural classification of proteins\nPeriodical patterns and tandem repeats of residues are often found in DNA and protein sequences. In proteins, their presence helps towards an understanding of the molecular structure of a fibrous/structural protein employing the principle of conformational equivalence and it may suggest ways of ultramolecular assembly for the formation of higher order structure. Characteristic examples are periodicities found in a number of sequences of fibrous proteins (e.g. tropomyosin, myosin, keratins and collagen). We used the Fourier analysis method to highlight hidden periodicities in protein sequences and developped FT, a tool accessible by biologists through the Internet1 2.\nIn the continuation of this work, we explored the use of hierarchical, artificial neural networks for the generalized classification of proteins into several distinct classes - transmembrane, fibrous, globular, and mixed - from information solely encoded in their amino acid sequences 3 4 5. The use of our implementations (PRED-TMR2 and PRED-CLASS) to analyze various test sets and complete proteomes of several organisms demonstrates that such methods could serve as a valuable tool in the annotation of genomic open reading frames with no functional assignment or as a preliminary step in fold recognition and ab initio structure prediction methods 6 7 8 9 10 11.\nPrediction of transmembrane alpha-helices in membrane proteins\nThe successful location of transmembrane segments, of their secondary structure and the packing modes of secondary structure elements is important because they define the architecture of a transmembrane protein. However, equally important is the determination of topology, which defines the polarity of integral membrane proteins.\nResearchers have identified several characteristics that are common to a large proportion of transmembrane segments. They observed, for example, that transmembrane segments are mainly composed of hydrophobic residues, and that the propensity of positively charged residues is higher in the non-transmembrane segments on the inner part of the cell, also that a high propensity of tyrosine and tryptophan indicates the outer part of the cell. To enhance this knowledge, we performed several statistical analysis of known transmembrane segments to find other characteristics of transmembrane parts. We determined, among other things, the distribution of transmembrane segment length, the propensity for each amino acid to be in a transmembrane region and the precise profiles of potential termini (“edges”, starts and ends) of transmembrane regions [@Pasquier1999a]. We combined this information with several scoring functions to predict the precise position of transmembrane segments and their topology 12 13. The accuracy of our method compares well with that of other popular existing methods. This work led to the implementation of several tools freely available on the Internet: PRED-TMR, OrienTM, CoPreTHi and Dam-Bio.\n|Program||Training and Mobility of Researchers (TMR)|\n|Funder||European Economic Community (EEC)|\n|Grant name||EEC-TMR “GENEQUIZ”, Integrated Software System for Molecular Biologists|\n|Project coordinator||Chris Sanders|\n- COPRETHI: Ensemble learning to predict transmembrane segments in proteins\n- DAM-BIO: Integrated environment designed to support protein sequence and structure analysis on the Web\n- DB-NTMR: Database of non transmembrane regions automatically extracted from the SwissProt database\n- DB-TMR: Database of transmembrane regions automatically extracted from the SwissProt database\n- FT: Analysis of periodic patterns in amino acid or DNA sequences by Fourrier transform\n- ORIENTM: Topology prediction of transmembrane proteins and segments\n- PRED-CLASS: System of cascading neural networks that classifies any protein into one of four possible classes: membrane, globular, fibrous, mixed\n- PRED-TMR: Prediction of transmembrane domains in proteins\n- PRED-TMR2: Identification of transmembrane proteins and prediction of their transmembranle domains\n- A Web Server to Locate Periodicities in a Sequence. Bioinformatics.(1998). ↩︎\n- A Web Interface for FT: A Tool Dedicated to the Study of Periodicities in Sequences. 20th Conference of the Hellenic Society for Biological Science.(1998). ↩︎\n- PRED-TMR2: An Hierarchical Neural Network to Classify Proteins as Transmembrane and a Novel Method to Predict Transmembrane Segments. 21st Conference of the Hellenic Society for Biological Sciences.(1999). ↩︎\n- PRED-CLASS: Cascading Neural Networks for Generalized Protein Classification and Genome-Wide Applications.. Proteins: Structure, Function, and Bioinformatics.(2001). ↩︎\n- PRED-CLASS: Bioinformatics Software for Generalized Protein Classification and Genome-Wide Applications. 23rd Conference of the Hellenic Society for Biological Sciences.(2001). ↩︎\n- CoPreTHi: A Program to Combine the Results of Transmembrane Protein Segment Prediction Methods. 20th Conference of the Hellenic Society for Biological Sciences.(1998). ↩︎\n- CoPreTHi: A Web Tool Which Combines Transmembrane Protein Segment Prediction Methods.. In silico biology.(1999). ↩︎\n- An Hierarchical Artificial Neural Network System for the Classification of Transmembrane Proteins. Protein Engineering Design and Selection.(1999). ↩︎\n- A Workbench for Computational Analysis of Protein Sequence and Structure on the Internet. 22nd Conference of the Hellenic Society for Biological Sciences.(2000). ↩︎\n- Frequent Pattern Mining in Attributed Trees. 17th Pacific Asia Conference on Knowledge Discovery and Data Mining (PAKDD'13), J. Pei et al. (Eds.): PAKDD 2013, Part I, LNAI 7818, Pp. 26–37. Springer, Heidelberg (2013).(2013). ↩︎\n- Evaluation of Annotation Strategies Using an Entire Genome Sequence. Bioinformatics (Oxford, England).(2003). ↩︎\n- OrienTM: A Novel Method to Predict Transmembrane Protein Topology. 21st Conference of the Hellenic Society for Biological Sciences.(1999). ↩︎\n- A Novel Tool for the Prediction of Transmembrane Protein Topology Based on a Statistical Analysis of the SwissProt Database: The OrienTM Algorithm. Protein Engineering Design and Selection.(2001). ↩︎""]"	['<urn:uuid:36843339-da9b-4335-9ab3-7a0f86886351>']	factoid	direct	long-search-query	distant-from-document	single-doc	expert	2025-05-01T23:55:16.606337	9	34	1051
491	I'm doing research on hereditary cancer patterns. What makes some families more susceptible to ovarian cancer, and how does this affect their recommended screening approach?	Ovarian cancer is much more common in certain family groups. A woman is considered at high risk if she has a strong family history of breast, ovarian, or colorectal cancer, or is known to have the BRCA-1 or -2 gene mutations. For these high-risk women, authorities recommend more frequent screening, typically every six months, using tests like ultrasound and pelvic examinations. This increased monitoring is necessary because cancer can develop very quickly in these individuals. For women without risk factors, the lifetime risk of developing ovarian cancer is less than two percent.	['Ovarian cancer is much more common in certain family groups. It is quite rare for other women. In addition, a number of other personal factors may either protect or indicate higher risk. It helps to know whether a woman is at higher risk when deciding whether to screen more often. The following factors may mean a woman is at higher risk:\nOvarian cancer has long been thought of as a silent killer. It was almost always diagnosed very late. By the time it was found, cancer had already spread through the abdomen. Symptoms came from outside the ovaries. New studies now show that women with ovarian cancer do have symptoms that may be present very early.\nIn June 2007, as a result of these studies, most of the major North American cancer societies dealing with ovarian cancer gave the following recommendations.\nWomen who experience one or more of these six symptoms, continuously or severely, for three weeks, should visit their doctor:\nHowever, it is important to keep this in perspective. Every woman has these same symptoms at various times in her life. The key difference is that in this case, they are a change from the usual, and last for three weeks.\nOther common conditions that cause the same symptoms are urinary tract (bladder) infection, irritable bowel syndrome, food sensitivity, and menstrual symptoms.\nIf a woman has symptoms associated with ovarian cancer, her doctor can do a number of tests. These generally include a urine test to check for infection, a pelvic exam to feel the ovaries, an ultrasound, and a CA125 blood test.\nThankfully, ovarian cancer remains quite rare. In most cases, the tests will be reassuring. A woman can feel at peace knowing she does not have ovarian cancer. She and her doctor can then search for another explanation.\nThe important message is that these symptoms should not be ignored. The tests are easy to do. If they do reveal the possibility of ovarian cancer, checking out the symptoms may save her life.\nOvarian cancer is still very rare in most women. Over the course of a woman’s life, she has only a two per cent risk of developing this disease. In fact, most cases are in women who have risk factors that can be identified. Women without risk factors have an even lower chance of developing it.\nOne of the biggest questions in dealing with ovarian cancer is whether all women should be checked for it. Screening means that women who are completely free of symptoms are regularly tested using a simple and inexpensive blood or physical test. Unfortunately, screening for ovarian cancer is not as simple as we might like.\nA good example of the hype around screening is in an email that has been circulating for a few years. It asks whether your doctor is ‘neglecting to order an important medical test.’ The email’s most popular version describes a woman’s close call with ovarian cancer, and the test that could have prevented her ordeal. That test is CA125. Unfortunately, CA125 is not great at screening for ovarian cancer. Not only is this e-mail alarming, it offers women false hope.\nCA125 is a marker for ovarian cancer. However, it also flags just about anything that irritates the pelvic organs or the lower abdomen. A CA125 test will react to abdominal and chest infections, menstruation, pregnancy, endometriosis, benign tumours of the ovaries, and liver disease. So a single or even yearly CA125 is not a good way to find ovarian cancer early for most women. Of all women who have elevated CA125, only three out of a hundred actually have ovarian cancer. Researchers are feverishly trying to find a more reliable screening tool.\nHowever, CA125 can monitor cell activity in the ovaries once the CA125 level has been lowered by cancer treatment. In this case, a rising level may suggest return of the cancer. Until a better test is found, it is also used to screen women at very high risk.\nOther screening tests that may be used for women at high risk include regular ultrasound and pelvic examinations. Some authorities recommend that these women should be tested every six months, as the cancer can develop in them very quickly.\nNo specific test exists to regularly screen for ovarian cancer. Thankfully, it is still rare for most women.\nThe ray of hope, however, is that we now know a set of symptoms that women themselves may notice. If concerned, they can get early diagnosis (or reassurance), and treatment where necessary. Successfully treating ovarian cancer is now much more likely.\nWe also understand much more about who is at high risk, and can monitor these women much more closely. A woman is at high risk if she has a strong family history of breast, ovarian, or colorectal (lower bowel) cancer, or is known to have the BRCA-1 or -2 gene mutations. If ovarian cancer occurs in these women, a custom designed screening program can detect it early.\nRemember that it is important to monitor your own body. Seek medical care if something changes.']	['<urn:uuid:9bdfff49-8582-48fb-ba23-c94819510334>']	open-ended	with-premise	verbose-and-natural	distant-from-document	single-doc	expert	2025-05-01T23:55:16.606337	25	92	845
493	What kind of legacy have the greatest Cincinnati Reds players left behind in terms of retired numbers and hall of fame recognition?	The Cincinnati Reds have honored their legendary players in several ways. They have retired the numbers of iconic players including Johnny Bench (5), Joe Morgan (8), and Tony Perez (24). The team has also had numerous players inducted into the Hall of Fame, including legends such as Joe Morgan, Johnny Bench, and Barry Larkin.	['The Cincinnati Reds, also known as the “Redlegs” or simply the “Reds,” have a rich and storied history in Major League Baseball. Founded in 1881, the Reds are one of the oldest professional baseball teams in the United States.\nThis iconic team, based in Cincinnati, Ohio, has had its fair share of triumphs and challenges over the years, showcasing exceptional talent and becoming a beloved fixture in the hearts of baseball fans.\nIn this article, we will explore 14 fascinating facts about the Cincinnati Reds, shedding light on the team’s achievements, memorable moments, and the impact they have had on the baseball world.\nThe Cincinnati Reds were established in 1881.\nWith origins dating back over a century, the Cincinnati Reds have a storied past that has contributed to their enduring legacy in Major League Baseball.\nThe team was originally known as the Cincinnati Red Stockings.\nDuring their early years, the team was referred to as the Cincinnati Red Stockings before eventually shortening their name to the Cincinnati Reds.\nThe Reds were the first professional baseball team.\nAs one of the oldest professional baseball teams in existence, the Cincinnati Reds hold the distinction of being pioneers in the sport.\nThe Cincinnati Reds have won five World Series championships.\nThroughout their history, the Reds have triumphed on the grandest stage, capturing World Series titles in 1919, 1940, 1975, 1976, and 1990.\nThe Big Red Machine dominated in the 1970s.\nDuring the 1970s, the Reds assembled a formidable lineup known as the Big Red Machine. Led by legendary players like Johnny Bench, Joe Morgan, and Pete Rose, the team solidified its place in baseball history.\nJohnny Bench won two National League Most Valuable Player (MVP) Awards.\nThe exceptional skills of catcher Johnny Bench were recognized with back-to-back MVP titles in 1970 and 1972, making him one of the greatest players in Cincinnati Reds history.\nThe Great 8 revolutionized defensive play.\nThe combination of the Big Red Machine’s talented infielders and outfielders, collectively known as the Great 8, revolutionized defensive play in Major League Baseball.\nPete Rose holds the record for the most career hits.\nCincinnati Reds legend Pete Rose etched his name into the history books by amassing an incredible 4,256 career hits, a record that still stands to this day.\nCincinnati Reds fans are known for their passionate loyalty.\nThe Cincinnati Reds fanbase is renowned for their unwavering devotion and support, creating an electric atmosphere at home games in the iconic Great American Ball Park.\nThe Reds have retired several legendary players’ numbers.\nIn recognition of their outstanding contributions to the team, the Cincinnati Reds have retired the numbers of iconic players such as Johnny Bench (5), Joe Morgan (8), and Tony Perez (24).\nThe Cincinnati Reds boast numerous Hall of Fame inductees.\nWith a rich history of talented players, the Cincinnati Reds can proudly claim a substantial number of Hall of Fame inductees, including legends like Joe Morgan, Johnny Bench, and Barry Larkin.\nThe Reds were the first professional baseball team to utilize floodlights for night games.\nIn a groundbreaking move, the Cincinnati Reds were pioneers in the introduction of floodlights, enabling night games to be played and revolutionizing the game of baseball.\nThe “Big Red Machine” era produced an impressive run of division titles.\nFrom 1970 to 1979, the Cincinnati Reds captured six division titles, showcasing their dominance during the highly successful “Big Red Machine” era.\nThe Reds have a strong rivalry with the St. Louis Cardinals.\nA rivalry that dates back decades, the Cincinnati Reds and St. Louis Cardinals engage in heated matchups that bring out the best of both teams, creating thrilling moments for fans.\nIn conclusion, the Cincinnati Reds are a historic and beloved baseball team that has left an indelible mark on the sport. From their origins in the 19th century to their numerous World Series victories, the Reds have captivated fans with their thrilling performances and passionate fanbase. The team’s rich history, iconic players, and enduring traditions make them a staple of Cincinnati’s sports culture. Whether you’re a die-hard fan or new to the sport, the Cincinnati Reds offer a truly unique and exciting baseball experience.\nQ: When were the Cincinnati Reds founded?\nA: The Cincinnati Reds were founded in 1881 as the Cincinnati Red Stockings.\nQ: How many World Series titles have the Cincinnati Reds won?\nA: The Cincinnati Reds have won a total of five World Series titles, which they clinched in 1919, 1940, 1975, 1976, and 1990.\nQ: Who is the most iconic player in Cincinnati Reds history?\nA: Pete Rose, also known as “Charlie Hustle,” is widely regarded as the most iconic player in Cincinnati Reds history. Rose holds numerous records and played a key role in the team’s success during the 1970s.\nQ: Where do the Cincinnati Reds play their home games?\nA: The Cincinnati Reds play their home games at the Great American Ball Park, which is located in downtown Cincinnati.\nQ: Are there any famous traditions associated with the Cincinnati Reds?\nA: Yes, one of the most famous traditions associated with the Cincinnati Reds is the singing of “Take Me Out to the Ball Game” during the seventh-inning stretch. It has become a beloved tradition that brings fans together.\nQ: How can I purchase tickets to Cincinnati Reds games?\nA: Tickets for Cincinnati Reds games can be purchased online through the team’s official website or through authorized ticket vendors. It is recommended to buy tickets in advance as games can sell out quickly, especially during popular matchups.']	['<urn:uuid:d5515d54-599a-4be2-999e-527aba346773>']	open-ended	direct	verbose-and-natural	similar-to-document	single-doc	novice	2025-05-01T23:55:16.606337	22	54	919
494	difference between large and small diaphragm condenser microphones frequency response high end	Small diaphragm condensers (1-1.5cm) have superior wide frequency response, especially in high frequencies. Large diaphragm condensers have less even high frequency response with frequencies dropping off beyond 10kHz, though manufacturers often add HF boost extending down to 2kHz.	['If you already own a selection of mics, or you’ve been able to borrow some mics off friends then you will already be on the right path to keeping your costs down for running a cheap multitrack recording session. The mics that you have will probably include some dynamic mics and maybe a few others, which are most likely to be condenser mics. There are other types of mics you might come across of course such as contact mics and boundary mics, but these are much more specialised and are unlikely to be sitting in the back of a mate’s cupboard. They are easy to recognise because they don’t often look like conventional microphones. You might be lucky and come across some ribbon mics, but the chances are slim so we’ll cover those in a later post when we look at buying new mics.\nSo, back to condensers and a quick overview of how they operate;\nA condenser mic works by sound waves changing the air pressure immediately next to the diaphragm, causing it to move a small amount. The diaphragm is placed very close to a metal backplate and a DC voltage is applied across the two (which is why they require phantom power). The diaphragm and backplate become the two plates of a capacitor. As the diaphragm is moved further away from or closer to the backplate, the capacitance changes and a current flows that is proportional to the movement of the diaphragm. Hey presto, you’ve got a condenser capsule!\nThis is a much more delicate arrangement than the capsule you will find in a dynamic microphone, and so they need to be treated with care. If you drop it and the two plates are knocked or moved, then that’s probably the end of the capsule, whereas if you just drop an SM58 (which I’m not advising) the grill might dent but should still work fine!\nCondenser mics generally come in two different flavours; those with large diaphragms and those with small diaphragms. I’m not going to go into great detail as to how the technical differences between the two affect their response, because DPA have already written an excellent page with all the info on it here that would take some doing to surpass.\nSmall Diaphragm Condensers\nThese tend to have a diaphragm diameter of maybe 1 to 1.5cm, and have a superb wide frequency response, in particular their hf response is generally better than large diaphragms. This is really useful when you want to pick up something with a lot of high frequency content like cymbals, so try them out as drum overheads! Generally they can handle higher sound levels too and have a good dynamic range, i.e. loud stuff = no problem. (see the DPA link above)\nTheir high frequency response makes them a very popular choice in the classical recording world, because without that nice flat top-end a recording can easily become dull-sounding. So if you are recording a piano or acoustic guitar, a small diaphragm will give you a nice crisp and bright high end.\nLarge Diaphragm Condensers\nThese typically have a less even high frequency response, as the physical size of the diaphragm means that high frequencies will ‘break up’ across the diaphragm rather than moving it all in one go, like a piston. So high frequencies usually drop off pretty quickly beyond about 10kHz. That might sound pretty high and maybe not worth considering, but to get the high top-end back, manufacturers often put in a little hf boost, which will extend down much lower than 10kHz, probably down to about 2kHz. This isn’t a bad thing, in fact it can be really useful on something like vocals to bring out the singer’s tone and can sound very flattering. They are also more sensitive than small diaphragm mics, and are less noisy i.e. very quiet stuff = nice and clean, again useful for things like vocals.\nMost large diaphragm condensers will come with a -10dB pad on them, because if they are subjected to high sound level they distort more easily than small diaphragms. So if you decide to try them out on something like drums then put the pad in. They are also more likely to have a switch-able directivity pattern, so you can for example put them in cardioid to reject some of the room if you want them on an acoustic guitar, or in omni if you want a nice deep low end on an upright bass.\nSo, once again, it would seem the key to getting the most out of the mics you have available, is to have a bit of an understanding of how they work and what they are likely to work well with, and of course a whole lot of experimentation. You will probably find that auditioning the mics before you use them to be a useful trick, more info on that with the page on dynamic microphones.\n[image via recordinghacks]']	['<urn:uuid:f239ae66-14eb-4143-9670-2cabdf14ef7f>']	factoid	direct	long-search-query	similar-to-document	single-doc	expert	2025-05-01T23:55:16.606337	12	38	827
495	What are the main advantages of using mediation to resolve disputes about horses instead of going to court?	Mediation offers several key advantages for horse disputes: 1) It can be more cost-effective when the court costs would be disproportionate to the horse's value, 2) It allows for quick resolution when the horse needs to be returned or sold, 3) It offers more flexible solutions than courts can order, such as arranging sale to third parties or providing replacement horses, 4) It maintains privacy and confidentiality unlike open court hearings, 5) It's beneficial when parties want to preserve their business relationship, and 6) It's helpful in cross-border disputes with jurisdictional issues.	['Latest insights from our experts\nEquine disputes and mediation\nMediation is a semi-formal way of resolving disputes outside court. Often known as Alternative Dispute Resolution (ADR) it can be very useful in horse disputes because:\n- The cost of a full blown court case may be disproportionate to the value of the horse.\n- An early resolution is often needed so that the horse can be returned to the seller, sold on, PTS, etc.\n- Solutions often require more imaginative terms than the court has power to order, eg. sale to a third party with all rights reserved as to the balance of the sum in dispute, supply of a replacement horse etc.\n- The parties may have an ongoing business relationship or wish to be able to deal with each other amicably in the future.\n- Mediations are private and confidential, unlike open court hearings.\n- In a cross-border dispute and there may be jurisdictional arguments.\nWhat if mediation seems hopeless?\nThe modern view is that mediation is always worth a try. Cases where it would be considered hopeless are very rare indeed. The courts now have the power (and inclination) to impose sanctions on any party who refuses to attempt mediation. They might be ordered to pay penalty costs or their claim might be stayed so that mediation can take place.\nHow does the process work?\nIt is usual for the parties lawyers to arrange everything and accompany them at the mediation but there is nothing to stop the parties going it alone. But if one side is represented the other will generally wish to be.\nThe parties appoint a mediator by agreement. Usually one party will suggest a few options from which the other party will choose. The mediator is contacted and asked to state his fee which the parties can accept (or not). The parties also have to choose a venue according to location cost, suitability, etc.\nOnce the parties have chosen a mediator and venue and have agreed all the costs, they must pay those costs up front, half each.\nThere is a certain amount of preparation for the mediation itself, including exchange of relevant documents and preparation of a mediation bundle and the drafting of Position Statements. Quite often the mediator will want a chat with the parties separately by telephone, just to get a feel for each side’s position.\nAt the Mediation meeting:\n- The parties will have arranged a large meeting room and an additional smaller conference room for each side and on arrival each party and its team (consisting usually of their lawyer and/or a supporter or two) will settle down in their own conference room.\n- The mediator will visit each side briefly and then open the mediation with a joint session in the large meeting room.\n- At the opening session, each side is often invited to make an opening statement and it is sometimes helpful if this is done by the parties themselves rather than their representatives. This will highlight particular points of concern and sometimes questions are raised and answered.\n- The parties will then each adjourn to their private conference rooms and the mediator will work back and to between them, trying to broker a deal.\n- If by the end of the mediation no agreement has been reached, the mediation has at that point failed. But very often the parties will continue discussions after the end of the mediation and reach agreement fairly quickly thereafter so not a failure after all.\n- If agreement is reached at the mediation, the legal representatives (or, if none, the mediator) will put it all into a formal written agreement and the parties will sign upon which the settlement agreement becomes binding and the dispute is over.\nA mediation is “without prejudice”\n- Another advantage of the mediation process is that the parties can speak frankly without worrying about damaging their case. The fact that a mediation has taken place will be known to the court but none of the statements or submissions or any of the comments made by the parties or their witnesses at the mediation will be admissible in court.\n- However if a binding agreement is reached at the end of the mediation, the blanket of privilege is lifted and the proceedings cease to be “without prejudice” because of course at that point the dispute is at an end.\nIt is common for an agreement reached at a mediation to be strictly confidential to the parties and their legal advisers. Indeed this is one of the great advantages of resolving disputes by mediation rather than in open court.\nMediation success rates\nIt is difficult to be sure but an audit carried out by the Centre for Effective Dispute Resolution (CEDR) in May 2016 reported that 86% of their mediations succeeded, the vast majority of those on the day and the rest shortly afterwards.\nEven if a mediation fails, it will often have served a useful purpose in clarifying the issues and highlighting what solution each party is really looking for.\nAt what point should I mediate?\nThe earlier the better. Perhaps the biggest advantage of mediation is the saving of legal costs. It is a simple fact that the earlier a dispute is resolved, the lower the costs for both sides. The lower the costs, the easier it is to reach a settlement. Sadly, it is far from uncommon for the parties to make a late dash for mediation when they are almost at trial. There are still advantages even at that late stage and at least the cost of trial can be saved but a equine dispute which can be settled at all can be settled early if the parties put their minds to it.']	['<urn:uuid:c6660c2c-668d-4e67-8517-40932c5486c9>']	open-ended	direct	verbose-and-natural	similar-to-document	single-doc	novice	2025-05-01T23:55:16.606337	18	92	961
497	geothermal energy benefits environment effects mining	Geothermal energy is a clean and sustainable heat source from the Earth that can be used for power generation and heating buildings. However, accessing these resources often requires mining activities which can have negative environmental impacts including erosion, loss of biodiversity, contamination of soil and water, and destruction of natural landscapes. While geothermal power plants can tap into underground reservoirs of hot water and steam for electricity production, the drilling and mining required can potentially damage ecosystems and wildlife habitats in surrounding areas.	"[""Geothermal Electrical power: The Earth's warmth-named geothermal Vitality-escapes as steam in a incredibly hot springs in Nevada.\nThe Earth's heat-known as geothermal Electrical power-escapes as steam at a scorching springs in Nevada. Credit history: Sierra Pacific\nGeothermal Electricity is the heat from the Earth. It can be clear and sustainable. Resources of geothermal Electricity vary from the shallow ground to incredibly hot drinking water and hot rock uncovered several miles beneath the Earth's surface, and down even further towards the exceptionally substantial temperatures of molten rock known as magma.\nJust about in all places, the shallow ground or higher 10 toes from the Earth's floor maintains a nearly consistent temperature in between fifty° and 60°File (10° and sixteen°C). Geothermal warmth pumps can tap into this useful resource to heat and funky structures. A geothermal warmth pump program is made of a heat pump, an air supply program (ductwork), in addition to a heat exchanger-a procedure of pipes buried inside the shallow floor near the making. Within the Wintertime, the heat pump eliminates warmth with the warmth exchanger and pumps it in to the indoor air supply system. In the summertime, the procedure is reversed, and the heat pump moves warmth from the indoor air into the heat exchanger. The warmth faraway get more information from the indoor air through the summer months may also be applied to provide a cost-free supply of scorching drinking water.\nIn America, most geothermal reservoirs of sizzling drinking water can be found within the western states, Alaska, and Hawaii. Wells might be drilled into underground reservoirs with the generation of electrical power. Some geothermal ability plants make use of the steam from the reservoir to ability a turbine/generator, while others make use of the incredibly hot h2o to boil a Operating fluid that vaporizes then turns a turbine. Warm water near the surface area of Earth may be used instantly for heat. Direct-use programs include things like heating properties, growing plants in greenhouses, drying crops, heating drinking water at fish farms, and a number of other industrial procedures which include pasteurizing milk.\nHot dry rock sources arise at depths of three to five miles everywhere you go beneath the Earth's surface and at lesser depths in particular places. Use of these methods consists of injecting chilly h2o down one nicely, circulating it by means of very hot fractured rock, and drawing from the heated drinking water from One more very well. Now, there isn't any professional applications of the technology. Existing technology also doesn't however permit recovery of heat directly from magma, the very deep and strongest useful resource of geothermal Electrical power.\nLots of systems are actually made to take advantage of geothermal energy - the warmth within the earth. NREL performs investigate to acquire and progress technologies for the next geothermal applications:\nGeothermal Energy Systems:\nGeothermal Energy Output\nMaking electric power through the earth's heat.\nGeothermal Direct Use\nProducing warmth straight from sizzling water within the earth.\nGeothermal Warmth Pumps\nUtilizing the shallow ground to heat and funky structures."", ""Mining has several bad effects. It leaves behind a huge hole after mining is done. Secondly it damages natural beauty. A beautiful landscape which once existed is now a huge piece of dug up earth.\nEnvironmental Effects. Environmental issues can include erosion, formation of sinkholes, loss of biodiversity, and contamination of soil, groundwater and surface water by chemicals from mining processes. In some cases, additional forest logging is done in the vicinity of mines to create space for the storage of the created debris and soil.\nThe effects of mining in Africa have left large-scale devastation when companies do not honour their responsibility. Because mining areas are left in an unsustainable condition, plant species and wildlife are threatened and these areas are at risk of becoming lifeless wastelands.\nThe Impact and Effect of Illegal Mining (galamsey) towards the Socio-economic Development of Mining Communities: A Case Study of Kenyasi in the Brong Ahafo Region Adjei Samuel1, N.K.Oladejo1, I.A. Adetunde2, * 1University for Development Studies, Department of Mathematics, Navrongo. Ghana.\nSome of the major effects of mining on the environment are as follows: Minerals are the natural resources which play an important role in the economic development of the country. But the extraction and mining of these natural resources leads to some adverse effect on our environment as well.\nMar 09, 2017· The mining industry has the potential to disrupt ecosystems and wipe out wildlife populations in several different ways. Here's how mining affects the environment and wildlife. Habitat Loss; Mining can lead to the destruction of habitats in surrounding areas. The …\nModern mining is an industry that involves the exploration for and removal of minerals from the earth, economically and with minimum damage to the environment. Mining is important because minerals are major sources of energy as well as materials such as fertilizers and steel.\nApr 25, 2017· Mining is the extraction of minerals and other geological materials of economic value from deposits on the earth. Mining has the potential to have severely adverse effects on the environment including loss of biodiversity, erosion, contamination of surface water, ground water, and soil.\nSome gold can be found by panning in rivers; heavy gold will remain in the pan, whereas lighter rocks and minerals float out. This small-scale form of gold mining has little effect on the body of water, but the large-scale practice of mining gold from ore can have tremendous negative effects on water quality.\nMining can effect the earth because first, deforestation, and because mining requires large portions of land to be removed before they can start mining, lots of trees and plants are removed.\n1.1 PHASES OF A MINING PROJECT There are different phases of a mining project, beginning with mineral ore exploration and ending with the post-closure period. What follows are the typical phases of a proposed mining project. Each phase of mining is associated with different sets of environmental impacts. 1.1.1 Exploration\nFeb 07, 2018· The effects in such cases can be devastating for the environment. Be it due to ignorance of the regulations or just a freak accident, incidents like the Guyana spill of 1995 may occur again. This highlights the fact that issues like mining's effect on the environment are worth some serious deliberation.\nAug 26, 2010· Dust, radon and mercury impact miners' health. Dust, radon and mercury impact miners' health. ... Miners Face Health Risks, Even on Good Days ... mining …\nThe effects of mining coal on the environment. There are 2 ways to mine coal – Strip Mining and Underground Mining – both ways have their own impact to the environment and health. We know it but coal is such a cheap energy source that we don't want to let go of it. The negative effects of coal mining cannot be disputed:\nApr 21, 2019· The human health effects due to cyanide leach gold mining are not well documented, and this is no exception in Montana. The State of Montana has done no formal studies to specifically study mine-related health effects. Pegasus, the last mining company at Zortman-Landusky, started to fund a health study with the $1.7 million supplemental money from the 1996 settlement, but because …\nADVERTISEMENTS: Some of the major environmental effects of mining and processing of mineral resources are as follows: 1. Pollution 2. Destruction of Land 3. Subsidence 4. Noise 5. Energy 6. Impact on the Biological Environment 7. Long-term Supplies of Mineral Resources. Mining and processing of mineral resources normally have a considerable impact on land, water, […]\npositive and negative effects of mining on the environment. Mankind has been mining for precious metals since 42000 years ago and that's a staggeringly long time ago and that's exactly how long our species has been digging into the ground, to harvest its precious metals.\nDownload Coal Mining sounds ... 76 stock sound clips starting at $2. Download and buy high quality Coal Mining sound effects. BROWSE NOW >>>\nMining affects the environment by exposing radioactive elements, removing topsoil, increasing the risk of contamination of nearby ground and surface water sources, and acidification of …\nApr 20, 2015· Effects of Mining. Coal mining, the first step in the dirty lifecycle of coal, causes deforestation and releases toxic amounts of minerals and heavy metals into the soil and water. The effects of mining coal persists for years after coal is removed.\nJul 25, 2018· Environmental impacts from fossil fuel pollution are rapidly increasing in regions that have the highest concentrations of fuels. There are multiple effects of mining fossil fuels. Drilling and mining practices take a substantial toll on local water sources, biologic life and natural resources.\nPublished by the American Geosciences Institute Environmental Awareness Series. ... How can metal mining impact the environment? PDF version. Material adapted from: Hudson, T.L, Fox, F.D., and Plumlee, G.S. 1999. Metal Mining and the Environment, p. 7,20-27,31-35,38-39. Published by the American Geosciences Institute Environmental Awareness Series.\nMining operations usually create a negative environmental impact, both during the mining activity and after the mine has closed. Hence, most of the world's nations have passed regulations to decrease the impact. Work safety has long been a concern as well, and …\nEffects of mining on aquatic resources are both physical and chemical in nature. Most of earthmoving activities of mining occurred well before the enactment of laws designed to protect aquatic resources - particularly the 1977 Federal Water Pollution Control Act.\nThe former is known as underground mining, the latter as strip mining or mountaintop removal. Either process contributes a high level of damage to the environment: #12 Noise pollution. One of the most obvious (albeit perhaps least harmful) environmental effects of coal mining is noise pollution.\nMining has an adverse effect on soil quality. Soil degradation is the prime impact. Another impact is deforestation and loss of fauna and flora.\nThe impact of mining on the environment and the effects of mining techniques need to be more advanced with the utilization of modern equipment to be unintrusive to the environment. Economic growth is high on the agenda of leading countries, sustaining …\nMining is an inherently invasive process that can cause damage to a landscape in an area much larger than the mining site itself. The effects of this damage can continue years after a mine has shut down, including the addition to greenhouse gasses, death of flora and fauna, and erosion of land and habitat.\nNov 14, 2016· After mining is over, the land is left as barren land. The effects of mining sometimes vary depending on what is mined out, but these are some of the general effects you will see in all mine-areas. I'm not an expert when it comes to health impact on miners, but here are some of the things I know will affect them-\nJul 08, 2017· In coal mining, the extraction, crushing, and transport of coal can generate significant amounts of airborne respirable (extremely fine) coal dust. Dust less than 10 microns in size (cannot be seen with the eye). In non-coal mining, stone, and san...\nEnvironmental impacts of mining can occur at local, regional, and global scales through direct and indirect mining practices. Impacts can result in erosion, sinkholes, loss of biodiversity, or the contamination of soil, groundwater, and surface water by the chemicals emitted from mining processes. These processes also have an impact on the atmosphere from the emissions of carbon which have ...\nApr 04, 2017· The Dangerous Effects of Illegal Mining. April 4, 2017 Environmental Issues Written by Greentumble. Illegal mining has been ravaging our planet for. decades. Not only is illegal mining riskier from a safety perspective for those who choose to participate, but it encourages reckless behavior and leads to outcomes that have negative long-term ...""]"	['<urn:uuid:565b1df2-acee-4926-9c56-b40e45481007>', '<urn:uuid:11ce18f5-51f7-4dfa-a26b-c4a5796e1622>']	open-ended	with-premise	short-search-query	similar-to-document	multi-aspect	novice	2025-05-01T23:55:16.606337	6	83	1962
498	I'm starting a new business and I'm confused about LLC vs C corp taxes. How do they differ in terms of taxation, and what are the legal protections they offer to owners?	LLCs and C corporations have different tax structures - LLCs are pass-through entities where profits are only taxed once on the owners' personal tax returns, while C corporations face double taxation (corporate level tax plus personal tax on dividends). Regarding legal protections, both structures provide limited liability, meaning owners' personal assets are protected from business debts and obligations. In both cases, owners/shareholders are not personally liable for the company's financial issues beyond their initial investment.	"['Possible Business Structures for a Slaughter/Processing Facility\nExcerpted with permission from Curtis, K. R.*, M. Cowee, A. Acosta, W. Hu, S. Lewis, T. Harris. 2007. Locally Produced Livestock Processing and Marketing Feasibility Assessment. Technical Report UCED 2006/07-13: University Center for Economic Development, Department of Resource Economics, University of Nevada, Reno.\nA cooperative is a business entity that is member-owned, meaning the business is controlled and owned by the same people who utilize its services. The owners of the cooperative finance and operate the business, striving for a mutual benefit by working together. By combining resources, the overall production costs are decreased, and the production capabilities and marketing successes are increased. Cooperatives are run similar to other business entities and usually incorporate under state laws. They require bylaws and a board of directors, who set policy and hire managers to run the day-to-day operations. In addition to the user-owned aspect, two other characteristics make a cooperative different from other business organizations: they are user-controlled, and user-benefited (Rapp and Ely, 1996).\nThe user-controlled characteristic refers to the election of a board of directors and the ability of common stock holders and/or cooperative members to vote on major organizational issues. User-benefited characteristics include the distribution of resources based on the member’s use of the organization. Cooperatives provide a direct cost savings through the purchase of bulk supplies, increases in market access, a distribution of overhead and fixed costs as well as the allocation of profits based on usage to the members. Cooperative members may finance the start-up and operation costs of the organization through a variety of methods. One option is for members to make a direct financial contribution through a membership fee, or through the sale of common or preferred stock. Another finance method is for the cooperative to withhold a portion of the net earnings from cooperative members for reinvestment back into the organization. Finally, assessment fees can be charged based on the number of units procured from each member, or based on the number of units sold after processing. The advantage of soliciting a direct contribution or utilizing the sale of stock is the upfront cash requirements to purchase capital equipment and building services. Assessment fees and/or net earning withholdings are more beneficial once the cooperative has begun operations and require working capital or future replacement cash.\nIt is vital to the success of a cooperative that owners stay informed of the business practices. A cooperative is a democratically controlled organization that operates through a majority vote. Members have a monetary interest in the financial well-being of the organization and rely heavily on the education and success of the other member producers. While the pooling of resources helps reduce risk in the market place, judgments and decisions made on one farm can affect the profitability of other cooperative members.\nNew Generation Cooperative\nThe “New Generation Cooperative” (NGC) is similar in structure to traditional cooperatives, but the NGC focuses on marketing niche strategies rather than the traditional cooperative roles, such as production and storage. One of the main focuses of the NGC is delivery rights, which are tied directly to the initial investment required from each member. The NGC establishes a production volume, and then sells shares based on a delivery commitment from farmers, which stipulates that enough of the NGC\'s product is produced to fulfill the NGC\'s capacity requirement. One disadvantage of this system is the inability of the cooperative to encompass new producers, as the production capacity is already maximized at inception. However, delivery rights may be sold or traded to other members of the cooperative and future expansion can allow for the sale of additional delivery rights.\nNGCs normally maintain a marketing agreement with the member producers, whereas traditional cooperatives do not. Because NGCs are limited to purchasing products from their members only, they require a much narrower level of quality standards than traditional cooperatives. The process of identity preserved is used to ensure that an acceptable quality product is grown by members, or it can trade lower quality member grain for the higher quality grain needed for processing.\nThe key advantage to NGCs is the fact that the organization can supply a large amount of its own start-up capital. NCGs can typically generate 30%-50% of their start-up capital, lowering long-term private debt commitments and freeing up future profits for larger dividend payments to farmers (Harris, Stefanson, and Fulton, 1996). Additionally, delivery rights ensure a reliable volume of product for the cooperative, while guaranteeing a home for the producer’s product. It also allows the cooperative to better react to market conditions.\nNew generation cooperatives may choose a combination of options, but usually organizations stay within a stock or non-stock form of capital acquisition. Potential members may feel more comfortable with stock options, as it is a more commonly understood system of capitalization.\nCapitalizing refers to the amount of money needed to begin operations and the mechanism for acquiring the cash. Important decisions include whether the cooperative will issue stock or non-stock options (i.e. membership dues), borrow from traditional financial institutions, and determine minimal rates of return for its members. The goal is to provide enough working capital to begin and maintain operations while sustaining manageable debt levels for the organization and making the investment affordable to prospective members.\nOwnership certificates come is a variety of forms, including common stock, preferred stock, membership certificates, and capital certificates. In terms of cooperatives, common stocks are shares of the cooperative representing membership/ownership in the cooperative and are accompanied by voting rights. Common stock can be divided into classes, each carrying different voting privileges and assessed different values. Those with more privileges are more expensive to purchase. Cooperatives usually do not pay interest on common stock issued. Preferred stock is nonvoting stock that can be issued to both members and nonmembers of the cooperative. The proceeds from the purchase of preferred stocks are usually used for capital investment and. As with common stock, preferred stock can be divided into classes, each with a different value receiving different scales of interest payments. Preferred stock owners receive interest for their investment, and are usually given their interest dividends before the distribution of profits to common stock holders. If the organization ceased to exist, preferred stock holders are compensated first.\nIf the members of a cooperative decide that they do not want to offer stock, membership is derived through membership certificates. Voting rights accompany membership certificates, which are issued once membership dues are paid. Usually memberships and capital certificates are insured, but are non-interest bearing.\nCapital certificates are similar to preferred stock, but are not issued as stock. They are sold in a variety of denominations and do not have accompanying voting rights. Interest may or may not be paid to capital certificate holders, but nonmembers may purchase the certificates.\nNGCs require a marketing contract, making all members producers. In an NGC, preferred stock and/or capital certificates are generally not offered. After the cooperative has begun operation, members continue their investment by providing additional risk capital. This can be accomplished in a variety of ways. The cooperative may retain a portion of earnings as an additional investment into the organization. This can be done in two ways: through the payment or retention of a per-unit fee for each member, or through the retention on the overall cooperatives net earnings. Either way, the equity investment is credited to the members’ equity accounts and held as a liability on the cooperatives balance sheet.\nCooperative Legal Considerations\nThe legal considerations cooperatives must consider include the drafting of articles of incorporation, creating bylaws, membership applications, creating and maintaining marketing and purchase agreements, and revolving fund certificates. While the Capper-Volstead Act of 1922 and the Farm Credit Act of 1971 have aided cooperatives in their ability to work together in the handling, processing and marketing of their goods, and allows them to borrow jointly, cooperatives are still subject to numerous antitrust laws and are responsible for all tax codes relating to their enterprise.\nArticles of incorporation give the cooperative a distinct legal standing. It limits personal liability for debt incurred by the cooperative, excluding the amount of their initial investment. The articles of incorporation also describe the nature of the business entity, its location, the proposed duration of the association, and the names of the principle parties involved. Once drafted, the articles are filed with the Secretary of State, activating the cooperative.\nBylaws define how the cooperative will conduct business. The bylaws describe membership requirements and list the rights and responsibilities of the cooperative\'s members. They also discuss voting procedures and the board structure that will govern the cooperative.\nMembership applications are composed of five main parts: the applicant’s statement addressing membership; the signature of the applicant; a statement of cooperative acceptance; signatures of the board president and secretary; and a statement of the duties and intent of the prospective member. A membership certificate may be issued to each member as evidence of entitlements to the organization.\nMarketing and purchasing agreements set the standard of quality acceptable to the cooperative. They also state how the proceeds of the cooperative will be distributed, once deductions for operating and capital expenditures have been taken. Often marketing and purchasing agreements are required when seeking outside financial backing.\nThe revolving funds certificate is a written receipt for capital investments and retained earnings that will eventually be revolved or redeemed. These investments may be deductions based on a per-unit of production, reinvested earnings, or original capital subscription, if not issued in stock form. All legal documents should be written with the help of a lawyer to ensure state provisions are addressed. Appendix A contains the name and contact information for several agricultural lawyers located in Nevada.\nInvesting risk capital is the responsibility of all members. The amount of risk capital invested is an important decision for the cooperative\'s members to consider. It must cover a large portion of the start-up and operational costs, so that outside investors feel comfortable that the membership will work to make the operation successful. Members must also invest enough capital to give them a financial stake in the success of the enterprise.\nMost private loan institutions will require the cooperative members to assume at least 50% of the capital risk, but it may take many years for the members to acquire this percentage. Long-term credit is available through federal and state sponsored credit programs. Sources of facility loans include: USDA Rural Development; Cobank; St. Paul Bank for Cooperatives; and National Cooperative Bank. Many commercial banks and credit unions have local programs for small business start-up, such as Bank of the West. Cooperatives can apply for short-term loans to cover operating costs during the first year of operation. These are acquired through the Farm Credit System and the National Cooperative Bank (Rapp and Ely, 1996).\nThe C corporation is the traditional form of corporation, which is a business entity that provides limited liability to its owners and shareholders, meaning the personal assets of the owners and shareholders are protected from the financial issues of the corporation (Legalzoom.com, 2006). Unlike a sole proprietorship or partnership, a corporation exists as a separate legal entity, and therefore is taxed separately from its directors and shareholders. When a C corporation goes public, it may have an unlimited number of shareholders (who are the legal owners of the corporation), who do not have to be residents or citizens of the United States.\nThe C corporation is managed by a board of directors elected by the corporation\'s shareholders and makes policy decisions on the corporation\'s behalf, while the officers and employees of the corporation conduct the business dealings of the entity. As mentioned, the directors, employees, and shareholders of the corporation are not personally liable for the corporation\'s debts. However, it is the responsibility of the directors and officers to ensure that certain formalities are observed on the corporation\'s behalf. This includes formalities such as annual meetings, appointment of officers and election of directors, and issuance of stock. Perhaps the largest responsibility of the corporation is to maintain enough capital to protect the corporation from any business debts. In the event that these formalities are not observed, shareholders may be held personally liable for corporate debts.\nS corporations are C corporations that have elected to file for S corporation tax status. Filing as an S corporation combines the limited liability of the C corporation with the tax status of the sole proprietorship or partnership. The main difference between C corporations and S corporations (and also the major advantage to S corporations) is the tax treatment. While C corporations are subject to double taxation, S corporations are granted ""pass through"" taxation because all of the corporation\'s profits are passed on to the shareholders in the form of dividends, so there is no taxation at the corporate level. Another advantage to the S corporation is that the corporation\'s directors may pass business losses through to their personal income tax return. The biggest disadvantage of the S corporation is the restrictions that are placed on shareholders: an S corporation may not have more than 100 shareholders, who must be citizens or residents of the United States.\nLimited Liability Company\nAs the name implies, a limited liability company (LLC) is a business ownership structure that provides limited liability to its owners, called members. The main differences between the LLC and the corporate structure are that the LLC is more flexible and less formal than the corporation, and the two entities are subject to different tax laws. An LLC can also serve as the general partner in a limited partnership, giving the individual owners protection from liability, financial or otherwise.\nSome of the advantages of the LLC are the operating flexibility they provide, including the fact that a board of directors is not required as with corporations, and there is currently no requirement in Nevada for an annual meeting of the shareholders. As with S corporations, LLCs are also free from double taxation because the LLC members report their share of profits or losses on their personal income taxes. The LLC is not taxed at the business entity level. The final advantage to the LLC is the limited liability the entity provides to its members. Disadvantages of the LLC are that they do not require an operating agreement, the lack of which may lead to management issues, and the fact that while the LLC isn\'t subject to double taxation, it may be taxed at a higher rate than a corporation.\n- Legalzoom.com, (2006). “Incorporations Library 2006.” Online. Available at http:www.legalzoom.com/law_library/corporations/forming.html. Retrieved December 2006.\n- Rapp, G. and G. Ely, (1996). “How to Start a Cooperative.” Report number 7, USDA Rural Business Cooperative Service, September 1996.', ""If you are looking to start a new business, it is important to understand the two most common legal entities that can be formed for doing business in the United States - C corps and LLCs.\nThe C corp and LLC are both business structures that help a company to lower its tax liability.\nHowever, they differ in the way that they operate. C corps are taxed differently than LLCs - C corps pay taxes on their net earnings while LLCs do not.\nAn LLC has greater flexibility in ownership structure, but C corps has more protective provisions for investors if there is any mismanagement of funds.\nThe choice between these two structures often depends on what type of business you want to run or your goals as an entrepreneur.\nWhat is a C Corporation?\nA C corporation represents a business entity formed by filing all the required paperwork with your state.\nThe business can be owned by corporation shareholders, which are people who have bought shares in the business.\nA shareholder's liability for business debts and other financial obligations ends when they sell their stock or lose their position as a company officer.\nThis business entity is taxed on business profits, which are then distributed to shareholders as dividends.\nThese earnings are subject to double taxation because the corporation itself must pay taxes before distributing dividends.\nCorporations work by creating a management structure that includes officers and directors, who are usually business employees.\nIf the corporate structure fails, shareholders are protected from liabilities because they do not have management positions in the corporation.\nThis business type is appropriate for companies with many investors seeking high control over company activities and management.\nThe Benefits of C Corp\nThe benefits of C corporations include:\n- Company profits are taxed only once at the corporate level; and,\n- Company shareholders cannot be held personally liable for company debts.\nHowever, corporations pay taxes on their net income after expenses and dividends received from other companies.\nCorporation owners must also abide by laws that apply to all U.S. businesses, including federal tax codes and employment guidelines like social security rules.\nThe corporation is considered a separate legal entity, so employees can form contracts with clients or sign leases without involving the company board of directors or officers in the agreement process.\nThis business type is appropriate if your company needs these benefits:\nC Corp pays its own taxes distributing dividends to you, making it a good company to use when you need your company's profits for personal or business needs.\nC Corp is best if you are trying to raise money from investors because they see it as a more professional business structure than an LLC.\nWhat Is a Limited Liability Company?\nLimited liability companies, or LLCs, are pass-through entities that provide limited liability protection.\nThis means that members of an LLC aren't personally liable for the company's debts and obligations.\nSo if you were sued because your business failed to pay back a loan from a bank, creditors couldn't come after your personal assets such as a house or car.\nLLC members are individuals or corporations that own an interest in the business and share profits. Their personal assets are protected, just like with a corporation.\nHowever, pass-through taxation for LLCs is less complicated than the corporate tax structure because it's reported on owners' personal income taxes—just as if they had earned that money personally.\nLLC owners are not taxed for profits made by the LLC. Pass-through taxation means you don't need to pay additional taxes on your business income; instead, it's reported alongside your personal tax return and incorporated into what you owe (or receive as a refund) at year-end.\nAny unincorporated business, such as sole proprietorship and partnership owned by one or more individuals who report their share of the taxable profit or loss in their individual tax returns, passes their financial burden onto owners just like shareholders do with C corporations.\nThe Benefits of LLC\nThe benefits of LLCs are numerous. First, LLCs can be much more flexible regarding personal liability for business debts and liabilities, including taxes.\nSecond, the owners or members of a multi-member LLC are not personally liable to creditors who have an unsatisfied claim against these businesses if they were unsuccessful in filing personal bankruptcy against their own assets as well.\nBecause each member has only entered into a limited personal liability with their co-owners by contract during formation, you aren't responsible for what your partner does after that point (until you agree to take on additional personal responsibility such as signing contracts).\nSince its inception, this type of legal structure has often been used by small business owners and real estate investors looking to protect themselves from their rental properties and personal property lawsuits.\nPaying Taxes: LLC vs. C Corp\nAn LLC is taxed differently from a corporation. Instead of filing taxes at both state and federal levels as corporations do, it files only one tax return each year at its own specific income bracket based on how much money was made during the said period taxable year.\nLLCs don't pay taxes on their earnings; instead, they pass income or losses through to individual members who report them on their personal tax returns.\nAn LLC is a disregarded entity, which means that it has no separate corporate existence from its members.\nAn LLC may elect to be taxed as a corporation, meaning the income is taxed twice at the corporate level and again when shareholders receive dividends (or upon sale of their stock).\nC corporations are responsible for filing their own tax returns with state and federal agencies; they also file an informational return under subchapter S if they meet certain criteria.\nWhile some states have corporate taxes on sales or incomes, most do not require them unless they have offices within those respective jurisdictions.\nC corps must pay corporate income tax before passing earnings through to individuals who then report taxable amounts on personal returns.\nEach member's proportionate share of profit distributions determines whether any resulting tax liability falls on the corporate entity or its members.\nMembers of an LLC pay taxes through their individual returns concerning allocations from their company's profit and losses - not just for wages they receive as compensation for services performed.\nBecause double taxation is generally avoided through this process, partnership taxation rules can be applied by default unless otherwise modified by an operating agreement between partners (except in cases where corporate characteristics exist).\nThis type of business structure provides pass-through liability protection that shields member personal assets from possible debtors who might try to target any assets.\nThe members of pass-through LLCs do not pay self-employment taxes. Instead, they make estimated tax payments and file an informational return each year to report income and expenses.\nC corps don't pay self-employment taxes. As a C corporation, you will be taxed on the business's profits and any salary you pay yourself. You do not pay self-employment tax as an employee, but the company pays the employer's share of those taxes.\nWhat Is the Difference Between C Corp and S Corp?\nThe difference between a C corporation and an S corporation is in how the business is taxed. For both, federal taxes are separate from personal income taxes for shareholders and employees of the company.\nThe key difference has to do with which type of taxation applies when there is a transfer of shares or distributions made by the corporation to its shareholder(s).\nThe C Corp:\nWhen it comes time for your business to distribute profits (dividends) after you've met all expenses, paid yourself salary/wages, covered other corporate costs like insurance premiums, etc., you will be required to pay corporate tax on any money remaining before paying dividends.\nAfter deductions and exemptions, this could mean double taxation - once at the corporate level and again at an individual level.\nThe S Corp:\nAn S corporation pays taxes at the shareholder level. When your business pays you a salary for services performed, it is taxed at normal rates - the same as an individual in this case since S corporations are pass-through entities (unlike C corps).\nMany small business owners choose to form their LLCs as S corporations because of the tax benefits.\nStill, there are also distinct differences in how state laws treat each with regard to taxes, liabilities, management structure, and personal asset protection from creditors.\nAn LLC taxed as an S corporation will have more tax benefits and possibly taxable income deductions.\nIn contrast, an LLC taxed as a C corporation will have greater legal and financial protections (lower tax rates, less corporate paperwork, more equity financing options, no ownership restrictions, etc.).\nDo C Corporations Pay More Taxes Than LLC?\nA C corporation is taxed separately from its shareholders. They pay both federal income tax and then pay personal income tax on shareholders' personal returns.\nAn LLC is a pass-through entity which means it's taxed similar to sole proprietorships, and so a business owner only pays his/her own income taxes.\nDoes an LLC Pay Corporate Tax?\nNo. LLCs don't pay corporate taxes unless they choose to be taxed as a C or S corp\nDo Corps Need Separate Bank Accounts?\nYes. Regardless of whether you chose a C or S corp, you will need a separate bank account to shield personal assets from the corporation's assets.\nCan a Single-Member LLC Be a C Corp?\nYes. Single-member and multi-member LLCs can be a C corp if they opt for corporate taxation.\nLLC vs. C Corp: The Final Verdict\nThe most important factor in deciding whether to form an LLC or a corporation depends on your business goals and plans.\nIf you want pass-through taxation without added paperwork, consider forming an LLC instead of a regular partnership or sole proprietorship.\nIn addition, limited liability protection makes an LLC particularly attractive when other members don't actively participate in day-to-day management decisions but share profits from the company's success.\nSuppose your business does not meet the requirements for an LLC. In that case, a corporation is usually the best option to protect personal assets from company liabilities and access more funding possibilities than with other legal structures.""]"	['<urn:uuid:57ed47df-3841-45bf-9d6c-47a92ada4942>', '<urn:uuid:244f5f36-4b24-42a0-b92d-050d356447a6>']	factoid	with-premise	verbose-and-natural	similar-to-document	multi-aspect	novice	2025-05-01T23:55:16.606337	32	75	4157
499	human role ai military decision making systems	Humans remain central to military AI systems in multiple ways. They are responsible for feeding information to the machines and adjusting for context, such as providing different reports based on geographical location. Military customers are involved from day one in defining key terms like 'causality' and 'impact' that form the framework for machine processing. While AI can assist by analyzing data and presenting options quickly, Army developers emphasize that humans need to remain the ultimate decision-makers in command and control. The technology aims to work around human biases while still preserving human judgment in the final decision-making process.	"['On 6 December, Raytheon announced that, under an award from the Defence Advanced Research Projects Agency’s Causal Exploration of Complex Operational Environments programme, it would explore artificial intelligence and machine learning techniques to develop tools that may enable military planners to understand how cultural and other factors combine to cause conflicts.\n“Machine learning works by giving the computer information that has been characterised beforehand,” says David Lintz, Vice President Raytheon BBN Technologies. “Based on that characterisation, one can then ask the computer to characterise different situations, scoring it each time based on whether its answer was right or wrong, so that the machine progressively learns how to make that characterisation itself with different data sets.”\nIn this case, Raytheon is working to develop a technology that would help military planners, operating in post-conflict environments, characterising situations so as to minimise the risks of a relapse into conflict when choosing between different courses of action.\nTo do this, the first step is to define the key terms around which the machine will be making its statistical analysis. “The military customer is involved from day one in this process,” continues Lintz. “We sit with them during their planning sessions and listen to the way they use terms such as ‘causality’, ‘impact’ or ‘precondition’ in their discussions; once we get a sense of what these terms mean for the customer, we work with them on definitions of ‘causality’, ‘impact’ or ‘precondition’ that will serve as the framework through which the machine will process the information to suggest different outcomes.”\nThe second step is feeding the machine the datasets it needs to recognise causal links and provide different possible outcomes to a course of action in a given context. This involves taking texts, or audio files that can be converted into texts, from open sources and classified intelligence analysts’ articles and reports, and inputting the relevant data in the machine. Lintz adds: “Of course, the quality of your model is no better than the quality of the sources, so the idea is to put in a wide range of sources to make sure the machine has a spectrum of different perspectives it can use to work out the outcome of a given situation.”\nAs such, Lintz confirms that humans remain central to the decision-making process, primarily because they are the ones feeding information to the machine and adjusting it to the context. For example, military planners will feed different reports to the machine depending on whether a mission will take place in Iraq or in Cambodia; this will ensure that the cultural context is also always taken into consideration. Just as importantly, Lintz adds: “The model does not make a decision, it only gives planners the likelihood of different outcomes according to the courses of action they are considering. The political problems inherent to decision-making in these contexts, however, remain because even if you know the right decision you might still be constrained by political reasons.”\nThe advantage of this technology is not to remove the human from the decision-making process, but rather to provide it with a tool that works around the biases inherent to human decision-making processes. “As a species we are just not really well designed for taking in additional information and adjusting our view of the probability of something happening,” says Lintz. “The advantage of having a programme is that the computer uses arithmetic to work out how a situation will evolve, where analysts would have read the same datasets magnifying the information they find relevant; the computer removes that bias.”', 'Army Futures Commander Sees AI-Driven, ""Hyperactive Battlefield"" in Future War\nVIDEO ABOVE: New Shaped Trajectory Excalibur Round Changes Course in Flight, Destroys Tanks Hiding Under Bridges\nBy Kris Osborn - Warrior Maven\n(Washington, D.C.) Future warfare will be characterized by what the Commander of Army Futures Command calls a “hyperactive battlefield” -- a chaotic, fast-moving mix of complex variables in need of instant analysis as lives….and combat victory...hang in a delicate, hazy balance of uncertainty.\nQuite simply put - outcomes in future wars will likely be determined by the “speed” of decision making. This phenomenon, referred to by Gen. John Murray, Army Futures Command, in an interview with Warrior, underscores some of the reasons why weapons developers are weaving Artificial Intelligence applications into nearly all major future systems.\n""The ability to see understand, decide and act faster than an adversary in what is going to be a very hyperactive battlefield in the future I think would be number one when it comes to the fast application of AI,"" Murray said.\nWhile Murray was clear to point out that there are some limitations and needed guidelines associated with AI-focused technologies, he did explain that fast-evolving uses of AI-empowered weapons systems can enable Army Commanders to…”see first, decide first, act first,” of course therefore destroying enemies faster. Essentially, AI-processed data can exponentially increase the speed at which humans can make decisions.\n“There was a guy named John Boyd in the Air Force who came up with this concept called the OODA Loop, which means Observe Orient Detect and Act... if you can observe and get inside the OODA Loop of your adversary that means you can get to understanding and action faster. I actually think that is a great way to look at what I believe is the most logical and valuable use of AI for military applications,” Murray said.\nA quick look across the Army’s portfolio of current high-priority modernization programs immediately reveals that, essentially, “all” of them are being developed with a mind to how AI will improve and impact performance; Army development of future combat vehicles, aircraft, long-range fires, infantry combat and of course warfare networks are all now being integrated with AI-related technologies. (To Read Warrior\'s Essay on Army Research Lab Efforts to Develop AI for Future Tanks..CLICK HERE)\nInterestingly, if even in a somewhat paradoxical way, the prominent emergence of AI has in some ways underscored the uniquely dynamic and indispensable qualities of human cognition. While AI can process information and perform an increasing range of functions by analyzing and organizing data, Army technology developers consistently emphasize that humans need to remain the ultimate decision-makers when it comes to command and control. Therefore, the current Army developers explain that AI can assist, or inform human decision makers by analyzing data, presenting options quickly and performing otherwise overly complex, time consuming or impossible tasks...in seconds. AI, the Army thinking goes, will “assist,” but not replace, human cognition and its many decision-making faculties.\nAI & The Counter-Drone War\nThere are simply too many examples of AI-weapons integration to cite… yet one interesting example of what Murray referred to as “see first, decide first, act first”... can be found in the Army’s current high-tech war on enemy drones.\nThe Army and Raytheon are now accelerating development and deployment of an upgraded counter-drone weapons system designed specifically to address close-in small drone threats. The integrated counter-drone system uses a Ku band mobile, 360-degree ground radar called KuRFS -- in conjunction with a suite of specific countermeasures, called effectors. KuRFS can provide threat information for ground commanders who can then opt to use laser countermeasures, EW, High-Powered Microwave weapons or a kinetic energy interceptor missile-drone called Coyote Block 2. However, before any threat can be destroyed, it must first be identified or “seen.”\nKuRFS began as an Urgent Operational Need request from the Pentagon to address an immediate and pressing need to counter enemy drones, rockets, mortars and other airborne threats -- including lower flying helicopters, Raytheon developers said.\n“A complete c-UAS (Counter UAS) solution needs to be able to automatically detect the intrusion of potentially multiple UASs, identify their type and possible payload, and track their movement consistently inside the monitored area. We have a holistic end to end kill chain which includes early warning,” James McGovern, Vice President, Business Development, Mission Systems & Sensors, Raytheon Integrated Defense, told Warrior.\nWhile preparing to upgrade the counter-drone system with the Coyote Block 2, Raytheon and the Army are emphasizing new innovations, such as the application of AI and Machine Learning. The Coyote Block 2 system is already integrated into an elaborate command and control system tasked with organizing and transmitting time sensitive threat data for human decision makers under attack. Raytheon developers tell Warrior the firm is looking at some of the next steps with “data fusion,” involving the use of AI to analyze fast arriving data from otherwise disparate sensor systems to optimize the delivery of crucial decision-informing combat data.\nMcGovern described Block 2 as a “larger, optimized warhead with improved tracking detection, engine performance and warhead effectiveness.” Equipped with an advanced seeker and small warhead, Coyotes can launch from a range of locations, including fixed locations and armored vehicles on-the-move\nBy comparing approaching threat information against a vast database of compiled information, AI-enabled algorithms can perform the real time analytics necessary to determine and present course of action options to a human decision - maker -- in a nearly instantaneous fashion.\nFor instance, AI and Machine Learning programs can analyze arriving threats against previous occasions wherein drones were used to attack in a variety of ways, factoring a wide array of variables such as previous speeds of approach, swarm techniques, weapons used and navigational factors such as weather obscurants or terrain details.\nTherefore, by receiving and quickly analyzing electronic return signals or “pings” from a KuRFS radar, AI-empowered command and control applications could instantly present commanders with optimal response options such as which effector, or “kill method” would be best. Perhaps weather complications would make a laser interceptor less effective? Perhaps an attack over an urban area would prevent an option to use “kinetic” or explosive defenses -- given how fragments or debris could present risks to nearby civilians? Perhaps the use of EW weapons or High-Powered microwave might be the optimal method to jam or disable approaching drone swarms, or interfere with the seeker or guidance system used by attacking aircraft? Lastly, so-called kinetic options, such as a Coyote Block 2 interceptor weapon, could directly intercept and explode an approaching drone or use a proximity fuse for an “area” explosive effect to knock out small groups of drones.\nAll of these potential scenarios require the merging, analysis and organization of threat-specific sensor data - precisely presenting the kinds of predicaments AI applications could perform for humans -- at lightning speed. Ideally, Machine Learning technologies could receive and integrate previously unseen threat specifics of great relevance, merging them with existing data, performing near real-time analytics and rendering organized options for human commanders.\nThis progress, already well underway by Army and Raytheon developers, is well articulated in an essay called “Deep Learning on Multi Sensor Data for Counter UAV Applications—A Systematic Review,” published by the U.S. National Library of Medicine, National Institutes of Health. -- essay CLICK HERE\nNetworked AI systems can, as described by the essay, be “utilized to process a large variety of data originating from many different sources. They are utilized to process a large variety of data originating from many different sources because of their ability to discover high-level and abstract features that typical feature extraction methods cannot…. The utilization of deep learning methods in data fusion aspects can be of significant importance in addressing the critical issue of multi-sensory data aggregation.”\nIntegrating accumulated sensor data can, according to the essay, pinpoint optimal sensor applications specific threat scenarios. Precision renderings generated by KuRFS could quickly be fortified by Electro-Optical/Infrared sensors, laser ISR, acoustic applications or radio (RF) signals. Furthermore, attributes of one sensor can compensate for limitations of another, creating what Raytheon developers describe as a “common operating” picture.\nFor instance, electro-optical cameras could bring additional detail to some of the electronic returns provided by KuRFS’ use of Doppler radar technology, an application which captures and analyzes speed, movement and other target-relevant details.\n“The intrinsic movements of the targets could describe the rotation of rotor blades of a rotary wing UAV or of a helicopter, the propulsion turbine of a jet, the flapping of the wings of a bird, and can be statistically described by the radar m-D (Micro-Doppler) signature,” the NIH essay states.\nThe essay further elaborates by stating that, for instance, radar might bring excellent precision detection; visual cameras could further distinguish target information and thermal sensors could, for example, detect the “heat signature” coming from an enemy drone’s engine.\n-- To Read Part 1 of Warrior\'s Intv with Gen. John Murray - on the Army\'s War on COVID - CLICK HERE\nPart II - Gen. Murray on Major Army Weapons Programs - Coming soon\nOsborn previously served at the Pentagon as a Highly Qualified Expert with the Office of the Assistant Secretary of the Army - Acquisition, Logistics& Technology. Osborn has also worked as an anchor and on-air military specialist at national TV networks. He has appeared as a guest military expert on Fox News, MSNBC, The Military Channel and The History Channel. He also has a Masters Degree in Comparative Literature from Columbia University.']"	['<urn:uuid:4f8888ca-af61-4a39-9d67-8b17490f84a6>', '<urn:uuid:736c226a-ec25-40e7-b6b2-7b0d9730ad40>']	open-ended	with-premise	short-search-query	similar-to-document	three-doc	expert	2025-05-01T23:55:16.606337	7	98	2172
