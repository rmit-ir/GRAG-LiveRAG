qid	question	answer	context	document_ids	question_factuality	question_premise	question_phrasing	question_linguistic_variation	question_multi-doc	user_expertise-categorization	generation_timestamp	question_length	answer_length	context_length
1	exocrine pancreatic insufficiency symptoms causes patient numbers usa	Exocrine pancreatic insufficiency (EPI) is a condition where patients cannot digest food properly due to pancreatic enzyme deficiency, causing symptoms like greasy diarrhea, fecal urge, and weight loss. In the United States, it affects over 30,000 patients with cystic fibrosis and approximately 90,000 patients with chronic pancreatitis. Without proper enzyme function, patients can develop maldigestion, leading to chronic nutritional deficiency and problems with fat absorption.	"['Get inside Wall Street with StreetInsider Premium. Claim your 1-week free trial here.\nAzurRx BioPharma, Inc. (NASDAQ: AZRX), a company specializing in the development of targeted non-systemic, recombinant therapies for gastrointestinal (GI) diseases, today announced the completion of patient enrollment in the first cohort of the Phase 2b OPTION 2 extension study evaluating immediate-release capsules of MS1819 for the treatment of exocrine pancreatic insufficiency (EPI) in patients with cystic fibrosis (CF).\nThe Phase 2b OPTION 2 trial extension arm is currently dosing patients at clinical trial sites in the U.S. and Europe who have participated in the previous arms of the OPTION 2 trial. The goal of the MS1819 clinical program is to provide cystic fibrosis patients with a safe and effective therapy to control EPI, a debilitating gastrointestinal condition common to patients with cystic fibrosis that can lead to a chronic nutritional deficiency. For cystic fibrosis patients, maintaining proper nutritional levels is essential to ensure healthy growth, weight management and good lung function.\nJames Sapirstein, President and Chief Executive Officer of AzurRx BioPharma, stated, “The extension arm of the Phase 2b OPTION 2 trial is providing us with an opportunity to determine both the optimized dosage and delivery mechanism of MS1819. We have fully enrolled the most important cohort of the extension study and would like to thank both our clinical collaborators and patients for their continued participation in the study. We continue to be encouraged by the absence of any reports of serious adverse events to date, and eagerly look forward to reporting topline results from this trial in Q1 2021.”\nOPTION 2 Extension StudyThe Phase 2b OPTION 2 study is an open-label, multi-center, crossover clinical trial designed to investigate the safety, tolerability, and efficacy of MS1819 in a head-to-head comparison against the current standard of care for EPI, porcine pancreatic enzyme replacement therapy (PERT). The primary efficacy endpoint is the coefficient of fat absorption (CFA). AzurRx BioPharma initiated the additional study arm, the Phase 2b OPTION 2 extension trial, to identify both the optimal dose and the optimal delivery method for MS1819 using immediate-release capsules at higher dose levels than previous early-stage clinical trials.\nTo date, there have been no serious adverse events reported during either the Phase 2b OPTION 2 trial or its extension arm. The Phase 2b OPTION 2 extension trial is enrolling volunteers 18 years or older at trial sites in the U.S. and Poland who have completed the OPTION 2 crossover trial at higher dose levels relative to the previous OPTION 1 trial. Trial participants will be treated with MS1819 over a two-week-period. AzurRx BioPharma expects to report topline data by the end of first quarter 2021.\nAbout MS1819MS1819 is a recombinant lipase enzyme for the treatment of exocrine pancreatic insufficiency associated with cystic fibrosis and chronic pancreatitis. MS1819, supplied as an oral, non-systemic biologic capsule, is derived from the Yarrowia lipolytica yeast lipase and breaks up fat molecules in the digestive tract of EPI patients so that they can be absorbed as nutrients. Unlike the standard of care, porcine pancreatic enzyme replacement therapy (PERT), the MS1819 synthetic lipase does not contain any animal products. The global market for PERT was estimated to be approximately $1.4 billion in the U.S. and more than $2 billion globally in 2019. There currently is no non-animal-based enzyme replacement therapy in the market for the treatment of exocrine pancreatic insufficiency. AzurRx believes that MS1819 has the potential to provide a safe and effective non-animal derived, or synthetic, alternative to PERT, without the risk of animal pathogen transmission or fibrosing colonopathy. In addition, we believe that MS1819 has the potential to improve patient compliance and quality of life given anticipated reductions in pill burden and pill size relative to PERT.\nAbout Exocrine Pancreatic InsufficiencyEPI is a condition characterized by a deficiency of the exocrine pancreatic enzymes, resulting in a patient’s inability to digest food properly, or maldigestion. The deficiency in this enzyme can be responsible for greasy diarrhea, fecal urge, and weight loss.\nThere are more than 30,000 patients in the U.S. with EPI caused by cystic fibrosis according to the Cystic Fibrosis Foundation and approximately 90,000 patients in the U.S with EPI caused by chronic pancreatitis according to the National Pancreas Foundation. Patients are currently treated with porcine pancreatic enzyme replacement pills.', ""The Digestive Process: What Is the Role of Your Pancreas in Digestion?\nYour pancreas plays a big role in digestion. It is located inside your abdomen, just behind your stomach. It's about the size of your hand. During digestion, your pancreas makes pancreatic juices called enzymes. These enzymes break down sugars, fats, and starches. Your pancreas also helps your digestive system by making hormones. These are chemical messengers that travel through your blood. Pancreatic hormones help regulate your blood sugar levels and appetite, stimulate stomach acids, and tell your stomach when to empty.\nYour pancreas creates natural juices called pancreatic enzymes to break down foods. These juices travel through your pancreas via ducts. They empty into the upper part of your small intestine called the duodenum. Each day, your pancreas makes about 8 ounces of digestive juice filled with enzymes. These are the different enzymes:\nLipase. This enzyme works together with bile, which your liver produces, to break down fat in your diet. If you don't have enough lipase, your body will have trouble absorbing fat and the important fat-soluble vitamins (A, D, E, K). Symptoms of poor fat absorption include diarrhea and fatty bowel movements.\nProtease. This enzyme breaks down proteins in your diet. It also helps protect you from germs that may live in your intestines, like certain bacteria and yeast. Undigested proteins can cause allergic reactions in some people.\nAmylase. This enzyme helps break down starches into sugar, which your body can use for energy. If you don’t have enough amylase, you may get diarrhea from undigested carbohydrates.\nMany groups of cells produce hormones inside your pancreas. Unlike enzymes that are released into your digestive system, hormones are released into your blood and carry messages to other parts of your digestive system. Pancreatic hormones include:\nInsulin. This hormone is made in cells of the pancreas known as beta cells. Beta cells make up about 75% of pancreatic hormone cells. Insulin is the hormone that helps your body use sugar for energy. Without enough insulin, your sugar levels rise in your blood and you develop diabetes.\nGlucagon. Alpha cells make up about 20% of the cells in your pancreas that produce hormones. They produce glucagon. If your blood sugar gets too low, glucagon helps raise it by sending a message to your liver to release stored sugar.\nGastrin and amylin. Gastrin is primarily made in the G cells in your stomach, but some is made in the pancrease, too. It stimulates your stomach to make gastric acid. Amylin is made in beta cells and helps control appetite and stomach emptying.\nCommon pancreatic problems and digestion\nDiabetes, pancreatitis, and pancreatic cancer are three common problems that affect the pancreas. Here is how they can affect digestion:\nDiabetes. If your pancreatic beta cells do not produce enough insulin or your body can’t use the insulin your pancreas produces, you can develop diabetes. Diabetes can cause gastroparesis, a reduction in the motor function of the digestive system. Diabetes also affects what happens after digestion. If you don't have enough insulin and you eat a meal high in carbohydrates, your sugar can go up and cause symptoms like hunger and weight loss. Over the long term, it can lead to heart and kidney disease among other problems.\nPancreatitis. Pancreatitis happens when the pancreas becomes inflamed. It is often very painful. In pancreatitis, the digestive enzymes your pancreas make attack your pancreas and cause severe abdominal pain. The main cause of acute pancreatitis is gall stones blocking the common bile duct. Too much alcohol can cause pancreatitis that does not clear up. This is known as chronic pancreatitis. Pancreatitis affects digestion because enzymes are not available. This leads to diarrhea, weight loss, and malnutrition. About 90% of the pancreas must stop working to cause these symptoms.\nPancreatic cancer. About 95% of pancreatic cancers begin in the cells that make enzymes for digestion. Not having enough pancreatic enzymes for normal digestion is very common in pancreatic cancer. Symptoms can include weight loss, loss of appetite, indigestion, and fatty stools.\nYour pancreas is important for digesting food and managing your use of sugar for energy after digestion. If you have any symptoms of pancreatic digestion problems, like loss of appetite, abdominal pain, fatty stools, or weight loss, call your healthcare provider.\nMarch 22, 2017\nUp To Date. Gastroparesis; Etiology, clinical manifestations, and diagnosis, UpToDate. Chronic Pancreatitis (Beyond the Basics), UpToDate. Physiology of Gastrin\nLehrer, Jenifer, MD,Taylor, Wanda, RN, Ph.D.""]"	['<urn:uuid:3b710308-c2a0-45cc-a851-d7cf8689c7c4>', '<urn:uuid:9848238d-ca6c-4a85-8a99-55ac51736f1c>']	factoid	with-premise	long-search-query	similar-to-document	three-doc	novice	2025-05-01T22:47:46.423955	8	65	1459
5	As a culinary historian exploring ancient pasta-making traditions, I'd like to know how did early Chinese, Middle Eastern, and Italian cultures differ in their approach to preparing and drying noodles before modern times?	The early cultures had distinct approaches to pasta preparation. Chinese noodles, which existed before 200 BCE, were made from mung beans and were typically soaked before being boiled or fried. In fact, frying or grilling were preferred over boiling, which was considered to produce bland meals. In the Middle East, by the 9th century, they made itriya - a dough shaped into strings and dried. In Italy, the first industrial pasta production began in Naples in the 15th century, where they utilized natural temperature fluctuations for drying, as mechanical drying wasn't invented until 1800. The Neapolitan process required specific hot and cold temperatures that occurred naturally up to four times per day.	['Pasta is a universally enjoyed food, and almost every country serves a type of noodle. In China, it is mein; Japan, udon; Poland, pierogi; Germany, spaetzle. The popularity of pasta can be attributed to several factors: it is easily manufactured, it takes up little storage space, it is easy to cook, and it is rich in complex carbohydrates.\nAncient Etruscan meals of gruel and porridge were eventually replaced with more appetizing unleavened bread cakes. Food historians believe these cakes may have been the precursor to pasta. Opinions about where the noodle originated vary. The Italian explorer Marco Polo has been commonly credited with bringing the noodle back to Italy from his travels in the Orient during the 1300s. However, some contend that a close examination of Polo’s papers reveals that he reported enjoying a certain type of noodle in China, comparing it favorably to the pasta he was accustomed to eating in Italy.\nNevertheless, it is true that Chinese noodles have been around for centuries. The vermicelli-like transparent noodles are made from the paste of germinated mung beans and are usually soaked in water before they are boiled or fried. (Pasta has not always been prepared by boiling. In fact, boiled noodles were once considered a relatively bland meal. Frying or grilling were the preferred preparations.) Koreans claim to have taught the Japanese how to make soba noodles in the 12th century, using Chinese buckwheat grown in the northern regions where rice paddies could not survive.\nEarly French writers also mention a dish called pastillum, essentially a ravioli-like pouch filled with meat. However, the Italians have staked the claim so vehemently that today we generally think of pasta dishes as Italian in origin. In fact, the word “pasta” comes from the Italian phrase “paste (dough) alimentari (relating to nourishment).”\nThe first industrial production of pasta occurred in Naples in the early 15th century. The site was chosen for its naturally fluctuating temperatures, sometimes as much as four times a day, which provided the hot and cold temperatures necessary for drying. Mechanical drying was not invented until 1800.\nPasta is made from a mixture of water and semolina flour. Semolina is a coarse-ground flour from the heart, or endosperm, of durum wheat, an amber-colored high protein hard wheat that is grown specifically for the manufacture of pasta. With a lower starch content and a higher protein content than all-purpose flours, semolina flour is easily digested. Farina, rougher granulations of other high-quality hard wheat, is also used to make some pastas. The semolina and farina flour are enriched with B-vitamins and iron before they are shipped to pasta plants.\nEggs are sometimes added to the mixture for color or richness. Federal guidelines stipulate that egg noodles contain a minimum of 5.5% egg solids. Vegetable juices, such as spinach, beet, tomato, and carrot, can also be added for color and taste. In recent years, the addition of herbs and spices such as garlic, basil, and thyme has become popular.\nWHAT IS PASTA AND HOW IS MADE\nPasta is one of the basic ingredients of the Mediterranean diet and is a food of ancient origin, which some scholars agree come from the Chinese civilization and introduced in Italy by Marco Polo on his return to Venice.\nPasta is a dry ingredient normally made from flour, semolina, eggs, water, and salt and in some cases dried vegetables are added to give the pasta a particular colour or taste turning them into “Special Pastas”. Pasta in general as an ingredient is considered part of the healthy foods group, this of course does not take into account the pasta sauces of which is normally accompanied which can be calorific and in some cases unhealthy.\nThe most commonly known pasta is the so called “egg pasta”. It takes this name because is made with flour, water, eggs and salt and has a yellowish colour. This pasta is typical from the North of Italy and in the international food scene this recipe for pasta making has become the norm.\nHowever, in the South of Italy pasta is made very differently. In the southern regions of Italy such as Naples, Puglia, Sicily and specially Calabria pasta is made using only semolina flour, water and salt. This combination produces a whiter, lighter and an easier to digest pasta avoiding the heaviness of the egg pasta caused by the combination of 00 flour and eggs. Because southern regions especially Calabria has not had the same international exposure this pasta making recipe has not had the same recognition or acknowledgement than the 00 flour and egg recipe.\nWithin Italy however, southern pasta makers especially those from Calabria have superseded and taken the art of pasta making to another level producing one of the best pastas in Italy now being sought by Northern Italians and slowly being noticed in the international food scene .\nThe key of the Calabrian artisan pasta relies on the quality of the semolina, the antique production techniques and very importantly the drying process which gives the pasta that very high quality texture and flavour only similar to fresh pasta when cooked.\nEvery drying time will depend on the pasta shape; they can go from 10 hours to 48 hours. For this process to be successful and produce the quality that any Italian expects the pasta needs to go through 2 drying stages:\n- The first stage is where the pasta loses 1/3 of its water content. This process creates a thin layer over each shape making the product to have the correct conditions to hold its shape throughout the entire process.\n- The second stage which is the real drying process the pasta in placed in large net trays inside a structure similar to a cupboard with holes on each side. The pasta is then subject to cycles of hot air ventilation and left to rest in a high humidity environment so the water of the most inner layers flows outwards and evaporates. Times and temperatures vary depending on the pasta shape but normally they range between 60° and 70°.\nOf course this product process is only found in real artisan pasta. Industrially made pasta is dried in very hot ovens for a period of less than 12 minutes resulting in a thin and fragile product.\nAnother factor in the quality of the pasta is the material of the molds from which the dough is put through. In order to produce the millions of different pasta shapes we nowadays find special molds had to be created, the best ones are made of bronze. This material creates a rough surface over the dough when passing through it, this “roughness “ is what makes the sauce stick and stay in the pasta. The best past will be made using these molds and the packaging will say “Trafilata al bronzo”.\nSo, the actual production of artisan pasta is a slow process that requires skill, technique and patience but be sure that at the end you will enjoy the best pasta you can get if the process and the skill of the pasta maker are good, resulting in a product of superior quality, flavour, texture and digestibility that sets it apart from industrially made pasta and from the heaviness of egg pasta.\nCalabrian pasta or Southern Italian pasta also fits perfectly in any vegetarian diet or vegan diet and can be part of a healthy cooking style if made with healthy pasta sauces that contain large amounts of vegetables, fat free meat, little oil and the avoidance of those pre made pasta sauces which contain artificial additives and large quantities of salt.\nHISTORY OF PASTA\nAncient Rome was the birthplace of fresh pasta (pasta fresca),which was made by adding water to semolina-flour. This vital ingredient is made from durum wheat, a thriving crop in Italy’s temperate climate. Unlike the dried pasta found at your local grocery store today, fresh pasta was meant to be eaten immediately. The Arab invasions of Sicily in the 8th Century are thought to be the origins of dried pasta (pasta secca). At the time, Palermo was producing mass quantities of the new product. Some Arabian influence can still be found in select recipes, using ingredients such as raisins and cinnamon.\nIn the 1300’s, dried pasta became very popular for use on long nautical expeditions because of its shelf-life and nutrition. These voyages contributed to pasta’s worldwide appeal and led to advances in its form and technology. Back in Italy, pasta was slowly migrating north to Naples and reached its destination in the 17th Century. A few historical events boosted pasta to a national icon. It became a kitchen staple during the Risorgimento (Italian Unification) in the mid 1860’s. Italian political and military figure Giuseppe Garibaldi introduced the country to La Scienza in cucina e l’Arte I Mangiar bene, a cookbook written in 1891 by Pellegrino Artusi that featured pasta. Tomato sauce was introduced to Italy in the 19th Century but was met with skepticism. The tomato, being a member of the nightshade family, was considered inedible in many regions; fortunately, those rumors were put to rest shortly thereafter. The last major event to influence pasta’s early history was the Italian Diaspora, a mass migration of Italians from their country in the time between the Unification and World War I. These times of hardship led Italians to take even more pride in refining the art of cooking.\nTYPES OF PASTA\nThere are two major classifications: pasta fresca (fresh) and pasta secca (dried). From here, there are more than 400 unique types of pasta: sheets, strips, long strands, cylinders, unique shapes, flavors, and many other local varieties. There are more names for pasta than the mind can retain, yet all are made from the same basic ingredients — 100% durum wheat and water with a specific percentage of acidity and humidity under Italian law. Varying from the basics, light flavors and colors can be added to pasta with egg yolk, spinach, tomato paste, chocolate, and even squid ink. Each of these pastas creates its own unique dining experience when properly served. Another crucial aspect of the experience is pasta being married with an appropriate, complimentary sauce. The individual shape and texture given to pasta can be somewhat of a code in determining the proper sauce. A simple rule of thumb would be as follows: thick pasta = thick sauce, light pasta = light sauce.\nPasta fresca, the starting point of all pastas, is created with higher humidity, and some types only exist in this category. Variations can often be regional. Northern Italy is known to use all-purpose flour and eggs, while southern Italy uses the standard semolina and water mixture. Reputed to have the best pasta fresca in Italy, the Emilia-Romagna region often serves fresh pasta with cream sauces. Another regional variation could be found in Piedmont where butter and black truffles are a common ingredient. Other ingredients vary, from potatoes to ricotta.\nSpecial tools are used when making dried pasta. First, the pasta is forced through holes in a die-plate and onto sheets for cutting. The next step is drying. Pasta secca is only considered real pasta if it is made in the proper Italian way, slow-drying it for upwards of fifty hours in a copper mold, and then in the open air. The rest of the world usually dries pasta in steel molds at extremely high temperatures for short periods of time, resulting in an inferior product. Italians take pride in their method and can be proud of a smoother tasting, quicker cooking pasta that can hold on to its sauce.\nNUTRITIONAL VALUE: FAT OR SKINNY?\nPasta’s fortunes have fluctuated over its long history: it has been considered both a luxury food (in the sixteenth century, Neapolitan authorities prohibited its consumption in times of famine or scarcity of wheat) and a vernacular staple. Commonly perceived as a poor man’s food at the beginning of the twentieth century, pasta began, with the support of nutritionists extolling the virtues of the Mediterranean diet in the 1970s, to experience a rehabilitation. New nutrition guidelines (and the food chart reformulated in the 1990s) recommend less protein, less saturated animal fat, more fiber, and more complex carbohydrates. Pasta, therefore, is now recognized to be a healthy food. It is also a highly versatile, immediately satisfying food, recommended for athletes (“carbo-loading” sustains energy before strenuous sports) and even for refined palates.\nVegetables, lean meats, or fish, combined with good quality (even enriched or whole wheat) pasta, makes an excellent, balanced meal. Components of pasta include moisture (water), energy, protein, fat, carbohydrates, and ash. According to the U.S. Department of Agriculture bulletin (1981), nutrient values for one cup of spaghetti (two ounces uncooked) are approximately seven to fourteen grams of protein, thirty-nine grams of carbohydrates, and when enriched, it provides calcium, phosphorus, iron, potassium, thiamin, riboflavin, and niacin. The caloric value of one cup of cooked pasta is approximately 190 calories (if al dente ) and 155 (if tender).\nPasta trends take place within wider social and nutritional contexts. There has been a move toward whole foods and alternative grains such as corn, buckwheat, and spelt. Innovative ingredients—some restaurant-driven—include colored pasta (tomato, herb, beet, mushroom, shrimp, even chocolate) and novelty-stuffed pasta (seafood, artichoke, dried tomato). There has also been a trend toward fusion cuisines, for example, blending East and West. New health guidelines advise lower fat, higher fiber, increased vegetarianism, less processing. The American trend toward greater convenience favors ready-cooked, frozen, microwaveable, and cold-serve pastas, although the Slow Food movement is beginning to counter this trend in the new millennium. Americans are becoming more sophisticated in regard to better quality products, taste, nutritional value, authenticity, seasonality, and the artisan tradition.\nIMMIGRANTS AND PASTA\nNeapolitans and other southern Italians were critical to pasta’s diffusion throughout the world. For it was as much immigration—and the majority of immigrants were, in fact, Neapolitan and southern—as technological advances and transatlantic trade, that brought pasta to the world’s attention. Along with the wave of late-nineteenth-century immigrants came shiploads of spaghetti in blue wrap (for example, Napoli Bella and Vesuvio brands), olive oil, and condensed tomato paste. Americans first considered these inedible foreign foods and tried to reform the newcomers’ diet, but spaghetti won out and eventually became American, not merely ethnic, fare. Italian immigrants were to introduce many other cultures to pasta wherever they settled.\nAlthough Thomas Jefferson, much interested in macaroni and pasta technology, brought cases of the foodstuff to America in 1786 (and later had a pasta machine shipped to him from Campania), it was not until 1848 that it began to be produced commercially in America. The World War I years and the interruption of pasta imports from overseas gave rise to an expanded pasta industry in the United States, as many Italian-American pasta importers became manufacturers, through small family operations, many of which still exist. Prohibition may have given pasta a boost as well, since it seemed a logical accompaniment to speakeasy wine. In the expanding pasta industry of the 1930s, pasta ceased to be merely Italian and became an American food.\nPASTA AS EMBLEM\nEthnic stereotyping frequently makes reference to food. Italians have long been associated with pasta, and Italians from different regions represent themselves by the type of pasta they eat. In England, from approximately 1750 to 1850, a “macaroni” referred to a foppish Englishman, a dandy, who affected foreign (Italian) style by over-dressing, wearing a preposterous wig, and perhaps eating foreign foods (for example, Yankee Doodle Dandy who “stuck a feather in his hat and called it macaroni” and the London gentlemen’s club, The Macaroni Club). On the negative side, a cultured Italian might have referred to a simpleton or country bumpkin as a gnocco, maccarone, or spaghetto. Sicilians—later Neapolitans—were derogatorily labeled mangiamaccheroni (macaroni-eaters) by Italians farther north. Americans have referred to Italians as “Spaghetti Benders.” And Marinetti’s Futurist Manifesto did not help matters when it declared war on traditional foods, especially pasta, a food which, the avant-garde insisted, promoted moral and physical laxity. The ideal, evidently, was the Germanic meat-eater, a virile warrior race. Italians ignored the Futurists’ cultural violence. Instead, Mussolini waged a battle on wheat (battaglia del grano ) in an attempt to make Italy wheat-sufficient. The vastly increased wheat acreage had the effect of shifting the epicenter of production northward (pasta producers included Agnesi in Oneglia, Buitoni in San Sepolcro, Barilla in Parma), thereby ending the dominance of Naples by the 1940s.\nMany legendary Italian pasta-eaters have helped raise the image of this food: Rossini, Caruso, Sophia Loren. Pasta iconography, old and new, traces its presence in cultural history, from early popular prints of Cuccagna or of Neapolitan pasta-eaters, to pasta advertisements, packaging, and film (for example, Charlie Chaplin in City Lights, Disney’s The Lady and the Tramp, and in Italy, Totò, Sophia Loren)—all of which molded pasta’s image for millions.', '“Everything you see, I owe to spaghetti,” Sophia Loren once said. But to what does spaghetti owe?\nThere’s no denying that pasta is decidedly Italian. However, as is common with well-loved world cuisines, the origins of pasta are highly contested and may be found in many intersections of time and place. As Tori Avey writes in The History Kitchen, “The history of pasta is difficult to trace for several reasons. The word itself translates to ‘paste’ in Italian. This is a reference to the dough, made from a combination of flour and water or eggs – all simple components that have been around for centuries. This makes it hard to differentiate pasta from other ancient dishes made from the same ingredients. In addition, since pasta has long been a food of the common people, it has not received as much attention as more extravagant foods.”\nToday, we travel back in time – and around the world – to take a look at the possible origins of pasta.\nThe Marco Polo Legend\nThe most common – and as many historians argue, quite inaccurate – story about pasta is attributed to the legendary traveler Marco Polo. Noodles existed in China and Asia long before pasta appeared in the Mediterranean world, and the legend goes that Marco Polo brought pasta to Italy from China in the 13th century. Apparently, there are passages in The Travels of Marco Polo (by Marco Polo, of course) that refer to “pasta-like dishes.”\nAt the same time, historians note that Marco Polo’s familiarity with the food “pasta” suggests that it was already in existence, and he simply gave it a name. Food historian Harold McGee writes in his book, On Food and Cooking: “It’s a story often told, and often refuted, that the medieval traveler Marco Polo found noodles in China and introduced them to Italy. A recent book by Silvano Serventi and Francoise Sabban has set the record straight in authoritative and fascinating detail. China was indeed the first country to develop the art of noodle making, but there were pastas in the Mediterranean world long before Marco Polo.”\nEarly References to “Pasta”\nWhile it’s highly unlikely that Marco Polo brought pasta to Italy, it is believed that pasta as we know it made its way westward from Asia at an earlier time, perhaps by nomadic Arab traders. According to Culinary Lore, “There are written reports of ‘a food made from flour in the form of strings,’ in Sicily, described by an Arab trader named Idrisi in 1154, well before Marco Polo’s travels. There were even noodles called rishta in the Middle East, a food of Persian origin. Also, at the Spaghetti Museum in Pontedassio, Imperia, there are several documents from 1240, 1279, and 1284 which refer to pasta, maccheroni, and vermicelli as known foods, well before Marco Polo’s return in 1292.”\nFurthermore, it is suggested that rishta became popular in Sicily, due to the high number of Arab traders on the island. It is believed that rishta came to Italy via the Silk Road, the well-worn trading path from Asia to Europe.\nThe Art of Noodles in China\nLong, long before pasta was a twinkle in the eye of Italy, some time before 200 BCE, the northern Chinese were already developing the art of noodle making. References to noodles and dumplings (precursors for ravioli perhaps?) appear throughout historical Chinese texts, such as an ode from 300 CE by Shu Xi (McGee notes that “poets frequently likened their appearance and texture to the qualities of silk”) and in a 544 CE document that outlines a number of flour-products, including wheat noodles.\nThough noodles – mian or mien in Chinese (hence lo mien) – began as a dish reserved for upper classes in northern China, over time they became a popular food among working classes. By the 7th or 8th century, McGee writes that noodles made their way to Japan, where they are called men (hence, ramen).\nPasta in the Middle East & Mediterranean\nIn the 9th century, a Syrian text mentions itriya, dough that is shaped into strings and dried. Could this be a precursor to Sophia Loren’s spaghetti? Later, in 11th century Paris, the term vermicelli (with verm from Latin for worm) was used to describe very thin pastas. In the 13th century, macaroni was first used to describe “various shapes, from flat to lumpy.”\nDuring the medieval period, “cooks made some pastas from fermented doughs; they cooked pasta for an hour or more until it was very moist or soft; they frequently paired it with cheese, and used it to wrap around fillings” (McGee).\nPasta in Italy\nThough pasta’s origins are varied and can be traced to different parts of the world, it is widely agreed that the evolution of pasta into the form we now know and love was perfected in the post-medieval period in Italy. McGee writes, “Pasta makers formed guilds and made fresh types from soft wheat flour throughout Italy, dried types from durum semolina in the south and in Sicily. Italian cooks developed the distinctive preparation called pastaciutta, or ‘dry pasta,’ pasta served as the main component of a dish, moistened with sauce but not drowning in it or dispersed in a soup or stew.”\nBy the 18th century, pasta was widely produced throughout Italy and was a common food amongst all classes of society. In the late 19th century, the term al dente – to the tooth – was first used to describe the perfect texture for pasta.\nHere at Cucina Toscana, we are proud to serve authentic Italian pasta dishes! Visit us for a taste of history.']	['<urn:uuid:239fecec-95de-40d2-b243-4d9ba9bd53c5>', '<urn:uuid:e088f9bd-e08e-4e2e-a9d8-e9d0b4e5c1b6>']	factoid	with-premise	verbose-and-natural	distant-from-document	three-doc	expert	2025-05-01T22:47:46.423955	33	112	3750
7	Where was the Christmas message filmed?	The Christmas broadcast was delivered from the quire of St George's Chapel, which mirrored the late Queen's 1999 festive address. This location was particularly significant as it is close to where the late Queen and King's father are laid to rest in the King George VI Memorial Chapel.	['His Majesty has delivered his inaugural festive message to the nation\nThe King has used his first Christmas broadcast to sympathise with families struggling with the cost-of-living crisis and praise individuals, charities and faith groups supporting those in need.\nCharles spoke about the “great anxiety and hardship” experienced by many trying to “pay their bills and keep their families fed and warm” during his televised message, which featured footage of a food bank and other scenes of meals being distributed to the homeless.\nThe country is grappling with an economic crisis due in part to the war in Ukraine and the monarch also praised volunteers, paying tribute to the “wonderfully kind people” who donated food or their time.\nCharles delivered his historic Christmas broadcast standing in the quire of St George’s Chapel, mirroring the late Queen’s 1999 festive address, and it followed his mother’s well-established template, a personal reflection on the year, touching on current issues and with a Christian framework.\nBut the King also recognised other faiths, highlighting how religious communities were helping those in financial difficulties and, like Christians, believed in the “power of light overcoming darkness”.\nThe central theme was a celebration of “selfless dedication”, a value embodied by Queen Elizabeth and reflected in the actions of many, from the emergency services to public spirited individuals, which helped to build and strengthen communities.\nThe pre-recorded message began with Charles reflecting on how he was standing “so close to where my beloved mother, the late Queen, is laid to rest with my dear father” in the King George VI Memorial Chapel, and he thanked the public for the “love and sympathy” expressed in cards and messages of condolence.\nHe also described how the festive period was a “poignant time” for bereaved families, adding “We feel their absence at every familiar turn of the season and remember them in each cherished tradition”.\nCharles said he shared the late Queen’s “faith in people” who can touch the lives of others with “goodness and compassion”, something he described as the “essence of our community and the very foundation of our society”.\nThese qualities were reflected in the “selfless dedication” of the armed forces, health and social care professionals, teachers and all those who work in public service.\nHis words come as the nation faces a series of strikes by public sector workers, including nurses, ambulance workers and Border Force staff.\nCharles added: “And at this time of great anxiety and hardship, be it for those around the world facing conflict, famine or natural disaster, or for those at home finding ways to pay their bills and keep their families fed and warm, we see it in the humanity of people throughout our nations and the Commonwealth who so readily respond to the plight of others.\n“I particularly want to pay tribute to all those wonderfully kind people who so generously give food or donations, or that most precious commodity of all, their time, to support those around them in greatest need, together with the many charitable organizations which do such extraordinary work in the most difficult circumstances.”\nFootage was shown of the armed forces and emergency services at work, from soldiers carrying sandbags to a speeding ambulance, followed by doctors and nurses on a ward and care workers in a home.\nThe King’s son and daughter-in-law were shown during a visit to St Thomas Church in Swansea in September, and he said: “The Prince and Princess of Wales recently visited Wales, shining a light on practical examples of this community spirit.”\nWilliam and Kate’s trip to Swansea, and earlier that day to Anglesey, was their first visit to Wales since receiving their titles and the prince helped pack a family food parcel for a foodbank based at the St Thomas, while the princess chatted to community nursery nurses who refer mothers to the church’s on-site baby bank.\nOther members of the royal family were shown at official events from the Queen’s 2018 visit to the RAF Club in London to the Queen Consort handing children Paddington bears left in memory of the late monarch.\nThe Earl and Countess of Wessex and Princess Royal were also featured but there were no images of the Duke and Duchess of Sussex, who stepped down as working royals in 2020.\nA few days before the late Queen’s funeral on October 19, Charles told faith leaders gathered at Buckingham Palace, as monarch he had an important role to discharge “…the duty to protect the diversity of our country, including by protecting the space for faith itself and its practise through the religions, cultures, traditions and beliefs to which our hearts and minds direct us as individuals.”\nHe recognised those other faiths when he said in his Christmas message: “Our churches, synagogues, mosques, temples and gurdwaras, have once again united in feeding the hungry, providing love and support throughout the year.\n“Such heartfelt solidarity is the most inspiring expression of loving our neighbour as our self.”\nAmong the collection of video clips showing the King at official events, Charles was seen wearing a Sikh rumal, or handkerchief, on his head as a mark of respect during a visit to the Guru Nanak Gurdwara in Luton earlier this month, and receiving condolences from the public during a walkabout outside Buckingham Palace in September.\nHis own faith was another central theme and he spoke about fulfilling a “life-long wish” to visit Bethlehem in 2020 and stand close to the sacred site in the Church of the Nativity that marks the spot where Christians believe Jesus Christ was born.\nCharles, who in the past has described himself as a “committed Anglican Christian”, said in the address: “It meant more to me than I can possibly express to stand on that spot where, as the Bible tells us, ‘The light that has come into the world’ was born.”\nThe Christmas broadcast, written by the King and lasting eight minutes, ended with a message for the religious and those with no beliefs: “While Christmas is, of course, a Christian celebration, the power of light overcoming darkness is celebrated across the boundaries of faith and belief.\n“So, whatever faith you have, or whether you have none, it is in this life-giving light, and with the true humility that lies in our service to others, that I believe we can find hope for the future.\n“Let us therefore celebrate it together, and cherish it always.”\nPublished: by Radio NewsHub Source : Radio News Hub']	['<urn:uuid:6741234b-7039-4f02-bb87-112b5144b186>']	open-ended	direct	concise-and-natural	distant-from-document	single-doc	novice	2025-05-01T22:47:46.423955	6	48	1080
14	what happens first pregnancy doctor visit	At your first antenatal visit, you will receive information about folic acid and vitamin D supplements, nutrition and diet advice, food hygiene, and lifestyle factors that may affect your health or your baby's health. The healthcare provider will also discuss antenatal screening tests and help plan your next medical visits. They will gather information about your medical history and schedule your next appointment for when you are 10-16 weeks pregnant.	"[""Antenatal Care at Various Clinics\nAntenatal clinic for check-ups & appointments\nBeing pregnant is both exciting and scary at the same time. That’s why when it comes to your antenatal care, St John Medical offers a variety of specialised services by seasoned health professionals, who take both your physical and mental wellbeing into account.\nSt John Medical in Cannington has a GP Obstetrician and an onsite CTG machine – a specialised piece of equipment that can measure your baby's heart rate. To book an appointment with a GP Obstetrician, either book online or call our Cannington clinic on 9350 8000.\nStarting your antenatal care\nYou can book an appointment with your doctor or midwife as soon as you know that you’re pregnant. At your first visit to our antenatal clinic, your health practitioner will advise you on your various antenatal care options, and help you plan your next medical visit.\nYou will be given information about:\n- Folic acid and vitamin D supplements\n- Nutrition, diet and food hygiene\n- Lifestyle factors that may affect your health or the health of your baby, such as smoking, recreational drug use and alcohol consumption\n- Antenatal screening tests\nWhen you find out you are pregnant, it’s best to book an antenatal check-up with an St John Medical doctor or nurse as soon as possible. If you have special health needs, your midwife, doctor or obstetrician may opt for shared responsibility regarding your maternity care, which means they may all decide to meet with you during your pregnancy.\nHospital bookings can be made by your health care professional. GPO at Cannington is accredited for Bentley Health Service. However, if you wish to deliver at Armadale, we can provide antenatal care until 20 weeks and then refer you.\nFor more information download our Pregnancy Care Schedule for a basic guideline of who you will see, when, and what will occur.\nBook an appointment online or call us on 9350 8000.\nWhat happens at your first antenatal visit?\nAt the end of your first visit, we will schedule your next antenatal appointment, which will be when you are 10-16 weeks pregnant. The midwife or doctor will ask questions to gather more information, this is to make sure you’re given the support you need, and allow us to identify any risks early on.\nIt’s important to tell your midwife or doctor if:\n- You’ve had any complications or infections in a previous pregnancy or delivery, such as pre-eclampsia or premature birth.\n- You’re being treated for a chronic disease, such as diabetes or high blood pressure.\n- You or anyone in your family have previously had a baby with an abnormality, such as spina bifida.\n- There’s a family history of an inherited disease, such as sickle cell anemia or cystic fibrosis.\nYou’ll be offered some tests to check for anything that may cause problems during or after your pregnancy. We’ll discuss these tests with you and you can choose whether to have them or not. If you haven’t already had a general health check-up, your midwife or doctor might recommend:\n- A check to make sure your heart, lungs and blood pressure are functioning well.\n- A urine test to make sure your kidneys are healthy, and to check for any signs of infection.\n- A pap smear test.\n- A mammogram.\nFrom around 24 weeks, your antenatal appointments will become more frequent. However, if your pregnancy is uncomplicated and you are in good health, you may not need to be checked as often as someone who needs to be more closely monitored.\nLater visits are usually quite short. Your midwife or doctor will:\n- Check your urine and blood pressure.\n- Feel your abdomen (tummy) to check the baby’s position.\n- Measure your uterus (womb) to check your baby’s growth.\n- Listen to your baby’s heartbeat if you want them to.\nYou can also ask questions or talk about anything that’s worrying you. Talking about your feelings is as important as all the antenatal tests and examinations.\nAntenatal questions you might be asked\nThroughout your antenatal care, the midwife or doctor might ask about:\n- The date of the first day of your last period.\n- Your current state of health and any previous illnesses and operations.\n- Any previous pregnancies and miscarriages.\n- Ethnic origins of you and your partner, to find out whether your baby is at risk of certain inherited conditions, or other relevant factors, such as whether your family has a history of twins.\n- Your job or your partner’s job, and what kind of accommodation you live in to see whether your circumstances might affect your pregnancy.\n- How you’re feeling, any signs of depression etc.\nIt’s up to you whether you want to answer these questions. We are not here to judge you, but your answers will allow your St John Medical midwife in Perth or obstetrician to gather more information and better support and care for you and your baby’s health.\nAnything you say will be kept in confidence and the information will only be shared (with your permission) with any other health workers on a need-to-know basis.""]"	['<urn:uuid:6c81efd1-0591-417f-851e-4a0ca8252ff8>']	open-ended	direct	short-search-query	distant-from-document	single-doc	novice	2025-05-01T22:47:46.423955	6	70	861
17	As someone studying crop quality parameters, I'm curious about the early test results for the 2021 hard red winter wheat harvest. What were the key measurements for moisture content, protein levels, and test weight?	According to early testing data from 522 samples, the 2021 hard red winter wheat crop showed moisture content of 10.9%, protein content of 11.9%, and test weight of 60.3 pounds per bushel (79.3 kilograms per hectoliters).	['In 2021, the United States saw an end to the multi-year trend of hard red winter (HRW) wheat acreage reductions with a modest increase from 21.7 million acres in 2020 to 23.6 million acres this year.\nAccording to the United States Department of Agriculture (USDA) National Agricultural Statistics Service (NASS) late June acreage report, total wheat planted area for 2021 is estimated at 46.7 million acres, up 5% from 2020. This represents the fourth lowest all-wheat planted area since records began in 1919.\nThe 2021 winter wheat planted area, at 33.7 million acres, is up 11% from last year and up 2% from the previous estimate. Of this total, about 23.6 million acres are HRW, 6.59 million acres are soft red winter (SRW), and 3.5 million acres are white winter wheat.\nThe USDA NASS mid-August crop production report projects winter wheat production at 1.32 billion bushels, up from 2020’s total production of 1.198 billion bushels.\nAs of August 1, yield is forecast at 51.8 bushels per acre (bpa), down 1.8 bushels from July but up 0.9 bushels from last year’s average yield of 50.9 bushels per acre. Area expected to be harvested for grain or seed totals 25.4 million acres, unchanged from July but up 11% from 2020.\n2020 recap. Winter wheat production for 2020 totaled 1.17 billion bushels, down 11% from the 2019 total of 1.32 billion bushels. Yield, at 50.9 bpa, was down 2.7 bushels from 2019. Area harvested for grain was estimated at a record-low 23 million acres, down 6% from 2019.\nCompared with 2019, harvested acreage in 2020 was down 11% in the major HRW growing states, the primary winter wheat-producing area. HRW production totaled 659 million bushels in 2020, down 22% from 2019.\n2021 HRW Crop Condition\nIn its Aug. 27 HRW harvest summary, Plains Grains Inc. (PGI) reported that harvest had been completed in the United States.\nAccording to PGI Executive Director Mark Hodges, the theme of the 2021 HRW harvest could be characterized as a tale of extremes – heat and drought.\nHarvest began in central Texas with lots of rain just as the crop matured. That was followed by damp, overcast, cool weather, making it very difficult to get the crop out of the field. These conditions prevailed for several weeks, and when it wasn’t raining, many areas experienced abnormally cool temperatures, heavy overcast, and very high humidity.\nWhile this weather was not unusual for the Southern Plains during harvest, the length of time it lasted was unusual. Harvest in most of the central and eastern parts of the HRW production area of the United States was delayed by almost 2 weeks due to excessive moisture and high humidity, delaying harvest start times and limiting the work to very few hours each day. The northern United States and Pacific Northwest experienced the opposite situation – exceptionally dry conditions and abnormally hot temperatures – leading to an early harvest and a short crop. Early lab results are reflective of these conditions.\nHarvest Quantity by State\n(Editor’s note: The following state and regional data is based on averages of individual sites. Data is not final and may be subject to change once weighting has been completed.)\nTexas: Approximately 2.25 million acres of winter wheat were harvested, producing 83.25 million bushels. The average yield was 37 bpa. This compares to 2.1 million acres harvested with production topping 63 million bushels in 2020.\nOklahoma: On 2.7 million harvested acres, production this year reached 108 million bushels compared to 113.4 million bushels in 2020. Yields were 37 bpa this year, down from a record high of 42 bpa in 2020.\nKansas: Production is estimated to be 379.5 million bushels on 6.9 million acres, which is an increase from 294 million bushels on 6.4 million acres in 2020. Yield this year is 55 bpa, up from 45 bpa last year.\nColorado: Approximately 1.85 million acres of winter wheat were harvested, producing 72.15 million bushels. Average yield is 39 bpa, up from 27 bpa in 2020.\nNebraska: Winter wheat production is expected to hit 39.48 million bushels on 840,000 harvested acres this year, which is up from 34.03 million bushels on 830,000 acres in 2020. Yields were 47 bpa in 2021 (41 bpa in 2020).\nMontana: Production is forecast to reach 52.7 million bushels, which is significantly lower than 75.99 million bushels in 2020, despite harvesting 1.7 million acres this year and 1.49 million acres in 2020. Average yield was 31 bpa this year and 51 bpa in 2020.\nNorth Dakota: Production is forecast to reach 1.93 million bushels on 55,000 acres with an average yield of 35 bpa. In 2020, production was 1.62 million bushels on 33,000 acres with an average yield of 49 bpa.\nSouth Dakota: production is estimated to hit 29.24 million bushels on 680,000 harvested acres with an average yield of 43 bpa, a decrease from last year’s level of 34.8 million bushels on 600,000 acres with an average yield of 58 bpa.\nOregon: Production is forecast at 31.97 million bushels from 695,000 acres for an average yield of 46 bpa. The state produced 46.4 million bushels in 2020 on 725,000 acres for an average yield of 64 bpa.\nIdaho: Production is forecast at 52.93 million bushels from 670,000 acres, which equals an average yield of 79 bpa. Production was higher in 2020: 66.66 million bushels on 725,000 acres with an average yield of 101 bpa.\nWashington: Production is estimated to be 74.36 million bushels from 1.69 million bushels for an average yield of 44 bpa. This is significantly less than in 2020’s harvest that produced 133 million bushels from 1.75 million acres.\nCalifornia: Production is estimated to be 4.8 million bushels from 60,000 acres for an average yield of 80 bpa. This is a reduction from the 2020 harvest, which produced 6 million bushels from 80,000 acres.\nEarly Quality Notes\nAs of Sept. 2, 522 of an expected 525 samples were in the lab for testing. Early data shows:\n• Moisture: 10.9%.\n• Protein: 11.9%.\n• Dockage: 0.5%.\n• Thousand kernel weight (TKW): 30 grams.\n• Test weight: 60.3 pounds per bushel (79.3 kilograms per hectoliters).\n• Foreign material: 0.3%.\n• Damage: 0.4%.\n• Shrunken and broken kernels: 1%.\n• Defects: 1.7%.\nFor more information on test weight and protein levels, go to the PGI website: plainsgrains.org. Another resource is the U.S. Wheat Associates’ crop quality reports at uswheat.org/crop-quality.\nTucker Scharfenberg, managing editor']	['<urn:uuid:dc8109c7-1b86-4b19-aecd-29ed9e08669f>']	open-ended	with-premise	verbose-and-natural	distant-from-document	single-doc	expert	2025-05-01T22:47:46.423955	34	36	1069
18	How much extra do stores add for credit card payments?	Surcharge fees typically range from 3-5% depending on the store, and cannot exceed 4% of the merchant cost of acceptance. These surcharges can only be applied to credit cards, not to debit, gift, or prepaid cards.	['Cash Discount vs. Surcharge Program\nTwo important words that make retail management difficult to understand are “cash discount” and “surcharge program.” The distinction between surcharging and cash discounts program is becoming increasingly hazy. This can cause issues for those who misunderstand and inadvertently violate the rules and regulations governing these transactions. However, the distinctions are not difficult to grasp, and compliance is simple once you are familiar with the concepts and procedures.\nBoth terms refer to discounts that retailers offer for paying cash instead of using credit cards or other forms of payment. Cash discounts usually range from 1-4% and apply as an incentive for using cash over other means of payment. The goal is to prompt customers to use cash, which is less expensive for the store, rather than their other options. Surcharge fees are separate from cash discounts and reflect the average cost of products in various retail stores nationwide. This can vary from store to store or country to country.\nWhat are Cash discounts and Surcharges?\nCash Discount is a program that discounts the price of an item by a set percentage if you pay in cash. This discount can be applied anytime, so long as you purchase in person. Cash Surcharge is a program that imposes an additional fee on customers who pay with credit or debit cards. Your credit or debit card may not be processed on your side, but the vendor will receive funds from your institution for the same purchase amount.\nDifferences between Cash Discounts and Surcharges\nSurcharges and cash discounts are transaction fees that can be imposed on a customer to compensate the merchant for certain costs. But there are some key differences.\nDiscount applies at the time of purchase. A surcharge is added to the original price and reduces the net sale amount.\nA cash discount program is not reported to a credit card processing company. The surcharge is reported when acquired and again when billed, which can be used by the landlord or reporting agency to establish the credit rating of the store merchant.\nSurcharges are a way of describing an extra cost, but these costs are not typically found on a bill or included in the initial purchase price (rather, they’re tacked on later). Most often, they’re applied when customers buy something with cash. Cash discounts refer to a decreased rate offered for items or services purchased during certain times.\nCash discounts help organizations with big budgets allow their business to work in harmony without having to pull the plug on other departments. Surcharges, on the other hand, work in the opposite way to cash discounts. They are small charges that are added to large orders; this is done to keep cash discounts from being applied too often. These surcharges help balance out the budget and ensure that those with smaller budgets can still get a break from their organizations.\nProblems with cash discount and surcharge transactions\nMerchants believe that by imposing a service fee on all credit card transactions, they are providing a “CASH DISCOUNT PROGRAM.” These transactions, however, are not exempt from Visa surcharge rules simply because the merchant stated that a service fee is added to all transactions and that cash sales are discounted. A SURCHARGE is the addition of any fee to a displayed price. While it may appear to be a minor distinction, it is crucial regarding legality and compliance with card brand rules. Surcharges are only permitted on credit card purchases under certain conditions. Surcharges on PIN-capable debit cards are not permitted, even if the PIN is not used for the transaction.\nMerchants can participate in a compliant surcharge program, but there are some guidelines to follow.\n- Before implementing a surcharge, merchants must register with credit card companies.\n- Surcharges can only be applied to credit cards; debit, gift, and prepaid cards are not eligible.\n- Surcharges should not exceed the merchant cost of acceptance, with a maximum of 4%.\n- The surcharge must be displayed at the point of entry and acceptance.\n- Surcharges are not permitted in some states.\nRisks in cash discounts and surcharges\nMany benefits come with using cash for transactions, but one of the most significant risks is how this payment method leaves retailers unprotected from surcharges. Retailers make their profits from surcharge fees, which can devastate a business. Research has shown that up to 30% of purchases in stores across the country have had charges built into them in some way or another, whether given as an incentive on top of the original price or hidden within product pricing (e.g., over 100% markups).\nWhich is better, cash discounts or surcharges?\nGreat question! Cash discounts have been around for centuries. They are a way for wholesalers or retailers to make deals with their customers and provide them with the best prices. With so many retail stores going cashless, knowing how much money you save when an item is discounted for cash is important. The term surcharge means that a store has built up a pricing tier for certain items: discounted priced, regular priced, and premium priced. So in this example, if you pay by credit card instead of cash, your purchase will include the premium price tier because it’s not discounted. Surcharges can range from 3%-5% depending on the store and what tier you find yourself in.\nSome IT (Information Technology) businesses use the terms cash discount and surcharge interchangeably—but they aren’t. They are advanced ways of getting more business through advanced POS (Point of Sale) technology, done manually or through your iPad or tablet. Cash discounts and surcharges are used to get customers to pay with cash instead of credit or debit cards. This is because cash discounts or surcharges mean you’ll lose out on paying interest rates, up to 30-50% depending on traditional credit cards.\nIt is more important than ever in today’s market to identify ways to become more competitive. After reading this article, you should have a better understanding of the differences between cash discounts and surcharges and which one to choose between two, depending on the type of business.']	['<urn:uuid:fece7380-cbed-4a32-a6a6-29d6a7273076>']	factoid	direct	concise-and-natural	distant-from-document	single-doc	novice	2025-05-01T22:47:46.423955	10	36	1017
19	tourist outdoor activities mid january september alice springs ahmedabad compare	Mid-January in Ahmedabad offers visitors the International Kite Festival experience, where people can enjoy watching colorful kites at venues like Sardar Patel Stadium and Ahmedabad Police stadium, visit kite museums, and participate in kite flying activities. In contrast, September in Alice Springs (Spring season) provides opportunities to visit Uluru and Kata Tjuta, enjoy the vivid colors of the natural landscape, see wildflower displays, and participate in various outdoor festivals including the Alice Desert Festival with its multi-arts programs. The weather in Alice Springs during this time is cool but getting warmer, making it ideal for outdoor activities.	"['Gujarat organizes many cultural festivals round the year; the International Kite Festival that takes place in Ahmedabad is one of them. Kite manufacturers and master kite flyers from across the world come here with various kinds of kites. This festival is held at a juncture in between the end of winter and the beginning of summer season based on the Hindu calendar. People from different parts of India come to enjoy the scene of kite flying. In this festival, you will find different kinds of traditional Indian foods like ‘Undhyu’ and ‘Laddoos’. This festival is famous by the name “Uttarayan” in Gujarat. Apart from Ahmedabad, kite festivals are also held in places like Surat, Rajkot, Vadodara, Nadiad and other places as well. The time of Uttarayan coincides with Makar Sankranti and Pongal festivals that are celebrated in other parts of India.\nNot only Indians but also people of various countries join at the International Kite Festival, Ahmedabad. The most suitable place to enjoy the festival is at Sardar Patel Stadium and the Ahmedabad Police stadium, from where you will be able to enjoy seeing the bright colors of the flying kites. During this festival, the markets in this area are flooded with many kites of different sizes and colors. Customers would be ready to buy the kites of their choice at much higher costs as well. You can also visit the kite museum that exhibits different varieties of kites.\nThere is a historical background for this kites festival. This kite flying festival symbolizes raising the Gods from their sleep. Throughout the history, this festival has been related to kings and their raising powers. Many international participants attend this festival with their colorful kites. The Wau-balang kites from Malaysia, 11 Ayang kites from Indonesia, the giant banner kites from the USA, Rokkaku fighting kites from Japan, Italian sculpture kites and Flying Dragon kites from China are some of the examples. Skillful kite flyers from across the world compete with each other to cut the strings of the nearby kites and bring them down. Many celebrities like well-known artists and politicians also visit the kite flying festival.\nThe kites in these festivals are usually made of leaves, plastic, metal, wood, nylon or some other materials. The main attraction is the central kite that is made of bamboo and lightweight paper; it has its own unique shape. The color and decoration of this kite makes it exceptional. The main attraction of this festival comes just after the dark when kites with lights in them known as “Tukkals” can be seen flying in the skies. During this festive season, people enjoy the beauty of kites and at the same time, they like to have varieties of food. They love to watch the live performance of the artists but still the main attraction is the kites. People love to enjoy the day flying kites not just in Ahmadabad, but elsewhere too. If you happen to be in Gujarat during mid-January, claim no reason to miss this wonderful festival.\nDate: January 14th, 2014 click here for festival dates\n“A good traveler has no fixed plans and is not intent on arriving.” – Lao Tzu', ""September in Australia’s Red Centre: Spring has sprung, the days are still cool (but getting warmer), the colours of Uluru are at their most vivid, and, if you’re lucky, the wildflowers might even put on a beautiful show.\nThere are many reasons why Spring is the ideal time to visit Alice Springs and the arid heart of this brutal, beautiful country. Many of them involve getting out in the great outdoors, enjoying nature and exploring iconic natural attractions such as Uluru and Kata Tjuta.\nBut there are other uniquely Australian experiences to be had in this neck of the woods at this lovely time of year.\nHere are three of the best festivals in the Alice, starting in September – plus a couple in the magnificent Top End:\nCentral Australia's premier annual multi-arts festival is a celebration of the desert, its people and its rich cultural landscape.\nSet in the beautiful surrounds of Alice Springs, the Alice Desert Festival is characterised by a diverse programme that features everything from music, dance, theatre, visual arts and comedy, to circus, film, cabaret, vaudeville, the spoken word, workshops and more.\nMost importantly, the Festival celebrates the exchange between cultures. It finds the most intriguing artists, dancers and musicians from some of the most remote Aboriginal communities in the land, and puts them alongside some of the best contemporary acts in Australia. The result is electrifying.\nThis year, a festival highlight will be performances of Bilarni – the story of WE (Bill) Harney, considered by many to be Australia's greatest ever yarn-spinner. A bushman who returned from WW1 to live amongst Aboriginal people, he ultimately became the first Ranger at Uluru, where he was known as the ‘Custodian of the Rock’. Bilarni is written and performed by Jan 'Yarn' Wositzky, famous for founding The Bushwackers Band back in 1971. Learn more about the Alice Desert Festival here.\nThis spectacular light festival paints the 300-million-year-old MacDonnell Ranges and surrounding desert in a riot of colours and patterns. Using cutting-edge technology, the 10-day event turns the natural landscape into a breathtaking outdoor gallery, highlighting artworks from contemporary Aboriginal artists via an interactive canvas and light show.\nHailed as the first authentic Aboriginal festival of its kind, Parrtjima (which means “shedding both light and understanding on a subject” in the local Arrernte languages), showcases the oldest continuous culture on earth on an epic and unforgettable scale. Click here to learn more.\n“What a Wonderful World! – celebrating global heritage” is the theme for this year’s Desert Song Festival, a 10-day musical extravaganza in the Red Centre, celebrating the singer, the song, the instrument, the land and its people.\nIt’s the perfect name, as this year the festival will feature musical traditions from not only Central Australia, but also India, Africa and the Americas. Visitors will experience something truly special, with choirs, vocal ensembles, musicians and solo artists performing in unforgettable settings ranging from heritage venues in Alice Springs to the Tjoritja/West MacDonnell Ranges.\nAs well as concerts, there are workshops and masterclasses, plus a screening of the documentary “The Song Keepers”, a story about the Central Aboriginal Women’s Choir. Click here to learn more.\nIf you’ve ever dreamed of visiting Kakadu, this three-day event will give you even more inspiration to visit Australia’s largest and most famous national park. At the Mayali Mulil Festival, members of the Murumburr clan are offering a genuine cultural experience at Kakadu Billabong Safari Camp, on the banks of a billabong complex along Jim Jim Creek.\nBy sharing their culture and traditions they’ll help visitors connect to the land and its traditional owners – everything from bushwalks, spear-throwing competitions and didjeridoo workshops to fishing, storytelling and traditional dancing corroborees can be enjoyed. Concerts, cultural food stalls and bush-tucker experiences, and camping and safari accommodation round off this incredible Kakadu event. Click here to learn more.\nWalk the red carpet in Darwin in September, when the International Film Festival comes to town. The 10-day movie-fest features around 40 fab flicks, plus workshops and exhibitions. Movies showcase the best of Northern Australia and Northern Territory film, Indigenous stories and film makers, plus films from around the world. A visit to the Deckchair Cinema is another must for cinephiles – it’s the world’s most retro outdoor cinema, where you sit on a canvas chair under the stars while watching the stars on screen. Click here to learn more.""]"	['<urn:uuid:fc7fb946-8b85-4569-9dfc-672ad49264e8>', '<urn:uuid:79e8357d-26a6-4024-800c-be5457cc4604>']	open-ended	direct	long-search-query	distant-from-document	comparison	novice	2025-05-01T22:47:46.423955	10	97	1261
22	dust collector box design requirements proper airflow considerations	"A dust collector box requires both proper ventilation and dust collection capability. It needs a minimum 4\"" outlet boot centered to the router motor for dust collection, while also incorporating make-up air porting to maintain optimal DC efficiency. For particle management, the system must account for dust loading - with baghouses handling 5-7 grains/cu ft and cartridge collectors requiring below 2 grains/cu ft. Additionally, dampers near pickup points are necessary to balance airflow and control dust collection across different areas of the system."	"['This is by Stick486\none very important thing you have to remember is to make sure your router box is vented w/ outside air for the motor or you will cook the motor from excessive heat because of the lack of cooling air for the motor...\ndo this by either sticking the motor\'s air intake outside of the box or add a \'\'snorkel\'\' to the end of router motor... This is by Herb Stoops...\nThat is a good point, Stick,I let the router protrude through the bottom of the box. By doing so I had to cut out the bottom to clear the posts for the Jessem lift. I like Stick\'s idea better to clamp a flex hose around the router and let it protrude thru the bottom of the box to allow the motor to suck clean air. I also have an adjustable port in the side of the box to allow more air into the box to create a maximum air flow thru the box.\nIn my first router table I had the Milwaukee router, it was a real workhorse, the reason I bought the Milwaukee was at that time it was one of the few routers you could adjust the height from the top of the table. I didn\'t have a dust collection under the table at that time and could reach under,unlatch the router and do the adjustment from the top ,then reach under and lock the router. But the amount of chips and dust that ended up under the table was a large amount. The fence dust collection just couldn\'t get half the chips.\nI also doored the router box for easy access to the router and the lift...\nStick did the same and he installed vents in his door..\nUnder table DC is a must, I branch off a 4"" dia. with a 2 1/2"" to the fence and a 4"" to the under table box.\nHerb This is by Stick486 Now for Plan \'\'C\'\'.....\nA closed dust collector box keeps the inside of the table\'s router box at negative pressure. Which limits air flow and to some extent, deprives the motor of cooling air flowing through the motor. This fosters a condition where the router motor will overheat.\nBuilding a box enclosing the lift/router motor that allows for elevation changes and provides make up air porting, allows the DC\'s air to flow at optimum efficiency.\nAdding a large square boot, (4\'\' outlet minimum), centered to the router motor, on the bottom of the box dedicates DC.\nNow, cooling airflow to the motor.\nAdding a \'\'snorkel\'\' made of plastic or metal to the end of the router motor, of sufficient length to protrude outside of the box, irrespective of motor elevation, would ensure fresh air cooling to the motor.\nThis snorkel/tube/sleeve goes right through the dust collector boot (you would need to cut a hole in the boot for integration). It allows the motor to draw clean outside air for cooling. HEAT\nwill destroy your motor in very short order without good clean airflow.\nWhen you attach the snorkel to motor make sure you don\'t cover/seal the air inlet vanes.\nRound routers only need a round tube. Oversize the tube and use a reducing bushing with an ID to fit your motor.\nSquare ended router motors need a little more creativity. There are a host of square to round PVC adapters found in the “Big Box” chain stores\' plumbing departments and they are also used in storm water drainage systems. Fernco also makes an extensive product line. In addition, look to vinyl guttering components. Also, don\'t skip by the HVAC section either. There is a vast variety of adapters available. There isn\'t anything saying that you can\'t use a length of square tube. There are a host DC fittings that may work. You could even fix the tube aka snorkel to the bottom of the box and let the router motor slide freely up and down in the tube.\nNow, as to the mounting. There are several options available; hose clamps, Velcro or mechanical (screws, nutserts, etc.). Mechanical method would be preferred if you have a thick motor cap and there\'s clearance under the cap, to give the end of your mechanical fastener room and it won\'t damage anything.\nVelcro; for that to work, (slide on - slide off can be tad difficult) barrier the hooks and loops w/ a plastic putty knife(s). Set the snorkel. Remove the putty knife(s).\nTo separate the H&L to remove the snorkel, slide/work the putty knife(s) in between the H&L to release one from the other.) Remove the snorkel. Notes:\nAn open bottom box won\'t work all that well if there are drawers under the router box, nor will the snorkel through bottom or a bottom mounted DC boot unless they are designed into the table. Venting and DC will work if installed through the back or side of the box. Whatever you do, you need to arrange for make up air (venting/cooling) and pickup for for the DC simultaneously. There many variables here but all in all this should give you plenty of ideas to work w/ for/on a finished system that will work well for you. Take this link to the thread', 'Dust has been one of the biggest air pollutants over the years. Dust extraction and collection systems are thus designed to eliminate dust particles at home and commercial settings. However, the dust collection system’s performance will depend on several factors such as location and number of dust collection points, duct diameter, and dust particle size, to mention just a few. A simple miscalculation when designing such a system can lead to costly performance issues.\nUnderstanding how dust extraction systems work is thus important before you commit to buy one. The following are some of the questions to guide you:\nDoes particle size distribution matter?\nDust particles usually appear in different sizes and shapes. Some of the factors that determine the size include the composition of the parent material and the processing machine’s nature that creates these particles. For instance, you will find some differences in the dust from the sawdust from a chainsaw from the dust you get from gravel in a construction site. The variance in the particle size is also known as the particle distribution. The dust extraction system company will thus be interested in the particles’ size for several reasons. Some of these particles can be inhaled and thus affects industrial hygiene standards. Dust collectors are designed to be permeable to air. However, such collectors may fail to trap dust if the particles are extra-small. Experts in this field must also check the dust particles’ combustibility and their ability to be disbursed during an explosion.\nFan wheel-style; does it affect performance?\nOne of the most important components in typical dust collection systems is the exhaust fan. It is this component that provides the motive behind the entire system. The system is thus bound to fail if the exhaust fan is not performing as expected. The fan must thus generate enough pressure and volume that will pick dust particles. There are three different types of wheels:\nAir handling wheel\nSuch wheel cleans extremely light dust loading or clean airstreams. Such wheels should never be used on the dirty side but the clean side.\nIt works best when the fan is on the dirty side of the dust collector. One of the best places where such wheels are used is in material handling. An open-type wheel applies best when the dust is fibrous or when there is a high dust loading. The design is meant to prevent/protect the dust from wrapping around the wheels.\nSuch wheels are not common on dust collection systems. They typically move a lot of air, but the force behind them is negligible. The material used to make such fans is an important consideration as abrasive specks of dust can erode those fans made from soft metals.\nWhat is a damper?\nA damper is a tool in a dust collection system that controls airflow to a specific branch of the ductwork. The dampers usually open and close, thereby allowing air to pass through. Air always uses a path with the least resistance. Typical dust extraction and collection system will have a damper near each pickup point or hood that allows the system to be balanced. It is this flexibility that will allow airflow to be varied across collection points. An unbalanced system could cause uneven pulling of air within an area. There are spaces or soft connects between flanges that control the airflow at pickup points. However, the approach is not that effective as it keeps the airflow constant in that specific area, even when it is not necessary. Dampers are more effective than soft connects as they close off branches that are not being utilized.\nWhat is load in dust extraction?\nMost dust collectors such as cartridge collectors and baghouses use filters and bags to separate dust from the air. Such collectors use fabric filters, which means that there is likely to be a negative impact on the performance when there is excessive dust loading. If a baghouse has a higher than 5-7 grains/cu ft concentration, then expect that there will be maintenance and operational issues. On the other hand, the load should be below 2 grains/cu ft if you are dealing with cartridge collectors. The airflow that goes through the collector is greatly reduced when the filters are overloaded, which leads to overall system inefficiency. The collection process thus becomes expensive as the system does not collect dust as it is expected. You must also replace the filters often, which means that the system will be offline on many occasions. There are also high chances of air getting into the environment.\nLeave A Comment']"	['<urn:uuid:a9888b48-59d1-4b15-a4f8-f2269785dd9d>', '<urn:uuid:0973069b-6eac-433b-9490-81c43bda35ca>']	factoid	with-premise	long-search-query	distant-from-document	multi-aspect	expert	2025-05-01T22:47:46.423955	8	83	1637
23	How do digital tools help retirement savings and what security risks exist?	Digital tools help retirement savings through email interventions that double enrollment rates and mobile apps that reduce monthly spending by 16%. However, these financial applications need strong security measures like MASVS-L2 standards to protect sensitive data and high-value transactions from threats like data breaches and tampering.	['Benartzi: Digital Nudges Can Boost Retirement Savings\nA recent analysis offers a fresh take on how to motivate individuals to save for retirement: wed technology and behavioral economics.\nIn “How Digital Tools and Behavioral Economics Will Save Retirement\n,” an article published in the Harvard Business Review, Shlomo Benartzi, Professor of Behavioral Decision Making at UCLA Anderson School of Management, argues that technology can be used for more than providing individuals with information and a way to enroll in a plan and then monitor and manage their accounts. He suggests that it can be used to change behavior — specifically, that concerning saving. “Nudges can drive lasting behavior change,” Benzarti writes. “Digital nudging holds particular promise in the domain of retirement savings.”\nBenartzi elaborates that digital nudging facilitates faster research and data regarding what interventions work with individuals. Further, he says, “the digital world offers unprecedented scale: by fixing a single website or app, we can potentially help millions of people make better financial decisions.”\nBenartzi outlines three case studies to illustrate the impact digital nudging can have.\nEffective Use of Email.\nBenartzi discusses a paper he co-authored that concerned a study of the effect of an email intervention on enrollment in a savings program sent to roughly 800,000 military service members. They found that email can be used to dramatically increase enrollment. “This email used simple nudges, such as providing actionable steps for enrolling in the savings program and giving people clear examples of how small contributions can lead to large account balances, to make the responsible choice the easy choice,” he says. The results? Those in the study who received the emails enrolled at twice the rate of those who did not. Even more impressive was their finding that the effort was approximately 100 hundred times more cost-effective than other, broader means of increasing enrollment such as tax incentives and financial education programs.\nBenartzi observes that the General Accounting Office reports that the percentage of U.S. workers who are not salaried — that is, self-employed, independent contractors, freelancers, part-time workers and other contingent workers — is climbing closer to half. And one of the many consequences, he argues, is that more workers are becoming solely responsible for their own retirement and financial well-being. “If we don’t provide them with easy digital tools for savings, we could be looking at a generation of workers struggling to achieve even a semblance of financial security in retirement,” Benartzi warns. “As a result, people need a digital solution,” he concludes, suggesting that these solutions should “directly and promptly links their savings to their income, even when that income appears inconsistently.” Plan sponsors “need to make it as easy for these workers to save as it is to spend,” he says.\nBenartzi reports that he was one of the researchers in a study that examined the effect of a mobile app that offers account aggregation service that brings together all of your financial accounts and lets people track their investment performance and spending behavior on their mobile devices. They found that the app “had a huge impact” and cut monthly spending by the average user by almost 16%.\n“The design of the digital world shapes our behavior in countless ways,” Benartzi notes. “The more we can do to understand the most positive uses of behavioral science combined with digital, the better off the world will be.”', 'SECURITY IN MOBILE APPLICATION\nMobile security in mobile application is the practice of protecting mobile apps from external threats such as malware, phishing, tampering, reverse engineering, and data breaches. It focuses on ensuring the confidentiality, integrity, and availability of the data and functionality of the apps, as well as the privacy and identity of the users.\nWe need mobile security because mobile devices are increasingly used for various personal and professional purposes, such as communication, banking, shopping, entertainment, education, health, etc. These devices store and transmit a lot of sensitive or confidential data, such as passwords, credit card numbers, photos, contacts, messages, emails, etc. that can be valuable or harmful if accessed by unauthorized parties.\nMobile security helps to protect our devices and data from various types of threats and risks, such as malware, phishing, data breaches, device theft or loss, network spoofing, etc…\nWHAT KINDS OF MOBILE APPLICATION NEED SECURITY?\n- Banking and financial applications: These applications allow users to manage their money, make transactions, pay bills, etc.\n- Healthcare and medical applications: These applications provide users with access to health records, prescriptions, appointments, etc.\n- E-commerce and retail applications: These applications enable users to shop online, browse products, make purchases, etc.\n- Gaming and entertainment applications: These applications offer users various forms of fun and leisure activities, such as playing games, watching videos, listening to music, etc.\n- Social media and communication applications: These applications allow users to connect with others, share messages, photos, videos, etc.\nHOW DO WE APPLY SECURITY?\nThere are many ways to improve security in mobile application. But to apply it effectively, we need a standard which is accepted and used widely by many companies. This is OWASP.\nOWASP stands for Open Web Application Security Project. It is a nonprofit foundation that promotes application security by publishing resources, education, and training. This also develops standards for mobile security called OWASP MASVS (Mobile Application Security Verification Standards).\nThe OWASP MASVS 2.0.0 is already available at v2.0.0. It has 7 categories of security requirements for mobile apps, which are:\n- MASVS-STORAGE: Secure storage of sensitive data on a device (data-at-rest).\n- MASVS-CRYPTO: Cryptographic functionality used to protect sensitive data.\n- MASVS-AUTH: Authentication and authorization mechanisms used by the mobile app.\n- MASVS-NETWORK: Secure network communication between the mobile app and remote endpoints (data-in-transit).\n- MASVS-PLATFORM: Secure interaction with the underlying mobile platform and other installed apps.\n- MASVS-CODE: Security best practices for data processing and keeping the app up to date.\n- MASVS-RESILIENCE: Resilience to reverse engineering and tampering attempts.\nBesides that, OWASP also define level of security:\n- MASVS-L1: Standard Security\n- A mobile app that achieves MASVS-L1 adheres to mobile application security best practices. It fulfills basic requirements in terms of code quality, handling of sensitive data, and interaction with the mobile environment. A testing process must be in place to verify the security controls. This level is appropriate for all mobile applications.\n- MASVS-L2: Defense-in-Depth\n- MASVS-L2 introduces advanced security controls that go beyond the standard requirements. To fulfill MASVS-L2, a threat model must exist, and security must be an integral part of the app’s architecture and design. Based on the threat model, the right MASVS-L2 controls should have been selected and implemented successfully. This level is appropriate for apps that handle highly sensitive data, such as mobile banking apps.\n- MASVS-R: Resiliency Against Reverse Engineering and Tampering\n- The app has state-of-the-art security, and is also resilient against specific, clearly defined client-side attacks, such as tampering, modding, or reverse engineering to extract sensitive code or data. Such an app either leverages hardware security features or sufficiently strong and verifiable software protection techniques. MASVS-R is applicable to apps that handle highly sensitive data and may serve as a means of protecting intellectual property.\nExamples of Security Level Usage:\n- Fitness apps, Transport apps that handle various types of sensitive data, such as user profiles, health records, location, preferences, and contacts which exposed the login user. Incase required advance protection such as Biometric authentication, SSL Pinning, Certificate Transparency for high-value transactions, they should be applied MASVS-L2/ MASVS-L2 + R.\n- Banking: Apps that allow users to access their accounts, transfer money, pay bills, and manage their investments. The app handles sensitive data such as personal and financial information and performs high-value transactions.\n- A gaming app that allows users to play online games with other players, chat with them, and buy virtual items. The app may/may not handle any sensitive data or perform any high-value transactions, but it has valuable intellectual property and business logic that could be stolen or copied by competitors or malicious users. The app operates in a hostile environment where reverse engineering and tampering are likely or have a high impact.\n- Financial Industry: Online banking apps that allow the user to move funds, where techniques such as code injection and instrumentation on compromised devices pose a risk. In this case, controls from MASVS-R can be used to impede tampering, raising the bar for malware authors.\nBy applying OWASP MASVS, we can prevent almost of security issues for mobile application. However, the effort is spent for it is not small and we also need more effort for security testing. Let categorize how much sensitive of your application and your budget, then pick up suitable level of security.\nThis blog is not providing you very details of how to implement it in mobile applications, but we can understand how important is it and also introduce a standard for Security in Mobile Applications.']	['<urn:uuid:6b17c008-09ea-4b99-af71-34694fb5688d>', '<urn:uuid:6d3b4a05-c434-4ebd-959e-b333e1dce1ab>']	factoid	direct	concise-and-natural	similar-to-document	multi-aspect	novice	2025-05-01T22:47:46.423955	12	46	1484
28	As a ruminant nutrition specialist, I'm researching methane emissions from cattle digestion. What is the role of protein in ruminant digestion, and how does this relate to their contribution to global warming?	In ruminant digestion, most ingested protein is broken down by rumen microorganisms and resynthesized as microbial protein, which makes up nearly 70% of protein absorbed in the small intestine. This process involves two forms of protein - true protein (classified as RUP or RDP) and small amounts of non-protein nitrogen. Regarding global warming impact, ruminants like cattle are major methane emitters, accounting for almost 70% of agricultural emissions and producing more CO2-equivalent emissions than any country except China. This occurs during their digestive process, making them the largest contributors to methane emissions within the agricultural sector, which is responsible for 40-50% of total anthropogenic methane emissions.	['This is an excerpt from information provided by the Beef Cattle Research Council of Canada, so naturally it’s focused on cattle. But the descriptions of energy and protein and the definitions of measurements of nutritional value cover all forages and ruminants. You’ll find this helpful no matter what livestock you raise.\nCattle require five key nutrients: energy, protein, water, minerals and vitamins\nEnergy is necessary for maintenance (feed digestion, core body functions, and activity requirements) and to support growth, lactation, and reproduction1. It accounts for the largest proportion of feed costs and is the nutrient required by cattle in the largest amount.\nThe components of feed that determine its energy content include carbohydrates, fats and proteins. On a feed test, energy content is usually expressed as total digestible nutrients (TDN); however, more precise terms such as metabolizable energy (ME) or net energy (NE) for maintenance (NEm) or production (NEg) may be preferred by nutritionists. These terms better reflect the amount of energy from feed that contributes to animal productivity. Energy deficiency caused by low intake or poor feed quality will limit growth, decrease milk production, reduce body condition, and (depending on timing and duration) may have negative consequences for reproduction.\nGross energy (GE) is the total amount of energy in the feed. But not all this energy is available to the animal. Feed energy is lost as it passes through the animal and is excreted as feces, urine, various gases, and heat. These losses are a normal consequence of feed digestion and the amount of energy lost at each step differs based on the quality of the feed. Digestible energy (DE) provides an indication of the portion of energy that the animal can digest, with the help of the rumen microbes. Metabolizable energy (ME) is the amount of energy available to the animal for metabolism and body functions after losses in energy from rumen fermentation (carbon dioxide, methane) and urine have been accounted for. Net energy (NE) is the amount that is available to the animal to maintain itself, grow, produce milk and reproduce.\nNeutral detergent fibre (NDF) and acid detergent fibre (ADF) are indicators of the amount of fiber in a forage. Higher values indicate poorer digestibility and voluntary intake may be reduced.\nNDF is a measure of the “bulkiness” of the diet and is mainly hemicellulose, cellulose, and lignin which make up cell walls and provide structure. Due to limitations in the analysis it also includes a portion of the protein and insoluble ash in the plant. When NDF increases, animals consume less.\nADF measures cellulose and lignin and is an indication of digestibility and energy intake. When plants mature, lignin content increases, resulting in higher ADF and reduced digestibility. Feeds high in ADF are less digestible than those high in starches and sugars. The starches and sugars in feed are classified as non-structural carbohydrates (NSC). Even in forages, NSC are an important source of energy.\nProtein is required for maintenance, growth, lactation and reproduction. It is a component of muscles, the nervous system and connective tissue1.\nProtein requirements depend on cattle/animal age, growth rate, pregnancy and lactation status. Young, growing cattle (and other animals), as well as those in late pregnancy or lactation, have increased protein requirements.\nMost protein that ruminants ingest is broken down by the rumen microorganisms and resynthesized as microbial protein. Forages contain crude protein (CP) in two forms. The greatest portion of protein in forage is referred to as true protein, but forages also contain low amounts of non-protein nitrogen (NPN), which rumen microbes can use to synthesize microbial protein.\nTrue protein in forages can be further classified as rumen undegradable protein (RUP or rumen bypass protein) and rumen degradable protein (RDP). RUP are peptides and amino acids that are digested in the abomasum and absorbed in the small intestine, while RDP is degraded or broken down by the microbial population in the rumen into ammonia and volatile fatty acids. Microorganisms in the rumen combine the ammonia supplied by RDP or other non-protein nitrogen sources (e.g. urea) with rumen digestible carbohydrates to synthesize microbial crude protein (MCP). MCP is digested in the abomasum, with the resultant amino acids absorbed in the small intestine. The amount of protein that reaches the small intestine depends upon the availability of RDP and the rumen digestible carbohydrate. If energy is deficient in the diet, surplus ammonia is converted to urea in the liver and then lost through urine. If protein is deficient in the diet, digestibility of fiber decreases due to diminished microbial activity and muscle will be degraded to meet the animal’s requirements for amino acids for core body functions. (Ed. Note: This is why we sometimes feed protein tubs to animals eating mature grasses. The protein helps microbes turn all that fiber into useable protein for the cow.)\nMicrobial protein makes up close to 70% of all protein absorbed from the small intestine and the protein contributions from microbes may be close to 100% for cattle fed low-quality forage.\nIn most cow-calf diets, forages with adequate digestibility will provide enough MCP to meet the cows’ requirements. But, for animals with higher protein demands, like growing calves or lactating cows, it can be beneficial to feed proteins that bypass the rumen and are absorbed in the small intestine, improving protein bioavailability. Extra protein can be provided by feeds that are high in RUP, like alfalfa dehydrated pellets, distillers’ grains, or alternative feeds like canola meal. Most forages have higher levels of RDP, particularly legumes.\nDuring summer months, while forages and legumes are actively growing, they may supply up to 20% crude protein (CP) with a high level of RDP, but during the winter, protein levels drop off dramatically. Native pasture, for example, may test as low as 3-7% CP. Putting up good quality feed is key to supplying the beef herd with adequate quality forage sources through the winter4.\nWater is an essential nutrient for cattle, accounting for between 50 and 80 percent of an animal’s live weight. Insufficient water intake reduces animal performance faster and more dramatically than any other nutrient deficiency.\nFor livestock to maximize feed intake and production, they require daily access to palatable water of adequate quality and quantity. Factors that determine water consumption include air and water temperature, humidity, moisture content of the feed/forage, cattle type (calf, yearling, bull, cow), the physiological state of the animal (gestation, maintenance, growing, lactating) and water quality.\nTotal dissolved solids (TDS) is the main indicator of water quality and is a measure of dissolved inorganic salts in water. TDS is impacted by high or low pH levels, sulphates, nitrates, salinity, excessive mineral levels, algae and bacteria. Testing water sources to ensure that cattle have access to adequate amounts of quality water is important.\nThe four main functions of water in the body are:\n• to help eliminate waste products of digestion and metabolism\n• a major component of secretions (milk, saliva) as well as individual and fetal growth\n• as an aid in body’s thermoregulation processes through evaporation of water/sweat from the skin’s surface and respiratory tract\n• to regulate blood pressure5\nRead more about water requirements for beef cattle here.\nNext week we’ll take a look at mineral and vitamin requirements. Stay tuned!', 'As global temperatures continue to rise and physical climate hazards become increasingly frequent and intense, more and more organizations are committing to lower their greenhouse-gas (GHG) emissions. Carbon dioxide commands much of their attention, but methane emissions from human activity are the second-largest driver of global warming, accounting for roughly 30 percent of the temperature increase from preindustrial levels. Curbing emissions of methane, therefore, will be critical to solving the net-zero equation—that is, reducing GHG emissions as much as possible, and counterbalancing any remaining emissions with GHG removals—and stabilizing the climate.\nThe bad news is that methane emissions have risen by about 25 percent in the past 20 years. The current trajectory is far off the 2 percent annual decline that would be required to meet the 1.5°C or 2°C warming objectives of the Paris Agreement.\nHowever, there are reasons for cautious optimism. New McKinsey research shows that five industries could reduce global annual methane emissions by 20 percent by 2030 and 46 percent by 2050—enough for a significant shift toward a 1.5°C warming pathway. What’s more, these reductions could be achieved largely with established technologies and at a reasonable cost.\nThe five industries, which together account for 98 percent of humanity’s methane emissions, are agriculture, oil and gas, coal mining, solid-waste management, and wastewater management. In each of these industries, there is a solid economic case to take abatement action. In this article, we look at methane’s impact on the climate, potential ways to reduce emissions, and steps that companies can take to begin managing methane effectively.\nReducing methane emissions is essential to stopping climate change—but some barriers stand in the way\nGlobal temperatures in 2021 are 1.1°C higher than preindustrial levels, with anthropogenic methane emissions responsible for 30 percent of that warming.\nAs temperatures continue to rise, there is a danger that climate feedbacks could accelerate the warming impact of methane from sources in the Arctic, wetlands, and landfills. In the Arctic, permafrost releases methane as it thaws. On the current emissions trajectory, permafrost release alone could add an incremental 5 to 20 percent to long-term methane emissions.\nIn 2018, the Intergovernmental Panel on Climate Change (IPCC) estimated that the world’s budget to keep warming below 1.5°C was 570 gigatons (or 570 billion tons) of carbon dioxide (GtCO2).\nHuman activities currently emit about 41 GtCO2 a year, which suggests the budget will be exhausted by 2031. A core element of the IPCC’s analysis is that pathways to limit global warming to 1.5°C are accompanied by deep reductions in emissions of methane. This means that the more methane that gets emitted, the less “room” there will be in the atmosphere for other GHGs. Put another way, if methane emissions stay high, the world’s carbon budget will soon be spent. The IPCC analysis assumes curtailment of methane emissions of more than 2 percent a year, reaching 37 percent below 2017 levels by 2030 and 55 percent by 2050.\nIf these targets aren’t met, the 1.5°C objective will effectively be beyond reach. On the other hand, if methane emissions can be cut quickly, there will be a sufficient carbon budget remaining for the global economy to reduce CO2 emissions to net zero in an orderly transition (Exhibit 1).\nWhile methane and CO2 have similar warming effects, they are contrasting in several aspects. Methane stays in the atmosphere for just a decade, compared with the centuries-long persistence of CO2, but traps many times more heat. Methane emissions are much more irregular, emitted intermittently from oil wells, cattle, landfills, and coal mines.\nAnother challenge is that sources of methane emissions are highly dispersed across and within the five industries that account for the majority of methane emissions from human activities (Exhibit 2). Agriculture creates 40 to 50 percent of global methane emissions, but these emissions come from millions of farms of different sizes and farming practices around the world.\nAs a result of these challenges, and despite recent technology advancements, methane emissions are notoriously difficult to track and measure. In addition, abatement solutions are rarely cut and dried. Across sectors, abatement measures vary widely in terms of cost per metric ton of methane abated, feasibility, and ease of implementation. Most measures require trade-offs, either between costs and benefits or in terms of environmental impact. Dry seeding in rice farming, for instance, will cut emissions associated with flooding but may boost emissions of nitrous oxide, another GHG. The cost of methane abatement in coal mining is four to five times higher than that of leak detection and repair (LDAR) in oil and gas, because the concentration of methane in released from coal mines is much lower.\nThis creates an uneven playing field that may challenge the business case for methane abatement at individual companies.\nIt is also important to note that reducing methane emissions in time to achieve a 1.5°C warming pathway would require both shifts in demand for commodities and technical solutions (Exhibit 3). The need for action on multiple fronts makes it all the more important to understand the feasibility of technical solutions, which we explore below.\nWe strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: email@example.com\nIndustries could reduce methane emissions with proven technologies at a manageable cost\nDespite practical hurdles, technical abatement solutions are available now across the five industries, and many rely on existing technologies and would support companies as they progress toward their net-zero targets. Moreover, on a 30-year timeline, our analysis shows that more than 90 percent of the potential emissions reductions associated with these solutions could be achieved at a cost of less than $25 per ton of carbon-dioxide equivalent (tCO2e)—a price sometimes paid in the voluntary carbon markets (Exhibit 4).\nFull deployment of the abatement measures described here would cost an estimated $60 billion to $110 billion annually up to 2030, $150 billion to $220 billion annually by 2040, and $230 billion to $340 billion annually by 2050. These estimates include capital investments, operational costs and savings, as well as potential revenues from recovered methane. Cumulatively, the cost of adopting all technical levers would amount to $3.3 trillion to $5.1 trillion over a 30-year period (Exhibit 5).\nOn 2030 and 2050 horizons, estimated emissions reductions by industry are as follows:\nThe agriculture sector, which emits an estimated 40 to 50 percent of anthropogenic methane, could achieve a 12 percent reduction in these emissions by 2030 and a 30 percent reduction by 2050. Agricultural emissions are primarily the result of ruminant animals (principally cows and sheep), farming practices, and rice production. Ruminants create methane during digestion, along with CO2 and other gasses. The impact is significant: ruminants account for almost 70 percent of agricultural emissions. They are responsible globally for more carbon-dioxide-equivalent (CO2e) emissions than every country except China.\nElsewhere in agriculture, biomass burning is a moderate source of emissions, driven by the expansion of land for pasture and crops, while rice farming produces methane via mechanical flooding, which is used in many countries to manage pests. A large proportion of the emissions from agriculture could be addressed with existing technologies. Several companies are already commercializing feed additives for cattle, for example, while alternative approaches to water, soil carbon, nitrogen, and land management provide proven options to rice and crop farmers.\nOil and gas\nOil and gas accounts for an estimated 20 to 25 percent of anthropogenic methane. Our analysis suggests that the sector could achieve a 40 percent reduction in sectoral emissions by 2030 and a 73 percent reduction by 2050. The oil and gas industry emits “fugitive methane” through venting, leaks, and incomplete combustion during flaring. Since methane is the primary constituent of natural gas, these emissions are an untapped source of value, contingent on the necessary infrastructure being put in place. Moreover, there are numerous options to prevent losses in upstream production, including LDAR, equipment electrification or replacement, instrument air systems, and vapor-recovery units.\nCoal mining produces an estimated 10 to 15 percent of anthropogenic methane. According to our analysis, the sector has the potential to achieve a 2 percent reduction in its methane emissions by 2030 and a 13 percent reduction by 2050. The vast majority of coal-mine-methane (CMM) emissions emanate from either working or abandoned deep mines. There is a significant challenge in measuring and recovering these emissions. However, established technologies can capture CMM and use it to generate power. The investment case is probably strongest for companies in China, which account for about 70 percent of CMM emissions and which have invested in coal gasification for the industrial sector.\nAccounting for an estimated 7 to 10 percent of anthropogenic methane, the solid-waste sector could achieve a 39 percent reduction in sectoral emissions by 2030 and a 91 percent reduction by 2050. The majority of methane emissions from waste originates in landfills and open dumps, where anaerobic organic material generates methane over time. Through biogas markets and other incentives, authorities could capture these emissions and either sell the methane as renewable natural gas or use it in the production of fertilizer. However, revenues may not be sufficient to offset the costs.\nThe wastewater sector now emits an estimated 7 to 10 percent of anthropogenic methane. These emissions could be reduced 27 percent by 2030 and 77 percent by 2050. Wastewater emits methane from the breakdown of organic material in wastewater streams. The primary method of reducing emissions would be to build out modern sanitation infrastructure and technology. However, capital costs and policy requirements would be a significant burden in many countries. Where there is funding and access to technology, alternative abatement approaches could include the use of covered lagoons or the application of microalgae to prevent gas formation. Biosolids responsible for producing methane could be collected and sold as fertilizer or bioenergy.\nCompanies can take three no-regrets actions to begin reducing methane emissions\nTo begin reducing methane emissions and meeting the goals of the Paris Agreement, some essential groundwork is required, comprising three no-regret actions:\n- Expand monitoring, reporting, and verification. First, there must be a concerted effort to expand monitoring, reporting, and verification. To get there, governments and industries would need to upgrade data collection, moving from estimates to observed measurements. Satellite, drone, and sensor monitoring, the costs of which are falling sharply, would be one way to help achieve this. Currently, methane emissions are reported in tandem with CO2 emissions. That needs to change, with methane described under its own methodology. Better measurement would offer the potential to create incentives for rapid methane reduction across industries. It could also support efforts to develop global tradable goods markets that value the carbon intensity of products along a traceable value chain.\n- Support sustainable consumption. Stakeholders could develop mechanisms to differentiate assets and score products based on their methane footprints. If every kilogram of rice, million British thermal units (MMBtu) of natural gas, ton of steel, pound of meat, barrel of oil, and ton of coal came with a methane-intensity label, the market signals could support a more orderly decarbonization transition. With this, retailers and consumers could make more informed purchasing decisions, producers could define new foundations for competitive advantage, and investors could better understand portfolio risk.\n- Increase innovation. Many solutions are sufficiently developed to be effective but are not adopted at scale because of excessive costs or a lack of awareness of available technology. In the oil and gas industry, innovation in methane monitoring—for example, leveraging flyovers and on-ground detection—could help businesses pinpoint leaks and cut mitigation costs. The beef industry is in the early stages of adopting feed additives, genetic breeding, and methane capture. These technologies would benefit from support to move more speedily from lab to field.\nThe insights here demonstrate that abating methane emissions will be critical to achieving a 1.5°C warming pathway and avoiding the worst effects of climate change. The good news is that there are many practical solutions available. Feed additives for cattle, new rice-farming techniques, advanced approaches to oil and gas leak detection, coal methane capture, and modern water and waste facilities can all be effective. Still, these solutions face implementation challenges.\nThe priority, therefore, is for action where it is practical. Many of the solutions can be implemented at a relatively low or net-negative cost, and these should be a priority. Where costs are prohibitive, there is a need for coordinated action to create the infrastructure and fiscal conditions that would support further action. Across the board, there is a need for more monitoring, reporting, and verification, more support for consumer choices, and more dedication to funding technical solutions. Without these efforts, it is likely that current initiatives will fail and the planet will continue on its collision course with an uncertain and dangerous future.']	['<urn:uuid:0e1d408f-3fad-4927-ade9-33ed275036e5>', '<urn:uuid:e97f7e36-5560-4dce-89bb-e8a28c4c9c13>']	factoid	with-premise	verbose-and-natural	similar-to-document	multi-aspect	expert	2025-05-01T22:47:46.423955	32	106	3346
30	How can companies protect their intellectual property?	Companies can protect intellectual property by identifying critical IP assets and high-risk insiders who have worked on them, reviewing access controls regularly, creating policies for IP access, automatically disabling access when employee roles change, and considering temporary access disabling during travel or leave. Additionally, organizations can implement user activity monitoring systems that track file activities while maintaining employee privacy through pseudo-anonymization of user data.	"['ptnphotof - Fotolia\nEditor\'s note: This is part three of a series on insider threat behavior. Part one examines patterns of insider...\nthreats and IT sabotage, while part two looks at the precursors and warning signs for such security incidents.\nThe CERT Coordination Center defines insider theft of intellectual property as ""an insider\'s use of information technology to steal proprietary information from the organization,"" while intellectual property is defined as ""intangible assets created and owned by an organization that are critical to achieving its mission.""\nExamples of intellectual property that may be targeted include software code, business plans and product designs.\nIn the previous article on information technology sabotage, the point was made that understanding an insider threat requires an understanding of what motivates people to behave the way they do, either positively or negatively. With regard to the theft of intellectual property, the insider generally does not steal the data in order to sell it, but for business advantages, such as taking it to a new job or using it to set up a competing company.\nA special case of motivation is when the insider engages in intellectual property theft as part of an economic or industrial espionage program that is led by a foreign government or other organization. In order to avoid the cost and time of developing intellectual property, the insider sees stealing it from an organization that has already borne those costs as the more viable option.\nWhen this occurs, insiders usually have a stronger attachment to the foreign government or organization, which leads to a greater sense of loyalty to their foreign beneficiaries rather than to their employer or host country.\nRegardless of their motivation, insiders that commit intellectual property theft are generally employees that have access to intellectual property, such as engineer scientists, programmers or salespeople. Given that these insiders have authorized access to the intellectual property -- or perhaps are the creators of the intellectual property -- it can be very difficult to detect their malicious behavior.\nIn any discussion about behavior and behavioral characteristics, it is important to remind ourselves why we are looking to discover characteristics of insider theft of intellectual property. Detecting some of these characteristics does not mean that a malicious insider has been detected -- an understanding of these characteristics cannot be used to trap employees.\nIt can be used as input into a risk-based analysis of job positions at risk for intellectual property theft, to help understand the organizational elements that influence insiders to carry out theft and, most importantly, to develop and implement protection and mitigation strategies to protect an organization from malicious insider attacks.\nPatterns in insider intellectual property theft\nCERT/CC has worked on insider threats since 2002 and has since developed two models of IP theft: the entitled independent and the ambitious leader. Let\'s use the entitled independent as an example.\nThis is an insider who feels entitled to take intellectual property because they worked on it as an employee. The entitled independent insider has a personal predisposition that results in a sense of ownership and entitlement to information that they worked on and that they feel is their property -- they are unable to see that their work is a part of a team effort that belongs to their employer.\nThe sense of insider entitlement is intertwined with employee contribution, meaning that the greater the contribution, the greater the employee\'s feelings of entitlement. These entitlement feelings may also be amplified in the insider\'s mind if they perceive their contribution to be exceptionally important; for example, working on a flagship product.\nThe entitled independent may also experience job dissatisfaction that intensifies the feeling of entitlement. Job dissatisfaction and employee disgruntlement are similar to job satisfaction issues seen in insiders who perform IT sabotage. This behavior includes:\n- dissatisfaction with compensation, promotions, benefits, bonuses and relocation;\n- mergers and acquisitions;\n- conflicts with supervisors and co-workers;\n- layoffs; and\n- disagreement over who owns intellectual\nJob satisfaction issues frequently motivate insiders to look for new jobs, where one-third used the stolen intellectual property to get a new job and another third stole intellectual property just in case. For the entitled independent, issues of an inappropriate sense of entitlement mixed with job dissatisfaction and a desire to leave the organization may lead to an insider leaving with stolen intellectual property.\nWhat to do?\nUnderstanding that stolen intellectual property tends to be property that insiders have developed or contributed to is important when developing a strategy to protect it. A successful strategy should be able to:\n- Identify critical intellectual property assets.\n- Identify insiders who have worked on said assets -- either now or in the past -- as they are high-risk insiders.\n- Review access controls that protect intellectual property to identify insiders that no longer need access, such as people who have moved on to other projects or left the organization.\n- Create policies regarding access to critical intellectual property, including a periodic review of access privileges.\n- Create procedures that automatically disable access to intellectual property when employee roles change.\n- Consider temporarily disabling access to intellectual property when insiders travel outside of the country, take a leave of absence or go on vacation.', 'Insider threats have long been recognized as a problem by the Federal Government. The National Insider Threat Task Force (NITTF) was established by Executive Order in 2011. In part, it ordered all federal departments and agencies with access to classified information to establish insider threat detection and prevention programs “for deterring, detecting, and mitigating insider threats, including the safeguarding of classified information from exploitation, compromise, or other unauthorized disclosure.”\nAs insider threats continued to grow, the Federal Government increased its demands. In 2014, Directive 504 from the Committee on National Security Systems (CNSSD 504 – Protecting National Security Systems from Insider Threat) prescribed the minimum measures required for User Activity Monitoring (UAM) on all classified networks “to detect indicators of insider threat behavior,” and have the “technical capability to observe and record the actions and activities of an individual, at any time, on any device accessing U.S. Government information.”\nAt a minimum, this includes:\n- Key stroke monitoring\n- Capture of full application content (e.g., email, chat, data import, data export)\n- Screen capture\n- File shadowing for all lawful purposes\n- Ability to set triggers/alerts based on user activity\nWhat about Protecting User Privacy\nIn many jurisdictions, mostly outside of the U.S., organizations are subject to employee privacy regulations. In these countries, focused observation capabilities as described above would be disallowed as they would by design and deployment infringe on privacy regulations. Workforce Cyber Security’s approach is different from UAM however. For example, DTEX InTERCEPT’s patent protected ‘privacy-by-design’ architecture allows for proportional deployment of Focused Observation capabilities (where allowed) while protecting employees’ privacy rights. DTEX InTERCEPT is specifically designed to collect the minimum amount of data needed to build a forensic audit-trail in a privacy compliant manner—gathering only the application and user metadata necessary, and uses pseudo-anonymization that tokenizes raw data fields, including username, email, IP address, domain name, and device name. When evidence indicates a threat, select administrators can de-anonymize user identities for investigations.\nFocus on Threat Behavior, not Actions\nThe directive recognizes an important distinction—one we agree with wholeheartedly. Looking for specific actions by specific users on specific data is a dated and ineffective method for stopping insider threats (and requires too much overhead for rules creation and curation). Instead, CNSSD 504 focuses on “threat behavior”; the things insider threats do as part of the insider threat kill chain.\nFocusing on malicious behavior allows security and compliance teams to stop threats before they steal data or do harm. By understanding activities in context of Data, Machines, Applications, and People, Indicators of Intent can help SOC teams identify activities that provide “the tell” when malicious actors are performing reconnaissance, circumvention, aggregation, obfuscation—long before exfiltration.\nHow DTEX InTERCEPT Addresses UAM\nDTEX combines privacy-first User Activity Monitoring, Insider Threat Management, User and Entity Behavior Analytics, Digital Forensics, and Endpoint DLP. It provides organizations with the ability to meet the UAM requirements of Directive 504.\nCapture of Full Application Content\nIdentifying Indicators of Intent requires observing activities across Data, Machines, Applications, and People (DMAP). Our DMAP+ Technology™ provides a continuous audit trail of unique endpoint metadata to observe, record, and correlate the actions and activities of data, machines, applications, and people in near-real-time, including the full capture of all Session, Process, File System, and Window activities, on and off the organizational network.\nScreen Capture and Key stroke Monitoring\nWhen a user has been elevated for focused observation, DTEX provides application content monitoring (includes SSL inspection for web browser based activities), video/screen capture and key stroke capture. Capture can be based on specific device, application, user rules, or for individuals flagged as “persons of interest.” All captures can be exported for further analysis.\nMalicious insiders will often attempt to disguise (obfuscate) their actions by changing file names or extensions. DTEX continuously tracks documents, even when names and locations have changed, using configurable hashing algorithms including MD5, SHA1 and SHA256. It can determine the ‘lineage’ of a file to answer who, what, when, where, and why was a file was copied, modified, obfuscated or exfiltrated. DTEX also tracks file classification meta-data as well as the usage of the Alternate Data Stream (ADS) for advanced attempts to obfuscate data.\nSet Triggers/Alerts Based on User Activity\nWhen a skilled insider wants to steal data, they often separate their activities into smaller steps over a period of time to avoid detection. Alerting on every activity (which could be benign) can result in alert fatigue. DTEX has partnered with MITRE Corporation to advance Five Eyes capability for Insider Threat and Foreign Interference detection and mitigation.\n- Alert Stacking and machine learning capabilities combine behavioral rules and anomaly detection to reduce false positives and analyst overhead.\n- Automated Activity Correlation allows multiple disparate events to be attributed to a defined sequence of events occurring within a given time window.\n- This further improves true positive detection rates by elevating alert scores for events that occur sequentially across the full Insider Threat Kill Chain, over and above alerting rules triggered in isolation.\nDTEX also provides the ability to automatically increase monitoring and alerting mechanisms for high risk user populations (e.g., new joiners, leavers or “flight-risk” detected employees and individuals flagged as ”persons of interest”) and automatic correlation of these populations with insider threat related activities.']"	['<urn:uuid:c11fd271-6cb2-4b87-b6d2-ea3850f3f9df>', '<urn:uuid:083d5eb6-0de2-4e49-995e-7e613812bb91>']	factoid	direct	concise-and-natural	similar-to-document	three-doc	novice	2025-05-01T22:47:46.423955	7	64	1747
33	I work with digital archives and I'd like to understand the relationship between public domain status and digital copies - how does copyright expiration affect works entering the public domain, and what special considerations apply to digital reproductions of these works?	Works enter the public domain when copyright expires (70 years after creator's death in most cases) or through deliberate dedication by the owner. However, digital copies of public domain works, particularly photographs, are considered artistic products in their own right and attract new copyright protection under Australian law. This means that while the original work may be in the public domain, collecting institutions own the copyright to their digital reproductions and can charge for their use. It's important to note that online availability doesn't automatically mean something is in the public domain.	['Copyright & Fair Use\nA clearinghouse of copyright related information and resources including Fair Use, Public Domain, Getting Copyright Permission, and Creative Commons Licensing\nLibrarians can provide information and resources to help you navigate copyright related questions, but we do not give legal advice, as we are not lawyers. If you have specific legal questions pertaining to copyright and intellectual property, please contact the legal offices of your college.\nCopyright protection is outlined in Title 17 of the U.S. Code. There are several exceptions to copyright law, especially relevant to educators:\n- “The Classroom Use Exemption” (Limitations on exclusive rights: Exemption of certain performances and displays), Title 17, Section 110 of the U.S. Code\n- The TEACH Act (Technology, Education, and Copyright Harmonization Act, 2002)\n- Fair Use (see below)\n7C Copyright Resources:\nFair use is outlined in Title 17, Section 107 of the U.S. code.\nCopyright law describes 4 factors to aid in determining whether it is fair to use a work that is protected by copyright for the purpose of commentary or criticism. Keep in mind that weighing these factors is often very subjective and contextual. These 4 factors are:\n- The purpose and character of the use, including whether such use is of a commercial nature or is for nonprofit educational purposes;\n- The nature of the copyrighted work;\n- The amount and substantiality of the portion used in relation to the copyrighted work as a whole; and\n- The effect of the use upon the potential market for or value of the copyrighted work.\nIf you want to use a work in your course, publication, thesis, or dissertation it is a good idea to complete a Fair Use Analysis Checklist and keep a record of it in case you ever need to show you did the due diligence necessary to determine if your use falls under fair use.\nFair Use Resources:\n- Center for Media & Social Impact’s Fair Use, Free Speech & Intellectual Property – Tools to better understand how to employ fair use and the right to use copyrighted materials without permission or payment. Developed with and for educators and practitioners.\nPublic domain refers to creative works that are not protected by copyright and so can be freely used by anyone. Works fall under the public domain through:\n- Expiration of copyright\n- Failure to renew copyright\n- Dedication: the owner deliberately places it in the public domain.\nPublic Domain resources:\nPermission to use copyrighted material must be obtained when the use is not covered by copyright law, fair use, or educational exceptions. Permissions should be in writing and from the copyright holder. Retain copies of all of correspondences.\n- Sample forms, UT Austin\n- Sherpa Romeo is a database of publisher policies related to copyright and licensing permissions and the ability to self-archive in Institutional Repositories.\n- Copyright Renewal Database – A searchable index of the copyright renewal records for books published in the US between 1923 and 1963.\nPublishers don’t always make rights clear to authors. As an author, you have the ability to:\n- Negotiate with publishers to retain explicit ownership of your content\n- Transfer, via an author addendum, to the publisher only those rights needed for publication\n- Specify other rights of particular value to you or your home institution\n- Consider publishing with an organization that will facilitate the widest dissemination of your work in order to help you fulfill your personal and professional goals as a scholar\nSometimes external funders will require you to make your publications freely available. Even if you don’t have a funding mandate to do so, there are benefits to placing a copy of your publication in an institutional or disciplinary repository. Making research as widely accessible as possible will ensure that others can benefit and build on your work, especially those who don’t have access to expensive subscription databases.\nResources for negotiating your rights with publishers:\nCreative Commons (CC) is both a nonprofit organization, and a movement in response to expanding copyright protections. Using Creative Commons Licenses, artists and creators can proactively make their work available for public use, while specifying the conditions under which they are used now and in the future.\nCC Licenses are copyright licenses, and depend on copyright laws to work. CC is designed to remove some of the barriers that copyright law puts in motion. If a CC license is used, it is not necessary to get permission or to make an educated guess if fair use is acceptable. The license lays it all out.\nAttribution CC BY\n- This license lets others distribute, remix, tweak, and build upon your work, even commercially, as long as they credit you for the original creation. This is the most accommodating of licenses offered. Recommended for maximum dissemination and use of licensed materials.\nAttribution-ShareAlike CC BY-SA\n- This license lets others remix, tweak, and build upon your work even for commercial purposes, as long as they credit you and license their new creations under the identical terms.\nAttribution-NoDerivs CC BY-ND\n- This license allows for redistribution, commercial and non-commercial, as long as it is passed along unchanged and in whole, with credit to you.\nAttribution-NonCommercial CC BY-NC\n- This license lets others remix, tweak, and build upon your work non-commercially, and although their new works must also acknowledge you and be non-commercial, they don’t have to license their derivative works on the same terms.\nAttribution-NonCommercial-ShareAlike CC BY-NC-SA\n- This license lets others remix, tweak, and build upon your work non-commercially, as long as they credit you and license their new creations under the identical terms.\nAttribution-NonCommercial-NoDerivs CC BY-NC-ND\n- This license is the most restrictive of our six main licenses, only allowing others to download your works and share them with others as long as they credit you, but they can’t change them in any way or use them commercially.\nThe CC0 tool\n- This allows licensors to waive all rights and place a work directly into the public domain.', 'Copyright: the basics\nWhat is copyright?\nCopyright is a set of rights that provide protection for all kinds of artistic products. It protects them from being copied, changed or exploited and acknowledges that the artistic product belongs to someone.\nIn Australia copyright is free and exists automatically once an artistic product is created.\nIt is determined by the Copyright Act 1968.\nCopyright can be denoted using the © symbol. Failing to display the © symbol does not extinguish copyright.\nWho has it?\nCopyright is owned by the creator and/or by a collecting institution.\nIf the creator is commissioned or contracted to make the work, or if it is made under normal employment, the standard copyright rules can change. For example:\n- When a work is created as part of regular employment the copyright is generally owned by the employer.\n- When a work such as a painting or photograph is commissioned or made under contract the commissioning organisation/person usually holds copyright. However this may not apply if the artist is working freelance.\n- With films and sound recordings the producer usually own copyright though in some situations performers can share copyright.\nIt is critical to have a contract which clearly specifies the terms of copyright.\nHow long does it last?\nIn Australia copyright begins when the work is created and generally lasts 70 years after the death of the creator.\nExceptions occur: copyright on sound recordings last 70 years from the date of the first publication and copyright on published written work is 25 years post publication date.\nOnce copyright lapses the work is considered in the ‘public domain’ which means that anyone can use it.\nFor example, copyright has expired on photographic images and negatives (although not their digitised copies) taken before 1955. For any photographs taken from 1955 on, copyright is for 70 years after the death of the creator.\nOther countries have different copyright rules and timeframes.\nThere are two main ways of managing copyright which are used when an organisation or an individual want to reproduce or use a copyrighted work which is not their own.\nThe copyright owner can either assign or licence a third party which transfers all, or some of the rights associated with copyright to that person/organisation.\nBoth these transfers must be done in writing and the process is best done with legal advice and a formal contract.\nBe aware that it is not necessary to register something for copyright, though there are organisations in Australia who can manage licencing fees resulting in use and publication of work. See Copyright Agency, Viscopy, and the Australasian Performing Right Association (APRA).\nWhat about Indigenous work?\nCopyright and intellectual property rights of Indigenous cultural product may vary from the Copyright Act because ownership is often intergenerational and group-owned.\nAppropriation of Aboriginal imagery such as pattern, motifs, spiritual figures, or story by non-Indigenous artists is considered as cultural theft and a breach of cultural protocols.\nThere are specific protocols and permissions around using and taking photographs of Aboriginal people that should be observed and having signed model release forms is desirable.\nArts Law suggests that Indigenous copyright be clarified through contract. They are specialists in the field with an Aboriginal liaison officer who can provide advice and the dedicated Artists in the Black website. Arts Law offers workshops which provide an in-depth explanation of Indigenous copyright issues and the implications of breaching protocols.\nProvisions for collecting institutions\nUnder Australian copyright law collecting institutions are allowed to copy material in their collections to maintain and conserve the collection as long as the collection is not-for-profit.\nMuseums and galleries fall under the definition of an ‘archive’ which is considered by law to be “a collection of material of historical significance or public interest, being maintained for the purpose of conserving and preserving the material.” (Australian Copyright Council, Information Sheet G068v07)\nKey collection institutions (defined as those holding an archive of material which is of historical or cultural significance to Australia) can make three preservation copies of original material, editions, films and sound recordings. Other collecting institutions can make one copy of the original version for preservation.\nThese images, usually photographs, also carry copyright which is owned by the collecting institution.\nMoral rights are different to copyright and exist as a complementary set of rights or obligations that must be observed when collecting, displaying or exhibiting artworks or objects.\nMoral rights include correctly and accurately attributing the creator of the work and caring for, or displaying the work in a way that does not prejudice the creator’s reputation or honour.\nWhat’s the public domain?\nWhen copyright has formally expired the material is considered to be in the public domain. This means that people can use it without seeking permission.\nExceptions exist: all digital copies of old photographs currently attract copyright under Australian law, as digital images are considered to be an artistic product in their own right.\nCollecting institutions own copyright on these images and are entitled to charge for reproductions/prints of them.\nIt’s important not to confuse online availability with something being in the public domain. Online images are often subject to the same copyright rules and have restrictions on their use.\nWhat is a Creative Commons licence?\nProviders such as Google Images, Flickr and Wikipedia Commons offer access to digitised material through the Creative Commons licence. A range of licences are available, most of which require attribution to the creator and a declaration if changes have been made to the work. Creators are able to limit the type of use or adaption.\nFor more information: Creative Commons Australia\nWhat if it’s on social media?\nStandard copyright law usually applies: users own and retain copyright of what they post, create, or contribute to a website, social network or other online service.\nThere are exceptions. Tweets, comments and short phrases of text are usually considered to be outside copyright because they are of general usage and no significant individual contribution to ownership can be demonstrated.\nBest practice in using this kind of material is to request permission from the contributor and to document the response. If an organisation is using shared material via social media it is a good idea to ensure the Risk Management Policy outlines responses to copyright breaches.\nIn signing up to, or opening an account on many social media platforms such as Twitter, Facecbook and YouTube, users agree to give permission for their material to be shared. In most situations privacy settings can be altered to control some of the ways the provider uses and distributes the material.\nSocial media is a complex copyright area and in many cases the technology means that copyright and breaches of it is difficult to control.\nBe aware that …\nCopyright does not protect ideas, information, techniques or style. It does not protect names, slogans or titles.\nWhile all care has been taken to ensure information is accurate at the time of publication, all information in this resource is intended as a guide only. You should obtain professional advice if you have any specific concerns.\nYou may also like:\nArts Law: Frequently asked questions\nAustralian Copyright Council: Find an Answer']	['<urn:uuid:dbba0dd4-8d1c-4dbc-a706-75439a3d8b89>', '<urn:uuid:8762d37b-b983-4562-862d-61f88da64fc5>']	open-ended	with-premise	verbose-and-natural	similar-to-document	multi-aspect	expert	2025-05-01T22:47:46.423955	41	92	2191
35	What solutions exist for wildlife conflicts in energy facilities?	Various solutions are implemented to address wildlife conflicts in energy facilities. For power substations, utilities use polymer coverings and animal guards on poles to prevent squirrels, snakes, and raccoons from causing outages. For birds near wind turbines, operators employ radars and cameras to prevent collisions, as turbines kill between 140,000-328,000 birds annually. In nuclear facilities, additional filters are installed to prevent jellyfish from clogging intake pipes. For bald eagles affected by disturbances like hunting noise near Lake Buchanan, protective measures include federal laws prohibiting activities that would 'disturb' the birds from breeding, feeding, or taking shelter. Additionally, some utilities build alternative nesting platforms to relocate raptor nests away from power poles.	"['From 2015 to 2019, an average of four birds per year came to Lake Buchanan—less than half of the 10.4 average for the five years before that. Could the noise from hunters be to blame?\nTim Mohan is intimately familiar with Lake Buchanan, the northernmost of the six Highland Lakes that squiggle through the Hill Country toward Austin. The outdoorsman can point out all the most interesting spots: Barringer Hill, on Buchanan’s western side, where rare earth metals were discovered in 1886 but later were lost to the lake; Buzzards Roost Creek, where turkey vultures catch warm thermals in their unyielding quest for carrion; and the intermittent waterfall aptly dubbed Seldom Falls.\nMost importantly, Mohan, a tour guide for Vanishing Texas River Cruises near the town of Burnet, knows about the bald eagles. Each year starting in November, the birds arrive from North America’s frigid northern expanses to temporarily roost in the scrub brush dotting Lake Buchanan’s austere canyon faces. Some are juveniles still honing their dive-bomb fishing technique; others are majestic, white-faced adults with eight-foot wingspans. “If you could see one of these mature birds, it’s phenomenal,” Mohan says. “It just knocks your socks off.”\nOn a chilly November morning, Mohan sits at the bow of a two-deck cruise vessel, binoculars in hand and a microphone affixed to his cheek. The boat charts a path northward as he regales the 60 or so passengers with trivia about the lake’s history (it was created by damming the Colorado River in 1939) and dimensions (measuring 31 miles long and five miles wide, it’s the largest of the Highland Lakes). But the spiel is merely a warm-up act for the main event: the bald eagles.\nThe problem is, there aren’t many to see today.\nAbout halfway through the three-hour tour, there are no eagles to be found. Mohan’s frustration starts to show. “I’m more than a little irritated we haven’t spotted any yet,” he tells the passengers. “That’s just not right.” After all, the bald eagles are what folks come to see from across the state. Streets and housing developments in Burnet are named after our national bird; eagle-themed shirts, koozies, and wine stoppers are sold in the lakefront gift shop; even this vessel is named the Texas Eagle.\nMohan and others familiar with the visiting bald eagles say that their numbers on the lake seem to be dwindling. Annual surveys show that the birds’ population has fallen to the lowest numbers since tracking efforts began in the late 1970s. From 2015 to 2019, an average of four birds per year came to Lake Buchanan—less than half of the 10.4 average for the five years before that. And no one’s exactly sure why. Climate change has messed with the birds’ migratory patterns, pushing eagles from southern to northeastern states. But a theory is also being floated that hunters illegally shooting ducks on Lake Buchanan may also be driving the eagles away. “Last year, their numbers were down considerably. We speculated if it wasn’t due to duck hunters,” Mohan says.\nIt’s not just idle speculation—Mohan and Shawn Devaney, the boat’s captain, have seen duck hunters setting up blinds both on the shoreline and in the water, despite rules prohibiting hunting in the area. And last year, Mohan says, a hunting party let off a shot just as the boat passed. “It was loud. You could tell it was a shotgun going off.” Devaney notes that it’s impossible to know to what degree hunters are contributing to the decline in the number of birds in the area, “but a bunch of shotguns going off while eagles are trying to roost isn’t good.”\nThere’s evidence to suggest that loud noises could drive the birds away, especially in a river canyon where tall walls echo and amplify noises. Near Chicago in 2012, environmentalists cried foul when police proposed a new shooting range adjacent to wetlands where bald eagles nest; they said gun noises could put the city in violation of federal law prohibiting disturbing the birds (the eagles prevailed and the range wasn’t built). At the University of Minnesota, researchers are using sounds to drive bald eagles away from wind turbines, which endanger the birds during their annual migration. This year, university researchers in Ireland showed that noise created by humans has an outsized effect on birds and other species. “Consequently, anthropogenic noise must be considered as a serious form of environmental change and pollution,” it said.\nAlthough the number of bald eagles roosting at Lake Buchanan seems to be dropping, nationwide the population is thriving. For the most part, the species has made a remarkable recovery since the 1970s, when it teetered on the brink of extinction. At that time, eagles were being killed by fisherman trying to protect their catches. They were also ravaged by the now-outlawed pesticide DDT, which was ingested by fish and then passed onto the eagles that ate them, making their eggs too fragile for chicks to reliably hatch.\nIn 1972, DDT was banned in the United States. One year later, the federal Endangered Species Act was passed and the bald eagle was listed as being endangered, granting it new protections. In the decades since, their numbers have bounced back so drastically that bald eagles were removed from the endangered species list in 1997. The laws, however, still forbid people from engaging in activities that would “disturb” the birds from breeding, feeding, or taking shelter.\nThe Lower Colorado River Authority (LCRA), which owns Lake Buchanan and the other Highland Lakes, forbids hunting on its water and land. A spokesperson told the Observer that it wasn’t aware of any duck hunting happening at Buchanan. LCRA employs “rangers” to police the lake, but citing “security reasons,” the spokesperson would not answer questions regarding how many of them are assigned to Buchanan or how frequently they patrol. Cody Hatfield, a supervisory state game warden who oversees compliance with state hunting rules in Burnet and surrounding counties, also said he hasn’t seen duck hunters on the lake—but he admits he doesn’t patrol the lake itself.\nCharles Tishcler, who’s conducted the annual count of bald eagles every year since 1979, has seen the hunters. The first time was in 2015, when he spotted one wielding a “long-barreled goose gun” on a boat in the Canyon of the Eagles. Since then, he’s spied more: “They have their duck decoys out and it’s just like, boom, boom, boom. You’ve got three guys with automatic shotguns and it turns into quite the tune,” he says.\nTischler said he reported the hunting activity to LCRA and to the Texas Parks and Wildlife Department, which regulates hunting in the state. Nothing ever came of it, he says. Tischler fears that if officials allow hunting to continue in this area, the eagles may decide to roost somewhere else completely—leaving this rugged and wild part of the state without its seasonal mascot. “I thought we’d lose the eagles to straight-out [housing] development,” he says. “I never saw this coming.”\nBack on the Texas Eagle, from the second deck, Devaney announces over a loudspeaker that he may have spotted the first bald eagle of the day: a juvenile, resting in a copse of cottonwood atop a cliff to the west. Tourists rush to the window to catch a glimpse, but even with binoculars, the bird was just a blip in the sky. Was it a trick of the eye? Hard to say. Later on, after the boat turned south to return to shore, Devaney spots another one. This is a definitive sighting: a brown-feathered juvenile racing south, blurring past juniper and cacti. The passengers watch in wonder until the bird comes to rest on a branch, immediately blending in with the canyon wall.\nAlmost as quickly as it appeared, the eagle vanishes.\nRead more from the Observer:\nAs Port Neches Plant Smolders, Trump Rolls Back Safety Rules for Chemical Plants: After a deadly explosion in the town of West in 2013, Obama implemented stricter safety rules for chemical plants. Trump’s EPA has just undone them.\nWhy I Started a Book Club in the Harris County Jail: Education programs make jails safer and reduce rates of recidivism when people reenter society.\nThe Last Nurse in Memphis, Texas: Carole Ward, a former nurse practitioner, ran the only health clinic in a small town in the Panhandle until she retired in 2017.', 'It’s no secret the power sector faces many challenges. But while serious arguments swirl around the future of utility business models, cutting-edge technologies and wonky policy issues like rate design, there is another challenge that utilities face on a very regular basis that doesn\'t often make headlines: Animals.\nFrom squirrels to jellyfish to a certain species of two-legged mammals, utilities have to share their service territories with critters who are not (usually) paying customers. And those critters can cause utilities some major headaches — such as the time when a single monkey took out an entire country’s grid.\nUtilities will tell you planning for animal-related challenges on the grid is just part of the daily grind. Here are some of the animal problems they face.\nForget about cyber hackers. Squirrels represent a far greater threat to the power grid, the anonymous creator of CyberSquirrel, a website that tracks squirrel-related outages, told the Washington Post.\nJust ask any of the Wall Street traders who couldn’t trade roughly 20 million shares on the NASDAQ in 1987 when a squirrel took out one of their computer centers. That may be the most dramatic example, but squirrels are a real and frequent problem for utilities.\n""[T]here is tons of hype about how we are at so much risk from a devastating cyber attack and yet we can\'t even protect our infrastructure from squirrels, or birds or snakes,"" the site\'s creator told The Post.\nThere were 89 outages related to squirrels this year, according to the Eaton Blackout Tracker, but it\'s not just them. Though they may be the furriest and nuttiest animal causing mayhem on the grid, snakes and raccoons can also do their fair share of damage. Animal-related outages overall are the number 5 cause of power outages in the U.S., according to Eaton, with 149 total outages this year.\nProtecting a substation against animal intruders can cost upwards of millions, the Eaton report found. But beyond eliminating wildlife entirely, there’s not much a utility can do, except for finding ways to stop them dead in their tracks — humanely, of course. Some of these strategies include wrapping vulnerable parts of substations in polymer covering, as well as putting animal guards on poles and other materials to ward off curious critters.\nNotably, zero blackouts caused by a cyberattack have been reported thus far in the past year. But blackouts aren’t the only headaches caused by animals.\nOnce you build something, it’s hard to keep animals away: Eagles like to perch on power lines. Squirrels and snakes climb into substations. If that wasn\'t hard enough, what do you do when you build something directly on an animal\'s home? Just ask the fish.\nHydro facilities have long threatened their migratory patterns and stream flow. Utilities in particular have often come under fire the ways dams impact trout streams and other aquatic life. Because many dams were built long before current environmental regulations, mitigation requirements today are more reactionary. But as Avista Corp., a Pacific Northwest utility in Washington, has found out, mitigating for aquatic species is just part of the job.\n“[Fish] are part of the natural environment, right? [And] it’s part of our mitigation impact of dams,” Bruce Howard, Avista’s director of environmental affairs, told Utility Dive. Avista declined to give cost estimates, citing the complex accounting that goes into environmental mitigation. Fish can\'t mutiny, exactly, but eventually dams outlive their usefulness and are retired, freeing up the roadways ... or waterways, once more.\nConcerns around aquatic life have even led some hydropower plants to be retired. Take the four hydroelectric dams in California and Oregon, which are involved in the biggest dam removal thus far. A coalition of tribes, environmental groups, and utilities including PacifiCorp hashed out a plan to begin a $450 million project to restore the river, streams and aquatic life by shutting down the dams.\nThe right perch\nIf you\'re an osprey or eagle looking for a nice and high perch for a nest, what better place can you find than a power pole? Well, that\'s not how utilities see it.\n“Raptors are naturally drawn to power poles because they offer a high place to perch, roost, nest and hunt,” Jenna Shaver, a spokeswoman for Arizona Public Service Co., told Utility Dive in an email. “The large wing spans of raptors, however, make them vulnerable to harm by the electricity being carried on the power lines.”\nIt also makes them more vulnerable to feral cats, who might try to scale those poles in search of lunch, Shaver said. That’s especially bad if those species are endangered.\nSometimes a little gullibility also goes a long way. Putting animal guards on power poles and setting up false poles a little ways down from the real ones are two options to help mitigate for these issues, an Avista spokesperson told Utility Dive. APS has built platforms to relocate the nests to avoid an electrifying death for the chicks. Eventually, the birds warm to their new home, returning for years to the same nest, never realizing they were fooled.\nJellyfish go for nuclear option\nFor nuclear plants, jellyfish may be their biggest animal threat. Swedish operators scrambled to shut down a nuclear reactor two years ago after a bunch of spineless aquatics slipped through filters and clogged the plant\'s intake pipes.\nThat\'s not the first time that sea creatures have caused trouble for nuclear facilities. Pacific Gas & Electric’s Diablo Canyon nuclear plant — now slated for shutdown for unrelated reasons — also shuttered two of its reactors after gobs of sea salp, a type of plankton, jammed the pipes.\nThis isn’t a new phenomenon, by any means. (Nor is it a plot by the gelatinous creatures to take over the sea world.) But marine biologists have warned it could get worse due to the impacts of climate change.\n“What we’ve seen as you increase temperature … you get massive blooms,” said Dr. Vicki Martin, a professor of biology at North Carolina State University. “Jellys seem to be liking this and increasing worldwide to the point they are clogging power plants. What happens that when you get these numbers of jellyfish continuously ... because there are so many of them, they clog the filters so they shut down.”\nOver the past 15 years, summers have warmed with 2016 being the hottest summer on record so far. As temperatures rise, oceans absorb the excess heat, which also boosts temperatures. Since jellyfish thrive in warmer water, Martin says more blooms are likely on the way, including from species of jellyfish making their way into regions where they never lived before.\nHer advice to nuclear plant operators? Install more filters.\nBirds in the wind\nClean energy is great — until it kills things.\nTake wind power: Researchers estimate monopole wind turbines kill between 140,000 and 328,000 birds in the U.S. every year. And the taller the poles, the more deadly the turbine.\nUnder the Migratory Bird Treaty Act, it’s illegal to kill protected birds, even if it’s accidental. So the stakes are high for wind turbine operators to prevent bird deaths. There are many ways that operators try to save birds with technology like radars and cameras.\nBut wind farms aren’t the only clean energy resource with a deadly side. Solar has done its fair share in sizzling creatures who venture too near.\nConcentrated solar’s Icarus problem\nIt’s like the tale of Icarus, who flew too close to the sun, singed his wings and fell back to the earth. Only this time the real story is about the birds who flew too close to a solar farm in the Mojave desert.\nLast year, the Wall Street Journal reported the Ivanpah concentrated solar project killed roughly 3,500 birds during its first year of operation, sparking concerns from environmentalists. The Los Angeles Times pegged the number of deaths a little higher — at 6,000 deaths a year.\nAccording to the Los Angeles Times, the concentrated solar farm\'s operators have replaced the flood lights with LEDs, rearranged the mirrors and installed anti-perching spikes to the solar towers in hopes of reducing bird deaths.\nAnimal deaths caused by wind and solar may contain an element of spectacle, but renewables advocates are quick to point out they are much more humane than their fossil fuel counterparts. According to a U.S. News review of available literature, coal production and generation kills nearly 8 million birds annually, while wind and solar combine for less than 500,000.\nLet\'s not forget what may be the most disruptive animal species of them all: Humans.\nMost of you may remember the blimp that escaped its moorings last year, floating from Maryland to Pennsylvania and knocking out power for thousands along the way. It inspired memes, social media commentary and even a reference during the presidential primaries. (Then-candidate Mike Huckabee referred to the federal government as a ""runaway blimp"" at a Republican primary debate after the incident.)\nWhile that may be a particularly notable incident, the most common human-related mishap on the grid is humans running their vehicles into power poles. According to the Eaton Report, 419 of outages were vehicle-related. Other than promoting responsible driving, there doesn’t appear to be any other deterrent.\nBut from cyber hacks to sniper attacks, not all human-related disruptions on the grid are accidental. Sometimes, a utility’s worst enemy can be the very people they serve.']"	['<urn:uuid:bcda076c-2dd8-48d0-8321-58de9a18d9cf>', '<urn:uuid:05889604-6292-41e6-927a-3e9b3d6133a1>']	open-ended	direct	concise-and-natural	distant-from-document	multi-aspect	expert	2025-05-01T22:47:46.423955	9	111	2959
38	I'm worried about both my heart health and digestion - should I stick to low-fat dairy products, and what digestive problems might dairy cause?	For heart health, you should use nonfat or 1% low-fat dairy products, such as milk, yogurt, sour cream and cottage cheese, and choose reduced fat versions of your favorite cheeses. Some people may experience food intolerance to dairy products, which affects digestion and can be identified by keeping a food diary to track symptoms. Unlike food allergies, food intolerance only affects digestion rather than causing respiratory problems or hives.	['To lose weight, how many calories should I eat a day?\nTheoretically, a deficit of 500 calories per day should promote one pound of weight loss per week. Here are the numbers:\n- 500 calories x 7 days = 3500 calories = 1 pound of body fat\nEven small changes in your diet can add up over time. If you eat just 150 calories less each day for one year that translates to almost 16 pounds you could lose.\nFollow these heart healthy and calorie-saving steps to launch you towards your goals of a healthy weight.\nSimple Steps to a Healthy Heart and Weight\nThe Plate Method\nOne of the best ways to control calories is to control portions. Try serving foods with these tips in mind:\n- Fill one quarter of your plate with lean protein. This portion size fits within palm of your hand. Lean protein sources include poultry, fish, seafood, lean beef (round, loin, flank), lean pork (tenderloin, Canadian bacon), tofu and eggs.\n- Fill another quarter of your plate with starch. Starches are foods like bread, rice, pasta, cereal, potatoes, yams, and beans. Choose most of your starches from whole grains, such as whole wheat bread or tortillas, brown rice, whole-wheat pasta, whole grain and bran cereals, or beans. Expand your whole grains to include barley, bulgur, quinoa, millet, teff, and farro.\n- Fill the other half of your plate with non-starchy vegetables, like salad and other greens, broccoli, carrots, and tomatoes.\n- If desired, add a fruit or cup of milk or yogurt to your meal, or enjoy as a snack later.\nEating the right amount and getting adequate exercise helps with weight control. Overeating can lead to weight gain. Choosing lean meats and lower fat dairy products helps with weight control and heart health. That’s because the animal fats tend to be “saturated” fats which are not heart healthy. Control calories and improve nutrition by following these tips:\n- Choose leaner proteins:\n- Avoid fatty meats like bacon, sausage, ribs and hot dogs.\n- Choose lean cuts of meat, such as “loin” and “round”.\n- Eat up to 6 to 8 ounces of lean meat, poultry or fish daily.\n- Trim visible fat from meat and remove skin from poultry.\n- Try vegetarian protein alternatives, like soy products and tofu.\n- Choose lower fat dairy products:\n- Use nonfat or 1% low-fat dairy products, such as milk, yogurt, sour cream and cottage cheese.\n- Buy reduced fat or low-fat versions of your favorite cheeses. Some cheeses, like mozzarella and ricotta, are naturally lower in fat.\n- Avoid cream, cream sauces and creamed soups.\n- Limit added fats in recipes and watch the condiments:\n- Strictly limit butter and hard stick margarine. Choose margarine labeled “no trans-fats”.\n- Avoid tropical oils (coconut and palm oils).\n- Choose liquid oils instead of solid fats (but control intakes as all fats are equally dense in calories).\n- Try reduced fat or nonfat versions of condiments, like salad dressings, mayonnaise, sauces and gravies.\nMore helpful tips:\n- Avoid fried foods. Try baking, broiling, barbecuing, steaming, boiling, light sautéing, grilling, poaching and braising.\n- Use a non-stick cooking spray to coat a pan instead of butter, margarine or oil.\n- Drain and discard visible fat when cooking.\n- Limit dining at fast-food restaurants.\n- Read Nutrition Facts labels on food packages. Choose foods with low or no saturated fat, trans fat, or hydrogenated fat. A low-fat choice is 0-3 grams of fat per ounce of meat or cheese, or 0-3 grams of fat per serving for other items.\n- Soluble fiber can help reduce blood cholesterol levels. Foods high in this type of fiber include oats, dried beans, split peas and lentils.\n- Include at lease 5 servings per day from a combination of fruits and vegetables.\n- Exercise more. Exercise does not have to be strenuous. Walking is an excellent form of exercise. Try to engage in at least 30 minutes of exercise per day.\nSelf assessment quizzes are available for topics covered in this website. To find out how much you have learned about Managing Your Weight, take our self assessment quiz when you have completed this section. The quiz is multiple choice. Please choose the single best answer to each question. At the end of the quiz, your score will display. If your score is over 70% correct, you are doing very well. If your score is less than 70%, you can return to this section and review the information.', 'What are digestion problems?\nThe digestive system is an intricate and extensive part of the body. It ranges all the way from the mouth to the rectum. The digestive system helps your body absorb essential nutrients and is responsible for getting rid of waste.\nDigestion problems can mean more than unwanted symptoms. Minor problems that are left untreated can lead to more serious, chronic illnesses.\nBecause there are so many different types of digestion problems, you might mistakenly dismiss them. It’s important to understand common digestion problems — as well as emergency symptoms — so you know when to talk to a doctor.\nChronic constipation indicates a problem with getting rid of waste. This most often occurs when the colon can’t pass or move stools through the rest of the digestive tract. You may experience abdominal pain and bloating as well as fewer bowel movements (which are more painful than usual).\nChronic constipation is one of the most common digestive problems in the United States.Getting enough fiber, water, and exercise will likely help curb constipation. Medications can also provide relief in more serious cases.\nFood intolerance occurs when your digestive system can’t tolerate certain foods. Unlike food allergies, which can cause hives and respiratory problems, an intolerance only affects digestion.\nSymptoms of food intolerance include:\nFood intolerance is usually diagnosed by keeping and reviewing a food diary. Recording what you eat and when can help you identify which foods are triggering your symptoms.\nCeliac disease, an autoimmune disorder, is one type of food intolerance. It causes digestive problems when you eat gluten (a protein in wheat, barley, and rye). People with celiac disease must follow a gluten-free diet to minimize symptoms and damage to the small intestine.\nHeartburn is an occasional occurrence for many adults. This happens when stomach acids go back up into the esophagus, causing chest pain and the trademark burning sensation.\nIf you have more frequent heartburn, you might have gastroesophageal reflux disease (GERD). Such frequent episodes can interfere with your daily life and damage your esophagus.\nSymptoms of GERD include:\n- chest discomfort\n- dry cough\n- sour taste in the mouth\n- sore throat\n- swallowing difficulties\nYou may need medications to control heartburn. A damaged esophagus can make swallowing difficult and disrupt the rest of the digestive system.\nInflammatory bowel disease (IBD) is a type of chronic swelling. It affects one of more parts of the digestive tract.\nThere are two types of IBD:\n- Crohn’s disease: affects the entire gastrointestinal (GI) tract but most commonly affects the small intestine and the colon\n- ulcerative colitis: affects only the colon\nIBD can cause more general digestive ailments, such as abdominal pain and diarrhea. Other symptoms can include:\n- incomplete bowel movements\n- loss of appetite and subsequent weight loss\n- night sweats\n- rectal bleeding\nIt’s important to diagnosis and treat IBD as soon as possible. Not only will you be more comfortable, but early treatment also reduces damage to the GI tract.\nA gastroenterologist is a doctor who specializes in diagnosing and treating diseases involving the digestive system. If you continue to experience digestion problems, it’s time to make an appointment.\nSome signs are more serious and could mean there’s an emergency medical problem. These signs include:\n- bloody stools\n- continuous vomiting\n- severe abdominal cramps\n- sudden, unintentional weight loss\nYou may be able to overcome digestion problems with treatment and lifestyle changes. Certain diseases of the digestive system might be long-term, but medications can help alleviate symptoms.\nIdentifying specific digestion problems and talking with a gastroenterologist can go a long way in terms of helping your doctor give you a proper diagnosis. Remember, you don’t have to put up with constant digestive issues.']	['<urn:uuid:f690838c-3bae-4709-806a-01b369ad49d2>', '<urn:uuid:63d74562-05c7-4f43-ba1a-10090daa58ae>']	factoid	with-premise	verbose-and-natural	similar-to-document	multi-aspect	novice	2025-05-01T22:47:46.423955	24	69	1377
39	What factors affect school closures and what business impacts need planning?	School closure decisions consider student safety factors including road conditions, temperature, wind chill (safe until -15 degrees with proper clothing), and whether it's a walking district. For businesses, closures require advance planning for production schedules, possible temporary workers for backlogs, overtime pay arrangements, and coordination with payroll companies to ensure timely payment. They also need procedures to notify customers and vendors of closures.	"['Many factors affect school closing, delay decisions\nWhen snowflakes fly or temperatures drop, students wish for just one thing a snow day. Or at least a two-hour delay of school.\nWhen the inevitable Western Pennsylvania winter weather issues arise, area superintendents are faced with the challenge of deciding if school can begin on schedule.\n""Obviously, the health, safety and welfare of our students is our first concern,"" West Mifflin Area School District Superintendent Dr. Janet Sardon said.\nLast week\'s series of snowfalls and frigid temperatures led many districts to delay early in the week and cancel school completely Friday. Typically, the decision-making process begins in the early hours with superintendents checking everything from road conditions to forecasts beginning as early as 4 a.m.\nIn South Allegheny School District, that\'s about the time the maintenance staff reports for work and begins clearing the school grounds and sidewalks, district public relations coordinator Laura Thomson said. District Facilities Manager Mark Zidek also checks conditions in the four boroughs that make up the district Glassport, Port Vue, Liberty and Lincoln so he can give Superintendent Wayne P. Gdovic a full report regarding roadways. Administrators often consult with local police departments, public works crews and district maintenance workers to help them determine if conditions are safe for travel.\nThough most municipal maintenance crews don\'t take their cues from the district\'s schedule, most are aware that student safety will be a concern when road conditions aren\'t favorable.\n""I always keep in the back of my mind that there\'s going to be school tomorrow,"" McKeesport Public Works Director Nick Shermenti said. ""We (plow or salt) the main arteries, the hospital routes and the bus routes first. Then we hit the neighborhoods.""\nSuperintendents will look to their counterparts in neighboring areas as additional information sources. Norwin School District Superintendent Dr. John Boylan said he telephones personnel in nearby districts as early as 5 a.m.\n""We share information related to road conditions and what the weather might bring over the next few hours,"" he said. ""Although each superintendent has his or her own unique geographic situation, there is always information that is useful in the decision-making process.""\nMany districts also put in a call to their bus company. Elizabeth Forward School District spokeswoman Jane Milner said Superintendent Bart Rocco must decide by 5 a.m. whether to delay or cancel and makes his decision, in part, by talking with the terminal manager at Pennsylvania Coach Lines.\n""We have special concern about rural roads in Forward Township and some in Elizabeth Township,"" Milner said.\nIcy roads are not only a danger for motorists, but for children waiting for transportation.\n""We sometimes see \'slippages,\' with cars going into bus stops and injuring the students there,"" said Dr. Michael B. Brinkos, superintendent of McKeesport Area School District.\nEven when roads are clear, temperature still can be a factor for a school delay or cancellation. ""Walking districts"" areas that do not have bus service such as Clairton City, Duquesne and Steel Valley school districts are especially sensitive to air conditions because students may walk several blocks from home to school.\n""Since we are a walking district, we always consider temperature and wind chill,"" Clairton Superintendent Dr. Lucille Abellonio said. ""Beyond that, we look at snow accumulation and forecasts from the day. We also discuss the roads with the bus company that transports our students to other schools (outside the district).""\nSarah McCluan, director of communication services for Allegheny Intermediate Unit, which oversees Duquesne City School District, said there isn\'t a ""magic number"" for a delay or cancellation.\n""There\'s not a set temperature that\'s the turning point,"" she said. ""It\'s more of a combination of what information administrators have available from weather reports and local media. It\'s really about the health and safety of our students.""\nThe National Weather Service notes that people can be outside for 30 minutes at wind chills as low as minus 15 degrees without danger, if they are properly dressed. NWS recommends dressing in several layers of loose-fitting, lightweight, warm clothing as air trapped between the layers provides insulation. Officials also recommend wearing a hat, as half of a person\'s body heat can be lost from his or her head, and covering your mouth to protect lungs from extreme cold.\nPrivate and parochial schools include a unique factor in their decision from where their students are coming as these schools often have children from a number of districts making up their population. Propel Schools in Pittsburgh, which operates charter elementary schools in several communities and a high school in Munhall, follows the local public school district\'s determination.\n""If the district in which the school building is located is closed, then that Propel school is closed,"" Superintendent Dr. Carol Wooten said. ""For instance, if McKeesport Area School District is closed, Propel McKeesport is closed.""\nSerra Catholic High School in McKeesport looks at its largest ""feeder districts,"" which include McKeesport Area, Elizabeth Forward, East Allegheny, Woodland Hills, South Allegheny and Pittsburgh Public Schools, to determine if its day will change.\n""We\'re really at the mercy of our largest school districts,"" said Vice Principal Diane DiNardi, who, along with Principal Timothy Chirdon, ultimately makes the decision to close or delay. ""When we see that the majority of our largest feeder schools are delayed, we typically also delay.""\nThe local public school district often provides transportation for students who attend parochial and private schools, which also contributes to those schools\' decisions. Dr. Robert Paserba, superintendent for Catholic schools in the Diocese of Pittsburgh, and Trent Bocan, superintendent for the Diocese of Greensburg, said principals generally follow the same schedule of the school district in which their building is located.\nProblems can arise when some of a school\'s feeder districts delay or cancel, while others operate on a regular schedule.\n""It creates some havoc here,"" DiNardi said. ""Some of our students come in late, and some of them will be here when we (in administration) aren\'t here yet.""\nBocan said the school tries to be accommodating in such situations and leaves transportation decisions to parents.\n""Principals get a lot of calls from parents asking if they should drive their children to school when the district they live in delays but their child\'s school does not have a delay,"" he said. ""We tell them to just use their judgment and, if they can get here safely, to do so if they wish.""\nIf a child misses school because of weather, it is considered a legal, excused absence under most circumstances. Most school officials said they wait until the morning to call for a two-hour delay or cancellation but will make the occasional exception.\n""I\'m sure each of us can recall times when weather forecasters predicted something dire during the evening news only to have the morning turn out to be very manageable,"" Boylan said. ""However, if the indicators are clear that the morning will require a delay or cancellation, we will get the word out the preceding evening so we can all get a good night\'s sleep.""\nEven with the best plans and forecasts, conditions can change at a moment\'s notice and create unexpected issues. Superintendents said that a delay can only be changed to a cancellation if conditions worsen before children board the bus.\n""Once students have left their homes for their bus stops and staff has left their homes to arrive at school, it is extremely difficult to change from a delay to a cancellation of school,"" East Allegheny School District Superintendent Roger A. D\'Emidio said in the district\'s policy. ""(The district) will do everything possible to ensure that students arrive safely at school and are returned safely to their homes at the conclusion of the school day.""\nIf school is canceled, district personnel look ahead to determine when the snow make-up day can be scheduled. Many districts schedule up to an additional three class days per year to prepare for days lost to bad weather. The state requires 180 scheduled days of instruction. If the number of cancellations exceeds the number of built-in snow make-up days, classes are extended into scheduled summer vacation until the 180 days are met.\nStaff writers Patrick Cloonan, Stacy Lee, Eric Slagle and Jennifer R. Vertullo contributed to this story.\nShow commenting policy\nTribLive commenting policy\nYou are solely responsible for your comments and by using TribLive.com you agree to our Terms of Service.\nWe moderate comments. Our goal is to provide substantive commentary for a general readership. By screening submissions, we provide a space where readers can share intelligent and informed commentary that enhances the quality of our news and information.\nWhile most comments will be posted if they are on-topic and not abusive, moderating decisions are subjective. We will make them as carefully and consistently as we can. Because of the volume of reader comments, we cannot review individual moderation decisions with readers.\nWe value thoughtful comments representing a range of views that make their point quickly and politely. We make an effort to protect discussions from repeated comments either by the same reader or different readers.\nWe follow the same standards for taste as the daily newspaper. A few things we won\'t tolerate: personal attacks, obscenity, vulgarity, profanity (including expletives and letters followed by dashes), commercial promotion, impersonations, incoherence, proselytizing and SHOUTING. Don\'t include URLs to Web sites.\nWe do not edit comments. They are either approved or deleted. We reserve the right to edit a comment that is quoted or excerpted in an article. In this case, we may fix spelling and punctuation.\nWe welcome strong opinions and criticism of our work, but we don\'t want comments to become bogged down with discussions of our policies and we will moderate accordingly.\nWe appreciate it when readers and people quoted in articles or blog posts point out errors of fact or emphasis and will investigate all assertions. But these suggestions should be sent via e-mail. To avoid distracting other readers, we won\'t publish comments that suggest a correction. Instead, corrections will be made in a blog post or in an article.', 'Is Your Inclement Weather Policy Prepared to Weather the Storm?\nThis last year has seen record-breaking weather events hit the nation and the region. Devastating images of surging seas, walls of fire, and roads of ice, normally reserved for fantasy or science fiction realms, should remind employers to review and revise their inclement weather policies to take into account the increased intensity of weather events and natural disasters, and the impacts they have on the business and its employees.\nThe goal of any employee handbook policy is to educate the employees on how the company will handle different situations, and this policy should be circulated well in advance of any extreme weather event. While the company is not expected to account for every particular instance, the policy should give employees key information about facility closures, notification procedures, attendance expectations, and employee pay.\n1. Is the Facility Open?\nWhile closing the facility is a difficult decision, the company should identify one person that makes that call so the day is not spent debating whether or not to close. The policy should indicate that the company intends to maintain normal working hours even during instances of inclement weather, but should provide a call-in number or website that employees can check to determine whether the facility will be open on a given day, opening late, or closing early. If the facility is open, but employees are unable to report to work given local conditions, the policy should require employees to report that to the call-in number, email/website, or their direct supervisor. Of course, in extreme weather conditions, employees may not have access to power, internet, or phone services.\nCompanies can also consider tying a facility closure to federal office closures, local government office closures, or school closures. Since parents are also often scrambling for childcare when schools are closed, the policy can also consider a discussion of when children are allowed to be in the workplace (which depends on the workspace, type of work and safety considerations).\n2. Employee Safety and Working Remotely\nThe policy should also consider a discussion of the importance of employee safety. Since employees commute from different parts of the region, most policies provide employees with some discretion about using their best judgment about whether to report to work in the instance of inclement weather. The policy should, however, retain discretion allowing the company to determine whether the employee’s absence will be counted as excused or unexcused.\nDepending on the type of work at issue, the policy can also permit, with permission, an employee to work from home. Telecommuting raises important concerns about productivity, safety and confidentiality/privacy, which are outside the scope of this specific policy and article, but which must be considered whenever an employee is allowed to work from home.\nAdditionally, the policy should note that if the employer discovers evidence that an employee is abusing the inclement weather policy, the employer reserves the right to conduct an investigation and discipline the employee accordingly.\n3. Employee Pay\nThe policy should also explain to the employees how pay is determined during an inclement weather event. The Department of Labor considers an absence due to adverse weather conditions to be an absence for personal reasons, such as when transportation difficulties during a weather emergency cause an employee to choose not to report for work and such an absence does not constitute an absence due to sickness or disability.\nDOL regulations explain that if an exempt employee is “ready, willing, and able to work, deductions may not be made for time when work is not available.” DOL’s guidance indicates that if the exempt employee performs any work, such as checking emails remotely, the employee must be paid for the full salary day, and with limited exceptions, salaried employees must be paid their normal salary in any workweek where they perform some work.\nHowever, if the business is closed for the entire week and the exempt employee performs no work at all, the employer may deduct the week’s pay. Where an exempt employee performs no work at all, the employer may be able to direct the employee to take a vacation or paid time off day from a company provided plan, but only if the employer has already provided written notice of this specific policy. Employers can still require employees that otherwise use vacation or PTO days to go through the proper request or reporting procedures.\nHourly employees are not required to be paid except for the hours they work, though many inclement weather policies voluntarily pay hourly employees who show up for work at least a certain amount of hours for the day (e.g., pay for four hours, even if they only end up working two hours before the facility closes due to inclement weather).\n4. Business Considerations\nIf the facility is open to the public, the employer should also have a system in place to notify customers, vendors, and the public (where appropriate) that the facility will be closed due to inclement weather.\nEmployers should also consider the impact that a closure lasting a day, a week or more will have on production and delivery schedules, and may need to bring in additional temporary or part-time workers to assist with any backlog or be prepared to pay those employees who are able to make it to work overtime. The company may also need to make advanced arrangement with its payroll company to ensure employees are paid in a timely fashion.\n5. Other Considerations\nEmployers subject to a collective bargaining agreement may have different contractual obligations regarding attendance and related discipline, and should consult their agreement.\nAdditionally, severe weather events may also trigger coverage under the federal Family and Medical Leave Act, or state law equivalents. These laws may provide enhanced protected leave for employees’ or their family members’ medical conditions related to the extreme weather event, including physical injuries, enhanced anxiety or the need for bereavement leave.\nRemember that in addition to reviewing and revising their policy, employers must also be sure to circulate the policy to employees and be prepared to answer any questions well ahead of the\nTyler Volm, firstname.lastname@example.org, 503-276- 2111']"	['<urn:uuid:c72b0991-3f8a-4fe8-bdff-14685fdb3504>', '<urn:uuid:9d73f928-bf67-4ca7-b429-895bad8af52b>']	factoid	with-premise	concise-and-natural	distant-from-document	multi-aspect	expert	2025-05-01T22:47:46.423955	11	63	2701
41	what hardware components needed build automatic loading firing catapult ev3	The automatic loading and firing catapult requires an EV3 brick, a motor connected to port C, and a touch sensor connected to port 2. It also uses a gear system with a standard clutch available in the LEGO Mindstorms EV3 kits.	"['Part four of the Catapult series is again about loading the catapult automatically but this time using EV3 brick, motor and sensor. We use a gear system with a medium complexity along with a ""standard clutch"" available in the LEGO Mindstorms EV3 kits. As a result, at the end of the video, the Catapult loads and fires automatically.\n- 25 Jan 2015\nIn this video lesson of the Catapult series a motor for loading the catapult is added. Firing is achieved using gravity force while loading is achieved with a motor. The power from the motor is transferred to the lever by a system of gears located on different axles. In this way the orientation of the gears is changed twice and transmitted four times.\nThe touch sensors used in the robot are very important. We should have a way to find out if the Catapult is already loaded and when we should stop loading. Configuring the motor to use rotations or degrees is a very bad practice and we should try to avoid it. Always try to use sensors.\nAdditional video lessons\nYou could find more explanations about changing gear orientation in the following video lessons:\nAll episodes from the series:\nThe current video lesson shows the robot built from LEGO Mindstorms EV3 parts.\nThis frame holds the motor and ev3 brick used in the catapult. The frame is placed on top of the rotating base and thus could be easily rotated. The brick could be both NXT and EV3\nThis is the initial construction of a catapult. The base on which we will place the rest of the robot. The goal of this construction is to give the catapult the ability to rotate.\nThis is an LEGO Mindstorms EV3-G program for the motor and touch sensor that we use for the LEGO Catapult\nMindstorms EV3-G program for running the LEGO catapult robot\nIn the fourth episode of the series on how you can build your own catapult we\'ll use an EV3 Mindstorm set and the motor and touch sensor from the set. In the previous episode we did the same thing with the NXT construction so, check it out. And at the end of the lesson we will have a completely automatic catapult that can fire like this. Fire, load; fire again, load.\nThe starting point is again the manual catapult that we have - we load manually, we fire manually. We load manually, we fire manually. We can also turn the catapult in each direction. The first thing that I\'d like to do is to remove the NXT brick and add an EV3 brick in its place. So, it\'s quite straightforward. Just remove one brick and add the other one. They are compatible.\nLike this. And, again, it is firing manually. As in the previous video, we should somehow attach a motor on one side and a touch sensor on the other side of the construction. The first thing will be to add this large gear wheel to the axle of the lever. In this way, when we turn the gear wheel, we\'ll load the catapult. When we release it, we\'ll fire. And we can do it even from this side. How do we transfer power from an EV3 motor to this gear wheel? In the previous episode we developed a clutch on our own but in the EV3 version of the robot we have the clutch already there. It\'s this small red part here. And the purpose of this part is to make this grey gear wheel turn. When the clutch is on, we attach the gear to the motor and when the clutch is off, the gear can move freely. As you can see, now the clutch is off and we can move the gear. But when the clutch is on, we can\'t move the gear, as it requires a move by the robot. You can find detailed instructions on how to build this module below the video, so check them out. But the basic principle is that you need a clutch and in some situations the clutch is on and in others the clutch is off. The other interesting thing about this module is that we have a change in the orientation of gears. We have gears that are, let\'s say, horizontal here and vertical here.\nNow we attach the module to the robot.\nLike this. Then the next step is to add the touch sensor. The purpose of the touch sensor is to make sure that the motor stops moving when the catapult is loaded. So, we are loading the catapult and when the catapult is loaded, we must stop moving. We are not loading the catapult based on rotations; based on degrees, but we are loading the catapult until the touch sensor is pressed. So, we add this touch sensor here\nNow the clutch is off. We are loading. The clutch is on. And the catapult is already loaded. If we release the lever, we fire. The last thing that we\'ll do is to improve this lever. We\'ll need the clutch to be on after firing so that we can again load it automatically. To do this, we\'ll just add a small modification to the lever.\nNow, the clutch is off, we are loading; the clutch is on and if we fire the catapult, it will automatically bring the clutch back into the ON position and we\'ll reload the catapult.\nLet\'s now connect the cables.\nThe motor should be connected to port C\nand the touch sensor - to port 2. Now let\'s write the program. The program is pretty straightforward. We take a medium motor. We\'d like to move the motor endlessly\nwith a power of, let\'s say, minus 100 because we\'re moving in the other direction and we are moving the robot until the touch sensor is pressed, so we are waiting. And we are waiting for the touch sensor to compare its state. The state of the sensor should be ""pressed"". We are waiting for a pressed sensor, as you can see, State 1. After the sensor is pressed, we stop the motor\nand then we wait till the sensor is released. This is the moment when we push the lever up; we release the sensor and we fire a part.\nThe state for ""release"" is Zero and again we wait for about a second for the firing to complete and we put all this in a loop. You can find the program below the video. Feel free to download it. Let\'s see how it performs. We start the program from the EV3 brick. Press ""Start"". The catapult is loaded - like this. Let\'s turn it to the camera. Now we release the lever. We fire, then we load again. We release the lever; we fire. Let\'s see what happens on the side of the touch sensor. We release the lever; we load until the touch sensor is pressed; we again release; we load. That\'s for our catapult. Try to improve it. Try to make it fire parts even further. This one fires part to about 1m, 1.5 m. We\'ll welcome any comments, improvements, modifications that you\'ve done to this robot.\nCourses and lessons with this Tutorial\nThis Tutorial is used in the following courses and lessons']"	['<urn:uuid:22865a5e-278b-46e8-8f51-24bd74e83a0f>']	factoid	direct	long-search-query	distant-from-document	single-doc	expert	2025-05-01T22:47:46.423955	10	41	1218
43	What role does augmented reality play in teaching abstract STEM concepts, and how are new paper technologies being integrated into educational materials?	AR technology helps students visualize complex and abstract concepts in STEM subjects, particularly beneficial since students often struggle with theoretical postulations. Through haptic devices, students can manipulate and utilize their sensory faculties when constructing knowledge, enabling visualization of large and small phenomena and anatomical figures. Regarding paper technologies, new developments include second generation (2G) paper that uses optical recognition to trigger digital information, and third generation (3G) paper with embedded sensors that can connect to digital content, allowing paper documents to have hotlinks to multimedia content that plays on nearby devices.	"['Continuing on the series….\nHere are few ways in which AR can be applied in a school dynamic.\n- STUDENT ENGAGEMENT\nTechnology has often been cited as a tool to increase student engagement. Bonascio (2017) and Magana, Serrano & Rebello (2019) theorise that AR is able to prolong attention and focus, as when multimodal resources and haptic devices are used, higher levels of enjoyment are experienced. This gratification is significantly reduced in students that do not comprehend the mechanics of the technology and indicated that whilst utilising AR can improve digital literacy, explicit teaching is required to ensure that all students are able to interact successfully with the technology (Magana, Serrano & Rebello, 2019).\n2. INQUIRY LEARNING\nOddone (2019) and Foote (2018) both suggest that greater educational benefits arise from students creating their own interactive images and overlays rather than using supplied ones. Apps such as Metaverse or Augment can be used by students to construct their own interactive content and would be an ideal cross curricular inquiry task across any discipline, but have curriculum value within the Science, History and Geography inquiry skills section. Examples of inquiry tasks include:\n3. ABSTRACT CONCEPTS & STEM SUBJECTS\nMagana, Serrano & Rebello (2018, p.526) believe that there is a positive effect to using multimodal resources and active learning for science and its related fields. This is because students often need assistance with visualising complex and abstract concepts (Saidin, Abd Hali & Yahaya, 2015; Riva, Banos, Botella, Mantovani & Gaggioli, 2016). Abstract concepts can be problematic for many students because of the difficulty students can have in visualising theoretical postulations (Furio, Fleck, Bousquet, Guillet, Canioni & Hachet, 2017, p.2-3 ). This struggle can negatively influence a student’s perception of the content material and lead to adverse learning outcomes (Furio et al., 2017, p.2-3 ). AR technology allows students to visualise the concept, albeit in animation, and increase comprehension which leads to improved outcomes (Saidin, Abd Hali & Yahaya, 2015, Wu et al., 2013). This is because haptic devices allow students to manipulate and utilise their sensory faculties when they are constructing knowledge. Large and small phenomena, as well as anatomical figures, can be visualised using AR technology (Wu et al. 2013).\n4. READING – RECREATIONAL & INFORMATIONAL\nAR books is the largest growing trend in children’s publishing and that many publishers are supplementing traditional texts with AR embedded resources (Levski, 2018; Zak, 2014). This is because AR books are seen as more innovative and able to improve flagging reading rates in children and adolescents (Levski ,2018, Zak, 2014). Many young readers find the interactivity extremely engaging and the use of technology appeals to digital natives (Magana, Serrano & Rebello, 2019).\nMayahayuddin & Mamat, (2019) point out that the multimodal nature of AR improves literacy because the audio visual cues assist students in decoding. Additionally, AR enables students that have low focus or attention to enhance their learning as it grants access to language in both formal and informal contexts, which is very useful for students with ADD, ADHD and those with social anxiety (Rafiq & Hashim, 2018, p.31; Mayayuddin & Mamat, 2019. These benefits are further improved when AR is combined with gaming principles which provides additional interest and intrinsic motivation (Mayahayuddin & Mamat, 2019; Levski 2018).\nFoote, C. (2018). Is it real or is it VR? Exploring AR and VR tools. Computers in Libraries. Retrieved from http://web.b.ebscohost.com.ezproxy.csu.edu.au/ehost/pdfviewer/pdfviewer?vid=0&sid=6093ea4d-06fa-42b1-8400-75e5bd1dd875%40pdc-v-sessmgr03\nFurio, D., Fleck, S., Bousquet, B., Guillet, JP., Canioni, L., & Hachet, M. (2017). HOBIT: Hybrid optical bench for innovative teaching. CHI’17 – Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems. Retrieved from https://hal.inria.fr/hal-01455510/file/HOBIT_CHI2017_authors.pdf\nLevski, Y. (2018). 10 Augmented Reality Books That Will Blow Your Kid’s Mind. AppReal- VR [Blog]. Retrieved from https://appreal-vr.com/blog/10-best-augmented-reality-books/\nMahayuddin, Z., & Mamat, Z. (2019). Implementing augmented reality (AR) on phonics based literacy among children with autism. International Journal on Advanced Science Engineering Information Technology 9 (6). Retrieved from https://core.ac.uk/download/pdf/296918932.pdf\nOddone, K. (2019). Even better than the real thing? Virtual and augmented reality in the school library. SCIS Connections. (110). Retrieved from https://www.scisdata.com/media/1921/scis-connections-110.pdf\nSaidin, N. Abd Halim, N., & Yahaya, N. (2015). A review of research on augmented reality in education: Advantages and applications. International Education Studies, 8(13). Retrieved from http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.730.8456&rep=rep1&type=pd\nRafiq, K., & Hashim, H. (2018) Augmented reality game (ARG), 21st century skills and ESL classroom. Journal o fEducational and Learning Studies. 1 (1) pp29-34. Retrieved from https://journal.redwhitepress.com/index.php/jels/article/view/23/pdf\nRiva, G., Banos, R., Botella, C., Mantovani, F., & Gaggioli, A. (2016). Transforming experience: The potential of augmented reality and virtual reality for enhancing personal and clinical change. Frontiers in Psychiatry 7. Retrieved from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5043228/pdf/fpsyt-07-00164.pdf\nWu, H., Lee, S., Chang, H., & Liang, J. (2013). Current status, opportunities and challenges of augmented reality in education. Computers & Education, 62. Pp41-49. Retrieved from https://doi.org/10.1016/j.compedu.2012.10.024\nZak, E. (2014). Do you believe in magic? Exploring the conceptualisation of augmented reality and its implication for the user in the field of library and information science. Information Technology and Libraries.', ""Next generation paper: Connecting paper to the web\nThis multidisciplinary project aims to explore the future of paper and its connection to the web. It will do so in the domain of travel and tourism where paper and screen-based information are already used together in the tourist experience.\nThe project proposal was in response to a call on ‘Content creation and consumption in the digital economy’. It aims to create new technology and business opportunities in the publishing and tourism industries. It will do this by using augmented reality and printed electronics to connect paper to the web, in what the team call second generation (2G) and third generation paper (3G).\nIf today’s ordinary paper is considered first generation (1G) paper, then 2G paper will be optically recognised with a camera, triggering associated digital information to be played or displayed on a nearby device.\n3G paper will dispense with the camera and contain tiny sensors printed or embedded in the fibres of the paper itself. This will trigger the same kind of associations around it. In this way, paper documents and books could have hotlinks to webpages, audio, video clips and so on that could play on speakers or screens around them. The team will be looking at how this could change and connect the use of paper and screen-based information in tourism, where tourist brochures and guides already co-exist with mobile apps, digital photography and online booking systems.\nMore information is available in this press release.\nA key feature of the project is that it will be investigating new business models for next generation paper, alongside building and testing the technology itself. This means that we will be working closely with our industrial partners on options for commercialisation and establishing industry standards.\nThe project team\nThis includes five groups at Surrey and one at the Open University. The project is led by Prof David Frohlich.\n- Digital World Research Centre (DWRC), Prof David Frohlich, Dr Emily Corrigan-Kavanagh, Alexandra Brown, Megan Beynon\n- School of Hospitality and Tourism, Prof Caroline Scarles, Dr Emily Corrigan-Kavanagh, Lauren Seigel\n- Centre for Vision Speech & Signal Processing (CVSSP), Prof Mirek Bober, Haiyue Yuan\n- Advanced Technology Institute (ATI), Dr Radu Sporea, Dr Brice Le Borgne, Dr Lori Liza Bulay-og, George Bairaktaris\n- University of Exeter, Prof Alan Brown\n- Department of Geography, Open University, Dr George Revill, Dr Jan Van Duppen.\nNon-academic partners include:\n- Bradt Travel Guides\n- Emirates Holidays UK\n- Otava Publishing Company\n- Ifolor Photo Printing\nThe project is funded by a grant of £1.17m from the Digital Economy programme administered by EPSRC. It ran from November 2017 to December 2020.\nBairaktaris G., Frohlich D.M. & Sporea R.A (2021) Printed Light Tags and the Magic Bookmark:Using light to augment paper objects. In press for CHI 2021 Conference Proceedings, New York: ACM Press.\nCorrigan-Kavanagh, E., Scarles, and M. Beynon (2020) Augmenting Photobooks for Enhancing Travel Performances. Proceedings of CAUTHE2020, Auckland, New Zealand, 10–13 February. Auckland: Auckland University of Technology, pp. 60–64.\nCorrigan-Kavanagh, E., Scarles, C. and Revill, G. (2020). Augmenting Travel Guides for Enriching Travel Experiences. Proceedings of ENTER2020 International eTourism Conference,The 27th Annual Conference Organized by IFITT, Guildford, UK, 8–10 January. Guildford: E-review of Tourism, pp. 334–348.\nCorrigan-Kavanagh, E., Scarles, C., Revill, G., Beynon, M. and van Duppen, J. (2020). Explorations on the future of the book from the Next Generation Paper Project. Publishing History, 83pp. 35–54.\nGeorgios Bairaktaris, Brice H. Le Borgne, Sirpa Nordman, Samuli Yrjänä, Timo Kurkela, Peter Bagge, Timo Turpela, Haiyue Yuan, Emily Corrigan-Kavanagh, George Revill, Miroslav Z. Bober, Alan Brown, Caroline E. Scarles, David M. Frohlich, Radu A. Sporea, Next-generation paper: a versatile augmented book platform, InnoLAE 2020, Cambridge, UK, 20-21 January 2020.\nRadu A. Sporea, Brice Le Borgne, Georgios Bairaktaris, David M. Frohlich, Vikram Turkani, Rudresh Ghosh, Vahid Akhavan, Stan Farnsworth, Next Generation Paper: Cost-Effective Printed Electronics Techniques Advancing Augmented Book Manufacturability, InnoLAE 2020, Cambridge, UK, 20-21 January 2020.\nCorrigan-Kavanagh, E. (2019). Next Generation Paper. Online: The Writing Platform. March 7 2019.\nBrown, A. W. (2019). Delivering digital transformation: A manager’s guide to the digital revolution. De Gruyter Oldenbourg.\nFrohlich DM, Corrigan-Kavanagh E., Bober M, Yuan H, Sporea R., Le Borgne B, Scarles C, Beynon M. (2019). The Cornwall a-book: An Augmented Travel Guide Using Next Generation Paper. The Journal of Electronic Publishing, 22(1).\nSporea RA, Le Borgne BH, Yrjana S, Nordman S, Bagge P, Yuan H, Corrigan-Kavanagh E, Seisto A, Revill G, Bober MZ, Brown A, Scarles CE, Frohlich DM (2019). Next Generation Paper: An Augmented Travel Guide Demonstrator. Presentation at InnoLAE 2019.\nSporea RA, Le Borgne BH, Yrjana S, Nordman S, Ritvonen T, Revill G, Bober MZ, Brown A, Scarles CE, Frohlich DM (2018). Next Generation Paper: An Augmented Book Platform. Presentation at SPIE Optics + Photonics 2018 Conference, September 2018, San Diego, California,United States.\nFrohlich, D.M. (2017) From audiopaper to next generation paper. WebMedia 2017: Proceedings of the 23rd Brazilian Symposium on Multimedia and the Web Pages 9-10. New York: ACM Press. October 2017.\nBober, M., Brown, A., Corrigan-Kavanagh, E., Frohlich, D.M., Scarles, C., Sporea, R., (2020) Next Generation Paper: Future book technology. Online Webinar\nCorrigan-Kavanagh, E., Scarles, C. and Beyon, M. (2020). Augmenting Photobooks for Enhancing Travel Performances. Proceedings of the 30th Annual Conference for The Council for Australasian Tourism and Hospitality Education. Paper presented at CAUTHE2020: 20:20 Vision: New Perspectives on the diversity of Hospitality, Tourism and Events, Auckland, New Zealand. Auckland: University of Auckland\nCorrigan-Kavanagh, E., Scarles, C. and Revill, G. (2020). Augmenting Travel Guides for Enriching Travel Experiences. Proceedings of ENTER2020 International eTourism Conference, The 27th Annual Conference Organized by IFITT. Paper presented at ENTER2020, Guildford, UK. Guildford: University of Surrey.\nScarles, C., Corrigan-Kavanagh, E., Beynon, M., Bober, M., Brown, A., Frohlich, D., Le-Borgne, B., Sporea, R., Revill, G., van Duppen, J. & Yuan, H. (2019). Next Generation Paper in Travel: Enriching Experience Through Augmented Guidebooks. Proceedings of TTRAEurope2019. Paper presented at TTRAEurope2019: Tourism in the era of connectivity, Bournemouth,UK. Bournemouth: University of Bournemouth.\nScarles CE, Beynon M, Next Generation Paper demonstration (2019) ENTER 2019, The 26th Annual eTourism Conference, Nicosia, Cyprus. 29th - 1st February 2019.\nCorrigan-Kavanagh, E. and Frohlich, D.M. (2018) Next Generation Paper: Revolutionising Paper and How Books are Read. Presentation at The Book in the Digital Age Conference, 24th October 2018, Loughborough University, UK\nCorrigan-Kavanagh, E. and Frohlich, D.M. (2018) Design for Next Generation Paper and Implications for the Future of Reading. Presentation at UGPN Annual Conference, 9th - 11th April 2018, University of Surrey, UK.\nFrohlich, D.M. (2017) From audiopaper to next generation paper. Keynote presentation to Webmedia 2017, 17-20th October 2017, Gramado, Brazil.\nScarles CE. From postcards to Instagram: Re-imagining tourist landscapes' paper presented at RGS-IBG Annual International Conference, Cardiff University, Cardiff, 29 August 2018.\nFrohlich, D.M. 'Introducing the a-book'. Keynote presentation to BIC New Trends in Publishing conference 2018.\nJourneys Between Print & Screen and Beyond: A Travel Media Ethnography, paper presented at the Digital World Research Centre -The University of Surrey, Guildford, 19 November 2018.\nTouching upon Print & Screen: How media and technology reshape tourism' paper presented at The School of Hospitality and Tourism Management -The University of Surrey, Guildford, 4 December 2018.\nIn the press\n- Print Week\n- OpenSpace Research Centre\n- BBC Radio Surrey interview (24 May)\n- FE News\n- Science news online\n- Health Medicine Net\n- Public Now\n- Sciences Avenir\n- The University Network (TUN)\n- University Business\nPaper Magic, COMM Museum of Communication, The Hague, June-December 2018""]"	['<urn:uuid:26278065-38dd-4fa0-b57b-f55b02ef89fe>', '<urn:uuid:95ccadf6-b071-44b4-a27c-a62bc3abbfc0>']	factoid	direct	verbose-and-natural	distant-from-document	multi-aspect	expert	2025-05-01T22:47:46.423955	22	91	2074
44	I'm an architectural historian researching luxury hotels in former financial buildings - what interesting features did they preserve in The Ned hotel from its past as a clearinghouse bank?	The Ned preserved several notable features from when it was the world's largest clearinghouse bank in the 1920s, including its soaring public space with beautiful marble columns. One of the most striking preserved elements is the giant vault, which was transformed into a nightclub while maintaining the original safe-deposit boxes inside.	"[""The Hospitality Industry Is Increasingly Stepping Up to Reuse Historic Buildings\nMetropolis speaks with Andrew Zobler, CEO of hospitality-focused company Sydell Group, on the industry's growing regard for investing in history.\nThe hospitality industry has become an unexpected steward of historic properties, with restaurants, clubs, and hotels taking up residence in the structures of yesteryear. Andrew Zobler, founder and CEO of the Sydell Group, is well acquainted with this trend. Indeed, he’s been at the forefront of it: His 14-year-old company has led adaptive-reuse hospitality projects across the United States (and internationally, starting in 2017 with The Ned), giving old buildings new lives through families of hotels like NoMad, LINE, Freehand, and Saguaro. Speaking with Metropolis’s Lila Allen, Zobler discussed why hotels, beyond being places to lay one’s head or grab a drink, are increasingly places to travel through time.\nLila Allen: Sydell has had a big couple of years, with new properties including The Ned.\nAndrew Zobler: We did two big things in these last couple of years. From a historic perspective, The Ned is certainly the most important. We also opened a large project in Las Vegas called Park MGM, which has a NoMad component, and we partnered with MGM on the building. The Ned was a pretty complicated building, and an important piece of architecture in its own right. It was once the largest clearinghouse bank in the world, built at the height of the British Empire in the 1920s. So it’s a really grand building, with a soaring public space and beautiful marble columns.\nThese buildings are, of course, compelling because you want to keep them alive and give people reasons to come see them, and certainly you can’t build them today; it wouldn’t be cost-effective. The art of it is finding buildings where you have a response that makes sense, because I always say: If you fight with the building, the building is gonna win.\nLA: You’ve worked with a wide range of building typologies. There’s The Ned on one side and then, going back a decade, you also worked as a developer on The Ace in Palm Springs, California, which was once an old Howard Johnson motel. [Editor’s note: Sydell is not affiliated with Ace.] What makes you fall in love with a piece of property? And how do you reconcile romance and finance?\nAZ: We tend to look for things where other people don’t necessarily see value. The Ned’s a good example—it’s a spectacular building, but it sat empty for almost a decade. A few different people owned it and couldn’t make a run of it, and I think a lot of that had to do with the fact that [the building demands] a whole bunch of food and beverage concepts. You had to be able to figure out the three levels downstairs. You needed to do all these things that we did to afford the renovation of that building, which was a pretty expensive undertaking. Anybody could have walked into the building and appreciated that it was beautiful, but what we tried to do is figure out, OK, how can we really make sense of it?\nWith something like The Ace in Palm Springs, it was the opposite: The building was super cheap, so that’s what made it interesting. Palm Springs then was not what it is today. Half of it was shuttered, and the only thing, really, of architectural interest was the old Howard Johnson’s fun, freestanding restaurant structure. The driver of the creative vision on that was Alex Calderwood from Ace, and Commune. Alex had a perfect touch for doing a little hippie-dippie in the desert; it just flowed naturally out of him. Our job there was more to make sure that the whole thing got built in an intelligent way.\nLA: I’m curious about how you create a property that is specific to where it’s based. What kind of research or community outreach or surveying goes on in order to craft a narrative that’s consistent with time and place?\nAZ: We think of ourselves first and foremost as storytellers. If you look at our hotels, they tend to be not necessarily ones that everyone loves, but ones that certain people become evangelical about because the hotels really speak to them. And that’s the goal. We’re not Marriott; we’re not producing things that work everywhere.\nSo the first thing we do is start to tell the story. We go visit local restaurateurs and nightlife, and see what’s going on. Very often, something we’ll do—which is the opposite of what most people do—is try and figure out what the art is going to be first. We’ll ask, “OK, who are we going to collaborate with? What’s our story? What art do we like?”\nLA: What are some examples of design features in recent projects that you feel were especially well resolved?\nAZ: There are lots, but I think what comes to mind more than anything is at the NoMad in L.A. It was originally the Bank of Italy’s headquarters, and the building had this really spectacular Italian-made ceiling, with light-blue pastels and other very soft colors. We preserved the ceiling and applied its color palette to all the furniture throughout the building. That ceiling just told us what to do.\nAnother one is the giant vault at The Ned, which is our nightclub. You go in and there are all these safe-deposit boxes. It’s huge. And it’s all inside this giant old vault about which, again, someone might have said, “What are we gonna do with it?” We turned it into something that people actually really love.\nLA: While it sounds like you embrace properties where the opportunity is right, is there any kind of “white whale” building type out there that you would love to work with? What’s ripe for a reinvention?\nAZ: We personally respond to some combination of architecture and location, and we’re a little bit eclectic about the architecture. Take The Ned, as you said, versus the Saguaro Palm Springs, versus the Brutalism of the LINE in L.A. These are very, very different buildings. But then there are some that are similar—if you look at the NoMad Los Angeles and NoMad New York, and Freehand New York and Freehand LA, there are similarities in those [families of] buildings. And we like that.\nOne question is, are there any building types we should avoid? We’re working on a hotel in London, which is in a former courthouse and jail. One of the questions I got, chatting with a savvy London reporter, was, “Do you feel weird about doing something in an old prison, with all the pain that went on in that building?” I was like, “No, I don’t think so.” It actually feels good to be taking what used to be a place of horror and turning it into a place of happiness.\nYou may also enjoy “Google Used Sensors to Connect Neurology and Aesthetics at Milan Design Week.”\nWould you like to comment on this article? Send your thoughts to: email@example.com""]"	['<urn:uuid:46b3ec16-e354-4dd9-8b48-e3fb99fceeef>']	factoid	with-premise	verbose-and-natural	distant-from-document	single-doc	expert	2025-05-01T22:47:46.423955	29	51	1175
45	inattentive adhd anxiety disorder physical symptoms	Inattentive ADD and anxiety disorders manifest different physical symptoms. Predominantly inattentive ADD is characterized by making careless mistakes, difficulty focusing, forgetfulness and disorganization, without physical restlessness. In contrast, anxiety disorders often present with bodily sensations like sweating, racing heart, palpitations, and tremors, particularly in situations like public speaking or test-taking. These physical anxiety symptoms can be targeted specifically with medications like beta-blockers.	['ADD / ADHD is a widely misunderstood disorder that affects a number of children. ADD / ADHD can occur in various forms. Numerous treatments are advised. Causes are not certain but the disorder is said to be genetic, following down the male line.\nAttention Deficit Disorder (ADD) is due to one key problem: the inability to consistently regulate attention and behaviours. Children who suffer from ADD often have problems concentrating and following through on their actions. Many make the mistake of attributing the problems children experience to laziness or poor parenting. These explanations are totally false. ADD / ADHD is recognised as a fully fledged biological disorder that can be treated in a variety of ways. ADD / ADHD can also affect adults.\nThere are 3 basic types of ADD / ADHD:\nPredominantly Inattentive Type\nThose who suffer from predominantly inattentive ADD find it difficult to focus but are able to sit still. Symptoms include:\n- Making careless mistakes in schoolwork\n- Not appearing to listen when somebody speaks\n- Being forgetful or disorganised\n- Having difficulties focusing on a specific task\nPredominantly Hyperactive/Impulsive Type\nThose who have predominantly hyperactive ADHD, battle to control body movements or behaviours. This poses more of a problem than maintaining attention. Symptoms include:\n- Not considering consequences of actions\n- Speaking or acting inappropriately\n- Fidgeting or feeling restless when trying to sit\n- Being excessively physically or verbally active\nThose who experience the combined type of ADD / ADHD have a combination of symptoms from both inattentive and hyperactive/impulsive ADD / ADHD.\nSymptoms of ADD / ADHD must recur for over 6 months before the possibility of ADD / ADHD can be considered. Other requirements for the possibility of ADD / ADHD to be considered include:\n- Appearing before the age of 7\n- Having a major impact on your life in more than one setting\n- Not having another disorder that could account for the symptoms (e.g. bipolar disorder)\n- Secondary symptoms of ADHD include:\n- Lack of motivation\n- Difficulty getting along with others\n- Bad time and/or money management\nThere is still much research to be done in the field of ADD / ADHD. Over the years, people have battled to identify the causes of ADD / ADHD. The most commonly identified cause of ADD / ADHD is genetics. ADD / ADHD research is therefore focused on identifying the genes that could be responsible for the disorder.\nBrain functions are also examined by comparing the brains of ADD / ADHD sufferers and those who are healthy. Those who suffer with ADD / ADHD have problems with self regulation. Controlling impulses, maintaining attention and moods are key problems. No matter what approach researchers may face there is no doubt that ADD / ADHD has a biological basis. Symptoms may be behavioural but causes are not. Different areas of the brain and neurotransmitters seem to play a role. Chemical releases in the brain are also thought to contribute to the disorder.\nMany differ when it comes to the mode of treating ADD / ADHD. Doctors suggest a 3 pronged approach to treating ADD / ADHD sufferers. Biological, psychological and social strategies are employed in treatment.\nBiological treatments are the first mode of defence. Without these treatments, psychological and social treatments are less effective. Biological treatments focus on the way the brain functions and can change the way the brain functions. Treatment includes:\n- Medication: Many doctors prescribe Ritalin or Dexedrine.\n- Diet: Ensure that the diet of AD D / ADHDsufferers excludes food additives and colouring.\n- Vitamin supplements and herbal remedies: Vitamins thought to be effective in helping ADD / ADHD sufferers include magnesium, Vitamin B and Vitamin B6.\n- Repatterning therapies\n- Rebalancing therapies, e.g. homeopathies, acupuncture and manipulation therapies, e.g. chiropractic and osteopathy\n- Regular exercise is also highly recommended to maintain stable energy levels.\n- Consulting a psychologist can help sufferers deal with the feelings that are evoked by the troubling symptoms of ADD / ADHD. Psychological tools can also help to cope with the problems you face as an ADD / ADHD sufferer. Psychological tools include:\n- Psychotherapy which includes supportive therapy, play therapy, skills training, psycho-educational counselling, and parent training.\n- Behaviour management which includes behaviour modification, cognitive behavioural counselling and awareness training.\n- People who are affected by ADD / ADHD often find it hard to negotiate basic social settings. Social workers and therapy can help develop social skills in the following areas:\n- Lifestyle choices\n- Occupational skills\nThere has always been much debate surrounding the issue of ADD / ADHD. A recent article in Time Magazine argues that children can outgrow ADD / ADHD. Even though half the sufferers retain the disorder when they reach adulthood, the study argues that the brain is constantly developing which can alleviate ADD / ADHD symptoms.\nMany also argue that doctors are too quick to prescribe Ritalin etc. for ADD / ADHD sufferers. These medications can have detrimental side effects including loss of appetite and aggression. However the drug has proven to alleviate symptoms in over 70% of ADD / ADHD sufferers. If its use is carefully monitored by a doctor, problems should be minimal.\nThere are various alternatives to traditional medication. Homeopathic treatment as well as behaviour therapy has proved very effective in treating ADD / ADHD. Using various methods that complement one another is generally the best approach to treating ADD / ADHD.\nADD / ADHD can only be diagnosed by a qualified doctor. If you feel your child may be suffering from ADD / ADHD, it is best to consult a medical professional. Each case is different, but through a multi-modal approach to treating ADHD, living a normal life with ADD / ADHD is more than possible.', 'Learn About Anxiety\nIs medication right for you?\n“…all anxiety disorders have one thing in common: persistent, excessive fear or worry in situations that are not threatening…”\nNational Alliance on Mental Illness-NAMI \nWhy is treatment so important?\nBecause an anxiety disorder can significantly interfere with the enjoyment and functioning of life.\nIt prevents you from realizing your full potential.\nAnxieties can range from a general and pervasive sense of worry or unease (Generalized Anxiety Disorder or “GAD,”) to something very specific and completely disabling, like the inability to leave the house (Agoraphobia).\nThis article provides additional information I hope you find helpful to gain insight into the types of medications doctors may use in treating anxiety.\nThe purpose of this article is not to suggest medication is the only treatment course for anxiety. It is intended to provide background about medications that a psychiatrist might suggest.\nPeople do experience anxiety without having an anxiety disorder. Techniques for managing anxious feelings can be effective whether or not you have an anxiety disorder.\n“Anxiety disorders include disorders that share features of excessive fear and anxiety and related behavioral disturbances. Fear is the emotional response to real or perceived imminent threat…anxiety is anticipation of future threat. ” DSM-5 \nWhat Is Anxiety?\nA person may feel anxiety is out of control or illogical. It can interfere with sleep or even get in the way of work or family life because a person’s anxious thoughts prevent them from concentrating on other tasks. There are other examples of ways anxiety changes from “feelings” to something more seriously detrimental to life-functioning. An anxiety disorder might be helped by medication—a decision to be made with your psychiatrist.\nBefore diagnosing an anxiety disorder, psychiatrists consider criteria described in the DSM-5 (Diagnostic and Statistical Manual 5th edition published by the American Psychiatric Association). \nCommon anxiety disorders include\n- Generalized Anxiety Disorder\n- Phobias (including Social Phobias, Agoraphobia, or specific types of phobias like a fear of blood, flying, or spiders)\n- Panic Disorder\nOnce the diagnosis of an anxiety disorder is made, the next order of business is treatment.\nThe subject of this article addresses medication, though that is by no means the only treatment available for an anxiety disorder.\nBefore discussing psychiatric medication treatment for an anxiety disorder, it is crucial to understand that the treatment for the underlying disorder includes non-chemical options. For example, types of psychotherapy or counseling, as well as ancillary treatments like meditation, relaxation techniques, exercise, and nutrition are key to enhancing effective medication treatment, as well as allowing medication weaning if possible.\nIf medication treatment is started and the patient does not undertake treatment for the underlying problem, then when the medications are stopped the anxiety symptoms are likely to reappear, making it crucial to include non-medication treatment for the anxiety disorder.\nIf medication treatment is started and the patient does not undertake treatment for the underlying problem, then when the medications are stopped the anxiety symptoms may reappear, making it crucial to include non-medication treatment for the anxiety disorder.\nMedication is not always the only or even primary option.\nIf medication is a treatment you and your psychiatrist decide to pursue, it is helpful to understand more about how these medications work.\nAnti-anxiety medications can be grouped into a few categories:\nAntidepressants That Help With Anxiety\nAntidepressants may also address anxiety in addition to depression. In fact, these antidepressants are sometimes called “anti-anxiety agents.” Not all antidepressants treat anxiety, but it is important to know that the term “antidepressant” doesn’t limit the benefits of the drug to treat anxiety.\nIn fact, the term “antidepressant” is an anachronism in that many of these medications are approved by the FDA (Food and Drug Administration) to treat various anxiety disorders. They may continue to be known as “antidepressants” rather than a long-winded name such as “antidepressant anti-anxiety agent.”\nSSRIs, like Prozac, Paxil and Zoloft are approved by the FDA to treat anxiety and depression. SSRI stands for ‘selective serotonin reuptake inhibiter’–a mouthful. What is important is that they can be effective in treating anxiety. Most SSRIs are readily available in an economic generic form: Prozac (fluoxetine), Paxil (paroxetine), Zoloft (sertraline), Celexa (citalopram), Lexapro (escitalopram). New medications are released frequently. Not all are available in generic form. To list them all is impractical, but you get the idea.\nAnother class of antidepressants that can help anxiety by affecting serotonin (and other neurotransmitters) are termed “dual reuptake inhibiters” or “serotonin-norepinephrine reuptake inhibitors (SNRIs)”. These include Cymbalta (duloxetine), Effexor (venlafaxine), and Pristiq (desvenlafaxine). Neurotransmitters, and the role they play in how we feel, needs its own article. Watch this space. Suffice to say, the relationship between the brain, anxiety, and depression is complex, as is the science behind the medications that treat them.\nOlder Antidepressants That are Still Used Effectively for Depression and Anxiety\nOlder antidepressants are still prescribed because they may be more effective for some patients than newer medications. For example, Desyrel (trazadone), Remeron (mirtazapine), Clomipramine (anafranil), Doxepin (Sinequan) and the MAO-Is (Marplan, Nardil, and Parnate) are all utilized (“off-label”) for anxiety treatment. So even though they are not officially “approved” by the FDA for anxiety, studies show, and clinical experience demonstrates, their efficacy. (It is possible that by the time a drug was proven to be effective for an off-label treatment, the drug had “gone” generic, was inexpensively available, and no drug company put forth the time, effort and money to get it approved as profits would not be realized.)\nBenzodiazepines: Relaxing Drugs That Treat Anxiety Disorders\nBenzodiazepines are a class of medication that have a relaxing effect, like Ativan, Xanax, Klonopin/Clonazepam, or Valium. Benzodiazepines are sometimes called “benzos” for short.\nBenzos can be addictive and require close monitoring by a psychiatrist—who is a licensed physician. Non-benzodiazepine alternatives exist though they may not be as effective. Discuss all options with your Psychiatrist.\nPatients who may be at risk to become dependent on the potentially addictive benzos include, for example, beta-blockers like Inderal (generic propranolol), Neurontin (gabapentin) and Buspar (buspirone).\nAnti-Anxiety Medications That Target a Particular Type of Anxiety\nPublic Speaking and Test-Taking Anxiety\nAny situation where a person is anxious because they must speak in front of others can trigger anxiety associated with an anxiety disorder. Anxiety symptoms are mainly in the form of bodily sensations like sweating, heart racing and palpitations, etc. It is also normal for a person to experience anxiety in these situations without having an anxiety disorder. However, a person with an anxiety disorder may become disabled by their anxiety. This can occur in any walk of life.\n- Speech, before other students and teachers\n- “Stage fright” (including, but not limited to, musicians and actors prior to a performance)\n- Presentation at work in front of colleagues and your boss\n- Professional presentation in a formal setting like a club or organization\n- Speech at a conference, alone or on a panel\n- Religious presentations such as a sermon, or Bar or Bat Mitzvah require a person to stand before others and a speak on a topic\n- A person who must take the stand in a trial. This includes witnesses, plaintiffs or defendants, expert witnesses…anyone who might be speaking in Court, testifying at a deposition or the attorney posing questions in this setting.\nAny test can trigger anxiety. An anxiety disorder may make it impossible to succeed by passing a test without medication and other treatment.\n- SAT or ACT\n- Bar exam\n- GMAT (Graduate School)\n- Medical licensing exam (yes, doctors can have an anxiety disorder)\n- Professional licensing exams. Virtually hundreds of professionals are required to take exams to be qualified to pursue their career\n- Final exams, quizzes, any test in an educational setting\n- Psychological testing\nThe drug Inderal  is used as an anti-anxiety medication. It is not approved by the Food and Drug Administration (FDA) to treat anxiety, but it is the drug of choice for some doctors to treat syndromes such as public speaking or test-taking anxiety. Performers or test-takers may find that, for instance, 20-40 milligrams (mg) of this drug an hour or two prior to the anxiety-provoking event does wonders. Inderal also comes in a long acting form (Inderal LA) and if effective, can be given around the clock. Sometimes it is prescribed along with short-acting Inderal when an acute anxiety provoking situation will occur or has the potential to occur.\nBecause Inderal appears to be more effective specifically in public-speaking and test-taking types of anxieties , the patient and doctor will discuss in advance circumstances that provoke anxiety about a test or speaking situation.\nHow Do Beta Blockers Work and Why Are They Helpful for Test-taking and Public Speaking?\nBeta blockers, like Inderal, work by blocking beta receptor sites in the nervous system and body in general. They are used to treat high blood pressure and heart conditions, but it is now recognized that they decrease the physical symptoms of anxiety (e.g., palpitations, accelerated heart rate, sweating, tremors, and other symptoms due to adrenaline over-activity in the adrenals and elsewhere).\nIntuitive reasoning is how a person deals with stress and fear if they are not disabled by anxiety. Studies show that when intuitive reasoning is replaced by anxiety, bodily symptoms occur first, at which point the subconscious mind detects that the person has become anxious. Physicians report that Inderal administered shortly before the event can be helpful, although the research is still ongoing to discover the true underlying nature of anxiety and its cure.\nIn the same ballpark as Inderal is clonidine (generic for Catapres), in that it too is an old time cardiovascular drug whose effect on receptors serves to treat anxiety and panic attacks.  It also happens to be the drug of choice for anxiety symptoms associated with opiate withdrawal (heroine, methadone, pain pills, etc.).\nNeurontin (gabapentin) has been found in several research studies  to be effective for anxiety including social phobia and panic attacks as well as those anxious patients with the diagnosis of bipolar disorder. It can be used as a stand-alone treatment for anxiety or in combination with other anti-anxiety medications.\nBuspar is an old-time drug approved by the FDA for treatment of anxiety, particularly GAD or generalized anxiety disorder. It is a good example of just how complex these drug mechanisms of action can be and the difficulty in extrapolation to clinical effect. For instance, Buspar works on several of the serotonin receptors as well as dopamine receptors. Effects impact various parts of the nervous system from the more primitive brainstem to the higher level functioning neocortex.\nAnxiety has been treated with medication for decades with varying success. Research and the introduction of ever-evolving pharmacological options provides physicians with tools to treat patients struggling with anxiety disorders. Older medications continue to work well for some patients. A combination of medication to manage symptoms and side-effects is one consideration for patient and doctor.\nAnxiety is debilitating and eats into the enjoyment of life we all seek.\nYou may be settling for a “low normal” when the “new normal” of your potentiality is waiting to be realized once you manage and remove unnecessary anxiety. If you suspect you have an anxiety disorder, the doctor is in—we are here to help.\nSimilarly, if a treatment program has not been working for you, Dr. Weiss’ mix of clinical experience and medical expertise may shed light on different approaches that might be more successful.\nYou might be surprised to learn what isn’t an anxiety disorder\nOCD Is Not An Anxiety Disorder\nObsessive-Compulsive Disorder (including subtypes like Hoarding Disorder, washing one’s hands, or Trichotillomania or hair-pulling) used to be in the anxiety disorder realm. OCD is now its own diagnostic condition in the DSM-5. Compulsive behavior can be very worrying. A person with OCD may also have an anxiety disorder. OCD itself, however, is not an anxiety disorder.\nPTSD Is Not An Anxiety Disorder\nPTSD also used to be considered an anxiety disorder but is now a separate diagnosis because criteria is complex and different from an anxiety disorder (though anxiety is usually a feature of PTSD).\n Anxiety Disorders | NAMI: National Alliance on Mental Illness. (2017, December). National Alliance on Mental Illness. https://www.nami.org/About-Mental-Illness/Mental-Health-Conditions/Anxiety-Disorders\n American Psychiatric Association. (2013). Diagnostic and statistical manual of mental disorders (5th ed.). https://doi.org/10.1176/appi.books.9780890425596\n Off-label use of a drug means it is up to the physician’s discretion to decide if use of a drug is indicated for treatment even if that is not the FDA approved use of the drug. When the FDA has approved an indication, like beta-blockers for cardiovascular conditions, it reflects that that the drug in question has been found effective in a statistically robust clinical trial. 20 years after a pharmaceutical company first files a patent on a drug, it can be released in generic form. The pharmaceutical company may see a considerable decrease in demand for its brand-name medication. Research that is sponsored by the drug company may fall off, with the potential of creating a lack of research about off-label use of a drug.\n “Inderal (PROPRANOLOL): USES, Dosage, Side Effects, Interactions, Warning.” RxList, RxList, 23 June 2020, www.rxlist.com/inderal-drug.htm.\n Davidson J. R. (2006). Pharmacotherapy of social anxiety disorder: what does the evidence tell us?. The Journal of clinical psychiatry, 67 Suppl 12, 20–26.\n Hoehn-Saric R, Merchant AF, Keyser ML, Smith NVK. Effects of Clonidine on Anxiety Disorders. Arch Gen Psychiatry. 1981;38(11):1278–1282. doi:10.1001/archpsyc.1981.01780360094011 .\n Frye MA, Ketter TA, Kimbrell TA, et al. A placebo-controlled study of lamotrigine and gabapentin monotherapy in refractory mood disorders. J Clin Psychopharmacol. 2000 Dec;20(6):607-14\nNational Institute of Mental Health public resource about Anxiety Disorders. “Anxiety Disorders.” National Institute of Mental Health, U.S. Department of Health and Human Services, July 2018, www.nimh.nih.gov/health/topics/anxiety-disorders/. Accessed online August 5, 2021\nDisclaimer: This article is not intended to be a comprehensive overview of medications used to treat anxiety. This article is not updated on a regular basis and new medications are being released with frequency.\nYou should consult with your doctor if you believe you might have a medical condition.\nThis is not a legal article and is not intended to be relied upon for legal purposes.']	['<urn:uuid:11e8511f-e0dc-43ce-98db-d74bf1ac4d8c>', '<urn:uuid:f5e4776f-e223-41ba-bc58-a954af51251d>']	open-ended	direct	short-search-query	similar-to-document	comparison	expert	2025-05-01T22:47:46.423955	6	62	3318
46	Why do birds fly high up in the evening?	Common swifts are known to ascend to high altitudes during evening twilight in their breeding season in the northern hemisphere. Scientists have proposed several possible explanations: they might be searching for food (as they feed on aerial insects), or they could be using this time for orientation, since twilight allows them to simultaneously detect landscape features, light polarization patterns, stars and magnetic cues.	"[""The functional significance of many animal behavioural patterns still eludes us. This is true even for the behaviour of the common swift (Fig. 2). It has long been known that during their breeding season in the northern hemisphere, swifts ascend to high altitude in the evening twilight. The common swift spends nearly its entire life on the wing. Foraging, mating and even nocturnal roosting are performed in flight, the latter possibly involving an ability to sleep with only one of the brain hemispheres while the other remains alert. Only breeding birds usually spend the night on the nest. So, up to now, hypotheses about the functional significance of the swifts' twilight ascents have all been related to their nocturnal flight behaviour.\nUntil recently, scientists entertained the hypothesis that during dusk ascent swifts select optimal flight altitudes for roosting. However, earlier work established that swifts do not select altitudes with slow or moderate winds that would minimize energy expenditure during roosting. This is all the more surprising because, so far, swifts are the only species for which scientists have demonstrated an ability to compensate for nocturnal wind drift during migration. The apparent paradox between the ability of swifts to compensate for strong wind drift during migration and their low selectivity for wind drift during roosting only demonstrates that the functional significance of twilight ascent is still not well understood.\nAn alternative possibility that has been mentioned is that the swifts' flights to high altitude at dusk represent foraging decisions because their feeding is entirely dependent on aerial fauna such as insect swarms. Weather at the breeding site is not always favourable for feeding and swifts are faced continuously with movement decisions depending on proper assessment of weather conditions. Another possibility is orientation. Twilight is a key period for combining information from different navigational systems because it allows simultaneous detection of landscape features, light polarization patterns, stars and magnetic cues.\nIn the present issue (pp. ?–?), Adriaan Dokter (University of Amsterdam and Royal Netherlands Meteorological Institute, The Netherlands), Susanne Åkesson (University of Lund, Sweden), Hans Beekhuis (Royal Netherlands Meteorological Institute), Willem Bouten (University of Amsterdam), Luit Buurma (Military Aviation Authority, The Netherlands), Hans van Gasteren (Royal Netherlands Air Force, The Netherlands) and Iwan Holleman (Royal Netherlands Meteorological Institute and Radboud University Nijmegen, The Netherlands) use a C-band Doppler weather radar, probably the first usage of an operational weather radar for this purpose, to test hypotheses about the functional significance of the swifts' twilight ascent. The authors employed the weather radar in two modes. The conventional scanning was used to derive altitude profiles of bird density. Altitude profiles were also generated for so called ‘clear air’, which includes insects and aerial plankton. The second, fixed-beam mode was used to record individual wing beat signatures, which allow species identification. The relatively low wing beat frequency in combination with a characteristic pattern of alternating flapping and gliding phases of varying length identifies the birds uniquely as swifts.\nClick here to view the full editorial by Michelle Pellissier Scott (Executive Editor)\nFigure 2. A common swift in flight. Photo: Anders Hedenström.""]"	['<urn:uuid:4ef02dd1-5737-446d-93cb-45e869c7ecba>']	open-ended	with-premise	concise-and-natural	distant-from-document	single-doc	novice	2025-05-01T22:47:46.423955	9	63	515
54	Hey, I'm fascinated by archaeological digs happening in Israel. What are they searching for at the Tel Shiloh site and have they found anything interesting so far?	At Tel Shiloh, archaeologists are searching for remains of the tabernacle, which is believed to be a shrine that hosted the Ark of the Covenant - a wooden chest said to have contained the ten commandments on two stone tablets. In their third year of excavation, they have made some discoveries, including a ceramic pomegranate, which is a fruit symbolically associated with the holy shrine. However, they haven't found anything decisive about the tabernacle's location yet.	"['A day of archaeological digging by the Associates for Biblical Research always begins with a reading of the Bible, the very text of which they are trying to demonstrate the historical reliability.\n""I am the light of the world. Whoever follows me will not walk in darkness, but will have the light of life,"" repeated the group of twenty ideologically-driven Evangelical Christians, mostly pro-Israel Americans on the white religious right of the faith at odds with many of its strands in the Middle East.\nIt is barely 5am in Jerusalem, and team members are just boarding a bus heading to Tel Shiloh, an archaeological site on private Palestinian land in Area C of the occupied West Bank, which is subjected to full Israeli control.\nThere, they say, may lie the remains of the tabernacle – the shrine that is believed to have hosted the Ark of the Covenant, a wooden chest said to have held the ten commandments on two stone tablets.\nThe dig site is suffused with a mild morning light. In a camel-coloured cowboy hat and sunglasses, always flashing a bright smile, team leader Dr Scott Stripling, 54, fits the Hollywood picture of an archaeologist. His work, however, is far from conventional.\nA proud Evangelical Christian, he and his team believe the Bible is to be read literally and it serves as a textbook for their research.\n“Is the Bible a reliable historical document? Some Israeli colleagues disagree, but I believe so,” says Mr Stripling, also arguing that many archaeologists are biased against the “holy word”.\n""On the one hand, we have the Old Testament and, on the other hand, archaeological artefacts. Is there a verisimilitude? That\'s what we expect.\n""But I don\'t walk around with a Bible in one hand and a shovel in the other.”\nIt is the third year of the excavation in Tel Shiloh and Mr Stripling hopes to find new clues to confirm that the elusive tabernacle was once located here. Last year, they discovered a ceramic pomegranate, a fruit symbolically associated with the holy shrine.\nThe pieces unearthed in Tel Shiloh are brought back to Jerusalem each day, before being analysed in collaboration with the Israeli antiquities authorities in a process critics say is disturbingly opaque. In mid-May, the Supreme Court ruled that Israel is not obligated to release information about archaeological digs in the occupied West Bank, rejecting an appeal by two non-governmental organisations.\n“Everything we find is stored in Israel and if a political solution to [the Israeli-Palestinian] conflict is found, the people in charge of the territory will then have access to the objects,” Mr Stripling says.\n“But I\'ll be dead before that happens,"" he laughs.\nThe inter-religious relationship between some Israeli Jews and American Evangelicals is sometimes labelled opportunistic. A subset of the Evangelical community believes that the return of the Jewish people to the land of their ancestors is necessary for the return of the Messiah and the end of times, as laid out in the Bible. Israeli authorities, meanwhile, are searching for allies to support their half-century old military occupation.\nEmeline and Perry Ginhart, a newly-wed American couple, hope to make more discoveries that will help support the authenticity of their Messianic vision of Christianity. They visited Tel Shiloh last May for their honeymoon, paying thousands of dollars to be allowed to take part in the dig. Both amateurs with no professional experience in archaeology, they spent long hours clearing the tiny area of dirt they were in charge of under the scorching sun.\n""By helping Israel, we are helping our cause. Our creator gave us these lands to take care of,” says Mr Ginhart.\nLeah Tramer, one of the few Israelis in the team, is a former research assistant at Tel Aviv University and a self-declared ""former leftist"". She says her political views changed after a particularly violent attack by Palestinian militants.\nSince then, she has been working for the University of Ariel, located in a large Israeli settlement in the occupied West Bank. She helps American Evangelicals who come to the area to dig – to them, Judea and Samaria, the biblical name they give to the West Bank, is a natural extension to the current Israeli state.\n""There is nothing more exciting than doing research related to the Bible,"" she says.\n""It is wonderful that Christians are helping us to recover our past.”\nArchaeological finds are used in a political and ideological context as theoretical evidence for the importance of Jewish heritage over Palestinian links to the land.\n""Israel uses archaeology as a political tool in East Jerusalem and the West Bank to try to justify its presence. This explains why they are working with Evangelicals, who support the same narrative,"" Yonathan Mizrachi, director of the left-wing Israeli NGO Emek Shaveh, told The National.\n“Evangelicals don\'t do research for the benefit of the local community but for their own benefit and to support the occupation.”\nMany other sites beside Tel Shiloh have raised controversy, in a land where archaeology is inherently political. The City of David in occupied East Jerusalem\'s Palestinian neighbourhood of Silwan (also known as Wadi Hilweh) is, according to biblical references, the original site of Jerusalem at the time of King David some 3,000 years ago. It is now a popular pilgrimage site for Evangelicals from all over the world.\nLast month, US Ambassador to Israel David Friedman and White House Mideast peace envoy Jason Greenblatt participated in an inaugural ceremony there to unveil the ""Pilgrimage Road,"" a now-subterranean stairway that is said to have served as a sacred Roman-era road for Jews to the Temple Mount.\nAccording to local residents, underground excavations at the site, which have lasted for years, have severely damaged 15 Palestinian houses.\nMazen Aweida, 48, points to thick cracks running along the walls of his home, where the kitchen sink has half-collapsed and the bedroom floor has buckled.\n""We\'re miserable,"" he says.\n""I have young children and I\'m afraid debris will fall on them. It stresses me out a lot,"" the father of seven whispers, glancing at his little boy sitting next to a gaping scar running from the floor to the ceiling.\nMany residents are convinced that archaeological digs are part of a broader strategy to drive Palestinians out and take control of their land.\nThe City of David Foundation, a nationalist Israeli organisation behind the project and known by its Hebrew initials ELAD, declined a request to comment, but it has previously denied responsibility for damage to Palestinian homes.\nA European specialist who has been working in the Middle East for decades decried Biblical archaeology, questioning those who believe that all of the Bible was intended to be understood literally.\n“The Israeli army must stop the archaeological massacre in the occupied territories,” said the specialist, who asked not to be named.\nAt 1pm, the sound of a shofar, a traditional Jewish horn, echoes through the rocky hills of Tel Shiloh to mark the end of the day’s dig. But those taking part will be back tomorrow in search of the holy tabernacle, despite the fact that they are yet to find anything decisive.\n“The absence of proof,” says Mr Stripling, “is not the proof of absence.”']"	['<urn:uuid:c79d9585-086c-4882-b90a-f0ef0e236c7c>']	open-ended	with-premise	verbose-and-natural	similar-to-document	single-doc	novice	2025-05-01T22:47:46.423955	27	76	1203
56	As a veterinary student focusing on feline development, I'm curious about the exact timeline of when kittens get their first teeth and how the teething process progresses - could you explain the key stages?	Kittens are born with no visible teeth, just gums. Their deciduous milk teeth start erupting through the gums at around 21 days old, and this teething process continues for about 5 weeks until the kitten is roughly 2 months old. These deciduous teeth, totaling 26, will begin to fall out once the kitten is around 6 months old. Within 8 weeks, all deciduous teeth should be replaced by permanent teeth. By 8 months of age, cats will have all 30 of their permanent teeth.	['Ever looked at your cat and wondered how many teeth they have? You are not alone!\nAfter all, your cute and cuddly kitten is the pinnacle of hunting evolution – they are bound to have some serious chompers in there!\nAn adult cat will have 30 teeth unless something has gone wrong at some point!\nCats who have more than 30 teeth may run into problems so could benefit from a trip to the vet.\nCats who have fewer teeth may have had them accidentally or deliberately removed.\nCurious? Keep reading to discover everything you need to know about your cat’s dentition!\nHow Many Teeth Do Cats Have?\nLike humans, cats have two sets of teeth in their lives. They have a set when they are young that drops out when the second set pushes through the gums.\nThe first set of teeth, a bit like a human child’s milk teeth, are called deciduous teeth.\nA kitten will have 26 deciduous teeth that fall out when the permanent teeth, or adult teeth, develop. An adult cat should have 30 permanent teeth.\nWhen Do Cats Get Milk Teeth?\nLike a human baby, a kitten is born with no visible teeth. They are just gums!\nAt around 21 days old the deciduous milk teeth – the ones that drop out – erupt through the gums.\nThis teething process will carry on for around 5 weeks until your cat is roughly 2 months old.\nRead more about the teething process below.\nWhen Do Cats Get Permanent Teeth?\nFortunately for your kitten, teething in cats is a fairly swift window of their lives. The process is even quicker for permanent teeth.\nOnce teething has finished and all of their deciduous teeth have erupted, your cat should be around 2 months old.\nThese teeth will begin to fall out once your kitten is around 6 months old – this is just a 4-month window for them to have baby teeth!\nWithin 8 weeks, all of their deciduous teeth should have fallen out and been replaced by its permanent counterpart and a few extras.\nBy the time your cat is 8 months of age, they will have all 30 of their permanent teeth ready to start chomping!\nDo Kittens Go Through The Teething Process?\nYes, kittens go through teething.\nThe first phase is when their deciduous teeth are coming through. This can be an unpleasant experience for your kitten.\nAs teeth are central to a cat’s overall health and well-being, it is recommended that you get them used to tooth brushing as soon as possible.\nIt is generally recommended that you get your cat used to your fingers being in or near their mouths before this stage of teething begins.\nThis is because teething can be very uncomfortable, and you don’t want to create any negative connotations between the toothbrush and pain.\nThe second phase of teething takes place when the adult teeth push to erupt and deciduous teeth fall out.\nDuring this time, the tooth buds gradually get closer to the gum line – ‘tooth buds’ is the term for undeveloped permanent or adult teeth.\nThese buds move through the bone of the jaw and eventually out of the gums and into the mouth.\nIn an ideal world, this eruption of the adult tooth would force out all the deciduous teeth 100% of the time. However, this does not always happen.\nOccasionally you may notice that the adult tooth has grown alongside the tooth that should have fallen out. When this happens, the milk tooth is called a persistent deciduous tooth.\nYou should not be alarmed if you find deciduous teeth or tooth shells while your kitten is teething – it is perfectly natural!\nYou also shouldn’t worry if you do not find all of their deciduous teeth as most of them will fall out while your kitten is eating, and they are usually swallowed.\nThis rarely causes issues. Remember that your kitten is likely to be in discomfort during this time so may not want to eat.\nYou may also notice that your kitten is more irritable, more forlorn, producing more drool, or has bad breath.\nAgain, these symptoms are natural and are not necessarily something to be concerned about.\nIt may be necessary to seek veterinary advice if these symptoms are particularly severe or if they persist for longer than a few weeks.\nOne other key thing to remember is that your kitten will want to chew when they are first teething.\nThe pressure in their gums when they clamp down with their jaws can help alleviate the pain and encourage the new teeth to erupt.\nKeep in mind that you may need to direct your cat’s chewing to appropriate things!\nChewing toys? Yes! Chewing humans? No! You also need to make sure that they are not chewing very hard objects.\nThese will damage the teeth as they come out of the gum.\nWhat Is A Persistent Tooth?\nA persistent tooth is a deciduous tooth that does not fall out when it is supposed to and stays in place next to the permanent tooth.\nThis means that it is taking up room in your cat’s mouth that it shouldn’t, often causing the adult or permanent tooth to erupt at a bad angle or in a weird position.\nThis can have serious consequences.\nKeep a particular eye out for your kitten’s upper and lower canine, and incisor deciduous teeth. These are the ones that are most likely to be persistent.\nAre Persistent Teeth Bad?\nIn short, yes. Persistent teeth are not good for your cat.\nYour cat has evolved to have 30 permanent teeth as an adult – anymore is too many and will cause issues.\nOvercrowding of your cat’s teeth or a permanent tooth in a suboptimal position can cause an abnormal bite to develop.\nThis is called malocclusion and needs to be avoided as much as possible.\nThis is because your cat’s teeth are sharp so any tooth hitting tissue it isn’t supposed to will cause serious damage quickly.\nKeep in mind that any dental misalignment can have serious consequences and affect your cat’s comfort.\nIt is common that these types of issues prevent them from eating properly, causing more damage to their health down the line.\nProper orthodontic treatment will guarantee that your cat has a happy life!\nHow Do I Treat My Cat’s Persistent Tooth?\nKeep an eye on your kitten as their deciduous teeth fall out. As soon as you notice a persistent tooth, make an appointment with your vet.\nThey will likely need to extract the tooth to keep your cat healthy.\nRegularly checking your cat’s mouth is important as treating misalignment issues early gives your cat the best chances of normal and healthy development.\nShould I Brush My Cat’s Teeth?\nYes! Brushing your cat’s teeth is by far the easiest way to prevent dental plaque and to keep your cat’s oral health in top condition.\nYou need to slowly introduce your cat to having their teeth brushed, with the end goal of incorporating this into their daily routine.\nYou must implement a tooth cleaning regime slowly, no matter what age your cat is.\nKittens have 26 deciduous teeth – fall out – and then 30 permanent teeth as adult cats.\nIt is essential to keep an eye on your cat’s oral hygiene no matter their age but is particularly essential to regularly check your kitten’s mouth when their deciduous teeth are coming out to monitor any persistent teeth.\nAs soon as you notice two teeth in one spot, you need to make an appointment with your vet to have some treatment.']	['<urn:uuid:a89aa88c-5492-41a5-bc0f-27343914df88>']	open-ended	with-premise	verbose-and-natural	similar-to-document	single-doc	expert	2025-05-01T22:47:46.423955	34	84	1274
57	mosquito virus symptoms effects	Chikungunya, a virus transmitted through mosquito bites, causes severe symptoms including crippling headache, vomiting, and swelling of limbs, and can potentially lead to death. Even after the fever subsides, patients may experience chronic symptoms such as intense joint pain, insomnia, and extreme prostration. The virus, originally found in sub-Saharan Africa, has now spread worldwide due to deforestation and climate change, with recent outbreaks occurring in USA and Europe.	['New vaccine technology delivers potent results for Chikungunya\nCredit: University of Bristol\nA new type of vaccine that can be stored at warmer temperatures, removing the need for refrigeration, has been developed for mosquito-borne virus Chikungunya in a major advance in vaccine technology. The findings, published in Science Advances today [Wednesday 25 September], reveal exceptionally promising results for the Chikungunya vaccine candidate, which has been engineered using a synthetic protein scaffold that could revolutionise the way vaccines are designed, produced and stored.\nInfectious diseases continue to plague populations worldwide. Among the means at our disposal to counter this threat, vaccination has proven to be exceptionally powerful. Smallpox has been eradicated, measles, polio and tetanus constrained from the world by vaccination. However, severe challenges to human health persist, evidenced by epidemics caused by Ebola, Zika and others. This is particularly severe in developing countries which often lack adequate infrastructure and resources to prevent or manage outbreaks, bringing about disruption and damage in affected communities and massive economic shortfall.\nA recent example is Chikungunya, a virus transmitted by the bite of an infected mosquito. The disease causes crippling headache, vomiting, swelling of limbs and can lead to death. Even if a fever ends abruptly, chronic symptoms such as intense joint pain, insomnia and extreme prostration remain. Formerly confined to sub-Saharan Africa, Chikungunya has recently spread worldwide as its mosquito host leaves its natural habitat due to deforestation and climate change, with recent outbreaks in USA and Europe causing alarm.\nResearchers from the University of Bristol and the French National Centre for Scientific Research (CNRS) in Grenoble, France, teamed up with computer technology giant Oracle to find a way to make vaccines that are thermostable (able to withstand warm temperatures), can be designed quickly and are easily produced.\n“We were working with a protein that forms a multimeric particle resembling a virus but is completely safe, because it has no genetic material inside, said Pascal Fender, expert virologist at CNRS. “Completely by chance, we discovered that this particle was incredibly stable even after months, without refrigeration.”\n“This particle has a very flexible, exposed surface that can be easily engineered, added Imre Berger, Director of the Max Planck-Bristol Centre for Minimal Biology in Bristol. “We figured that we could insert small, harmless bits of Chikungunya to generate a virus-like mimic we could potentially use as a vaccine.”\nTo validate their design, the scientists employed cryo-electron microscopy, a powerful new technique recently installed in Bristol’s state-of-the-art microscopy facility headed by Christiane Schaffitzel, co-author of the study. Cryo-EM yields very large data sets from which the structure of a sample can be determined at near atomic resolution, requiring massive parallel computing.\nEnabled by Oracle’s high-performance cloud infrastructure, the team developed a novel computational approach to create an accurate digital model of the synthetic vaccine. University of Bristol IT specialists Christopher Woods and Matt Williams, together with colleagues at Oracle, implemented software packages seamlessly on the cloud in this pioneering effort. Christopher explained: “We were able to process the large data sets obtained by the microscope on the cloud in a fraction of the time and at much lower cost than previously thought possible.”\n“Researchers have had a long tradition of building and installing their own super computers on-premises, but cloud computing is allowing them to run large data sets in record time, with fast connectivity and low latency. This is helping them crunch data and make scientific breakthroughs much faster. Going forward, technologies like machine learning and cloud computing will play a significant part in the scientific world, and we are delighted we could help the researchers with this important discovery,” added Phil Bates, leading cloud architect at Oracle.\nThe particles the scientists designed yielded exceptionally promising results in animal studies, soundly setting the stage for a future vaccine to combat Chikungunya disease.\n“We were thoroughly delighted,” continued Imre Berger. “Viruses are waiting to strike, and we need to have the tools ready to tackle this global threat. Our vaccine candidate is easy to manufacture, extremely stable and elicits a powerful immune response. It can be stored and transported without refrigeration to countries and patients where it is most needed. Intriguingly, we can now rapidly engineer similar vaccines to combat many other infectious diseases just as well.”\n“It really ticks a lot of boxes,” concluded Fred Garzoni, founder of Imophoron Ltd, a Bristol biotech start-up developing new vaccines derived from the present work. “Many challenges in the industry require innovative solutions, to bring powerful new vaccines to patients. Matching cutting-edge synthetic biology with cloud computing turned out to be a winner.”\nThe authors would like to thank the Finovi Foundation, the Agence National de Recherche (ANR), EPSRC, BBSRC, Wellcome Trust and GW4 for their support.\n‘Synthetic self-assembling ADDomer platform for highly efficient vaccination by genetically-encoded multi-epitope display’ by Vragniau et al in Science Advances']	['<urn:uuid:e1b9f921-e42c-44a0-983e-f2aaab958e8e>']	open-ended	direct	short-search-query	distant-from-document	single-doc	novice	2025-05-01T22:47:46.423955	4	68	808
58	compare warehouse automation cold storage medical supplies handling	Both industries use automation, but in different ways. Cold storage uses automation for temperature monitoring, preventing spoilage, and handling frozen goods, particularly in food storage. Medical supply warehouses like McKesson use automation through A-Frame systems for picking pharmaceuticals and medical supplies, with integrated technology to track expiration dates and ensure accurate order fulfillment.	['Industrial robots are replacing some of the more menial jobs in the average supply chain. These robotic devices – often known as automated storage and retrieval systems, or AS/RS – are streamlining operations across many different industries.\nCold storage probably isn’t the first industry that comes to mind when thinking of advanced robotics or industrial automation. With such stringent requirements surrounding temperature control and the quality of cold products, consistent human interaction was always a necessity. With next-gen technology on the rise, the entire industry will see several key improvements.\nStrengthening Accuracy in Staging and Picking\nWhile human order pickers are rightfully concerned that robots will replace their jobs, automation ultimately enhances the typical supply chain in many different ways:\n* Deadline-oriented staging: Automated systems are fully customizable and schedulable. They can also work around the clock to meet last-minute deadlines or ad-hoc requests.\n* Accurate picking: Automation improves the accuracy of outbound shipment. Let’s face it: humans aren’t perfect. Even the most diligent employees are prone to making mistakes. Outside of any errors in their programming, robots will perform their duties flawlessly and without end.\nBut the supply chain revolution isn’t spurred on by AS/RS alone. It has a valuable partner in the Internet of Things – or IoT – and many of its benefits target the sector of cold storage.\nReducing the Risk of Contamination or Spoilage\nContamination and spoilage provide substantial challenges to the cold storage supply chain. According to Kroger’s CIO, Chris Hjelm, issues like drastic temperature changes, malfunctioning hardware and human error are all common.\nHis company recently adopted an IoT strategy to address such problems. Their new system – which utilizes the IoT – uses automation to monitor temperatures inside their freezers. If something is amiss, the system instantly generates an alert. Apart from preventing unnecessary contamination or spoilage, this saves employees from having to check the temperature twice per day.\nOther industries depend on cold storage, too. The medical industry uses cold storage to facilitate drug testing and storage, mixing specific ingredients and handling human tissues before surgery. Many manufacturers – including those in automotive, clothing and metalworking – test or store their goods at low temperatures to ensure durability, longevity and freshness.\nGrocers and manufacturers will adopt similar automated systems as the IoT becomes more mainstream. Not only will we see automation in factory and warehouse settings, but we’ll it in more public-facing positions like this. If a shopper accidentally leaves a freezer door ajar, the IoT can detect this – via automated sensors – and transmit an immediate alert.\nEmbracing the Cold Storage Warehouse\nLong-term storage of frozen foods and other consumer products is one of the biggest challenges in the cold storage supply chain. Not only is this phase also prone to human error, but it requires extra attention due to the time-sensitive nature of frozen goods.\nOnce again, industrial automation has the potential to save the day. By automating processes like stock rotation, warehouses can ensure that they’re always distributing fresh items. RFID chips and scanners provide a way of tracking expiration dates, too, and automated picking systems can locate these expired goods for separation and eventual disposal.\nAccording to Jeff Hedges, director or business development with HK Systems, companies with more than 8,000 pallet positions might reduce labor and energy costs by 60 percent to 80 percent by embracing the automated cold storage warehouse model. The increased automation also reduces the company’s footprint by as much as 50 percent.\nStreamlining a warehouse layout and reducing floor space is just the start of things to come. By using innovations like data analytics and the IoT in tandem with industrial automation, manufacturers can reduce their long-term storage needs altogether. By accurately forecasting consumer habits, staging expected orders and capitalizing on recent trends, it’s possible to elevate the supply chain – and, by extension, the customer experience – to brand new heights.\nHow Automation is Finding its Way Into Various Supply Chains\nThe effects of industrial automation and robotics are increasingly seen throughout our society. Whether it’s making sure a freezer door is closed at the local grocer or staging an order to save time and expedite delivery, automated systems are seemingly everywhere. It’s easy to write this off as another fad or trend, but make no mistake – automation has entered the modern supply chain and it’s here to stay.\nCredit: Megan Ray Nichols', 'Traditionally, warehouses have been sprawling, manually operated facilities with a handful of forklifts, a waiting room for truck drivers and stacks of paperwork to document transactions. However, shifts in retail distribution have boosted the distribution center and warehouse industry into a high-tech, fast-paced world. Today, managers process unprecedented volumes of goods, while keeping workers safe and moving products to and from trucks within hours—sometimes while packing and repacking those goods—and do it with as few errors as possible. Enabling this transition is technology such as robotics, drones, mass conveyor systems and the internet of things (IoT) technology to track what is taking place in real time.\nIntegrators are taking on a variety of installations to help the logistics industry meet the demands of an impatient world.\nThe evolution from standard warehouse to intelligent distribution center was already underway when COVID-19 upended the economy and the supply chain. In fact, digitalization and intelligence in retail distribution vaulted forward in 2020 at a rate that had been on a 10-year trajectory before the pandemic. In part, this was fueled by those ordering goods that they expect to receive today, not in a few days or next week.\n“It starts with the consumer,” said Jim Dempsey, director of U.S. business development and partnerships at Panasonic System Solutions Co. of North America, Newark, N.J. While initially the expectation was for orders to be fulfilled, shipped and received within a week or two, buyers now order food, household goods, office supplies or manufacturing tools and supplies with the expectation of receiving the product in just a few hours.\nThat has required many changes in warehouses. New facilities are opening closer to customers, receiving, storing and shipping a wider variety of products. Because goods move so quickly, more pickers are at work in the warehouses, too.\nAdditionally, Dempsey said returns are skyrocketing. As much as 30% of goods ordered online are being returned today. That means warehouses are receiving a high volume of product from both ends of the supply chain.\nWith the pandemic still untamed, employers need to ensure workers don’t come into close proximity with each other and potentially cause a spreader event in the warehouse. Tech tools can solve most of these problems and are widely employed.\nPanasonic sells products equipped with technology such as Bluetooth, Wi-Fi and RFID for asset tracking, and it also has an IoT Solutions division focused on technology to help numerous industries, including warehouses, track people and equipment. With location-based data, warehouses can leverage real-time and historical information based on sensor data about the flow of goods in the facility, delays, bottlenecks and potential for error.\nHealthcare is another market with critical supply-chain requirements. Pharmaceutical and medical supply company McKesson Corp., Irving, Texas, uses intelligent warehouses to move its healthcare products and medications.\nAt a typical McKesson warehouse, thousands of workers pick and pack goods together with automated systems; speed and accuracy are critical. McKesson uses integrated technology to reduce workers’ steps with A-Frame—a self-contained, automated piece-picking machine—for the fastest moving products. This configurable technology is used for picking and packing small goods such as pharmaceuticals, cosmetics, tobacco, office items and contact lenses. An order storage and retrieval system also brings products to associates as they are packed for orders, and the system automatically detects the goods and their expiration dates before shipping to the customer.\nSystem software, in many cases, collects data about what is taking place in real time so management can oversee operations without being directly on the busy floor, thereby increasing the ability to work remotely and reduce the number of people in the warehouse.\nMobile devices, fixed readers and scanners identify what is being picked or packed, as well as when goods come into and leave the warehouse, reducing the need to stop and scan bar codes and preventing errors before they can happen, such as a carton being loaded on the wrong van.\nBlockchain data captures the details related to what takes place on-site and stores that information in immutable ledgers that can be viewed by warehouse managers, shippers and customers to understand what is occurring during the loading of goods.\nIn addition to conveyor belts, automatic vehicles such as driverless forklifts and drones help keep track of what is on-site. Some of this warehouse automation includes conveyors and robotics—an automated system to receive, store and retrieve goods as needed. Robotic capabilities are continuing to improve. In 2019, Amazon, had 200,000 robots already in use, working alongside hundreds of thousands of human workers.\nOver time, this smart warehouse technology could reduce the carbon footprint of some of the largest logistics centers, since the added efficiency and visibility results in less movement of goods on-site and fewer workers who require lighting and HVAC systems.\nStill, warehousing technology remains woefully behind that of today’s manufacturing facilities. Logistics Bureau, a global specialty management consulting company headquartered in Sydney, has also indicated a fast-paced change in warehouse management even before COVID-19 put new pressure on the supply chain. The long-term goal is to reduce the number of workers on-site by using technology to make warehouse activities more efficient. Faster picking is accomplished through software on forklifts that points workers to the location of goods, using technology such as real-time location systems.\nPaperwork is eliminated as each transaction is automatically stored based on the location of the forklift, the warehouse operator and the delivery vehicle parked at the dock doors. For instance, TagMaster North America, Tacoma, Wash., has a solution in which battery-assisted passive RFID tags can be applied to forklifts to identify when they are approaching an automated door and confirm whether the door will open. The same technology can be used to alert drivers if they come within range of each other, which helps prevent collisions.\nIn the long term, the focus will be on reducing the need for personnel in more automated warehouses, which could reduce expenses on several levels, including the cost of energy used on-site as well as payroll. When it comes to lighting, LED industrial fixtures are replacing the conventional lamps, which use a fraction of the energy required traditionally, while the level of lighting required can be lower, which saves carbon footprint and cost.']	['<urn:uuid:01e42156-cb2d-4ac0-9339-e6ca10d6b958>', '<urn:uuid:3108f115-691e-4087-9237-359637ce701c>']	factoid	direct	short-search-query	similar-to-document	comparison	novice	2025-05-01T22:47:46.423955	8	53	1768
60	What hardware components are essential to assemble a CNC machine?	A CNC machine typically requires both electrical and mechanical parts. The essential electrical components include a processor/control board (or PC), stepper shield, stepper drivers, and power supply. For mechanical parts, you need cutting tools, a frame, guides and supports, as well as basic hardware like spacers, washers, nuts, screws, and bolts.	['CNC machines have been around for decades, with their history stretching back to the 1950s. In that time, they’ve transformed the way we manufacture things. They’ve also helped to democratize the process, providing a way for budding engineers and makers around the world to create their own products. With such versatility on offer, you—yes, you!—might be wondering how to build your own CNC machine.\nIf this sounds like you, never fear—the team at Scan2CAD is here to help. We’re here to provide handy tips on building a CNC machine. We’ll include some great options for CNC kits, as well as details and resources covering how to build your own CNC machine from scratch. Let’s get started!\nWhat to look out for\nSo, you’re about to build your own CNC machine. But where do you start?\nBefore comparing kits or choosing components, it’s important to start answering some fundamental questions.\nWhat are you going to make with your CNC machine?\nOf course, CNC machines are versatile, and allow you to create a wide range of different products. However, different types of CNC machine are better for different projects.\nStart by considering the types of projects you’re likely to take on, and use this as a basis for the type of CNC machine you choose. This decision will also inform the components you need to produce your machine.\nHow much time do you have to build the machine?\nThe answer to this question will derive in part from whether you are interested in CNC as a hobby or as a potential business. After all, it’s worth spending longer on your machine if there are possible financial rewards at the end.\nHowever, this isn’t the only factor you should take into consideration. CNC Cookbook recommends that, if this is your first build, that you start with a simpler machine. This way, you’ll be more likely to get it done, rather than biting off more than you can chew and giving up.\nHow much are you looking to spend on your CNC machine?\nMuch as with the above question, your answer here will partly arise from whether you intend to use the machine for professional or personal use.\nIn both scenarios, however, it’s always worth trying to get the most for your money. As such, you should evaluate which parts and components are necessary for the machine you want to build. If you don’t need them, don’t buy them! Set yourself a budget you know you can afford, and stick to it.\nWhat skill sets do you have?\nIt’s easier to build your own CNC machine if you already have some of the necessary skills. As such, aim to complete a project that plays to your experience.\nIf you’re already experienced in woodworking or metalworking, then you may wish to try out a more challenging project. A newcomer, meanwhile, may wish to start out with something simpler.\nA CNC kit is an incredibly convenient way to build your own CNC machine. That’s because a kit generally comes complete with everything you need to put your machine together and get started with making things.\nMost kit manufacturers will also offer a number of customization options. This allows you to choose the right components to suit your needs. You can opt for the most basic package if you’re on a tight budget—or splurge if you have more specific requirements.\nThankfully, here at Scan2CAD, we’ve already put together a list of some great CNC kits for beginners. Featured on the list are:\n- MillRight CNC — though basic, this comes in as one of the cheapest CNC kits on the market. A great option if you’re looking to build your own CNC machine for the first time.\n- Shapeoko — this machine arrives partially assembled, making it one of the easiest projects to complete. If you’re feeling more ambitious, Shapeoko is also hackable, giving you real freedom to modify the machine.\n- Maslow — affordable CNC—bigger. Maslow offers users a massive 4’x8′ workspace, letting you create large projects easily.\n- Next 3D — don’t want to get your hands dirty? The Next 3D offers users the chance to build a CNC machine without soldering, drilling or gluing. Simply screw together and get going in no time.\nLooking for more detail? Check out our full list of the best CNC kits for beginners.\nBuild your own CNC machine from scratch\nUsing a CNC kit is one of the easiest ways to get up and running, but it’s not for everyone. If you’d rather have the freedom to build your CNC machine your way, then building from scratch can be a great option.\nWhat you’ll need\nAs you may have already guessed, there are a vast array of possibilities when it comes to building a CNC machine. However, your CNC machine will likely include most, if not all, of the following parts:\n- Electrical parts, including:\n- Processor/control board (some machines may use a PC)\n- Stepper shield\n- Stepper drivers\n- Power supply\n- Mechanical parts, including:\n- Tools, such as cutting tools\n- A frame\n- Guides and supports\n- Spacers, washers, nuts, screws, and bolts\nOf course, figuring out which type of CNC machine to build will help to clarify which parts you’ll need. If you’re struggling to come to a decision, check out our comparison of CNC machines to find out which one’s right for you.\nThe exact assembly of your CNC machine will depend on the type of machine you choose to build, the custom options you choose, what you plan on making with the machine, and many other factors. Nevertheless, the key steps to build your own CNC machine will generally be as follows:\n1. Design your machine\nCreating a design for your CNC machine will help give you a clear idea on the finished project. You may choose to start out with a sketch, before converting the paper drawing to CAD using programs such as Scan2CAD. From there, you can extrude your 2D drawing into a 3D CAD model in programs such as SolidWorks (or one of our top affordable SolidWorks alternatives).\n2. Get the parts\nOnce you’ve designed your machine, you can then proceed to buying the parts for it. Use the list above as a guideline, but feel free to customize the machine to meet your requirements!\n3. Construct the frame\nYour frame is what holds together all the other parts of your machine. As such, it’s the first construction you’ll perform when you build your own CNC machine. Metals such as aluminum are good choices for your frame, as they will ensure stability and rigidity. This will, in turn, help increase the lifespan of your other hardware.\n4. Add the gantry\nNot all CNC machines will feature a gantry, but as one of the most popular design options, we’ve featured it here. A gantry allows your machining tool to move along the Y-axis; it will hold your tool in place above the workspace. Ensure to balance forces acting on your gantry to reduce the potential of machine deformation or shaking.\n5. Bring in the Z-axis…\nYour tool itself will be moving up and down along the Z-axis. You will, however, need a place to house your tool. You’ll mount this housing to the gantry, giving your tool a greater range of depth.\n6. …then the X-axis\nAdding bearings and guide rails will help to maintain the rigidity of your CNC machine, and will enable your tool to move forwards and backwards along the X-axis.\n7. Drive it!\nNow that you’ve added the parts that will allow your CNC to move forwards and backwards, it’s time to add those that will actually make it move on this axis. This is the drive system, typically made up of motors, pulleys, spindles, screws, bolts and nuts, amongst other parts.\n8. Introduce the electronic parts\nYou’re now ready to add the many electronic parts that will make up the heart of your CNC machine. Key to this is the motor that will, ultimately, drive the machining tool. In this case, you’ll have a choice of stepper and servo motors. However, this is far from the only important tool: you’ll also need to include a PSU, breakout board, drivers, and—of course—a processor or computer.\n9. Put the table top on\nYou can’t machine parts without having a place to put them! Your cutting table can be made of plywood, MDF or metal. Bear in mind, however, that not all of these materials will be suitable for the type of CNC machine you’re creating!\n10. From rotational to linear movement\nThe motor you’ve installed will cause the machine to spin. However, your CNC machine will typically require linear motion. A spindle converts the rotational motion of the motor to linear motion, meaning that your machining tool will be able to move up and down.\n11. Choose your controller\nA CNC controller is vital to the operation of a CNC machine. This is the part that interprets the signals given by your processor or computer, and transforms them into signals for the electronic parts of your CNC machine. As such, it acts as the “brain” of the entire system.\n12. Select your software\nYour machine is now almost operational! First, however, you’ll need to choose the software that controls your CNC machine. Most of these will use languages such as G-code to control the movement of your machine along its three axes, enabling you to perform the action of machining.\n13. Add your machining tool\nThere are a wide variety of machining tools available. Metal cutting tools are one of the simpler varieties, but more elaborate machines may use laser or plasma cutting tools.\n14. Start making things!\nYour machine is now complete, and you’re ready to start tackling your own projects!\nWhy build your own CNC machine?\nIf you’ve read this entire article, then chances are that you’re already sold on the benefits of building a CNC machine. However, if you’re still unsure, we’ll quickly run through some of the best reasons to build your own CNC machine:\n- Customizability. When you buy a CNC machine, it may lack features you need—or make you pay extra for features you don’t. If you build your own CNC machine, you have the ability to choose what (not) to include.\n- Save money. Purchasing a ready-made CNC machine can often set you back thousands of dollars. Building your own CNC machine instead can give you the same results for a much lower cost.\n- Create awesome things. Okay, so this applies to any CNC machine, regardless of whether you buy or build. But it remains true—building a CNC machine gives you the ability to manufacture your own amazing products. Whether you want to launch your own business, replace hard-to-find parts, or simply create custom products that aren’t available anywhere else, you can do it with a CNC machine. And where better to start as a maker than in building your own machine?']	['<urn:uuid:5737044f-d5b5-43b2-8676-ecec9e6dc9b0>']	open-ended	direct	concise-and-natural	distant-from-document	single-doc	expert	2025-05-01T22:47:46.423955	10	51	1834
61	photo print longevity storage methods comparison	Different photo printing methods vary significantly in their longevity. Archival pigment prints offer excellent durability because they use non-degradable pigment particles that remain on the paper's surface rather than being absorbed into fibers, preventing color fading and shifting. The Argyrotype process, developed in the 1990s, uses silver sulphamate instead of silver nitrate to create longer-lasting prints by avoiding problematic iron salt deposition that caused fading in older processes. Metal prints are particularly durable, being waterproof and scratch-resistant, while also maintaining their appearance over long periods. The choice of proper materials is crucial - for instance, fine art paper must have a neutral pH to ensure longevity, and proper storage techniques like waxing with Renaissance Wax (as used in the Argyrotype process) can further extend print life.	['The Argyrotype print process is a “modern” nineteeth century way of making silver prints on paper. It was created by Mike Ware in the early 1990’s [British Journal of Photography, 139, (6824), 17-19 (13 June 1991)].\nBack in 1842, right at the start of photography, Sir John Herschel created a process based on iron and silver called Argentotype. Later in the 19th century a whole bunch of variations on iron-silver printing were developed including Kallitype, Van Dyke, Sepiaprint and Brownprint. All these 19th century iron-silver processes suffered from the problem of clearing residual iron salts from the paper. Any iron salts that remain react with the tiny silver particles that make up the image and eventually the print will fade.\nMike Ware, who is a chemist as well as photographer and has consulted on archiving of older prints, created the Argyrotype process based on the rarer silver sulphamate rather than silver nitrate. This avoids the deposition of iron salts and partially sulphide tones the silver resulting in, we hope, longer lasting prints. More importantly from my point of view the process is very simple. It is almost as straight forward as cyanotypes. There is a single bottle of sensitiser that is coated on the paper, exposed under UV, cleared in water for 2 minutes (with a pinch of citric acid), fixed/toned in Hypo for 2 minutes and washed. When dry I then wax with Renaissance Wax. The sensitiser can be bought off the shelf (actually off the web from somewhere like Silverprint). The sensitiser has a shelf life of a year.\nI had kind of given up on plain paper based printing and was going to concentrate on making conventional silver gelatine darkroom prints but when Covid-19 arrived I lost access to my darkroom and had to look for alternatives. I ordered some Fotospeed Argyrotype sensitiser from Silverprint and have started playing. I love it. I have wanted to get the feel of salt prints for a while but that process can be messy to do in limited space, especially if you do floating paper method of sensitising, and takes a lot of tweaking.\nThe Fotospeed instructions say the contrast is about equivalent to Grade 0 on conventional photographic papers so you need really high contrast negatives. Here are my four 4×5 test negatives printed in a similar way to the way I printed them for cyanotype the other day.\nIt definitely benefits from the higher contrast negs, although you can see my coating isn’t perfect.!Prints #3 & #4 were given the same exposure (90s) but I could have cut it half a stop for #3. I’m not sure where the uneven colour comes from. I thought it was drying marks at first.\nMuch to learn and do. I feel this may be “the one” process I want to work with for a while. The sensitiser isn’t cheap but that is only in comparison to cyanotype which is practically free. The 50ml of Fotospeed sensitiser cost me £30 and according to the instructions would cover 28 prints at 8×10 – although I suspect that varies enormously by paper. If I really get into it I think I could make up my own sensitiser for less than half the cost if I had to. Doing this would also allow me to have batches of different contrast. I have a stack of archival paper/board from work that was going to be pulped that I can use so things are looking good. Next I’ll maybe try an 8×10 Fomapan 100 neg.', 'by Jeffrey Grunthaner\nMore than any other medium, photography is a misunderstood genre. Often associated with wedding photos, polaroids, and unimpressive portraits, the context, and techniques that make photographs great are generally ignored by all but specialists. Along with this, the various ways in which photographs can be presented, the different materials on which they can be printed, is even less known. But for anyone looking to amass a respectable art collection without having to break the bank, prints can be a pragmatically inexpensive alternative to the acquisition of more tactile media like paintings or sculptures. Along with the desire to develop a respectable art collection, the versatility of different printing techniques must be known.\nSimilar to the global impact of the printing press, the dawning of photography changed how we view the world and revolutionized humanity’s understanding of art. As Susan Sontag writes in On Photography, “photographed images do not seem to be statements about the world so much as pieces of it, miniatures of reality that anyone can make or acquire. Photographs, which fiddle with the scale of the world, themselves get reduced, blown up, cropped, retouched, doctored, tricked out. They age, plagued by the usual ills of paper objects; they disappear; they become valuable, and get bought and sold.” As we will see, not all photographs are on paper, and their value varies with the printing process they’re subject to. Here, we will examine some of the printing techniques that have taken the art of photography beyond the borders of the store-bought frame.\nArchival Pigment Prints\nThe term archival pigment printing refers to a process whereby non-degradable and ultra-resistant pigment particles are used to make an image that will be resistant to erosion and other environmental factors. In short, archival pigments ensure the longevity of an image. And while archival pigments have been in use since the 19th century, today the range of pigments available has been vastly enriched, and formerly difficult-to-render shades of orange, pink, and green can be easily printed.\nArchival pigment prints are perfect for artists who want to make work on demand, rather than committing to a mass-produced series. The reproduction of a stored digital image is quite inexpensive as compared with the production of a run of prints.\nRather than being absorbed into the ﬁbers of paper, as happens with molecularly soluble dyes, archival pigments utilize tiny particles which, when placed on paper, are large enough to remain on the paper’s surface. This process allows pigment prints to retain their color over a longer period of time, as the pigment will not be broken apart by absorption, and then intertwined into ﬁbers, fading, or shifting colors.\nDigital Prints on Aluminium\nDigital prints on aluminum are not really printed on the metal directly. Rather, a print is infused into a coating applied to the metal. This is a dye-based process, rather than an inkjet process. The silver color of the aluminum plate provides a shimmering image, which looks like metallic inks have been used in the photo, even though an aluminum substrate actually provides the entire sheen.\nDigital prints on aluminum are scratch resistant and rigid, requiring no glass or framing prior to hanging. This modifies the conventions of photo presentation and provides a more intimate and informal viewing experience.\nThe Magna Chrome website described their technique as follows: “Special dyes are printed onto a transfer paper and then infused into a patented coating under pressure and heat.” The images are rigid, durable, and waterproof. No glass or frame is necessary, so glare is reduced. Furthermore, the depth of the patented coating gives a luminous quality to the photos and brilliance to the colors. The image will seem to float within its coating.\nPhotographs on Fine Art Paper\nFine art printing is the term often used to refer to professional photographs printed on very high-quality paper. This designation, which is by no means a universal label, meets certain quality criteria, with regard to the paper in particular, which are sought after by many photographers and printers.\nFine art paper allows you to emphasize the composition of the image while providing the ideal support for intense colors and marked contrasts, while also enabling a wide range of grey tones.\nThe difference between fine art paper and normal photo paper lies in the composition of the paper itself. As there are different kinds of fine art paper, the process will vary depending on the material used. As a matter of fact, natural fibers (usually cotton or alpha cellulose) must be included within the composition of fine art paper. Because fine art paper is intended for the printing of high-quality photographs, its quality must be ideally suited to receiving inks and pigments. The composition of the surface layer must allow the ink to adhere well over time while offering a neutral pH to ensure that the paper also stands the test of time.\nPhotographic Print on Metal\nIt used to be that if you wanted to print on metal you’d have to make a tintype or, even earlier, go see Louis Daguerre. But in recent years, there’s been a resurgence in metallic printing options, some of which are actually printed on sheets of real metal, while others are just metallic-looking photo papers that impart a metallic look.\nIt takes a long time before the images on metallic prints start to fade. What’s more, the printed graphics and text cannot get scratched or peeled off. Metal prints can look as modern or traditional as you wish.\nThere are two ways to make metal prints. Either an inferior quality “direct print” onto an aluminum sheet, or a much higher quality “dye sublimation” process. During the latter process, dyes get transferred beneath the aluminum’s exterior coating, which ensures that the finished product is more durable than conventional paper and canvas prints.\nNeed some specific advice regarding your art collection or help in starting afresh? Benefit from our curatorial services! To know more, contact us at firstname.lastname@example.org\nGiclée printing came into existence in the wake of computer technologies becoming more and more readily available to artists. Graham Nash (of the rock band Crosby, Stills, Nash, & Young) was one of the first to successfully utilize computer printers for his printing business. Giclée prints are often an inexpensive alternative for digital artists who wish to make reproductions of their original two-dimensional artwork while preserving the original rendering for themselves.\nGiclee printing tends to hold its colors for far longer than standard prints. In fact, giclee prints are thought to last up to two hundred years before starting to fade. What’s more, there is no issue with the ‘photocopy of a photocopy’ that plagues other printing methods, and the results are often just as good as the originals. It’s also worth pointing out that giclée reproductions look just as good on other materials. Artists can use giclee print onto canvas, for example.\nSimilar to archival prints, giclée printing is a process that uses fade-resistant, archival inks and archival substrates to print on large format printers. However, not all inkjet printers produce giclee prints. It all boils down to these four elements: resolution, ink, paper, and printer type. Giclee printing is priced per sq. ft and includes color matching in the product price. The best way to provide the most accurate reproductions is for clients to mail the original artwork to an office where such products are printed.\nThe Essentials of Printing\nThe expansion of printing technology has created a bridge between fine art and commercial art. Today, the way a photographic print is made is often just as important as the composition of the original photograph. Knowing how different printed surface alter the appearance of a photograph will often help connoisseurs and collectors alike to distinguish the technical abilities of the photographer from the quality of the image presented. As we have seen, different printing processes will emphasize different aspects of a photograph, which makes these processes fall into the realm of post-production. At the same time, many photographers try to create an aesthetic whole where an image feels at one with the surface its printed on. In this case, the kind of print used will be essential to how the photograph appears.\nHave more questions? Contact our experts at email@example.com.\nJeffrey Grunthaner is a writer based in New York. You can find his work in BOMB, artnet News, The Clauduis App, Archinect, Imperial Matters, Folder, or Hyperallergic. He curates a reading series on contemporary poetics at Hauser & Wirth, West 22nd Street.']	['<urn:uuid:4d638e8b-170b-4005-9916-93b9fe405aef>', '<urn:uuid:c37d4996-3915-4039-9a11-d3cff91b143b>']	open-ended	direct	short-search-query	distant-from-document	multi-aspect	novice	2025-05-01T22:47:46.423955	6	126	2009
63	important art academies realism training	Several influential institutions for realism training include the Water Street Atelier, Grand Central Academy of Art, New York Academy of Art, Ani Art Academy, and Janus Collaborative School of Art.	['Joshua Liner Gallery is pleased to present Resolve, an exhibition of twenty-five emerging and established artists whose work is rooted in classical art traditions and training. In rendering the figure, still life, or landscape subject, this illustrious group (including twenty-two painters, two sculptors, and one photographer) expresses a collective interest in classical art forms with a variety of distinct and decidedly contemporary voices. As the first in a series of annual artist-curated exhibitions at Joshua Liner Gallery, Resolve is organized by gallery artist Tony Curanaj and includes works by the following artists:\nAnthony Waichulis, Brad Kunkle, Christopher Gallego, Dan Thompson, David Kassan, Edward Minoff, Graydon Parrish, Jacob Collins, Jacob A. Pfeiffer, Jefferson Hayman, Jeremy Mann, Kate Lehman, Kim Cogan Kris Kuksi, Kris Lewis, Lee Misenheimer, Michael Grimaldi, Rob Leecock, Scott Waddell, Shawn Smith, Shawn Barber, Steven Assael, Tony Curanaj, Travis Schlaht, Will Wilson\nThough considered divergent from the postwar developments of Pop, Conceptual, and Minimalist art (among others), the curriculum of classical art training—with its emphasis on skill and the realistic depiction of the figure, still life, and landscape—has nevertheless continued to evolve through the interests and talents of contemporary artists. Creating on the fringes of graduate-school art programs and modern art theory, these intrepid practitioners of traditional art forms and techniques have kept them alive and vibrant, while reinterpreting them through the social and visual culture of their time.\nSuch influences as Van Eyck, Caravaggio, and Rembrandt, as well as Klimt, Degas, and the pre- Raphaelites, to name but a few, can be discerned in many of the figure and portrait paintings and drawings collected here. The gestures, settings, and mood, however, are entirely of the moment, emphasizing the evergreen nature of classical training and its capacity to adapt to whatever arises, from tattoo culture to contemporary graphic design. Vestiges of Turner, Eakins, and other masters are also apparent in the landscape and figurative works included, but elsewhere one can see the boundary-pushing daring of more recent and contemporary figures such as Andrew Wyeth, Antonio López García, and Odd Nerdrum.\nAmong the painters featured, all work in traditional media, most employing oils or egg tempera on canvas, linen, or panel. The sculptors choose from more unorthodox materials, such as toy figurines and dyed blocks of wood, while continuing a dialogue with their time through the tools and history of realism. The founders, teachers, or graduates of such influential institutions as the Water Street Atelier, Grand Central Academy of Art, New York Academy of Art, Ani Art Academy, and Janus Collaborative School of Art are included in the exhibition. In their masterful hands, the tendency toward realism serves a fresh, new generation of artists in capturing their disparate worlds, lives, and vision.\nAccording to curator-artist Tony Curanaj: “This exhibition of colleagues and influences reflects a relatively narrow but varied slice of the art world, and presents it to an audience that may not be exposed to this segment of contemporary art practice. The title Resolve speaks of their determination and progression, qualities that imbue each of these works with beauty and technical virtuosity. From concept to execution, these contemporary masters of their craft are completely engaged in the artist’s process and an artistic direction that is unwavering, regardless of fashion or trend.”']	['<urn:uuid:8c74e594-9e28-4be7-9f5d-c73d2c007095>']	factoid	direct	short-search-query	distant-from-document	single-doc	expert	2025-05-01T22:47:46.423955	5	30	542
64	What kind of materials does Bio-lutions use to make their biodegradable packaging products and how do they process them?	Bio-lutions uses agricultural waste materials like sugar leaves, pineapple leaves, tomato leaves, banana stems, and water hyacinth plants. They process these materials using a patented 'mechanical process' that converts agricultural residual fibres into self-binding micro and nano fibrillated natural fibres using only water, without any chemicals or additives.	['Using just water and agricultural excess, Bio-lutions is making the world greener one biodegradable carton at a time.\nPlastics clog up our oceans, take a million years to decompose, and directly affect our food chain. Basically, they’re a threat to our entire ecosystem. On the other hand, we have tonnes of agricultural excess that is burnt, leading to another big problem—adding to the existing unchecked air pollution. The after effects of the two create a sight of terror.\nImagine replacing this plastic with packaging or disposables made of agricultural waste. It suddenly sounds like a solution to two of the biggest problems Mother Earth wouldn’t have to deal with anymore.\nBio-lutions GmbH, a revolutionary company that believes in sustainable innovations, does just this. The idea is to create a win-win situation. No more mountains of plastic and cellulose waste that takes forever to decompose, plus the added income for the farmers who would otherwise just burn the excess plant scrap.Their innovation is a patented ‘mechanical process’ through which agricultural residual fibres are converted into self-binding micro and nano fibrillated natural fibres using only water.\nThis Germany-based company, founded by architect and industrial designer Eduardo Gordillo in 2012 has set up its first ever pilot project in Bengaluru and is slowly working toward making a huge change in the game of disposables and packaging.\nJourney in India\nAccording to a report by the Central Pollution Control Board (CPCB), India goes through 15,000 tonnes of plastic produced every day, out of which 6,000 tonnes remain uncollected. Also, an estimated 32 million tonnes of agricultural residue is burnt every year, adding to the already alarming problem of air pollution in the country. This makes the Indian market perfect for a product such as this.\nBio-lutions Eco Tech India focuses on not having to go through the stages of the 3Rs by eliminating the use of plastic altogether and preventing the infringement of forests to procure otherwise used petroleum or virgin cellulose with the alternative of using readily available agricultural excess.\nThe company was set up in January 2017 by three Indian partners: Kurian Mathew, 41, Managing Director; Kurian George, 35; and George Thomas, 35 the directors in collaboration with Bio-lutionsGmbh owning majority share of the company.\nKurian George says, “Although the roots of the company are in Germany, the biggest part we have played is that for the first time in the world, from a research stage we have been able to take the company to a commercial stage.”\nAn established one-of-a-kind production plant on the outskirts of Bengaluru currently sources agricultural waste from the farmers of the Mandya region. Sugar leaves, pineapple leaves, tomato leaves, banana stems, water hyacinth plants are obtained from working with the farmers’ cooperative in the region, who in turn can earn from what was earlier disregarded, improve their livelihood through varied income, and can contribute to the good cause of cutting down on the use of plastics.\nThe agricultural excess is then converted into all natural, biodegradable, recyclable, and 100 percent food grade packaging. The end product is being provided to local businesses in Bengaluru where plastic is already banned, filling in the need for sustainable packaging.\nKurian Mathew says, “Localisation is at the heart of the company. We source locally, produce locally, and cater to the local market. We are able to be part of the local waste management system. Given that agriculture is a primary source of income, it is a win-win situation for farmers and us.”\nAn unparalleled technology\nBio-lutions stands out in terms of its distinctive technology. Kurian George says, “Another research organisation had been working on a particular technology for a different purpose. On Mr Eduardo’s interaction with them, this technology was tweaked wherein now the crop residue is incorporated with this modified technology to produce the products we manufacture today.”\nTheir unique, first of its kind “upgrading” technology uses only agricultural excess and water in a two-step procedure with zero chemicals and additives unlike any of the traditional technologies that undergo processes involving chemicals, bleaching agents, and additional binders using a great deal of water and energy to convert agricultural fibres to cellulose.\nBaby steps towards making an incredible change\nBio-lutions has put into perspective an issue that needs to be addressed right away. With a fast-paced lifestyle like ours, we mindlessly throw away thousands of non-biodegradable disposables every day. This company offers a solution to it all. It puts an end to pollution caused by non-biodegradables, offering products that are so green and recyclable they can be added to home compost and will degrade without any effort. They are also a socially responsible venture. By providing for farmers in terms of profitable ways of disposing waste, adding to their income and generating a backup in times of drought and inconsistent rains, they make them independent.\nPresently, Bio-lutions works with the farmer producer organisations (FPOs) under the Government of Karnataka and more importantly with the corporate society called Organic Mandya that works with the farmers in Mandya district, educating them on organic farming. These are the farmers who act as providers of raw materials to the company.\nOvercoming challenges in the research stage and issues in adapting to the machinery in the commercial stage, George says, “We are in the process of setting up a second plant by October or November in Mandya district itself. Since we have no benchmark, we are learning as we progress.” Currently, bio-lutions converts one tonne of raw material in a month but with the second plant in place they will be able to upscale and convert six tonnes per day, making a huge advancement. The company has two product lines—\nbiodegradable tableware for consumers and a biodegradable option over petroleum-based plastic or paper packaging for businesses. They also already have a tie-up with a major online supermarket as well as a food delivery service to provide ethical packaging at competitive market prices.\n“Bio-lutions has been voted ‘the world’s bio-based material of the year’, 2017, held recently in Cologne, Germany and has received financial support from DEG, a German Bank, that promotes pioneering investments of small and medium-sized enterprises (SMEs) through its upscaling programme This has enabled the company to scale up its production capacity,” says George.\nIn a wider sense, Eduardo seeks to take the technology across the world and tie up with partners from each country. He says, “Imagine tomato trays made from tomato plants, coffee capsules made from agricultural waste of pitted coffee sherry, or perhaps, cookie packaging made from wheat straw. The possible potential is limitless.”\nA world with less pollution and plastic—that is what they have set out to achieve.']	['<urn:uuid:4ae0d32a-91db-46ad-b89e-81d46f257c7e>']	factoid	direct	verbose-and-natural	similar-to-document	single-doc	novice	2025-05-01T22:47:46.423955	19	48	1109
65	how are modern vinyl floorcloths made	Modern vinyl floorcloths are created through a detailed process that begins with stretching cotton duck canvas on a wooden frame. The canvas is then sealed with six coats of exterior-grade latex. After light sanding, an artist hand paints and uses custom stencils to apply artwork. The piece is finished with three coats of clear acrylic and a top layer of bowling alley wax to prevent cracking, warping, and rolling.	['Walkable Art | Vinyl Floorcloths\nPhoto: Beija Flor, Available at Bailey Grey Interiors.\nWhat once was old is new again. With a rich history of adorning floors in the south, vinyl floorcloths are making a comeback. More casual, durable and easily maintained than rugs, vinyl floorcloths protect floors from grime and wear, while dressing up spaces with versatile design options that can be vintage, modern or whimsical. Floorcloths are popular today even with buyers who aren’t tethered to history. Because any pattern that you can imagine is possible, creative design freedom is truly within reach, with product designs that feel personal rather than mass-produced. Since every inch is hand-made by an artist, the addition of a floorcloth to your spaces sums to art, geometry, and history combined.\nFloorcloths are about as vintage as you can get for a good reason—they are wonderfully durable and lie flat on the floor; these classics are easy to clean and bring a burst of color and fun to any space. Non-slip vinyl floor cloths are perfect for kitchens, dining areas and laundry rooms.\nThough elemental in early American design heritage, the textile tradition of painting canvas floorcloths originated in France in the 1400s. These early pieces were small and generally used on tabletops as decoration, considered too precious to place on the floor. In the 1700s, American colonists took the idea one step further and transformed old ship sails into floorcloths. The cloths proved to be an inherently great product—they were durable and stood up to insects, heavy foot traffic and muddy boots. Floorcloths were also easy to clean and helped to control the interior climate by blocking out cold drafts in winter and staying cool underfoot in summer. Floorcloths were used in every area of Colonial homes—in entryways, under dining tables, in kitchens and bedrooms.\nOriginally, floorcloths were designed to resemble imported woven rugs and expensive marble and parquet floors. Primarily imported from England and usually with just one color, early cloths were produced using stencils; eventually, the palette grew to include chrome, blue, black, vermilion and malachite green.\nFloorcloths used a common material of the era—sturdy woven cotton—to address an equally common problem—protection and adornment of bare wood floors. The design staple had extra appeal in the sweltering South, where floorcloths often replaced heavy wool rugs in summer and were used as insulation under carpets in colder months.\nPresident Thomas Jefferson had at least two floorcloths—one in the great hall at Monticello and another in a small dining room—in his words, “to secure a very handsome floor from grease and the scouring that it necessitates.” George Washington had a cloth at Mount Vernon, and John Adams listed floorcloths in his exit inventory when he left the White House. These original, historic floorcloths are rare—literally worn to pieces; only fragments remain to be found, primarily in museums. The Golden Age of the American floorcloth spanned the late 1700s through the mid-1800s; when Sir Frederick Walton invented cheaper, mass-produced and easily available linoleum in the 1850s, it cornered the market.\nThe process of creating an old-style floorcloth in modern times is not lost; each is a work of art. Each floorcloth begins with stretching cotton duck—the tightly woven canvas used in awnings and theater sets—on a simple wooden frame. The canvas is sealed and stiffened with six coats of exterior-grade latex. Period floorcloths used linseed oil mixed with pigments and turpentine, but weren’t as durable and adept at handling high traffic and humidity as modern products.\nNevertheless, the traditional art form survives. After a light sanding, an artist hand paints and employs custom stencils to apply artwork; Greek keys, compass roses, and faux marbling are mainstays. Finally, three coats of clear acrylic and a top layer of bowling alley wax make the one-of-a-kind floor art resistant to cracking, warping, and rolling.\nWalk on the wild side\nIf you’re a do-it-yourselfer, you might want to make your own floorcloth; consider buying a remnant of vinyl flooring and painting your design on the underside. Remnants are easy to cut to size, extremely affordable and have no need of special edge treatment. It’s a fun process, but the tricky part can be coming up with an original design. A few hints: keep it simple or free-form; use two colors or multiple hues. Above all, make the process an expression of your creativity. Any good acrylic paint will work for your design, but don’t forget to protect your work of art with a couple of coats of Trewax once you’ve finished. Most purchased floorcloths come with a skid-proof backing already applied. If you are making your own, use clear silicone painted around the backside edges to keep your floorcloth from slipping.\nPhotos: Spicher and Company\nEverything old is new again\nMiriam Riggs is an area artisan who recently created three traditional floorcloths for the bedchambers at Point of Honor in Lynchburg. A veteran of her craft, Riggs has been making floorcloths for 35 years now, many of them custom designed for historic interiors. For her inspiration at Point of Honor, Riggs looked to laurel wreaths on the carved mantle detail as well as colors and styling from the custom wallpaper found in the house. Riggs explains, “In historic houses such as Point of Honor, I always seek to make the floorcloth based on historically appropriate designs and colors, while also adapting the design to the interior decoration currently in use.”\nMiriam Riggs doesn’t just create historical floorcloths. She also makes modern custom designs based on her clients’ specifications; those floorcloths can be very personal. In her words, “I see my custom designs often as an extension of the client’s imagination. I can help them visualize a concept, and turn it into a functional piece of ‘walkable art.’”\nSandusky House in Lynchburg also has a floorcloth worth a visit to see first-hand. The floorcloth now in the grand entry was designed by Jennifer Frantz of Americana Floorcloths at her studio in Ohio; it was transported from her workshop to Sandusky and installed as a wallto- wall piece.\nMoyanne Harding, owner of Estates and Consignments in downtown Lynchburg is a great fan of new floorcloth styles, preparations and products available, and is especially fond of using them in kitchens, mudrooms, and laundry rooms. In her words, they belong, “Anywhere kids, animals or husbands might bring in dirt.” She says floorcloths have come back en vogue due to their availability in a variety of sizes, patterns and colors. Further, because of their thin profile, modern vinyl pieces present no trip hazards. In her design studio, she showcases samples from a number of lines; pieces can be ordered outright or custom-made, with pricing typically from $20 to $40 per square foot. A leader in the vinyl floorcloth design space, Spicher and Company of Carlisle, Pennsylvania has a fantastic line of vintage-inspired vinyl floorcloths designed by Kolene Spicher.\nBailey Grey Interiors carries the Beija Flor line of vinyl floorcloths; Beija Flor specializes in traditional designs recreated in a contemporary medium; their floorcloths are produced from high quality, layered vinyl sheets. These beautiful pieces are strong, flexible and movable; they are made partly from recycled materials and finished with finely printed designs using a sand embossing technique. ✦']	['<urn:uuid:f8d01a0b-41a3-4e5c-a9ac-f833a65e3114>']	open-ended	direct	short-search-query	similar-to-document	single-doc	novice	2025-05-01T22:47:46.423955	6	69	1204
67	How did ancient leaders die while defending their lands?	Two ancient leaders died defending their territories in different ways. In Egypt, King Seqenenre Tao II was killed in battle against the Hyksos around 40 years old. CT scans revealed he was captured with his hands tied behind his back and executed by multiple attackers using different weapons like axes, spears, and daggers. In biblical times, Aaron died on Mount Hor after being stripped of his priestly robe, which was given to his son Eleazar, as punishment for disobeying God at Meribah.	"[""Water from a Rock 20 1The people of Israel arrived at the Zin Desert during the first month[F] and set up camp near the town of Kadesh. It was there that Miriam died and was buried. 2 The Israelites had no water, so they went to Moses and Aaron 3and complained, “Moses, we'd be better off if we had died along with the others in front of the LORD's sacred tent.[G] 4You brought us into this desert, and now we and our livestock are going to die! 5Egypt was better than this horrible place. At least there we had grain and figs and grapevines and pomegranates.[H] But now we don't even have any water.” 6Moses and Aaron went to the entrance to the sacred tent, where they bowed down. The LORD appeared to them in all of his glory 787-8and said, “Moses, get your walking stick.[I] Then you and Aaron call the people together and command that rock to give you water. That's how you will provide water for the people of Israel and their livestock.” 9Moses obeyed and took his stick from the sacred tent. 10After he and Aaron had gathered the people around the rock, he said, “Look, you rebellious people, and you will see water flow from this rock!” 11 He raised his stick in the air and struck the rock two times. At once, water gushed from the rock, and the people and their livestock had water to drink. 12But the LORD said to Moses and Aaron, “Because you refused to believe in my power, these people did not respect me. And so, you will not be the ones to lead them into the land I have promised.” 13The Israelites had complained against the LORD, and he had shown them his holy power by giving them water to drink. So they named the place Meribah, which means “Complaining.” Israel Isn't Allowed To Go through Edom 14Moses sent messengers from Israel's camp near Kadesh with this message for the king of Edom: We are Israelites, your own relatives, and we're sure you have heard the terrible things that have happened to us. 15Our ancestors settled in Egypt and lived there a long time. But later the Egyptians were cruel to us, 16and when we begged our LORD for help, he answered our prayer and brought us out of that land. Now we are camped at the border of your territory, near the town of Kadesh. 17Please let us go through your country. We won't go near your fields or vineyards, and we won't drink any water from your wells. We will stay on the main road[J] until we leave your territory. 18But the king of Edom answered, “No, I won't let you go through our country! And if you try, we will attack you.” 19Moses sent back this message: “We promise to stay on the main road, and if any of us or our livestock drink your water, we will pay for it. We just want to pass through.” 20But the king insisted, “You can't go through our land!” Then Edom sent out its strongest troops 21to keep Israel from passing through its territory. So the Israelites had to go in another direction. Aaron Dies 22After the Israelites had left Kadesh and had gone as far as Mount Hor 23on the Edomite border, the LORD said, 24“Aaron, this is where you will die. You and Moses disobeyed me at Meribah, and so you will not enter the land I promised the Israelites. 25Moses, go with Aaron and his son Eleazar to the top of the mountain. 26Then take Aaron's priestly robe from him and place it on Eleazar. Aaron will die there.” 27Moses obeyed, and everyone watched as he and Aaron and Eleazar walked to the top of Mount Hor. 28 Moses then took the priestly robe from Aaron and placed it on Eleazar. Aaron died there. When Moses and Eleazar came down, 29the people knew that Aaron had died, and they mourned his death for 30 days.\nContemporary English Version / ©1995 American Bible Society About"", 'CAIRO - 17 February 2021: Renowned Egyptian archaeologist Zahi Hawass posted on his Facebook page a scientific paper on the death of the Egyptian Pharaoh Seqenenre Tao published by Frontiers in Medicine, and carried out by Hawass in cooperation with Sahar Selim, a professor of radiology at the Faculty of Medicine, Cairo University.\nThe study says modern medical technology helped tell the story of an ancient Egyptian king, who died to reunify Egypt in the 16th century BC. It revolves around examining the second mummy of King Seqenenre Tao II by CT scan.\nSeqenenre Tao II, dubbed “The Brave”, ruled southern Egypt during the Hyksos occupation that seized the delta in northern Egypt for a century (1650-1550 BC). His mummy was discovered in the Deir el-Bahari cache in 1881, was examined for the first time at the time, and was studied by X-ray in the 1960s.\nThese examinations indicated that the deceased king had suffered several serious head injuries, but there were no wounds on the rest of the body.\nTheories have differed as to the cause of the king\'s death; some believe that the king was killed in a battle, perhaps at the hands of the Hyksos king himself; others indicate that some may have conspired to kill Seqenenre Tao II while he slept in his palace, and others suggested that the mummification may have been carried out in a hurry far from the royal mummification workshop, in light of the poor condition of the mummy.\nCT scan technique is one of the medical imaging techniques used to, safely and without interference, study archaeological remains, including mummies, which helps maintain them. CT scans helped study many Egyptian royal mummies, determining age at death, gender, and cause of death.\nIn their research, the two Egyptian researchers Zahi Hawass and Sahar Selim presented a new interpretation of the events before and after the death of King Seqenenre Tao II, based on two and three-dimensional CT images that were installed using advanced computer technologies.\nThe deformation of the arms revealed that Seqenenre Tao II was indeed captured on the battlefield, with his hands tied behind his back, which prevented him from repelling the fierce attack to his face.\n""This indicates that Seqenenre Tao II was really on the front line with his soldiers, risking his life to liberate Egypt,"" said Selim.\nA CT scan of the king’s mummy revealed subtle details of the head injuries, including wounds that had not been discovered in previous examinations as they were skillfully hidden by embalmers. The research also included a study of various Hyksos weapons preserved in the Egyptian Museum in Cairo, including an ax, spear and several daggers, which showed compatibility with the wounds of Seqenenre Tao II.\nThe results indicate that Seqenenre Tao II was killed by several Hyksos attackers who surrounded him from different angles and with different weapons. His killing appears as a ceremonial execution.\nFurthermore, the CT scan determined that Seqenenre Tao II was about 40 years old at the time of his death, based on the shape of the bones detected in the images, providing the most accurate estimate so far.\nThis study provides important details about a pivotal point in Egypt\'s long history.\nIn a painting known as the Carnavaron stela, found in the Theban Temple at Karnak, the battles the son of Seqenenre Tao II fought against the Hyksos are recorded. Seqenenre Tao II’s son, Camus, fell a martyr during the war against the Hyksos, and Ahmose, the second son of Seqenenre Tao II, was the one who completed the expulsion of the Hyksos.\nHe fought them, defeated them and chased them to what is known as Gaza today (Palestine). He also succeeded in unifying Egypt.']"	['<urn:uuid:e7ee0b9f-b0de-497b-bdad-b120cdd4c11b>', '<urn:uuid:63329205-7d18-4e31-9ccb-bf028f0cc7df>']	open-ended	direct	concise-and-natural	similar-to-document	multi-aspect	novice	2025-05-01T22:47:46.423955	9	82	1299
70	What are the key variables in convertible debt and bee population health?	Convertible debt variables include effective interest rate, time period before equity conversion, current premium, collateralization, and company earnings stability. For bee population health, the key factors include climate change affecting flower blooming schedules, habitat elimination due to urbanization, pesticide use (particularly neonicotinoids), and parasites like the Varroa mite that transmits pathogens like deformed wing virus.	['This may appear simple but in reality, there is a lot more to this. There are many different variables involved. More importantly, convertible debt in small business has an appropriate application. This article will explain the technical definition and how the variables impact the situation. The next section will explain why convertible debt is not used in small business and how venture capitalists use the tool.\nSo let’s get started:\nDefinition and Variables\nThere are several different terms used as substitutes for convertible debt and they include:\n- Convertible Bonds\n- Convertible Debentures\n- Convertible Notes\nAll of them are equivalents of the term convertible debt with forms of either restrictions or the type of debt instrument used.\nBasically, convertible debt is a loan to a company whereby the lender may at some time in the future convert the debt into equity in the company. Typically the interest rate for the debt instrument is slightly lower than traditional loans because of the value attributable to conversion. In effect, there is value in the ability to convert to equity and therefore the lender has some opportunity. The price the lender pays for that potential opportunity is a reduced interest rate.\nSince the interest rate is lower, usually about five to seven % (so a normal 7% interest rate charge would be reduced to 6.65% to 6.51%); there is a conversion premium incentive. Most premiums run between 20 and 25%. For example:\nThis would initially appear to be a great deal for Jim. But as always, the devil is in the details.\nIn the publicly traded world of finances, convertible bonds and debentures have more information and track records to determine the respective interest rates and the premium involved. Often, the conversion aspect has a preset stock price or conversion value. As an example:\nImmediately the reader should realize that converting the bond today has no value. The real value is in the holding time period. If the company’s stock price increases, the bondholder could get a nice return on his investment. But if the stock remains relatively flat or decreases in value, the bondholder will simply elect to get his principle back at time of maturity. But this opportunity for gain in the value of the stock comes at a price; a lower interest rate is earned on the debt.\nThe following are the various variables that affect the overall deal:\n- Effective Interest Rate on the Debt\n- Time Period to Hold the Debt Instrument Prior to Equity Conversion\n- Current Premium on the Bond – the higher the premium the less likely the stock’s selling price will eclipse the premium at time of conversion\n- Collateralization of the Debt Instrument – if collateral is used to back the debt instrument the lower the interest rate for the respective bond. In the TESLA example above the proceeds from the bond were used to fund the GIGA Factory Elon Musk is building to manufacture electric car batteries.\n- Stability of Earnings and Growth of the Company\nIn general, most convertible debt issues are used to fund a project of some sort hopefully fueling growth which then increases the value of the stock. In effect, it is a win-win scenario for both the lender and the company. This is appealing at the large corporate and publically traded stock situations, but it is a bit trickier when used in small business. The next section will explain this in more detail.\nConvertible Debt – Small Business Application\nAfter reading the above, convertible debt seems like a wonderful way for small business to raise capital to finance operations. Think about it, you simply tie the loan to some function or goal and apply the tool. Dealerships could finance inventory, site developers could purchase more and heavier duty equipment, real estate developers could purchase additional land and more. So why isn’t this tool used more in small business?\nA one word answer: ‘Control’.\nYou see, in small business most if not all the equity is held by either a single individual or a closely held group like a family. If debt is converted to equity, then some outside person could gain control over the company. The lender would almost demand to have at least 50% of the stock plus one share to have control over the company. In small business, if you don’t have a majority ownership position, your equity is pretty much worth ZERO! It is too easy for those that do have control to drain the profits into their own pockets.\nSo existing owners do not wish to give up control and lenders would need it in order to financially gain on their investment.\nIn the publicly traded domain of finances, there really isn’t any need to control an entity but the real goal is to influence the direction of the entity. So large retirement funds and investment groups purchase these bonds and they ultimately influence the company’s direction, culture and goals.\nConvertible debt is rarely used in small business and the only time you will see this financial tool is when the company is in the preliminary stages of going public with its stock. Examples of its use are when venture capitalists use the tool to fund the final stages of a new product for the market. Basically all the research is done, the testing is complete, models have been built and government approvals with licenses are issued. Now the product is ready for market and it is time to tool up for production and distribution. Convertible debt is then used by venture capitalists with a requirement that in a certain period of time, the company goes public.\nSo I’ve never have really seen this financial tool used at the really small business level.\nIn summation, convertible debt is very common in the publicly traded world of stock. There is more reliable information for the bond holder to use in analyzing and valuing the risks involved. With small business, lenders of money will not use convertible debt because control becomes a significant issue with the conversion to equity. If your business is growing and is currently a regional operation and you believe you will go public within the next 10 years, convertible debt is an option for capital.\nAs the lender of money, you would love to have a wild card that could pay off big for you once the deal is done. Convertible debt can be the appropriate wild card. Act on Knowledge.\nIf you have any comments or questions, e-mail me at dave (insert the usual ‘at’ symbol) businessecon.org. I would love to hear from you. If interested in my services as an accountant/consultant; click on ‘My Services‘ in the footer of this article.', 'Pollinators play an important part of human existence. In recent years some pollinators have been struggling to survive. The preservation of our ecosystem including the food we consume daily relies on the health and abundance of our pollinators.\nLet’s start off by familiarizing what the role of a pollinator actually is. A pollinator is an agent that transmits or removes the pollen from flowers, grasses, trees and weeds. Pollination is the transfer of pollen from the anthers (male part) to the stigma (female) part of flowers. The most popular pollinators are bees and wasps, flies, butterflies and birds. Surprisingly to many, bats and rodents are pollinators too. However, bees are responsible for the majority of pollination.\nHOW POLLINATION HAPPENS. Plants contain reproductive cells, which are known as gametes. There are both male and female gametes. The male gametes are found inside minute pollen grains on the anthers (oval shaped and pollen producing) of the flower. Female gametes are found in the ovules of a flower. When the male and female gametes are joined, this process is known as pollination.\nPollination plays a critical role in the life cycle of flowering plants. It’s the sexual reproduction process of flowering plants, which results in seeds germinating into new plants. Flowering plants contain the necessary elements that are needed for sexual reproduction.\nPollen can’t move on its own. So, pollination relies heavily on other sources to move or transport it. Insects, mammals and birds gather the pollen from the male anthers and carry it to the female stigma. Wind also can be a conductor to transport pollen. This process is called anemophily. Both plant crops and trees are pollinated by the wind. Some examples are: barley, corn, rice, rye, oats and wheat, firs, pines and spruce. Some species of hardwood trees are utilized for the production of nuts. There are many different species of flowers. Each one has its own color, shape and odor that it emits. What attracts pollinators to them are the sugary nectar and pollen that each one contains.\nMOST PROLIFIC POLLINATORS. Bees, which are social insects, are the most responsible for the pollination of our food supply. Arguably, the one that is referenced the most is the western honey bee (Apis mellifera). The western honey bee is responsible for pollinating about 80 percent of our food supply. Some of the crops they are responsible for pollinating are apples, alfalfa, blueberries, strawberries, raspberries and almonds. The pollination of almonds relies solely on the honey bee. Pollination performed by the honey bee and other insects is known as entomophily.\nThe honey bee belongs to the insect order Hymenoptera, which is the third largest order of insects. This insect order is composed of ants, bees, sawflies and wasps. As our pollinators, they are the most beneficial insect order to mankind. Honey bees are eusocial as they belong to a complex society. Their colonies consist of one breeding female queen, a few thousand males (drones) and a large population of sterile female bees known as workers. These insects go through a complete metamorphosis, which consists of egg, larva, pupa and adult. The gestation time varies for each cast from 16 days for the queen to 21 days for the worker and 24 days for the drone. The life expectancy of the queen is three to four years. The drone dies after mating or is banished from the hive prior to winter. The worker bee can live up to six weeks during summer months and even longer in the winter contingent upon the geographic location of the hive. Honey bees in general are very docile.\nThe female does possess a stinger and she does not want to sting, unless provoked. In the event she would sting a human or an animal she would die. This is due to the fact that the stinger, which is located at the end of the abdomen, becomes removed. All of the types of bees co-exist with one another in a habitat known as a hive. Depending on the locale of the hive, there could be approximately 40,000 to 80,000 bees during peak summer months. This is the time of year the hive would be the strongest. The worker bees are the ones who forage for a food source. Once the food source is located, they communicate with one another in a well-choreographed dance know as the “waggle dance.” This informs the others of where the specific food source is located.\nDECLINING POPULATION. There has been an alarming decline of these insects over the years. One of the most well- known phenomenon is colony collapse disorder (CCD). CCD was first reported in 2006 by beekeepers as they experienced significant losses to their hives during the spring. These losses are attributed to the worker bees vacating the colony, leaving behind a queen, honey and a few nurse bees to care for the immature bees and the queen. CCD was once thought to be a major factor of bee decline. However, the number of reported cases has declined over the last five years.\nBecause there has been a decline in both managed colonies and bees in the wild, there are additional elements contributing to this. Based on research that is ongoing and conducted by multiple governing/extension agencies, universities and research labs, one factor is climate change. Different parts of the United States that experience unseasonably mild winters have altered the schedule of blooming flowers. When the bees first emerge for the new season, the flowers, which are their food source, have already bloomed and died. A second factor would be the elimination of habitat. Plush, rural areas that are normally full of flowers, weeds and grasses have been changed into suburban or urban settings.\nAnother reason that’s widely discussed in the consumer media is pesticide use. The neonicotinoid class of insecticides in particular has been singled out. Neonicotinoids can be applied to the soil, used on crops as well as used as a seed treatment. Eventually, it reaches the nectar and the pollen, which then in turn can be ingested by the insect. There is ongoing research that is being conducted by many governing/extension agencies, universities and other organizations regarding neonics and honey bee health. Just this year, the state of Maryland became the first state to ban the use of neonicotinoids to consumers. However, individuals who are properly trained and licensed can still utilize this material when following specific guidelines.\nLastly, another factor in honey bee health is the Varroa mite (Varroa destructor). This mite was first reported in the U.S. in 1987; it originally emanated from Asia. This parasite attaches itself to the honey bee and sucks hemolymph fluid (blood) from the bee. They are also transmitters of pathogens with one of them being the deformed wing virus. Presently, beekeepers say the Varroa mite is the main culprit of colony loss today. Honey bees and their hives are also susceptible to the tracheal mite, hive beetle and wax moths. Education, proper nutrition, routine inspection, record keeping and the use of Integrated Pest Management (IPM) practices will assist in keeping one’s colony as healthy as possible.\nWHAT CAN WE DO? As we struggle to help save the bee and bring more of them back into our world, there are many things that society — and pest management firms — can do.\nOne is education. While honey bees can swarm and can be found in the voids of homes and commercial structures, it’s important that the bees are not treated with pesticides. They should be removed by a local beekeeper or a designated pest management firm.\nProfessionals and customers alike can create an environment conducive to a pollinator habitat. For some, this includes eliminating the use of all pesticides and switching to an all-organic program. It may include an organic lawn and garden program that utilizes IPM techniques. Natural pest management may be incorporated such as the use of lady bugs and/or lacewings to control aphids and spider mites, nematodes to control grubs, etc.\nHomeowners can install plants and flowers that are conducive to pollinator attraction. Different species of flora attract different pollinators. There is an abundance of resources available via the web (check out the U.S. Forest Service publication titled “Attracting Pollinators to Your Garden Using Native Plants”. Once a specific species of flora is found, it is recommended to check the USDA Plant Hardiness Zone map to determine if the selected flora will thrive in your geographic location.\nIf pest management firms or customers want to take this initiative one step further, they can become a beekeeper hobbyist. This is when an individual manages a beehive or multiple beehives on his or her property. The first step would be to obtain literature and other resources to educate oneself. Two superb magazine publications are Bee Culture & The American Bee Journal. This is, in part, to determine if this is right for you and/or your customer’s family.\nDue to the vast interest in keeping bees, the term “backyard beekeeper” has been coined. For those who don’t necessarily have the land to keep bees there is also urban beekeeping that takes place in a city setting. Urban beekeeping has exploded during the last several years. It utilizes rooftops, balconies and other spaces for people to manage their own bee hives. To illustrate just how popular urban beekeeping has become, there are almost 300 registered hives in the New York City metropolitan area. London is also another major city where urban beekeeping is prevalent.\nIt’s good to check with your municipality or city ordinances to determine if the keeping of bees is legal. Join your local beekeepers club. It’s a great way to network, meet other keepers and obtain knowledge.Purchase your equipment and bees through local beekeepers or various online stores. If keeping bees is not for you but you would like to help… some beekeepers will place their hives on your property, they will care for them and in exchange you will be rewarded with honey. This is another way of making an impact.\nYou are now on your way to becoming a beekeeper and contributing to preserving our eco-system.\nThe author is a service specialist and master technician with RK Environmental Services, Westwood, N.Y.']	['<urn:uuid:3f1fa037-a068-4d01-9f1a-2d116baf3c84>', '<urn:uuid:e48e99b7-843c-47c7-abab-4b0e15d81d6a>']	factoid	with-premise	concise-and-natural	similar-to-document	multi-aspect	expert	2025-05-01T22:47:46.423955	12	55	2827
71	As an aviation engineer, what causes ice formation on aircraft and how is it monitored for safety?	Ice forms when supercooled water droplets impact aircraft surfaces, most severely at temperatures just below 0°C. The severity depends on droplet size and quantity, with larger droplets producing more concerning clear/glaze ice. For safety, aircraft undergo mandatory inspections before flights, with busy planes checked multiple times daily and grounded if issues are found. Maintenance procedures are conducted monthly for minor checks and every two months for major inspections.	"[""If you wish to contribute or participate in the discussions about articles you are invited to join SKYbrary as a registered user\nIce Formation on Aircraft\nThis article aims to address the basics of ice formation on aircraft and in their engine air inlets. It does not consider the formation of frost which is created by sublimation, the process by which water vapour freezes directly onto sub zero surfaces. With this exception, the formation of ice attached to the external surface of an aircraft or to the surfaces within its engine air intakes, requires that liquid water drops impact the surface involved. Usually, that moisture must be supercooled, that is it must be in liquid form below 0°C273.15 K\n491.67 °R. There are a couple of specific variations in this general scenario which will be considered later:\n- issues relating to the difference between the temperature of the aircraft skin and the temperature of the air through which it is, has been or will be passing, especially during climb and descent and in the temperature range +/-10 degrees Celsius.\n- issues arising from the temperature and/or pressure difference between the ambient air and air within engine air inlets, most often reductions in air pressure or increases in air temperature.\nIce from Supercooled Moisture\nIce which accretes on the external parts of an aircraft is most often the result of the impact of supercooled water droplets of various sizes on that aircraft. This may happen within cloud or when flying through precipitation. The reason why water droplets do not all freeze as soon as the ambient temperature falls below 0°C273.15 K\n491.67 °R is the release of latent heat as water changes state to ice. So much latent heat is released that the change of state is slowed down so that it takes place progressively as temperature continues to fall. This continues until, by about -20°C253.15 K\n455.67 °R, most of the by now supercooled water has turned to ice. Ice grains which have already fully formed and are dry when they impact an aircraft do not adhere but simply bounce off. Therefore, the relative severity of ice accretion can be expected to progressively decrease as ambient temperature reduces below 0°C273.15 K\n491.67 °R so that little, if any, risk of accretion remains below -20°C253.15 K\n455.67 °R. Two factors are important in respect of supercooled water droplets:\n- the extent of their presence, which will affect the rate of any ice accretion; and\n- their size, which will affect the severity of that accretion by adversely influencing its rate.\nBoth the quantity and, perhaps unsurprisingly, the droplet sizes of supercooled water in cloud are greatest at temperatures just below 0°C273.15 K\n491.67 °R and both decrease as temperature falls. The size of the supercooled water droplets is very important in respect of the potential to induce ice accretion. Larger droplets have greater inertia and are less influenced by the airflow around the aircraft than smaller droplets so they will impinge on more of the aircraft surface than smaller droplets. This is especially the case in respect of the in-flight air flow around the leading edge of wings and empennage. It is also the larger droplets which produce clear or glaze ice which is well recognized as the ice form of most concern and is often also the most difficult to detect visually.\nClouds and Supercooled Moisture\nThe majority of supercooled droplets in clouds are between 1 micron (0.001mm) and 50 microns (0.05 mm) in diameter. [For comparison, the thickness of the average human hair is approximately 100 microns]. Layer (stratiform) clouds typically contain average droplet diameters of up to 40 microns. Vertically developed (cumuliform) clouds of moderate scale typically have average droplet diameters of up to 50 microns (0.05mm) but large Cumulonimbus clouds often contain much more liquid water, including large quantities in droplets with diameters up to and beyond 100 microns (0.1mm).\nFreezing Rain and Freezing Drizzle\nPrecipitation droplets that are clear of cloud are much larger than those within cloud and, if they are supercooled, they are described as creating Freezing Drizzle where droplets have a diameter of between 50 and 500 microns (0.05mm and 0.5mm) and Freezing Rain where the droplets exceed 500 microns (0.5mm) in diameter. Freezing Rain often has much larger droplets of 2mm diameter or more, although if they get much beyond 6mm in diameter, they will tend to break up.\nFreezing rain below cloud forms when rain droplets are supercooled by passage through a layer of air which has a sub-zero temperature. Since air temperatures normally increase as altitude reduces, freezing rain implies the existence of an air temperature inversion. Such conditions can occur below an advancing warm front or a warm occlusion where a relatively warm air mass is overrunning colder air. The existence of freezing rain normally means that there will be warmer air (above 0°C273.15 K\n491.67 °R) above.\nThe smaller supercooled droplets of freezing drizzle can also form in this way but it is generally considered that they more commonly arise by a different process called the collision-coalescence process. When, through condensation, some droplets in a cloud grow to approximately 30 micrometers in diameter, they begin to settle, falling fast enough so that they collide with some smaller droplets. If the droplets then coalesce, a larger droplet is produced and this now has an even better chance of ‘capturing’ smaller droplets. Under favorable conditions, this process can produce drizzle-size drops in a supercooled cloud, usually near the top, where the largest droplets generally are found in any cloud. Data capture has varied but some studies have reported that freezing drizzle in non-convective clouds forms more than 80 percent of the time by the collision-coalescence process. So, importantly, when in freezing drizzle, it cannot be assumed that warmer air (above 0°C273.15 K\n491.67 °R) will exist above it.\nThe term ‘icing severity’ is essentially about the rate at which significant ice accretion occurs. The descriptions of supercooled water droplets so far have been in terms of their size. These comparative diameters are important - typical drizzle droplets have a diameter 10 times that of typical cloud droplets and typical rain droplets have a diameter 100 times that of typical cloud droplets. Size as described by diameter is, though, not what matters most in terms of the potential for ice accretion through impact. What really makes the difference is the volume (or mass) of water contained in a droplet since this is what controls the amount of water which will impact the aircraft and also how far aft of the airflow stagnation point ahead of a leading edge surface that droplets will strike the aircraft. This latter point is of considerable importance since large droplets may impact far beyond the leading edges in areas which are not anti iced or de iced and may also turn to ice as they are flowing aft in contact with the surface initially hit.\nIt is important to note that the volume of a droplet is not proportional to its diameter but to approximately the cube of half the diameter (i.e. the radius). Therefore, if 20 microns (0.02 mm) is taken as a typical diameter for a cloud droplet and 2000 micrometres (2mm) is taken as the typical diameter of a freezing rain droplet, then although the diameters of these droplets differ by a factor of only 100, their volume, and therefore their mass, differ by a factor which is of the order of 1,000,000.\nIt is this vastly greater mass of supercooled water droplets in freezing precipitation compared to those in cloud, even cumulonimbus cloud, which precludes any aircraft undertaking a significant period of sustained flight - and in most cases any flight - in freezing precipitation clear of cloud.\nDifferences between ambient and aircraft skin temperature\nThere are a number of factors which vary the propensity for ice to accrete on an aircraft:\n- When any aircraft moves through the air, the resultant kinetic hearting due to both compression at points of air obstruction and friction at surfaces of air passage raises the aircraft skin temperature above that of the ambient air in the vicinity. The extent to which this occurs, and therefore the extent of its significance to ice formation, has been calculated to be directly proportional to the square of 1/100 x the true airspeed in knots. Pilots will be aware of the consequent difference between SAT and TAT which can be observed to increase with speed since the effect of TAS increase is greater than the opposite effect of air density decrease.\n- If an aircraft is climbing into colder air and frozen or semi frozen deposits are resting on the upper surfaces of the wings or horizontal tailplane surfaces or in related flight control hinge gaps, the possibility exists that these deposits might freeze fully and attach to the airframe in situ. However, this will usually only be a significant problem if the climb is made concurrently into conditions likely to produce independently significant ice accretion.\n- When an aircraft is descending from high altitude, the increase in the structure surface temperature as the ambient air warms is likely to lag behind the ambient air temperature increase, especially in the case of wings used as fuel tanks which still contain a significant quantity of fuel. This will particularly apply where fuel is ‘tankered’ for use on the next flight sector in preference to uplifting at the initial destination. The significance of fuel is its tendency for temperature to recover from prior cold soak more slowly than the structure containing it. One particular effect of this is the formation of ‘fuel ice’ on the lower surface of a wing because this is where the cold fuel is in direct contact with the wing structure. Such clear ice is often still present during the subsequent turnaround even when OAT is several degrees above freezing.\nEngine Air Inlet Icing\nAll aircraft certificated for flight in icing conditions are fitted with anti-icing systems. These prevent air intake lip and guide vane ice formation by use of electrically heated mats, circulated hot engine oil or bleed air extracted from the engine. However, further inside an air inlet, ice can form in unprotected areas even when an aircraft is not flying in icing conditions as presently defined for engine certification purposes. There are two such circumstances: the cooling of moist air above freezing temperature by pressure reduction in piston engines; and the melting of ice crystals which are warmed after entering turbine engines.\nIn the first case, moist air entering a piston engine intake at a temperature above 0°C273.15 K\n491.67 °R is then accelerated by a suction effect through a reduced channel. This ‘venturi’ effect reduces its temperature causing the moisture load to condense out and be precipitated on the walls of the air channel as ice. See Piston Engine Induction Icing for more detail. This article also describes two other types of induction icing which occur in piston engines.\nIn the second case, high densities of very small ice crystals in very cold, high altitude air are ingested into high bypass gas turbines. They then either temporarily freeze and detach as larger pieces of ice causing engine airflow disruption, or cause mechanical damage either as pieces of ice or via discrete throughputs of liquid water. For further information, refer to High Level Ice Crystal Icing: Effects on Engines.\nThere are no definitions for absolute icing severity in aviation forecasting. However, the relative qualifications light, moderate and severe are generally used (in respect of airframe icing risk only) in a way which has at least reasonable consistency regionally in the context of the type of forecast in which they are used. It is understood by most forecasters that a term like ‘light icing’ will be interpreted rather differently by a commercial transport flight crew and a private pilot wondering whether they are likely to be able to undertake their planned flight clear of all icing conditions. As a consequence, low level icing forecasts are usually presented in such a way that they are specifically accessible to pilots of light aircraft vulnerable to the effects of any icing. However, the forecasts provided primarily for commercial air transport will use moderate and severe icing in terms which reflect their likely significance to aircraft which are certificated for routine flight in ‘icing conditions’ because they are equipped with appropriate ice protection systems. This use of higher level forecast presentations by general aviation can produce misunderstandings about the icing conditions that might be expected, and sometimes lead to inappropriate flight planning. The point is that the relative forecasts of icing severity cannot and do not take account of their user and the aircraft they are flying, so the interpretation of forecasts is as much a matter of judgement as monitoring the apparent icing reality once in the air.\nWith all the above caveats, a brief look at the usual ‘descriptions’ and ‘definitions’ of icing conditions used by forecasters may still be helpful. The descriptions all assume that an aircraft is certificated for “flight in icing conditions”.\n- Light Icing is often described as conditions such that ‘no change of course or altitude is necessary and no loss of airspeed occurs. It has been more rigorously defined by some as a rate of ice accretion per hour on outer wing of between 0.25 inch and 1 inch (0.6 to 2.5 cm).\n- Moderate Icing has been typically described as ice accretion which continues to increase but not at a rate sufficient to affect the safety of the flight unless it continues for an extended period of time, but air speed may be lost. A definition based upon an ice accretion rate per hour on the outer wing of 1 to 3 inches (2.5 to 7.5 cm)\n- Severe Icing has been variously described as ice accretion:\n- in which either the icing rate or ice accumulation exceed the tolerance of the aircraft;\n- which continues to build and begins to seriously affect the performance and manoeuvrability of an aircraft;\n- at a rate such that ice protection systems fail to remove the accumulation of ice and ice accumulates in locations not normally prone to icing;\n- such that an immediate exit from the condition is necessary to retain full control of the aircraft.\nIt is generally accepted that, although aircraft certification for flight in icing conditions rarely includes any stated restrictions, no aircraft is approved for flight in severe icing conditions, and that severe icing conditions may occur at any ice accumulation rate.\nIn North America, the terms clear, rime or mixed are more often used in forecast material than elsewhere and are both intended and taken as a proxy for droplet size regardless of other factors such as temperature and liquid water content. In this use, a forecast of rime icing indicates smaller drop sizes and a forecast of mixed or clear icing indicates larger drop sizes but with only a vague and undefined boundary between the two.\nFinally, a “clean aircraft” at rotation is an essential requirement for flight in or into icing conditions for those aircraft so approved. It is achieved by the use of appropriate ground de-icing or anti-icing fluids which have a sufficient holdover time for the prevailing conditions. Anti Icing is nearly always achieved by thickened fluids which adhere to the airframe and then progressively shear off during the take off roll so that they have all been shed by 100KIAS. There is no approved fluid protection against freezing rain or freezing drizzle conditions and so departure in them is generally not possible.\n- In-Flight Icing\n- Icing - Collection Efficiency\n- Aircraft and In Flight Icing Risks\n- Piston Engine Induction Icing\n- Freezing Rain\n- Aircraft Ground De/Anti Icing\n- Ice Protection Systems\n- High Level Ice Crystal Icing: Effects on Engines\n- Extract from Transport Canada Aviation Safety Letter 1/2007: The Adverse Aerodynamic Effects of Inflight Icing on Airplane Operation\n- Aircraft Icing Handbook, Version 1 by Civil Aviation Authority of New Zealand\n- Appendix C 'Icing Conditions' to CFR 14 Part 25, FAA, 2014"", 'Safety while flying elicits a lot of attention from all those who venture to fly. As much as statistics show that travelling by cars is more dangerous than aircrafts, flying is more feared due the loss of control that people feel as a result of being suspended in the air. Many regulatory bodies look at aviation safety seriously as much as passengers. These bodies are tasked with the enforcement of rules and standards that address safety of the passengers while on board a moving aircraft from liftoff up to landing.\nThe aviation industry is one of the most highly regulated. All players from the manufacturers of the giant jumbos to the suppliers of the smallest parts are required to adhere to a wide range of standards. Each part that is made is tested so as to verify whether it is compliant with predetermined tolerance limits failure to which it must be done away with. There are approved third parties who are empowered to certify companies that engaged in the aircraft industry (Krause, 2003).\nAll companies that are involved in air travel are closely monitored to ensure they are competent. This is not only expected of manufacturers of parts but also those companies that assemble aircrafts. After the assembly every plane is tested so as to ascertain whether it complies with regulatory requirements. The tests include flying so as to establish whether it is operating properly and safely (Krause, 2003).\nDuring a test flight only a small portion of the crew is taken on board. New models are examined through a battery of tests that are designed to simulate real flight conditions. This process can take over a year to be completed. Production runs of a particular model are also subjected to lesser demanding tests but test flights are always conducted on every produced unit. Regulations are also enforced when a plane is in service. Actually, the rules become stricter through a schedule of maintenance and inspections before every flight (Stolzer & Goglia, 2011).\nIf an aircraft deviates from a set-out schedule it may be grounded. Every busy plane is usually inspected for more than one occasion every day. Those that fly occasionally are inspected after a few days or weekly. If a plane fails an inspection it is immediately grounded until all required repairs are completed. Minor maintenance procedures are done at least one time a month or after a few days. On the other hand major maintenance is done as required or at least one time after every two months. The regulations that govern how safe aircrafts are also applied to the crew.\nAs far as the crew is concerned, the major bone of contention is the number of crew members that are included in each flight as well as how experienced they are and for how long that they have flown. This is extended to how much sleep pilots have before entering into a cockpit every time. As much as most people worry about how safe they are aboard an aircraft is one of the safest activities that anyone can engage in (Krause, 2003). Rules and procedures are enforced so as to reduce the number of airborne accidents to the minimum by ensuring that all aircrafts are in proper working order at all times.\nEvery passenger who boards a plane always expects that it is well equipped with devices for utilization during an emergency situation. In many modern aircrafts such devices extend beyond procedures for ensuring that passengers are safe to warning systems that are designed to avoid accidents. These systems have to be correctly installed and constantly maintained (Stolzer & Goglia, 2011). Devices that are considered as basic for ensuring that each and every flight is safe are standards that must be adhered by each plane whether it is the smaller planes to the huge commercial jets. Large jets have a deployable slide that is used to evacuate passengers from the sides very quickly in case of an emergency. If such devices are not there, evacuation may not be feasible which portends that a jet would hit the ground while passengers are aboard which would lead to catastrophic results (Rodrigues & Wells, 2012).\nParachutes are a primary requirement in the smaller aircrafts. This device is one of the foremost precautions that is available in every plane and should be maintained adequately to ensure that it is in proper working condition and it can be deployed without damaging the parachute. Parachutes are rarely used during an accident but they still remain an option that is considered seriously (Huang, 2009).\nThere are computerized equipments that are installed in aircrafts and calibrated to avoid occurrence of accidents altogether. These are recent developments and pilots consider them as important ways of controlling planes and helping them to understand problems as they develop during a flight, thereby giving them sufficient time to appropriately react.\nThe aircraft industry has seen the enforcement of so many standards that are geared towards ensuring that all flights are safe. Companies have to hire highly experienced personnel to fly and manage their planes. Such personnel should have an established record of safety as well as in implementation of best practices. One of the most basic ways of ensuring that a plane flies and lands without interruption is that every cockpit must have two pilots just in case one of them becomes deactivated during a flight.\nStatistically the number of aircraft accidents is low as a result of developments that have enhanced the performance of aircraft through superior engine design as well as adequate training of pilots which are deemed to be the focal points of ensuring that each plane lifts off and lands without any incidences. International organizations that govern manufacture and management of aircrafts always recommend that all national authorities should implement safety regulations.\nSince the advent of flying planes have crashed leading to very serious results. This is a result of the flight nature which is unforgiving as a small medium is suspended in air to support a large mass whose failure does not give an option but quick descent with catastrophic eventualities (Stolzer & Goglia, 2011). Due to this planes are designed with an emphasis of reducing the chances of mechanical malfunctions and pilots are intensively trained.\nIn the earlier developments in aircraft technology there were those who have been of the view that a plane should be designed with consideration of how it would endure an accident. However, such a design would lead to the manufacture of the very heavy model that would be more susceptible to crash as a result of the added weight. As a result of this it is not uncommon to find the nonstructural parts of planes, especially the small ones are very light and when such planes crash devastating results follow.\nFlying in private jets is more dangerous in comparison to the scheduled flights. This is partly attributable to less maintenance and training. In most cases privately owned aircrafts do not have system redundancy to be utilized if a system failure occurs. Therefore it can be presupposed that it is safer to fly using commercial airlines (Rodrigues & Wells, 2012).\nAir traffic can be considered to be intense as there are usually ten thousand planes in flight at the same time. Despite this accidents are rarely sighted given the high number of operations. Statistically flying by scheduled airlines in the developed world is at least ten times safer than driving. However, this is not the case in many African nations and Russia. Plane accidents make headlines throughout the world when they occur (Rodrigues & Wells, 2012). The perceived impact of such accidents has magnifying effect. The main reasons that lead to the airborne accidents are flaws in the design, pilot’s errors and improper maintenance procedures.\nThere are inspectors whose sole mandate is to ensure that regulations regarding performance and quality of aircraft including personnel are adhered to. These professionals are specialized in the inspection of either single or multiple engine aircrafts or commercial carriers. Other inspectors perform inspections on the operation of airlines where they evaluate commercial carriers as well as air operations. In addition inspectors also certify flight instructors, pilots as well as ensure verification of flight training facilities and programs.\nThe aeronautical profession is very dynamic and highly technical. There are numerous technologies that emerge with a view to improve travelling through airborne means. Every flight implies that many lives are at stake at any one time which places a very high demand on the crew and pilots to be highly trained and constantly updated with new developments (Rodrigues & Wells, 2012).\nThe training of pilots must be very intensive so as to ensure that the passengers aboard their aircraft are safe. Prior to being allowed to fly an actual aircraft an aviator is required to hone his skills using simulators that emulate real flight conditions. This is intended to prepare the pilots to deal with many types of scenarios that may present themselves while in flight mode. A pilot is certified after amassing a certain number of flight hours.\nPilot trainers are also constantly put to speed with every new development so that they pass on the knowledge to their students. Aircraft mechanics and engineers are also required to be equally competent as pilots and are held responsible in case a plane develops mechanical problems while in flight (Huang, 2009). This is intended to ensure that they carefully do their work so as to prevent aircraft accidents that usually cause multiple deaths.\nPlanes do not fly a lot during winter. However, the importance of proper winterizing a plane should not be understated as it is a matter of safe flying as well as enhancing the useful life of an aircraft. Manuals usually spell out how a plane should be winterized. One basic thing that should be done is to cover the canopy, windows, prop blades and the horizontal tail as these are the most crucial external parts. Covering reduces damage that is caused by snow, ice, rain and cold which are experienced during winter.\nIn order to enhance the welfare of all passengers it is important for a pilot to be very observant about pressure and oil temperature while flying in cold conditions as such features oscillate significantly when in flight as well as while not in flight. Repairs should be immediately done in case an oil cooler bypass occurs (Stolzer & Goglia, 2011).\nOne of the most basic things to do so as to ensure that flight is completed successfully is checking that the fuel tank is full and that the valves are properly closed. Emptiness in the fuel tank of a plane leads to condensation during winter which may cause corrosion that leads to complications during flight. When flying during cold weather, a pilot should establish whether his plane requires the use of isopropyl alcohol that is added to the fuel while operating in low temperatures.\nMany regulations in aircraft management are usually precipitated by catastrophic events. Such rules have gone long way in preventing other air disasters. The ability of a pilot is one of the most crucial factors during the occurrence of accidents. Pilots are properly evaluated so as to ensure that accidents do not occur as a result of easily avoidable things like fatigue. Aviation safety will continue to be an important matter for all national and international air travel regulators. This will ensure that travelling by air continues to be the safest mode of transport in comparison with others like motor vehicle transportation (Huang, 2009).']"	['<urn:uuid:feb0abc0-d768-40b0-ab94-269ded9eeac1>', '<urn:uuid:a11a4a5c-c4dd-4710-a236-e71f5f39cb79>']	factoid	with-premise	concise-and-natural	similar-to-document	multi-aspect	expert	2025-05-01T22:47:46.423955	17	68	4621
74	reframing negative thoughts psychological therapy methods low versus high income	Reframing negative thoughts has varying impacts across income levels. For lower-income individuals (below $35,000/year), cognitive reappraisal strategies significantly reduce anxiety both short-term and long-term, as shown in laboratory experiments and national surveys. This approach is part of cognitive behavioral therapy, where people learn to reconsider and reframe experiences. According to REBT principles, it's not situations themselves that cause distress, but rather our thinking about them. However, this reframing strategy becomes less effective for higher-income individuals, who may benefit more from directly changing their circumstances.	['Dr. Michael R. Edelstein is a licensed clinical psychologist with over 25 years experience. He is in private practice in San Francisco and is the author of Three Minute Therapy: Change Your Thinking, Change Your Life, a self-help book for overcoming common emotional and behavioral problems.\nIn his practice, Dr. Edelstein specializes in the treatment of anxiety, depression, relationship problems, and addictions, and is one of the few practitioners of Rational Emotive Behavior Therapy (REBT) in the Bay Area. He is a SMART Recovery (SR) Professional Advisor and has served as a Rational Recovery (RR) Specialist. He is a Certified Sex Therapist and has served as a Consulting Psychologist for the National Save-A-Life League, Inc., the oldest suicide prevention center in the United States.\nDr. Edelstein is a Training Supervisor and Fellow of the Albert Ellis Institute. He holds a diplomate in Cognitive-Behavioral Therapy from, and is on the Board of Advisors of, the National Association of Cognitive-Behavioral Therapists. He is Past President of the Association for Behavioral and Cognitive Therapy. He also writes the popular advice column, “Ask Dr. Mike,” which appears in the San Francisco Intelligencer.\nDr. John Grohol: Dr. Edelstein, we’ve long heard about the ABCs of cognitive behavioral therapy, but in your book, you talk about Three-Minute Therapy using the ABCDEFs of REBT. What is REBT, and can you walk us through the ABCDEFs?\nDr. Michael Edelstein: Sure, John. And I just want to thank you for inviting me to take part in this interview.\nREBT stands for Rational Emotive Behavior Therapy. It was devised by Albert Ellis in 1955, and since then, it’s spawned a variety of cognitive behavior therapies, most notably those devised by Aaron Beck and David Burns. And REBT says that it’s never situations themselves that upset us or disturb us or cause us to feel anxious, depressed, angry, or act in addictive ways, but rather it’s our thinking about those situations.\nIt’s our ideas that use notions, thoughts, views, opinions in our head, what we tell ourselves about those adverse situations that cause our problems, not the situations themselves. And that’s a very powerful idea because that means, if you’re feeling anxious, depressed, or angry, you are in control. You are creating that. You are making yourself feel that way. So you can uncreate those feelings. And that’s what cognitive behavior therapy and Rational Emotive Behavior Therapy is based on.\nAnd Albert Ellis took that theory, or actually devised that theory, and took it down to a simple ABCDEF that you mentioned.\nAnd let’s take a problem. Let’s suppose your mate criticizes you unfairly, in your view, and you get angry. So let’s see how we can apply the ABCDEF model to that. And I call that the three-minute exercise.\nDr. Grohol: OK.\nDr. Edelstein: So, A stands for activating event or adversity. So, A is “My mate criticized me unfairly.”\nThen B is what you tell yourself about it. Now, B normally starts with a reasonable notion, such as “I prefer he or she not criticize me unfairly. I don’t like it. This is unpleasant, frustrating. I wish he wouldn’t.” And that preference leads to appropriate negative emotions, such as displeasure, frustration, concern, disappointment.\nAnd those are appropriate negative emotions in that they’re not dysfunctional to feel that way; if you get criticized unfairly, it makes sense to have some negative reaction. It doesn’t make sense to feel numb or happy about it, so it makes sense to have a more measured or reasonable response to it.\nBut then, being imperfect humans, we take our strong preferences and convince ourselves they’re absolute musts, shoulds, have-tos, laws of the universe, things absolutely have to be that way. So I take my preference, “I’d prefer my mate not to criticize me,” and insanely convince myself, “Therefore she must not criticize me unfairly. She must be fair. And she’s no good, she’s rotten, because of her unfair treatment.”\nAnd we call that B irrational belief. And that irrational belief in B leads to C, undesirable emotional consequence: anger, resentment, hostility, wife abuse, those kinds of things. So it’s B that causes C. My demand is she treat me fairly, rather than A, activating event, her unfair treatment.\nDr. Grohol: Got you.\nDr. Edelstein: So, if we look at B, “She must not treat me unfairly, ” my goal is reasonable, that I be treated fairly. That makes sense. It’s just the must about it that’s the toxic part that does me in and gets me angry.\nSo the question is, how can I keep my goal, to be treated fairly by my mate, but get rid of the demanding, the commanding, the musting about it? And the answer is we go on to D.\nD stands for disputing or questioning the irrational belief. And to do that, it’s a simple process. We just take what we have at B, “She must not criticize me unfairly,” and just put “Why?” or “What is the evidence?” in front of it, and we get a good question: “Why must she not treat me unfairly? Where’s the evidence she must always be fair in her criticisms? Where is it written that my mate must be understanding, fair, kind, and considerate?” So that’s a good question.\nAnd then we go on to E. E stands for effective new thinking, or the answer to the question. And if you think about it, and think about it and think about it, you’ll normally never find evidence for must. Since you don’t run the universe, as far as I know–I didn’t see in this morning’s paper that any of us were elected ruler of the universe–there’s no reason why anyone must or has to act the way we want them to.\nSo that’s what we could put in E: “No reason she absolutely must treat me fairly, although I’d prefer she treat me fairly.” And then the more you have in E, the more persuasive it tends to be, as long as what you write in E is meaningful and not pie-in-the-sky.\nSo you can add more things, like “It is disadvantageous to be treated unfairly, but not the end of the world.” “I don’t like being treated unfairly, but I definitely can stand it.” “I’ve survived unfair treatment in the past, and I’ll survive it in the future.” “It’s not my mate’s unfair treatment of me that makes me angry, but rather it’s my unrealistic thinking about it, and I can change my thinking.”\n“In order to have the advantages of a good relationship with a mate, a partner, or a friend, or even a colleague, it’s necessary to have the disadvantages. That’s inevitable.” “I can still have a happy life, even though I’m treated unfairly at times, although I’d be happier if everyone in the world always treated me fairly.”\nSo you write out all the reasons why the must is false and self-destructive. And then, if you do that on a regular basis, even daily, once or twice or three times a day, you practice writing out those three-minute exercises and reinforce the effective new thinking, then, due to the learning process which says “Reinforcement is the royal road to learning, ” you slowly, or not so slowly, get to F, your new feeling: concern, disappointment, displeasure, frustration, or if it’s a big issue, great displeasure, great concern, great disappointment. But not anger, not resentment, not hostility, because you’ve banished the must.', 'How Optimism Reduces Financial Anxiety\nWhat do you do when bad things happen? Trying to find something good in a bad situation appears to be particularly effective in reducing anxiety the less money a person makes, possibly because people with low incomes have less control over their environment, according to research published by the American Psychological Association.\n“Our research shows that socioeconomic status has a powerful effect on whether reframing a situation can reduce anxiety, both in the short term and the long term,” said Claudia Haase, Ph.D., of Northwestern University and co-author of the study. “As social inequality continues to rise, it becomes increasingly important that we understand how emotional regulation strategies might benefit mental health across the socioeconomic spectrum.”\nThe research was published in the journal Emotion.\nHaase and her colleagues used data from an experiment and a national survey to analyze the role of income in what the authors called cognitive reappraisal strategies, where an individual attempts to regulate his or her emotions (thereby reducing anxiety) by reconsidering, reframing or gaining a new perspective on past or anticipated experiences.\n“After a romantic breakup, for example, you might be afraid of being lonely,” said lead author Emily Hittner, MA, a Ph.D. candidate, also from Northwestern. “You could use cognitive reappraisal to manage this fear by telling yourself that now is a great time to get to know yourself better, discover new passions, rekindle old friendships and have space to find a more fulfilling relationship.”\nThe researchers first conducted a laboratory-based experiment involving 112 married spouses. Participants were asked to watch a short film designed to upset them (e.g., an excerpt from a movie in which a mother learns of the death of her two daughters) and were instructed that if they felt any negative emotions, to try to think about or reframe the situation in such a way that they experienced fewer negative emotions. They were also asked to report on whether they used reappraisal strategies in their daily lives and on their annual income using a scale of one (less than $20,000 per year) to seven (more than $150,000 per year).\nParticipants from lower socioeconomic strata who reappraised more said they felt less anxious, but this was not the case for middle- or upper-income participants.\nThe researchers also analyzed data from Midlife in the United States, a national telephone survey funded by the National Institute on Aging involving more than 2,000 participants interviewed in the mid-1990s and again nine years later. As part of both surveys, respondents answered a series of questions designed to measure the extent to which they engaged in reappraisal strategies and to measure their anxiety levels. People who said they used reappraisal strategies reported decreases in anxiety nearly a decade later, but once again, this was only true for those with lower incomes.\nIn both experiments, cognitive reappraisal started to lose its effectiveness when incomes rose above $35,000 per year.\nHaase believes these findings may have something to do with a person’s control over external factors. People who make more money may have more control over their environment, and therefore may be better off changing the situation itself rather than their take on it.\n“Individuals with lower incomes, though, have less access to resources to directly change a stressful situation they may find themselves in,” she said. “For that reason, they may find it more effective to deal with anxiety by reframing the situation.”\nCognitive reappraisal is one element of cognitive behavioral therapy, which is one of the most common types of psychotherapy used to treat anxiety disorders, but not the only element, Hittner noted. While further research needs to be done to confirm, people from higher socioeconomic backgrounds might find better results using other strategies where they put their resources to work to change situations for the better, she said.\n“Socioeconomic Status as a Moderator of the Link Between Reappraisal and Anxiety: Laboratory-Based and Longitudinal Evidence” by Emily Hittner, MA, Katie Rim, BA, and Claudia Haase, PhD, Northwestern University. Emotion. Published online Dec. 17, 2018.']	['<urn:uuid:830c0154-4135-4a44-b2c7-499f33f227fc>', '<urn:uuid:1f71d5f5-ae1c-40ac-bee2-11d3c61d2a2f>']	factoid	direct	long-search-query	distant-from-document	multi-aspect	novice	2025-05-01T22:47:46.423955	10	84	1917
79	toxic waste dump locations minority communities research history first study	In August 1990, Professor Robert Bullard published the landmark book 'Dumping in Dixie', which was one of the first scholarly studies to demonstrate that toxic waste dumps and highly polluting factories tend to be located in or near communities of color and poor white communities, both in urban and rural areas throughout the United States. Bullard is considered the founder of the environmental justice movement for this work.	"['John McCain, the ‘Maverick’ was the last Republican presidential candidate to be asked about climate change on the debate stage. Now 70 House Democrats have requested that change in this year’s debates. (Photo: Rona Proudfoot, Flickr, CC BY-SA 2.0)\nIn this week’s edition of Beyond the Headlines, Peter Dykstra joins Bobby Bascomb to discuss calls for climate change to be a centerpiece topic in the upcoming Presidential debates. This week’s segment also covers the EPA announcement that the agency would shift focus away from climate change, and towards “community cleanups”. Finally, looking back through history, the pair discuss the 30th anniversary of the landmark book Dumping in Dixie by “the father of environmental justice,” Prof. Robert Bullard.\nDOERING: It’s Living on Earth, I’m Jenni Doering.\nBASCOMB: And I’m Bobby Bascomb. It’s time now for a look Beyond the Headlines with Peter Dystra. Peter is an editor with Environmental Health News, that’s EHN dot org and Daily Climate dot org. Hey Peter, what do you have for us this week?\nDYKSTRA: Hi, Bobby is of course getting into the thick of election time. This past week 70 democrats from the House of Representatives sent a letter to media organizations demanding that climate change be a centerpiece of the 2020 presidential debates.\nBASCOMB: Well, I do remember in 2016, there was no mention of the environment or climate change specifically in the debates. But when was the last time it did come up in a presidential debate?\nDYKSTRA: Not in 2016, as you said, not in 2012. But the last time was in 2008, where the moderator Bob Schieffer asked a question, except not about climate change. He said climate control, which is of course, a term not used in climate science. It\'s a term used in the plumbing and heating industry.\nBASCOMB: He just misspoke then?\nDYKSTRA: He misspoke. He was very politely corrected by the late Senator McCain.\nSCHIEFFER: Let\'s talk about energy and climate control, every president since Nixon has said what both of you --\nMCCAIN: Climate change\nSCHIEFFER: --climate change? Yes\nDYKSTRA: Both McCain and Obama went on to give somewhat evasive answers, not talking about climate change and its causes. But talking about energy independence.\nBASCOMB: Well, these 70 democratic house legislators are hoping to change that this time around. What else do you have for us this week?\nDYKSTRA: In the EPA, which is called the Environmental Protection Agency, although some people would take issue with how protective they are of the environment these days, the administrator Andrew Wheeler, who of course, is a former lobbyist for big coal, announced a shift away from climate change as an EPA priority and toward community cleanups\nBASCOMB: Community cleanups, okay, I mean, I\'ve heard President Trump say many times that he wants crystal clear air crystal clear water as he puts it, but of course, this administration doesn\'t have a very good track record of protecting our air and water or communities. For that matter, they\'ve rolled back dozens of Obama era environmental laws and regulations, many of which did protect air and water. So what\'s their goal here? How\'s that gonna work out?\nDYKSTRA: Well, it\'s hard to say precisely from the administration\'s language, as you suggest from its actions maybe a little differently. Administrator Wheeler talked about how much cleaner our air is how much cleaner our water is, but he didn\'t point out that one of the main reasons that our air and water are cleaner would be the regulations that the White House and the EPA are now trying to roll back.\nBASCOMB: All right, well, what do you have for us from the history books this week?\nDYKSTRA: We have a very important 30th anniversary. This was actually last month in August, but it\'s worth mentioning. Bob Bullard is a professor at Texas Southern University. He\'s been called the founder of the environmental justice movement. And one of the reasons he can claim that title is a book and study that he released in August of 1990, called ""Dumping in Dixie"" was one of the first scholarly looks at how toxic waste dumps, how highly polluting factories, all tend to make their way into or near communities of color, or even poor white communities, both urban and rural throughout the United States.\nBASCOMB: Yeah, boy, that\'s a problem that\'s been going on a long, long time. And I really timely reminder for us now, given the Black Lives Matter protests taking place across the country.\nDYKSTRA: It is and it doesn\'t just refer to government inaction, or questionable action from big business, but even in the environmental community. Shortly after Bullard\'s ""Dumping in Dixie"" book came out 30 years ago, there was a letter sent to the CEOs of big environmental nonprofits criticizing the number of positions in authority in those organizations, held by people colour. With a few notable exceptions, that\'s still the case 30 years later, and the environmental movement is much open to criticism as being an elite white movement, and that pretty clearly would undermine its chances for success.\nBASCOMB: All right, thanks, Peter. Peter Dykstra is an editor with environmental health news. That\'s ehn.org and daily climate.org. And we\'ll talk to you again real soon.\nDYKSTRA: Okay Bobby, thanks a lot, talk to you soon.\nBASCOMB: And there\'s more on these stories on the living on earth website. That\'s LOE.org.\nLiving on Earth wants to hear from you!\nP.O. Box 990007\nBoston, MA, USA 02199\nNewsletter [Click here]\nDonate to Living on Earth!\nLiving on Earth is an independent media program and relies entirely on contributions from listeners and institutions supporting public service. Please donate now to preserve an independent environmental voice.\nSailors For The Sea: Be the change you want to sea.\nInnovating to make the world a better, more sustainable place to live. Listen to the race to 9 billion\nThe Grantham Foundation for the Protection of the Environment: Committed to protecting and improving the health of the global environment.\nEnergy Foundation: Serving the public interest by helping to build a strong, clean energy economy.\nContribute to Living on Earth and receive, as our gift to you, an archival print of one of Mark Seth Lender\'s extraordinary wildlife photographs. Follow the link to see Mark\'s current collection of photographs.\nBuy a signed copy of Mark Seth Lender\'s book Smeagull the Seagull & support Living on Earth']"	['<urn:uuid:e0aafa4b-b30f-4e48-8be7-4dbd06677fa9>']	open-ended	with-premise	long-search-query	distant-from-document	single-doc	novice	2025-05-01T22:47:46.423955	10	68	1071
84	thai english learning strategies classroom support	For effectively learning both Thai and English, key strategies include using modeling, repetition, and emphasis in the classroom, along with watching Thai TV programming for at least an hour daily to absorb pronunciation. Additionally, children benefit from early exposure to English through day-care, pre-nursery, or English-speaking playgroups, while being mindful of learning the structured rules of Thai's 44 consonants and complex vowel system.	['Learning a new language can be daunting to say the least, but learning a new language that has absolutely no Latin or Germanic foundation – like Thai - can be, for us native English-speakers, downright frustrating.\nI’m going to give you a primer on the language and what, in general terms, to expect, and I’ll also provide you with some suggestions to get you going along the right path.\nI want to stress that there is nothing to be afraid of. Though the Thai language may appear to be a very tall mountain to climb, with persistence and patience it can be done. There’s a lot of information here, and it’s going to seem overwhelming, but in reality the Thai language is highly structured with few exceptions to the rules.\nLearn and memorize the rules and you’ll be well on your way to living the expat life happily and fluently!\nIt’s all about the tones\nThai is a tonal language. Unlike English where the intent of a sentence is determined by inflection (questions usually rise at the end, statements usually fall, etc…) Thai has a very specific set of tone rules. This is the single most important thing you need to understand about the language.\nThere are five tones in Thai: mid, low, falling, high, and rising. Every syllable has a tone associated with it based on certain rules (don’t worry about the rules for now).\nA mid-tone has a monotone sound in the natural register of your voice.\nA low tone is also somewhat monotone-sounding but requires you to lower the pitch of your voice/make it deeper.\nA falling tone starts a little bit higher than your mid tone and lowers in pitch at the end.\nA high tone gets higher in register at the end of the syllable.\nA rising tone sounds like a high tone but starts lower and is a bit more dramatic.\nThis is, of course, an oversimplification, and I strongly suggest that you listen very closely to Thai natives to hear the distinctions.\nThe bottom line is that you must understand the importance of tones. If you mispronounce the tone of a syllable or word you could, for example, say the word for “horse” when you meant to say the word for “dog.”\nThere are many Thai language learners that will tell you not to worry about tones and to just start with vocabulary. I completely disagree with this, and my suggestion is to be aware of how important the tones are and to be sure to learn them from the onset of your Thai language education.\nConsonants in the Thai language\nThere are 44 consonants in the Thai language. Consonants are arranged into three groups called “classes”: low, mid, and high. Each of the 44 consonants belongs to one of these groups, and is one of the determining factors for a syllable’s tone.\nA few of the consonants – and this goes for some vowels, too – have sounds that we English speakers are not familiar with and may prove awkward to learn at first. For example:\nDT – This sound is not something we naturally produce in English. It’s a combination of a “D” and “T” sound.\nNG – Think of the word “singing.” The Thai NG sound is produced similarly to the first “ng” in singing.\nSeveral of the consonants have the same sound but are written differently. For example, the letter “s” in Thai can be written four different ways:\nซ, ศ, ษ, ส\nConsonants also have a unique feature in that their sound changes depending on whether or not they are found at the beginning or end of a syllable. Using our letter “s” example, when one of those four characters is used at the beginning of a syllable, the “s” sound is used. However, if one of those same characters is used at the end of a syllable, they are pronounced with a “t” sound. (Thai does not have an ending “s” sound for a syllable, so “t” is used instead.)\nVowels in the Thai language\nVowels, admittedly, are a bit of a pain in the butt to wrap your head around. Not only do some of the vowels have sounds that are – like some consonants – difficult to reproduce for us, but vowels can be found before, after, on top of, or below a consonant, as well as in several combinations thereof. Here are some examples:\nThis syllable is pronounced /nai/. The first character, ใ, is actually the vowel. Yes, that’s right; in this case the vowel “ai” comes before the consonant “n.”\nThis is the word for “good” and is pronounced as /dii/ (“dee”). The vowel is above the consonant in this case.\nThis is a fun one. /rao/ is the word for “we,” and the vowel is actually the first and third character. The “r” sound is sandwiched in between the vowel!\nThe word for “ear” is /hǔu/ (pronounced with a rising tone). The vowel is the small u-shaped symbol underneath the consonant “h.”\nLastly, here is a hard one:\nThis is the word for “alone” - /diiao/. The vowel is a combination of everything except for the ด. Yes, this vowel is to the left, above, and to the right (with two characters) of the consonant.\nHave I scared you yet? Probably. They scared me at first. But as I mentioned at the beginning, persistence is the key. Just remember that there is only one vowel sound per syllable.\nTone marks in the Thai language\nAs if the information already provided isn’t intimidating enough to have you scouring the web for English language expat groups and media sources, the Thai language also has four symbols called tone marks, which are used to determine a syllable’s tone. The good news here is that when a tone marker is present you can ignore all of the other factors that determine a syllable’s tone. The four tones marks are:\n่ mái èek\n้ mái too\n๊ mái dtrii\n๋ mái jàt-dtà-waa\nDon’t worry about the dotted circles; they are just there to represent where a consonant should be. All tone markers go above the corresponding consonant.\nAny last words?\nYes, a few things, but since this is just a primer I won’t drown you in detail. There are a few more quirks like consonant clusters and other symbols that come into play, but for now I think I’ve given you enough to warrant a few mind-numbing margaritas.\nAs a consolation prize of sort:\nSorry to have to do this to you, but I should also mention that written Thai has no spaces in between words. Yes, that’s right, Thai looks like one huge run on sentence. There are spaces in between sentences, but not in between the words in a sentence. For example:\n/kun wâai-náam dâi mǎi/\nCan you swim?\nHere are the individual words separated out as if it were English:\nคุณ ว่าย น้ำ ได้ ไหม\nUnfortunately, we don’t get the luxury of having Thai written the English way.\nIt’s also important to know that Thai is also, in some cases, gender specific. Men will use certain words for something and women will use certain words for the same thing. As you start to learn the language, be aware of this so you don’t walk around saying words a woman would normally use when you are a man (and vice versa). Though it’s not the end of the world, it could cause for some unexpected chuckles.\nAny suggestions for tackling Thai?\nBe patient – This is a marathon, not a sprint. As complex as Thai may seem, it’s really not. Just go step by step and take your time.\nMake a friend – There is nothing more valuable than finding a few Thai people and becoming friends. I assume this will happen by default, but the point here is to start speaking Thai to them right away. You’ll find that a few things happen:\nYou make instant friends. (Thai people LOVE when they see you making the effort.)\nThey will start to help you with your Thai. At first you may need to nudge them a little bit, but once the friendship has been established they will most often be eager to help you.\nWrite, Read, Speak – Learn to do all three at once. Children’s books are a great place to start. But don’t neglect one for the other two. Just learning how to speak may seem like the thing to do, but it’s really not.\nDO NOT try to learn Thai from the newspapers – One of the interesting quirks about Thai is that speakers will always try to shorten everything being said or written. Because of that, newspapers and magazines will often be very difficult to understand. Trust me; the last thing you want to do is talk like a newspaper!\nLearn from the right people – If you are a 60-year old man, you probably don’t want to be learning to speak Thai exclusively from a 22-year old girl. Not only will you probably start to use woman-specific words, but you’ll also be picking up all of her slang. In essence, you’re going to sound pretty strange!\nListen, listen, listen! Get a TV and watch Thai programming, a lot. At least an hour a day if you can. Don’t worry about trying to figure out what they are saying, just listen. You’ll absorb the pronunciation the same way a child learns.\nHave fun. You’re going to hear the Thai word sanuk (“fun”) a lot. Thai people are all about having fun, so you should too!', 'The Surprising Link Between English Proficiency And Academic Performance: What This Could Mean For Thai Children In English-Based Schools\nSome bilingual children learn both of their languages from birth, whereas other children learn a second language well after their first. In Thailand, local families speak Thai at home, so children are usually first exposed to English once they attend an English-based school. Children who learn English during their school years face the challenge of learning a new language while trying to keep up with academic content. Some content is likely to be missed during this process . It is commonly assumed that after some time and English exposure, these children just “catch-up”, however, in Thailand where the local language is Thai, this is not necessarily the case.\nThere are several studies which have looked at how learning English at school can impact a child’s performance at school. The findings will surprise you...\nHow long does it take a child to become proficient in English?\nStudies have shown that it can take a child anywhere between 1- 6.5 years of exposure to English to become proficient in English . This is also influenced by other factors such as family, education, social and individual factors [3.]\nHow does English proficiency impact a child’s academic performance?\nAn Australian study published last year found that school-aged children who are not yet proficient in English are likely to face academic difficulties compared to their peers . This study also found that children who had better English proficiency when starting school achieved higher academic outcomes overall towards the completion of primary school .\nWhat do these findings mean?\nThese findings suggest that children who first learn English through exposure at an English-based school, could struggle with learning academic content at school for up to 6.5. years. These findings were based on populations living in countries such as Australia and the US, where the main language is English to begin with. However, in a country like Thailand, where the local language spoken is Thai, this could take even longer.\nAs a result, it is likely that local Thai children might be over-identified as requiring Speech Therapy during their school years. I often find myself teaching children concepts in English which I then realize during the session that they already have sound knowledge of in Thai (e.g. ‘past’ and ‘future’ tense). In these cases, the child’s underlying difficulty is not language, but specifically English. Thus, an ESL program is often more suitable for these children.\nHow can we use this evidence practically?\nChildren who are learning English at school would benefit from the use of strategies such as modeling, repetition and emphasis in the classroom. These strategies will help support their understanding of instructions and material presented in class. Once their understanding is supported, their performance when completing tasks will likely improve.\nSeveral children who learn English at school require individualized programs to be tailored to support their learning and performance at school. Before a program can be recommended, there needs to be a strong understanding of the child’s Thai language skills. If the child has adequate Thai language skills, then they can be enrolled in an ESL program. However, if a child is having difficulty with both Thai and English, Speech Language Therapy is recommended, as there is likely to be underlying language impairment.\nThere is a greater need for spreading information about the benefits of being bilingual as well as the difficulties a child is likely to face if they are expected to learn English while at school. This might encourage local parents to expose their children to both Thai and English from a young age if they intend to send them to an English-based school in the future.\nAttending day-care or pre-nursery is a fantastic way for children to become exposed to English from a young age. Attending playgroups or arranging play-dates with other English-speaking children will also help.\nLocal Thai children who first learn English at school are likely to face difficulties keeping up with academic content. Increasing exposure to English from a young age is likely to help with this. Certain classroom modifications and programs such as ESL can be provided for these children during their school years.\n1. Macswan, J., & Pray, L. (2005). Learning English bilingually: Age of onset of exposure and rate of acquisition among English language learners in bilingual education program. Bilingual Research Journal, 29, 653-678.\n2. Brinkman, S. et al. (2009). Population monitoring of language and cognitive development in Australia: The Australian early development index. International Journal of Speech Language Pathology, 11, 419-430.\n3. Halle, T. et al. (2012). Predictors and outcomes of early versus later English language proficiency among English language learners. Early Childhood Research Quarterly, 27, 1-20.\n4. Dennaoui, K., Nicholls, R. J., O’Connor, M., et al. (2016). The English proficiency and academic language skills of Australian bilingual children during the primary school years. International Journal of Speech-Language Pathology, 18: 157-165.\nWelcome to my blog!']	['<urn:uuid:32a4c2eb-734c-4260-ae63-83e1f7256e2c>', '<urn:uuid:efc51235-e3e6-4e42-9cca-e2bb4fcf0429>']	factoid	with-premise	short-search-query	distant-from-document	three-doc	expert	2025-05-01T22:47:46.423955	6	63	2433
88	What major milestones have women achieved in American society?	Women have achieved several groundbreaking milestones in American society. In aviation, Amelia Earhart became the first woman to cross the Atlantic by airplane and later attempted to circumnavigate the globe in 1937, though she disappeared during this attempt. In politics, Frances Perkins became the first female cabinet member as Franklin D. Roosevelt's Secretary of Labor. In sports, women made strides with the creation of the All-American Girls Professional Baseball League, and Manon Rhéaume became the first woman to play in an NHL game. A particularly significant achievement came in 2016 when Hillary Clinton became the first female presidential nominee of a major party. In government representation, while progress has been slow, women's participation in state legislatures has quintupled since 1971, with Nevada achieving over 50% female representation in 2019.	"['Colonial era[ edit ] A stamp honoring Virginia Darewho in became the first English child born in what became the U. Colonial history of the United States The experiences of women during the colonial era varied from colony to colony, but there were some overall patterns. Most of the British settlers were from England and Wales, with smaller numbers from Scotland and Ireland. Groups of families settled together in New England, while families tended to settle independently in the Southern colonies.\nSanger tried to reopen the clinic twice more, but police forced her landlord to evict her the next month, closing it for good. The book has inspired several stage and screen adaptations, and the writer Cecily Von Ziegesar has said that it was the model for her popular Gossip Girl series of books.\nTwenty-two of the required 38 states ratified it right away, but then conservative activists mobilized against it. It would force wives to support their husbands, send women into combat and validate gay marriages. This anti-ratification campaign was a success: InIndiana became the 35th and last state to ratify the ERA.\nIn Junethe ratification deadline expired. The amendment has never been passed. Amelia Earhart is the first woman to cross the Atlantic in an airplane, After that first trip across the ocean, which took more than 20 hours, Amelia Earhart became a celebrity: She won countless awards, got a ticker-tape parade down Broadway, wrote a best-selling book about her famous flight and became an editor at Cosmopolitan magazine.\nInEarhart attempted to be the first female pilot to fly around the world, and the first pilot of any gender to circumnavigate the globe at its widest point, the Equator. No trace of Earhart, Noonan or their plane was ever found.\nThe 15 states that never ratified the Equal Rights Amendment are: Frances Perkins becomes the first female member of a Presidential cabinet, Perkins, a sociologist and Progressive reformer in New York, served as Franklin D. She kept her job until The All-American Girls Professional Baseball League becomes the first professional baseball league for female players, Women had been playing professional baseball for decades: But byso many major-league stars had joined the armed services and gone off to war that stadium owners and baseball executives worried that the game would never recover.\nIt would keep ballparks filled and fans entertained until the war was over. Searle applied for a license from the federal Food and Drug Administration to sell its drug Enovid, a combination of the hormones estrogen and progesterone, for use as an oral contraceptive.\nFDA approval was not guaranteed: For one thing, the agency was uncomfortable with the idea of allowing doctors to prescribe drugs to healthy people; for another, the young bureaucrat assigned to the case was fixated on moral and religious, not scientific, objections to the pill. Despite all this, Enovid was approved for short-term use in October She turned to car racing instead and became the first woman to qualify for the Daytona and the Indianapolis Mechanical difficulties forced her out of the Indy race, but the next year she finished in ninth place with a broken wrist!\nThe helmet and suit that Guthrie wore in her first Indy race are on display in the Smithsonian Institution in Washington D. In that game, she deflected seven of nine shots; however, she was taken out of the game early and never played in a regular-season game.\nThe team also won silver at the Olympics in Nagano, Japan.\nInCondoleezza Rice became the second woman—and first African-American woman to hold the job. Written by Mark Boal, a former journalist who covered the war in Iraq, the movie follows an Army bomb squad unit as they conduct dangerous missions and battle personal demons in war-torn Baghdad.\nHillary Clinton becomes first female presidential nominee of a major party, On July 26,the former first lady, U. Clinton had previously mounted an unsuccessful presidential campaign in before losing to Barack Obama in the Democratic primaryand fought off a strong challenge by Vermont Senator Bernie Sanders in before clinching the glass ceiling-breaking nomination.\nStart your free trial today.An American women\'s rights and temperance advocate. She presented her views in her own monthly paper, The Lily, which she began publishing in When Amelia was 22, she married a lawyer by the name of Dexter Bloomer. This online exhibit from the National Women\'s History Museum traces the experiences of African American Women from the transatlantic slave trade to the twenty-first century.\n""From Slave Women to Free Women: The National Archives & Black Women\'s History in the Civil War Era"". The history of the United States began with the settlement of Indigenous people before 15, BC.\nwas refuted by the enthusiastic participation of tens of thousands of American women on the home front in World War I. Across the world, grateful nations gave women the right to vote.\nWomen’s History Month, established in , is a celebration of women’s efforts across the nation to make the world a better place for females. Before the month is out, let’s not forget our. This is a piece on history of women in the United States since , and of the Thirteen Colonies before that. The study of women\'s history has been a major scholarly and popular field, with many scholarly books and articles, museum exhibits, and courses in schools and universities. The roles of women were long ignored in textbooks and popular histories. Mar 10, · Watch video · During World War II, some , women served in the U.S. Armed Forces, both at home and abroad. They included the Women’s Airforce Service Pilots, who on March 10, , were awarded the.\nPioneer in Women\'s Education A thirty-six-year-old Rhode Island high school teacher and principal, Sarah Elizabeth Doyle was a founder of the coeducational Rhode Island School of Design (). The history of the United States is what happened in the past in the United States, a country in North America.\nNative Americans have lived there for thousands of years. In the 19th century, there was something called the “cult of domesticity” for many American women. For most of history, Virginia Woolf suggested, anonymous was a woman.\nAnd even those whose names we know have largely not gotten their due. Celebrate some of the many female women who have shaped our world with these profiles and biographies.', 'By Jennifer Nicoll Victor, Ph.D., George Mason University\nAmerica was established as a democracy, but it was a particularly weak one. We credit the American civil rights movement as helping to significantly expand democracy and civil rights in the country. Let us take a look at the policy of affirmative action and the women’s suffrage movement that can be seen as a precursor of the civil rights movement in America.\nThe End of the Jim Crow Era in America\nThe election of 1960, between John F. Kennedy and Richard Nixon, was a turning point in the struggle against racial discrimination. To win the election, Kennedy supported civil rights as a central theme of his campaign. Kennedy won the election but was assassinated in November 1963 before civil rights legislation could be enacted.\nWith a promise to carry out Kennedy’s legacy, his Vice President, Lyndon Johnson, a southerner (from Texas) himself, oversaw the passage of the 1964 Civil Rights Act and the 1965 Voting Rights Act—landmark policies that fundamentally changed the course of American history.\nThese laws effectively ended the Jim Crow era in the South. Moreover, the strategic choice of elite Democrats to help end systematic disenfranchisement of African Americans created a strong bond of partisan loyalty between the Democratic Party and the African American community that remains to this day.\nThis is a transcript from the video series Understanding the US Government. Watch it now, on The Great Courses Plus.\nThe Rise of Affirmative Action\nAffirmative Action refers to a policy that uses some form of preferential weighing of individuals in order to achieve diversity.\nIn an attempt to achieve a more diverse employee or student population, companies or universities enacted policies that provided some preferential treatment to candidates from minority backgrounds.\nThere were three key Supreme Court cases that addressed the legality of affirmative action.\nRegents of University of California v. Bakke Case\nIn 1978, a white student sued the university for racial discrimination upon being twice denied admission to medical school at the University of California, Davis.\nThe Supreme Court agreed with Bakke that using race as a criterion was “suspect”. The Court ruled that schools could not set aside seats for students using a race-based quota system to achieve a diverse student body, they also found that the use of race as a criterion in admissions decisions in higher education was constitutionally permissible.\nHopwood v. Texas Case\nIn 1996, a case was decided not in the Supreme Court, but in the Fifth Circuit Federal Court of Appeals—one step below the Supreme Court.\nThe Fifth Circuit Court ruled that race could not be considered at all as a factor in university admissions. The Supreme Court declined to hear the case on appeal, which meant that the ruling of the Fifth Circuit became the legal standard for all states under its jurisdiction.\nGrutter v. Bollinger Case\nIn 2003, the Supreme Court gave a ruling in a case that has put affirmative action on its strongest footing yet. The ruling stated that racial considerations can sometimes be utilized to serve a compelling state interest.\nIn upholding the University of Michigan Law School’s affirmative action program that took race into account (minus quotas), the Supreme Court provided a legal blessing to a key system many companies/universities utilized to help achieve racial diversity goals.\nLearn more about the Supreme Court’s role in politics and government.\nThe Revolution of Women’s Rights Movement\nThroughout the late 1800s, thanks to Lucretia Mott and Elizabeth Cady Stanton, two key figures in the women’s suffrage movement, some states granted women the right to vote. However, women did not gain federal protection for their right to vote until 1920, with the ratification of the 19th amendment.\nAfter securing voting rights, the women’s rights movement sought further civil rights (protection from discrimination based on sex) and advocated that the US adopt an Equal Rights Amendment to the Constitution. Section One of the proposed amendment reads:\nEquality of rights under the law shall not be denied or abridged by the United States or by any State on account of sex.\nThe proposal became known as the ERA.\nFeminism vs. Anti-Feminism and the Fate of ERA\nIn 1972, during the peak of the movement known as second wave feminism, the House of Representatives passed the ERA by an overwhelming 354 – 24 vote, and the Senate passed it with a vote of 84 – 8. Once passed by Congress, a constitutional amendment had to be ratified by three-quarters of state legislatures.\nHence, the ERA had to be ratified by at least 38 states, and 30 did so within the first full year. By 1978, 35 states had ratified. At that point, anti-feminist organizations such as Eagle Forum Led by Phyllis Schlafly generated intense pressure against ratification.\nThey argued that the amendment would be detrimental to American families and communities and would encourage women to eschew their traditional roles as caretakers or homemakers. Pro-ERA feminist groups became ineffective advocates for ratification because they were divided over the issue of abortion.\nBut when the landmark Supreme Court case, Roe v. Wade was handed down in 1973, America’s focus on women’s issues heightened. In 1978, Congress extended the ratification deadline to 1982.\nNo new states ratified the ERA during this extension period, but some states rescinded their previous ratification, and ultimately the 10-year clock ran out. On January 27, 2020, however, Virginia became the 38th state to ratify the ERA.\nLearn more about American Democracy.\nThe Effects of ERA on Women’s Political and Social Status\nWomen continue to be underrepresented in political office. While about half the US population is female, in 2019, only 24% of US Congress members were women (30% for state legislators).\nSince 1971, however, the number of women serving in state legislatures has more than quintupled. Notably, as of 2019, the Nevada state legislature is more than 50% female, but in Mississippi, only 14% of state legislators are women.\nThe first woman to serve in the US House of Representatives was Jeannette Rankin, elected as a Republican from Montana in 1916—before her right to vote was federally protected.\nA Renewal of Feminist Social Movement\nIn recent years, women’s issues have gained increased public attention, leading some to suggest that we are entering a period of renewed feminist social movements. Various campaigns have led many victims of sexual harassment to go public about the abuses they’ve experienced.\nSeveral high-profile and powerful male executives have lost their jobs as a consequence of being exposed. Most were top news and entertainment heavy-hitters as well as several politicians.\nCommon Questions about Social Movements in America: The Fight for Equality\nTo win the elections in 1960, John F. Kennedy made the civil rights his focus point during the presidential campaign.\nAfter securing voting rights, the women’s rights movement sought further civil rights (protection from discrimination based on sex) and advocated that the US adopt an Equal Rights Amendment to the Constitution. The proposal became known as the ERA.\nIn the mid-1800s, women began their movement for civil rights.']"	['<urn:uuid:0ab0d89c-02e8-4404-b849-a108db3b6548>', '<urn:uuid:4fb09f35-46fe-4a7c-b15c-9b3f7df6eafc>']	open-ended	direct	concise-and-natural	distant-from-document	three-doc	novice	2025-05-01T22:47:46.423955	9	129	2234
97	How did New South Wales perform in the rugby match at Perth?	New South Wales achieved a dominant 38-6 victory over Queensland in Perth. Tom Trbojevic scored a hat-trick and James Tedesco delivered a masterful performance at full-back. The Blues showcased slick ball handling and dynamic outside backs, leading 18-6 at half-time before extending their lead in the second half. The match was played in front of a record crowd of 59,721 fans at Perth Stadium.	"[""State of Origin: New South Wales dominates Queensland 38-6 in Perth to set up decider\nNew South Wales has claimed a dominant, series-levelling 38-6 victory over Queensland in State of Origin game two.\n- New South Wales needed to win in Perth to stay alive in the series\n- The Blues led 18-6 at half-time before running away in the second half\n- Queensland's only try was a penalty try after Will Chambers was impeded\nA hat-trick from centre Tom Trbojevic and another masterful performance by James Tedesco at full-back saw the Blues put Queensland to the sword in front of 59,721 fans, a record for any match at Perth Stadium.\nNew South Wales' slick ball handling and dynamic outside backs blew Queensland away, with the Maroons never really in the contest and rarely threatening the Blues line.\nWith the series all square, the two sides will head to Sydney's Olympic Stadium for the decider on July 10, although the Blues will consider themselves clear favourites to retain the Origin shield after such a clinical performance.\nBlues coach Brad Fittler made seven changes to the side that was beaten in game one amid much criticism, but he will feel vindicated by his selections as James Maloney and Trbojevic in particular scythed Queensland apart.\nThe Blues got off to a perfect start when Trbojevic claimed a towering Maloney bomb over the top of Kalyn Ponga, inside the opening 10 minutes.\nQueensland did not look the same fluent team that came from behind to win the series opener at Lang Park but were gifted a way back into the game on their first foray into NSW territory thanks to a penalty try.\nJack Wighton impeded the progress of opposing centre Will Chambers when the Storm centre was the sole pursuer of a Ben Hunt kick into the in-goal.\nChambers failed to ground the ball but Gerard Sutton referred up to the video referee who agreed that the centre was impeded and awarded the penalty try, allowing Queensland to pull level with the kick in front of the posts.\nBut the parity did not last long.\nTyson Frizell regained the lead for the Blues with some exceptional hands to hold on to a Maloney pass and crash over from short range, after a bulldozing run from Daniel Saifiti put the Maroons on the back foot.\nDespite having a Josh Addo-Carr try called back for a forward pass by Maloney, the Blues were still celebrating their third before half-time thanks to some Tedesco magic.\nThe Roosters full-back was NSW's best in game one and continued his sparkling form in Perth.\nPicking up the ball from dummy half, Tedesco ghosted around five seemingly static Maroons defenders before fending off Morgan and shovelling an inside pass to Trbojevic, who breezed over untouched for his second.\nThe Blues made three line breaks to zero in the first 40 minutes, running for 250 more metres than the Maroons in a dominant first-half display.\nTrailing by 12 points at the break, Queensland would have hoped to muster the same fighting spirit that saw them overturn an eight-point deficit in game one.\nBut a similar fightback never looked like materialising in Perth as the Blues dominated possession to the tune of 60 per cent.\nDespite Cleary failing to take the field in the second half with an ankle injury, the Blues barely missed a beat, with Maloney slotting two penalties after the restart to take the game away from the Maroons.\nIf the decision to take a second two points was strange at that stage of the game, the Blues ensured it was a moot point moments later when Trbojevic scored his third.\nAddo-Carr broke the line and offloaded to Tedesco, who got his arms free and flicked the ball out the back to Trbojevic who raced under the posts unopposed.\nAddo-Carr got in on the act himself moments later, dotting down after a chip through the line by Wade Graham as the Blues ran riot, and adding a second in the final 10 minutes to add the gloss to what was a perfect night for the Blues.\nRelive all the action as it unfolded in our live blog below.""]"	['<urn:uuid:e7a9d70d-b75e-49be-b937-b824a285c568>']	open-ended	direct	concise-and-natural	distant-from-document	single-doc	novice	2025-05-01T22:47:46.423955	12	64	700
99	Which dessert is traditionally eaten during Chinese New Year and Epiphany?	Eight Treasures Rice Pudding is traditionally eaten during Chinese New Year, while the Galette des Rois (King's Cake) is traditionally eaten during Epiphany/Twelfth Night.	"['Eight Treasures Rice Pudding is a traditional Chinese new year pudding. Eight treasures topping is made up with eight different kind of dried fruits, raisin and sweets. You can choose any ingredients which are easy for you to buy. Of course, you don’t have to use “eight” different toppings but the number of toppings you use is really down to personal preference.\nI used five different kinds of toppings today because I only a small rice pudding for Chris and I. If I were to use eight different kinds of toppings for a rice pudding this size it would look a bit of a mess\nThe number eight is a magic number for Chinese people. In Chinese the number eight sounds like another Chinese word “發”. 發 in Chinese means rich and I believe everybody likes being rich. So, eight is a lucky number. Also, this dessert is really colourful and pretty so Chinese people love to have this dessert in Chinese New Year.\nChina has so many different provinces and different provinces also have different traditions. Whether you go to Taiwan, Hong Kong, Singapore or even Malaysia, although we all celebrate Chinese New Year the customs are different. Sometimes it’s really hard to say which Chinese dish is a typical Chinese New Year dish but I always say as long as the dish is petty, colourful and has a lucky or pretty name then it’s a good Chinese New Year dish.\nHere is recipe for this eight treasures rice pudding. I wish all of you have a great Chinese new year and I hope you will give my recipe a go and make eight treasures rice pudding for your friends and family. Trust me, they’ll love it.\nHandful of sugar glazed cherries\nHandful of black raisins\nHandful of yellow raisins\nHandful of sugar lotus seeds (available in Chinese supermarket)\n1 dried apricot\n2 cups of “round” glutinous rice\n100g red bean paste (available in Chinese supermarket)\n1 tablespoon sunflower oil\n¼ teaspoon salt\nIngredients for sugar syrup:\n1 tablespoon sugar\n1 tablespoon honey\n½ cup water\n2 tablespoon potato starch water (1/2 teaspoon potato starch with 1 tablespoon water and mix evenly )\nCouple drops of rose or any kind of flower essence.\nIn some traditional eight treasures rice pudding recipes, it says use “sweet-scented osmanthus sauce” but it’s very difficult to get in UK so I use rose essence to replace it.\n- Soak round glutinous rice in cold water for 1 hour at least. Cook it in a rice cooker or steamer. Mix the cooked rice with sunflower oil and salt when it’s still hot.\n- Brush some oil on a medium size bowl and cut the sugar glazed cherry in half. Place the dried fruits and sugar glazed cherries as shown in the photos.\n- Put half of the cooked glutinous rice in the bowl and press down a little bit then put 100g red bean paste in the middle.\n- Use a little bit of glutinous rice to cover the red bean paste and place the sugar lotus seeds and sugar glazed cherries around the bowl.\n- Put all of the glutinous rice in the bowl and press down. Steam for 30 minutes.\n- Use a small pot to boil all the ingredients for the sugar syrup. Stir in potato starch water to thicken the syrup.\n- Flip the rice pudding on a plate and brush sugar syrup on top. Ready to serve.\nServe: 3~4 people\nCooking time: 1 hour\nCredit: All photos were taken by Chris at: http://www.chrisradleyphotography.com', 'The Tradition of the Three Kings\nby Patricia Purvis with recipes edited by Gael Stirler\nBearing gifts we traverse a-far\nField and fountain\nMoor and mountain\nFollowing yonder star!\nTwelfth Night or Twelve Nights, as it is called in some places, celebrates the arrival of the Three Kings to the birthplace of Christ. It is observed on January 5th, the night before Epihany, and marks the end of the Twelve Days of Christmas, although Eastern Orthodox churches celebrate the arrival of the Three Kings on a different day.\nThe Three Kings, also known as the Wise Men or the Magi, were traditionally called Caspar, King of Tarsus, the land of myrrh; Melchior, King of Arabia, the land of gold; and Balthasar, King of Saba, where frankincense was said to flow from the trees.\nThe Kings presented gifts of gold, frankincense and myrrh to the Christ Child. Gold symbolized kingship, frankincense depicted godliness, and myrrh represented a painful death. In return, charity and spiritual riches would be offered for the gold, faith for incense, and truth and meekness for the present of myrrh. The Wise Men returned home and, in 7 A.D., it is said, Saint Thomas the Apostle discovered the Kings in India and baptized them. They are said to have become martyrs and their bodies buried within the walls of Jerusalem. It is believed the remains were later moved to Turkey by the Emperor Constaine\'s mother and, later still, to Milan, Italy until they were finally laid to rest in Cologne (Köln) on the Rhine River in Germany.\nTwelfth Night was a part of the year-end festivities in the British Isles and France. These celebrations originated in the 5th century when French and English churches created the ""Feast of Fools."" ""Temporary Bishops"" and ""Archbishops of Fools"" play-acted, reveled and generally caused mischief. By the fifteenth century, such ceremonies were banned from church by the French government due to lewd behavior. A new street festival was created and a temporary ""king"" for the season known as the Prince des Sots was elected. In England, this king was called the ""Lord of Misrule"" and, in Scotland, the ""Abbot of Unreason."" The king\'s reign began on Halloween and lasted for three months.\nThe ""state duties"" of both the French and English kings ended on Twelfth Night. A cake called Galette du Roi or ""King\'s Cake"" was consumed and marked the end of the celebrations. In addition, a large cake with a hole in the center was placed on the horns of bulls for the Twelfth Night Games and wine and ale was imbibed by all. Originally, cake was a symbol of the pre-Christian Goddess. Bulls\' horns represented the consort of this Goddess and her spirit was the ale and wine. This custom is the origin of communion.\nCelebration of such Twelve Nights festivities was no longer a tradition by the mid-19th century, but were replaced with ""Mummer Plays,"" which are still performed today throughout the British Isles. The troupes of performers are known as Morris Dancers and consist of six men who dance complex steps to the accompaniment of an accordion or fiddle. One of the men is dressed as a woman and is called Maid Marian. Other characters include Robin Hood and Friar Tuck. Another man, dressed in a horse-skull mask and a wide-hooped petticoat, chases young women and covers them with his skirt. He is known as the ""Hobby Horse.""\nSupernatural events are thought to occur during the Twelve Days of Christmas. The ""Wild Hunt"" and ""Faery Host"" are thought to ride through the countryside collecting souls. In Ireland, these beings are referred to as the ""Yule Host.""\nIn Whittlesey, the Sunday before the first Monday after Twelfth Night is the ""Procession of the Straw Bear."" A man wrapped in straw from head to toe dances through the streets while other Mummer Plays feature such characters as the ""She-Males."" These are men who dress up as old hags for the celebrations and represent the Goddess of Winter.\nDuring early times in rural Austria, the Twelve Nights between December 25th and Epiphany (January 6th) used to be referred to as ""Smoke Nights,"" due to the fact that incense was burned. Today, this is done on January 6th. The head of the household moves through the farm with incense in order to ""smoke out"" any evil spirits. Holy water is sprinkled on the house, the grounds and the barns. The head of the family then uses chalk to mark the door with the initials of the Three Wise Men—K(aspar), M(elichor) and B(althasar)—along with the number of the year. This lettering replaced the original pentagram chalkmark of ancient times which prevented evil spirits from entering the home.\nAustrian Twelve Nights celebrations also feature parades of costumed characters who blow horns and crack whips intended to drive away spirits. In Styria, a parade of bellringers known as Glocklerlauf takes place on January 5th. Elaborate headdresses are made for this occasion. On December 6th, children dress up as the Three Kings and the Star of Bethlehem in order to go caroling. They are rewarded with hot chocolate and gingerbread. In certain areas of the Alps, the traditional Twelve Nights custom is to light bonfires.\nIn the Netherlands, midwinter horn blowing known as midwinterhoornblazen is an ancient Yuletide tradition that dates from 2500 B.C. The sound is designed to drive away evil spirits and sometimes the horns can be heard up to three miles away. The instruments are specially carved from birch and elder trees, with a competition held on January 6th to decide the most proficient musician. ""Saint Thomas Ringing"", called St. Thomasluiden by the Dutch, is continuous bell-ringing in the bellhouses of Friesland cemeteries. The bells toll for the death of Saint Thomas a Becket, the English Archbishop of Canterbury who was murdered in his Cathedral on December 29, 1170. January 6th is known as""Three Kings\' Day"" or Driekoningendag. An Epiphany cake is baked and whoever finds the bean inside is king for the day, complete with gold paper crown. After this ceremony, the holiday season comes to an end and families remove their decorations. Many Dutch towns have organized burning of Christmas trees.\nIn France, the Twelve Nights feature the displaying of a creche or crib. This was invented by Saint Francis of Assisi in Italy on Christmas Eve, 1223 A.D. He turned a nearby cave into a stable, erected a manger and held a service. The French creche or manger scene is put up in the home and gifts are exchanged on January 6th. Young people dressed as shepherds and shepherdesses go to midnight mass at church carrying drums and pipes and torches to find their way. The French carol, ""Bring a Torch Jeanette-Isabella"" is a lyrical illustration of this custom.\nGalette des Rois\nThis marzipan-filled puff pastry is a favorite Twelve Nights treat in Paris, northern France and Belgium. It is usually decorated with a golden paper crown like this. You can prepare this cake ahead of time, refrigerate, then bake it just before serving.\nThaw puff pastry in the refrigerator overnight. Take the puff pastry out of the fridge and let it warm up to room temperature before using it. Pre-heat the oven to 450° F. Roll each sheet of the pastry to 10"" (if necessary) and cut off the corners to form a 10"" circle. Butter a medium size pizza pan or a cookie sheet and lay one circle of puff pastry on it. Cream the butter and one egg in a bowl. Add the marzipan and mix them thoroughly. Roll or pat marzipan paste into a circle. Lay the paste on the pastry base, leaving two finger widths all round. Bury one or more beans or charms in the paste.\nLay the second circle of puff pastry on a work surface and decorate by slitting the top layers with the point of a sharp knife. Beat the other egg in a small bowl. Brush the beaten egg on the edge of the pastry around the marzipan. Place the other decorated puff pastry circle on top, gently pressing down the edges to seal them. Brush egg over the top layer. Place the cake in the pre-heated oven and bake for 25 to 30 minutes. When the pastry is all puffed up and the glaze is golden brown, remove from the oven and allow to cool 10 minutes. Best if served warm, but it can also be eaten cold. Place a gold paper crown on top before serving and crown the ""King of Festivities"" when the bean is found. (Serves 6-8)\nOrange Epiphany Cake (or Goddess Cake)\nThis cake comes from the British Isles and uses fresh oranges, imported from the Mediterranean this time of year. Decorate the cake with candy to make it look like a jeweled crown for the Three Kings or, in homage to goddess traditions, bake the cake with a hole in the middle and decorate with fruit slices. Either way, you can hide a bean and a dried pea in the cake batter before baking. When it is eaten, the person who finds the bean is the King of Fools and the one who finds the pea is the Queen, regardless of the gender of the finder!\nPowdered Sugar Glaze\nCream the butter and sugar and add the eggs one at a time until well mixed. Mix in grated orange peel and orange juice. Fold self-rising flour into the batter. Pour into a 9"" buttered round springform, angle food cake, or in a bundt cake pan. Bake at 350° F for 55 minutes or until it is browned and pulling away from the edges. Turn out of the pan and poke holes in the top with a fork. Drizzle the Triple Sec liqueur over the top (optional). When completely cool, decorate with sugar glaze, gum drops, candied fruit or orange slices. (Serves 8-12)\nIf you want to add this article to your list of favorites or email it to a friend, please use this permanent URL, http://stores.renstore.com/-strse-template/0601A/Page.bok. Permission is granted by the author to quote from this page or use it in handouts as long as you include a link back to Renstore.com.\n|Previous Article||Next Article|']"	['<urn:uuid:3ef62bde-8085-4fd8-8ab9-cee52273f3ec>', '<urn:uuid:5db45943-dc58-43d0-b8c1-acb8e8705e0e>']	factoid	with-premise	concise-and-natural	similar-to-document	comparison	expert	2025-05-01T22:47:46.423955	11	24	2295
105	What are BMD test applications and who should get screened?	BMD tests measure bone strength and predict fracture risk by measuring mineral content in spine, femur or forearm. Screening is recommended for women over 65, men over 70, and younger adults with risk factors like chronic rheumatoid arthritis, early menopause, corticosteroid use, or strong family history of osteoporosis.	"['Bone Mineral Density tests are quick, painless tests that can measure bone strength and predict fracture risk. Bone Mineral Density is an accurate way to measure the mineral content and density of a patient’s bones. Our technologist is able to take measurements of the spine, femur or forearm. The length of the examination varies, depending upon what part of the body is examined. A bone mineral density test is one of the more accurate ways to diagnose osteoporosis in its early stages and to monitor any changes.\nPatient Instructions: Recommended for patient to wear comfortable clothes with no metal zippers, buttons or buckles.\nGeneral Radiology is a term used to describe basic x-ray procedures. Many x-ray procedures require no preparation and can be done at any time during our office hours. Patients may walk in for these studies without an appointment.\nExamination of the body with ultrasound. There is no radiation involved. No dye or intravenous contrast media is required. There are no known biological effects. Similar to sonar, sound waves are transmitted into the body with a transducer that can send and receive sound signals. When the sound waves are received a picture is formed by the computer using the information.\nArterial Doppler with Segmental Pressures is a valuable tool for accessing the blood supply to the lower extremeties in patients who have claudication. Claudication is reproducible pain or cramping with exercise that is relieved with rest. Doppler waveforms are obtained and blood pressures at different levels of the legs are measured and compared to the blood pressure in the arm. Precautions: None. Patient Instructions: There is no patient preparation for the exam.\nPeripheral Vascular and Carotid Doppler are used to examine disease inside the lumen of the blood vessels. Not only are images made of the vessels themselves, but blood flow direction as well as speed can be detected and measured. Precautions: None.\nNerve conduction velocity (NCV) is a test of the speed of conduction of impulses through a nerve. The nerve is stimulated, usually with surface electrodes, which are patch-like electrodes (similar to those used for ECG) placed on the skin over the nerve at various locations. One electrode stimulates the nerve with a very mild electrical impulse. The resulting electrical activity is recorded by the other electrodes. The distance between electrodes and the time it takes for electrical impulses to travel between electrodes are used to calculate the nerve conduction velocity.\nAfter showering on the day of your examination, do not use any creams, moisturizers or powders on your skin. If you have any bleeding disorders, let the examining physician know prior to testing. If you take blood thinners, even any aspirin or aspirin like medications let the examining physician know. You may be asked to stop blood thinners and aspirin products prior to your examination.\nIf you have a pacemaker or other devices that are implanted in your body to deliver medications, let the examining physician know. Any history of back or neck surgery should be discussed with the examining physician, as the examination may need to be modified. Also, any recent fevers or chills may indicate current bodily infection and should be mentioned to the examining physician.\nElectrocardiography (EKG, ECG) measures your heart’s electrical signal as it triggers each of your four heart chambers to pump (contract). Small pads (electrodes) attached to the surface of your skin detect the electrical signals. The electrodes are attached with wires to a machine that draws a graph of the electrical signals.\nA comprehensive measurement of your heart’s signals requires 6 electrodes on your chest and 4 distributed across your arms and legs. Each electrode measures your heart’s electrical activity from a different angle, which the EKG machine displays as 12 separate readings. Your doctor gets the equivalent of a three-dimensional perspective of your heart’s electrical function from these readings.\nThe different “waves” on the EKG graph show the signal triggering different parts of your heartbeat. By looking at these EKG waves, your doctor can detect problems with your heart’s rhythm. An EKG can also show evidence of other problems with your heart.\nWe have on-site testing laboratory and we also use the services of', ': Facilities : Bone Mineral\nA bone mineral density (BMD) test measures how much calcium and other types of minerals are present in a section of your bone. Your health care provider uses this test, along with other risk factors, to predict your risk of bone fractures in the future. Bone fracture risk is highest in people with osteoporosis.\nHow the test is performed\nSeveral different kinds of machines can do BMD testing. The most common method, called a DEXA scan, uses low-dose x-rays (about 1/10th the radiation dose of a chest x-ray).\nWhile you are lying on a cushioned table, a scanner passes over your body. Typically, the machine takes x-rays of your lower spine and hip. This is called a central DEXA scan. In most cases you won\'t need to undress.\nThere are smaller machines that just measure the bone density in your wrist, fingers, leg, or heel. You may find these in pharmacies, shopping centers, and health fairs. However, a central DEXA scan that measures bone density in your lower spine or hip is the best test to predict your risk of fractures.\nHow to prepare for the test\nRemove any jewelry before the BMD test. Inform your health care provider if you may be pregnant.\nHow the test will feel\nThe scan is painless, although you will need to remain still during the test.\nWhy the test is performed\nGuidelines recommend screening for those who are thought to be at increased risk for osteoporosis:\n- Women over age 65 and men over age 70\n- Women under age 65 and men ages 50 - 70 who have risk factors such as:\n- A fracture in any man or woman over age 50\n- Chronic rheumatoid arthritis, chronic kidney disease, eating disorders\n- Early menopause (either from natural causes or surgery)\n- History of hormone treatment for prostate cancer or breast cancer\n- Significant loss of height (See: Compression fractures of the back)\n- Strong family history of osteoporosis\n- Taking corticosteroid medications (prednisone, methylprednisolone) every day for more than 3 months\n- Three or more drinks of alcohol per day on most days\nIf you are being treated for osteoporosis, BMD testing can help your health care provider monitor your response to the treatment.\nFrom this score, you and your doctor can determine whether you might need medication to treat the osteoporosis.\nThe results of your test are usually reported as a ""T score"" and ""Z score.""\n- The T score compares your bone density with that of healthy young women\n- The Z score compares your bone density with that of other people of your\nage, gender, and race\nIn either score, a negative number means you have thinner bones than the standard. The more negative the number, the higher your risk of a bone fracture.\nA T score is within the normal range if it is -1.0 or above.\nWhat abnormal results mean\nBone mineral density testing does not diagnose fractures. However, along with other risk factors you may have, it helps predict your risk of having a bone fracture in the future. Your doctor will help you understand the results.\n- A T score between -1 and -2.5 indicates the beginning of bone loss (osteopenia)\n- A T score below -2.5 indicates osteoporosis\nBMD testing involves exposure to a low level of radiation. Most experts feel that the risk is very low compared with the benefits of identifying osteoporosis before you break a bone.\nBMD test, Bone density test, Bone densitometry, DEXA scan, DXA, Dual-energy x-ray absorptiometry.']"	['<urn:uuid:1931648e-f018-496a-bee3-6fd19aef26ba>', '<urn:uuid:8ba32ea5-c15d-408c-bdc8-d989990c5bdd>']	factoid	direct	concise-and-natural	distant-from-document	multi-aspect	expert	2025-05-01T22:05:01.292488	10	48	1291
106	health benefits head covering brain function explained	Wearing a turban has scientific benefits. It helps stabilize cerebral matter and the 26 parts of the brain connected to the neurological system and electromagnetic field. When 5 to 7 layers of cloth cover the temples, it prevents movement in different parts of the skull, providing cranial self-adjustment. The head covering also puts the sixth center (agia chakra) at one's command and creates a focus of the brain hemispheres' functional circuit.	"['When France recently announced that it would not overturn its ban on the Sikh turban for Sikh people living in the country, Sikh people in New Delhi held placards outside the French Embassy to protest the move. This was a natural reaction, considering the significance of a turban to followers of the Sikh faith.\nWhile the French government has clarified that the ban on religious symbols in schools is not Sikh-specific, and no student of any religion can wear a religious symbol to school, be it the Jews, the Muslims or the Catholics. The Catholics, despite constituting 75% of France\'s population, cannot openly wear a cross to school, apparently. But the country fails to appreciate that for a Sikh, it is much more difficult to hide his turban. The French government also clarified that the ban was only valid for schools and Sikhs were free to wear turbans on the streets, unlike the burqa, which is banned on the streets.\nSikhism and the turban\nGuru Gobind Singh advised every Sikh to carry a sword, take up the name Singh, and have his kesh (hair) and turban displayed boldly, without any fear, as expected of an aristocratic warrior, in contrast to a common peasant.\nAgainst this background, the turban is seen as a celebration of that psychological upliftment of a humble human being who had offered his services to Waheguru.\nSpiritual thoughts on a turban\nFurther, there are spiritual thoughts associated with a turban. As a Sikh ties each layer around his head, he is said to wind in his own consciousness, his own commitment, his own identity. Another person looking at a Sikh just gives one glance and understands that you are someone to reckon with. Merely tying a turban and having hair on your head does not make one a Sikh. A turban also makes a Sikh deathless in the face of a direct confrontation with death.\nThe science of a turban\nThere\'s even a scientific reason behind the wearing of a turban. Wearing a head covering is believed to put one\'s sixth center, the agia chakra, at one\'s command. Covering one\'s head is said to stabilise one\'s cerebral matter and the 26 parts of the brain, which are interlocked with the neurological system and electromagnetic field. Covering one\'s head creates a focus of the functional circuit of the hemispheres of the brain, and tunes the neurological system. A turban is to be worn such that the whole head is covered, not just the crown chakra. The benefit of wearing a turban is that when you wrap the 5 to 7 layers of cloth, you cover the temples, which prevents any variance or movement in the different parts of the skull. A turban automatically gives you a cranial self-adjustment.\nBefore France, its neighbouring country, the UK, too had something to say on the wearing of a turban by its huge Sikh population. These were the do\'s and don\'ts by that country:\n1. For Sikh people employed at construction site: Where employees or potential employees have particular cultural and religious needs which conflict with existing work requirements, it is recommended that employers should consider whether it is reasonably practical to vary or adapt these requirements to enable these needs to be met. For example, it is recommended that they should not refuse employment to a turbaned Sikh because he could not comply with unjustifiable uniform requirements.\n2. S11 of the Employment Act 1989 exempts turban-wearing Sikhs from any requirements to wear safety helmets on a construction site. Where a turban-wearing Sikh is injured on a construction site, liability for injuries is restricted to the injuries that would have been sustained if the Sikh had been wearing a safety helmet.\n3. Riding Motor Cycles: Sikhs who wear turbans need not wear crash helmets when they ride motor-cycles or scooters. They have been allowed to wear the turban as their only headgear. In accordance with the Motor-Cycle Crash Helmets (Religious Exemption) Act 1976 passed by the British Parliament in 1976, Section 2A ""exempts any follower of the Sikh religion while he is wearing a turban"", from having to wear a crash helmet.']"	['<urn:uuid:2dfab2ad-cbb9-431e-8a33-85f0e919e962>']	factoid	with-premise	long-search-query	distant-from-document	single-doc	novice	2025-05-01T22:05:01.292488	7	71	690
109	unit m building g phases construction white monastery	Building G in unit M underwent four distinct building phases. The first phase involved the construction of a boundary wall that suffered fire damage. The second phase saw the building's construction and its use for limestone chip production. The third phase included wall repairs, basement construction, floor resurfacing, and storage jar installation, followed by burning. The fourth phase involved reusing burned bricks to resurface the floor and reconstruct the superstructure.	['Area 3: The White Monastery Project\nArea 3 is located to the south and southwest of the White Monastery church. Since the renewal of Dayr al-Anba Shenouda in the 1980s, the archaeology of this area has been under intensified threat due to several human-related factors: regular vehicle traffic (including cars, buses, farm equipment, bicycles, etc.), the construction of new monastic buildings (including a modern toilet facility for visitors), and patterns of visitation by thousands of pilgrims each year (including the pitching of tents during the saint’s feast day). Accordingly, our work in this area has been negatively affected by modern intrusion on the ancient remains.\nUnits E and F\nIn the first season of work (2005), two test trenches were dug at the far southeast end of the site (units E and F). Area supervisor, Louise Blanke, encountered problems in both units. In the case of unit E, the excavation was halted when the monks of the monastery identified the location as part of a modern burial ground. In the case of Unit F, the mixed yield of late Roman pottery and modern artifacts revealed the location of an ancient pottery dump that had been bulldozed in modern times. As a result, these test trenches could not be used as a basis for subsequent work.\nUnits M and P\nIn subsequent seasons, however, our team received permission to work in locations previously excavated by the SCA. In the 1980s and 1990s, the SCA had conducted excavations in two different area 3 locations. These locations were labeled units M and P. Unit P is located immediately to the south of the main church (adjacent to the southwest corner), and it contains architectural elements that probably belonged to an industrial area. Unit M is located further to the southwest, between the church and the modern guest facilities of the monastery.\nFrom December 2006 to January 2007, our team took on the task of documenting, photographing, and surveying the exposed mud-brick architecture in unit M. Seven different buildings (A–G) were identified and analyzed archaeologically. Each of the structures had undergone two or three phases of renovation or reconstruction, often with multiple strata or sub-phases in evidence. For example, building A (at the southeasternmost corner of the unit) was modified in three phases, with nine separate strata identified. The final phase included the digging of a monk’s grave to the east of the building (Figure 1).\nThe history of building G is equally complex, featuring four building phases with eight separate strata. Located at the northwestern corner of unit M, it is in fact one of several architectural structures built against a major wall running north-south at the western end of the unit (Figure 2).\nFigure 1 (left): Monk’s grave discovered in the final phase of building A. Figure 2: Architectural remains of building G, with the remains of the boundary wall in the background.\nThis wall may have been a western boundary wall for the monastery, as no archaeological features have yet been identified further west of it. Parts of the wall were damaged by an episode of burning, and it was subsequently repaired on its eastern side with mud bricks and three buttresses. The construction of this boundary wall and the episode of burning together represented the first phase related to the history of the building and its environs. The second phase involved the building’s construction and use as an area for the production of limestone chips. Such chips were typically laid down as a foundation layer in the construction of buildings at the monastery. The third phase consisted of four separate strata, including the repair of the boundary wall, the construction of a basement, the resurfacing of the floor, and the insertion of a large storage jar into the basement. This third phase was followed by an episode of burning. Phase four involved the use of the older burned bricks to resurface the floor again and to reconstruct the building’s superstructure.\nThe ceramic finds in building G and throughout unit M again primarily date to the late Roman and early Islamic periods (5–8th centuries). However, some later Islamic sherds (10–16th centuries) were also documented. Their presence either indicates continuous use over an extended period or a later stage of modification and reuse.\nThe documentation of area 3 units previously excavated by the SCA is an ongoing responsibility of the Yale Monastic Archaeology Project. Accordingly, in October and November of 2008, part of our work also entailed the surveying of unit P, immediately to the south of the church (Figure 3). This unit includes large circular stone basins to the east and a series of at least six rectangular tanks to the south (Figure 4).\nFigure 3 (left): Plan of unit P. Figure 4: Photo of rectangular tanks in unit P.']	['<urn:uuid:c379e558-7554-4ce2-87af-75c21a59e8b6>']	open-ended	direct	short-search-query	similar-to-document	single-doc	expert	2025-05-01T22:05:01.292488	8	70	799
110	How do chia seeds help with weight loss and what makes them such an effective food for controlling appetite?	Chia seeds help with weight loss through several mechanisms. They have a unique hydrophilic property that allows them to absorb more than 12 times their weight in water, making people feel fuller after consumption. Their high fiber content promotes gradual digestion, which prevents untimely food intake. Additionally, when consumed, the seeds create a gel-like effect that separates carbohydrates from digestive enzymes, preventing the creation of sugar from carbohydrates and reducing fat storage. Just one ounce of chia seeds in daily meals can contribute to successful weight loss.	['Chia seeds are traditional herbs of Mexico and the US. For the Native Americans, legendary myths have reiterated the usage of this herb in the age of the Aztecs, Mayans and Incans. A member of the sage family Salvia Hispanica, the seeds of this plant was used as a staple food crop and was also used to prepare nutritious juices. The word ‘Chia’ in the Mayan language stands for strength and this food source was used mainly by the messengers who travelled large distances carrying a small packet of this energy source stored during the journey. It is also known as the ‘Indian running Food’ by many.\nThe tiny black and white seeds of Chia are rich in omega-3 fatty acids. They are the potent source of carbohydrates, fibre, protein, numerous vitamins like A, B, E, and D, and several minerals such as calcium, magnesium, phosphorus, potassium, iron, sulphur, iodine, zinc, copper, sodium, manganese, niacin, silicon, thiamine and antioxidants. One ounce of Chia seeds is proven to have 137 calories, 11 grams of fibre, 4 grams of protein, 12 grams of carbohydrate, 9 grams of fat and multiple other vitamins and minerals. Moreover, it is free of sugar which makes it even more delectable for fitness freaks. The advantageous part of consuming Chia seeds is that, it needs no processing unlike many and has a tasty flavour like nuts. The easiest and most popular way of consuming it is by mixing with water and gulping it down. It can help one to avoid food cravings for a long time and sustain the body energy at the same time.\nChia seeds have become popular gradually although, it is not yet much visible in the European consumerist market. Several recipes have also come up to use it in different dishes. It is even recommended to have at least a teaspoon of Chia seeds right before starting with the day. To start a good, zestful, energetic morning a spoonful of Chia with enough water to drink can boost your spirit up and help you retain energy through the odds of the day for a longer stretch.\nChia seeds are most commonly added to beverages and also used as garnishing ingredient over cooked vegetables, salads, cereals and other baked products. As a good substitute to food, chia seeds can work as the powerhouse of energy and prevent one from excess calorie intake. An ounce of Chia seeds in the whole day meal chart can work wondrous and cause weight loss successfully. It becomes even better a weight loss food due to its rich fibre content as well. Almost half the fibre value required from food intake in a single serving is provided by Chia seeds.\nThe essential fatty acids in these seeds are extremely necessary for our bodies to build up the multiple cells that are in constant constructive mode throughout the body . It regenerates good hair and skin and protects the heart.\nCalcium an essential nutrient for human beings is an unavoidable source for our survival. Right from birth our mother’s milk becomes the sole source of the calcium we need. Without calcium our entire skeletal structure would become fragile and porous. Malnutrition, a serious issue across the world has attacked millions of individuals who are deprived of the basic nutrition and women are the prime victims of this attack. Osteoporosis, a major issue with bones is more common for those without proper calcium nutrition. Chia seeds have more than 3 times the source of calcium than found in skimmed milk.\nThe reason Chia seeds makes one feel heavier with every time of consumption is because the seeds have the unique capability to trap moisture every time they are exposed to any kind of liquid. As a result of this, they can trap the water content inside their shell which makes them slippery from outside. The hydrophilic property of the seeds helps to absorb more than 12 times of water than its actual weight. When we consume it, the water inside each seed makes the actual quantity of the seeds more than what it is and we feel fuller. Moreover, a food that can help in good digestion is always pro weight loss program. The gel like effect of these seeds helps to segregate the carbohydrate from the digestive enzymes which in turn prevents the creation of sugar from the carbohydrate. Thus, the fat storage in the wrong body sections is prevented. The rich fibre content in the seeds helps in gradual digestion which keeps us away from untimely food intakes.\nJust like Garcinia Cambogia, it balances the blood sugar level in the body. While the seeds of chia substitute the food intake, Garcninia Cambogia does not work as a meal substitute. It rather stirs the secretion of serotonin level in our body that regulates our food cravings and moods from time to time.\nChia seeds also restore the omega- 3 fatty acids that yet again balance energy without much food consumption in real. Omega-3 is also good for improving digestion, and relieving few kinds of arthritis pain. Metabolism is the key to weight loss. Any food source that stimulates good metabolism should be encouraged, although few have their own lists of side effects as well.\nThere has been no serious negative consequence recorded from the use of Chia. Yet, in case of any doubt it is preferable to get a doctor’s advice before using it. In the recent time, it is used mainly by athletes to keep them strong and sturdy and fat free. Several pharmaceutical companies have gradually popularised the use of this product but it needs to be promoted more across the world. This natural multi nutrient food can save many malnourished sections of the society. It needs to be cultivated on larger scaled with mass production.\nNot only is it a good egg substitute or milk substitute, it is used in mainly preparing puddings, soups, salads, yoghurts and even making meatballs with bread crumbs. Its thickening agent is good for preparing many dishes. A little smash of lemon juice with chia seeds is a wonderful drink to gulp down during the strenuous hours of the day. Many find it better than flax seeds that need more care before consuming. It needs processing and then powdering which altogether is a time consuming process.\nChia seeds are a great way to start a day but it should not be forgotten that such supplements work better when we control our mind to eat more nutritiously along with these products and maintain a hygienic and healthy living.']	['<urn:uuid:20af008f-733a-487c-bbf4-b5dc10ff29a9>']	open-ended	direct	verbose-and-natural	similar-to-document	single-doc	novice	2025-05-01T22:05:01.292488	19	87	1095
111	cost most expensive artwork crystal bridges purchase	The most expensive artwork purchased by Crystal Bridges Museum was Edward Hopper's 'Blackwell's Island', which was acquired on May 23, 2013 for $19.1638 million at auction.	"['Crystal Bridges Museum of American Art\n|Crystal Bridges Museum of American Art|\nView across the upper pond to one of the museum\'s\nnamesake bridge pavilions\n|Established||11 November 2011|\n|Location||600 Museum Way\n|Nearest car park||Garage and surface lot on site (no charge)|\nCrystal Bridges Museum of American Art is a museum of American art in Bentonville, Arkansas. The museum, founded by Alice Walton and designed by Moshe Safdie, officially opened on 11 November 2011. It offers free public admission.\nOverview and founding\nAlice Walton, the daughter of Walmart founder Sam Walton, spearheaded the Walton Family Foundation\'s involvement in developing Crystal Bridges. The museum\'s glass-and-wood design by architect Moshe Safdie (Boston, MA) and engineer Buro Happold (New York, NY) features a series of pavilions nestled around two creek-fed ponds. The complex, constructed by a joint venture of Linbeck Group (Houston, TX) and Nabholz Construction (Conway, Arkansas), includes 217,000 square feet (20,200 m2) of galleries, several meeting and classroom spaces, a library, a sculpture garden, a gift shop designed by architect Marlon Blackwell, a full service restaurant and coffee bar, named the Eleven after the day the museum opened ""11/11/11"". Crystal Bridges also features a gathering space that can accommodate up to 300 people. Additionally, there are outdoor areas for concerts and public events, as well as extensive nature trails. It employs approximately 160 people, and is within walking distance of downtown Bentonville.\nThe museum has amassed $488 million in assets as of August 2008, an amount that will increase as more pieces are continually added to the museum\'s collection. It is the first major art museum (over $200 million endowment) to open in the United States since 1974. Over $317 million of the project\'s cost has been donated by Alice Walton. A 2013 Forbes\' ranking of the world\'s richest people placed the Wal-Mart heiress at No. 16, with an estimated net worth of $26.3 billion.\nIn 2005, art historian John Wilmerding was hired for acquisition and advice on museum programming. Wilmerding commented that Alice Walton ""will not spend at any cost"" and will do her ""homework on almost every individual acquisition and will ask for paperwork on market comparables"". He stated that often when an artwork became available through a private sale Walton would state ‘Wait, it will come to auction where we can get it at a better price,’ and she was usually correct. He also stated that the museum ranks at least in the top half dozen of American art museums. The museum\'s ""quality and its range and depth already place it among one of the very best.""\nHeadlines were generated after delays in construction and considerably higher costs for the museum than originally proposed to the city of Bentonville, Arkansas led to concerns about the favorable tax exemptions granted to the museum from the state in 2005 to secure its construction. Total tax losses to the state of Arkansas and the city of Bentonville are estimated at $17 million based on the financial disclosures given by the museum in the 2008 court case with Fisk University. The total amount of tax loss is estimated to have become considerably higher since then, but may never be disclosed due to the museum\'s guarded financial practices, including its decision not to disclose the amount spent since 2008 to secure collections, major art pieces, and lesser known works. However, the museum\'s IRS Form 990-PF notes acquisitions of $43.6 million during 2008, $81.9 million during 2007, $97.3 million in 2006. Through 2008, the total art acquisitions were at least $222.8 million.\nDon Bacigalupi was appointed director of the museum in August 2009. Previously, Robert G. Workman had served as director. In early May 2011, the museum announced three endowments by the Walton Family Foundation totaling $800 million. These endowments were established for operating expenses, acquisitions and capital improvements. The operating endowment, totaling $350 million, is being used to contribute to the museum\'s base annual operating expenses expected to total between $16–20 million per year. The acquisition endowment, totaling $325 million, will be used to fund additions to the museum\'s permanent collection. The remaining $125 million will be used as a capital improvement endowment to fund future improvements to and maintenance of the museum.\nCollaboration with other museums and institutions\nIn the past few years, Crystal Bridges has been in the news for numerous arrangements and partnerships with other art museums to share collections.\nIn 2006, the museum partnered with the National Gallery of Art in an attempt to purchase Thomas Eakins\' The Gross Clinic from Thomas Jefferson University. Under the terms of the agreement, the two museums agreed to pay a record $68 million, but the university gave Philadelphia 45 days to match the offer. The Philadelphia Museum of Art and Pennsylvania Academy of Fine Arts agreed to collectively match the offer and the painting remained in Philadelphia. The purchase forced both museums to sell some of their best Eakins pieces including Cowboy Singing and the The Cello Player. In April 2007, Crystal Bridges acquired another Eakins belonging to Thomas Jefferson University entitled Portrait of Professor Benjamin H. Rand for an estimated $20 million\nWalton held talks with Randolph-Macon Woman’s College in Lynchburg, Virginia in spring of 2007. The college was exploring selling part of the Maier Museum of Art\'s collection, but voted instead to sell select items from the collection at Christie\'s.\nIn 2006, Fisk University agreed to sell a 50% stake in a 101 piece Stieglitz collection to Crystal Bridges for $30 million. The collection was donated to the university by Georgia O\'Keeffe in 1949. This agreement became tied up in a legal battle between Fisk and the Georgia O\'Keeffe Museum in New Mexico, but the museum withdrew its lawsuit. The Tennessee Attorney General attempted unsuccessfully to stop the sale. In October 2010, a judge ruled that a 50% stake in the collection could be sold to Crystal Bridges if modifications to the contract were made so that Fisk University could not lose its interest in the collection, nor could the joint venture holding ownership of the collection between Fisk University and Crystal Bridges be based in Delaware (or outside Tennessee Courts). The modified agreement would allow the works to stay at Fisk University until 2013 and then begin a two-year rotation with Crystal Bridges. In April 2012, the Tennessee Supreme Court upheld a lower court decision to allow the sale to move forward. A few months later on 2 August, The Davidson County Chancery Court approval a Final Agreed Order that establish joint ownership between Fisk and Crystal Bridges through the newly established Stieglitz Art Collection, LLC. The operating agreement required Fisk to set aside $3.9 million of the $30 million sale proceeds to be used to establish a fund for the care and maintenance of the collection at the Carl Van Vechten Gallery at Fisk. The court dispute cost Fisk $5.8 million in legal fees.\nCrystal Bridges has announced a four-year collaboration with the musée du Louvre in Paris, High Museum of Art in Atlanta, and the Terra Foundation for American Art. The resulting exhibitions, featuring works from the collections of all four partners, will be seen in Paris, Bentonville, and Atlanta, beginning in 2012.\nThe museum\'s permanent collection features American art from the Colonial era to contemporary work. All of the featured artists are United States citizens, though some spent most of their art careers in Europe. Notable works include a Charles Willson Peale portrait of George Washington as well as paintings by George Bellows, Jasper Cropsey, Asher Durand, Thomas Eakins, Marsden Hartley, Winslow Homer, Eastman Johnson, Charles Bird King, John LaFarge, Stuart Davis, Romare Bearden, Norman Rockwell, Mary McCleary, Agnes Pelton, and Walton Ford. Also included are works by Chuck Close, Jasper Johns, Alfred Maurer, Jackson Pollock and Tom Wesselman. Two works, Richard Caton Woodville\'s War News from Mexico and Arthur Fitzwilliam Tait\'s The Life of a Hunter: A Tight Fix were included in American Stories: Paintings of Everyday Life, 1765–1915, a traveling exhibition organized by the Metropolitan Museum of Art. The Woodville painting was deaccessioned by the National Academy of Design, and was purchased in 1994 by Detroit collector Richard Manoogian. The piece was later purchased in 2004 by Crystal Bridges.\nIn May 2005, the museum purchased a coveted Asher B. Durand landscape entitled Kindred Spirits from the New York Public Library for more than $35 million in a sealed auction. In September 2012, the museum announced the acquisition of a major 1960 painting by Mark Rothko entitled No. 210/No. 211 (Orange). The abstract expressionist painting had been in a private Swiss collection since the 1960s and had only been shown in public twice.\nSculpture also figures prominently in the collection, on view in interior galleries and along outdoor sculpture trails. Sculptors represented in the permanent collection include Paul Manship, Roxy Paine, Mark di Suvero, and James Turrell.\nSelect auction results by date for items in the collection (including buyer\'s premium) are:\n- Green River, Wyoming by Thomas Moran, purchased 5 December 2002 for $2.9245 million\n- George Washington by Charles Willson Peale, purchased 18 May 2004 for $6.1675 million\n- Robert Louis Stevenson and his wife by John Singer Sargent, purchased 19 May 2004 for $8.8 million\n- Orca Bates by Jamie Wyeth, purchased 19 May 2004 for $360,000.\n- Portrait of Anne Page by Dennis Miller Bunker, purchased 1 December 2004 for $3.592 million\n- A French Music Hall by Everett Shinn, purchased 1 December 2004 for $7.848 million\n- The Indian and the Lily by George de Forest Brush, purchased 1 December 2004 for $4.824 million\n- The Studio by George Bellows, purchased 1 December 2004 for $2.472 million\n- Spring by Winslow Homer, purchased 1 December 2004 for $2.024 million\n- Ottoe Half Chief, Husband of Eagle of Delight by Charles Bird King, purchased 1 December 2004 for $1.352 million\n- Wai-Kee-Chai, Sanky Chief, Crouching Eagle by Charles Bird King, purchased 1 December 2004 for $792,000\n- Portrait of Carolus Duran by John Singer Sargent, purchased 2 December 2004 for $724,300\n- Sick Puppy by Norman Rockwell, purchased 2 December 2004 for $511,500\n- George Washington (The Constable-Hamilton Portrait) by Gilbert Stuart, purchased 30 November 2005 for $8.136 million\n- Mrs. Theodore Atkinson, Jr. by John Singleton Copley, purchased 30 November 2005 for $3.376 million\n- Marquis de Lafayette by Samuel F. B. Morse, purchased 30 November 2005 for $1.36 million\n- Winter Scene in Brooklyn by Francis Guy, purchased 30 November 2005 for $1.024 million\n- Rose Garden by Maria Oakey Dewing, purchased 24 May 2006 for $2.032 million\n- The Lantern Bearers by Maxfield Parrish, purchased 25 May 2006 for $4.272 million\n- Dr. William Smith by Gilbert Stuart, purchased 23 May 2007 for $1.888 million\n- Still Life with Stretcher, Mirror, Bowl of Fruit by Roy Lichtenstein, purchased 20 June 2007 for £4.052 million (US$8.055 million - based on 20 June 2007 exchange rates)\n- Homage to the Square: Joy by Josef Albers, purchased 14 November 2007 for $1.497 million\n- View of Mount Edna by Thomas Cole, purchased 29 November 2007 for $541,000\n- Our Town by Kerry James Marshall, purchased 13 May 2009 for $782,500\n- Supine Woman by Wayne Thiebaud, purchased 12 November 2009 for $1.818 million\n- Portrait of a Girl and Her Dog in a Grape Arbor by Susan Catherine Moore Waters purchased 7 March 2010 for $41,475\n- Portrait of Martha Graham by Marisol Escobar, purchased 13 May 2010 for $116,500\n- Dolly Parton by Andy Warhol, purchased 14 May 2010 for $914,500\n- Standing Explosion (Red) by Roy Lichtenstein, purchased 14 May 2010 for $722,500\n- The Return of the Gleaner by Winslow Homer, purchased 19 May 2010 for $2.2105 million\n- Trinity by Adolph Gottlieb, purchased 11 May 2011 for $1.1425 million\n- Hammer and Sickle by Andy Warhol, purchase 13 November 2012 for $3.4425 million\n- Untitled, 1989 (Bernstein 89 24) by Donald Judd, purchased 14 November 2012 for $10.1625 million\n- Blackwell\'s Island by Edward Hopper, purchased 23 May 2013 for $19.1638 million \nSelected works in the museum collection by chronologic order\nPortrait of George Washington (The Constable-Hamilton Portrait, 1797) by Gilbert Stuart\nCupid and Psyche (1808) by Benjamin West\nWinter Scene in Brooklyn (c.1817-1820) by Francis Guy\nView of Mount Edna (1843–44) by Thomas Cole\nWar News from Mexico (1848) by Richard Caton Woodville\nThe Good Shepherd (1848) by Thomas Cole\nKindred Spirits (1849) by Asher B. Durand\nPortrait of Professor Benjamin Rand (1874) by Thomas Eakins\nThe Reader (1877) by Mary Cassatt\nGreen River, Wyoming (1878) by Thomas Moran\nRobert Louis Stevenson and His Wife (1885) by John Singer Sargent\nThe Art Student: Portrait of James Wright (circa 1890) by Thomas Eakins\nWorld\'s Columbian Exposition (1894) by Theodore Robinson\nThe Lantern Bearers (1908) by Maxfield Parrish\nExcavation at Night (1908) by George Bellows\n- Christopher Spencer (18 November 2010), Crystal Bridges in Bentonville to open 11.11.11\n- ""Top Ten Most Expensive Projects Worth $369.5 Million"". The Northwest Arkansas Morning News. 1 January 2006.\n- Luisa Kroll and Kerry A. Dolon (4 March 2013). ""The World\'s Billionaires, The Richest People On The Planet 2013"". Forbes Online.\n- Carol Vogel (14 May 2005). ""A Determined Heiress Plots An Art Collection"". The New York Times.\n- Jan Cottingham (12 July 2010), ""Crystal Bridges Collection Turns Toward The Modern"", Arkansas Business\n- Carol Vogel (16 June 2011). ""A Billionaire’s Eye for Art Shapes Her Singular Museum"". The New York Times.\n- Evie Blad (8 March 2010). ""Taxes lost on museum unclear Crystal Bridges exemptions will pay off, officials say"". Arkansas Democrat-Gazette (Little Rock).\n- Randy Kennedy (17 August 2009). ""Crystal Bridges Museum of American Art in Arkansas Names a New Director"". The New York Times.\n- Press release, ""Robert G. Workman named Executive Director"", 2 February 2006\n- http://www.crystalbridges.org/about/News/News-Details?id=22d24e55-ee4c-4460-a503-fa079b7517de%7CCrystal Bridges Museum of American Art Announces Endowment Gifts from Walton Family Foundation retrieved 2 July 2011\n- Vogel, Carol (24 April 2008), Philadelphia Raises Enough Money to Retain a Masterpiece by Eakins, The New York Times, retrieved 20 September 2010\n- Vogel, Carol (12 April 2007), Philadelphia School Sells a Second Eakins, The New York Times, retrieved 24 September 2010\n- Vogel, Carol (2 October 2007), A Southern College to Sell Prized Paintings, The New York Times, retrieved 25 September 2010\n- Kennedy, Randy (11 October 2010), Fisk University in New Bid to Gain Approval to Sell Art, The New York Times, retrieved 12 October 2010\n- Pogrebin, Robin (3 August 2012), Legal Battle Over Fisk University Art Collection Ends, The New York Times, retrieved 5 August 2012\n- Allyn, Bobby (4 August 2012), Fisk finalizes deal to sell half-stake of Alfred Stieglitz collection in end to long fight, half-stake sold to Arkansas museum, The Tennessean, retrieved 5 August 2012\n- Mead, Rebecca (27 June 2011), Alice\'s Wonderland: A Walmart heiress build a museum in the Ozarks, New York: The New Yorker\n- The Metropolitan Museum of Art Web site, ""American Stories: Paintings of Everyday Life, 1765-1915\n- Vogel, Carol (14 May 2005), A Determined Heiress Plots an Art Collection, The New York Times, retrieved 25 September 2010\n- Dobrzynski, Judith H. (22 September 2012), A Rothko Fills a Museum\'s Breach, The Wall Street Journal, retrieved 27 September 2012\n- http://www.christies.com/LotFinder/lot_details.aspx?from=searchresults&intObjectID=4013516&sid=b49235b2-21df-4531-ae47-86d15cf92259 retrieved 30 December 2011\n- http://www.christies.com/LotFinder/lot_details.aspx?from=searchresults&intObjectID=4277849&sid=b52808ee-606d-4692-8170-fa101166be70 retrieved 25 September 2010\n- http://www.sothebys.com/app/live/lot/LotDetail.jsp?lot_id=47V7W retrieved 24 September 2010\n- http://www.sothebys.com/en/search.html#keywords=orca%20bates retrieved 17 April 2012\n- http://www.sothebys.com/app/live/lot/LotDetail.jsp?lot_id=4C258 retrieved 24 September 2010\n- http://www.sothebys.com/app/live/lot/LotDetail.jsp?lot_id=4BZYC retrieved 18 November 2010\n- http://www.sothebys.com/app/live/lot/LotDetail.jsp?lot_id=4C24B retrieved 24 September 2010\n- http://www.sothebys.com/app/live/lot/LotDetail.jsp?lot_id=4BZYQ retrieved 24 September 2010\n- http://www.sothebys.com/app/live/lot/LotDetail.jsp?lot_id=4BZY8 retrieved 23 September 2010\n- http://www.sothebys.com/app/live/lot/LotDetail.jsp?lot_id=4C24C retrieved 23 September 2010\n- http://www.sothebys.com/app/live/lot/LotDetail.jsp?lot_id=4C24D retrieved 23 September 2010\n- http://www.christies.com/LotFinder/lot_details.aspx?from=salesummary&intObjectID=4387864&sid=ccf27e2c-c25d-4fce-813b-377656e8afea retrieved 5 December 2010\n- http://www.christies.com/LotFinder/lot_details.aspx?from=searchresults&intObjectID=4387967&sid=223bdf9e-c213-4c00-b50f-eb1e971a08eb retrieved 5 December 2010\n- Parker, Suzi (11 July 2010), Galleries - Discount shopping and fine art? Suzi Parker on the latest offer from Wal-Mart, newstatesman.com, retrieved 6 December 2010\n- http://www.sothebys.com/app/live/lot/LotDetail.jsp?lot_id=4J5VV retrieved 24 September 2010\n- http://www.sothebys.com/app/live/lot/LotDetail.jsp?lot_id=4J5VX retrieved 23 September 2010\n- http://www.sothebys.com/app/live/lot/LotDetail.jsp?lot_id=4J5VS retrieved 23 September 2010\n- http://www.sothebys.com/app/live/lot/LotDetail.jsp?lot_id=4J5VT retrieved 23 September 2010\n- http://www.thecityreview.com/s06samp.html retrieved 17 April 2012\n- http://www.christies.com/LotFinder/lot_details.aspx?intObjectID=4715256 retrieved 23 September 2010\n- http://www.sothebys.com/en/auctions/ecatalogue/2007/american-paintings-n08322/lot.160.html retrieved 24 May 2014\n- http://www.christies.com/lotfinder/roy-lichtenstein-still-life-with-stretcher-mirror/4931754/lot/lot_details.aspx?from=searchresults&intObjectID=4931754&sid=ec36e9d3-f080-4c23-a64e-dcda425df088 retrieved 30 August 2011\n- http://www.sothebys.com/en/catalogues/ecatalogue.html/2007/contemporary-art-evening-n08363#/r=/en/ecat.fhtml.N08363.html+r.m=/en/ecat.lot.N08363.html/37/ retrieved 30 December 2011\n- http://www.christies.com/lotfinder/thomas-cole-view-of-mount-etna/5001291/lot/lot_details.aspx?from=searchresults&intObjectID=5001291&sid=dead3677-4f5d-4b6f-8f19-b3a98f7c67b1 retrieved 30 December 2011\n- http://www.christies.com/LotFinder/lot_details.aspx?intObjectID=5204578 retrieved 23 September 2010\n- http://www.sothebys.com/app/live/lot/LotDetail.jsp?lot_id=159565865 retrieved 23 September 2010\n- http://www.skinnerinc.com/asp/fullCatalogue.asp?salelot=2494+++++107+&refno=++842129 retrieved 23 September 2010\n- http://www.sothebys.com/app/live/lot/LotDetail.jsp?lot_id=159598888 retrieved 16 December 2010\n- http://www.sothebys.com/app/live/lot/LotDetail.jsp?lot_id=159594511 retrieved 23 September 2010\n- http://www.christies.com/LotFinder/lot_details.aspx?intObjectID=5315241 retrieved 23 September 2010\n- http://www.sothebys.com/en/catalogues/ecatalogue.html/2010/american-paintings-drawings-sculpture-n08641#/r=/en/ecat.fhtml.N08641.html+r.m=/en/ecat.lot.N08641.html/79/ retrieved 9 November 2011\n- http://www.sothebys.com/en/catalogues/ecatalogue.html/2011/contemporary-i-n08744#/r=/en/ecat.fhtml.N08744.html+r.m=/en/ecat.lot.N08744.html/35/ retrieved 20 June 2011\n- Peacock, Leslie Newell (17 June 2011), Eyes Candy, The Arkansas Times, retrieved 20 June 2011\n- http://www.sothebys.com/en/auctions/ecatalogue/2012/contemporary-art-evening-auction-n08900/lot.35.html retrieved 26 March 2013\n- Dobrzynski, Judith H. (21 March 2013), Crystal Bridges answers criticism with post-war acquisitions, The Art Newspaper, retrieved 26 March 2013\n- http://www.christies.com/lotfinder/sculptures-statues-figures/donald-judd-untitled-1989-5621968-details.aspx?from=searchresults&intObjectID=5621968&sid=c29a3e5c-30b9-49cf-b20f-de2161bf4275%7C retrieved 26 March 2013\n- http://www.christies.com/lotfinder/paintings/edward-hopper-blackwells-island-5683318-details.aspx%7C retrieved 29 September 2013\n- Crystal Bridges Museum of American Art website\n- Architectural Record, Crystal Bridges Museum of American Art, Safdie Architects, commentary, slide show, and drawings, January 2012\n- TimePhotos (Time magazine), Crystal Bridges Museum of American Art, photos, 21 November 2011\n- Bridges Acquires New Work by Walton Ford\n- \'A Billionaire’s Eye for Art Shapes Her Singular Museum\', Carol Vogel, The New York Times, 16 June 2011\n- Bentonville123 History and Photography Bentonville Arkansas history and photograph archive\n- American Art Artnews 1/12/2012']"	['<urn:uuid:778f56e8-b8f1-4118-84a9-971284bfc72c>']	open-ended	with-premise	short-search-query	distant-from-document	single-doc	expert	2025-05-01T22:05:01.292488	7	26	2886
116	Did both Kimetto and Kipchoge set their records in the same city?	No, they set their records in different cities. Dennis Kimetto set his record of 2:02:57 in Chicago, Illinois in 2014, while Eliud Kipchoge set his world record of 2:01:39 at the Berlin Marathon in 2018.	['No Products in the Cart\nIn 2014, at thirty years old, Dennis Kipruto Kimetto, (b. Jan 22, 1984) a long-distance runner from Kenya set the marathon record of 2:02:57 (two hours, two minutes and 57 seconds) in Chicago, Illinois. He was the first man to ever run under 2:03.\nHe held the record for four years. It was then broken by Eliud Kipchoge (b. Nov 5, 1984), another Kenyan long-distance runner. Kipchoge is now the world record holder in the marathon with a time of 2:01:39, which he set Sept. 16, 2018, at the 2018 Berlin Marathon.\nKipchoge also ran the marathon distance at a special event in Vienna, Austria, and achieved a time of 1:59:40. The run did not count as a new marathon record, however, because it was not an open event and the standard competition rules for pacing and fluids were not followed, but he did become the first person to ever run a marathon in less than two hours. (https://en.wikipedia.org/wiki/Dennis_Kipruto_Kimetto and https://en.wikipedia.org/wiki/Eliud_Kipchoge)\nWhen someone does the seemingly impossible, everyone’s interest is heightened and they, too, want to improve. For the most part, to run long distances it takes the right genetics along with having the correct limb lengths and, of course, at least 70 percent Type 1/slow twitch/slow oxidative muscle fibers, but you also must train efficiently.\nThe most efficient way to improve is to gain muscular endurance. At the end of a marathon it is the legs that give out, not the lungs. Most will incorrectly try to increase their VO2 max, but it cannot be increased by top athletes as it cannot be raised after 12 or 18 months in endurance runners. This leaves only one way and that is to raise muscular endurance by maximally training strength endurance.\nIf one simply runs a set distance at a set body weight at the same pace, then you are not increasing your work. You must become more powerful. For example, by becoming stronger you can deliver greater ground force that can reduce ground contact time. A study by Leema Paavolainen concluded that reduced ground contact time is the most important for faster running times no matter the distance.\nThe study on 5K racers who had an average stride length of two meters found they would use 2500 strides to cover a 5K. A one one-hundredth of a second reduction in ground contact time would reduce their 5K time by 25 seconds. More on this topic can be found in Underground Secrets to Faster Running by Barry Ross.\nWhy is increasing strength so important? This is a simple physics equation. First, let’s look at what is work. In physics, work is defined as the product of the net force and the displacement through which that force is exerted, or W=Fd.\nLet’s look at power. Power is defined as work done divided by the time used to do the work (P=wt). This simply says that the more powerful you are, the faster you can do the work; the work in this case being 60, 100, or 25,000 meters or even a marathon.\nIf you are just running and not strengthening your body you have most likely developed a speed barrier where you can no longer cover your distant faster. That’s the definition of the biological Law of Accommodation—that your body adapts to a constant continued stimulus by decreasing its response. So just by running you won’t eventually run faster. To break that speed barrier, you must train other activities such as special exercises for the running muscles—the calves, hamstrings, hips and glutes, and of course, some upper body work for strength and balance. Westside uses weight sleds to build running muscles.\nFor strength endurance training instead of doing the same amount of work with just body weight, the runner should use three weights on a weight sled that is connected to your body with a strap. This does not effect your running technique when using 15, 25 and 35 pounds.\nThrough experimentation Westside found that long-distance runners lack maximal strength. For instance, one long-distance runner could parallel box squat 65 pounds for 100 reps, but could only squat 100 pounds for one rep. By doing interval training with a weight sled with three different weights, strength endurance was built. Westside established 25, 35 and 45 pounds in a three-week wave will build strength endurance.\nBy doing interval training with a weight sled with three different weights to build strength endurance. But experimenting Westside has established 25, 35 and 45 pounds in a three-week wave will build strength endurance.\nFor races up to 10,000 meters one can pull a weight sled for 30 minutes or just over the world record for that length race. For the very fit, two trips can be performed. Time between trips will depend on your level of preparedness, meaning letting your heart rate get back to your normal range and then repeat. Pull the sled two times a week, but remember to cut your running back by at least 30 percent.\nA 16-ounce bottle holds 16 ounces and no more, so when you include weight sled work you have to cut your running back. We know it will be hard to change your thinking, but you must. Your total work capacity is just like that 16-ounce bottle. The bottle can only hold 16 ounces at one time, but it can be full of different substances. For 20,000 meters—a half marathon—do two trips for 30 minutes or four trips for the advanced, and then push for two trips of 45 minutes. Remember, if your pace starts to slow down, you should stop. The key is to maintain top speed for as long as you can. If you slow down you lose … period.\nIf you run a full marathon, start with four trips using the interval method, meaning powerwalk for 30 minutes. Let your heart rate return to normal and repeat. Then, you should try to increase your speed on the second, third and fourth trips. Note: you must always use the same power walking style to correctly monitor your speed.\nFor runners with distances less than 30 minutes—10K and under—you should pull a weight sled for 30 minutes. Mark the distance you cover at the 30-minute time limit and try to cover a longer distance each trip. When this can be achieved you have improved your top speed maintenance velocity as well as increased your strength endurance.\nRoss, Barry. 2005. Underground Secrets to Faster Running. Lulu.com.\nSimmons, Louie. 2017. Strength Manual for Running—Raising Strength to Prevent Injuries. Westside4Athletes', 'No Products in the Cart\nIn 2014, at thirty years old, Dennis Kipruto Kimetto, (b. Jan 22, 1984) a long-distance runner from Kenya set the marathon record of 2:02:57 (two hours, two minutes and 57 seconds) in Chicago, Illinois. He was the first man to ever run under 2:03.\nHe held the record for four years. It was then broken by Eliud Kipchoge (b. Nov 5, 1984), another Kenyan long-distance runner. Kipchoge is now the world record holder in the marathon with a time of 2:01:39, which he set Sept. 16, 2018, at the 2018 Berlin Marathon.\nKipchoge also ran the marathon distance at a special event in Vienna, Austria, and achieved a time of 1:59:40. The run did not count as a new marathon record, however, because it was not an open event and the standard competition rules for pacing and fluids were not followed, but he did become the first person to ever run a marathon in less than two hours. (https://en.wikipedia.org/wiki/Dennis_Kipruto_Kimetto and https://en.wikipedia.org/wiki/Eliud_Kipchoge)\nWhen someone does the seemingly impossible, everyone’s interest is heightened and they, too, want to improve. For the most part, to run long distances it takes the right genetics along with having the correct limb lengths and, of course, at least 70 percent Type 1/slow twitch/slow oxidative muscle fibers, but you also must train efficiently.\nThe most efficient way to improve is to gain muscular endurance. At the end of a marathon it is the legs that give out, not the lungs. Most will incorrectly try to increase their VO2 max, but it cannot be increased by top athletes as it cannot be raised after 12 or 18 months in endurance runners. This leaves only one way and that is to raise muscular endurance by maximally training strength endurance.\nIf one simply runs a set distance at a set body weight at the same pace, then you are not increasing your work. You must become more powerful. For example, by becoming stronger you can deliver greater ground force that can reduce ground contact time. A study by Leema Paavolainen concluded that reduced ground contact time is the most important for faster running times no matter the distance.\nThe study on 5K racers who had an average stride length of two meters found they would use 2500 strides to cover a 5K. A one one-hundredth of a second reduction in ground contact time would reduce their 5K time by 25 seconds. More on this topic can be found in Underground Secrets to Faster Running by Barry Ross.\nWhy is increasing strength so important? This is a simple physics equation. First, let’s look at what is work. In physics, work is defined as the product of the net force and the displacement through which that force is exerted, or W=Fd.\nLet’s look at power. Power is defined as work done divided by the time used to do the work (P=wt). This simply says that the more powerful you are, the faster you can do the work; the work in this case being 60, 100, or 25,000 meters or even a marathon.\nIf you are just running and not strengthening your body you have most likely developed a speed barrier where you can no longer cover your distant faster. That’s the definition of the biological Law of Accommodation—that your body adapts to a constant continued stimulus by decreasing its response. So just by running you won’t eventually run faster. To break that speed barrier, you must train other activities such as special exercises for the running muscles—the calves, hamstrings, hips and glutes, and of course, some upper body work for strength and balance. Westside uses weight sleds to build running muscles.\nFor strength endurance training instead of doing the same amount of work with just body weight, the runner should use three weights on a weight sled that is connected to your body with a strap. This does not effect your running technique when using 15, 25 and 35 pounds.\nThrough experimentation Westside found that long-distance runners lack maximal strength. For instance, one long-distance runner could parallel box squat 65 pounds for 100 reps, but could only squat 100 pounds for one rep. By doing interval training with a weight sled with three different weights, strength endurance was built. Westside established 25, 35 and 45 pounds in a three-week wave will build strength endurance.\nBy doing interval training with a weight sled with three different weights to build strength endurance. But experimenting Westside has established 25, 35 and 45 pounds in a three-week wave will build strength endurance.\nFor races up to 10,000 meters one can pull a weight sled for 30 minutes or just over the world record for that length race. For the very fit, two trips can be performed. Time between trips will depend on your level of preparedness, meaning letting your heart rate get back to your normal range and then repeat. Pull the sled two times a week, but remember to cut your running back by at least 30 percent.\nA 16-ounce bottle holds 16 ounces and no more, so when you include weight sled work you have to cut your running back. We know it will be hard to change your thinking, but you must. Your total work capacity is just like that 16-ounce bottle. The bottle can only hold 16 ounces at one time, but it can be full of different substances. For 20,000 meters—a half marathon—do two trips for 30 minutes or four trips for the advanced, and then push for two trips of 45 minutes. Remember, if your pace starts to slow down, you should stop. The key is to maintain top speed for as long as you can. If you slow down you lose … period.\nIf you run a full marathon, start with four trips using the interval method, meaning powerwalk for 30 minutes. Let your heart rate return to normal and repeat. Then, you should try to increase your speed on the second, third and fourth trips. Note: you must always use the same power walking style to correctly monitor your speed.\nFor runners with distances less than 30 minutes—10K and under—you should pull a weight sled for 30 minutes. Mark the distance you cover at the 30-minute time limit and try to cover a longer distance each trip. When this can be achieved you have improved your top speed maintenance velocity as well as increased your strength endurance.\nRoss, Barry. 2005. Underground Secrets to Faster Running. Lulu.com.\nSimmons, Louie. 2017. Strength Manual for Running—Raising Strength to Prevent Injuries. Westside4Athletes']	['<urn:uuid:3246222e-e61d-4f7c-b696-08c7b3d69b0e>', '<urn:uuid:3246222e-e61d-4f7c-b696-08c7b3d69b0e>']	open-ended	with-premise	concise-and-natural	similar-to-document	comparison	novice	2025-05-01T22:05:01.292488	12	35	2190
117	What are the main purposes of conducting regular cybersecurity audits, and what are the typical financial costs companies face when these audits fail to prevent ransomware attacks?	Regular cybersecurity audits serve multiple important purposes. They help identify gaps in defenses before they can be exploited, ensure compliance with data privacy regulations like GDPR and HIPAA, increase employee awareness about security best practices, and establish a baseline for future improvements. These audits involve comprehensive testing of software programs, networks, servers, databases, and access controls to identify potential vulnerabilities that hackers could exploit. Regarding financial costs when attacks occur, ransomware attacks can be devastating. Recent studies show average ransomware attack costs between $570,000 and $812,360. These costs include not only potential ransom payments but also significant business downtime losses, productivity losses up to 20% during system outages, and damage to brand reputation. In fact, about 60% of small to medium businesses go out of business within six months of experiencing a data breach.	"['In today’s fast-paced technological world, cyber threats have become a common occurrence for businesses of all sizes. From hacking to data breaches and identity theft, the potential risks are endless. That is why maintaining a secure online environment has become crucial for any business that wants to ensure the protection of its intellectual property, customers’ personal information, and remain legally compliant.\nKeeping up with the ever-evolving digital landscape requires forward thinking organizations to prioritize cybersecurity. Regular cybersecurity audits are an integral part of any business’s security strategy, and in this article we’ll dive into what they entail and why they’re so important.\nThe importance of cybersecurity audits cannot be ignored in today’s business landscape. Cybersecurity risks are becoming increasingly sophisticated, and businesses need to take proactive measures to protect their sensitive data and systems from potential breaches.\nA cybersecurity audit is a comprehensive assessment of an organization’s information security policies, procedures, practices, and systems designed to uncover vulnerabilities that could be exploited by cyber attackers.\nRegular cybersecurity audits help businesses stay up to date with the latest threats and continually improve their security posture. These audits also ensure compliance with legal regulations related to data privacy such as GDPR or HIPAA. Some other key benefits of cybersecurity audits include identifying gaps in defenses before they can be exploited, increasing employee awareness about security best practices, and establishing a baseline for future improvements.\nConducting regular cybersecurity audits is vital in protecting your business from the ever-evolving cyber threats that exist today. It not only helps prevent costly data breaches but also promotes trustworthy relationships with customers who entrust company information through online transactions. As technology continues to change rapidly over time, these periodic assessments become even more crucial for maintaining strong protection against unforeseen malicious attacks on critical infrastructure within any organization.\nA security audit is an assessment that aims to evaluate the effectiveness of a company’s cybersecurity measures. It involves comprehensive testing and analysis of various aspects, including software programs, networks, servers, databases, access controls, policies and procedures to identify potential vulnerabilities or weaknesses that hackers could exploit. This type of evaluation provides key insights into areas where an organization needs to improve its security strategies.\nThe purpose of conducting regular cybersecurity audits is not only to identify current threats but also to proactively anticipate potential future attack scenarios. These evaluations help companies stay ahead of emerging threats by keeping their systems up-to-date with the latest patches and protections against malicious activities. Regular assessments can also identify gaps in staff training or suggest additional measures for reducing risk factors adequately.\nWhen preparing for a cybersecurity audit, there are several crucial factors to consider. First, it is important to choose an experienced and reputable company that specializes in cybersecurity. The auditor should have the knowledge and expertise necessary to identify potential vulnerabilities and assess risk within your specific industry or area of business.\nDuring the audit process, the auditor will likely review your organization’s security policies, procedures, controls, systems architecture, and incident response plans. They may also conduct penetration testing to determine whether there are any weaknesses in your networks or applications that hackers could exploit.\nAnother important consideration when preparing for a cybersecurity audit is ensuring that all necessary documentation is available and up to date. This includes policies and procedures related to data privacy and protection, employee training materials on cybersecurity best practices, incident response protocols, disaster recovery plans, etc.\nProactive measures like conducting periodic cybersecurity reviews with a reliable external auditor and staying informed of the most up-to-date compliance requirements for data privacy, such as GDPR and CCPA, are key to shielding businesses from costly security breaches. Taking these steps helps ensure that any potential vulnerabilities can be detected and addressed immediately, so companies stay ahead of ever-evolving cyber threats.\nImplementing regular cybersecurity audits is an essential step for any organization that wants to safeguard its assets from potential cyber threats. These audits involve evaluating the company’s network infrastructure, policies, and procedures to identify any vulnerabilities and areas that need improvement. To implement these audits effectively, it is important first to develop a comprehensive security plan based on industry best practices and regulatory compliance standards.\nNext, organizations can work with their IT teams or hire third-party professionals specialized in cybersecurity auditing to conduct thorough assessments of their systems regularly. The audit should cover various aspects such as password management protocols, access controls, software updates and patch management systems, firewalls configuration checks among others.\nAfter conducting a detailed audit, an analysis report outlining all the found vulnerabilities that need to be addressed will be generated. Timely and effective corrective action should be taken to mitigate or reduce any potential risks of attacks from external sources like ransomware attackers. These attackers can encrypt your files, demanding payment in exchange for them being opened up again. Such situations may harm the reputation of your business and lead to mistrust from clients; therefore, preventive measures must be taken to protect against this now and in the future.\nRegular cybersecurity audits play a crucial role in keeping businesses safe and secure from ever-changing cyber threats. As digital technology continues to advance, the importance of staying ahead of potential risks cannot be overstated. These audits serve as an essential component in identifying vulnerabilities, assessing gaps, and implementing proactive measures against cyber-attacks.\nConducting frequent audits not only prevents financial losses but also helps maintain customers’ trust by safeguarding their sensitive data. While investing time and resources into cybersecurity audits may seem daunting for some organizations, it is imperative to view them as an investment in the long-term viability of the business.\nCybersecurity is no longer optional for most companies; it’s a necessity in today’s increasingly digitized world. Organizations that prioritize conducting regular cybersecurity assessments will gain peace of mind knowing they have taken all necessary steps towards maintaining healthy security hygiene while preventing potentially devastating breaches or losses.\nEssential Steps for Restoring Your Network and Rebuilding Trust\nThe True Cost of a Data Breach\nEducating Employees as the First Line of Defense\nEnter your details below and we will contact you within 1 business day.\n""*"" indicates required fields', 'Financial Costs of a Ransomware Attack and Breaking the Attack Chain Ransomware is a type of malware that typically utilizes encryption to impede or restrict admittance to information until a payoff is paid.\nFor organizations that experience the ill effects of a ransomware attack, the blow-back to income is in many cases more terrible than the size of the payoff and regardless of whether to pay it. The monetary harm can be far reaching and go a long ways past how much the payment.\nThe Financial Costs of a Ransomware attack can be huge. In addition to the ransom, businesses lose business due to downtime. These losses can quickly compound and spiral out of control. For example, one ransomware attack affected Maersk and left the company unable to operate for weeks. The company estimates that the downtime cost them $300 million.\nSpecialists suggest that organizations don’t pay ransoms as it gives cybercriminals a thought process to proceed. Organizations that really do wind up paying the payoff are frequently disheartened with the outcomes.\n- The information they recuperate is harmed.\n- The aggressors request more cash.\n- The aggressors disappear, and they don’t recuperate their information.\nLate investigations by Sophos and Pao Alto put the normal ransomware attack costs at somewhere in the range of $570,000 and $812,360.\nAs cybercriminals now utilize hilter kilter encryption strategies, having the option to unscramble the information is profoundly impossible. If you would rather not pay the payment, you will either need to recuperate the information from reproductions or reinforcements or lose it through and through.\nAt the point when you experience a ransomware attack, it is smarter to pick up and move on and follow your occurrence reaction plan. In the event that you have a viable recuperation plan set up, you might have the option to recuperate your information with negligible disturbance, and you won’t have to pay the payment. A recuperation plan typically includes five stages: survey, moderate, answer, convey, and hindsight.\nCounteraction is in every case better compared to attempting to manage the broad harm a ransomware attack can cause. Figure out more about how to diminish the gamble of turning into a ransomware casualty in any case at Discernment Point.\nCyber Insurance Academy\nThe cyber insurance industry is in a state of flux as more organizations are exposed to ransomware attacks. These attacks see hackers infect an organization’s computer network and demand money in return for control. These attacks have resulted in a massive increase in ransom payments, increasing by three-fourths to $412 million by 2020. In response, the cyber insurance industry has started an educational program to prepare students for such attacks.\nCyber insurance could take a cue from other forms of insurance. One professor at King’s College London studied the phenomenon of kidnap for ransom insurance and discovered that the insurance company’s “disruptive bargaining” strategy helped reduce kidnap gangs’ demands.\nWhile ransomware is becoming increasingly widespread, some insurers are beginning to reconsider their policy and stop covering ransom payments. For example, AXA, which insures several large French companies, has decided to stop covering payments to ransomware attackers for future policyholders. This move has come in response to government pressure.\nGovernments are eager to provide adequate cyber insurance coverage but don’t want insurers’ solvency to suffer. The failure in either direction could lead to a financial burden on governments. Cyber insurance companies are increasingly working with outside firms to vet their insureds’ security protocols and procedures.\nBy restoring your computer and all of its data with NeuShield, you can stop ransomware attacks from destroying your information. Ransomware typically attempts to encrypt and wipe a disk, but NeuShield protects your data by restoring it to the original state. It does this by creating an undetectable overlay over your data. The attacker only has access to the data that is in the overlay – all of your original files are preserved. Moreover, NeuShield can be restored to a previous state, allowing you to regain access to your information quickly and easily.\nAnother key aspect of defending your computer is breaking the attack chain. By understanding the structure of cyber attacks, you can identify and block them before they start. The attack chain is also known as the kill chain, and it is originally a military concept. It describes the methods of malware infiltration, deployment, and execution. Basically, breaking the attack chain means to prevent the attacks before they begin, but it is not as easy as it sounds. Whether you are a small or large business, the idea of breaking the attack chain is important and a vital part of cyber security.\nCybercrime has continued to evolve rapidly, and the scope of its attacks increases. As a result, future attacks will be much harder to detect and respond to. This arms race between attackers and defenders is becoming more apparent. In many ways, this is why cyber insurance premiums have skyrocketed.\nWhile traditional endpoint security can prevent the majority of cyberattacks, it may not be enough. Malware has become so sophisticated and evasive that traditional signature-based endpoint security cannot keep up. As a result, organizations need to employ a multi-layered endpoint protection strategy to combat the latest threats. By deploying a multi-layered endpoint security strategy, you can stop threats across multiple attack chains.\nAn innovative multistakeholder approach can effectively disrupt the financial capabilities of malicious actors and help reduce the global impact of ransomware attacks. Such an approach would leverage information-sharing and pooled resources to assess the costs and organizational vulnerabilities of ransomware.\nRansomware is a highly disruptive and costly cyberattack that can lead to crippling downtime and substantial productivity losses. The costs of downtime and recovery are enormous – some estimates estimate that they are 50 times higher than the ransom demands. The downtime from a ransomware attack can affect a business for months and may cause it to file for bankruptcy.\nThe recovery process from a ransomware attack is complicated and requires all hands on deck. Depending on the size and scope of the attack, it may involve internal teams, incident response companies, forensic experts, and even the assistance of local and federal law enforcement agencies. Each step in the recovery process carries its own set of costs. Some companies may choose to pay the ransom instead of dealing with the recovery process, avoiding the financial consequences of losing customer data.\nThe impact of ransomware attacks is becoming increasingly widespread and complex. As a result, CISOs are losing confidence in the ability to mitigate ransomware attacks. Moreover, 73 percent of respondents said that failure to mitigate the risk of cyberattacks could expose organizations to fines and legal action. Cybersecurity Ventures estimates that ransomware attacks will cost $265 billion by 2031, which makes it crucial for organizations to prepare for the costs of these attacks.\nRansomware supply chains have become more sophisticated. As a result, cybercriminals are now targeting companies with extensive digital networks. This means that ransomware supply chain attacks will become more prevalent in the future. The SolarWinds ransomware attack, for example, should serve as a warning to all companies with global supply chains. This attack affected 18,000 corporate customers, including Fortune 500 companies and U.S. government agencies.\nIn January 2022, the BlackCat ransomware group infected 233 gas stations in Germany and forced the oil company Shell to reroute supplies. The attack used two vulnerabilities in two different software applications to encrypt data and exfiltrate intellectual property. The resulting disruptions rendered more than half of the organization’s systems inoperable for 48 hours, forcing Shell to hire security experts to restore access to their systems. The attack was so widespread that German intelligence services feared that the attackers had penetrated the networks of gas stations and oil companies to steal information. In Baltimore, the ransomware attack affected the city’s official email servers and rendered critical systems inaccessible.\nMany small and medium-sized companies have limited resources to protect themselves from ransomware. Security is costly and time consuming, so they often put off investing in it in favor of other critical business requirements. Unfortunately, the longer they wait to secure their networks, the more expensive it will be to repair the damage. This negative feedback loop has left many organizations unprepared for attacks and paved the way for predatory ransomware groups.\nThe costs of ransomware attacks can be staggering. In the United States, companies face billions of dollars in ransomware losses every year. As a result, ransomware has become a top concern for businesses, affecting both organizations and consumers. In addition to the financial burden of downtime, ransomware can damage a company’s reputation, and cause customers to lose trust in it.\nThe cost of ransomware attacks is escalating – a single attack can cost up to $265 million. Those figures are staggering, and many companies that have been affected go out of business within a year of being infected. Fortunately, there are ways to mitigate the risk of a ransomware attack.\nThe financial costs of a ransomware attack can be staggering. The Cybersecurity Ventures report predicted that ransomware attacks would cost more than $5 billion in 2017, up from $325 million in 2015. This represents a 15X increase in just two years, with a projected total of $8 billion in 2018 and $11.5 billion in 2019. By 2021, ransomware attacks are expected to cost $20 billion, and every 11 seconds, an average business will be hit by ransomware.\nIn addition to the financial cost, ransomware attacks can also have a huge impact on an organization’s business. For example, an attack on the Colonial Pipeline Company caused a panic buying of fuel on the East Coast because a compromised password had given access to their IT system. The attack resulted in the shutdown of the company’s operational technology networks and IT systems for several days. Fortunately, the company was able to recover a significant portion of the $4.4 million ransom.\nIn addition to monetary costs, the recovery and downtime costs associated with a ransomware attack are also enormous. This is why it is essential to seek outside legal counsel when dealing with ransomware. A seasoned attorney will be able to guide you through the process and minimize your risk.\nTrend Micro has also recently discovered a new vulnerability impacting e-commerce websites. In April 2021, the company found that BIQS software was vulnerable to an XSS vulnerability, which could allow threat actors to inject malicious code on the servers. In August, the company also discovered that Atlassian Confluence servers were vulnerable to a local file inclusion vulnerability, allowing threat actors to insert arbitrary code on its servers.\nDowntime and labor costs\nWhile your frameworks are down, you will experience monetary misfortunes. Most associations require essentially a week and frequently significantly longer to recuperate information. Until it is reestablished, your entire situation is probably going to be disabled. Client information is essential to maintaining a business easily, and without it, you will fight to sell items, administration clients and substantially more. A regular efficiency misfortune can really depend on 20% during free time.\nIn a 2021 ransomware attack, the Kaseya assault, around 1,500 oversaw specialist organization clients were impacted. This shows how store network assaults cause more broad harm than assaults against single people.\nIT groups frequently need to stay at work past 40 hours to reestablish frameworks, and there is normally an overabundance of work all through an association because of an absence of admittance to information. Extra counseling or expert help might be expected to determine information issues.\nThe cost to brand reputation\nA harmed brand notoriety is difficult to fix, and this can have a broad monetary effect. Any bad exposure about an information break can influence the relationship with clients as well as with representatives, financial backers and different partners. Research from the Public Digital protection Coalition shows that around 60% of little to medium organizations leave business in no less than a half year of encountering an information break.\nThere’s a developing pattern for cybercriminals to take steps to uncover delicate information they exfiltrate before encryption. Where the information is strategic, for example, in medical clinics, government or crisis call focuses, this can really hurt.\nIn certain enterprises, clients can guarantee direct pay for an information break. Scripps Wellbeing, retail goliath Target, and gas organization Frontier Pipeline are only a portion of the organizations that have confronted legal claims.\nMost cases are privately addressed any remaining issues as organizations would rather not face extended court fights. Administrative and legitimate fines can be especially high for the spilling of individual wellbeing information, monetary data like charge card subtleties, and actually recognizable data.\nData loss and collateral damage\nYou might lose an information totally due to a ransomware attack. The deficiency of information might address many long stretches of work. Regardless of whether you can reestablish records from reinforcements, there’s an opportunity they were not supported totally or accurately. Today there are ransomware variations that likewise target reinforcement frameworks so you can’t reestablish information.\nYou should figure out how cybercriminals accessed your frameworks. There are numerous ways they can do as such, from conveying phishing messages and setting up counterfeit sites to straightforwardly going after programming weaknesses.\nContaminated machines might need to be totally reformatted, and programming reinstalled. You will likely need added assurance to ensure another information break doesn’t happen.\nIn the ongoing monetary circumstance with expansion and downturn, every one of the costs of a ransomware attack might cause a huge monetary misfortune. In 2020 different reports demonstrated that the normal expense of tidying up after a ransomware attack could depend on $1.85 million. In the event that you don’t tidy up your information and fix any fundamental issues, you could gamble with another assault.\nStep by step instructions to prevent ransomware attacks\n- Having security frameworks set up, representative preparation, and powerful design the executives are a portion of the ways of forestalling ransomware attacks.\n- Keeping awake to date with the most recent working software is vital.\n- Ensure you have total and exceptional reinforcements as they can assist you with recuperating information.\n- Stay up with the latest, and remember to apply security patches.\n- Persistently look at security to ensure you have the right estimates set up.\nIT experts need to adopt a protection strategy as once programmers get inside your association, limiting the damage can be hard. You want to safely safeguard each channel, with email frequently being quite possibly of the most weak one.\nCybercriminals keep on utilizing perpetually complex methods to convey ransomware by means of email. You want to search for cutting edge email security arrangements that utilization quick and successful unique filtering. Arrangements ought to likewise can identify dangers covered somewhere inside happy.\nRansomware can be monetarily harming to organizations in various ways, including pay-off costs, personal time costs, work costs, notoriety harm and legitimate expenses. Associations need to investigate their network protection safeguards. Distinguishing and managing likely dangers and channels, for example, email and cloud coordinated effort apparatuses, can assist with alleviating ransomware attacks.\n- Also Read: Price In India Emo Robot What Is The Cost?\n- Also Read: Kbm 25 Com Know The Latest Authentic Details!\n- Also Read: Is My Derma Dream Legit? Authentic Review!']"	['<urn:uuid:ee1a90ee-9bc1-4a29-8ef0-e3673db2ff2b>', '<urn:uuid:a4aad484-a3a3-4984-8feb-404e3a6bba70>']	open-ended	direct	verbose-and-natural	similar-to-document	multi-aspect	novice	2025-05-01T22:05:01.292488	27	134	3562
118	Is arts recognized as a core academic subject?	The arts are recognized as a core academic subject under the federal Elementary and Secondary Education Act, and 48 states have adopted standards for learning in the arts.	['The Arts and Education Council builds appreciation, participation and support for arts and humanities training throughout the St. Louis community. Nor does help for the arts by high directors necessarily translate into instruction for kids. The School of Arts and Schooling affords top quality and interesting courses from undergraduate and postgraduate coursework levels to PhD …\nThe Arts and Education Council builds appreciation, participation and support for arts and humanities training throughout the St. Louis community. Nor does help for the arts by high directors necessarily translate into instruction for kids. The School of Arts and Schooling affords top quality and interesting courses from undergraduate and postgraduate coursework levels to PhD level analysis. We are proud to have sturdy, collaborative relationships with the Workplace of Superintendent of Public Instruction (OSPI, our state department of education) and ArtsEd Washington , a statewide arts education alliance.\nAll tickets are available at backed costs for college students and teachers. And school is the place many of us will first encounter the humanities. Since the program started in 2004, we’ve got served 176,500 students and lecturers, averaging sixteen,000 served on an annual basis.\n7) The arts are acknowledged as a core tutorial subject under the federal Elementary and Secondary Schooling Act, and forty eight states have adopted requirements for learning in the arts. The flexibility of this programme means it’s excellent for college kids from a range of topic, skilled and profession backgrounds including lecturers, lecturers, directors, training advisors, or other related professions.\nOur higher degree by research college students obtain skilled steerage and inspiration to proceed the tradition of innovation and inventive discovery inside a supportive research atmosphere. System-large implementation of the Kindergarten to Grade 8 Dance, Drama, Music, and Visual Arts curriculum frameworks was initiated in 2011.\nPurple Hook Group Justice Heart JustArts Pictures program with Educating Artist Brenna McLaughlin. Our members include art and generalist educators, colleges and tertiary institutions, arts and cultural organisations, and companies across Victoria and beyond. Perhaps moreÂ alarmingly, respondents overwhelmingly talked about the arts as a release valve for a few of the pressures they experience at college or at dwelling.\nNone of this research will occur, nevertheless, until defenders of the arts acknowledge the necessity for it. Arts advocates can no longer rely on weak studies that simply compare college students who take part in the arts with those that don’t. Residencies train the weather of the art kind, emphasis artistic expression and the artistic course of, and have fun the students’ inventive work.anonymous,uncategorized,misc,general,other\nOregon Division Of Schooling\nThe report studied students at 12 New York, Connecticut, Virginia and South Carolina colleges to compile their outcomes. Gavin Newsom will do in terms of the future of arts in California faculties.\narts council education funding, freedom arts and education center, arts and education council board, arts and education council chattanooga, art and education store coupons\nHold Art Taking place\nThis program gives students with arts learning experiences that spark creativity, imagination, and innovation. Obtain an information packet and are available to an information session to be taught more about our graduate trainer education schemes. The Arts in Training web site permits for online requests, the creation of contracts for the visiting artists, an analysis process for both artists and faculties, and monitoring of district expenditures.\nIt checked out over 62 completely different studies from a hundred researchers, spanning the range of fine arts from dance to the visual arts. The Annual Grants Program is the Arts Council’s only position in offering funding organizations or artists. We are delighted to supply World Excellence Scholarships for college students of excellent educational high quality applying to postgraduate Taught programmes starting in autumn 2019.\n‘We Should Hear To Pupils About Arts Training’\nNYSCA’s Arts Education Program cultivates the creativity of all New Yorkers, from preschoolers to seniors,Â in both faculty and neighborhood settings. Additionally, you will be doing your part to help art education in Victoria. Arts Edge is an internet resource middle funded by the Nationwide Endowment for the Arts and the United States Department of Schooling and administered by the Kennedy Heart Education Department.\nUsing this knowledge, researchers decided that students who obtained more arts schooling did better on standardized tests, improved their social abilities and were more motivated than those who had diminished or no entry. By means of the humanities, college students have a spot not only to find out about completely different cultures than their own, but in addition to ask questions and be extra knowledgeable concerning the daily struggles and realities of people that could appear completely different.\ngarcia arts and education center, art and education store centerville ohio, arts and education deakin\nArt and music are key to student improvement. As a Masters level scholar you will develop into a part of the analysis-intensive Graduate College of Training, learning with a number of the leading students in their disciplines. California’s statewide arts education coalition, Create CA , is a new collective influence organization specializing in advancing arts and education by means of multiple initiatives, partnerships, and tasks.']	['<urn:uuid:3ec2ee17-6a4b-4d15-bdd9-d37741360350>']	factoid	direct	concise-and-natural	similar-to-document	single-doc	novice	2025-05-01T22:05:01.292488	8	28	844
119	I'm studying bird population dynamics and need to understand how black ducks move between regions during migration. What percentage of black ducks stay in their original Canadian regions versus moving to wintering areas?	The data shows that black ducks rarely remain in their Canadian breeding regions during migration. Specifically, only 3.3% stayed in Northwest Canada, 0.2% in Southwest Canada, and 1.2% in Northeast Canada. In Southeast Canada, 13.5% remained in the region. For birds banded in Northwest and Southwest Canada, about 90% moved to wintering regions. In Northeast Canada, 58% moved to wintering regions, while 80% of those banded in Southeast Canada moved to wintering areas.	['Effectively conserving migratory species requires knowledge of the demographic processes occurring at breeding, non-breeding areas, and the migratory pathways connecting these areas. Often, knowledge of connectivity between breeding and non-breeding areas is a limiting element for effective management and conservation (Faaborg et al., 2010). The demographic processes in one of these stages of a migratory species’ life cycle are also likely to affect the others (Marra, Hobson & Holmes, 1998; McGowan et al., 2011). Knowing where migratory species move and how they get there can also shed light on the metapopulation dynamics that may occur among distinct populations of these species, furthering our understanding of which ‘stocks’ within a population may be at higher risk of decline (Esler, 2000; Zimpfer & Conroy, 2006). Another goal of understanding migration is in identifying important stopover sites (Mehlman et al., 2005; Skagen, 2006). Understanding migratory pathways and the role of migration along them in shaping the demography of populations can allow conservation practitioners to make complicated decisions about how best to spend limited capital (Conroy, Stodola & Cooper, 2012; Desholm et al., 2014). Estimating connectivity between breeding grounds, stopover sites and wintering grounds can help managers understand how management enacted on one part of the annual cycle will interplay with other parts of the annual cycle.\nLarge strides have recently been made in understanding inter-seasonal migratory connectivity (Webster et al., 2002; Robinson et al., 2009), with new techniques currently being tested and implemented using stable isotopes (Hobson et al., 2014), genetic markers (Ruegg et al., 2014), geolocators (Catry et al., 2014) and mark-recapture modeling (Cohen et al., 2014). However, there are drawbacks to each of these approaches. Stable isotope analysis and genetic markers require rather expensive equipment, as there is some cost in developing the assays for the genetic marker analysis. Results from stable isotope studies may not be as accurate as basic probability models (Wunder et al., 2005). Provided one has the equipment and the assays for genetic analysis, it would cost roughly $10 (USD) per individual bird (Ruegg et al., 2014). This is still less expensive than the $25 (USD) per sample for stable isotope analysis and the $150 per unit for geolocators (Hobson et al., 2014). In addition to their great expense, geolocators have also been shown to have a negative effect on survival and reproduction (Scandolara et al., 2014) and require recapturing the individual sometime after initial application to recover the location data. Modeling migratory connectivity via analysis of marked individuals requires capturing an individual at least once, then seeing that same individual and/or capturing it again. For some species, this has proven very difficult (e.g., Pied Flycatcher (Ficedula hypoleuca); Webster et al., 2002). Mathematical models, such as those used in modeling movement from marked individuals, are frequently seen as black-boxes (Addison et al., 2013) and not as transparent as simply attaching a geolocator to an individual and determining where it went once the bird is recaptured and the data are recovered.\nWhile banding (ringing) data has its issues, it is still the most widely used and accessible way to estimate migratory connectivity. One may access more than 70 million banding and 5 million encounter records from the North American Bird Banding Laboratory (BBL) and over 10 million encounter records from EURING (www.pwrc.usgs.gov/bbl; www.euring.org; Cohen et al., 2014). Individuals may also receive information about birds they may have observed in the field and begin building a database through sites such as www.bandedbirds.org. Banding data has proven useful in many contexts, including movement estimation for many different groups including doves (Collier et al., 2012), waterfowl (Lavretsky et al., 2014), shorebirds (Gill, Handel & Ruthrauff, 2013), raptors (Goodrich et al., 2012) and songbirds (Suomala, Morris & Babbitt, 2012).\nAmerican black ducks (Anas rubripes, here after black ducks) are a harvested, international migratory waterfowl species in eastern North America (Loncore et al., 2000). There were significant long term declines in black duck populations between the 1960s and 1990s according to winter count data and breeding season monitoring (Devers & Collins, 2011). Despite an extended period of restrictive harvest regulations (Francis, Sauer & Serie, 1998) the black duck population is still below the population goal identified in the North American Waterfowl Management Plan (NAWMP) (Devers & Collins, 2011). The Black Duck Joint Venture (BDJV) was created in 1989 under NAWMP to develop monitoring and research programs that will aid in the continental black duck population achieving the NAWMP goal.\nIt has been hypothesized that density dependent factors restrict population growth in black duck populations and that habitat management (increases, improvements, etc.) may be a key component of growing black duck populations and reaching the prescribed NAWMP population goal (Conroy, Miller & Hines, 2002; Devers & Collins, 2011). However, deciding how much habitat to preserve and where to acquire or restore that habitat at the continental scale to best benefit black duck populations is first and foremost limited by understanding how habitat management actions in any portion of the annual life cycle will affect the overall population (Devers et al., 2010; Devers & Collins, 2011). To aid in management decision making, the NAWMP has called for building and parameterizing full annual cycle (FAC) population models for black ducks, as well as many other waterfowl species (Anderson et al., 2007).\nFollowing the NAWMP, the framework for a FAC population model has been created (Robinson et al., 2016) that fits the management units outlined by the BDJV. The first step in parameterizing a large scale optimal habitat management model for migratory species is understanding how wintering and breeding region populations are connected to each other (Hostetler, Sillett & Marra, 2015). There have been studies conducted to evaluate black duck movement in the past; however, these studies used data from birds banded between 1971–1994 (Conroy, Fonnesbeck & Zimpfer, 2005) and between 1965–1998 (Zimpfer & Conroy, 2006). These studies also used different regions in their movement estimations than the regions drawn by the BDJV. Here, we have updated the estimation of movement probabilities for black ducks using band recovery data. We estimate the number of birds banded in each of the seven regions defined by the BDJV and the subsequent movement of those birds among the regions. Our study adds 27 additional years of data to the most recent analysis for estimating cross seasonal, continental scale movements (Zimpfer & Conroy, 2006). Furthermore, we did not limit our data to only those black ducks that were banded in the traditional breeding areas and did not discard data for those birds migrating northward or not migrating at all as previous studies have done (Zimpfer & Conroy, 2006).\nMaterials and Methods\nWe obtained more than 50,000 band recoveries of black ducks banded in the United States and Canada from 1951–2011 from the BDJV. We only included birds that were banded during the preseason (1 July–30 Sept.) and recovered during the hunting season. Birds that were recovered in the hunting season immediately after they were banded (i.e., they were banded and recovered in the same year) and within the region in which they were banded were removed from the analysis. The removal of these birds was to ensure that the individuals at least had an opportunity to move between the banding and recovery events. Since migration occurs primarily between October and February, any birds recovered in those months that was banded in the banding period immediately preceding migration (that same year) were not included in our analysis. We split the data into seven regions (e.g., four breeding regions and three wintering regions; Fig. 1) and black ducks banded in all of the seven regions were included in the study. The regional boundaries were set by the BDJV habitat integration working group as these are the regions that will be used for future simulation modeling to inform continental habitat management strategies (Devers et al., 2010; Devers & Collins, 2011; Robinson et al., 2016).\nUsing a hierarchical Bayesian approach, we calculated the probability (π) that an individual moved from region i to region j, was recovered (e.g., shot by a hunter) and reported as\nfollowing Conroy, Fonnesbeck & Zimpfer (2005), where Ψ is the movement probability, λ is the reporting probability and h isthe harvest rate in the region. Ψ was informed by an uninformative multinomial distribution (Dirichlet distribution) where the movement probabilities were constrained to sum to one. λ was drawn from a beta distribution with α and β parameters calculated so that the distributions for the reporting probability for each band type had a mean equal to the reporting probability of each band type provided by the BDJV (P Devers, 2015, unpublished data). This differs slightly form previous analyses where λ was assumed to be constant. We had multiple band types, each with different reporting probabilities. Previous studies have recommended including these data to analyses such as ours if it is available (Conroy, Fonnesbeck & Zimpfer, 2005). We constrained h to be constant with respect to each region. As h and λ are confounded, this assumption must be made so that Ψ is identifiable. Therefore, a continental harvest rate was drawn from a beta distribution with α = 2 and β = 19 to produce a distribution with a mean of 0.055 (value for mean taken from Conroy, Miller & Hines, 2002). The data (Dij; the number of birds recovered in region j that were banded in region i) was then modeled as binomial distribution\nwhere N is the total number of birds banded. Using OpenBUGS (Thomas & O’Hara, 2007), values for Ψij were then sampled via MCMC from its posterior distribution to create a new distribution of estimates for Ψij influenced by the prior distribution and the data. This analysis was performed for each band type, and the results weighted by the proportion of the data contributed for each band type. The model was sampled to convergence according to convergence diagnostics using the package CODA (Plummer et al., 2006) in program R (R Core Team, 2013).\nOnce the data were constrained to the banding and recovery periods described above, we were left with 14,624 black ducks recovered in the United States and Canada from 1951–2011. Ducks that were banded in NW, SW, and NE Canada rarely stayed in that region during the migration period (3.3% for NW Canada; 0.2 % for SW Canada; 1.2% for NE Canada; Table 1). Of the ducks banded in SE Canada, 13.5% stayed in the region; however, 39% of the ducks banded in NE Canada moved to SE Canada. For ducks banded in the S Atlantic and Interior regions, more than 50% stayed within the region during the migration period, while 29.4% of the ducks banded in the N Atlantic stayed in that region. For NW and SW Canada, about 90% of birds banded in those regions moved to one of the wintering regions. For ducks banded in NE Canada, 58% moved to one of the wintering regions, and for those banded in SE Canada, 80% moved to a wintering region. For ducks banded in the United States, more than 15% in each region moved north during the fall migration period.\nHere, we have extended the previous efforts of Conroy, Fonnesbeck & Zimpfer (2005) and Zimpfer & Conroy (2006) to estimate movement of black ducks. Our simple update to previous methods (incorporating multiple band types and their different reporting probabilities) has allowed us to include an additional 27 years of data. The reporting of different band types has changed over the years; from bands that required the person who made the recovery to mail the band and location to the bird banding laboratory, to those that require an easily accessible online form to be filled out. Occasionally, there are “reward” bands placed on birds that offer a reward to the person who reports the band (these are usually assumed to be reported at 100% and typically used to estimate reporting probabilities of non-reward bands). All of these band types have different reporting probabilities (Williams, Nichols & Conroy, 2002). In order to consider long-term movement probabilities, one must include them all rather than assuming one reporting probability or choosing a subset of data from bands with only one reporting probability. This was recognized by Conroy, Fonnesbeck & Zimpfer (2005), who suggested the use of such data when possible. Being able to use long-term banding data for movement analysis allows us to detect trends in the movement data. For example, climate change has been shown to have an effect on waterfowl abundance and on timing of migration (Sorenson et al., 1998; Guillemain et al., 2015). Using a method such as ours, with multiple band types and allowing for birds that do not migrate out of their region, one could potentially determine how the movement (or lack of movement) of black ducks among regions has changed over time in response to changes in habitat availability, climate, or other aspects of environmental change.\nMovement analyses may help influence habitat management by suggesting the most important regions used by the species of interest. Our results show that many black ducks use the Atlantic coast during the winter months. We estimate that 33–63% of black ducks, regardless of breeding region, move into or remain in either the N Atlantic or S Atlantic regions. This corroborates a recent meta-analysis suggesting the importance of the Atlantic coast as vital black duck wintering habitat (Ringelman et al., 2015). Further, Aagaard et al. (2015) showed that habitat was the most important factor among a suite of variables for predicting winter black duck abundance in the Atlantic flyway. These studies, along with our movement analysis strongly suggest that habitat improvements along the Atlantic coast of the United States would greatly benefit the continental black duck population.\nWe found that black ducks generally exhibit flyway fidelity (e.g., individuals banded in the western breeding regions tended to over winter in western regions, but see above) similar to Addy (1953), Conroy, Fonnesbeck & Zimpfer (2005), Zimpfer & Conroy (2006) and Lavretsky et al. (2014). There may be some error or bias in the results. For example, some northward movements that we observed may be post breeding/fledging movement prior to migrating and settling into an over wintering home range. Using only birds banded in the preseason and recovered during the hunting season tried to limit the potential temporally caused biases in our results. Using large regional boundary definitions also reduces the effect of location reporting errors. Some of these northward movements may also be local scale movements of birds that, for example, were banded in northern Maine and recovered in New Brunswick some years later. If this is a concern, one could adjust the analysis to account for distance moved as well as movement across the boundaries of the regions. The regional boundaries also reflect the region definitions used in a larger population simulation modeling effort that will evaluate continental scale habitat management strategies (Devers et al., 2010; Devers & Collins, 2011; Robinson et al., 2016). The objective of that annual cycle modeling effort is to identify which region and part of the annual cycle should habitat management be focused on to best benefit black duck populations (Robinson et al., 2016). This analysis can provide a way to prioritize management efforts by acting as a component of a larger modeling effort (Conroy, Stodola & Cooper, 2012). The results can be used in the recent projection modeling context to evaluate how habitat or harvest management actions in one region would propagate throughout the continental population of black ducks (Robinson et al., 2016). The results of these analyses serve as the first step in parameterizing projection models and developing a framework for making continental scale habitat management decisions to support black duck populations and to fit the needs of the BDJV. Our results also demonstrate the potential utility of banding data for estimating interseasonal connectivity of migratory species, with much less expense than genetic, isotope or geolocator techniques.']	['<urn:uuid:6150e405-7ee7-4045-b398-cccc581ae62a>']	open-ended	with-premise	verbose-and-natural	distant-from-document	single-doc	expert	2025-05-01T22:05:01.292488	33	73	2645
120	genetic science researcher analyzing dna structure and impacts relationship between dna helix configuration chemical properties and how mutations affect genetic code	The DNA double helix consists of two right-handed polynucleotide chains coiled around the same axis, with heterocyclic amine bases projecting inward. The structure follows the Base Pairing Principle where adenine pairs with thymine (A-T) through two hydrogen bonds, and guanine pairs with cytosine (G-C) through three hydrogen bonds. The helix has a diameter of 20 Angstroms, with repeating patterns every 34 Angstrom units and 10 subunits per turn. When mutations occur, they can affect this structure through various mechanisms, including base-pair substitutions, deletions, or insertions. These changes can alter the amino acid sequence in proteins and potentially reduce or inactivate protein function. Mutations can result from accidents during DNA replication or exposure to radiation or reactive chemicals, and while mostly deleterious, some may be beneficial in certain environments.	"[""If you like us, please share us on social media, tell your friends, tell your professor or consider building or adopting a Wikitext for your course.\nThe secondary structure of DNA is actually very similar to the secondary structure of proteins. The protein single alpha helix structure held together by hydrogen bonds was discovered with the aid of X-ray diffraction studies. The X-ray diffraction patterns for DNA show somewhat similar patterns.\nIn addition, chemical studies by E. Chargaff indicate several important clues about the structure of DNA. In the DNA of all organisms:\nChargaff's findings clearly indicate that some type of heterocyclic amine base pairing exists in the DNA structure. X-ray diffraction data shows that a repeating helical pattern occurs every 34 Angstrom units with 10 subunits per turn. Each subunit occupies 3.4 Angstrom units which is the same amount of space occupied by a single nucleotide unit. Using Chargaff's information and the X-ray data in conjunction with building actual molecular models, Watson and Crick developed the double helix as a model for DNA.\nThe double helix in DNA consists of two right-handed polynucleotide chains that are coiled about the same axis. The heterocyclic amine bases project inward toward the center so that the base of one strand interacts or pairs with a base of the other strand. According to the chemical and X-ray data and model building exercises, only specific heterocyclic amine bases may be paired.\nThe Base Pairing Principle is that adenine pairs with thymine (A - T) and guanine pairs with cytosine (G - C)\nThe base pairing is called complementary because there are specific geometry requirements in the formation of hydrogen bonds between the heterocylic amines. Heterocyclic amine base pairing is an application of the hydrogen bonding principle. In the structures for the complementary base pairs given in the graphic on the left, notice that the thymine - adenine pair interacts through two hydrogen bonds represented as (T=A) and that the cytosine-guanine pair interacts through three hydrogen bonds represented as (C=G).\nAlthough other base pairing-hydrogen bonding combinations may be possible, they are not utilized because the bond distances do not correspond to those given by the base pairs already cited. The diameter of the helix is 20 Angstroms.\nThe double-stranded helical model for DNA is shown in the graphic on the left. The easiest way to visualize DNA is as an immensely long rope ladder, twisted into a cork-screw shape. The sides of the ladder are alternating sequences of deoxyribose and phosphate (backbone) while the rungs of the ladder (bases) are made in two parts with each part firmly attached to the side of the ladder. The parts in the rung are heterocyclic amines held in position by hydrogen bonding. Although most DNA exists as open ended double helices, some bacterial DNA has been found as a cyclic helix. Occasionally, DNA has also been found as a single strand.\nQUES. Describe the structure of the double helix of DNA in your own words including the terms: backbone, heterocyclic amines, complementary base pairings, hydrogen bonding, deoxyribose, phosphate.\n|Quiz: In RNA, which base hydrogen bonds with uracil? Carefully compare the structure of uracil to the others to find the one that is most similar.|\n|Quiz: If DNA is heated, what happens to the double helix? Hint: The result is similar to the denaturing of a protein by the same method. What type of bonding holds the secondary structure of both proteins and DNA?|| |\nAn NSF funded Project"", ""Our editors will review what you’ve submitted and determine whether to revise the article.Join Britannica's Publishing Partner Program and our community of experts to gain a global audience for your work!\nMutation, an alteration in the genetic material (the genome) of a cell of a living organism or of a virus that is more or less permanent and that can be transmitted to the cell’s or the virus’s descendants. (The genomes of organisms are all composed of DNA, whereas viral genomes can be of DNA or RNA; see heredity: The physical basis of heredity.) Mutation in the DNA of a body cell of a multicellular organism (somatic mutation) may be transmitted to descendant cells by DNA replication and hence result in a sector or patch of cells having abnormal function, an example being cancer. Mutations in egg or sperm cells (germinal mutations) may result in an individual offspring all of whose cells carry the mutation, which often confers some serious malfunction, as in the case of a human genetic disease such as cystic fibrosis. Mutations result either from accidents during the normal chemical transactions of DNA, often during replication, or from exposure to high-energy electromagnetic radiation (e.g., ultraviolet light or X-rays) or particle radiation or to highly reactive chemicals in the environment. Because mutations are random changes, they are expected to be mostly deleterious, but some may be beneficial in certain environments. In general, mutation is the main source of genetic variation, which is the raw material for evolution by natural selection.\nHow are mutations passed to offspring?\nWhy does mutation occur?\nWhat are mutation hotspots?\nThe genome is composed of one to several long molecules of DNA, and mutation can occur potentially anywhere on these molecules at any time. The most serious changes take place in the functional units of DNA, the genes. A mutated form of a gene is called a mutantallele. A gene is typically composed of a regulatory region, which is responsible for turning the gene’s transcription on and off at the appropriate times during development, and a coding region, which carries the genetic code for the structure of a functional molecule, generally a protein. A protein is a chain of usually several hundred amino acids. Cells make 20 common amino acids, and it is the unique number and sequence of these that give a protein its specific function. Each amino acid is encoded by a unique sequence, or codon, of three of the four possible base pairs in the DNA (A–T, T–A, G–C, and C–G, the individual letters referring to the four nitrogenous bases adenine, thymine, guanine, and cytosine). Hence, a mutation that changes DNA sequence can change amino acid sequence and in this way potentially reduce or inactivate a protein’s function. A change in the DNA sequence of a gene’s regulatory region can adversely affect the timing and availability of the gene’s protein and also lead to serious cellular malfunction. On the other hand, many mutations are silent, showing no obvious effect at the functional level. Some silent mutations are in the DNA between genes, or they are of a type that results in no significant amino acid changes.\nMutations are of several types. Changes within genes are called point mutations. The simplest kinds are changes to single base pairs, called base-pair substitutions. Many of these substitute an incorrect amino acid in the corresponding position in the encoded protein, and of these a large proportion result in altered protein function. Some base-pair substitutions produce a stop codon. Normally, when a stop codon occurs at the end of a gene, it stops protein synthesis, but, when it occurs in an abnormal position, it can result in a truncated and nonfunctional protein. Another type of simple change, the deletion or insertion of single base pairs, generally has a profound effect on the protein because the protein’s synthesis, which is carried out by the reading of triplet codons in a linear fashion from one end of the gene to the other, is thrown off. This change leads to a frameshift in reading the gene such that all amino acids are incorrect from the mutation onward. More-complex combinations of base substitutions, insertions, and deletions can also be observed in some mutant genes.\nMutations that span more than one gene are called chromosomal mutations because they affect the structure, function, and inheritance of whole DNA molecules (microscopically visible in a coiled state as chromosomes). Often these chromosome mutations result from one or more coincident breaks in the DNA molecules of the genome (possibly from exposure to energetic radiation), followed in some cases by faulty rejoining. Some outcomes are large-scale deletions, duplications, inversions, and translocations. In a diploid species (a species, such as human beings, that has a double set of chromosomes in the nucleus of each cell), deletions and duplications alter gene balance and often result in abnormality. Inversions and translocations involve no loss or gain and are functionally normal unless a break occurs within a gene. However, at meiosis (the specialized nuclear divisions that take place during the production of gametes—i.e., eggs and sperm), faulty pairing of an inverted or translocated chromosome set with a normal set can result in gametes and hence progeny with duplications and deletions.\nLoss or gain of whole chromosomes results in a condition called aneuploidy. One familiar result of aneuploidy is Down syndrome, a chromosomal disorder in which humans are born with an extra chromosome 21 (and hence bear three copies of that chromosome instead of the usual two). Another type of chromosome mutation is the gain or loss of whole chromosome sets. Gain of sets results in polyploidy—that is, the presence of three, four, or more chromosome sets instead of the usual two. Polyploidy has been a significant force in the evolution of new species of plants and animals. (See also evolution: Polyploidy.)\nMost genomes contain mobile DNA elements that move from one location to another. The movement of these elements can cause mutation, either because the element arrives in some crucial location, such as within a gene, or because it promotes large-scale chromosome mutations via recombination between pairs of mobile elements in different locations.\nAt the level of whole populations of organisms, mutation can be viewed as a constantly dripping faucet introducing mutant alleles into the population, a concept described as mutational pressure. The rate of mutation differs for different genes and organisms. In RNA viruses, such as the human immunodeficiency virus (HIV; see AIDS), replication of the genome takes place within the host cell using a mechanism that is prone to error. Hence, mutation rates in such viruses are high. In general, however, the fate of individual mutant alleles is never certain. Most are eliminated by chance. In some cases a mutant allele can increase in frequency by chance, and then individuals expressing the allele can be subject to selection, either positive or negative. Hence, for any one gene the frequency of a mutant allele in a population is determined by a combination of mutational pressure, selection, and chance.\nLearn More in these related Britannica articles:\nheredity: Gene mutationGiven the complexity of DNA and the vast number of cell divisions that take place within the lifetime of a multicellular organism, copying errors are likely to occur. If unrepaired, such errors will change the sequence of the DNA bases and alter the genetic…\nheredity: MutationGenetics has shown that mutation is the ultimate source of all hereditary variation. At the level of a single gene whose normal functional allele is\nA, it is known that mutation can change it to a nonfunctional recessive form, a. Such “forward mutation” is…\nradiation: Damage to genes (mutations)Gene mutations resulting from radiation-induced damage to DNA have been produced experimentally in many types of organisms. In general, the frequency of a given mutation increases in proportion to the dose of radiation in the low-to-intermediate dose range. At higher doses, however, the frequency…""]"	['<urn:uuid:670c5a8d-fee1-4415-91f5-097b19e606b5>', '<urn:uuid:33f7379f-2295-417d-b2fe-5bd070cc08f3>']	open-ended	with-premise	long-search-query	distant-from-document	multi-aspect	expert	2025-05-01T22:05:01.292488	21	128	1895
121	island museums stockholm vs gainesville attractions	Stockholm features multiple museums across its islands, including the Vasa Museum housing a 17th-century warship, the Museum of Modern Art on Skeppsholmen, and the Nordic Museum for Swedish cultural history. Meanwhile, Gainesville offers the Florida Museum of Natural History with fossil exhibits and a butterfly rainforest, plus Paynes Prairie State Park featuring hiking trails and wildlife viewing.	"[""You'd be hard pressed to find a prettier setting for a capital city than Stockholm, Sweden.\nWith one third of the city's area made up of waterways,\n...it seems like it is part of the sea...\n...And seafaring is certainly in the Swedish blood.\nIt's a city that spreads over 14 islands...\nBut you only need to visit three or four of them to get a real feeling for this Nordic capital.\nThe sea that Stockholm sits next to is the Baltic, but it is actually built on Lake Malaren which flows into the Baltic.\nNorrmalm is the downtown area. The train from the airport arrives here, so this is probably the area where you'll start. The bus depot is in the same building.\nYou'll find lots of hotels and shopping on this island. It's a convenient place to stay, and it's within walking distance to Gamla Stan.\nDon't ignore it though. Wander around here too. Find the flower market. See the Concert Hall.\nGamla Stan is the Old Town. It's a colorful, well preserved tangle of winding, cobble-stoned streets lined with restaurants, antique stores and tourist shops.\nIt's anchored by the Royal Palace.\nYou'll spend much of your time just wandering here.\nYou can watch the Changing of the Guard at the Royal Palace at noon. Tour the Palace itself.\nYou'll find street performers or you may stumble on a school band concert like we did in the small square in front of the Nobel Museum.\nThere are several museums here. There is also an open air folk museum, and an amusement park.\nThe first place you want to head is the Vasamuseet, The Vasa Museum.\nThe Vasa is a well preserved 17th century Swedish warship. She is really beautiful to behold, but she was a sailor's nightmare.... having sunk 20 minutes into her maiden voyage. with several museums, an open air folk museum, and an amusement park.\nIt was probably because she she sank in those shallow, cold and brackish waters that she survived to be raised and put in this museum for us to marvel at.\nThe inside of the Vasa Museum is a photographers nightmare I might add.\nIt is dark in the museum, so we really didn't get any good photos. Sorry for us and for you.\nHow about a photo of the outside of the museum... from the hop-on-hop-off boat... that's the best way to get there.\nAround the corner from the Vasa is an exhibit building that houses old boats including one used by the King for Royal weddings and greeting dignitaries.\nAlso on this island is Skansen, Europe's first open-air folk museum. Today, around 150 traditional and historic houses and buildings have been moved here from all over Sweden.\nIf you have time, you could visit the Nordic Museum to learn about Swedish cultural history. And for the child in you, you could visit the Tivoli Grona Lund amusement park.\nSkeppsholmen is a small island stuck in the middle of these three.\nIt's a traffic-free park with trails and the Museum of Modern Art.\nIf you just want to take a walk in the park... right in the city... this island is for you.\nThe hop-on-hop-off boats stop here.\nYou can arrive by cruise ship right into the heart\nof the city.\nIf you fly in, you will arrive at Arlanda Airport.\nThe fastest way to get into the city is the Arlanda Express train. It's a little expensive, but you can get a two-for-one price on weekends. It effectively whisks you into town in 20 minutes.\nThe Flygbussarna, the airport bus, is half as much, but it takes longer with traffic.\nAirport shuttles are another alternative that will get you right to your hotel if you're staying in Gamla Stan or away from the central train/bus station.\nThe Tourist Office at any point of entry will give you lots of information on where to stay, how to get into town and how to get around. They're very helpful.\nStockholm is a city that invites wandering on foot or getting around on the water with the hop-on-hop-off sightseeing boats.\nYou really should see it from both perspectives... land and sea... because it's such a beautiful combination of both."", 'Rule No. 1 when it comes to fleeing an alligator: Don’t run in a straight line. I learned this while standing feet from a prehistoric-looking, kayak-size animal that had crawled up onto the bank of a canal to bask in the crisp January morning sun.\n“If you have to run, run zigzag,” warned Brack Barker, whom I had hired to show me around Paynes Prairie Preserve State Park in Gainesville. “They can run fast, but only straight ahead.” We’d been walking along a grassy path, Barker slightly in front, and he’d turned around to warn me about a gator hidden in the grasses. I approached slowly and found an abnormally large-headed animal with bumpy skin and closed eyes.\nRule No 2: Don’t forget your grade school science lessons, in which you probably learned that reptiles experience a sort of half-doze called thermoregulation. In plain English, that means they’re not really asleep. So even though this creature was still as a log, I was aware of standing well beyond the suggested wildlife viewing distance and began thinking about zigzagging.\nBut I also couldn’t dismiss the fact that I had come to the park for this very experience. I was traveling through the Southeast, and my friend Jason, a recent transplant from San Francisco, told me Paynes Prairie was filled with wildlife — not only the iconic gators, but also, surprisingly, bison, along with wild horses and cattle descended from those brought over centuries ago by Spaniards.\nNever miss a local story.\nOf course, Gainesville is perhaps best known for the University of Florida Gators. I don’t generally make detours for mascots, but nose-to-snout encounters with wildlife? Sign me up.\nPaynes Prairie is a 20,000-plus-acre park less than 10 miles from the UF campus and downtown Gainesville. The state’s first preserve and a designated National Natural Landmark, the terrain was once home to the saber-toothed cat and, much later, the largest Spanish cattle ranch in Florida.\nToday, it sustains more than 20 distinct biological communities, including more than 270 species of birds. It has campsites and trails for hiking, horseback riding and cycling; because of its wide-open vistas, the park is also a great place to watch sunrises, sunsets and stars.\nThe evening before my tour with Barker, I drove into town, passing ranches, vegetable stands and dogs barking in the flatbeds of pickup trucks. Early the next morning, the air was chilly. I walked around the cabin where I’d stayed and noticed Spanish moss hanging not only from trees but also from telephone wires and street signs, making everything look like it needed a good dusting.\nBarker met Jason and me in the parking lot outside Pearl’s Country Store. A wiry man with a gray beard, Barker wore wire-rimmed glasses and a bandanna around his neck. We drove to Paynes Prairie, stopping along Highway 441 to look out to the land from an observation platform. Standing on the boardwalk, surrounded by cattail and pickerelweed, Barker explained that the park was formed by a number of sinkholes coming together to create the basin tens of thousands of years ago.\n“You’re standing in a giant sinkhole,” he said. “This used to be underwater.”\nIn the late 1800s, the eight-mile-wide prairie was a lake, with fish camps, steamboat charters and barges that transported citrus. Then, suddenly, the sink drained. Just like that. Within days, the prairie went dry — and could do so again anytime. For now, Paynes Prairie has smaller bodies of water that drain underground to recharge the aquifer, a giant reserve used for drinking water.\nWe drove to the northern side of the park, passing a turtle-crossing sign and some ancient live oaks. La Chua Trail is among the park’s most popular because of wildlife sightings. As we followed the trail along the water, Barker pointed out birds: the anhinga, spreading its impressive wings to warm in the sun; the red-legged white ibis, picking around in the wet ground for snails and frogs; and the great black cormorant, jockeying an uncooperative fish into its beak.\nWe saw our first gators lined up along the water line, their short legs half submerged — as when humans drag beach chairs to sit in the sand right where the surf breaks. Through binoculars, I studied their graceless, cartoon-character bodies and rows of stubby teeth.\nBarker, an anthropologist who used to work for the Florida Park Service and St. Augustine Alligator Farm, dropped gator tidbits — like the fact that males bellow during mating season to set their territory. The total inches between the alligator’s eyes and snout equal the length of the body in feet, he explained, putting some of our specimens at well over eight feet.\nA few times, we wouldn’t see an alligator nestled in the grasses until we were nearly on top of it. One was only five feet away, its eyes open and it feet moving in slow motion as though it were stretching after a nap.\nWe stopped under overcast skies and listened to the cacophony of squawks, squeaks, caws and chattering. Birds landed on the water like water-skiers, splashed and dove under for fish, flapped their wings, waded and frolicked. All the activity looked and sounded like that of kids swimming in a massive pool. Paynes Prairie was putting on quite a show.\n“The coots are on the march,” Barker said, pointing to countless small birds creating a commotion in the water. He identified the little blue heron, belted kingfisher and mockingbird. We even heard the trumpeting of the beloved sandhill crane. “It’s a bird-watcher’s dream today,” he said.\nAlthough we passed piles of horse manure and hoof prints, we saw no similar signs of bison. Like most visitors, I was surprised to learn that bison roam in a state better known for spring training and Mickey Mouse. But fossils show that they once grazed in north central Florida.\nPark officials decided to import 10 from Oklahoma in 1975, and — with no natural predators — the herd grew, inevitably causing problems such as escapees to the suburbs. So a few years ago, the park culled the herd, removing the males and creating yet more controversies. Today about 50 bison roam the prairie, but they remained elusive on our walk.\nAs we retraced our steps on the trail, we counted 33 alligators. Jason even spied one underwater. “You’ve got a good eye,” I said, squinting to find the animal.\n“I’m getting good gator-dar,” he said, straight-faced.\nJason and I bid farewell to Barker, and we drove to Blue Highway, just outside the park, for lunch. On the radio, I tuned into an AM station that ran a 1950s-sounding promotional loop for Paynes Prairie. A scratchy voice proclaimed, “As wild as the Everglades, but easier to see and experience!”\nLater, I walked on a few trails by myself and realized my sense of place had been completely upended. All day, I’d forgotten I was in Florida. The wide-open prairie made me think of the Great Plains, and the Spanish moss and pickups reminded me of the Deep South. Each instance of remembering my whereabouts was a burst of delight — the type of travel surprise I welcome.\nAs I walked on the pine-needle-and-sand trail, the sun began relaxing into the horizon, and the temperature dropped quickly. I headed back toward my car, mindfully zigzagging, just in case.\nGoing to Gainesville\nGetting there: American Eagle flies nonstop from Miami to Gainesville, a flight of about 1 1/4 hours, with round-trip airfare starting around $260. There are no nonstop flights from Fort Lauderdale, but Delta and Silver offer trips with a connecting flight and travel time under four hours, starting around $290 roundtrip. Gainesville is a 335-mile drive from Miami, most of it along Florida’s Turnpike.\nWHERE TO STAY\nHerlong Mansion, 402 NE Cholokka Blvd., Micanopy; 352-466-3322; www.herlonginn.com. A cracker-style pine farmhouse built in 1845, the mansion now has bright rooms with decks and claw-foot tubs. Rooms from $119, including a full Southern breakfast.\nTwin Lakes Fish Camp, 17105 S. County Rd. 325, Hawthorne; 352-466-3194; www.twinlakesfishcamp.com. Rustic four-person cabins, $91 per night. Guests can check out canoes at no charge; pontoon rentals $110 daily.\nHilton Garden Inn Gainesville, 4075 SW 33rd Pl., Gainesville; 352-338-1466; www.hiltongardeninn.com. Located across from the UF campus and near the Florida Museum of Natural History, with fitness center and free Wi-Fi. Standard rooms start at $139.\nWHERE TO EAT\nSouthern Charm Kitchen, 1714 SE Hawthorne Rd., Gainesville; 352-505-5553; www.facebook.com/southerncharmkitchen. Soul-food heaven, with equally heavenly vegan options and substantial sides. Pentecostal fried chicken, $9.95; spicy corn waffle with Cajun shrimp, $13.50; pickled watermelon tofu, $11.95.\nBlue Highway, 204 NE U.S. Hwy. 441, Micanopy; 352-466-0062; www.bluehighwaypizza.com. Just outside Paynes Prairie. Salads, sandwiches and pizzas with local produce. Funghi pizza with portabello, shiitake, fancy white and oyster mushrooms on a thin crust, $13.50.\nThe Yearling Restaurant, 14531 E. County Rd. 325, Hawthorne; 352-466-3999; www.yearlingrestaurant.net. Old-Florida fare, open for lunch and dinner Thursday to Sunday. Offerings include alligator, frog legs, quail, “cooter” (land turtle) and catfish, entrees $13.95-$31.95.\nWHAT TO DO\nPaynes Prairie Preserve State Park, 100 Savannah Blvd., Micanopy; 352-466-3397; www.floridastateparks.org/park/Paynes-Prairie. The 50-foot observation tower reopens after repairs in March. Admission $6 per vehicle, $2 pedestrians and cyclists. Guided wildlife walk, $2; half-day hike, $5; overnight camping trip and hike, $15.\nWild Florida Adventures, 352-215-4396; www.wild-florida.com. Explore northern Florida and view wildlife by kayak or foot with guide Brack Barker. Half-day kayak tours, including manatee-viewing tours and sunset/moonrise tours, $50; beginners welcome. Paynes Prairie walking tours, $10.\nFlorida Museum of Natural History, UF Cultural Plaza, SW 34th Street & Hull Road, Gainesville; 352-846-2000; www.flmnh.ufl.edu. Thousands of Florida specimens and artifacts, including a fossil plant garden and butterfly rain forest. “A T.rex Named Sue,” featuring a 42-foot dino skeleton cast, on display through Sept. 13. Admission free; fees for some exhibits.']"	['<urn:uuid:806ebbc5-8607-403c-84ff-bf19ddad14ab>', '<urn:uuid:9a98edde-e215-4f69-8af3-f673eaee54dd>']	factoid	direct	short-search-query	similar-to-document	multi-aspect	expert	2025-05-01T22:05:01.292488	6	57	2346
123	prehistoric ice age animals survival how did life continue during global freeze	During the Snowball Earth period, life managed to survive despite the challenging conditions because sea ice would have been moving and forming patches of open water. These open patches would have provided good places for life to survive, ensuring access to necessary sunlight and water. The evidence shows that primitive sponge-like creatures were able to exist in ocean reefs during this time, indicating that the ocean was not entirely covered with ice.	"['There are two ideas about how glaciers formed on Earth between about 717 and 630 million years ago – a time known as “Snowball Earth”. The idea that at least two long glaciations happened during which communication between the ocean and the atmosphere was cut off (described in the top half of this image) is more likely based on the evidence we have today. In this scenario, the Earth was ice-free at 670 and 630 million years ago because carbon dioxide built up in the atmosphere.\nClick on image for full size\nCredit: Zina Deretsky, National Science Foundation\nScientists Find Signs of “Snowball Earth” Amidst Early Animal Evolution\nThere used to be sea ice floating on the tropical ocean, according to new evidence found by geologists. This was quite a long time ago, 716.5 million years ago, during a time known as Snowball Earth.\nThis chilly time was among the greatest ice ages known to have taken place on Earth. Ice formed all over the planet, even in the tropics. It was in this frozen world that scientists believe the first animals evolved.\nThe geologists studied ancient tropical rocks and found evidence that ice was floating in the sea at the time when they formed. These rocks formed in the tropics long ago, but today they are located in a remote area of northwestern Canada thanks to the continent-moving abilities of plate tectonics. Based on magnetic information and the minerals in these rocks, scientists know that they used to be located at sea level in the tropics, just north of the equator.\nOf course, scientists can’t find ice preserved in rocks. So how did they figure out that it was icy near the equator? They found evidence of ice in the rocks that is like a footprint that ice used to be there. This evidence includes pieces of rock that have been gouged by glaciers and pieces of rock that were carried out to sea within ice and then dropped to the seafloor as the ice melted.\nA world covered with snow and ice must have been a challenging place to live. But life did survive during this time. This suggests that sunlight and water, which are needed by living things, were available somewhere on Earth. So the ocean could not have been entirely covered with ice. The geologists say that sea ice would have been moving and forming patches of open water. These open patches would have provided good places for life to survive.\nAccording to the fossil record, all of the major groups within the Domain Eukaryota (except perhaps animals) existed before the ice formed. Scientists have a hypothesis that the cooling climate during Snowball Earth may have allowed animals to evolve. In face, times of stress in environments are thought to prompt new species to evolve.\nScientists don\'t know exactly what caused the glaciers to form or what caused them to melt, but there is evidence that at about the same time lots of volcanic eruptions were happening. This could mean the cold “Snowball Earth” time was either formed by, or ended by, volcanic activity.\nShop Windows to the Universe Science Store!\nLearn about Earth and space science, and have fun while doing it! The games\nsection of our online store\nincludes a climate change card game\nand the Traveling Nitrogen game\nYou might also be interested in:\nSea ice is frozen seawater. It can be several meters thick and it moves over time. Although the salts in the seawater do not freeze, pockets of concentrated salty water become trapped in the sea ice when...more\nThe main force that shapes our planet’s surface over long amounts of time is the movement of Earth\'s outer layer by the process of plate tectonics. This picture shows how the rigid outer layer of the...more\nMinerals are the building blocks of rocks. They are non-living, solid, and, like all matter, are made of atoms of elements. There are many different types of minerals and each type is made of particular...more\nMeasuring sea level, the height of the ocean surface, allows scientists to calculate whether sea level is changing over time and how much sea level rise is happening now because of global warming. But...more\nFrozen water is found in many different places on Earth. Snow blankets the ground at mid and high latitudes during winter. Sea ice and icebergs float in the chilly waters of polar oceans. Ice shelves fringe...more\nFor a glacier to develop, the amount of snow that falls must be more than the amount of snow that melts each year. This means that glaciers are only found in places where a large amount of snow falls each...more\nScientists have learned that Mount Hood, Oregon\'s tallest mountain, has erupted in the past due to the mixing of two different types of magma. ""The data will help give us a better road map to what a future...more', 'Possible discovery of earliest animal life pushes back fossil record\nIn findings that push back the clock on the scientific world\'s thinking about when animal life appeared on Earth, Princeton scientists may have discovered the oldest fossils of animal bodies, suggesting that primitive sponge-like creatures were living in ocean reefs about 650 million years ago. The shelly fossils, found beneath a 635 million-year-old glacial deposit in South Australia, represent the earliest evidence of animal body forms in the current fossil record by at least 70 million years.\nPreviously, the oldest known fossils of hard-bodied animals were from two reef-dwelling organisms that lived about 550 million years ago -- Namacalathus, discovered in 2000 by John Grotzinger\'s group at the Massachusetts Institute of Technology, and Cloudina, first found in 1972 by Gerard Germs of the University of Cape Town, South Africa. Additionally, there are controversial fossils of soft-bodied animals that date to the latter part of the Ediacaran period between 577 and 542 million years ago. These fossils were first observed in the 1940s by Australian geologist Reginald Sprigg, and the oldest evidence to date of undisputed Ediacaran animals -- organisms called Kimberella -- was found in sediment about 555 million years old in Australia and Russia.\nPrinceton geosciences professor Adam Maloof and graduate student Catherine Rose happened upon the new fossils while working on a project focused on the severe ice age that marked the end of the Cryogenian period 635 million years ago. Their findings, published in the Aug. 17 issue of the journal Nature Geosciences, provide the first direct evidence that animal life existed before -- and probably survived -- the severe ""snowball Earth"" event known as the Marinoan glaciation that left much of the globe covered in ice at the end of the Cryogenian.\n""We were accustomed to finding rocks with embedded mud chips, and at first this is what we thought we were seeing,"" Maloof said. ""But then we noticed these repeated shapes that we were finding everywhere -- wishbones, rings, perforated slabs and anvils. By the second year, we realized we had stumbled upon some sort of organism, and we decided to analyze the fossils. No one was expecting that we would find animals that lived before the ice age, and since animals probably did not evolve twice, we are suddenly confronted with the question of how some relative of these reef-dwelling animals survived the \'snowball Earth.\'""\nFind viewed as significant\n""These scientists have found that animals may have appeared on Earth 90 million years earlier than previously known,"" said H. Richard Lane, program director for the Directorate for Geosciences of the National Science Foundation\'s Division of Earth Sciences, which funded the research. ""This is comparable to resetting modern times to begin during the late Cretaceous.""\nAnalyzing the fossils turned out to be easier said than done, as the composition and location of the fossils made it such that they could not be removed from the surrounding rock using conventional techniques, nor could they be imaged using X-ray scanning techniques. This is because X-rays are only able to distinguish between materials with different densities, which is why they can be used to image bones that are inside the human body or buried within a rock. But the most ancient skeletal fossils are made not of bone, but of calcite -- the same material that makes up the rock matrix in which they are embedded. Therefore X-rays could not be used to ""illuminate"" the newly discovered fossils and the researchers had to develop and refine another method.\nMaloof, Rose and their collaborators teamed up with professionals at Situ Studio, a Brooklyn-based design and digital fabrication studio, to create three-dimensional digital models of two individual fossils that were embedded in the surrounding rock. As part of the process, team members shaved off 50 microns of sample at a time -- about half the width of a human hair -- and photographed the polished rock surface each time. The team ground and imaged nearly 500 slices of the rock.\nUsing specialized software techniques developed specifically for this project, the researchers then ""stacked"" the outlines on top of one another to create a complete three-dimensional model of the creature. The technique is similar to the way in which CAT scan technology combines a series of two-dimensional X-rays to create a three-dimensional image of the inside of the body. The technique that was developed served to automate the process -- turning a prohibitively time-consuming task into an efficient and effective method for fossil reconstruction.\n""For Situ Studio, the most exciting aspect of this collaboration is that we were able to successfully employ knowledge developed within an architectural practice to help solve problems in an entirely different field -- applying design tools to spatial problems on a completely different scale,"" said Bradley Samuels, a founding partner of Situ Studio. ""It became an exercise in marrying disparate bodies of knowledge to address pressing questions in the geosciences.""\nWhen they began the digital reconstruction process, the shape of some of the two-dimensional slices made the researchers suspect they might be dealing with the previously discovered Namacalathus, a goblet-shaped creature featuring a long body stalk topped with a hollow ball. But their model revealed irregularly shaped, centimeter-scale animals with a network of internal canals.\nThese critters looked nothing like Namacalathus.\nAfter considering a variety of alternatives, the researchers decided that the fossil organisms most closely resembled sponges -- simple filter-feeding animals that extract food from water as it flows through specialized body channels. Previously, the oldest known undisputed fossilized sponges were about 520 million years old, dating to the Cambrian Period.\nBut evidence has suggested that sponges appeared on the scene much earlier in Earth history. For example, scientists have conducted detailed analyses of genetic material in a wide range of organisms to create ""molecular clocks"" that suggest how long ago a given species evolved. According to these clocks, sponges existed millions of years before the Cambrian. This has been supported by the relatively recent discovery of lipid biomarkers -- essentially, traces of recalcitrant fats that resist degradation over millions of years -- in sedimentary rocks from Oman of nearly the same age as those studied by the Maloof group in Australia.\n""For many years the great Marinoan ice age has formed a hard floor to the fossil record of animals, even though most molecular clocks suggest a deeper history, at least for sponges,"" said evolutionary biologist Andrew Knoll of Harvard University, who was not part of the research team. ""Adam and his students are digging deeper and finding that there is much to catch our attention in pre-glacial carbonate rocks … . I\'m convinced that the structures Adam\'s group have found are not simply shards of material, formed and deposited by purely physical processes. That said, it isn\'t easy to be sure what they are. Adam\'s group has carefully spelled out the biological alternatives and built a reasonable case for interpreting the structures as sponge-like animals. At the very least, this should drive paleontologists back to the field to seek similar or better evidence in other rocks of comparable age.""\nIn future research, Maloof and his collaborators intend to refine the three-dimensional digital reconstruction technique to automate and increase the speed of the process. This could have a significant impact on paleontology, enabling the analysis of myriad early fossils that are currently inaccessible to the tools of modern science.\nIn addition to Maloof and Rose, Princeton researchers on the team included geosciences professor Frederik Simons, former postdoctoral fellow Claire Calmet, Nan Yao, the director of the Imaging and Analysis Center in the Princeton Institute for the Science and Technology of Materials (PRISM), and PRISM senior research specialist Gerald Poirier. The team also included Douglas Erwin of the Smithsonian Institution and Samuels, Robert Beach, Basar Girit, Wesley Rozen, Sigfus Briedfjord and Aleksey Lukyanov of Situ Studio. The work was funded by the National Science Foundation.']"	['<urn:uuid:f8a3b38b-a438-4913-8118-f1de8e965c46>', '<urn:uuid:149df4eb-afb6-40a2-afe7-60e2cdd2584f>']	factoid	with-premise	long-search-query	distant-from-document	multi-aspect	novice	2025-05-01T22:05:01.292488	12	72	2137
125	How do tax benefits differ between hybrid arbitrage funds and municipal bonds?	Hybrid arbitrage funds and municipal bonds offer different types of tax advantages. Arbitrage funds provide tax efficiency with returns from arbitrage opportunities being taxed at a lower rate compared to regular equity funds. In contrast, municipal bonds offer more comprehensive tax benefits, with interest typically being exempt from federal income taxes. Additionally, municipal bonds may provide triple-tax-free benefits (federal, state, and local) for investors residing in the issuing state or locality. For example, a New York City bond would be triple-tax-free for a New York City resident.	"['Investing can be a complex and often intimidating endeavor, especially for those new to the world of finance. However, among the many investment options available, hybrid funds have gained popularity as a middle-ground solution for those seeking a balance between risk and returns. In this article, we will explore what hybrid funds are and how they work, shedding light on their potential benefits and risks.\nWhat Are Hybrid Funds?\nHybrid Funds makes an amalgamation of the elements of both equity and debt securities in a single portfolio. Moreover, these funds are designed to offer you a diversified mix of assets, aiming to form a balance between potential returns and risk. Also, they are commonly referred to as balanced funds because of their balanced approach to investment.\nHow Do Hybrid Funds Work?\nHybrid funds work by pooling money from multiple investors and investing it in a mix of asset classes, primarily equities and debt instruments. Moreover, the specific allocation between equities and debt is determined by the fund’s investment strategy, which can vary from one hybrid fund to another.\nWhat Are The Types Of Hybrid Funds?\nHybrid funds come in several variations, each with its own risk-return profile. Understanding the different types is essential to make an informed investment decision:\n1. Conservative Hybrid Funds:\nThe Conservative hybrid funds, are also known as debt-oriented hybrid funds, primarily invest in debt securities with a smaller allocation to equities. They are suitable mostly for investors looking for stability and income generation, as they have lower exposure to equity market fluctuations.\n2. Balanced Hybrid Funds:\nBalanced hybrid funds maintain a balanced allocation between equity and debt. These funds are designed to provide a mix of capital appreciation and income generation. They are ideal for investors seeking a moderate level of risk and returns.\n3. Aggressive Hybrid Funds:\nThese funds, known as balanced funds, allocate a significant portion of their portfolio to equities. At the same time, they aim for higher capital appreciation. However, they also include debt instruments to reduce risk. These funds are suitable for investors with a higher risk tolerance.\n4. Dynamic Allocation of Asset Funds:\nThese funds have a flexible approach to asset allocation. They adjust their equity-debt ratio based on market conditions and valuations, aiming to capture opportunities and minimize risk.\n5. Arbitrage Funds:\nArbitrage funds exploit price differentials in the cash and derivative markets. They primarily engage in arbitrage opportunities and invest a small portion in debt securities for stability. These funds are tax-efficient and low on risk.\nWhat Are The Benefits Of Hybrid Funds?\nHybrid funds offer several advantages that make them appealing to a wide range of investors:\nHybrid funds offers diversification across different asset classes, and they reduce the risks that are associated with investing in a single asset class. This diversification helps to spread risk and enhance stability.\n2. Risk Management:\nThe combination of equity and debt in hybrid funds helps in managing risk. At the same time, the debt component provides stability, while the equity component offers the potential for higher returns.\nInvesting in hybrid funds is relatively simple, making them suitable for beginners in the world of investments. Professional fund managers handle the asset allocation, allowing you to benefit from their expertise.\nHybrid funds offer liquidity as you can buy and sell units at net asset value (NAV) on any business day. This provides flexibility in managing investments.\n5. Tax Efficiency:\nCertain hybrid funds, like arbitrage funds, offer tax efficiency. The returns from arbitrage opportunities are taxed at a lower rate compared to regular equity funds.\nRisks And Considerations\nWhile hybrid funds offer diversification and balance, you should be aware of the potential risks and considerations:\n1. Market Risk:\nInvestments in these funds are subject to market fluctuations. Changes in equity and debt markets can impact the fund’s NAV.\n2. Fund Manager’s Strategy:\nThe fund’s performance is heavily dependent on the fund manager’s strategy.\n3. Expense Ratio:\nBe aware of your expense ratio, higher expenses can impact your profits. It’s important to compare expenses across different hybrid funds.\n4. Tax Implications:\nCertain funds, like arbitrage funds, offer tax efficiency. At the same time, the returns from arbitrage opportunities are taxed at a lower rate compared to regular equity funds.\n5. Investment Horizon:\nConsider your investment horizon. Hybrid mutual funds are best suited for medium to long-term investors who can ride out market volatility.\nThese funds provide a balanced and diversified approach to investing, making them a valuable option for those who seek a combination of stability and returns. However, like all investments, they come with their own set of risks and considerations. Before investing in them, it’s crucial to assess your financial goals, risk tolerance, and investment horizon.\nAdditionally, research and due diligence are vital to selecting the right hybrid fund that aligns with your objectives. With proper planning and a clear understanding of how hybrid funds work, you can potentially benefit from a well-rounded investment strategy.', '- What are tax-free investments?\n- What different types of municipal securities are available to investors?\n- What factors should investors consider when choosing between taxable and tax-exempt securities?\n- Are there risks associated with municipal securities?\n- How can investors gain exposure to tax-free investments in their portfolios?\n- What are the benefits of tax-free mutual funds?\n- Are there drawbacks to tax-free mutual funds?\n- Who should consider tax-free investments?\nState and local governments around the country issue a large quantity of debt securities to raise needed capital. The majority of these securities—often referred to as municipal bonds or simply ""munis""—provide investors with interest that is exempt from federal income taxes. This income may also be exempt from state and local taxes for investors who reside in the issuing state or locality. A New York City bond, for example, would be triple-tax-free (i.e., exempt from federal, state, and local taxes) for an investor living in New York City. Because of this tax exemption, the terms ""tax-free investments"" and ""municipal investments"" are often used interchangeably.\nGeneral obligation bonds (GOs) and revenue bonds are two major classes of municipal securities differentiated by the source of funding for their interest payments. GOs are issued to finance various government operations and are backed by the issuer\'s power to raise taxes, if necessary, to make scheduled interest and principal payments. Revenue bonds, meanwhile, finance specific projects, such as transportation and utilities, and are backed by the revenue generated from the projects. Due to their potentially variable cash flows, revenue bonds are often considered riskier than GOs.\nIn addition, municipalities sometimes issue securities to help finance private development considered beneficial to local economies. The income from these ""private activity"" bonds is exempt from federal income tax but may be subject to the alternative minimum tax.\nMunicipal securities are issued for a wide variety of purposes and, as such, have varying maturities and yields. Many munis are short-term notes issued in anticipation of pending tax receipts or other revenues. These money market securities generally offer low yields due to their short maturities. Major projects, on the other hand, tend to be funded by longer-term bonds offering higher yields. In either case, coupon payments may be fixed or tied to a floating interest rate that resets periodically.\nDue to the potential tax advantage, investors typically accept lower yields from munis than they would from similar taxable securities. Because of this yield differential, one\'s tax status plays a major factor in the attractiveness of tax-free investments. While municipal securities could benefit investors in any tax bracket, they tend to appeal the most to those who are in the highest tax brackets or live in high-tax jurisdictions.\nA simple way to gauge whether investing in a given municipal security would be more attractive than investing in a comparable taxable security is to calculate its equivalent taxable yield. This can be done in three steps:\n|(1)||Find the current yield of the tax-free investment you are considering (e.g., 5%).|\n|(2)||Subtract your federal tax bracket, expressed as a decimal, from 1.0\n(e.g., 1.0 – 0.25 = 0.75).\n|(3)||Divide the tax-free yield in step 1 by the number obtained in step 2\n(e.g., 5% ÷ 0.75 = 6.67%).*\nIn this example, an investor in the 25% tax bracket would need a taxable security yielding at least 6.67% to receive the same amount of income, after the deduction of federal taxes, as a tax-exempt security yielding 5%. If no such taxable security is available, the tax-free security would be the better option. Of course, investors should make sure to compare securities with similar risk attributes such as credit quality and time to maturity.\nIn addition, the decision to invest in tax-free securities should be made in the larger context of maintaining a diversified portfolio of stocks and bonds that is in line with your risk tolerance, time horizon, and investment objectives. Also bear in mind that tax-free securities typically are not appropriate for inclusion in tax-deferred accounts such as IRAs.\nLike other types of fixed income securities, munis are subject to interest rate and credit risk. Interest rate risk is the potential for price fluctuations due to changes in interest rates—as interest rates rise, bond prices fall (and vice versa). In general, the longer a bond\'s maturity, the more sensitive its price will be to interest rate movements.\nCredit risk is the possibility that the security issuer will not be able to make scheduled interest or principal payments. Although municipal bond defaults historically have been rare events, a weak local economy and reduced tax revenues could present serious challenges for a state or local government\'s finances. To gauge credit risk, the major credit rating agencies grade municipal bonds\' credit qualities in a similar manner to corporate bonds. A downgrade to a bond\'s credit rating could result in a lower bond price and a higher yield to compensate for the additional risk.\nOther municipal market risks include liquidity risk—or the ability to easily sell a security, if needed, at a desired price—and uncertainty about future tax laws. In addition, some income may be subject to the federal alternative minimum tax.\nYou can purchase municipal bonds through a broker or bond dealer. Another option is to invest in a mutual fund focused on municipal securities. Many large fund companies offer tax-free bond and money funds for investors nationwide as well as funds targeted to residents of certain states. Funds may also focus on specific credit-quality or maturity segments of the municipal market.\nA major benefit of mutual funds is diversification. When buying individual bonds, it may be difficult to develop a portfolio that has a sufficiently diverse range of holdings to reduce the impact of losses on individual securities. Tax-free mutual funds—even those investing in a single state—often hold dozens of different issuers and types of securities. Of course, diversification cannot assure a profit or protect against loss in a declining market.\nMutual funds also have professional managers and municipal analysts who perform the essential credit research and security selection processes that would be time-consuming and impractical for most individuals to do on their own. Funds also provide liquidity by allowing investors to easily sell all or a portion of their shares at the day\'s closing market price, often without the transaction costs associated with individual bonds. Finally, many fund companies offer conveniences such as automatic dividend reinvestment and checkwriting.\nA downside to municipal funds is that they do not have fixed coupons or maturity dates like individual bonds. Thus, there is less certainty about future income. With an individual bond, an investor knows—barring a default or the early retirement of a bond with a call option—the timing and amount of cash flows.\nAnother downside to municipal funds is the possibility of taxable capital gain distributions. Although investors in individual bonds may be subject to capital gains taxes if they sell municipal securities above their purchase price, they have greater control over the distribution decision.\nInvestors should also carefully compare a mutual fund\'s annual expense ratio, which is expressed as a percentage of fund assets, with the costs and fees they would incur from purchasing individual muni bonds.\nInvestors often overlook municipal securities when building a portfolio. Due to the potential for lower investment taxes and regular income, investors in every tax bracket should consider whether munis are a good fit for the fixed income portion of their portfolios. This is especially true when there are expectations for tax rates to rise.\n*A more precise approach is to also consider state and local taxes that are deductible at the federal level. To do this, subtract your combined state and local tax rate, expressed as a decimal, from 1.0, and then multiply the result by the number obtained in step 2. Finally, divide the tax-free yield in step 1 by the product of the two numbers.']"	['<urn:uuid:bc97bf5e-3d3d-48cb-8455-199fd220bd98>', '<urn:uuid:c1ef5665-9098-4dc3-b504-940acc5c0558>']	open-ended	with-premise	concise-and-natural	distant-from-document	comparison	expert	2025-05-01T22:05:01.292488	12	87	2133
129	head lice life cycle how many days until mature adults capable crawling between hosts	After hatching from eggs, head lice take 6 to 10 days to mature into adults that are capable of crawling from one host to another.	['Yes, the hair is indeed our crowning glory. But not when we are often scratching and having a persistently itchy scalp. This article aims to tackle such a problem, what can cause this itchiness, and how one can deal with it.\nThe scalp actually has 5 distinct anatomic layers: the skin, close connective tissue with its cutaneous nerves and vessels, epicranial aponeurosis, loose connective tissue, and the pericranium. [1, 2, 3]\nAn illustration showing the layers of the scalp.\nBeing thick, the skin is the layer from which the scalp hair grows. It is abundant in blood vessels and sebaceous glands.\n2. Close Connective Tissue\nIt consists of layers of fat and fibers, lying underneath the skin. Sometimes called superficial fascia, this layer provides a passageway for nerves and blood vessels.\n3. Epicranial aponeurosis\nAs a layer of tendons, this provides insertions for the occipitofrontalis muscles. It also allows fluid and blood to pass from the scalp to the upper eyelids.\n4. Loose Connective Tissue\nThis layer separates the upper three layers from the pericranium. Emissary blood vessels also navigate through this layer, linking the diploic veins and intracranial venous sinuses to the scalp veins.\nConsidered as the cranial bones’ periosteum, this layer provides nourishment to the bone and the ability to repair.\nWithin these layers exist cells, collagen and elastic fibers, blood vessels, sweat glands, oil glands, adipose and muscles. These all work together to perform the scalp’s functions, which is to enable breathing of the skin, exocrine secretions, temperature regulation, control of water loss, and protection against bacteria and other microorganisms. Any abnormality of these structures can produce deviations from the skin’s normal functions and thus cause symptoms such as scalp itching. \nWhat Causes Itching of the Scalp?\nA pruritic scalp is usually brought about by either infection, lack of moisture, inflammation, or even anxiety. The more common roots of itching include the following:\nParasitic Infection: Head Lice\nPediculosis capitis, more commonly known as head lice, are one of the most common reasons for an itchy scalp. These parasites are usually 2-3 millimeters in length, swarming the head, and affixing their eggs at the foot of the hair shaft. These usually cause severe itching of the scalp and are usually transmitted by direct person to person contact. [ 5, 6]\nA female head louse places its ova on the hair, attaching them to the shafts. A week after, these lice hatch and the nits remain, growing more obviously as the hair lengthens. These lice nourish themselves by feeding on the host’s blood. After 6 to 10 days, they mature in to adults, capable of crawling from one host to another. Hence, further pruritus prevails, provoking one’s need to scratch. \nAn image showing an adult head louse, causing an itchy scalp.\nA photo of a patient with visible nits on the hair shafts.\nThis is usually caused by skin or scalp contact to chemicals such as dyes, shampoos, conditioners and other cosmetics. These substances may either cause skin irritation or allergic reactions. They are usually presented as skin itching, causing erythematous lesions from relentless scratching. Succeeding use of the irritant can induce crusting, scaling and more profuse itching of the scalp. Thus, recognition of the allergen or irritant substance, and its avoidance must be done. [5, 8]\nA subject with an itchy scalp due to contact dermatitis from use of a new shampoo.\nA fungal infection brought about by Malassezia furfur, this is a common scalp condition, mostly occurring after the adolescent stage of childhood. The infected person constantly scratches his scalp, which sheds off whitish silver scales. [5, 8, 9]\nIf affected with dandruff, the cell turnover of the scalp is faster than normal. Skin cells of the scalp mature and are discarded every 2 to 7 days. This results in large, oily, dead skin cells in clumps, what we usually see as dandruff. [9, 10]\nThis is often influenced by sebum or sebaceous secretions, metabolic derivatives of skin inhabitants such as Malasezzia, and one’s susceptibility. [11, 12, 13]\nAn image showing fungal infection of the scalp, or dandruff.\nPsoariasis is an autoimmune illness producing erythematous, elevated, scaly skin lesions, usually at the scalp, knees and elbows. The skin may appear thickened and pruritic, but may bleed when their scales are rubbed off. \nIn this illness, an inflammation of the skin is triggered by the immune system, enabling a more rapid skin cell turnover as fast as 3 to 4 days. The upsurge of old cells being substituted by the new ones produces the silver scales, as seen in psoriasis. [15, 16]\nAn image depicting psoriasis of the scalp, with its characteristic silvery white scales.\nSource : www.noskindiseases.com\nRingworm of the Scalp\nScalp ringworm infection is brought about by the fungus Tinea capitis. Usually affecting the hair shaft and the scalp, the illness is contagious, particularly among toddlers and preschool children. \nAside from scalp itching, hair loss and a scaly skin lesion may also be present. If severe, a swollen mass with pus discharge may be visible on the scalp, which may be a bit tender. \nScalp infected with Tinea capitis, having ringworm infection of the scalp.\nAlso known as Proprionibacterium foliculitis and acne necrotica miliaris, scalp folliculitis are characterized by inflamed hair follicles of the scalp. It is usually brought about by the bacteria Propionibacterium and Staphylococcus, the fungal Malassezia, and mites Demodex. It is commonly presented as small, pruritic pustules on the scalp. When scratched, they can become uncomfortable and crusted. [19, 20]\nAn image showing scalp folliculitis, with inflamed hair follicles at the scalp.\nThis is a condition in which one experiences pruritus even without any physical stimuli, except anxiety. Studies have been made showing that skin sensitivity and stress reactions may further aggravate anxiety and induce itchiness of the scalp. [21, 22]\nIt often produces a cycle of repeated itch–scratch-itch episodes. This causes hyperpigmentation and production of scars. It is also thought to be influenced by nerve stimulation, which eventually lead to irritation of the skin. \nHow to Deal With An Itchy Scalp: The Treatment Options\nTreatment of scalp itching is based on the root and origin of the pruritus. [5, 8, 16]\nPediculosis capitis, or head lice, are usually treated with medications such as Permethrin, Malathion and Benzyl alcohol lotions and shampoos. These agents eradicate either the lice, the nits, or both. They are usually done repeatedly for 7 to 9 days for more complete and thorough treatment results.\nThe main treatment for contact dermatitis is still prevention and avoidance in using the irritant causing the allergic reaction to the scalp. Application of a topical corticosteroid can also be done as management.\nDandruff can be treated using shampoos with zinc pyrithione, ketoconazole and selenium sulfide as components. These agents do not only eliminate fungi, but also control skin cell production. If severe infections are at hand, steroids like betamethasone can also be prescribed.\nIn managing psoriasis, medicated shampoos and creams with tazarotene, coal tar, salicylic acid and calcipotriene can be utilized. Oral medications may also be of use, particularly the retinoids, steroids, methotrexate, cyclosporine and monoclonal antibodies.\nTinea capitis infections, or ringworms, can be treated using antifungals like ketoconazole, itraconazole, terbinafine, fluconazole and griseofulvin. They may be given as shampoos or taken orally.\nFolliculitis of the scalp usually resolve spontaneously after 2 weeks. However, if persistent, Burow’s solution or medicated shampoos may be used.\nAntihistamines and anti anxiolytics can be used to manage neurodermatitis. This does not only control itching, but can alleviate anxiety attacks as well. Thus, preventing further itching and stopping the itch-scratch- itch cycle.\nPreventing Itchy Scalp\nIn preventing itching of the scalp, one must be reminded of the following: \n- Brush the hair 2 to 3 times daily to disseminate natural oil\n- Change your hair product every two weeks to remove any build up caused by the previously used shampoos and conditioners.\n- Use a conditioner to add shine, and invigorate nutrients and fibers\n- Avoid products containing alcohol, to prevent further drying of the hair and scalp\n- Dry the hair thoroughly\n- Try to check for the presence head lice occasionally\n- Avoid too much sun exposure to prevent drying of hair and scalp, and thus eliminate itching as well.\n- Avoid too much stress\n- Try to consume 8 to 10 glasses of water per day\n- Vitamin E supplementation advised\n- Consult a physician if such symptoms are noticed\n- De Angelis, Y, et al. Three Etiologic Facets of Dandruff and Seborrheic Dermatitis; Malassezia fungi, Sebaceous Lipids, and Individual Sensitivity. Journal of Investigative Dermatology Symposium Proceedings. 2005; 10 (3): 295-7.\n- Ro, B, et al. The Role of Sebaceous Gland Activity and Scalp Microfloral Metabolism in the Etiology of Seborrheic Dermatitis and Dandruff. Journal of Investigative Dermatology Symposium Proceedings. 2005.; 10 (3): 194-7.\n- Gemmer, C, et al. Fast, Noninvasive Method For Molecular Detection and Differentiation of Malassezia yeast Species on Human Skin and Application of the Method to Dandruff Microbiology. Journal of Clinical Microbiology. 2002; 10 (9): 3350-7.\nby on in Skin, Hair And Nails']	['<urn:uuid:dbed765d-cec5-4b58-90a5-b96eb488921c>']	factoid	with-premise	long-search-query	similar-to-document	single-doc	expert	2025-05-01T22:05:01.292488	14	25	1512
130	I'm researching behavioral intervention programs and would like to understand both how cognitive activity shapes behavior and how intervention teams are structured in practice. Can you explain these aspects?	Cognitive activity affects behavior through a process where individuals attend to stimuli, file information, and recall it under similar conditions. This cognitive activity can be monitored and modified to increase desired behaviors. In practice, the intervention team typically consists of a behavior consultant/program supervisor, senior interventionist, and two junior interventionists. The behavior consultant works 6-7 hours monthly, while the senior interventionist works 8 hours monthly, delivering services in two-hour sessions.	['Behavior Intervention Services\nMany students who attend the Holistic Learning Center for one-on-one services receive behavioral intervention. The goal is to increase positive behavioral outcomes through engaging the cognitive processes.\nBehavior Therapies share three core concepts:\n- Cognitive activity affects behavior.\n- Cognitive activity can be observed, monitored, and altered/modified.\n- Desired, adaptive behaviors can be increased through cognitive change and growth.\nWhat is behavioral activity?\n- Attending to stimuli, registering it, filing it with like information, and recalling it when similar antecedent conditions exist\n- Learning as defined by a change in behavior as a result from experience\n- Activity that combines previous information with current experience to create new patterns of behavior and a more mature/developed level of cognition\n- That which occurs after the integration of information, and\n- The ability to demonstrate that intellectual processing has occurred\nWho offers Behavioral Intervention Services at the Holistic Learning Center?\nProfessionals with degrees in behavioral psychology as well as childhood education and behavioral disorders are qualified to offer Behavioral Intervention Services. When working with the pediatric population, it is important that a provider be fluent in childhood development, educational assessment, cognitive behavioral assessment and remediation. Providers hold master’s degrees in the above areas of specialization.\nWhat types of diagnosed disorders can be treated with Behavioral Intervention Services?\nChildren in need of increased cognitive skills as it relates to performing increasingly adaptive responses to their environment benefit from CBT.\nBehavior is defined by activity that is observable and measurable. If behaviors are maladaptive or atypical, CBT can be employed as a non-aversive strategy for remediation.\nDisorders include, but are not limited to:\n- Learning Disabilities\n- Pervasive Developmental Disorders\n- Attentional Disorders\n- Obsessive Compulsive Disorders\n- Oppositional Defiance Disorders\n- Global Developmental Disabilities\n- Motor Delays\n- Speech and Language Disorders\n- Sensory Processing Disorders\n- Multi-Sensory System Disorders\n- Anxiety Disorders\nAn example of how Behavioral Intervention is used at the Holistic Learning Center with children:\nIn order to learn in a kindergarten class for example, one must be able to attend to appropriate stimuli, comply with directions given by teachers, maintain a calm, yet alert state of self regulation, react to spontaneous situations with problem solving and possess the understanding of cause-effect relationships. In order to problem solve, a learner must take in the information, process its meaning, and immediately review all possible options of response. Then, he/she must filter through the possible responses to determine which will produce the desired outcome. In order to generate alternative solutions, the learner must be able to conceptualize the outcomes of their actions before producing them. At that point, a choice of behaviors must be made and executed. This level of high order processing and the ability to sequence the cause-effect relationship poses significant difficulty for the learner with developmental delays/disabilities.\nIn a nurturing manner, problem solving strategies are taught through developmentally appropriate learning activities. Behavioral responses are monitored and shaped to the highest possible level for each learner. Reinforcers are delivered for correct adaptive responses, thus increasing the probability of more correct desired responses. The learning curve is monitored, and as it becomes a natural integrated part of the learner’s repertoire, assistance and reinforcement schedules are faded.The use of the ABC model:\nEvery behavior has an antecedent and is followed by a consequence.\nA = antecedent\nB = behavior\nC = consequence\nReinforced behaviors increase. Clinicians are trained to document the patterns of behavior in order to develop individual behavior plans.\nFunctional Behavioral Analysis (FBA) techniques are used to determine the reason, or the function of behaviors so that the written plans can be created for a team to follow. A Behavior Intervention Plan (BIP) is then created to produce an effective learning curve. This process of learning creates behavioral change. That is the premise of CBT. FBA’s are written with antecedent management strategies and consequence management strategies. These plans are shared with parents and caregivers so that consistency across providers can occur creating a safe and predictable environment for the child.\nThe staff at the Holistic Learning Center are available to consult with families and school districts to develop strategies that best fit the family and classroom culture. Please feel free to call for further information contact us.', 'Home Program | Pacific ABA Academy\nA home program is comprised of a team of behavior interventionists who work directly with a child on a daily basis providing intensive ABA therapy. The number of hours will vary based on the child’s level of functioning and the family’s budget (between 8-40 hours a week).\n- The team consists of a behaviour consultant and/or program supervisor, senior interventionist, and two junior level interventionists.\n- Sessions are two hours in length and involve discrete trial teaching in a 1-1 setting.\n- The behaviour consultant or program supervisor works 6-7 hours a month with the family and the senior behaviour interventionist works 8 hours a month or twice a week.\n- The home program is flexible and working shifts will be scheduled based on the family and staff’s availability.\n- It is mandatory for all families to be assigned a senior level behaviour interventionist, but clients have the option of privately hiring their junior level staff.\n- The senior and junior level staff are supervised and trained by the behaviour consultant to implement scientifically validated programs to the child in the following areas: receptive language, compliance skills, expressive language, gross and fine motor skills, academic skills, requesting/manding, and natural environment teaching.\n- Team meetings occur once a month for 1.5-2 hours with the entire ABA team. This meeting involves a program review to discuss which objectives and targets are in acquisition and which ones are mastered so the team can analyze progress. It also involves a discussion of any issues and concerns raised by the family or team members, as well as a formal review of behaviour plans implemented for challenging behaviour.\n- Intervention overlaps with the senior level interventionist and behaviour consultant/program supervisor occur at least twice a month. These overlaps are mandatory so the consultant and/or program supervisor can monitor, evaluate, assess, and provide further feedback and training for the staff.\n- The Behaviour Consultant is responsible for conducting an Assessment of Basic Language and Learning skills of the child.\n- Those skills involved in social interaction, group instruction and generalized responding are assessed during preschool/school visits.\n- Additional assessments are conducted with school age learners to investigate critical thinking skills and learning style.\n- Subsequent assessments are conducted every 6 months depending on the child’s progress.\n- The Behaviour Consultant is responsible for developing a comprehensive curriculum that will reflect child’s individual needs. The Intervention Plan will clearly outline short-term and long-term academic objectives.\n- The Behaviour Consultant will conduct functional assessment and functional analysis to address behavior issues and assist parents in implementing behavior plans.\n- The Behaviour Consultant will continuously provide intensive training to therapists and parents in Discrete Trial teaching methodology and Natural Environment Training based on the principles of Applied Behavior Analysis. The Behaviour Consultant will implement other techniques that had been supported by scientific research; those include Incidental Teaching, Pivotal Training or Group Intervention that focuses on developing social awareness and interactive play skills.\n- The Behaviour Consultant will provide ongoing supervision of the team members to maintain the integrity of the program.\n- The Behaviour Consultant will conduct monthly team meetings to review child’s progress and consult other professionals that had been assigned to work with the child.']	['<urn:uuid:f6a4b5f1-5792-4666-8a86-b130f833d948>', '<urn:uuid:32546fc6-48fd-47db-8998-bcb1839db6ea>']	factoid	with-premise	verbose-and-natural	distant-from-document	multi-aspect	expert	2025-05-01T22:05:01.292488	29	70	1253
131	What percentage of information that travels through the informal communication network known as the grapevine is actually related to business matters?	More than three-quarters of the information that travels along the grapevine actually pertains to business.	"['CHAPTER 1 REVIEW\n- The formal communication network is an unofficial but important part of any organization.\n- The more links in the formal communication chain, the greater the opportunity for distortion of messages.\n- Large companies, by necessity, must establish a hierarchy with many levels.\n- Most of the information that flows downward in an organization is geared toward helping employees do their jobs.\n- Upward communication in an organization is just as important as downward communication.\n- The ""grapevine"" is another name for formal horizontal communication within an organization.\n- Instead of trying to eliminate the grapevine, sophisticated companies minimize its importance by making certain that the official word gets out.\n- Successful managers avoid the temptation to tap into the grapevine.\n- Public relations messages are not openly sponsored and paid for by the company; instead, they are carried by the media when they are considered noteworthy.\n- One high-profile function of the PR department is to help management plan for and respond to crises.\n- The best way to improve your own and your company\'s effectiveness is to (A) listen carefully to your superiors; (B) agree with your boss as much as possible; (C) get to know the ""power"" employees; (D) make sure that you receive, use, and pass on all messages required to help your group function well.\n- A manager\'s basic role is to (A) make and carry out decisions; (B) attend meetings and make speeches; (C) pass little gems of information along to junior employees; (D) coordinate external communication sources.\n- Flat communication structures (A) increase the number of levels in the organization; (B) require fewer people to report to the same supervisor; (C) reduce the number of levels in the organization; (D) restrict the communication between employees of different departments.\n- Managers\' over-dependence on formal communication channels can result in (A) increased employee flexibility; (B) condensed lines of authority; (C) information overload; (D) distorted information.\n- A sales manager giving instructions to a salesperson is an example of (A) upward communication flow; (B) downward communication flow; (C) horizontal communication flow; (D) informal communication flow.\n- Formal methods for channeling information upward include (A) group meetings; (B) interviews with employees who are leaving the company; (C) formal procedures for resolving grievances; (D) all of the above.\n- The sales manager writing a memo to the vice president of finance is an example of (A) upward communication flow. (B) downward communication flow; (C) horizontal communication flow; (D) informal communication flow.\n- Horizontal communication flow is (A) only implemented through advanced technology; (B) only important if the company is very large; (C) crucial; (D) less important today than it was in the past.\n- A casual conversation between co-workers is an example of (A) upward communication flow; (B) downward communication flow; (C) interdepartmental communication flow; (D) informal communication flow.\n- How much of the information that travels along the grapevine actually pertains to business? (A) almost none of it; (B) half of it; (C) more than three-quarters of it; (D) none of the above.\n- Cultural diversity in the domestic workplace (A) is one result of firms hiring more and more employees whose cultural backgrounds differ; (B) is less important than cultural diversity in foreign countries because the cultural differences within a county are less significant. (C) will be nonexistent by the turn of the century. (D) has nothing in common with cultural diversity across national borders.\n- One result of ever-changing technology in the workplace is (A) a decrease in the speed of communication. (B) a decrease in the amount of information to be processed. (C) a decrease in wages for white-collar workers. (D) an increase in the speed of communication.\n- When you use an audience-centered approach to communication, you (A) ignore ethical questions completed. (B) keep your audience in mind at all times while communicating. (C) get your own way, even if it isn\'t beneficial to your audience. (D) tell jokes and stories.\n- Which of the following contributes to effective organizational communication? (A) a small organization (B) state-of-the-art equipment (C) efficient flow of messages (D) all of the above\n- The term corporate culture refers to (A) the number of organizational levels within a corporation. (B) the extent to which corporations dominate a particular culture (C) the mixture of values, traditions, and habits that give a company its atmosphere or personality (D) a company\'s sponsorship of cultural events.\n- How does communication affect your business future?\n- How do organizations use internal communication?\n- What are the differences between formal and informal communication channels?\n- Describe the two departments responsible for external communication in most organizations.\n- How can companies communicate successfully in a crisis?\n- What is meant by ""fostering an open communication climate""?\n- How can you determine communication is ethical?\n- What are some of the difficulties involved in intercultural communication?\n- What is meant by ""use an audience-centered approach to communication""?']"	['<urn:uuid:f445808c-e744-48ee-84bf-9af27967d9f9>']	factoid	direct	verbose-and-natural	similar-to-document	single-doc	expert	2025-05-01T22:05:01.292488	21	15	824
137	birth problems early pregnancy brain spinal cord chiari malformation spina bifida risk factors differ	Spina bifida has several known risk factors including race (more common in whites and Hispanics), family history, folate deficiency, certain medications (like valproic acid), diabetes, obesity, and increased body temperature during early pregnancy. For Chiari malformation type I, the exact cause of the congenital form is not known, but it may be caused by problems during fetal growth, exposure to harmful substances during pregnancy, or genetic factors. Unlike spina bifida, the documents don't mention specific risk factors like race, obesity, or folate deficiency for Chiari malformation.	"['Spina bifida or Cleft Spine\nSpina bifida is a birth defect that involves the incomplete development of the spinal cord or its coverings. The term spina bifida means “split” or “open” spine. Spina bifida is part of a group of birth defects called neural tube defects. The neural tube is the embryonic structure that eventually develops into the baby’s brain and spinal cord and the tissues that enclose them. Most children who have spina bifida do not have problems from it\nSpina bifida occurs at the end of the first month of pregnancy when the two sides of the embryo’s spine fail to join together, leaving an open area. In some cases, the spinal cord or other membranes may push through this opening in the back. The condition usually is detected before a baby is born and treated right away. Other neural tube defects include amencephaly, a condition in which the portion of the neural tube which will become the cerebrum does not close, and encephalocele, which results when other parts of the brain remain unfused.\nWhat causes spina bifida\nThe exact cause of this birth defect is not known. Genes and environment factors are said to be the most important cause women who have had one child with spina bifida are more likely to have another child with the disease environmental factors, such as nutrition and exposure to harmful substances, probably contribute to spina bifida. Spina bifida does seem to run in families, spina bifida can be prevented by adequate intake of folic acid. Folic acid, one of the B vitamins that is a key factor in the synthesis (the making) of nucleic acid (DNA and RNA). before and during early pregnancy people with spina bifida appear to have abnormal metabolism of folic acid. spina bifida may be an inborn defect in folic acid metabolism rather than a simple deficiency in this nutrient. A high fever during pregnancy may increase a woman’s chances of having a baby with spina bifida. Women with epilepsy who have taken the drug valproic acid to control seizures may have an increased risk of having a baby with spina bifida.\nTypes of spina bifida\nThe different types of spina bifida are—-\n1) spina bifida occulta\n2) spina bifida cystica\nspina bifida occulta\n“occulta means hidden, defect is not visible or without symptoms. This is the mildest forms of spina bifida. In occulta, the outer part of some of the vertebrae are not completely closed. The split in the vertebrae is so small that the spinal cord does not protrude. The skin at the site of the lesion may be normal, or it may have some hair growing from it; there may be a dimple in the skin, or a birthmark Most children with this type of defect never have any health problems, and the spinal cord is often unaffected. Spina bifida occulta is rarely linked with complications or symptoms. Spina bifida occulta is usually discovered accidentally when the person has an x-ray or MRI for some other reason\nSpina bifida cystica\nIn spina bifida cystica, a cyst protrudes through the defect in the vertebral arch. spina bifida cystica may result in hydrocephalus and neurological deficits\nThe least common form of spina bifida is a posterior meningocele (or meningeal cyst involves the meninges, the membranes responsible for covering and protecting the brain and spinal cord. If the meninges push through the hole in the vertebrae (the small, ring-like bones that make up the spinal column), the sac is called a meningocele Fluid leaks out of the spine and pushes against the skin. You may see a bulge in the skin. In many cases, there are no other symptoms..In a posterior meningocele, the vertebrae develop normally, however the meninges are forced into the gaps between the vertebrae. As the nervous system remains undamaged, individuals with meningocele are unlikely to suffer long-term health problems, Symptoms can vary from none to partial paralysis, but these cysts can sometimes be removed with surgery, allowing the child to develop normally.\nis the most severe form of spina bifida. It occurs when the meninges push through the hole in the back, and the spinal cord also pushes though. Most babies who are born with this type of spina bifida also have hydrocephalus, an accumulation of fluid in and around the brain. ecause of the abnormal development of and damage to the spinal cord, a child with myelomeningocele typically has some paralysis. The degree of paralysis largely depends on where the opening occurs in the spine. The higher the opening is on the back, the more severe the paralysis tends to be. Part of the spinal nerves push out of the spinal canal, and you may see a bulge in the skin. The nerves are often damaged, which can cause problems with walking, bladder or bowel control, and coordination. In some babies, the skin is o pen and the nerves are exposed . this is the type of spina bifida that causes the vast majority of disability. The exposure of these nerves and tissues make the baby more prone to life-threatening infections. Many individuals with spina bifida will have an associated abnormality of the cerebellum, called the Arnold Chiari II malformation In affected individuals the back portion of the brain is displaced from the back of the skull down into the upper neck.\nRisk factors of spina bifida\n- Race. Spina bifida is more common among whites and Hispanics.\n- Family history of neural tube defects. Couples who’ve had one child with a neural tube defect have a slightly higher chance of having another baby with the same defect\nFolate deficiency. Folate (vitamin B-9) is important to the healthy development of a fetus. Folate is the natural form of vitamin B-9. The synthetic form, found in supplements and fortified foods, is called folic acid. A folate deficiency increases the risk of spina bifida and other neural tube defects\n- Some medications. Anti-seizure medications, such as valproic acid (Depakene), seem to cause neural tube defects when taken during pregnancy, perhaps because they interfere with the body’s ability to use folate and folic acid.\n- Diabetes. Women with diabetes who don’t control their blood sugar well have a higher risk of having a baby with spina bifida.\n- Obesity. Pre-pregnancy obesity is associated with an increased risk of neural tube birth defects, including spina bifida.\n- Increased body temperature. Some evidence suggests that increased body temperature (hyperthermia) in the early months of pregnancy may increase the risk of spina bifida.\nSigns and symptoms of spina bifida\nchild’s symptoms will depend on how severe the defect is.\nSpina bifida occurs in three forms, each varying in severity:\nSpina bifida occulta. This mildest form results in a small separation or gap in one or more of the bones (vertebrae) of the spine. Because the spinal nerves usually aren’t involved, most children with this form of spina bifida have no signs or symptoms and experience no neurological problems. An abnormal tuft of hair, a collection of fat, a small dimple o a birthmark on the newborn’s skin above the spinal defect may be the only visible indication of t he condition.\nMeningocele. In this rare form, the protective membranes around the spinal cord (meninges) push out through the opening in the vertebrae. abies who are born with the meningocele form have a fluid-filled sac visible on the back. The sac is often covered by a thin layer of skin and can be as small as a grape or as large as a grapefruit.\nMyelomeningocele n myelomeningocele, the baby’s spinal canal remains open along several vertebrae in the lower or middle back. Because of this opening, both the membranes and the spinal cord protrude at birth, forming a sac on the baby’s back. In some cases, skin covers the sac. Usually, however, tissues and nerves are exposed, making the baby prone to life-threatening infections.\nNeurological impairment — often including loss of movement (paralysis) — is common. So are bowel and bladder problems, seizures and other medical complications. Many children who have severe spina bifida develop an allergy to latex (a type of rubber) Spine, hip, foot, and leg deformities are often due to imbalances in The most common bladder and bowel problems are inability to voluntarily relax the muscles (sphincters) that hold urine in the bladder and muscle strength and function resulting mostly from residual paralysis . there is foot or leg deformities, hip dislocation, or scoliosis.\nDiagnosis of spina bifida\nPregnant woman can have a blood test (maternal serum triple or quadruple screen) and a fetal ultrasound to check for spina bifida and other problems with the fetus.\nIf test results suggest a birth defect, she can choose to have an amniocentesis. This test helps confirm if spina bifida exists. But the test also has risks, such as a chance of miscarriage.\nTreatment of spina bifida\nTreatment depends on how severe the defect is. Most children with spina bifida have only a mild defect and may not need treatment. But a child with a severe defect may need surgery. If child has problems from nerve damage, he or she may need a brace or a wheelchair, physical therapy, or other aids. If y child has bladder control problems, he can use a catheter each day. It can help prevent infection and kidney damage in the child , child has little or no feeling in the limbs and can’t sense pain, he or she may get injured and not know it. the need is to check the child’s skin each day for cuts, bruises, or other sores. A baby who also has hydrocephalus will need an operation to place a shunt in the brain. The shunt is a thin tube that helps to relieve pressure on the brain by draining and diverting extra fluid. Most affected individuals will need to use braces, crutches walkers or wheelchairs to maximize their mobility', ""What is a Chiari malformation?\nA Chiari malformation is a problem in which a part of the brain at the rear of the skull bulges through a normal opening (foramen magnum) in the skull where it joins the spinal canal. This puts pressure on parts of the brain and spinal cord, and can cause mild to severe symptoms. In most cases, the problem is present at birth (congenital).\nThere are several types of Chiari malformations, but type I (CM-I) is the most common type. In type I, part of the cerebellum bulges through the foramen magnum. This type is most often congenital (also called primary CM-I), but is often not found until a child is a teen or young adult. In rare cases, this type may also develop later in life. This is known as acquired or secondary CM-I.\nWhat causes a Chiari malformation type I?\nThe exact cause of a congenital Chiari malformation type I is not known. A problem during fetal growth may cause the defect. It may be caused by contact with harmful substances during pregnancy. Or it may be linked with genetic problems that run in families.\nAn acquired Chiari malformation type I happens to a person after birth. It is caused by excess leaking of spinal fluid from the lower back (lumbar) or chest (thoracic) areas of the spine. This can happen because of an injury, contact with harmful substances, or an infection.\nWhat are the symptoms of a Chiari malformation type I?\nYour child may not have any symptoms. Or symptoms may develop slowly over time. Most children don't have symptoms until they are teens or young adults.\nThe most common symptoms are headaches or pain in the back of the head or neck. The headaches and pain are made worse by coughing, laughing, or sneezing.\nYour child may also have other symptoms of a Chiari malformation type I, such as:\nHoarseness or trouble speaking\nRapid, back and forth eye movements (nystagmus)\nPeriods of not breathing during sleep (sleep apnea)\nWeakness or abnormal movements\nTrouble with balance\nAbnormal shape of the spine (scoliosis)\nYour child may also have a pocket of fluid in the spinal cord or brain stem. This is called a syrinx. A syrinx can cause trouble walking or pain in the arms or legs.\nHow is a Chiari malformation type I diagnosed?\nIn a child with no symptoms, the defect may be found when imaging tests are done for other reasons. For a child with symptoms, the health care provider will ask about your child's medical history and give your child a physical exam. He or she may refer your child to a specialist.\nImaging tests are done to detect a Chiari malformation type I. Your child may have 1 or more of these tests:\nMRI. This test is the one most often used to diagnose Chiari malformations. It uses large magnets and a computer to make detailed pictures of the inside of the body.\nCT scan. This test uses a series of X-rays and a computer to create detailed pictures of the inside of the body. A CT scan is more detailed than a regular X-ray.\nHow is a Chiari malformation type I treated?\nYour child may be treated by neurologists and neurosurgeons. These are experts in brain and spinal cord problems. Treatment will depend on your child’s symptoms, age, and general health. It will also depend on how severe the condition is.\nWith no symptoms. Your child’s health may be watched closely. This may include frequent physical exams and MRI tests.\nWith symptoms. Your child's health care provider may prescribe medicines to reduce pain. Or he or she may advise decompression surgery. This is done to relieve pressure on the brain, or to restore the flow of spinal fluid.\nWith few or no symptoms, but a syrinx. Your child's health care provider may suggest close monitoring of the defect with a special type of MRI called cine phase contrast. This helps look for blocked spinal fluid flow. Your child may need surgery, based on the MRI results or if symptoms get worse.\nWith signs of sleep apnea. Your child may need a sleep study. In this test, your child will be monitored during sleep to look for problems. A sleep study can also help the health care provider decide on additional treatment.\nWhat are the complications of a Chiari malformation type I?\nComplications of a Chiari malformation type I can include:\nDevelopment of syrinx\nPermanent damage to muscles or nerves\nCarefully watching for changes in your child’s health can help prevent complications. This helps to make sure that treatment is done early.\nHow is a Chiari malformation type I managed?\nIt is hard for health care providers to predict how a Chiari malformation type I will affect a child’s long-term health. Your child may not have any changes caused by the defect. Or he or she may have worsening neurological problems. Your child’s health will be closely watched. This will include with frequent physical exams and imaging tests such as MRI. There is ongoing research as to how to best manage Chiari malformations.\nWhen should I call my child's health care provider?\nCall your child's health care provider if you notice any changes in your child. Be sure to call if you notice problems with:\nWalking or moving\nKey points about Chiari malformation type I\nWith a Chiari malformation, the lower part of the brain dips down through a normal opening at the bottom of the skull. In some cases, more brain tissue also dips down through this opening.\nIn most cases, the problem is present at birth (congenital).\nThere are several types of Chiari malformations. Type I is the most common type.\nYour child may not have symptoms. If symptoms occur, the most common ones are headaches or pain in the back of the head or neck. The headaches and pain are made worse by coughing, laughing, or sneezing.\nYour child may also have a pocket of fluid in the spinal cord or brain stem. This is called a syrinx.\nImaging tests are done to detect a Chiari malformation type I. Your child may have an MRI or a CT scan.""]"	['<urn:uuid:9cf4905e-bf14-4649-86f5-ead7af9b9697>', '<urn:uuid:ea61f1f2-749f-4232-aa5a-b62f58c5015b>']	factoid	with-premise	long-search-query	distant-from-document	comparison	novice	2025-05-01T22:05:01.292488	14	86	2685
138	best mic placement violin sound holes	Since violins have sound holes that point upwards, the optimal approach is placing a mic from above at an angle to capture the sound well. The specific distance should be adjusted based on room acoustics and ambience. A good position is below the bridge, between the deck and the strings, which can capture both hard sounds and natural string plucks. The microphone should be capable of handling high frequencies accurately.	['Benefits of Mounting a Microphone on Musical Instrument\nWhen you are producing music, how it is captured is crucial. The various musical instruments can sound even better if you use microphones in a way that best captures their sounds with lowest interference.\nOne smart way to maximize the acoustic effects of the instrument is to mount the mic directly onto the musical instrument. Since most instruments are designed to be heard from a distance, this can be a practical challenge in order to make sure that the quality of sound does not deteriorate due to too much proximity. Keeping them at a distance may cause ambient noise.\nThe delicate balance of finding the right spot to place a microphone near an instrument is not so simple. Of course, there are many microphones with varying shapes and mount stands that can help, yet there are mountable techniques and solutions that specialize in enabling robust close-miking.\nThe selected mount solution will obviously depend upon the type of instrument. Here is how you can get that balanced sound with a mic:\nThe Winning Positions:\nWhen the mic is close to the center of the sound source, you get a clean and clear sound. As the mic moves to the sides of the source, there is more bass. Hence at times, the mic is positioned close to the center of the speaker for a hard tone and slightly off for a subtle and softer effect.\nPositioning the mic close to the floor may mean that you get some low-end. At times, clubbing the mic and the amp together inside a sound absorber as crude as a quilt or packed with cushions can work wonders!\nEach Instrument Has Its Peculiars to be Taken Care of:\nPositioning the mic around a piano can produce interesting variants. Many prefer angling 2 mics one from each side or from above. Another option is to position the mic at the ear level of the player for recording the sound as is being perceived by him/her. Placing a mic at the rear side can also lead to a completely new effect. A combination of mics in back and front may also help. These can be adjusted separately or at angles that give the desired effect.\nViolins have sound holes that point upwards, hence placing a mic from above at an angle will capture the sound well. The actual distance of course depends on the ambience and room acoustics as well. The mic needs to be able to handle high frequencies accurately. Positioning a mike at the spot below the bridge, between the deck and the strings, is a good place. This can capture the hard sounds as well as natural string plucks.\nMusic from a cello can be handled effectively by a mic that is placed at 90 degrees from the bridge. A combination of mics, including stereo ones can help capture the string effects smoothly, blending in all the sounds during the mixing stage.\nSince the guitar’s body bounces off noises and sounds from other sources in the room, it may enter the mic as well. The position of the mic that is often considered the most optimum is the place between the sound hole and the fret board. This can capture the low tines as well as the mire aggressively played strums. Pointing the mic straight at the sound hole can yield much higher volumes.\nThe mic being too close to the guitar will make a dry effect, a bit away may lead to lack in sharpness. One might want to try more than one mic, one near and one further away, or else use an omni-pattern mic. One may also place amps from the guitar in separate rooms and mic them back as a feed to the player.\nDrums and Drum Kits\nThese are very peculiar to get the right effect. Placing a mic close to the skin can cause it to pick reverberations. Drum kits, for instance, have high peak sounds which may cause clipping in mics close to the cymbals or drum head. The overhead hanging mic on each drum and cymbal is a conventional method, but nay lead to phasing effect between multiple mics.\nFor bass drums, a mic positioned at the hole in the front skin, adjusted to angle and distance is the best way to optimize between wind issues and frequency response. For snare drums, two mics, one on top and one below will yield the best results.\nFlutes have polar patterns and thus a mic can be placed right above the player’s head, pointing at the holes of the flute. A mic placed mid-way between the mouth and left hand also picks up the sounds well, but it can also pick up unwanted breathing sounds. Overhead mics angled at the flute players) are probably useful as well.\nClarinets can be captured in very much the same way as the flutes, but the mic should be placed at about one thirds of the length away from the instrument’s bell. Another option is to place the mic very close to the bell, but pointed towards the keys to pick up a smooth blend.\nSaxophones have complex sound patterns and capturing the perfect sound can be quite a tricky affair. Since sound is emanated from the bell as well as the holes, the microphone will need to balance all the sources. A conventional position is to place the mic to the player’s right side, near the bell. Adjustments can be made with angle and distance.\nThe Clipping Strategy\nMics can be mounted either on various types of stands that are available in the market. For close-miking, a range of clip-on attachments can be very effective as well, as these allow the microphones to be mounted directly on top of the instrument. One can also use clips that come with holders that fit easily on the frame of the instrument.\nUsually a mix of instruments are used in a performance or recording. A little bit of experimentation and innovation in mounting the microphones around can product the best results.']	['<urn:uuid:5112ee2b-d5e0-44f0-a094-a5aa7e591387>']	open-ended	with-premise	short-search-query	similar-to-document	single-doc	expert	2025-05-01T22:05:01.292488	6	70	1014
139	looking for camera with good screen what is lcd size resolution and features	The camera has a Tilting 3.2-inch LCD touchscreen with a resolution of 2,100k dots. Being a touchscreen, you can change settings and set focus points with your fingertips.	"[""LCD and Viewfinder\nNikon Z6 has a Tilting 3.2 LCD screen with a resolution of 2,100k dots. The Nikon Z6's 3.2 screen is larger than average and its resolution is up to the class standarts.\nLCD is Touch screen\ntype, so you can change the settings and set the focus point with your fingertips.\nZ6 has a built-in Electronic viewfinder. The viewfinder has a resolution of 3,690kdots and coverage of 100%. 100% coverage ensures that what you see in the viewfinder while shooting matches exactly what you will get later in your image, helping accurate framing your shots and minimizes the need for cropping images later.\nMax Shutter speed\nNikon Z6 can shoot continuously at max speed of 12.0 fps\nand has max shutter speed of 1/8000 sec\nUnfortunately Z6 doesn't have a built-in flash but it has a flash shoe for mounting external flashes.\nNikon Z6 features both Contrast Detection and Phase Detection autofocus (AF) systems which ensures speed and accuracy of focusing in most situations. The AF system has 273 points to choose from. Nikon Z6 also features Face detection AF\nwhere it intelligently detects the faces in the frame and locks the focus automatically.\nMacro shooters will love Nikon Z6's Focus Stacking feature. In this mode, Z6 automatically composites multiple shots taken at different focal positions using focus bracketing to create a single image with maximum depth of field.\nWith Nikon Z6, you can record your videos at a highest resolution of 3840 x 2160 at 30p, 25p, 24p fps with bit rates up to 144 mbps and save in MPEG-4 and H.264 formats. This means that Nikon Z6 provides 4K (Ultra-HD)\nvideo, highest resolution that is available in the market today. When viewed on a 4K screen, you will be amazed by the level of details and the crispness.It is also a big step up from its predecessor\nwhich has a max video resolution of only. If you are thinking of upgrading your and shoot a lot of video, this is a big factor to consider in favor of Z6.\nZ6 has a built-in Yes microphone and a Mono speaker. Nikon Z6 also has a port for an external microphone and a headphone port for connecting external headphones which make Nikon Z6 a very suitable camera high quality videography.\nConnectivity and Storage\nNikon Z6 features built-in wireless (Wi-Fi)\nconnectivity ( 802.11ac + Bluetooth) which lets you transfer your photos directly to compatible devices without any physical connection.Nikon Z6's Bluetooth\nconnectivity feature comes handy for connecting other devices that supports it. One other feature that we like is the ability to use our smartphone as a remote to control our Z6. You can change camera settings, release shutter, view LCD screen and tranfer files using remote control app.\nYou can connect Z6 to compatible devices via its HDMI port or Yes port.\nNikon Z6 is powered by a proprietary battery which provides a shooting life of 330 according to CIPA standards.\nConsidering that the average battery life of Mirrorless type cameras is 364 shots, its battery life is about average in its class but it would still be wise to invest in some spare batteries for long photo trips.\nBattery Life Comparison in Pro Mirrorless Cameras\nOlympus E-M1X with its 870shots is the model with longest battery life among Pro Mirrorless cameras. Check the comparison of Nikon Z6 vs Olympus E-M1X or take a look at Longest Battery Life Mirrorless cameras list.\nNikon Z6 Features Compared to Main Competitors""]"	['<urn:uuid:fab45223-bfbf-4dde-a753-b4b6685c3fca>']	factoid	with-premise	long-search-query	similar-to-document	single-doc	novice	2025-05-01T22:05:01.292488	13	28	582
145	How do they make metal-looking props shiny?	To achieve a shiny metal look on props, a process called cold casting is used. First, aluminum powder is dusted inside the mold to create a thin film. The resin is then poured into the mold, and after the part is removed, it's polished first with 0000 steel wool to achieve a brushed finish. For a higher polish, aluminum wheel polish (like Mother's brand) is applied with a soft cloth. Any excess polish in cracks needs to be cleaned with q-tips or a toothbrush.	['Sophitia’s Omega Sword, Soul Calibur IV\nAs a partner to the completed Elk Shield, I was asked to build a copy of Sophitia’s blade from Soul Calibur IV. The Omega Sword is actually quite similar to another weapon I’ve made a long time ago – Cassandra’s Digamma sword – but I wanted to try a few new techniques on this project.\nAfter creating a set of 2D blueprints, I set to work on the handle section first. The grip and pommel were both turned down from urethane resin blanks. The off coloration on the pommel comes from mixing two tinted resins into one cup simultaneously. This isn’t relevant to the project at hand, but it does look kind of cool.\nThe blade was built in a pepakura-style combination of styrene sheets. This piece will end up being a master for a mold. While the technique I used made for an extremely lightweight piece, it would be very fragile. Good for less fatigue if you’re carrying it at a convention but you’d have to be super careful!\nI started by trimming the center section of the blade out of some .060″ styrene sheet, then adding a center box for the raised shape that runs along the middle of the sword. To make sure this piece was secured at a 90º angle to the center blade spine, I used a piece of aluminum square tube as a jig when gluing it in place. Once one side was done, I repeated the process for the other half of the blade.\nSmall triangular parts were used as an interior structure for where the rest of the blade edges would be added. I also put in a few more structure-assisting shims along the center spine.\nThe side panels were angles I couldn’t determine exactly until the center of the blade was finished. For these, I laid paper over the opening and traced the pattern onto it, then transferred this shape to styrene. This shot shows one of the side panels being glued in place. This has a subtle compound curve down the side because of the concave blade shape.\nThis left me with a passable shape but it needed a bit of help to be crisp. Bondo was added in the seams and along the edges of the blade to make sure things were nice and pointy.\nI repeated the process of sand, fill, repeat until the blade was ready for molding.\nFor the center raised letters, I lucked out and was able to re-use my mold from the Cassandra project. This piece started out as MDF sanded to shape, with styrene bar added around the perimeter for the raised details.\nThe lettering along the panel was cut at a local sign shop and added to the part before molding, so the finished resin piece would have a slight raised letter texture. This could also be done in reverse (letters cut out of a raised panel) if you were after a more engraved look.\nFor the cross guard and rain guard, I started with a few piece of acrylic that formed a perimeter shape. These were filled with apoxie sculpt and sanded down.\nThe rain guard was vacuumformed twice and the two styrene pulls layered on top of one another to create the final shape.\nFor the cross guard, I only made one piece – this would be molded and cast twice for one complete blade. Like the rain guard, a small piece of styrene was used for the raised detail.\nHere’s the two parts being molded. I filled the rain guard with clay since it was a thin vacformed part and wasn’t thick enough for a pour mold without this backing.\nThe blade was also clayed up for a large pour mold. The silicone used here is Smooth-On’s Mold Max 40. All of the parts were cold cast, a process that involves adding metal powder to a resin casting in order to give the cast parts a surface that can be polished.\nMy process for cold casting is first to “dust” the mold with the metal powder. For these blade parts I’m using 100% aluminum powder. (This is essentially a can of tiny metal flakes, so make sure to wear a respirator any time you’re cold casting so you don’t breathe in a million little razorblades.) Dusting the mold involves pouring a lot of powder over the surface to cover the entire interior, then lightly tapping any excess out onto a piece of paper to be used later. You want a very thin film of powder without any thick pockets in the detail crevices. Too thin and it won’t polish well; too thick and the resin won’t fill the area. Ideally, you don’t want to be able to see the color of the mold material after powdering.\nSome tutorials will say to add powder to the resin before pouring. I’ve had mixed results with this, as it can change the physical properties of the cured resin and make it more brittle. It can also trap air in annoying places. Most of the time, I only dust my molds and don’t add the powder to the actual plastic.\nI also prefer to tint my resin gray to make sure any small missed spots aren’t obvious. Once you pull your parts out of the mold they’ll look dull and matte like this. When pouring, try to pour onto a part which does not need to be polished or will be hidden. The motion of the resin pouring into a mold will sometimes push away the dusted powder where you’re pouring and leave a small bare spot.\nI start polishing first with some 0000 steel wool. This is very fine stuff and won’t last long before you’ll need to change pads. Don’t use too much pressure – you’re not sanding, just polishing. This will give you a “brushed” finish\nFor a polished look, I use aluminum wheel polish (my preferred brand is Mother’s) applied with a soft cloth. Excess in cracks and nooks needs to be cleaned out with q-tips or an old toothbrush. After a couple polishing passes, you’ll have a much shinier part! On the left in these photos is a piece with only 0000 steel wool, on the right is a polished blade.\nAfter polishing all the parts to a high shine, I drilled holes in the blade for mounting pins. Pinning parts will make them far more stable than just putting glue on a joint, and this is especially useful for cosplay props that get knocked around a lot. The clearances on these parts was a bit tight, which is why the pins are all labeled down to the thousandth of an inch. I used 2 part epoxy to secure all the parts in place.\nThe handle wraps are gray leather and were created by my friend Cathy at God Save the Queen Fashions. After that, the swords were complete!\nHere’s a few shots of the finished weapon – for higher res pics be sure to check out the gallery. For more process photos (I take too many to be included in every blog entry) take a look at my Flickr page.\nThanks for reading!\nAll of the products listed in this write up are the products that I used and can recommend. Some of them are provided as Amazon affiliate links, which help support Volpin Props.']	['<urn:uuid:1d9f7540-3d0b-4750-9305-190ffc0d4db7>']	open-ended	direct	concise-and-natural	distant-from-document	single-doc	novice	2025-05-01T22:05:01.292488	7	84	1234
147	I'm trying to learn meditation on my own but feel overwhelmed. What do experienced teachers say is needed to succeed in any spiritual practice?	According to the framework of the Five Spiritual Faculties, success in practice requires five key elements: conviction (saddha), energy (viriya), mindfulness (sati), concentration (samadhi), and wisdom (panna). This framework is described as a sophisticated understanding of how the mind works and can help practitioners make adjustments to their practice in real time.	['Insight Journal interviews Willa Thaniya Reid and Dr Elizabeth Day about the Five Spiritual Faculties, which they will be teaching in the course “Touching Nibbana through the Five Spiritual Faculties” at BCBS on July 12-17, 2019.\nWilla Thaniya Reid trained in the Thai Forest Tradition of Ajahn Chah, which harmonizes with her affinity for the natural world and for reflective practice grounded in the Buddha’s suttas. She was a monastic for 18 years, eight years as senior nun of Cittaviveka. Dr Elizabeth Day trained as a monastic within the lineage of the Thai Forest Sangha. She is committed to presenting the clarity of the core Buddhist teachings, and bringing these alive for minds shaped by contemporary democratic paradigms. Together, they have a center for Dhamma enquiry in Kihikihi, New Zealand where they offer Dhamma teaching to the local community through regular sessions, day-longs and longer retreats.\nInsight Journal: We look forward to having you both here with us this July. Your upcoming course is entitled “Touching Nibbana through the Five Spiritual Faculties.” Why did you choose this particular lens to focus on for your course offering?\nElizabeth Day: It seems important to make explicit that Nibbana is the very real possibility of practice and to keep that in the forefront. As to the Five Spiritual Faculties, I find the frameworks offered in the Suttas so clarifying and enabling of practice. This particular framework of the five faculties can be a framework for success in anything that we do. It is a succinct summary of a sophisticated understanding of how the mind works. And it offers a helpful way for practitioners to make adjustments to practice in real time. We start with saddha, which I translate as conviction; that quality of motivation that brings energy to the practice. Even that, being conscious of that and holding it at heart as we establish and compose ourselves for practice, can go a long way to maintaining awareness of what it is we are practicing, moment to moment. I have been drawn to practice consciously with the Five Spiritual Faculties and I have found, in teaching in our community in Kihikihi New Zealand, that practitioners feel more empowered by having a map of the process they are engaged in. The practice takes everything that we have, heartmind and body, and so through iterations of practice with the Five Spiritual Faculties we condition the possibility of touching Nibbana.\nWilla Thaniya Reid: When considering what would be helpful to explore in the setting of BCBS we thought that it was an opportunity to encourage the Indriya (spiritual faculties) as a way for us all to reflect on what is happening in our practice. As Elizabeth states, those in our community have found them a helpful lens. The sutta we have chosen as central for this exploration (the Apana Sutta) has many threads that I find helpful in my own practice, and I see others also relating to them. When the Buddha analyzed moments of awakening out of dukkha he identified that each of these faculties was present. He makes it clear that these are essential factors for us to be able to see clearly. It is also clear that this is an embodied practice ‘touching Nibbana with the body’, which I find an essential recognition, that this is not an intellectual analysis, rather a framework for understanding what is happening in the energetic of the present moment. When I review what is happening in my own mind I also treasure the sense of ‘again and again they establish mindfulness…’ the sense of the ongoing steady quality that brings cultivation to fruition. So in sharing this with others we would hope they connect with the affirming quality of this practice: We come out of judgement and views into a clear analysis of what is happening, recognizing the causal links in this cultivation of ours. Liberation is possible.\nIJ: Would you say that the five faculties: faith (saddha); energy (viriya); mindfulness (sati); collectedness, or concentration (samadhi); and wisdom (panna) build upon one another?\nWTR: Of course there is this tangible linear dimension to this cultivation. We recognize awakening is possible, that we are capable of undertaking this practice — this sense of faith/ confidence/ conviction — and then this brings our engagement with our practice. Suffering leading to the quest, which leads to the hearing of teaching about the possibility of freedom from stress, and the faith that arises brings a willingness to start experimenting with this cultivation, so energy is aroused, mindfulness becomes established, the mind is focused on the inquiry into dukkha and true understanding arises.\nHowever, in the Apana sutta the Buddha and Sariputta are mulling on this process and describe it as culminating with the faculty of faith. That a practitioner who has developed these qualities “will experience the remainderless fading away of this mass of darkness, recognizing this is peaceful….’Those things that before I had only heard about, now I dwell having contacted them with the body, and having pierced through with wisdom, I see.’ That faith, is their faculty of faith.” Doesn’t it give you goosebumps?\nIJ: Which of the five faculties have you personally found most useful or stabilizing for your practice?\nED: As an enthusiast, I find the qualities of motivation (faith) and energy come relatively easily, so the work initially was to strengthen and deepen mindfulness in order to sustain the practice after the initial flushes of delight and joy that can come with the focus of energy. As a person oriented to disciplined philosophical enquiry, and more to sensuality than to aversion, I have also found the pleasure of a concentrated mind quite motivating. The challenge then is to cultivate conditions for a mind poised at equanimity, rather than formless states, in order for the wisdom faculty to arise. And of course it can depend on what is happening in life at a given moment. In our lives of escalating complexity, energy may not always be forthcoming. So this is a practice, like all of the cultivations, that rewards patient endurance; starting again and again, with clear comprehension of the process, moment to moment. I was once given precious advice from a Kruba Ajahn, a purported arahant, visiting Australia from Thailand: when I enquired about deepening mindfulness, in my walking meditation, his response was simple but profound. “You can use the breath like a banister, and as you ascend the stairs take hold of the banister every moment, until the stairs disappear and you let go completely”.\nIJ: Can you talk a little bit about chanting practice? How you relate to it within your personal practice?\nWTR: Over the years my relationship to chanting has morphed in various directions: at different times my heart needs different medicines. Initially it was a powerful way of having the Teaching resonate in my mind, heart and body. I would find spontaneously that central teachings I chanted would arise in my mind as a basis for reflection. This can be a powerful spur to practice. Particularly the morning chanting from the Forest tradition that we will use on the retreat; it is both heart-based and an unsentimental analysis of human experience. It helps give perspective to day-to-day experience. And if we are practicing alone or in a small group it also evokes other practitioners across time and space, the millions of others who also chant these words.\nI have also used chantings that keep me connected to the bigger frame of awakening. Your question evokes memories of some of my bleakest times, walking for hours on my jongram path reciting the names of all the Buddhas and their qualities. Or a chant I made for myself of epithets for Nibbana, keeping my heart centered in the possibility of freedom from all dukkha while the harshest winds were blowing… Asokam, Virajam, Khemam…. (Sorrowless, Dustless, Secure) what solace this can be.\nIJ: What is the one thing you would like people to understand within their own path and practice?\nED: Understand that practiced consistently, this path leads to the remainderless, spotless, dustless, unconditioned; to freedom from all suffering, from all coming and going. Put into perspective like this, doesn’t it stir saddha (motivation, conviction, faith, trust)? And see how energy arises, conditioned on saddha, and the whole cycle of practice rolls onward in the right direction, undoing the spin of the world. This is possible. The time is now, the place is wherever you are right now.\nWTR: As Elizabeth says, that they taste the fruit of welcoming this present moment, the power of this practice. To quote the Buddha, ‘Do not think any good deed is of little worth, drop by drop the water jar fills.” So in each moment we attend, ‘again and again establishing mindfulness’, letting the ‘jar’ fill with the clarity these spiritual factors bring, until our hearts overflow with liberating insight. The Buddha, and those who have followed his way, show this is possible when the right conditions are established. This is not about personality, it is Dhamma. And there is a great compassion in this.']	['<urn:uuid:e69caf96-8975-44f5-8f06-704b0dbbd880>']	factoid	with-premise	verbose-and-natural	distant-from-document	single-doc	novice	2025-05-01T22:05:01.292488	24	52	1517
153	How do the setting methods differ between homemade cranberry curd bars and traditional apple butter when preparing them for storage?	Cranberry curd bars set through chilling in the refrigerator for about 2 hours until firm, while apple butter can be preserved through multiple methods including water bath canning (processing for 5 minutes), freezing (with 1/2 inch headspace), or refrigeration (used within two weeks once opened).	"[""Sometimes you want to make a recipe that is just big on 'wow' factor. Sometimes you want to make something that is fun and crowd-pleasing. These bars are both, and they make a 9 x 13 pan full so makes enough to share with a crowd.\nIf you've never made curd before, this is a fairly straightforward recipe, and does not involve baking the bars twice. Often bars made with a curd will require baking to set the crust and then again to set the filling. This one incorporates a good amount of butter in the curd to provide a lovely mouthfeel as well as setting abilities. Note the optional step of straining the curd after cooking it on the stovetop (over simmering water, a make-shift double burner). If you want the curd to be smooth, be sure to follow this step. If you don't mind bits of zest or cranberries, you can go ahead and skip it.\nI hope you enjoy this beautiful treat!\nyields one 9 x 13 pan of bars\n8 ounces gingersnap cookies + graham crackers (about half and half of each, but your preference)\n1 cup pecans, optional\n6 tablespoons unsalted butter melted\n3/4 cup white chocolate chips (or 6 oz high quality bar, chopped)\n1 12-ounce package fresh (or frozen thawed) cranberries\n1 cup + 1/2 cup granulated sugar\n2 large eggs\n4 large egg yolks\n1 teaspoon finely grated lemon zest\n1 teaspoons finely grated lime zest\n1/2 cup fresh lime juice\nPinch of kosher salt\n3/4 cup (1½ sticks) unsalted butter room temperature, cut into pieces\nWhipped cream (for serving)\nStart with the crust:\nPreheat oven to 350°. Pulse cookies in a food processor until very finely ground (you should have about 1 cup). Add pecans if using; pulse until finely ground. Add butter and brown sugar; pulse to combine. Transfer to a 9 x 13 pan. Using a measuring cup, press firmly onto bottom of dish. Bake until firm and slightly darkened in color, 10-15 minutes.\nOnce the crust is browned, sprinkle the white chocolate over the crust and return the pan to the oven for one minute. Once softened, gently spread the chocolate over the crust, making as even a layer as possible. Let cool. Do Ahead: Crust can be baked 1 day ahead. Store tightly wrapped at room temperature.\nNext make the filling:\nBring 12 oz. cranberries, 1 cup granulated sugar, and ¼ cup water to a boil in a large saucepan over medium-high. Reduce heat; simmer until cranberries burst and most of the liquid evaporates, 12-15 minutes. Let cool. Purée in a blender until very smooth.\nCombine purée, eggs, egg yolks, lemon zest, lime juice, salt, ½ cup sugar, and 1 tsp. lime zest in a heatproof bowl. Whisk well, and then set over a saucepan of simmering water (bowl should not touch water), stirring with a rubber spatula and scraping down sides of bowl often, until curd thickens and coats spatula, 8-10 minutes. Optional: If you want the curd to be perfectly smooth, press the curd through a sieve over a large bowl. Discard bits that remind in the sieve. Let cool until just warm.\nUsing an electric mixer on medium-high, beat curd, adding butter a piece at a time and incorporating after each addition, until curd looks lighter in color and texture, about 5 minutes. Scrape into crust, spread evenly, and chill until firm, about 2 hours.\nTo serve, cut into small bars. Enjoy!"", 'Instead of cooking in a crock pot, apple butter can be made in a microwave oven. Process in boiling water bath 5 minutes. Place 2 pounds of washed, cored, and quartered apples in a microwave-safe bowl and zap on high for 15 minutes or until the apples are completely soft. Then, process them in a food mill to remove the peels. Cortland apples work well because they don’t oxidize as … Of course, just like many jams and jelly recipes, this old fashioned apple butter recipe uses sugar to sweeten the spread. https://www.victoriamag.com/old-fashioned-apple-butter-recipe Reduce heat to medium. Make this delicious apple butter recipe using the Douthit family’s old-timey food tradition and make it a fantastic fall project. Offers may be subject to change without notice. Put soft fruit in a food mill to remove skins. Put in the crock pot. Add lemon extract and blend. For the drink, combine apple butter, apple cider, bourbon, and bitters in a cocktail shaker. However, if you are looking for a Sugar Free Apple Butter recipe we have one that you will love! Lisa Hubbard / Photolibrary / Getty Images. Cook for another 4-1/2 hours with NO lid. It\'s apple season, and I\'m on a serious apple baking marathon! Quickly ladle apple butter into hot sterilized jars, leaving 1/4- inch headspace. Bring to a boil; cover and cook over medium heat 30 minutes or until apples are tender. ** Make sure each jar has sealed. Expert baker and published author, Carroll Pellegrinelli shares her knowledge of bread baking and desserts. Then pour over ice and top with club soda. Remove from the heat and add lemon juice, cinnamon, and vanilla. Wash, core and quarter apples (no need to peel). Once a container is opened, it must be refrigerated and used within two weeks. Allow apple butter to cool and then store in the freezer. It is the easier, shortcut version. Directions. This Apple Butter Old Fashioned cocktail recipe is simple. Stir every 2 hours. Cover and cook on high for 6 to 8 hours. Add molasses, blending well. Step 3. 1. No forks or spoons required, just easy-to-pick-up party foods, so you can clean up in no time. This flavorful, homemade apple butter requires little effort but tastes like you labored all day. Add sugar and spices. Get it free when you sign up for our newsletter. Then, process them in a … Preheat oven to 350 degrees. the whole family loves fresh apple butter on toast biscuits and just plain bread. 2. Start in the morning and come home to a house that is perfumed with the homey aroma of cooked apples. Reduce heat and simmer covered for 20 to 25 minutes. Apple Butter. An Old Fashioned is traditionally made with bourbon, bitters, simple syrup, club soda, orange and a maraschino cherry. Well, when we went to the old mill to scope out the venue and book our wedding day with them, they gave us a small cloth bag with a jar of their homemade apple butter inside. https://hillsidehomestead.com/2014/10/25/apple-butter-recipe MyRecipes is a registered trademark of Meredith Corporation All Rights Reserved. Measure fruit back into the crock pot. Combine apples, apple cider, brown sugar, honey and 1/2 teaspoon salt in a Dutch oven over medium heat. *Can seal in hot water bath or top with paraffin. Cover at once with metal lids, and screw bands tight. Whether you\'re cooking for yourself or for a family, these easy dinners are sure to leave everyone satisfied and stress-free. Cook apples until soft (around 20 minutes). Remove from heat and stir in the butter until it melts completely. Sift dry ingredients together and add to creamed mixture. this link is to an external site that may or may not meet accessibility guidelines. Stir in cider or juice. This is a great weekend project with the kids, especially after a trip to an apple orchard. Its enough for a “small batch” of Apple Butter. Place first cake layer on cake plate that has a cover. MyRecipes.com is part of the Allrecipes Food Group. Add 3/4 cup unsweetened apple cider or apple juice (can be reconstituted from frozen), 2 to 4 tablespoons the sweetener of choice (agave syrup, honey or sugar), 1 teaspoon ground cinnamon and 1/4 teaspoon ground cloves. Add sugar and spices. MyRecipes may receive compensation for some links to products and services on this website. Apple Butter Recipe: You’ll need these ingredients. Cover and cook on low for 10 to 18 hours (or high for 2 to 4 hours). I\'ve been whipping up family favorites like homemade apple pie with an all-butter pie crust, rustic apple tarts and of course this deliciously thick apple butter recipe!. This yummy recipe is a favorite in my family. Cream butter and sugar; add eggs and beat well. https://www.halfbakedharvest.com/apple-butter-old-fashioned In the fall, old-fashioned apple butter is magical! Sign up to receive weekly recipes from the Queen of Southern Cooking Instructions. Press apples through a sieve. ), Homemade Apple Soda With Fresh Apple Juice, Vegan Apple Cobbler with Cloves and Allspice Recipe, The Best Apples for Homemade Apple Butter, Pennsylvania Dutch Low-Sugar Apple Butter. Any leftover apple butter should be eaten with warm homemade bread or biscuits. Cook, stirring frequently, 1 hour or until mixture thickens. FILLING: Stir together apple butter and brown sugar in a medium saucepan over medium high heat. Spoon into hot canning jars and process according to canning jar directions. Old Fashioned Apple Cocktail Ingredients. This Apple Butter Old Fashioned is the perfect way to ring in the fall season! Slow Cooker Apple Butter Recipe… Combine apples and apple juice in lightly oiled crock-pot. After 4-1/2 hours stir and add remaining ingredients. Slow cooking a variety of apples, sugars and balanced spices for hours results in the best apple butter ever! See Best Cooking Apples and use the varieties you would use for applesauce. makes a great present with a loaf of homemade bread wrapped in a kitchen towel & basket That means you don’t have to peel, core, and chop up 5 pounds of apples to make it. Submit a Recipe Correction. Place 2 pounds of washed, cored, and quartered apples in a microwave-safe bowl and zap on high for 15 minutes or until the apples are completely soft. It lets the flavors of the apples shine, along with their nutrients! Old Fashioned Apple Butter Recipe (This made about 8 pints): 8 pounds of apples (about 32 medium) 4 cups of sugar (or more as needed, up to 8 cups) 2 cups liquid, water or apple cider Place apples in crock pot; cook on high for 4-1/2 hours (covered). Cover and cook on low setting for 10 to 18 hours or high setting for 2 to 4 hours. If you don’t want to schnitz apples, you can also cook apple butter directly from applesauce. Cool, transfer to a jar, and store in the refrigerator. By William T. Pryor | September/October 1973 Fill sterilized pint and/or quart jars (good to sterilize while apple butter is cooking) with extremely hot apple butter. Begin by washing the apples very well under cool running water. Cover at once … Reduce heat to medium. Stir well. If you have never eaten apple butter, I urge you to make this! DIRECTIONS. From chips and dip to one-bite apps, finger foods are the perfect way to kick off a party. Nothing beats the taste of homemade, and even more so when it comes to rich and delicious apple butter… Combine the puree with 1/3 cup maple syrup (or more to taste) and 1/2 teaspoon cinnamon (or more to taste). To update this classic cocktail for fall and winter, I’ve added apple butter and a cinnamon stick in lieu of an orange and cherry. The apple butter can be eaten immediately, ""put up"" (canned) by using a water-bath process, or transferred to freezer-proof containers and frozen for future use. This recipe was made using a crock pot that has three settings—off, high, and low. Cozy up and celebrate the season with the most delicious apple cocktail. Return strained pulp to kettle; cook over high heat, stirring constantly, until pulp rounds up in a spoon. Return it to the microwave and zap for 5 minutes or longer until the consistency you desire is reached. For each pint (2 cups) of fruit, add 1 cup sugar, 1 teaspoon cinnamon, 1/2 teaspoon allspice, 1/2 teaspoon ground cloves, and 1/2 teaspoon freshly grated nutmeg. Add all of the ingredients for the topping, except for the butter, to a medium sized bowl and stir to combine. Make your own apple butter with this simple recipe. If you use one that has four settings—off, high, low, and warm—be advised that they cook hotter, so you will have to watch your apples more carefully so they don\'t burn. (Nutrition information is calculated using an ingredient database and should be considered an estimate. Apple butter is a delicious alternative to peanut butter, and a great way to use fresh apples. The apples should be very mushy. How to Can Apple Butter *A detailed and printable recipe … Pour puree into a shallow baking dish and bake at 300° for 2 hours or until thick enough to hold its shape. … Slice the apples into quarters or, smaller size pieces if the apples are really large. © Copyright 2020 Meredith Corporation. Add sugar and spices, mixing well. Everybody understands the stuggle of getting dinner on the table after a long day. If you\'re looking for a simple recipe to simplify your weeknight, you\'ve come to the right place--easy dinners are our specialty. Cook at a gentle simmer for several hours adding a little more water from time to time if there seems to … A recipe for a small batch of Apple Butter Most of you won’t be stirring apple butter in a 30 gallon kettle, so we’ve included a recipe for a small batch you can make in your own kitchen. The caramelization of the sugar in the apples, combined with cinnamon, nutmeg and cloves, creates a traditional rich, sweet and smooth classic apple butter. Cook, stirring frequently, 1 hour or until mixture thickens. … I’m using 5 pounds of apples. This simple recipe cooks up low and slow in My favorite way to eat apple butter … Quickly ladle apple butter into hot sterilized jars, leaving 1/4- inch headspace. Just use applesauce! A traditional Old Fashioned cocktail is made by muddling […] Puree apple mixture in a blender. This creative recipe puts a festive spin on an old favorite, creating a drink that no one can resist! Peel, core and cut up apples in abundance, put them over the fire with just enough water to keep them from scorching, and let them come to the boil slowly. To freeze apple butter, keep 1/2 inch of space between the top of the apple butter and the top of the jar. Process them in a food mill, throw the puree back into the crock pot and, the following morning, you\'ll have hot apple butter to go with your toast and butter (if you don\'t mind getting up a few times during the night to give the mixture a quick stir). For the rim, just use sugar to coat. Newsletter Signup. Clean rims and top with hot, sterilized lids and tightened rings. Don’t peel, but wash, core, and quarter the apples. With this cookbook, you’re never more than a few steps away from a flavorful dinner. Place apple slices and cider in a flat-bottomed kettle. Place a lid on the jar and freeze for 6-12 months. Otherwise, the puree can be cooked down under your watchful eye during the day. Bring to a boil, then reduce heat, cover, and simmer, stirring often, for 1 hour. Cooking it in a crock pot is the secret. Stir often while cooking. Or spoon into freezer containers. INDIANAPOLIS (WISH) — Here’s a recipe given to Annessa’s family by a dear friend more than 40 years ago. Allow the apple butter to fully cool before freezing. If some have not, refrigerate until ready to use. Bring apples and cider to a boil in heavy saucepan. Bring just to boiling. Stir and seal in jars. For an easy supper that you can depend on, we picked out some of our tried-and-true favorites that have gotten us through even the busiest of days. Remove cover after 3 hours to allow fruit and juice to cook down. Wash, peel, core and quarter apples.']"	['<urn:uuid:4453ebf7-2ba6-438a-a9ce-cefc35eb6d3d>', '<urn:uuid:03a7f59c-cb80-40fa-8f07-328983ebacaa>']	factoid	direct	verbose-and-natural	distant-from-document	comparison	expert	2025-05-01T22:36:12.692263	20	45	2659
159	Can you tell me about Nolan Ryan's pitching speed and strikeout achievements?	Nolan Ryan set multiple impressive records. He threw a 100.9 mph pitch on August 20, 1974, which was a record at the time (equivalent to 108.1 mph if measured from 50 feet). Throughout his 27-year career, he accumulated 5,714 strikeouts, finishing first all-time with over 1,500 more strikeouts than the second-place pitcher. He also holds records for most seasons with 100+ strikeouts (24), 200+ strikeouts (15), and is tied for most seasons with 300+ strikeouts (6).	['August 20, 1938: The Iron Horse, Lou Gehrig, hit the 23rd and final grand slam of his career on August 20, 1938, his last full season with the New York Yankees. Gehrig knocked the ball out of the park with bases loaded in the top of the first inning, as the Bronx Bombers faced Philadelphia. It took 75 years, and another Yankee, to break his record. Alex Rodriguez broke the record in September of 2013.\nAugust 20, 1974: You can mark this day as the day Hall of Fame pitcher Nolan Ryan entered the history books as well as the Guinness Book of World Records. On August 20, 1974, Ryan clocked at 100.9 mph pitch, a record at the time. The speed was apparently measured by a laser radar when it was only about ten feet from the plate. If measured from 50 feet, it would have been clocked at 108.1 mph.\nAugust 20, 1991: If you look at this contract now, it may not seem like much for one of the greatest quarterbacks ever. But when Dan Marino signed his five-year extension with the Miami Dolphins on August 20, 1991, he became the highest paid NFL player. The contract extension was worth $25 million and included a $3 million signing bonus. Before Marino signed the contract, Hall of Fame QB Joe Montana was the league’s highest paid player.\nAugust 21, 1931: Babe Ruth is one of the greatest players to ever step foot on a baseball field, if not the greatest. The Sultan of Swat set a number of records which players have struggled to break over the years. One of those records was his home run record. He was the first player to reach 600 home runs (though he would go on to hit 714). Ruth knocked no. 600 out of the park on August 21, 1931.\nAugust 22, 1950: Before Arthur Ashe there was Althea Gibson. On August 22 she became the first black competitor in US national tennis competition at Forest Hills, New York. A year later, in 1951, she became the first black competitor at Wimbledon.\nAugust 22, 1989: Nolan Ryan was the king on the mound. The Hall of Fame pitcher struck out 5,714 batters throughout his career. On August 22, 1989, he struck out his 5,000th batter, the first pitcher in MLB history to do so. He was 42 years old at the time, playing in his 22nd season in the league.\nAugust 24, 1972: On August 24, 1972, two NHL greats, Gordie Howe and Jean Beliveau were inducted into Hall of Fame. Both were inducted just a year after they retired from the league. Beliveau, a life-long Canadien, played 20 seasons in the league, scoring 507 goals and winning the Cup ten times. Howe spent 25 years in Detroit, and only joined another team several years after his induction, when he played for the Whalers. He scored 786 goals while in a Red Wings uniform, winning four Cups along the way.\nAugust 26, 1971: On August 26, 1971, Bobby Orr signed the first million dollar contract in the NHL. The Hall of Famer was coming off of a record-setting season, scoring 139 points and was already the league’s top-paid player. He signed a five-year contract with the Boston Bruins that would pay him $200,000 a season.\nAugust 21, 1936 Legendary NBA player and all-time rebounds leader, Wilt Chamberlain was born in Philadelphia, PA\nAugust 21, 1986 Recently retired Usain Bolt, the fastest man in the world, was born in Sherwood Content, Jamaica\nAugust 22, 1941 Hall of Fame NFL coach Bill Parcells was born in Englewood, NJ\nAugust 23, 1978 LA Lakers legend Kobe Bryant was born in Philadelphia, PA\nAugust 24, 1952 Former NFL head coach Mike Shanahan was born in Oak Park, IL\nAugust 24, 1960 legendary MLB infielder, “The Iron Man” Cal Ripken was born in Havre de Grace, MD\nAugust 25, 1927 The first black tennis player to compete in a US national championship, Althea Gibson, was born in Clarendon County, SC\nAugust 25, 1970 Seven-time NBA champion, Big Shot Bob, Robert Horry, was born in Harford County, MD', 'Where Vintage is King and All Conditions and Brands Are Welcome!\nFriday, October 30, 2009\nNolan Ryan Record Breaker, Card #6\nOn July 16, 1977 Nolan Ryan fanned 12 Seattle Mariners en route to an Angel’s victory, it was the 98th time that Ryan had struck out 10 or more batters in a game in his career and this earned him a record breaker card. The previous record was held by Dodgers ace Sandy Koufax who whiffed 10 or more 97 times. This is the first of many pitching records that Ryan set in his career. He would go on to pitch for 16 more seasons and would also lead the league in strikeouts 6 more times. Once he broke Koufax’ record, he built on it and made it pretty much unbreakable. His final number of 10 K games after his retirement in 1993? He had 215 games with 10 or more Ks. That’s way more than double Koufax’ record, practically triple. Ryan did the bulk of his striking out in the American League, though. He had 148 10+K games for the Angels and the Rangers, but playing for the Mets and Astros he only reached the feat 67 times which means that Koufax is still the career leader in the NL. During his 27 year career Nolan Ryan struck out 5714 batters, good for first place all time and over 1,500 more than the guy in second place. In 1973 with the Angels Ryan struck out 383 batters to set a Major League Record which still stands 35 years later. With 24 in his career he holds the mark for most seasons with 100 or more Ks, with 15 he set the standard with most seasons at 200 plus and yes, he does hold the record for most seasons with 300 or more Ks with 6. He is tied with Randy Johnson for that last one. Those records aside, this card celebrates him breaking Koufax’ record for most games with 10 or more Ks. It is incredible that Ryan broke Koufax’ record, but more incredible that he broke it, doubled it and then got some more. In the end he bested the record by 118 games. In 1977 Sparky Lyle captured the AL Cy Young Award, but Ryan was named the Sporting News Pitcher of the Year. He was third in the league in wins with 19 and led the league with 341 Ks and 22 complete games while pitching 299 innings. He average 10.64 strikeouts per nine innings and led the league in that category, too. Ryan never won a Cy Young Award during his career and his SN Pitcher of the Year Award in 1977 was his only one. He finished in the top-5 in voting for Cy Young 6 times, but never took the prize. In 1973 he struck out a record 383 batters and won 21 games while completing 26 games, but Jim Palmer who had 220 fewer strikeouts took the honors. As far as the card goes, they did get a decent looking head on portrait of the guy, but why not have a pic of him doing what he did to break the record? A pic of him pitching, presumably striking someone out would have been much better. In 1990, at the age of 43 Ryan struck out 232 batters to lead the American League in that statistic for the 11th and final time. That year he went 13-9 with a 3.44 ERA. The year prior, he went to his final All Star game, struck out 301 and notched 16 wins, all at age 42. Ryan only topped 20 wins twice, he never won a Cy Young and he even led the league in losses one year, but he will forever be known as the most prolific strikeout pitcher of All Time. Ryan stands out even among the other record breakers for a lot of reasons, but most impressively, that he played 16 more seasons after breaking this record. Still, even with all of his records and amazing performances, when I think of Nolan Ryan, I still go right to him getting Robin Ventura in a headlock... Just one more record breaker to go. Go Baseball!!!\ni machine metal for a paycheck, i announce roller derby for reasons other than a paycheck. i put out records, still waiting for the paycheck...i spend a lot of time sitting in front of the computer... i go by a few different names; marck bacontowne, sinkhole marck, side of bacon, mister gin n juice and now you can call me Collective Troll']	['<urn:uuid:73ef62bd-ef76-4dbf-b99c-907c5121d5b7>', '<urn:uuid:3960a71f-323e-408d-ba2c-c55ee85d510a>']	open-ended	with-premise	concise-and-natural	similar-to-document	multi-aspect	novice	2025-05-01T22:36:12.692263	12	76	1456
163	solvent vapors vs asbestos exposure health surveillance requirement workplace	While both solvent vapors and asbestos exposure require workplace safety measures, only asbestos exposure legally requires formal health surveillance under OSH Regulations 1996. Solvent exposure is monitored through exposure limits (PELs and TLVs), while asbestos exposure must be monitored through mandatory health surveillance conducted by an Appointed Medical Practitioner.	['Asbestos: Health surveillance - Guide for employers\nInhalation of respirable asbestos fibres may cause diseases such as asbestosis, lung cancer and mesothelioma. Risk factors include the dose (number of fibres inhaled), lifetime exposure, fibre type, smoking status and genetics. If the health of a person is at risk as a result of exposure to asbestos at work, the employer must ensure that health surveillance is carried out in accordance with the Occupational Safety and Health (OSH) Regulations 1996.\nWhat is health surveillance?\nHealth surveillance is monitoring a person to identify changes in their health resulting from exposure to a hazardous substance.\nWhy should health surveillance be conducted?\nHealth surveillance may detect harm to health at an earlier stage, allowing controls to be improved to protect workers’ health or earlier medical treatment.\nWhat regulations apply to health surveillance?\nIf the health of a person is at risk as a result of exposure to asbestos at work, the employer must ensure that health surveillance is carried out in accordance with the Occupational Safety and Health (OSH) Regulations 1996. Regulation 5.1 defines ‘health surveillance’ and regulation 5.23 requires an employer, main contractor or self-employed person to provide health surveillance to a worker in relation to hazardous substances.\nWhat activities may present a health risk?\nActivities that may present a health risk due to asbestos exposure, and where health surveillance should be carried out, include:\n- Removal or handling of friable asbestos materials (‘friable’ means the asbestos containing material is in a powder form, or can be crumbled by hand pressure);\n- Handling asbestos using unsafe practices (eg cutting with power tools - note that this is not permitted under OSH legislation); or\n- Activities where asbestos exposure is at or above the asbestos exposure standard (8 hour time weighted average of 0.1 fibres/mL)\nPlease note that excessive exposure to asbestos must be reported to WorkSafe (OSH Regulation 5.40) and exposed people must be informed (OSH Regulation 5.41).\nAll air has a very low background level of asbestos. Low risk activities such as working in asbestos cement buildings, or maintaining such buildings using safe work methods, do not require health surveillance.\nWho can provide health surveillance?\nHealth surveillance must be conducted by an Appointed Medical Practitioner (AMP), a doctor with adequate training and experience in relation to asbestos and who has been appointed by the employer after consultation with the worker/s. WorkSafe has a list of doctors who conduct health surveillance work, although not all such doctors are listed.\nIf the doctor you choose has not conducted health surveillance for asbestos previously, it is essential for them to contact WorkSafe’s occupational physician on 1300 307 877 to ensure they are aware of their duties under OSH legislation.\nShould there be any indications of adverse health effects from asbestos exposure, the AMP can refer the person to a respiratory physician for an assessment.\nHow often should health surveillance for asbestos be conducted?\nFollowing the baseline assessment, the frequency of health surveillance is based on medical advice and depends on the individual’s risk profile.\nWhat further information is available?\nAsbestos health surveillance reporting form (for the AMP to report results to WorkSafe):\nSafe Work Australia guidance on health surveillance (also called “health monitoring”):\n- Health Monitoring for Exposure to Hazardous Chemicals - Guide for persons conducting a business or undertaking\n- Health Monitoring for Exposure to Hazardous Chemicals - Guide for workers\n- Health Monitoring for Exposure to Hazardous Chemicals - Guide for medical practitioners\n- Hazardous Chemicals Requiring Health Monitoring\nWorkSafe guidance on asbestos safety:\n- National code of practice for the management and control of asbestos in workplaces [NOHSC:2018 (2005)]\n- National code of practice for the safe removal of asbestos 2nd edition [NOHSC:2002(2005)]\n- Asbestos in the workplace\nShare this page:', 'Many solvents pose serious health and safety hazards, and the government is increasingly regulating worker exposure and overall usage. Epoxy users commonly use solvents to dissolve epoxy from tools and to degrease surfaces before bonding. Solvents’ ability to dissolve and degrease is part of why they are hazardous to your health. They leach oils from the skin and break down protective fatty layers. This makes skin more susceptible to dermatitis. While dermatitis is the most common skin problem solvents cause, it doesn’t stop there.\nOnce solvents have penetrated the protective skin layers, they may quickly find their way into the blood stream. You can absorb toxic amounts in this way. If you use solvent to clean epoxy from your skin, your skin can absorb both the solvent and the dissolved epoxy. This will intensify epoxy exposure.\nAlmost all solvents are toxic if you swallow, absorb or inhale enough. Solvents can irritate your respiratory system, eyes, and skin. Some solvents may damage your heart, liver, and other vital organs. Several solvents have been linked to cancer.\nRepeatedly inhaling low to moderate levels of solvents can irritate the respiratory tract. Because of their drying effect, solvents can also interfere with the lung’s natural ability to clean themselves of impurities. When inhaled in high concentrations, solvents may depress the central nervous system. This is called narcosis. Symptoms of overexposure range from nausea and irritability to something that resembles alcohol intoxication. Continued overexposure to particularly toxic solvents can lead to loss of consciousness, permanent brain damage and death.\nSome solvents give off a strong odor when highly concentrated, while others do not. Even for those that do, you may not notice the odor after you are exposed to it for a few hours, or if you have a cold. If you notice a strong odor while using a solvent, vapors may already be too highly concentrated and you will need to ventilate more or use a supplied-air respirator. Many milder solvents are being developed to replace the more hazardous solvents. If the manufacturer of solvent claims its product can be used on the skin, you should follow instructions carefully, and wash afterward with warm, soapy water.\nOSHA sets Permissible Exposure Limits (PELs) for chemicals, based on the amount or vapor level a worker can safely be exposed to in a given time period. The American Conference of Governmental Industrial Hygienists also sets exposure levels based on an 8-hour time-weighted average, called Threshold Limit Values or TLVs. These values are expressed in parts of contaminant per million parts of air.\nAlways select the least toxic and least flammable solvent that will get the job done. Avoid solvents completely if at all possible.\nDo not smoke or use equipment that may generate sparks near solvent vapors or solvent storage areas. Store solvents in tightly closed, approved containers. Store them a safe distance from any ignition source and out of children’s reach.\nUse solvents only in well-ventilated areas. Bring fresh air into your shop and exhaust solvent laden air. In confined areas, wear the appropriate respiratory protection. If you can, set up a basic mechanical ventilation scheme for all projects calling for solvents.\nTake special care in hot weather, when solvents evaporate quickly and are more likely to ignite.\nDo not operate power machinery or climb ladders if you have been working with solvents in a confined area. If you feel drowsy, nauseated, *high* or irritable while using solvents, immediately move to an area of fresh air. First aid for unconsciousness resulting from overexposure to solvent vapors is fresh air.\nMost solvents are extremely flammable. By themselves, in paints, or other products, solvents cause many shop fires. The fire hazards that solvents pose may be their greatest threat, to both human health and property. You must follow basic shop safety rules whenever you use them. Research the flash points and evaporation rates, and use adequate ventilation. Remove all ignition sources. The table below lists some important comparative health and flammability information for solvents commonly used in the shop.\nAn explosion can happen when solvent vapors mix with high concentrations of fine dust particles suspended in the air. Even by itself, wood dust is explosive. The finer the dust particle, the greater the chance of explosion. Also, as temperatures increase, an explosion can happen at lower solvent vapor concentrations. One worker, hand sanding, could not raise enough dust to cause an explosion, but several people operating power sanding equipment could.\nAn open flame can set off an explosion, as can an accidental charge of static electricity or a spark from a combustion engine, light switch or power tool. Some fine powders and fillers can generate enough static electricity to ignite a flammable atmosphere. When handling large quantities of powdered material, keep airborne concentrations to a minimum and use grounding devices on transfer equipment.\nDust from partially cured epoxy can cause respiratory problems if inhaled, and dermatitis if allowed to settle on skin. Dust from fully cured epoxy is chemically inert and considered a nuisance dust from a health hazard standpoint. However, enough cured epoxy dust suspended in the air could creat a combustible dust atmosphere.\nDust from woods commonly used with epoxy, such as cedar, redwood, mahogany and teak, can cause allergic skin and respiratory reactions. Wood saps and oils contain irritants. These allergens are reduced as lumber dries, so it is always better to work with seasoned wood.\nDust from minerals, such as asbestos and crystalline (not amorphous) silica are dangerous because of their shape, which makes them difficult to expel from the lungs. This is also true of airborne glass, carbon and similar fibers, coming from cutting and handling glass tape or cloth, or from sanding or grinding a fiberglass composite. Use these materials only with adequate ventilation and appropriate respiratory protection, such as an approved particulate dust mask. For comfort and safety, avoid inhaling these dust!\nThe following sensible shop suggestions may help to reduce exposure to epoxy dust, wood dust and fillers.']	['<urn:uuid:ab46da40-6d62-4978-b0b1-405f041d3134>', '<urn:uuid:db55812f-8784-41f2-931f-46abce06943d>']	factoid	direct	long-search-query	similar-to-document	comparison	novice	2025-05-01T22:36:12.692263	9	49	1626
164	lymph node removal patterns compare egja gastrectomy	The patterns of lymph node removal differ between EGJA and standard gastrectomy procedures. In EGJA, lymph node involvement varies by tumor type - Type I has more mediastinal lymph node dissemination, while Types II and III show more involvement in lower mediastinum and celiac trunk area, requiring D2-lymphadenectomy extended to lower mediastinum. For standard gastrectomy in gastric cancer, the extent of lymph node removal is debated, but studies indicate improved survival with greater lymph node removal, though the specific number to remove remains controversial. The surgical approach must be tailored to the location and type of disease in both cases.	"[""Identifying and defining the esophagogastric junctional adenocarcinoma (EGJA) as an independent disease apart from gastric cancer (GC) and esophagus cancer (EG) it has always been a difficult issue entailing doubts about the appropriate therapeutic approach. In fact, the EGJA is not entirely comparable with GC and EG in terms of epidemiology, risk factors, etiology and pathophysiology.\nThe incidence of EGJA has showing an opposite trend compared to GC because the incidence of EGJA has been increasing in the recent years while the GC has been decreasing. Furthermore, the EGJA prognosis is worse than the GC. In fact, EGJA has a lower prevalence of early gastric adenocarcinoma (5.6% vs. 22.2%, P<0.001) and R0 (86% vs. 92.8%, P<0.001) and a higher frequency of lymph node metastasis (76.3% vs. 67.4%, P<0.003) compared to GC (1).\nLeers et al. (2) showed that the presence of reflux symptoms and peritumoral intestinal metaplasia is greater in the distal esophagus adenocarcinoma than in EGJA, while the location and prevalence of lymph node metastases is similar.\nThe incidence of EGJA, since the mid-1970s, has increased in Western countries, mostly in the white man and in the United States (3.1 per 100.000) surpassing EC and EG (3).\nMessager et al. (4) compared five different European countries, noting that EGJA and EG predominate in Europe except in Spain where the GC is prevalent.\nSince the borderline tumor location of EGJA between esophagus and stomach (stratified squamous epithelium vs. gastric simple columnar epithelium), a clear definition and classification of the tumor was necessary to arrive to an optimal therapeutic strategy.\nIn 1996, Siewert at al. (7) have proposed a different classification and definition of the EGJA. The EGJA is a neoformation growing within 5 cm from anatomical cardia (distally or proximally), dividing into three subtypes:\n- Type I: adenocarcinoma of distal esophagus with extension from 1 to 5 cm above the junction (which may infiltrate the esophagogastric junction).\n- Type II: adenocarcinoma of the cardia or “junctional carcinoma” with extension from 1 cm above to 2 cm under the junction.\n- Type III: subcardial gastric carcinoma with extension from 2 to 5 cm under the junction (which may infiltrate the esophagogastric junction).\nType I is often associated with Barrett dysplasia and a long history of gastro-esophageal reflux disease (GERD).\nThe incidence of GERD is higher in the United States and in Europe than in Asia and Southern China. Although, in recent years it has been an increase on the frequency of GERD in Asia (8).\nIn 2007 Siewert et al. (9) showed that in 79.5% of Type I EGJA an area of intestinal metaplasia (Barrett’s esophagus) was present, while it was not found in the type III. This is probably due to the higher degree of undifferentiation (G3/G4 grading) of type III compared to the type I (54.4% vs. 73.4%). Epidemiologically type II has been considered a middle group between type I and type III.\nOver the years, a possible correlation between GERD and EGJA has been discussed. Many authors have highlighted that a long exposure of gastric acid can damage epithelium of the esophagus and of the esophagogastric junction resulting mutation in Barrett’s esophagus, dysplasia, and then finally in adenocarcinoma (10-12). Chak et al. (11) have shown a strong association between EGJA and GERD related to other risk factors like a positive family story, age (older), gender (male) and obesity. However, not all the three types of EGJA seem to have a correlation with GERD. In fact, there is a positive correlation with the type I and not with the type II and III (12).\nLiu et al. (6) have showed a recent increase of type I and type III prevalence and a type II decrease in 5,053 patients during 1988–2012. In type I the prevalence of GERD oscillated from 41.3% to 57.1%.\nIn the literature, many authors have attempted to identify the risk factors most involved on this type of tumors. Multiple studies have shown a strong correlation between smoking (pack-years of smoking) and increased risk of EGJA. Moreover, the use of alcohol appears to have no correlation with EGJA. Other risk factors involved in the onset of the EGJA are obesity and high fat dietary (13).\nThe choice of a more appropriate therapeutic strategy requires a correct staging of the disease determined by TNM classification. This is possible by using CT scan, endoscopic ultrasound, MRI and PET.\nMany studies have shown the importance of radical surgery (radical resection of the tumor and complete lymphadenectomy) for a long-term survival in this type of tumors. However, it remains yet discussed the most appropriate surgical approach.\nThe possible surgical approaches for the EGJA include transhiatal total or subtotal gastrectomy, abdominothoracic total esophagogastrectomy, distal esophagectomy with resection of the proximal stomach, total gastrectomy with transhiatal resection of distal esophagus, limited resection of the esophagogastric junction or Ivor-Lewis.\nVrouenraets et al. (14) have highlighted an advantage in terms of fewer complications and reduced hospital stay performing the transhiatal esophagectomy approach for cardia cancer and EGJA compared to transthoracic approach with a better 5-year survival rate.\nHulscher et al. (15) compared transhiatal esophagectomy with extended transthoracic esophagectomy in patients with adenocarcinoma of the mid-to-distal esophagus or cancer involving the gastric cardia and the distal esophagus at early stage. The transhiatal approach is associated to a lower morbidity, while the 5-year survival was slightly better in the extended transthoracic approach.\nMany authors described a different surgical approach according to the classification of Siewert. For the type I no impressive differences were found in the long-term survival rate between the radical transmediastinal esophagectomy and the transthoracic esophagectomy with the resection of proximal stomach. For type II and III a transhiatal total gastrectomy was recommend with the resection of distal esophagus (16-18).\nIn the early carcinoma (with tumors limited to the mucosa and without lymph node metastases, T1N0) a limited resection of the esophagogastric junction (16) possibly associated to the distal esophagus with interposition of a pedicled jejunal was indicated (17). Whereas, many authors have shown that the subtotal gastrectomy is characterized by an increased post-operative complications rate, such as increased incidence of reflux oesophagitis and anastomotic stenosis, compared to a total gastrectomy (18,19).\nIn the stage T3/T4 a neoadjuvant therapy was recommended (17).\nDuan et al. (20) compared the application of the right transthoracic Ivor-Lewis to the left transthoracic and thoracoabdominal approach in Siewert type II, concluding that the Ivor-Lewis approach is a more effective approach concerning the margin free resection, the adequate lymphadenectomy and the long-term patient survival.\nThe intraoperative digestive tract reconstruction after total gastrectomy plays an important role to reduce post-operative complications. The classic Roux-en-Y reconstruction is considered the optimal choice. Xiao et al. (21) compared the Roux-en-Y reconstruction with the antrum-preserving double-tract reconstruction showing that the Roux-en-Y approach is characterized by an increased complications rate such as cholelithiasis, malnutrition, dumping syndrome and esophageal reflux. Furthermore, the antrum-preserving double-tract reconstruction by jejunal interposition offers less hospitalization and reduces the gastroesophageal reflux, the malabsorption syndrome and the dumping syndrome. Moreover, they recommended this approach for the Siewert type I and III.\nFor the reconstruction of digestive tract in limited resection (subtotal gastrectomy) a gastric-esophageal anastomosis is normally performed, leading to a severe alkaline reflux and a low quality of life. The interposition of an isoperistaltic jejuan or colon segment can improve the quality of life (22).\nThe 5-year survival in EGJA is also related to an adequate lymphadenectomy. Lymph node involving is less common in the type I than in the type II and III. In the type I is more common the lymph node dissemination in the mediastinum (in the tracheal bifurcation and above). Type II and III are most affected by the lymph node dissemination in the lower mediastinum and in the area of coeliac trunk (8).\nIn a German review (23) a D2-lymphadenectomy extended to the lower mediastinum by a transhiatal approach is recommended in type II and III. For type I is recommended a lymphadenectomy of the lower mediastinum and a lymphadenectomy of the perigatric region.\nIn the esophagus-predominant adenocarcinoma a lower mediastinal lymphadenectomy has a greater therapeutic index value. In the stomach-predominant adenocarcinoma the right and left cardia, the small curvature, along the left gastric artery and the subpancreatic lymphadenectomy has a greater therapeutic index value. In conclusion, the prophylactic distal stomach lymphadenectomy seems to offer an advantage in terms of survival (24).\nFinally, Ito et al. (25) showed a lack of cervical lymph node invasion in EGJA and a higher incidence of mediastinal lymph node metastasis in the esophageal-predominant cancer, resulting in a lower survival compared to a gastric-predominant cancer.\nLiu et al. evaluated a sample of 5,053 patients with GERD and EGJA underwent surgical treatment during a period of 25 years (from 1988 to 2012) highlighting the changing of epidemiological characteristics and treatment approaches in recent years. The study is well written, presenting a large number of patients enrolled during 5 homogeneous periods of time. Thus, the study is statistically valid.\nThe strength of this study is that in different periods of time various aspects were analysed: the changing trend of EGJA subtypes (Siewert classification), the changing trend of the presence of GERD in EGJA, the change of trend of clinical-pathological features and the changing of trend of surgical treatment and post-operative complications.\nHowever, the study retains a retrospective nature, carried out in a single centre of Western China. Only patients who underwent surgical treatment were enrolled while those patients with EGJA who did not have the surgical treatment were excluded.\nIn conclusion, the recent increase of 5-year survival rate in EGJA may be due to the new EGJA classification (considering the EGJA a different tumor from esophagus or GC) and to the new technologies and surgical techniques. In the future, the advent of newer diagnostic techniques, allowing an earlier diagnosis, and innovative surgical techniques associated to decreased post-operative complications will probably lead to an improvement of survival and quality of life of patients with EGJA. Furthermore, an effective screening with a primary prevention can reverse the trend in countries with increased incidence of GERD and EGJA.\nConflicts of Interest: The authors have no conflicts of interest to declare.\n- Liu K, Zang W, Chen X, et al. Comparison on Clinicopathological Features and Prognosis Between Esophagogastric Junctional Adenocarcinoma (Siewert II/III Types) and Distal Gastric Adenocarcinoma: Retrospective Cohort Study, a Single Institution, High Volume Experience in China. Medicine (Baltimore) 2015;94:e1386. [Crossref] [PubMed]\n- Leers JM, DeMeester SR, Chan N, et al. Clinical characteristics, biologic behavior, and survival after esophagectomy are similar for adenocarcinoma of the gastroesophageal junction and the distal esophagus. J Thorac Cardiovasc Surg 2009;138:594-602. [Crossref] [PubMed]\n- DeMeester SR. Adenocarcinoma of the Esophagus and Cardia: A review of the desease and its treatment. Ann Surg Oncol 2006;13:12-30. [Crossref] [PubMed]\n- Messager M, de Steur WO, van Sandick JW, et al. Variations among 5 european countries for curative treatment of resectable oesophageal and gastric cancer: A survey from EURECCA Upper GI Group (Europian Registration of Cancer CAre). Eur J Surg Oncol 2016;42:116-22. [Crossref] [PubMed]\n- Hasegawa S, Yoshikawa T. Adenocarcinoma of the esophagogastrici Juntion: incidence, characteristics, and treatment strategies. Gastric Cancer 2010;13:63-73. [Crossref] [PubMed]\n- Liu K, Yang K, Zhang W, et al. Changes of Esophagogastric Junctional Adenocarcinoma and Gastroesophageal Reflux Disease Among Surgical Patients During 1988–2012. A Single-institution, High-volume Experience in China. Ann Surg 2016;263:88-95. [Crossref] [PubMed]\n- Siewert JR, Stein HJ. Classification of adenocarcinoma of the oesophagogastric junction. Br J Surg 1998;85:1457-9. [Crossref] [PubMed]\n- Lim LG, Ho KY. Gastroesophgeal reflux desease at the turn of millennium. World J Gastroenterol 2003;9:2135-6. [Crossref] [PubMed]\n- Siewert JR, Feith M. Adenocarcinoma of the esophagogastric juntion: competition between Barret and gastric cancer. J Am Coll Surg 2007;205:S49-S53. [Crossref] [PubMed]\n- Goldblum JR. Barrett's esophagus and Barrett's-related dysplasia. Mod Pathol 2003;16:316-24. [Crossref] [PubMed]\n- Chak A, Lee T, Kinnard MF, et al. Familial aggregation of Barrett's oesophagus, oesophageal adenocarcinoma, and oesophagogastric junctional adenocarcinoma in Caucasian adults. Gut 2002;51:323-8. [Crossref] [PubMed]\n- Yang K, Hu JK. The thinking to the huge disease burden of gastric cancer in China and the increasing tendency of esophagogastric junctional adenocarcinoma. Transl Gastroenterol Hepatol 2016;1:32. [Crossref] [PubMed]\n- Buas MF, Vaughan TL. Epidemiology and risk factors for gastroesophageal junction tumors: under standing the rising incidence of this disease. Semin Radiat Oncol 2013;23:3-9. [Crossref] [PubMed]\n- Vrouenraets BC, van Lanschot JJ. Extent of surgical resection for esophageal and gastroesophageal junction adenocarcinomas. Surg Oncol Clin N Am 2006;15:781-91. [Crossref] [PubMed]\n- Hulscher JBF, van Sandick JW, de Boer AG, et al. Extended transthoracic resection compared with limited transhiatal resection for adenocarcinoma of the esophagus. N Engl J Med 2002;347:1662-9. [Crossref] [PubMed]\n- Stein HJ, Feith JR, Siewert JR. Individulized surgical strategies for cancer of the esophagogastric junction. Ann Chir Gynaecol 2000;89:191-8. [PubMed]\n- Stein HJ, Feith JR, Siewert JR. Cancer of the esophagogastric juntion. Surg Oncol 2000;9:35-41. [Crossref] [PubMed]\n- Rüdiger Siewert J, Feith M, et al. Adenocarcinoma of the esophagogastric junction. Results of surgical therapy based on anatomical/topographic classification in 1,002 consecutive patients. Ann Surg 2000;232:353-61. [Crossref] [PubMed]\n- An JY, Youn HG, Choi MG, et al. The difficult choice between total andproximal gastrectomy in proximal early gastric cancer. Am J Surg 2008;196:587-91. [Crossref] [PubMed]\n- Duan XF, Yue J, Tang P, et al. Lymph node dissection for Siewert II esophagogastric junction adenocarcinoma: A retrospective study of 3 surgical procedures. Medicine (Baltimore) 2017;96:e6120. [Crossref] [PubMed]\n- Xiao JW, Liu ZL, Ye PC, et al. Clinical comparison of antrum-preserving double tract reconstruction vs roux-en-Y reconstruction after gastrectomy for Siewert types II and III adenocarcinoma of the esophagogastric junction. World J Gastroenterol 2015;21:9999-10007. [Crossref] [PubMed]\n- Siewert JR, Feith M, Stein HJ. Biologic and clinical variation of adenocarcinoma at the esophago-gastric junction: relevance of a topographic-anatomic subclassification. J Surg Oncol 2005;90:139-46. [Crossref] [PubMed]\n- Mönig SP, Schröder W, Beckurts KT, et al. Classification, diagnosis and surgical treatment of carcinomas of the gastroesophageal junction. Hepatogastroenterology 2001;48:1231-7. [PubMed]\n- Yamashita H, Seto Y, Sano T, et al. Results of a nation-wide retrospective study of lymphadenectomy for esophagogastric junction carcinoma. Gastric Cancer 2017;20:69-83. [Crossref] [PubMed]\n- Ito H, Inoue H, Odaka N, et al. Clinicopathological characteristics and optimal management for esophagogastric junctional cancer; a single center retrospective cohort study. J Exp Clin Cancer Res 2013;32:2. [Crossref] [PubMed]"", 'Gastrectomy is the surgical removal of all or part of the stomach.\nGastrectomy is performed most commonly to treat the following conditions:\n- stomach cancer\n- bleeding gastric ulcer\n- perforation of the stomach wall\n- noncancerous polyps\nStomach cancer was the most common form of cancer worldwide in the 1970s and early 1980s, and the incidence rates have always shown substantial variation in different countries. Rates are currently highest in Japan and eastern Asia, but other areas of the world have high incidence rates, including Eastern European countries and parts of Latin America. Incidence rates are generally lower in Western Europe and the United States.\nGastrointestinal diseases (including gastric ulcers) affect an estimated 25–30% of the world\'s population. In the United States, 60 million adults experience gastrointestinal reflux at least once a month, and 25 million adults suffer daily from heartburn, a condition that may evolve into ulcers.\nGastrectomy for cancer\nRemoval of the tumor, often with removal of the surrounding lymph nodes, is the only curative treatment for various forms of gastric (stomach) cancer. For many patients, this entails removing not only the tumor, but part of the stomach as well. The extent to which lymph nodes should also be removed is a subject of debate, but some studies show additional survival benefits associated with removal of a greater number of lymph nodes.\nGastrectomy, either total or subtotal (also called partial), is the treatment of choice for gastric adenocarcinomas, primary gastric lymphomas (originating in the stomach), and the rare leiomyosarcomas (also called gastric sarcomas). Adenocarcinomas are by far the most common form of stomach cancer and are less curable than the relatively uncommon lymphomas, for which gastrectomy offers good chances of survival.\nGeneral anesthesia is used to ensure that the patient does not experience pain and is not conscious during the operation. When the anesthesia has taken hold, a urinary catheter is usually inserted to monitor urine output. A thin nasogastric tube is inserted from the nose down into the stomach. The abdomen is cleansed with an antiseptic solution. The surgeon makes a large incision from just below the breastbone down to the navel. If the lower end of the stomach is diseased, the surgeon places clamps on either end of the area, and that portion is excised. The upper part of the stomach is then attached to the small intestine. If the upper end of the stomach is diseased, the end of the esophagus and the upper part of the stomach are clamped together. The diseased part is removed, and the lower part of the stomach is attached to the esophagus.\nAfter gastrectomy, the surgeon may reconstruct the altered portions of the digestive tract so that it may continue to function. Several different surgical techniques are used, but, generally speaking, the surgeon attaches any remaining portion of the stomach to the small intestine.\nGastrectomy for gastric cancer is almost always done using the traditional open surgery technique, which requires a wide incision to open the abdomen. However, some surgeons use a laparoscopic technique that requires only a small incision. The laparoscope is connected to a tiny video camera that projects a picture of the abdominal contents onto a monitor for the surgeon\'s viewing. The stomach is operated on through this incision.\nThe potential benefits of laparoscopic surgery include less postoperative pain, decreased hospitalization, and earlier return to normal activities. The use of laparoscopic gastrectomy is limited, however. Only patients with early-stage gastric cancers or those whose surgery is intended only for palliation (pain and symptomatic relief rather than cure) are considered for this minimally invasive technique. It can only be performed by surgeons experienced in this type of surgery.\nGastrectomy for ulcers\nGastrectomy is also occasionally used in the treatment of severe peptic ulcer disease or its complications. While the vast majority of peptic ulcers (gastric ulcers in the stomach or duodenal ulcers in the duodenum) are managed with medication, partial gastrectomy is sometimes required for peptic ulcer patients who have complications. These include patients who do not respond satisfactorily to medical therapy; those who develop a bleeding or perforated ulcer; and those who develop pyloric obstruction, a blockage to the exit from the stomach.\nThe surgical procedure for severe ulcer disease is also called an antrectomy , a limited form of gastrectomy in which the antrum, a portion of the stomach, is removed. For duodenal ulcers, antrectomy may be combined with other surgical procedures that are aimed at reducing the secretion of gastric acid, which is associated with ulcer formation. This additional surgery is commonly a vagotomy , surgery on the vagus nerve that disables the acid-producing portion of the stomach.\nBefore undergoing gastrectomy, patients require a variety of such tests as x rays, computed tomography (CT) scans, ultrasonography, or endoscopic biopsies (microscopic examination of tissue) to confirm the diagnosis and localize the tumor or ulcer. Laparoscopy may be done to diagnose a malignancy or to determine the extent of a tumor that is already diagnosed. When a tumor is strongly suspected, laparoscopy is often performed immediately before the surgery to remove the tumor; this method avoids the need to anesthetize the patient twice and sometimes avoids the need for surgery altogether if the tumor found on laparoscopy is deemed inoperable.\nAfter gastrectomy surgery, patients are taken to the recovery unit and vital signs are closely monitored by\nSurgery for peptic ulcer is effective, but it may result in a variety of postoperative complications. Following gastrectomy surgery, as many as 30% of patients have significant symptoms. An operation called highly selective vagotomy is now preferred for ulcer management, and is safer than gastrectomy.\nAfter a gastrectomy, several abnormalities may develop that produce symptoms related to food intake. They happen largely because the stomach, which serves as a food reservoir, has been reduced in its capacity by the surgery. Other surgical procedures that often accompany gastrectomy for ulcer disease can also contribute to later symptoms. These procedures include vagotomy, which lessens acid production and slows stomach emptying; and pyloroplasty , which enlarges the opening between the stomach and small intestine to facilitate emptying of the stomach.\nSome patients experience lightheadedness, heart palpitations or racing heart, sweating, and nausea and vomiting after a meal. These may be symptoms of ""dumping syndrome,"" as food is rapidly dumped into the small intestine from the stomach. Dumping syndrome is treated by adjusting the diet and pattern of eating, for example, eating smaller, more frequent meals and limiting liquids.\nPatients who have abdominal bloating and pain after eating, frequently followed by nausea and vomiting, may have what is called the ""afferent loop syndrome."" This is treated by surgical correction. Patients who have early satiety (feeling of fullness after eating), abdominal discomfort, and vomiting may have bile reflux gastritis (also called bilious vomiting), which is also surgically correctable. Many patients also experience weight loss.\nReactive hypoglycemia is a condition that results when blood sugar levels become too high after a meal, stimulating the release of insulin, occurring about two hours after eating. A high-protein diet and smaller meals are advised.\nUlcers recur in a small percentage of patients after surgery for peptic ulcer, usually in the first few years. Further surgery is usually necessary.\nVitamin and mineral supplementation is necessary after gastrectomy to correct certain deficiencies, especially vitamin B 12 , iron, and folate. Vitamin D and calcium are also needed to prevent and treat the bone problems that often occur. These include softening and bending of the bones, which can produce pain and osteoporosis, a loss of bone mass. According to one study, the risk for spinal fractures may be as high as 50% after gastrectomy.\nOverall survival after gastrectomy for gastric cancer varies greatly by the stage of disease at the time of surgery. For early gastric cancer, the five-year survival rate is as high as 80–90%; for late-stage disease, the prognosis is bad. For gastric adenocarcinomas that are amenable to gastrectomy, the five-year survival rate is 10–30%, depending on the location of the tumor. The prognosis for patients with gastric lymphoma is better, with five-year survival rates reported at 40–60%.\nMost studies have shown that patients can have an acceptable quality of life after gastrectomy for a potentially curable gastric cancer. Many patients will maintain a healthy appetite and eat a normal diet. Others may lose weight and not enjoy meals as much. Some studies show that patients who have total gastrectomies have more disease-related or treatment-related symptoms after surgery and poorer physical function than patients who have subtotal gastrectomies. There does not appear to be much difference, however, in emotional status or social activity level between patients who have undergone total versus subtotal gastrectomies.\nMorbidity and mortality rates\nDepending on the extent of surgery, the risk for postoperative death after gastrectomy for gastric cancer has been reported as 1–3% and the risk of non-fatal complications as 9–18%. Overall, gastric cancer incidence and mortality rates have been declining for several decades in most areas of the world.\n""Disorders of the Stomach and Duodenum."" In The Merck Manual. Whitehouse Station, NJ: Merck & Co., Inc., 1992.\n""Stomach and Duodenum: Complications of Surgery for Peptic Ulcer Disease."" In Sleisenger & Fordtran\'s Gastrointestinal and Liver Disease, edited by Mark Feldman et al. Philadelphia: W. B. Saunders Co., 1998.\nFujiwara, M., et al. ""Laparoscopy-Assisted Distal Gastrectomy with Systemic Lymph Node Dissection for Early Gastric Carcinoma: A Review of 43 Cases."" Journal of the American College of Surgeons 196 (January 2003): 75–81.\nIseki, J., et al. ""Feasibility of Central Gastrectomy for Gastric Cancer."" Surgery 133 (January 2003): 75–81.\nKim, Y. W., H. S. Han, and G. D. Fleischer. ""Hand-Assisted Laparoscopic Total Gastrectomy."" Surgical Laparoscopy, Endoscopy & Percutaneous Techniques 13 (February 2003): 26–30.\nKono, K., et al. ""Improved Quality of Life with Jejunal Pouch Reconstruction after Total Gastrectomy."" American Journal of Surgery 185 (February 2003): 150–154.\nAmerican College of Gastroenterology. 4900-B South 31st St., Arlington, VA 22206. (703) 820-7400. http://www.acg.gi.org .\nAmerican Gastroenterological Association (AGA). 4930 Del Ray Avenue, Bethesda, MD 20814. (301) 654-2055. http://www.gastro.org .\nMayo Clinic Online: Gastrectomy. http://www.mayohealth.com .\nCaroline A. Helwick\nMonique Laberge, PhD\nWHO PERFORMS THE PROCEDURE AND WHERE IS IT PERFORMED?\nA gastrectomy is performed by a surgeon trained in gastroenterology, the branch of medicine that deals with the diseases of the digestive tract. An anesthesiologist is responsible for administering anesthesia, and the operation is performed in a hospital setting.\nQUESTIONS TO ASK THE DOCTOR\n- What happens on the day of surgery?\n- What type of anesthesia will be used?\n- How long will it take to recover from the surgery?\n- When can I expect to return to work and/or resume normal activities?\n- What are the risks associated with a gastrectomy?\n- How many gastrectomies do you perform in a year?\n- Will there be a scar?']"	['<urn:uuid:6b00e754-c483-4c30-b40c-c311b452fd6c>', '<urn:uuid:c93b5928-4281-43e4-a94d-110c36017997>']	open-ended	direct	short-search-query	similar-to-document	comparison	expert	2025-05-01T22:36:12.692263	7	100	4176
165	contrast hunting tactics versus shot success rate tree stand spot stalk bow hunting	In tree stand hunting, hunters see many deer but often out of range, requiring potential stand relocations to get closer to deer travel paths. Success comes from waiting for the right moment when deer pass within 30 yards, ideally to the left for right-handed shooters. In spot and stalk hunting, approximately one in six stalks results in a shot opportunity, even when getting within 50 yards of mature bucks. Tree stand hunters should tuck their shot behind the front leg on the lower third when deer are broadside or quartering away, while spot and stalk hunters must be prepared to shoot from various positions including side hills, uphill, downhill, or crouching. Both methods require extensive practice in their respective shooting positions before the season.	['Hunting VideosBowhunt or Die\nEarly Season Whitetail Hunting\nForget the rut, the first week of bow season in September or October can be a great time to whack a buck. Whitetail deer are still locked into late-summer feeding patterns, and you can take advantage of that with this 10-step plan.\nSpend a few evenings glassing for deer in a field of alfalfa, clover or cut corn. If you deer huntmostly timbered terrain, glass for does and bucks that feed and mingle at dusk in a clear-cut, power line right-of-way…you get the picture. Your goal is two-fold. Locate at least one Pope & Young buck to go after. And, critically, pinpoint the spot where that brute most often pops out of the surrounding cover.\nDo your glassing, but don’t get lulled into the no-impact, “stay out of a buck’s turf or you’ll spook him” strategy recommended by some of today’s deer hunters. Some hunters feel strongly that at some point you need to go in and evaluate the terrain and sign where deer travel from bed to feed. If you don’t, how in the world can you hang a tree stand and expect Mr. Big to cruise within 20 or 30 yards of it?\nScout one day around lunchtime, when whitetail deer are bedded back in the woods and thickets. Walk across a field or cutover to a spot where you’ve watched a buck step out of the cover. Check the wind; it should blow out into the open area or at least parallel to it. If so, sneak 50 to 100 yards back into the woods. But never push much deeper than that, or else you’re apt to bump loafing deer.\nScout the fringes for doe trails—a trophy buck might stroll down one and into the feed in a couple of weeks. Look for a thin ridge, ditch or edge that might funnel deer. Look closer still for an “inner terrain,” a creek crossing, fence corner or the like, that might further squeeze a buck past a tree stand. Scout for buck rubs and tracks (the bigger the better).\nYou can never, go wrong by locating a tree stand near mast that falls, heaping and fresh, 50 to 100 yards off a field or cutover. Most does and bucks will stop to nibble the acorns or soft mast before heading out to a main feeding area after dark. Try to home in on one or two trees that will rain nuts in a week or so (white oaks are best).\nMany deer hunters pack in a tree stand and fling it up into the first big tree that looks good. After 30 minutes or so of speed scouting, some hunters beat feet out of the woods, go home and study their maps and aerials. They evaluate the terrain, cover, sign\nand mast they found in the transition zone between a feeding and bedding area. These hunters try to piece things together and predict deer movements.\nA few days before the bow opener, some hunters will sneak back in a second time to set a tree stand for afternoon hunting. Again, hunters will go at midday and enter the woods from the food-source side when the wind is right. Head for a spot where you have deduced that your chances of an ambush are high. Check to make sure deer are still running the same trails, and monitor the status of mast trees. Note any buck rubsthat popped up since you were last there. Then look around for a stout tree on the downwind side of a doe trail or funnel. Back up 30 yards, kneel and check the tree from a deer’s perspective. If it offers adequate background cover, bingo!\nTry to lock your tree stand on a tree so that it faces a crop field, food plot or clear-cut. Most deer will come from the woods and thickets to the rear, and the tree between you and them will provide yet more cover. If you shoot right-handed, always try to set up where deer will pass within 30 yards to your left. You can draw and shoot with ease and little movement as a trophy buck quarters past.\nWith the leaves still thick on the trees, you might actually be able to see and shoot best by hunting only 16 to 18 feet high. Be doubly sure the wind is right and steady if you hunt low. Trim at least 3 good shooting lanes to the sides and front of your tree stand. Get out of there and let the spot rest for a couple of days.\nRemember the mantra when you go back to hunt: Access your tree stand from the food-source side, and make sure the wind quarters out of the woods. Climb into your perch by 2 p.m. or so, especially if you hunt in the Midwest or West, where whitetail deer tend to get up and move to feed early.\nAn afternoon fades. Some does tip past, but you spot nary a buck. Don’t get down, get ready! As dusk settles into the woods, stand up and rest your bow in a belt holster. A trophy buck often comes late and quickly to a crop field or mast tree, especially on a warm day. Listen for the pop, pop, pop of his stiff-legged gait behind you. A buck ghosting past your stand in the twilight often looks farther away than he really is. Don’t risk taking too long of a shot, but on the other hand, don’t let a shooter slip by at 25 or 30 yards. If in doubt, do a juggling act and try to laser a deer with a rangefinder.\nAs far as bowhunting shot placement, when a buck is broadside or quartering away, tuck a sight pin behind his front leg and on the lower third of his side. If he ducks when the string twangs, your arrow should still strike the middle or top of his lungs. If the deer doesn’t drop you’ll make an even better shot, low in the lungs and heart.\nIf you double-lung a buck and see him fall, go get him. But when a deerbolts into thick foliage and you’re not so sure about the shot, wait at least 2 hours before tracking. Come back with a buddy and big, powerful lights. A buck might wheel and run back toward a bedding area on a doe trail, so check there for blood. It is no wives’ tale: A wounded deer often runs downhill and toward water.\nOn all those evenings when shooting light wanes and you’re left with no shot, sit awhile and glass deer that still cruise toward a field or mill around mast. Who knows, you might spot a whopper buck you’ve never seen before. When the deer move on and the coast is clear, slip out of your tree stand. By now you should have mapped out an exit route that will take you 50 yards or so back into the woods and away from the feeding area. Circle back to your truck without spooking deer and guess what? Your chances of sticking a buck are still good when you come back to hunt the next afternoon or the next.', 'Preseason scouting and keeping high standards led the author to this mature mule deer buck that he took with his bow and arrow.\nBow and arrow hunting is considered one of the biggest challenges of hunting. To get into bow range of any big game animal can be a challenge, with taking a mature animal such as a buck deer or bull elk being the pinnacle of all hunting. How to increase your odds and becoming a better bow hunter is what we will talk about here.\nThe single thing that can increase your odds of scoring a mature animal the most is scouting. It is incredible the amount of advantage you give yourself over most other hunters and the game itself by knowing where the animals will be come the first day of bow and arrow hunting season. This means you will have to get out early in the mornings throughout the season; time consuming but fun and productive. Evening scouting trips are typically easier to do, but do offer less prime time.\nThe more mature animals you can find before the season, the better. Try to get pictures or video of them if you can. Before the season starts, have them numbered in the order that you want the most and focus on number one opening morning. You can choose to focus on him the rest of the season, or try the next one in the lineup if you can’t turn #1 up.\nScouting can mean different things for different areas. If you plan to be hunting out of a tree stand, then your best scouting weapon will undoubtedly be trail cameras. Put these up where you think the animals will be. Not only will you figure out how many deer, elk, or whatever you are hunting are in the area, but you will also be able to get a good idea of the quality. That way you can pass up a nice buck if you know there is a bigger one in the area. Take time to pick the best location possible for a tree stand and put it up at least a month before opening day of bow and arrow hunting season so the animals will have time to get use to it. It may be wise to have more than one tree stand up in different locations that you can hunt depending on weather conditions; mainly wind.\nFor areas that are more prone to spot and stalk or ambush hunting, then good optics will be your best scouting tool; namely binoculars and a spotting scope (click link to see a list of the best of each in order by price). Try to find the animals from a distance, and then observe. Do not try to get to close; you do not want to spook them. When the season opens you will know right where to go.\nBy putting in your time scouting preseason you will get the most efficient use of your hunting time, especially if you plan to spot and stalk. With bow and arrow hunting you need to waste as little time as possible.\nTree Stand or Blind Hunting: If you have done your preseason scouting, opening day will find you in the spot you have located your first pick animal. Pick your tree stand depending on the wind. Even if you think one of your stands is in a better location than the others, if the wind is wrong, leave it alone. With big bucks or bulls, one false move may be the end of it and they will go elsewhere.\nGet in your stand early; well before light. This will give things time to settle down. Make sure you can get to and from your stand silently and as quickly as possible. Then it is a waiting game. Be patient and stick it out. If you have done good scouting, then you have already increased your odds.\nWaiting for the conditons to become right all day long resulted in taking this nice white tail buck with bow and arrow right before dark as he got up to feed.\nSpot and Stalk Hunting: Opening day should find you doing one of two things. If you have done your scouting and have a good pattern established on the buck you are focusing on, then your best bet might be to intercept him at some point in his daily routine. This can be at a water hole, at his bedding area, feeding area, or anywhere in between; it will mostly depend on the individual animal and where you can slip into without being detected.\nIf you think spot and stalk is your best bet for your area, then opening morning should begin just like a scouting morning, except you will have your bow and arrows with you. The goal is to find the animal first, and then decide on when and how to go about getting within bow and arrow hunting range.\nThe right time to make the stalk may be right away if you determine the wind is blowing right and you feel you have a shot at getting within range undetected. Other times you might have to just watch them until conditions improve, they bed down, and or the wind changes or gets stronger.\nOne of the hardest things to do while spot and stalk bow and arrow hunting is to be patient and hold off on a stalk if conditions are not right or if the target animal is in a bad position. If you choose to stalk a buck and fail do to getting winded, heard, or seen, then there is a chance you will have a much harder time finding that deer again then if you just wait until things change. More times than not, the animal will change location or conditions will change throughout the day making the likely hood of getting to within bow and arrow range of the buck much better. It is not uncommon to watch a deer all day and not have the opportunity presented to make a probable stalk. At least there is a good chance you will be able to find that deer the next day if you do not spook it.\nDo Not Get Discouraged:\nOne of the main reasons for hunters to give up on bow and arrow hunting is the many times you will get close, but not get a shot off. Some people are lucky enough to get a shot their first time out, but this is unlikely. Most people have their fair share of close calls before they get off a shot.\nTree Stand Bow and Arrow Hunting: You will undoubtedly see more deer out of range than in range, unless you set up your stand in an area where you can only see 40 yards. Many times a nice buck will pass by just out of range. It is frustrating, but at least you know the animals are in the area. If this happens repeatedly, then you might want to consider a quick stand placement change to get closer to where the deer are coming through.\nSpot and Stalk Bow and Arrow Hunting: After many years of hunting with a bow and arrow, I have had more than my fair share of close calls. In fact, I have found that it is not all that hard to stalk within 50 yards of a mature buck or bull. The hardest part is getting a shot opportunity. I have found that about one out of six stalks results in a shot opportunity, even if you get within shooting range every time. So if a stalk is unsuccessful, then go find another buck to stalk on. It is largely a numbers game. If you can average at least one stalk per day, then you can expect to have the chance to kill an animal in a week hunt. Sometimes it will take longer though and others it might happen on day one.\nBow and Arrow Practice:\nYou cannot shoot your bow enough to prepare for an upcoming season. If you plan to begin bow and arrow hunting, then it is suggested that you get your bow and arrows early and practice a long time before the season opens. Some people buy a bow and arrows and then expect to shoot an animal in as little as a couple of weeks. This is not acceptable as it takes time and lots of practice to become consistent with archery.\nPractice in the field: If you are hunting out of a tree stand, then you need to practice shooting like you will be hunting. Practice shooting from an elevated position, as it is much different than shooting on the ground. Same goes for spot and stalk; you might find yourself shooting from a number of positions: on a side hill, up or down hill, crouching, off a cliff, or any other angle you can think of. It is best to be prepared, so practice all different ways. You do not want to miss the buck of a life time due to a miss; I speak from personal experience.\nHaving the Right Setup Tuned Properly\nIt is pointless to do anything that has to do with archery without having a bow and arrow setup that is tuned correctly. Even the most expensive bow on the market will not shoot a good group if it is not tuned correctly. Make sure you have an experienced archery technician take a look at your set up.\nThere are things that need to be lined up correctly in order to get consistency. Likewise, your arrows will need to have the correct specs in accordance with the amount of draw weight and arrow length you are shooting. The biggest factor is arrow spine with most arrows having a spine of 340–400, with the smaller the number meaning the stiffer the arrow/spine. When in doubt, go with a stiffer spine.\nIf you are experiencing difficulties in consistent accuracy, you should have things checked out by an experienced technician. Even if your bow and arrows are dialed in, then the tech might be able to point out problems in your shooting form.\nDetermine Your Own Luck:\nSure, there is a part of hunting that is luck, but with the information above you will be able to put that luck on your side. Why do some people consistently get mature animals? It is because they know what they are doing and have learned from the mistakes they have made in the past.\nTo get you started in the right direction as far as equipment, check out these links: Best Arrows for Hunting and Best Broadheads for Hunting. Of course the right equipment will only get you started. It is up to you to do the practice and scouting that result in trophy animals.']	['<urn:uuid:296bb954-66a1-4320-9689-35e9fe6d4bcc>', '<urn:uuid:8908e3f4-e2ef-47d5-9c01-d4914044a5ba>']	open-ended	direct	long-search-query	distant-from-document	comparison	expert	2025-05-01T22:36:12.692263	13	124	3020
167	When was the first beer probably discovered?	The first beer was likely discovered when some grains of barley were left in the rain, leading to microorganisms fermenting the starch-derived sugars into alcohols.	['Food Preservation is not new. In fact, it has been around for thousands of years. To survive, early man worked to harness nature. In frozen climates, he froze meat on the ice. In tropical climates, he dried foods in the sun.\nFood starts to spoil the moment it is harvested. Food preservation enabled early man to stay in one place and form a community. He no longer had to consume his kill or harvest it immediately, but rather could preserve some for later use. Each culture preserved their local food sources using the same basic methods of food preservation.\nLet’s look at some food preservation types.\nIn early times, the sun and wind were used to naturally dried foods. Evidence exists that Middle Eastern and Asian cultures actively dried foods as early as 12,000 B.C. in the hot sun. Later cultures left more evidence and each would have methods and materials to reflect their food supplies—fish, wild game, domestic animals, etc.\nVegetables and fruits were also dried from the earliest times. The Romans were particularly fond of any dried fruit they could make. In the Middle Ages, in areas that did not have enough strong sunlight for drying, they built “still houses” to dry fruits, vegetables and herbs. A fire was used to create the heat needed to dry foods and in some cases, foods were smoked them as well.\nFreezing was an obvious preservation method in the appropriate climates. Any geographic area that had freezing temperatures for even part of a year used temperature to preserve foods. Less than freezing temperatures were used to prolong storage times. Cellars, caves and cool streams were put to good use for that purpose.\nIn America, large estates had icehouses built to store ice and food on ice. Soon the “icehouse” transformed into the “icebox”. In the 1800’s mechanical refrigeration was invented and quickly put to use. Also in the late 1800’s, Clarence Birdseye discovered that quick freezing at very low temperatures made for better tasting meats and vegetables. After some time he perfected his “quick freeze” process and revolutionized this method of food preservation. In your lifetime, you’ve no doubt purchased “Birdseye” frozen vegetables at the grocery store.\nFermentation was not invented, but rather discovered. The first beer may have been discovered when a few grains of barley were left in the rain. Opportunistic microorganisms fermented the starch-derived sugars into alcohols. This can also be said about fruits fermented into wine, cabbage into Kim chi or sauerkraut, and so on. The skill of early peoples to observe, harness, and encourage these fermentations was admirable. Some anthropologists believe that mankind settled down from nomadic wanderers into farmers to grow barley to make beer in roughly 10,000 BC. Beer was nutritious and alcohol was divine. It was treated as a gift from the gods.\nFermentation was a valuable food preservation method. It could not only preserve foods, but could also create more nutritious foods. It was also used to create more palatable foods from less than desirable ingredients. Microorganisms responsible for fermentations can produce vitamins as they ferment. This produces a more nutritious end product from the ingredients.\nPickling is a method of preserving foods in vinegar (or other acid). Vinegar is produced from starches or sugars fermented first to alcohol and then the alcohol is oxidized by certain bacteria to acetic acid. Wines, beers and ciders are all routinely transformed into vinegars.\nPickling may have originated when food was placed in wine or beer to preserve it, since both have a low pH. Maybe wine and beer went sour and the taste of the food in it was appealing. Containers had to be made of stoneware or glass, since the vinegar would dissolve the metal from pots. Never ones to waste anything our ancestors found uses for everything. The left over pickling brine found many uses. The Romans made a concentrated fish pickle sauce called “garum”. It was powerful stuff which packed a lot of fish taste in a few drops.\nThere was a huge increase in food preservation in the sixteenth century owing to the arrival in Europe of new foods. Ketchup was an oriental fish brine that traveled the spice route to Europe and eventually to America where someone finally added sugar to it. Spices were added to these pickling sauces to make clever recipes. Soon chutneys, relishes, piccalillis, mustards, and ketchups were commonplace. Worcester sauce was an accident from a forgotten barrel of special relish. It aged for many years in the basement of the Lea and Perrins Chemist shop.\nThe earliest curing was actually dehydration. Early cultures used salt to desiccate foods. Salting was common and even culinary by choosing raw salts from different sources (rock salt, sea salt, spiced salt, etc.). In the 1800’s, it was discovered that certain sources of salt gave meat a red color instead of the usual unappetizing grey. Consumers overwhelmingly preferred the red colored meat. In this mixture of salts were nitrites (saltpeter). As the microbiology of Clostridium botulinum was elucidated in the 1920’s it was realized that nitrites inhibited this organism.\nJam and Jelly\nPreservation with the use of honey or sugar was well known to the earliest cultures. Fruits kept in honey were commonplace. In ancient Greece quince was mixed with honey, dried somewhat and packed tightly into jars. The Romans improved on the method by cooking the quince and honey producing a solid texture.\nThe same fervor of trading with India and the Orient that brought pickled foods to Europe brought sugar cane. In northern climates that do not have enough sunlight to successfully dry fruits housewives learned to make preserves—heating the fruit with sugar.\nCanning is the process in which foods are placed in jars or cans and heated to a temperature that destroys microorganisms and inactivates enzymes. This heating and later cooling forms a vacuum seal. The vacuum seal prevents other microorganisms from recontaminating the food within the jar or can.\nCanning is the newest of the food preservations methods being pioneered in the 1790s when a French confectioner, Nicolas Appert, discovered that the application of heat to food in sealed glass bottles preserved the food from deterioration. He theorized “if it works for wine, why not foods?” In about 1806 Appert’s principles were successfully trialed by the French Navy on a wide range of foods including meat, vegetables, fruit and even milk. Based on Appert’s methods Englishman, Peter Durand, used tin cans in 1810.\nAppert had found a new and successful method to preserve foods, but he did not fully understand it. It was thought that the exclusion of air was responsible for the preservations. It was not until 1864 when Louis Pasteur discovered the relationship between microorganisms and food spoilage/illness did it become clearer. Just prior to Pasteur’s discovery Raymond Chevalier-Appert patented the pressure retort (canner) in 1851 to can at temperatures higher than 212ºF. However, not until the 1920’s was the significance of this method known in relation to Clostridium botulinum.\nAdapted from an article at:']	['<urn:uuid:345f5619-5091-4463-b979-8cfe5b2a0295>']	factoid	with-premise	concise-and-natural	similar-to-document	single-doc	novice	2025-05-01T22:36:12.692263	7	25	1171
168	As a literary scholar, I'm curious how death inspires creation in Joyce and Verdi. Care to explain?	Both works show how death catalyzed creative responses, but in different ways. In Joyce's Ulysses, death and infertility are symbolically explored through Stephen's 'Parable of the Plums' where two barren women throw plum seeds from atop Nelson's pillar, representing Dublin's cultural stagnation. In contrast, Verdi directly responded to death by creating his Messa da Requiem - first conceived as a collaborative work after Rossini's death in 1868, then fully realized as his own composition following Manzoni's death in 1873, transforming loss into a powerful musical legacy.	"['by James Joyce\nUlysses Aeolus Analysis Summary\nIn the last few episodes, we\'ve been focusing a great deal on character development. Here, let\'s put our eye on the theme of the chapter. Namely: pumped up rhetoric and the chaos of the media world.\n""Aeolus"" has the first visually jarring stylistic change-up in the book: the insertion of newspaper headlines throughout the chapter. There are a number of different ways to think about what these headlines are doing here. As we keep saying, style is something that is extremely flexible in Ulysses. The way that Joyce writes incorporates the moods and emotions of his characters as well as the current setting. It\'s not too hard to imagine the free-associating Mr. Bloom imagining everything that goes on in the newspaper office in terms of headlines, but that\'s not quite what\'s going on here. The headlines are coming from outside the context of the scene. We\'re being made aware of the narrator of the story, and of the fact that the book is aware of itself as a book. Whoever is telling this story acknowledges that it is being written, and this acknowledgment of the written form allows the narrator to toy with the form as he sees fit.\nThere\'s another way one might think of these headlines. Normally, when we wander down to breakfast to read the paper, we think of headlines as something quite separate form our lives. The newspaper is telling us: ""This is what\'s going on in the world today. Listen up."" We think of the news as something external, something that happens to us, something out there. The waythat the headlines in ""Aeolus"" pick up on little bits of speech between the men in the newspaper office and puts words to minor events emphasizes the fact that the news is pulled from everyday experiences. It is tied into human lives, not disconnected from them. In other words, the news records what\'s going on in the world; it does not dictate it.\nNow, in the Odyssey, Aeolus is the god of the winds. He first agrees to help Odysseus make his way home by harnessing all of the winds and putting them into a bag for Odysseus to keep while he sails home. Yet Odysseus\'s crew, thinking that the bag must be full of treasure, opens it and the winds are released. They are blown all about and eventually end up back at Aeolus\'s island. This time he isn\'t so ready to help Odysseus.\nHere, the winds are compared to the rhetoric of the journalism world: speech just being blown this way and that without really being controlled or carefully crafted. In the back offices of the paper, the men banter and recall great journalists and orators of the past. But speech just floats about in the chapter. Many stories hang open-ended. We often move from one conversation to another without much warning or indication. Each person\'s words are overblown and largely directionless. Bloom is one of the only men there who seems to be focused upon a specific task – renewing Keyes\'s ad – but his attempts are thwarted. Crawford, eager to hurry over to the bar, tells Bloom that Keyes can ""Kiss his Royal Irish Arse.""\nAs the cast of minor characters continues to widen, we also get more of a sense of the overall atmosphere of Dublin. We learn that Myles Crawford is something of a drunk; we see that for all his erudition professor MacHugh isn\'t exactly set on accomplishing much; we are introduced to J.J. O\'Molloy who once was a promising lawyer but now has fallen on hard times and needs a loan. As in Dubliners, we get a sense of Dublin as a stifling place, one that is quick to knock men\'s ambitions flat. And the solution here is often: go to the pub.\nThe chapter also brings our two major characters, Bloom and Stephen Dedalus, into early glancing contact. Stephen Dedalus enters while Bloom is across the street trying to track down Keyes. Then Bloom returns just as Stephen and the rest of the men are headed out to the pub. Bloom observes Dedalus as ""a moving spirit"" and it is clear that he is attentive to him as he notices that he has put on new boots. Stephen, in contrast, doesn\'t even acknowledge Bloom. Stephen\'s in his element; Bloom is not. The newspapermen dote on Stephen. Crawford agrees to publish Deasy\'s letter because it came from Stephen, and offers him a job at the paper. Bloom, by contrast, is constantly slighted by other men in the office and remains aloof, left to observe them as they all go off drinking together.\nWhat\'s the deal with ""The Parable of the Plums?"" Stephen tells a bizarre story about these two old Irish virgins climbing up to the top of Nelson\'s pillar, having a picnic on top and throwing their plum seeds down to Dublin. First, note that Lord Nelson was a British Flag Officer famous for his participation in the Battle of Trafalgar. He later became famously embroiled in an affair with the wife of the British Minister to Naples. In Joyce\'s time, there was much controversy over the pillar in the center of O\'Connell street that had been set up to commemorate Nelson. Part of the controversy was related to the fact that there was a statue honoring a British officer in the center of Dublin when many people in the city wanted nothing more than to be free of their British oppressors. On a simpler level, people thought that it was ugly and that it blocked traffic (this controversy was settled later, in 1966, when some IRA men blew up the pillar; today the Spire of Dublin stands in its place).\nNow, in Stephen\'s parable, these two older women who have never given birth to anyone hike up the top of this British monument and sit admiring Dublin. They eat their plums and then throw down the seeds. On one level, Stephen is comparing Dublin (namely, an independent Dublin) to the Promised Land in the Old Testament. But, in his version, the people looking out on the Promised Land are looking out on it from a British monument. Everything seems barren, infertile, unpromising; the old women eat their plums, but then toss the desiccated seeds down into the street. In short, optimism is not running high in Dublin.', 'Classical music has such a long, storied history, that it can be difficult to know where to start. Each week, we’ll be exploring an important event that left its mark.\nThis week? Gioachino Rossini’s death inspired Verdi to launch an ambitious project involving twelve Italian composers to create a requiem in his honor. The project was eventually aborted, but Verdi’s musical tribute to Rossini survives in the Libera Me of his Messa da Requiem, a grandiose work composed in honor of another idol…\nLike most requiems, Verdi’s Messa da Requiem began with an ending.\n“A great name has disappeared from the world!”\nThe great opera composer Gioachino Rossini died in November 1868, and Giuseppe Verdi—the great opera composer of his own generation—was deeply moved. But, when Verdi wrote the above in a letter, he was also thinking about another Italian artistic titan.\n“When the other one who still lives is no more, what will we have left?”\n“The other one?” He was referring to Alessandro Manzoni, a poet and novelist of about Rossini’s age, best known for The Betrothed. But for now, Verdi’s attention was mainly focused on his dear, departed fellow composer.\nVerdi hit upon an original idea with which to mark Rossini’s life. On the first anniversary of his death, he proposed, a requiem mass would be performed. It would be written jointly by Italy’s leading composers, with Verdi contributing one movement himself—as it transpired, the final movement, Libera me (above).\nAs if that project weren’t unusual enough already, Verdi had some rather specific stipulations. For a start, rather than getting paid, the composers and performers would be expected to contribute financially to the project. After the performance, the score “should be sealed and placed in the archives… from which it should never be taken,” except perhaps for anniversaries. Oh, and Verdi would quit the project immediately if anyone foreign or unartistic became involved.\nCasting an eye over Verdi’s demands, it’s perhaps surprising that the Messa per Rossini project got off the ground at all. But a fairly promising start was not enough to make it happen. The project gave up the ghost fairly slowly, but seems to have been consigned to an unmarked grave by August 1871.\nBy then, however, Verdi had written his own Libera me. “Deliver me, O Lord” says the text… and yet Verdi’s music lingered unperformed.\nThen, on May 22, 1873, Alessandro Manzoni died.\nAnd this time, Verdi decided to write the whole thing himself. He had already written the ending.\nThings went far more smoothly this time. He met his own deadlines, and the first performance did indeed take place on the first anniversary of Manzoni’s death—May 22, 1874—at the church of San Marco in Milan. Unlike the plan for the Rossini requiem, further performances were permitted: three more immediately took place at La Scala. The reaction was positive from almost everyone, with Hans von Bülow one of few exceptions. An “opera in ecclesiastical costume,” he called it. Referring to a sacred work by a leading opera composer, this is surely one of music history’s least imaginative insults.\nThe troubled genesis of Verdi’s Requiem is now a matter for the history books. The ends of Rossini and Manzoni, and the conclusion of the Messa per Rossini project, proved to be the beginning of a work which remains very much alive—above all, thanks to its spectacular Dies irae, that unforgettable whirlwind of wrath and fear that still reverberates today.\nIt’s so thrilling, in fact, that it even seems to have terrified Herbert von Karajan, albeit only briefly. Watch closely at 1:41.']"	['<urn:uuid:5adc5a3e-69c3-43f5-b250-058728158169>', '<urn:uuid:54986c44-5abd-4e2d-a6c0-6586bfdb48b6>']	open-ended	with-premise	concise-and-natural	distant-from-document	comparison	expert	2025-05-01T22:36:12.692263	17	86	1665
172	Where did trick-or-treating come from and how much do people spend on it now?	Trick-or-treating originated in Scotland and Ireland where poor people would visit affluent homes to offer prayers for the dead in exchange for food or money. Today, Americans spend over two billion dollars on Halloween candy annually, with the average consumer planning to spend around $100 on Halloween items including candy, décor, cards and costumes in 2022.	"['As you are busily gearing up to get out and celebrate Halloween with your friends and family, perhaps you’ve actually wondered where on earth did this somewhat bizarre holiday come from? Who thought of trick or treating? Why do we dress up in costumes anyway? For all you curious folks, we’ve compiled a top 10 listing of the most important details of the history of Halloween. The holiday has changed a lot through history but one fact will always remain the same, Halloween is one of the most beloved holidays we celebrate every year and is considered to be the 2nd most commercially successful holiday celebrated in the U.S. As you don your best Halloween costume and hit the streets to do some serious trick or treating, here are some fun facts for you to keep in mind!\nPumpkins: Pumpkins are plentiful in the U.S. and are actually indigenous to the Western hemisphere. Normally harvested in October, pumpkins are most commonly orange, but these members of the gourd family also can be found in green, yellow, white, blue and tan! When the Irish immigrated to the U.S. they had been formerly making lanterns with scary faces in them out of turnips to use on ‘All Hallows Eve’, but they quickly switched to pumpkins because they were far easier to carve than turnips and were more readily available. A Halloween tradition was born!\nJack-o-Lanterns: The legend of the Jack-o-Lantern is actually based on a man named Jack. Legend states that a miserly, angry as well as evil man named Jack liked to play pranks on his fellow townspeople. One day Jack decided to mess with the devil himself and tricked him, trapping him up in a tree. Jack circled the tree trunk with crosses and other religious symbols and would not let the devil escape until he agreed that he would never take Jack’s soul into hell. Of course the devil had no choice but to agree to this bargain and he was allowed to go free. When Jack eventually died, he was far too evil to go to heaven but the devil was true to his bargain and did not take Jack’s soul into hell. Jack was forced to roam the earth for eternity. The devil did leave Jack with an endlessly burning ember, which Jack placed inside a turnip lantern to carry on his way as he eternally searched for his final resting place. The tradition of the lit Jack-o-Lantern carries on to this day!\nHalloween Parties: Back in ancient days, villagers would gather on All Hallow’s Eve for a celebration called Samhain, which marked the end of the Harvest and the beginning of their new year, which was November 1st. Large bonfires would be made and various rituals would be performed around these, including throwing the bones of slaughtered animals into the fire as an offering. This celebration was also thought to honor the dead, which these people believed could roam the earth freely in spiritual form on this night. It became commonplace to dress as one were dead in an effort to fool the spirits in hopes that any malevolent amongst them would leave them alone.\nImmigrants: Most of the traditions we have surrounding Halloween come from the Irish or other European immigrants who brought their ancient customs with them when they immigrated to the U.S. Halloween is an eclectic mixture of customs of the Irish, Catholic and the Romans. In particular, the highly superstitious Celts gave us many of the ideas for what we now know as Halloween. The Celts believed that the lines between the living and the dead were completely blurred on October the 31st and they were fearful of any mischief or problems that might be caused by these spirits when they returned.\nGhosts: Because of the ancient beliefs that the spirits of the deceased were out running rampant on All Hallows Eve, Halloween will always have a close association with ghosts and spirits. Throughout history it has been common to tell ghost stories and folk tales involving spirits around the time of Halloween. These traditions have carried on today and it is common for people to create and visit attractions that are designed to appear ‘haunted’ as part of a way to celebrate Halloween.\nMonsters: Aside from ghosts, over the years many other monsters have become associated with Halloween. Two of the most common are vampires and werewolves. Vampires are part of ancient folklore that tried to explain away why random plagues would cause groups of mysterious deaths in various villages. Superstitious people thought that these deaths must be due to a newly deceased person being actually ‘undead’ and rising from the crypt in order to feast on the blood of the living in order to maintain their life force. Potential werewolves, another mythological being, were picked out from amongst others by features such as uni-brows, hairy palms and having a middle finger that was longer than the other digits.\nCostumes: The first Halloween costumes were made in Ireland and were made of various types of make up and animal heads or skins. These costumes were made in an effort to ward off evil spirits, but during the celebration of All Hallows Eve, were also used in the ceremonies that were performed during various festivities. Fortunes were often told and it was common for various rituals to be performed during this time. Nowadays, although scary costumes are still worn on Halloween, the variety of costumes you will see cover many different categories including superheroes, pop stars, humorous costumes and historical figures as well.\nWitches: The word witch comes from the Old Saxon word ‘wica’, which actually means ‘wise one’. In ancient days, witches were originally considered to be healers who were very familiar with the use of herbs and other remedies to help the sick and otherwise afflicted. As Christianity spread throughout Europe, the church clergy unfairly labeled these ‘healers’, calling them devil worshipers or sorcerers, even though that was hardly the case. Early immigrants that still believed these old ancient superstitions regarding witches brought these rumors with them into the U.S.\nTrick or Treating: In the ancient days of Scotland and Ireland, it was common practice on All Hallows eve for the poor or less fortunate to go to the homes of more affluent people and offer prayers for the dead in exchange for food or money. This practice was once again brought to the states by immigrants and eventually evolved into the custom of trick or treating, as we know it today.\nCandy: Candy is the preferred ‘treat’ of trick or treaters, the most favored of all being chocolate bars. The number one chocolate bar favorite amongst trick or treaters is Snickers. Consumers will spend over two billion dollars on Halloween candy this year. Over twenty five percent of all candy purchased annually in the U.S. is bought for Halloween purposes.\nHalloween is one of the most beloved holidays out there. Knowing a little bit of the facts surrounding its magical history will help you to understand and enjoy it all the more! Happy Halloween!', ""SCENE + HEARD: Today's Read Skeletons, Spellcasting, ‘Stranger Things’ and Spending: A Look at 2022’s Halloween Trends By Gwendolyn Plummer Friday, September 30, 2022 8:30 AM NEW YORK—October has arrived, and for many people that can only mean one thing: Halloween season is in full swing. There are just 30 days until the sweetest and spookiest day of the year, and, according to the National Retail Federation (NRF), Americans are taking full advantage of the witching season. The NRF reported that Halloween spending is back to pre-pandemic levels this year, with Halloween sales up to $10.6 billion in 2022, up from $10.1 billion in 2021. Consumers are planning to spend $100 on average for Halloween candy, décor, cards and costumes; the NRF said that this amount is on par with last year’s record of $103 and is the second highest in the survey’s history. So, if people are spending all that money on Halloween costumes, décor and candy, what exactly are they buying? Each year, Google Trends releases Google Frightgeist, a tool that compiles Google searches and data to determine the most popular Halloween costumes. The 2022 version hasn’t been shared yet, but the 2021 data is still available to peruse. Last year, Google found that “witch” was the trendiest costume, followed by “rabbit,” “dinosaur,” “Spider-Man,” and “Cruella de Vil” rounding out the top five. Frightgeist also lets users toggle between national and local trends, so you can see what your neighbors and coworkers are likely planning to wear this Halloween, too. For this year’s data, we can turn to Spirit Halloween, the U.S.’s largest Halloween retailer. So far, Spirit Halloween’s most popular costumes have been Hocus Pocus costumes, maybe because the classic movie’s highly anticipated sequel releases this weekend. “Witches” in general follow, and the third category is broadly “TV and Movie,” encompassing costumes from cultural phenomena like Stranger Things, Ted Lasso and movie superheroes. The NRF’s research echoes Spirit Halloween’s, reporting that “Spider-Man” is the top trending costume, with “witch” in third place. When it comes to décor, there’s one trend that seems to be taking over the rest: giant lawn decorations. From Home Depot’s famous 12-foot skeleton to oversized jack-o-lanterns and massive inflatable ghosts, bigger is better this season, House Digest suggests. If your style is more understated, though, there are still plenty of options: Hocus Pocus is trending in décor, too, reports House Digest, and so is more subtle Halloween-themed dinnerware that might even be adaptable year-round. All of this Halloween spending echoes a general return to pre-pandemic spending overall, says the NRF’s president and CEO Matthew Shay: “Halloween is an exciting time for many families, and that enthusiasm is reflected in the number of Americans who plan to celebrate the holiday this year. As consumers continue to return to pre-pandemic behaviors, retailers are prepared to meet that demand and help make this holiday a fun and memorable one.” The retail data seems to indicate that Americans are excited for Halloween, and are willing to spend money to celebrate it. For ECPs and retailers, of course, the trending data is great for getting involved on social media or in-office. From Instagram costume contests to 12-foot skeletons in exam chairs, there’s no shortage of ways to adapt this year’s Halloween trends to the optical industry. And with 30 days left to get involved, there’s plenty of time, too. So let’s get spooky.""]"	['<urn:uuid:415ca75b-a9c5-470d-94c4-d87d44fb87fa>', '<urn:uuid:a6fa1997-b69e-4a0b-a604-4785e960d4b9>']	factoid	direct	concise-and-natural	distant-from-document	multi-aspect	novice	2025-05-01T22:36:12.692263	14	56	1750
173	institutional investor comparing gold palladium stability profit margin	Gold shows more price stability compared to palladium during market fluctuations. When prices fall, gold remains steadiest while palladium is hardest hit. This is evidenced by gold's modest 20% decline from its peak in 2022, compared to palladium's dramatic 80% drop from $3,440.7 to $1,854 per ounce. Additionally, GOLD stocks show a net profit margin of 3.91% with current earnings growth of 18.52%.	['A block trade is a significant transaction involving the buying or selling of securities that is conducted privately, away from the public markets. Its purpose is to minimize the impact on the price of the security. Typically, block trades are carried out by hedge funds and institutional investors through investment banks and other intermediaries. However, high-net-worth accredited investors may also have the opportunity to participate in these trades.\nAccording to the criteria set by the New York Stock Exchange and the Nasdaq, a block trade involves a minimum of 10,000 shares of stock or a value exceeding $200,000. For instance, in the present scenario, a block trade is taking place involving GOLD. The trade consists of 964,472 shares being exchanged at a price of $16.32 per share, which is slightly higher than the ask price of $16.31. To maintain confidentiality and disguise the true magnitude of the trade, it is likely that different brokers will be involved in executing this transaction.\nIt should be noted that the specific exchange on which this block trade is occurring has not been specified in the information provided. Nonetheless, the CME Group offers the opportunity to execute block trades for futures, options, or combination transactions that are permitted to be conducted separately from the public auction market.\nBarrick Gold Corporation\nUpdated on: 28/09/2023\nDebt to equity ratio: Buy\nPrice to earnings ratio: Strong Sell\nPrice to book ratio: Strong Buy\nDCF: Strong Buy\n12:00 PM (UTC)\nDate:28 September, 2023\n|Analyst / firm||Rating|\nBank of America Securities\nGOLD Stock Performance: Mixed Results on September 19, 2023 with Positive Turnaround in Earnings Growth\nOn September 19, 2023, GOLD stocks experienced mixed performances. The previous close for GOLD stocks was at $16.68, and today’s open was slightly higher at $16.72. Throughout the day, the stock fluctuated within a range of $16.20 to $16.75. The trading volume was 14,976,724, which is higher than the average volume of 13,188,653 over the past three months.\nLooking at the company’s financials, GOLD has shown a significant decline in earnings growth over the past year, with a decrease of 78.54%. However, there has been a positive turnaround this year, with earnings growth of 18.52%. Looking ahead, the projected earnings growth for the next five years is a modest 2.00%. The revenue growth for the previous year was -7.40%, indicating a decline in sales.\nIn terms of valuation, the P/E ratio is not available (NM), suggesting that the company may have negative earnings. The price/sales ratio is 2.74, which indicates that investors are willing to pay $2.74 for every dollar of sales generated by the company. The price/book ratio is not provided, so it is difficult to assess the company’s value based on its book value.\nTaking a closer look at the individual stock performances, Newmont Corporation (NEM) experienced a decrease of $0.16, which translates to a decline of 0.41%. Agnico Eagle Mines Ltd (AEM) also saw a decrease of $0.50, representing a decline of 1.00%. Gold Fields Ltd (GFI) had a smaller decrease of $0.08, resulting in a decline of 0.65%.\nLooking ahead, the next reporting date for GOLD stocks is set for November 9, 2023. Analysts forecast an EPS of $0.27 for this quarter. The net profit margin for GOLD stocks is 3.91%, indicating the company’s ability to generate profit from its revenue.\nGOLD operates in the Non-Energy Minerals sector and falls under the Precious Metals industry. The corporate headquarters of GOLD is located in Toronto, Ontario.\nOverall, GOLD stocks had a mixed performance on September 19, 2023. While there was a slight increase in the stock price at the opening, it fluctuated within a range throughout the day. The company’s financials show a decline in earnings growth over the past year, but there has been a positive turnaround in the current year. The next reporting date will provide further insights into the company’s performance.\nAnalysts and Investors Bullish on Barrick Gold Corp Stock Performance: Promising Investment Opportunity in 2023\nOn September 19, 2023, Barrick Gold Corp saw its stock performance being discussed by analysts and investors. According to data from CNN Money, 21 analysts provided 12-month price forecasts for the company’s stock. The median target price was estimated to be 22.25, with a high estimate of 30.00 and a low estimate of 17.20.\nThe consensus among 25 investment analysts polled is to buy stock in Barrick Gold Corp. This rating has remained unchanged since September.\nBarrick Gold Corp reported earnings per share of $0.27 for the current quarter. Additionally, the company’s sales for this period amounted to $3.4 billion.\nInvestors and analysts eagerly await the reporting date of November 9, when Barrick Gold Corp will release more detailed financial information for the current quarter.\nThe positive sentiment among analysts and investors, as well as the projected increase in stock price, suggests that Barrick Gold Corp is currently viewed as a promising investment opportunity.\nHowever, it is important for investors to conduct their own research and consider various factors before making any investment decisions.\nIt is worth noting that the information provided is based on data from September 19, 2023, and stock prices and forecasts are subject to change based on market conditions and other factors. Therefore, it is advisable to consult up-to-date sources and seek professional advice before making any investment decisions.', 'Precious metals analyst Sanjiv Arole examines the market forces that are driving palladium’s fortunes.\nAlthough palladium was classified as a precious metal only in 2009, it became the most expensive precious metal in 2019. Palladium has topped $2,300 per ounce (against platinum’s all-time of $2,273 per ounce in 2008) on umpteen occasions. In fact, palladium topped $3,000 per ounce for the first time on 4th May, 2021.\nThe Ukraine war too triggered off a rally in palladium as it scaled a fresh all-time high of $3,440.7 per ounce (intra-day) on 7th March, 2022. Although gold managed to be at par with palladium on a few occasions this year, palladium still remains the most expensive of (non)precious metals in the precious metals basket.\nThe palladium price has gained by over 6% to $2,018 per ounce on 2nd September, 2022 as compared to $1,893 per ounce at the beginning of the year. It was the only precious metal to have gained as of 2nd September this year, while the rest of the precious metals all showed a decline in price as compared to the beginning of the year.\nGold fell by 5.78% to $1.712.50 per ounce while silver decline sharply by 27.34% to $17.92 per ounce, platinum too slipped by 16.07% to $840 per ounce.\nAs Russia accounts for a substantial portion of palladium supplies in the world, the Ukraine war will continue to have an impact on the palladium price in the remainder of the year as well.\nThe crowning glory for palladium in the immediate aftermath of the Ukraine war was when its price scaled an all-time high of $3,440.7 per ounce on 7th March, 2022. In sharp contrast, the palladium prices dipped by a whopping 80% to $1,854 per ounce on 20th July, 2022.\nGold’s decline from its peak of $2,039 per ounce for the year was more subdued at around 20% as gold slumped to $1,694 per ounce on 1st September, 2022. Silver and platinum too declined, by over 47% and 38%, respectively, from their highest to their lowest levels. However, as far as year-to-date prices were concerned, palladium was the only one that remained in positive territory. If one were to look at the average prices, then all the precious metals showed a decline in the average price year-to-date as compared to the average price for the previous year. Gold declined by just over 1%, while palladium fell by 14%. Silver and platinum fell steeply by 23% and 21%, respectively. Overall, it once again supported the view that when the price surges, gold climbs the slowest, while palladium and silver lead the way. But, when prices fall, gold is the steadiest, while palladium and silver are the hardest hit. Platinum is usually between gold and the other high-flyers.\nComing to the fundamentals of palladium as per the Johnson & Matthey PGM Market Report 2022. Some of the salient features for 2021 are:\n(a) Russia is the largest primary palladium supplier accounting for around 40% of mined production. In 2021, Russian mine production was 2,689 thousand ounces.\n(b) In 2021, palladium prices scaled $3,000 per ounce on liquidity concerns following the flooding of mines in Siberia. However, increased supplies from South Africa saw the price slump to below $1,600 per ounce in December.\n(c) High prices incentivised scrap yards to expedite reprocessing palladium-rich catalysts. Secondary supplies increased as a result of the backlog of auto scrap as well. However, as the price declined so did the scrap inflows.\nThe outlook for 2022:\n(a) The Ukraine war has resulted in uncertainty over shipments from Russia in 2022. In fact, J&M has not made any forecasts for palladium supplies from Russia. Then, South African supplies are set to fall in the current year due to plant maintenance, etc.\n(b) Expected weaker car sales to hit recycling of vehicles, less vehicles for scrapping.\n(c) Any recovery in auto PGM demand likely to hit due to supply constraints and Covid-19 restrictions, particularly zero-Covid tolerance in China and the resultant lockdowns there.\n(d) Industrial palladium demand to be hit due to high prices.\n(e) Since Russia is the largest palladium supplier in the world, supply disruption from Russia could give rise to inflation and depress growth. This would be further accentuated with palladium ingots from Russian refineries being unacceptable as ‘good delivery’ bars in London and elsewhere from April 2022.\n(f) Average platinum content of a gasoline car in 2022 is forecast to rise by over 66.6% compared to 2021. Automakers in Europe and North America are set to begin fitting tri-metal catalysts in greater numbers, reflection substitution efforts to replace palladium with platinum. Even China is expected to ramp up substitution. Overall, a tumultuous time for PGM metals, particularly palladium\nMeanwhile, US Fed Chief Jerome Powell’s speech at Jackson Hole symposium sent chills across global stock markets as well as commodity markets. The symposium was held from 25th August, 2022 and Powell’s comments on inflation were far more hawkish than anticipated. His overwhelming focus on inflation was reflected in the usage of the word inflation around 44 times in his speech.\nPowell stated that all his efforts would be centred on bringing inflation down to 2% from the current 9%, implying that higher than normal interest hikes would continue till inflation numbers slide down. He added that while higher interest rates, slower growth and softer labour market conditions will bring down inflation, they will also bring some pain to households and businesses. They are the unfortunate costs of reducing inflation. But a failure to restore price stability would mean greater pain.\nJerome Powell appears to be on the verge of throwing caution to the winds in his relentless pursuit of taming inflation. He seems to be oblivious of the lower GDP growth, higher debt servicing of long-term debt weighing down on the US economy, trade sanctions, Covid-19 hovering around, and the likely harsh winter for most of Europe due to fuel shortages as a backlash against sanctions by Russia and above all the Ukraine war.\nIn his endeavour he has embarked on a path of rapid rise in interest rates to tame inflation. In the game of brinkmanship, he is risking job losses and lower growth giving way to even recession. While higher interest rates could encourage savings account holders, it could hurt the stock markets as well as the precious metals market.\nGold, in particular, would wait with bated breath to see the outcome of the monetary policy statement later in the week. If the Fed continues it hawkish trend (a further substantial hike as in July), then gold could be under enormous pressure of a strong dollar as well as an option for savings in banks accounts. Thereby, gold could sink further along with the rest of precious metals.\nA recovery in the gold price could be seen only when it transpires that inflation cannot be tamed despite the rate hikes or the Fed end the rate hikes citing victory over inflation.\nWill palladium still remain in positive territory even if the Fed continues to hike interest rates? As they say, ‘the proof in the pudding is in the eating’. Wait and watch!']	['<urn:uuid:8074c8dd-940e-423e-ba27-9b7b26fbde95>', '<urn:uuid:f98cd933-b322-4819-92b9-5bf92cde845e>']	factoid	with-premise	short-search-query	distant-from-document	multi-aspect	expert	2025-05-01T22:36:12.692263	8	63	2075
177	as incoming marine corps officer need explanation duties responsibilities fitness standards series commander position	A Series Commander in the Marine Corps must meet high physical fitness standards, including achieving 1st class PFT and CFT scores while maintaining height and weight standards. They must also complete obstacle and confidence courses before their series does. In terms of duties, they are responsible for supervising recruit training safety, conducting recruit interviews to prevent abuse, leading PT sessions, conducting inspections, and teaching Marine Corps policies. They oversee Drill Instructors and ensure training complies with Standard Operating Procedures. Series Commanders are typically First Lieutenants or Captains who maintain accountability of personnel and equipment, screen recruit folders, and provide positive leadership to assigned Marines.	"['Welcome to Drill Instructor School, Series Commander Course. Here are some preparation considerations and things you should have before you are underway:\n· Read the book: Pride and Discipline: The Hallmarks of a United States Marine by Colonel Donald J. Myers, USMC (Ret). Be prepared to discuss the book during the Series Commander Course.\n· Physical Conditioning: As a series commander, you are expected to set the example for Marines and recruits. You are also expected to execute the obstacle and confidence courses prior to your series executing these events. During the Series Commander Course, you will be required to achieve a 1st class PFT and CFT score and be within height and weight standards. You will also be required to successfully negotiate each obstacle of the obstacle course and confidence course.\n· Uniforms: Ensure all of your uniforms, to include covers, are serviceable, well-fitted, presentable, and in accordance with uniform regulations. A clean, polished appearance is expected.\n· Mameluke Sword: You will use your sword often while at Parris Island. Bring your sword and all its trappings (frog, sling, knot, etc.).\n· Black belt: You will need this for OOD and graduations. You can check out black belts, to include the entire Sam Browne belt ensemble from Organizational Clothing.\n· Organizational PT Shirts: Sign for 2 short sleeve shirts and 1 sweatshirt from O-Clothing marked with your billet on the back.\n· Name Tags: Order name tags and your hatch plate from the Engraving Shop on base (or through your Battalion S-4). They are the black and white name tags with two prongs. The Engraving Shop has the forms for you to fill out and will know what you need. It is suggested to order, at the very least, four name tags. Your hatch plate is your identifier as Series Commander outside the series office. It takes roughly two to four days for this order to be complete.\n· Duty Shirts: (Females) You will tuck in your shirts while standing duty or participating in graduation. Ensure your service and dress trousers have belt loops sewn on. Belt loops for the black belt should be on the sides and the back of the trousers.\n· Shirt Stays: (Females) Shirt stays will assist in keeping your service shirts tucked into your trousers and keep them from creeping up.\n· Pictures: You will need to have command photos taken at the Office of Communications Strategy and Operations. These are taken in the Service A uniform. You will also need to go to Recruit Photo for a picture for the Recruit/Series Cruise Book. Ensure your pictures match the rest of your company.\n· Glow Belt: Suggested to have more than one on hand, you can keep one on your pack so it is always ready to go and one in your locker, camel back, or wherever else you find it handy at the last minute. Plastic yellow glow belts only…no stretch/fabric glow belts.\n· Supply Issue: You will need your ILBE pack from Bucket Issue prior to beginning the Series Commander Course.\n· Personal Affairs: It is recommended that all billeting, TMO, and personal issues are taken care of before or after the course. The course is time intensive and demanding.', ""This article does not cite any sources. (February 2007) (Learn how and when to remove this template message)\nThe Series Commander is a United States Marine Corps officer assigned to a Recruit Training Company who is responsible for the conduct and instruction of Marine recruits and Marine Corps Drill Instructors within one of the two series, lead or follow. Series Commanders are typically of the rank of First Lieutenant (O-2) or Captain (O-3), and they are assisted in their duties by a Series Chief Drill Instructor (MCRD San Diego) or a Series Gunnery Sergeant (MCRD Parris Island).\nThe Series Commander is primarily charged with supervision and safety during recruit training. Before a recruit is allowed to run the Obstacle Course or the Confidence Course, the Series Commander must run the course first and check each obstacle for any unsafe conditions. The Series Commander will then oversee his Drill Instructors as they lead the recruits through the course. The Series Commander also serves as a verifying officer and safety officer during the Rifle Range, A-Line, Basic Warrior Training, and The Crucible.\nThough Series Commanders do not train recruits in the same way as Drill Instructors do, they do conduct PT, lead conditioning hikes, conduct hygiene and uniform inspections, make on the spot corrections, and teach classes covering Marine Corps policies on Hazing, Fraternization, and Equal Opportunity. Additionally, the Combat Training Pool, Martial Arts Instructors, Academic Instruction Company, and Crucible Training Company are all commanded by former Series Commanders. A Recruit Training Battalion Operations Officer will most likely be a former Series and Company Commander from that Battalion.\nThe role was also created to provide another layer of authority to monitor more closely the individual drill instructors, as a result of the Ribbon Creek incident. Throughout the training cycle, every recruit is interviewed personally by the Series Commander to ensure their drill instructors have acted in accordance with the proper orders and policies. The purpose of these interviews is twofold; first, it allows individual recruits access to a commissioned officer, and second, it allows the Series Commander the opportunity to speak with each recruit in his series individually throughout the course of boot camp. Underlying the policy in the Standard Operating Procedures for Recruit Training against recruit abuse, recruit interviews are also used to ensure recruits are not physically or verbally abused by their drill instructors or any other personnel in the training command.\n- Ensure the welfare and safety of each recruit in his care.\n- Provide positive leadership to the Marines assigned to him for duty.\n- Support by example and authority the letter and spirit of the Standard Operating Procedures for Recruit Training.\n- Ensure the Drill Instructors train recruits in accordance with the Recruit Training SOP.\n- Evaluate the effectiveness of the recruit training process and recommend improvements or corrections as necessary.\n- Maintain the objectivity and integrity of the recruit training process.\n- Lead by example ensuring strict compliance with core values, Commandant of the Marine Corps' vision for recruit training and the Commander's Intent.\n- Foster spirit and discipline within the series through positive leadership; ensure that drill instructors are routinely given objective and accurate written performance assessments.\n- Ensure the safety, health, and welfare of recruits and drill instructors.\n- Maintain accountability of personnel and equipment within the series.\n- Responsible for screening all pick-up and drop evaluation folders and recruits.\nDepot Order 1513.6A Recruit Training Order Marine Corps Recruit Depot Parris Island, South Carolina""]"	['<urn:uuid:5c116b20-4ecd-484f-8fb8-5fe73d22807d>', '<urn:uuid:a1b20d25-4616-40da-8800-602ad698ba24>']	open-ended	with-premise	long-search-query	distant-from-document	multi-aspect	expert	2025-05-01T22:36:12.692263	14	104	1118
180	What are the 4 teaching approaches for speech disabilities?	The four teaching approaches are communication passports, visual schedules, partner training, and aided language stimulation.	['The question of how best to teach learners who are deaf or hard of hearing (DHH) is perhaps the oldest topic in any area of education for children with diverse learning needs. Developments in a number of fields have accounted for more DHH learners achieving educational outcomes commensurate with their hearing-age peers than at any point in that long history. Efforts to further develop and implement effective educational practices with these learners continue, with an abundance of interventions proposed in the literature and in practice. Despite this, evidence for their efficacy remains limited. Such evidence as there is tends to be drawn from observations of professional practice and not always from the outcomes of high-quality research. This is not to say that a lack of research evidence for a particular educational practice means that it is necessarily ineffective or should not be used. Rather, it is to acknowledge the preeminence of quality research outcomes as the cornerstone of an evidence-base for educational practice with DHH learners while recognizing that contributions can come from two other sources: the expertise and experiences of professionals involved in the education of DHH learners in educational settings, and the views and preferences of DHH learners and their families about how the best educational outcomes can be achieved. The vast majority of DHH learners are educated in regular classrooms alongside their hearing peers, including a significant minority whose primary or preferred language is a signed language. Questions of how best to facilitate access to regular classrooms for those DHH learners are inextricably linked to issues in three areas: (a) communication, language, and literacy; (b) classroom access; and (c) pedagogical practices and other educational supports. The first area covers the unique set of challenges that relate to DHH learners acquiring a language (i.e., whether that be spoken or signed) and how best to support their ongoing development and use of their communication, language, and literacy skills in the classroom. The other two sets of issues, relate to the difficulties that are typically encountered by DHH learners in gaining access to the regular classroom curriculum through their preferred language and mode of communication (i.e., how best to access the auditory and visual environment of the classroom on an equitable basis with their hearing peers), and how best to support that access through instructional techniques and/or specialist support services. In all three areas there remains the challenge of assembling an evidence base for practice from quality research evidence.\nGreg Leigh and Kathryn Crowe\nCommunication is about working together to create shared meaning. It usually requires at least two people (one acting as the sender, and one or more acting as the receiver), uses a particular code (which may involve either conventional or unconventional signals), may take linguistic or nonlinguistic forms, and may occur through speech or other modes. In the classroom context, spoken language is typically the preferred mode of communication and the primary medium through which teaching and learning takes place. For learners with speech and langue disabilities, this is problematic. Communication does not develop in a vacuum. Cognitive and social routes are both important and therefore evidence-based practices (EBP) that impact on both need to be considered. In an attempt to delineate evidence-based strategies from assumptions or commonly accepted practices that have become “teaching folklore,” three aspects should be considered: (a) the best available research evidence that should be integrated with (b) professional expertise (using for example observation, tests, peer assessment, and practical performance) as well as (c) the learner’s and his/her family’s values. EBP thus recognizes that teaching and learning is individualized and ever-changing and therefore will involve uncertainties. Being aware of EBP enriches service delivery (in this case teaching practice) and enables teachers to support their learners to achieve high-quality educational outcomes. Research has shown that high expectations from teachers have a significant influence on the development of academic skills for children with speech and language disability. Teachers should therefore be empowered to understand how they can set up the environment in such a way that responsive, enjoyable interaction opportunities can be created that will enable learners to develop a sense power and control which are important building block for learning. They also need to understand the important role that they play in shaping behavior through the provision of consistent feedback on all communication behaviors and that communication entails both input (comprehension) and output (expression). Four teaching approaches that have some evidence base for learners with significant speech and language disabilities include: a) communication passports: this is a means through which idiosyncratic communication attempts can be captured and shared enabling everyone in the learner’s environment to provide consistent feedback on all communication attempts; b) visual schedules: a variety of symbols (ranging from objects symbols to graphic symbols) can be used to represent people, activities, or events to support communication. Visual schedules signal what is about to happen next and assists learners to predict the sequence of events, to make choices, and to manage challenging behavior; c) partner training: as communication involves more than one person, communication partner (in this case teachers) training is required in order to ensure responsivity; d) aided language stimulation: this classroom-based strategy attempts to provide a strong language comprehension foundation by combining spoken language with pointing to symbols, thereby providing learners with visual supplementation.']	['<urn:uuid:e9e5bb4b-9699-42e3-93fd-f28cee36a5c7>']	factoid	direct	concise-and-natural	similar-to-document	single-doc	novice	2025-05-01T22:36:12.692263	9	15	883
186	How do space efficiency needs differ between aquaponics and aeroponics?	Aquaponics requires significant space to accommodate both fish tanks and growing beds, with a recommended growing surface at least two times the tank surface area. In contrast, aeroponics is extremely efficient in terms of space and resources, making it suitable for space exploration applications - NASA has investigated it for growing plants in space and potentially on the moon or Mars.	"[""Aquaponics combines aquaculture, the raising of edible fish, with hydroponics, a method of growing plants in a soilless medium. It is one the most efficient and sustainable approaches to food production capable of producing hundreds of pounds of healthy, low-fat protein and organic vegetables in an area the size of a small room.\nAquaponics systems are modeled on natural aquatic systems, where the waste products of the fish are the source of nutrients for the plants, which in turn purify the water for the fish. It is a model of self-sufficient food production, as it requires little in the way of external inputs and lessens reliance on large-scale unsustainable food systems.\nAquaponics is a lot more involved than a typical vegetable garden, but it is a worthwhile project within reach of any motivated homesteader. You can try your own DIY system or work with a ready-made kit. The key is to keep your system as small and simple as possible until you master the basic techniques.\nIndoor Versus Outdoor Systems\nAquaponics systems are often incorporated into greenhouses in order to keep them going year round. They can even be used indoors under artificial lighting. There are pro and cons for each approach.\nBecause indoor systems produce food continuously in any climate, they are inherently more productive than outdoor systems. However, building a greenhouse or setting up an artificial lighting system adds a great deal of complexity and expense to an aquaponics system, not to mention the cost of heating the greenhouse.\nIn mild winter climates, fish and vegetables can be produced all year outdoors, but in temperate climates the system generally has to be shut down for winter. This is potentially a big issue if the fish have not yet reached a harvestable size, though some species are able to overwinter.\nSome people choose to have a very small system indoors for breeding fingerlings in the winter that are then released into the outdoor tank once the water has warmed sufficiently.\nAll aquaponics systems have certain features in common although the exact materials used can vary significantly depending on the approach.\nMany vegetables grow perfectly well without soil, as long as nutrients are provided in an aqueous solution. This is the basis of hydroponics, which is one half of the equation in an aquaponics system. Perlite, vermiculite, sand, fine gravel, coco coir and many other inert growing mediums are available. You can make your own recipe with some of these ingredients or make use of a commercially available hydroponic growing medium.\nThe options for containers to hold the growing medium are equally diverse. Ordinary plastic pots are the simplest DIY approach; at the other end of the spectrum are things like hydroponic towers that allow increased productivity by making use of vertical space. In between are a myriad of products from floating rafts to simple plastic growing boxes.\nOne popular approach is to build rectangular wooden boxes just like those used for ordinary raised bed vegetable gardens. These are then lined with pond liner and filled with fine gravel or some other free-draining growing medium.\nBarrel and Tank Options\nAn ordinary 55-gallon drum or a square 225-gallon bin are easy, inexpensive options for an aquaponic fish tank. Many people have used aboveground swimming pools for larger backyard systems. Specialty suppliers offer heavy duty plastic tanks or you can improvise your own system using pond liner in a raised wooden structure or set into the ground.\nIf you're considering recycled plastic bins for your tank, make sure they were used for food products or other non-toxic materials and clean them thoroughly before adding water and fish.\nOther Critical Components\nProfessional aquaponics systems can be high-tech and quite complex. Still, the backyard gardener needs a lot more than just a fish tank and growing beds.\nFirst off, a pump is necessary to move water between the tank and growing area. A standard fountain pump sold for backyard water features is generally sufficient.\nSecond, and equally critical, is an aerating device to maintain oxygen level for the fish. This is a mission critical component - if it stops running for even a few hours, a fish kill may occur. This can take the form of a bubbler device that sits at the bottom of the tank or agitators that swish the water around on the surface to add oxygen.\nYou will also need a system to distribute the water from the fish tank to the vegetables (unless floating beds are used). Again, there are numerous products designed for this purpose, though many backyard growers simply drill 1/4-inch holes every six or eight inches in pieces of 1/2-inch PVC pipe as a rudimentary drip system to deliver the water. In the raised wooden box system described above, the PVC pipes would be laid parallel to each other about 12 inches apart. A seedling can be planted at each of the drip holes in the PVC pipe.\nFish Species to Consider\nThe species you choose depends on whether your system will be kept outdoors or indoors.\nCatfish are a reliable choice for a recirculating aquaculture system and are the top species used in systems that are allowed to overwinter. As long as a small area on the surface is kept free of ice wit an agitator, catfish will survive the winter in a semi-dormant state just as they do in nature. Once the water temperature hits 70 degrees in spring, they will wake up and start feeding again.\nTilapia are the most widely farmed fish in the world and are perfectly adapted to aquaponics systems. The only disadvantage is their inability to survive cold weather. They are a tropical species and will die if the water temperature dips below 50 degrees. The water needs to be at least 70 degrees for them to thrive and reproduce. It is possible to grow them out to a harvestable one-pound size in a six-month period of warm weather from April to September, though there is no guarantee they will grow that fast, especially for a beginner. For this reason tilapia are typically used in greenhouse systems.\nYellow perch are another species used in aquaponics systems that are known for their excellent culinary qualities, as well as their ability to grow in cool waters.\nBest Choices for Hydroponic Vegetables\nLettuce, kale, arugula, spinach and other leafy greens are by far the easiest crops to grow in an aquaponic system along with herbs like basil and dill. Essentially, anything harvested in the leaf stage, as opposed to a fruit, does well with the mix of nutrients contained in fish waste. Tomatoes, peppers, cucumber and strawberries are commonly grown in hydroponic systems as well, but they need nutritional supplements to produce a crop.\nAssembling Your System\nFull sun, flat ground and easy access to a water supply are the three main requisites when choosing a site for an aquaponics system. There are many possible configurations depending on the chosen approach.\nOne of the main decisions is whether to have the grow beds higher in elevation than the tank or vice versa. The lightweight growing medium makes it possible to elevate the grow beds above the tank on a table if desired. For this method, a system of piping has to be devised to collect the water and funnel it back to the tank. In this case the pump will be in the bottom of the tank. If the beds are on the ground, however, a second pump is needed to return the water that drains from them to the fish tank.\nAnother big question in designing an aquaponics system is the ratio of growing space to tank space. In general, the more growing space the better, as it it's actually the growing medium, not the plants, that do most of the filtering. A good rule of thumb is to plan for the growing surface to be at least two times the surface of area of the tank.\nAn Abundant Harvest\nAquaponics systems can be stocked at up to one fish per gallon of water, making them incredibly efficient at food production. It's recommended that beginners start with one fish per 10 gallons of water while learning the ropes of aquaculture, but that's still a lot of fish that can be grown in a very small space. With the veggies you'll harvest from the growing beds, your family will have the freshest food imaginable."", ""Aeroponics is the most efficient growing method in terms of energy and resources used during the process compared to plant production. Aeroponic growth refers to growth achieved in an air culture. The basic principle of aeroponics is to grow plants in a closed or semi-closed environment by spraying the plant's roots with a nutrient rich solution. The main distinction from a variety of other hydroponic methodologies is the lack of a true growing medium. Many times closed cell foam is compressed around the lower stem and inserted into an opening in the aeroponic chamber, which is just for convenience. Larger plants are typically attached to a trellis to support the weight of the plant and its fruit. An example of naturally occurring aeroponics can be seen in those orchids which grow high up in trees.\nAeroponics is extremely efficient in the use of both water/nutrients and energy, and for this reason has been investigated by NASA as a means of producing plants in space, and potentially on the surface of the moon and/or mars. It generally is not well suited to commercial production of fruit producing plants such as tomato, cucumber, and peppers; it is however well suited for herbs, lettuce and strawberries. Basil might be the most popular example of widely available, aeroponically grown produce. Aeroponics is the preferred method to grow herbs when the roots are the harvested portion. It also is particularly useful in the propagation of plants from cuttings (cloning), some difficult to clone plants produce very good results in an aeroponic system. Because of the hardware investment and time required for maintenance, aeroponic growing has relatively few commercial applications. Aeroponics is brought to the average consumer in an automated prepackaged form marketed under the name AeroGarden (see page for detailed description).\nIt is the lack of a growing medium that distinguishes aeroponics from other forms of hydroponics. The roots are typically suspended in a closed or semi-closed environment, and are periodically bathed in a mist or fog based nutrient solution. The mist provides all of the water and nutrients for the plant to thrive. One of the attractive growing features of aeroponics is that the roots are constantly suspended in the air, and therefore are continuously exposed to ample quantities of oxygen. The roots should be exposed to oxygen something like 99% of the time.\nThe first factor influencing the effectiveness of an aeroponic system is the droplet size. Small droplets tend to stick to the roots better, allowing the plant to absorb the nutrients it needs; large droplets have a tendency to coalesce and fall to the reservoir below, and restrict oxygen to the root system. A very fine mist will produce excessive root hair without developing a lateral root system required for sustained growth. The droplets of nutrient solution are can be made using sprayers, misters, foggers, or ultrasonic nebulizers. The droplets are typically formed by forcing the stream of liquid through a small nozzle. The smaller the nozzle opening, the smaller the droplets. Greater pressure is required for smaller nozzles though, and particles dissolved in the solution could clog very small nozzles, or leave deposits on the ultrasonic foggers. NASA funded research has determined that high pressure mist of 5-50 micrometer droplets are necessary for long term aeroponic growth.\nThe second significant factor influencing the effectiveness of an aeroponic system is the frequency of the misting. The combination of droplet size and misting frequency are correlated. In most applications a compromise is made to accommodate a larger droplet size in order to take advantage of using a lower pressure. Plants with a large leaf surface area could wilt even under a continuous fine mist sprayed on their roots. For this reason, a shallow pool of nutrient solution is typically allowed to collect at the bottom of the chamber where the tips of the roots can likely uptake sufficient water to keep them from wilting.""]"	['<urn:uuid:09a7388e-fe50-4057-aceb-a7cfd2988909>', '<urn:uuid:e73e0763-9286-49eb-b389-65567bf4312c>']	open-ended	direct	concise-and-natural	similar-to-document	comparison	expert	2025-05-01T22:36:12.692263	10	61	2054
187	I'm planning to do some home improvements and would like to know what materials are commonly used in kitchen fixtures and how they should be handled during installation?	Various materials are used in kitchen fixtures, each requiring specific installation considerations. For sinks, options include composite (which needs structural support due to weight), stone (requires proper sealing), fireclay (needs reinforced cabinetry), enamel (requires careful handling to prevent chipping), and stainless steel (easiest to install). For plumbing installation, particularly with copper pipes, proper preparation is crucial. The pipes must be cleaned until smooth and shiny using specific materials like 320-grit sandpaper or plumbers emery cloth (not steel wool or files). When installing, it's critical to use compatible metals to prevent galvanic reaction. The installation process involves applying soldering flux, properly fitting the pipes together, and using a propane torch with moving heat to create proper seals.	"['A white kitchen sink is made from a wide variety of materials. It has a classic aesthetic look and timeless style. It is a common thing that white works well with everything.\nThe styles come in white kitchen sink farmhouse, traditional, and modern. The designs will blend well with any color of countertops and kitchen islands.\nFurthermore, there are several options for the kitchen sink that fit your needs. Those are fireclay with step rim, composite apron front, under-mount, single or double basin, kitchen island sink, and so on.\nThen, you will have a question of which kitchen sink is the best? First is considering your family habits and needs. Different purposes determine what type and material to buy.\nLearn more about the kitchen sink from the following information. Once you define the purpose, you can choose from lots of options below.\nTable of Contents\nComposite Kichen Sink\nAre you looking for a great and durable sink? Composite material might suit your need. This type provides a modern aesthetic and cutting-edge to the kitchen.\nComposite combines acrylic resins and quartz dust that gives stone appealing. Importantly, its surface can hide scratches and watermarks.\nThis kitchen sink features a sound-absorbing effect because of its density. Moreover, avoid exposure to extreme heat since it will damage the surface.\nIf you are installing a composite sink, get ready to add structural support to accommodate the heavyweight.\n- Unique piece\n- Resistant to heat\n- Smooth surface\n- Very heavy\n- Need annual sealing\nStone White Kitchen Sink\nStone sinks include marble and granite. They preserve the natural textures and give a unique look since the carving process is from a single block.\nCombine the kitchen sink with natural stone countertops. It will provide an attractive appearance to your kitchen. Unfortunately, this material is porous, so it needs proper sealing.\nSome kinds of stone are more prone to staining than others. The surface needs to be sealed to avoid being damaged and scratched from chemicals and cleaning products.\n- Unique design\nSolid Surface Apron Front\nThe solid surface comes from the acrylic resin that looks like enamel with lower price and lightweight. Therefore, if you are on a tight budget, it is a great choice.\nBeware of purchasing the cheaper option of solid sink since it may consist of a calcium powder filler. It causes a yellowed and dingy look within a year.\n- Many styles and colors\n- Short lifespan\n- Prone to scratches\n- Discoloration overtimes\nMatte Fireclay with Step Rim\nClays and glaze have been heated at a very high temperature to form fireclay. Because of a heavy fireclay white kitchen sink, you need to prepare reinforced cabinetry to support it.\nFireclays look like traditional a cast-iron enamel kitchen sink. This material is more resistant to scratching. It just requires re-glazing after being used over time.\nWhite kitchen sink material is commonly from fireclay, although it is also available in off-white, blue, and black tones. A deep single bowl farmhouse is the most attractive fireclay design.\n- Limited colors and sizes\n- Susceptible to stain\nEnamel Under-Mount Sink\nA timeless model of the white kitchen sink is the enamel. It has a softer and quieter look than stainless steel. If you do proper maintenance, its style will enhance the kitchen value.\nCast iron and a glass-based glaze are two materials to construct an enamel white kitchen sink. They easily resist strains, so only use a non-abrasive sponge and mild acid to remove any scratches on the surface.\nIf the basis of the sink is cast iron, it will be very sturdy. Avoid hitting hard because the surface can chip. However, enamel-over-steel becomes a less durable low-end choice.\nEnamel is different from the white ceramic kitchen sink, although both are designed to fit any style. Porcelains provide more colors, whereas the other has fewer options for design.\n- Many color options\n- Low maintenance\n- High risk of chipping\n- Potential for staining\nCopper Apron Front Sink\nAn identical feature of copper material is its bright rosy-colored surface that becomes a standard model of the drop-in kitchen sink. Smooth and hammered finishes are available to choose as you please.\nWe know that the cooking area often becomes a breeding ground for germs. Copper is one of the best white kitchen sink materials since it can kill bacteria.\nYou can keep the copper sink clean and shiny by regular cleaning. Wash with ordinary soap dish in a soft sponge and then towel dry to avoid watermarks.\nMoreover, high-quality copper sinks resist corrosion and have a long lifespan. It also enables to diminish any unpleasant odors.\n- Easy to maintain\n- Antibacterial property\n- Low risk of staining\n- High maintenance\n- Prone to denting\n- Sensitive to acid and heat\nStainless Steel Kitchen Sink\nWhen it comes to modern kitchen sinks, stainless steel becomes the most popular material. This option is easy to install.\nSheeting thickness called gauge classifies the quality and price. A thicker gauge shows a cheaper sink. Besides, the thinner design means that the style is lighter and more expensive.\nThe stainless steel kitchen sink perfectly pairs with matte dark countertops to give a soothing look. In modern style, a double bowl sink with mirror-finished rim creates an attractive design.\n- More affordable\n- Lack of variety\n- Easy to scratch\nIn conclusion, we have presented everything that is to know about the white kitchen sink, various types of materials, and several variations of colors and designs.\nEvery kitchen sink has its advantages and disadvantages. Don’t worry about which material is the best. You can make a comparison of the most popular materials and what they are known.\nEach white kitchen sink serves a specific purpose, so it goes well with what you want to do. After defining the purpose, you can decide the best sink for your cooking space.', ""Many homes have copper pipes carrying its occupants their water supply. As with most homes, issues will arise in various areas in the house or you may find you need to add something or take it away. Your plumbing system is part of that too. Sometimes sections of copper piping can become damaged from impact or frozen pipes that may burst. Some do it yourself type homeowners look to add on to their plumbing system whether adding a new bathroom, laundry room or utility sink.\nFirst off let me start by saying, no plumber would ever call this sweat soldering so if you speak to one just tell them you are sweating in a new pipe. Homeowners tend to call it soldering and the real term is sweat soldering, but professionals shortened it to sweat or sweating. If you need to add to existing plumping or repipe your plumbing, the first thing to keep in mind, the golden rule if you will, use like metals. Do not try to attach copper fittings to cast iron pipe or vice versa, it won't work.Dissimilar metals will go through a process known as galvanic reaction, which mean the metals will react to each and degrade. Galvanic reaction will destroy your pipes.\nPrepare the Copper Pipe and Fitting\nClean the ends of the copper pipes that are to be joined together. The ends need to be very smooth. Use a piece of very 320-grit sandpaper, plumbers emery cloth or a wire pipe brush that fits into an electric drill.\nRub the abrasive material around the inside of the pipe and the outside of the that will fit into it. Make sure the copper turns smooth and shiny.\nDo not use steel wool, a file or rasp because they leave behind small copper shavings, burrs and scars on the pipe and fitting.\nGet Ready To Sweat The Pipe\nAs soon as you have sanded the copper fitting and pipe to a shine, apply soldering flux to the inside of the fitting and the end of the pipe. Typically, soldering flux has a small brush attached to the inside of the lid so you can spread the flux. Soldering flux can be purchased in hardware stores and home improvement stores.\nPlace the end of the pipe into the fitting and push it in as far as it will go by hand. Do not bang or hammer the pipes together.\nTurn the pipe a couple of times to completely and evenly spread the flux on the inside of the fitting.\nUse a clean rag to wipe off any excess flux that may have squeezed out of the copper fitting.\nUse a propane torch to heat the pipe and fitting. Move the torch flame around the edge of the fitting to heat it, do not leave the flame burning steadily in one place, keep the flame in motion.\nKeep waving the flame over the copper pipe and fitting until it becomes very hot.\nUse lead free solid core solder. Touch the solder to the edge of the fitting, if the pipe and fitting are hot enough, the solder will melt and run a ring around the edge of the fitting to seal it.\nDo not use the flame from the torch to melt the solder, the heat emitted from the copper pipe and fitting should be great enough to melt the solder.\nIf the solder did not melt and run a ring around the pipe and fitting, continue to heat the area with moving heat from the propane torch.\nThat's it -- done!\nWear heat resitant gloves when sweating copper pipes.\nWear safety glasses.\nMove all flammable materials out of the area prior to lighting the propane torch.""]"	['<urn:uuid:3098ce43-3b94-4159-9b28-1a059de8aa4b>', '<urn:uuid:682f559f-2031-4797-8353-b5c4d80cce95>']	open-ended	direct	verbose-and-natural	distant-from-document	three-doc	novice	2025-05-01T22:36:12.692263	28	116	1600
194	What are the benefits of contests and the legal requirements?	Contests help engage customers and increase business exposure through competitions and prizes. However, they must comply with legal requirements including prohibiting mandatory purchases, disclosing prize details and odds of winning, using skill-testing questions for chance-based contests, and following specific rules for Quebec residents like filing contest rules with the Régie and providing French translations.	['Pre-Show Planning Guide\nBusinesses choose to attend trade shows as a way to get the word out about their company. Because the audience you reach at a trade show is highly targeted, it is the perfect opportunity to showcase the goods or services your company can provide. If you want to make the most of your trade show experience, you need to do whatever it takes to make your booth stand out from every other booth at the show. Starting about six months before your next show, you need to use the following tips.\nThink about how you will spread the word about your attendance at the trade show. There are plenty of options available to you, including sending email or printed invitations, advertising through local or industry publications, public relations, posting to your website, telemarketing, sending direct mailings or soliciting sponsorships.\nOn-Site Promotion Tactics\nYou can make use of the area at or around the trade show to make the most of your promotion budget. Some of the areas in which you can advertise include the airport, nearby hotels, public transportation, billboards or the show directory itself. Sponsorship can be another useful promotional technique at the venue.\nUse the Media\nThe media can still be useful tool in spreading the word about your business. All you need to do is provide them with a newsworthy angle on your business. Build a press kit to distribute to the media that includes this angle. You can provide the local media outlets with these kits by mailing them out, making them available at the show and passing them out after the show.\nThere are basically two ways to reach the media: press releases and press conferences. Always make sure you have new information to share if you choose a press conference.\nCreate a Little Competition\nMany people love to compete for prizes. You can take advantage of this by providing competition for prizes to entice people to visit your booth. However, it is important to make sure you keep your game in tune with your marketing goals and corporate image. For instance, a trivia contest can work well for many companies. Make sure your prizes tie into company as well.\nAs you plan your competition, it is important to think about what type of competition you will hold, what your prizes will be, how long it will last and how to tie it into your promotional efforts. Make sure you are aware of any trade show regulations and local rules or laws that apply to these competitions.\nGive Something Away\nEveryone loves to get something for free. Think about the types of things your customers would be able to use in their lives and order them in bulk imprinted with your corporate logo and contact information. This will ensure those who take one will think of you often. As you choose your corporate giveaway, make sure it ties into your company and marketing effort in some way. It should also be something unique.\nTrends have changed. Trade show attendees expect to be treated as if they are a friend or family member, not a stranger. This is especially true if you are attending an international trade show. Some of the ways you can implement hospitable treatment into your trade show includes meal style events, sponsorship or a hospitality suite.\nPay Attention to Detail\nIn the world of business, the minor details are often important, though they are often overlooked. Therefore, you need to pay close attention to every detail to avoid losing customers who feel you are missing something important. Some of the most important “minor” details you should pay close attention to include marking your booth number clearly on your literature, keeping a large supply of extra marketing materials, making sure the information in the show guide is correct, clear and concise, and having an adequate supply of tickets to hospitality suites or other events.', 'If you’ve spent any amount of time on Facebook, Twitter or any social media site, you have probably noticed that they are littered with contests. Social media is a great venue for promoting awareness of a business or a brand and in a world where engagement is the name of the game. Social media contests are a great way for any business to get exposure, increase their number of followers or “likes”, encourage participation and engagement and grow their email database. Social media has provided a powerful medium for businesses to harness their customer’s playful and competitive nature and social media platforms, such as Facebook and Strutta, are now providing tailored solutions to ensure that it’s easy to run a contest without a hefty investment.\nSo what is a social media contest? It can be a sweepstake or a giveaway, or involve a competition, where submitted materials are judged. Social media lends itself to competition based contests where contestants submit photos or videos of themselves doing fun and interesting things. Judging of these contests is often audience-based, which has the effect of increasing the exposure of the contest and therefore, the product or business. Contests can also be used to harness valuable data about your customers; for example, asking entrants for their email is an easy way to ask them to opt-into receiving your newsletter.\nAnd while most participants are excited to discover they’ve won a contest; ambiguities in the contest rules can result in unintended consequences. Carefully worded rules and promotional materials can help avoid both negative publicity and unhappy participants.\nWe’ve all seen the “no purchase necessary” language in contest rules. This requirement originates from the Criminal Code, which prohibits contests where winners are determined based on chance (or a mix of chance and skill) if the entrant is required to pay money or give valuable consideration. Contest providers should also take care to specify how a participant can enter the contest without making a purchase, for example, by visiting the prover’s website or by mailing an entry.\nThe Criminal Code also prohibits contests where winners are determined solely by chance and as a result, often include a skill-testing question. If a contest already involves an element of skill, the contest provider may forgo the skill-testing question, but as there is some ambiguity around what qualifies as a “skill”, contest providers may opt to include the skill-testing question out of an abundance of caution.\nThe Competition Act, which also governs Canadian contests, sets out a number of requirements and requires adequate and fair disclosure. In particular, it requires disclosure of the number and approximate value of prizes, the regional allocation of prizes and important information relating to the chances of winning (such as the odds of winning). Additionally, such disclosure must be made available to participants without them having to take active steps to obtain these details. Other key requirements relate to contests where there are early bird prizes for first entrants to a contest and where there are multiple prizes to be awarded at different times. The Competition Act also stipulates that the distribution of prizes cannot be unduly delayed and that participants be selected or prizes distributed on the basis of skill or on a random basis.\nThe Competition Act also protects against false and misleading representations and deceptive marketing practices and it is important that contest providers review their contest marketing materials to ensure they are not misleading in any way.\nContest providers also need to be aware of the particular requirements of running a contest in Quebec. The Régie des alcools, des courses et des jeux (known as the Régie) has additional established specific requirements for contests that are available to residents of Quebec. These onerous requirements involve filing the contest rules and all promotional materials with the Régie, paying duties on the value of the prize to the Régie and in some cases, paying a security bond. Additionally, certain statements must be included in the contest rules and ultimately, the Régie has authority to determine whether the contest rules can be changed or cancelled. And finally, the Office Québécois de la langue française requires that all contest rules be translated and made available in French. Given these requirements, it’s not surprising that may contests limit eligibility to exclude residents of Quebec.\nSocial media contests also have unique considerations. Providers should be careful to limit the number of entries to prevent websites from being overwhelmed with entries and providers that make use of any technology to receive or tabulate entries should consider protections around the failure of technology. Additionally, contests that involve the submission of any intellectual property (art, photos, music, etc.) should have carefully drafted rules which state that: the submission is the original work of the submitter and does not violate any other parties’ intellectual property rights; that the submitter relinquishes all rights to such submitted content to the contest provider; and that the submitter has obtained all permissions required to make the submission.\nContest rules should also contain other key provisions, such as eligibility requirements, the right to disqualify inappropriate submissions, the right to amend the contest rules and the right to provide a different prize. Contest providers should also include releases and indemnities in the contest rules, especially where travel-related or high value prizes are included. Finally, contest providers should ensure that their contest complies with Canadian privacy laws and that any personal information collected from participants is not used for any other marketing purpose, unless the participant has expressly consented to such use.\nSocial media platforms may impose their own rules governing contests run on their platforms. For example, Facebook has its own rules governing Facebook promotions, which include making participants aware that Facebook is not affiliated with the promotion and prohibiting certain features from being used to administer the promotion (such as “sharing on your timeline” to gain an entry). Twitter also has guidelines that govern Twitter contests and these are aimed at discouraging the creation of multiple accounts and repeated Tweets.\nSponsorship is another area of contest law that many businesses fail to consider. Where a third party is donating a prize that forms the basis of a contest, contest providers would be prudent to enter into a sponsorship agreement that outlines the rights, responsibilities and protections of each party.\nSocial media has provided a powerful medium for businesses to harness their customer’s playful and competitive nature and social media contests are now seen to be a key piece of any social media strategy. However, contest providers should be aware of the various requirements of the Criminal Code and the Competition Act. A failure to comply with the applicable legislation can result in a fine, imprisonment or being ordered to publish a corrective notice. Contest providers should also be aware of the need for adequate and full disclosure in their marketing materials, appropriate disclaimers in their contest rules, and compliance with privacy laws and platform guidelines. Finally, the particulars of each contest can raise unique issues and therefore contest providers would be well-served to have counsel review any proposed contest rules and materials, including sponsorship agreements, prior to a contest campaign being launched.\nThe information provided above is for educational purposes only. This information is not intended to replace the advice of a lawyer or address specific situations. Your personal situation should be discussed with a lawyer. If you have any questions or concerns, contact a legal professional.The information provided above is for educational purposes only. This information is not intended to replace the advice of a lawyer or address specific situations. Your personal situation should be discussed with a lawyer. If you have any questions or concerns, contact a legal professional.']	['<urn:uuid:13a9a6e0-34a2-48ce-a698-707a4c8fdb18>', '<urn:uuid:e7100cbc-bd57-41a9-b3ad-8b61e333a0d4>']	factoid	direct	concise-and-natural	similar-to-document	multi-aspect	novice	2025-05-01T22:36:12.692263	10	54	1939
195	What healing roles do masters serve in martial arts versus veterinary settings?	In Kalaripayattu, the Gurukkal serves a dual role as both martial arts teacher and healer, providing Kalari Chikitsa treatments and passing down secret herbal medicine recipes through generations. In contrast, at veterinary centers, practitioners serve as integrative healers who combine multiple treatment modalities - conventional medicine, acupuncture, chiropractic care, and herbal medicine - to provide comprehensive care, with the goal of curing disease rather than just suppressing symptoms.	['Why traditional medicine making is part of Kalaripayattu training\nHerbal medicine has always been a part of Kalaripayattu, the traditional martial art of Kerala in Southern India. For the ancient Kalaripayattu warriors, knowing what herbs in the wild could be used for treating injuries and wounds from combat was an essential part of their knowledge. The ability to identify and successfully use medicinal plants was, in many cases, a matter of life and death.\nThis knowledge continues to be used in Kerala’s traditional martial arts centres where herbal medicine is given as part of Kalari Chikitsa treatments. Here the Kalaripayattu master (Gurukkal) plays the dual role of martial arts teacher and healer.\nWhat is Kalari Chikitsa medicine?\nIn Kalari Chikitsa, the herbal medicines are made from secret recipes passed down through the generations from master to student. As Kalari Chikitsa follows the same principles as Ayurveda, the medicine making techniques are mostly the same. But in Kalari Chikitsa, the combination of ingredients is more specialised for martial arts related conditions. Internal and external medicines are made for fractures, dislocations, bruises, sprains, strains, cuts and wounds, musculoskeletal and neuromuscular conditions, etc.\nLearning to make Kalari Chikitsa medicine\nCollecting, preparing, and cooking the medicine is an elaborate process that requires much skill, knowledge, dedication and persistence. The various medicine making stages benefit the students in their martial art practice, and also prepares them for advanced training when they learn to become healers.\nIn Kalari Chikitsa, the medicines are all freshly made according to the patient’s condition. Depending on the medicine the Gurukkal prescribes, the students will collect the part of the plant needed.\nThe part of the plant is chosen and used depending on where its medicinal value lies and its specific actions. It could be the leaf, flower, bark, stem, root or the whole plant.\nCollecting herbs is physically demanding with climbing trees, pulling roots out of the ground and carrying huge quantities of plants on the head, etc.\nThe student also learns to identify a variety of plants, what parts of the plants are used and the action of those plants for a particular client and their condition.\nJust like Ayurveda, Kalari Chikitsa uses a range of methods for preparing the herbs depending on how they will be used. Each method maintains the potencies of the herbs in different ways.\nSome of the methods used include:\n- Fresh leaves are pounded to a pulp with a mortar and pestle, and the juices are squeezed out by hand and filtered through a strainer.\n- Plants are put in the sun or shade to dry and then pounded with a mortar and pestle into a fine powder.\n- Fresh plants or powdered plants are mixed with water or herbal juice and ground on a big stone with a smaller stone to make a paste.\nAs the medicines are all handmade, the preparation of the herbs improves the strength and stamina of the student and improves their skill in the martial art. Their hands and arms are particularly strengthened, which aids their weapons practice.\nThis strength is also required for advanced stages of training in healing when the student learns to give massages and marma applications.\nIn Kalari Chikitsa and Ayurveda, herbs are generally not used alone but in formulas. It is the particular combination of herbs and their percentages that determines the specific actions of the herbal medicine.\nMost of the herbal medicines are cooked over a fire. They can take hours, days or more than a week to cook, and some require constant stirring. The herbs must be added in a specific order in a specific timeframe. A small mistake could destroy the entire batch of medicine.\nThrough this elaborate process, the student learns patience, perseverance, concentration and attention to detail. These attributes are all needed for progressing in the martial arts as well.\nIt also prepares the students for a future as healers as they learn not only the qualities of individual herbs but also the art of combining them and how the herbs work together on different patients’ conditions.\nDue to the diverse nature of the various stages of traditional medicine making, the opportunity exists for the development of many skills. The student also sees the depth of the Gurukkal’s knowledge and is inspired to continue gaining more knowledge and passing on the lineage.\nKalari Marma Massage\nKalari Marma Massage is an ancient south Indian warrior massage specially developed to treat and prevent injuries and pain-related conditions.\nChavutti Thirummal is an ancient south Indian warrior massage specially developed to increase flexibility, agility and strength.\nTraditional Indian Sports Medicine\nKalari Chikitsa is an ancient system of musculoskeletal treatments. Originating in Kerala in Southern India, Kalari Chikitsa was developed to benefit the warriors of Kalaripayattu. The techniques that were used to treat the ancient warriors are also highly effective in the treatment of modern day aches, pains and injuries.\nKalari Ayurveda Centre uses the traditional Indian healing systems of Ayurveda and Kalari Chikitsa to effectively treat your aches, pains and injuries.', 'Our goal at the Integrative Veterinary Center is to provide clients with all available options for pet care. This is achieved by using conventional medicine, diagnostics, and all other reasonable therapies or systems of medicine to obtain the best therapeutic results. Every system of medicine has its strong and weak points and each is utilized according to what tool is best suited for an individual pet’s problem. The goal is to try to resolve or cure disease and not to suppress symptoms alone. In cases where the animal is at the end of its lifespan or has a terminal condition, the goal is to provide our patients with as high a quality of life as possible.\nAcupuncture is a branch of Traditional Chinese Medical (TCM) that has been practiced for over 5000 years. Traditional Chinese Medicine theory holds that Qi (vital energy) flows throughout the body along energetic channels called meridians. Each meridian is also associated with a specific internal organ that reflects the physiological and pathological conditions of that organ. The meridians connect the exterior of the body with the interior.\nAcupuncture points are located along these meridians, and when stimulated can relieve pain and restore normal body functions. Acupuncture points have specific locations and effects and have been documented over millennia. From a Western perspective, acupuncture has been shown to stimulate a variety of sensory nerves in the body that transmit the signal through the nervous system to the brain, which then releases various chemicals that produce multiple physiologic effects that activate the body’s homeostatic regulatory mechanisms.\nAt IVC, we always say that anyone, human or pet, can benefit from acupuncture. Acupuncture can be used to treat numerous ailments from diarrhea to kidney failure. There are multiple acupuncture techniques: dry needle acupuncture, moxibustion, aquapuncture, alectroacupuncture, laser acupuncture, and gold wire implantation into acupoints. These various methods allow for flexibility in animal acupuncture because different pets respond to the various techniques in different ways.\nAcupuncture and herbal medicine are typically used together because clinical results can be obtained more quickly that way. The combined effects are also stronger, this is especially important in the treatment of difficult cases.\nFor more information on the different types of acupuncture practiced at IVC please go to the Pain Management page of our website.\nBotanical (Herbal) Medicine\nTraditional Chinese Medicine (TCM) has been used in China for over 2500 years to maintain health in humans and animals. TCM includes herbs, acupuncture and massage. Herbal therapy and acupuncture are typically used together, as the combined effect is greater than using one of them alone. Chinese herbal medicine is the primary type of botanical medicine practiced at IVC. However, Western, Aryuvedic, Native American, South American and Hawaiian herbs may also be used depending on the case.\nThe Chinese herbal prescriptions used at IVC are not available over the counter; they are prescribed the same as conventional pharmaceutical drugs. The herbs used in these prescriptions are from the same companies as those used to treat humans. They have been tested for purity and quality. TCM herbs are safe and effective and can be used for long periods of time without side effects when prescribed by a qualified herbalist and used appropriately.\nChinese herbs can be used to treat most conditions recognized by conventional medicine. They can be used alone or combined with other therapies for an enhanced or synergistic effect. Often, a Chinese herbal and a conventional prescription will be used together.\nChinese herbs are especially helpful in the treatment of internal medicine disorders, failing organs, chronic diseases and diseases of the geriatric animal. They can be used to relieve pain, help improve and restore organ function, strengthen and support the immune system. TCM herbal prescriptions are specific for the individual patient and are directed at the root cause of an illness to correct it, and are not given to disease present and are not used to control symptoms alone.\nIn general, TCM herbal prescriptions must be given for longer periods of time than pharmaceutical drugs, but the benefit lies in their natural ability to gradually return the body to a state of balance and health, without adverse effects. Herbs must be given regularly two to three times a day just like conventional medications to see a therapeutic effect. Modern botanical medicine research is currently working to identify and document the active chemical constituents of many of the herbal formulas used today. Clinical results from TCM herbs can be seen in as little as 3 days but some take up to 2 months depending on the formulation for full effect.\nHerbal medications come in a variety of formulations: pills, tablets, capsules, liquids, topical tinctures, washes or pastes, and concentrated herbal extracts in powder or granule form. The formulation used depends on the type of condition treated and the species of animal.\nFor best results, our veterinarians will periodically monitor your pet’s condition, utilizing both conventional diagnostics and Chinese veterinary medical examination (tongue and pulse diagnosis) to determine if the formula they are being given is effective and still appropriate. In general, for acute conditions an animal may need to be rechecked once every 3-7 days; for chronic cases, once a month or longer may be adequate.\nAnimal chiropractic is a medical therapy that is used to maintain the health and normal functioning of the nervous and musculoskeletal systems. It follows the same principles and practice as chiropractic medicine in human medicine.\nA chiropractic adjustment is a very specific treatment that corrects subluxations. Subluxations are defined as misaligned vertebrae that are stuck or unable to move correctly causing pain, stiffness and/or neurological deficits. When the movement of the vertebrae or bones of the spine are restricted, the animal will not have normal function or flexibility of the spine and/or limbs.\nAnimal chiropractic is a medical therapy that is used to maintain the health and normal functioning of the nervous and musculoskeletal systems. It follows the same principles and practice as chiropractic medicine in human medicine.In general, chiropractic treatments or adjustments correct subluxations.\nA subluxation is defined as a partial dislocation of the joints where the articular surfaces are still in contact with each other, but are misaligned. Subluxations commonly occur in the spine secondary to acute injury, over exercise and chronic orthopedic disease, but can affect other joints as well. Subluxations can cause poor performance, stiffness, pain, decreased flexibility and function of the muscles and nerves.\nWhat is a Chiropractic Adjustment?\nA chiropractic adjustment or spinal manipulation is a specific high velocity controlled thrust on the specific joint that is being manipulated to correct subluxations or misalignment of the spinal column to relieve pain and restore normal range of motion and neurologic function to the area being treated. Chiropractic medicine is designed to stimulate a natural healing response and return the body to homeostasis as quickly as possible without harmful side effect.\nChiropractic adjustments can treat neck pain, back pain, sacroiliac pain, and tail pain that occur secondary to hip and elbow dysplasia, arthritis, disc prolapse, cruciate ligament tears, cancer, and others. Early chiropractic treatment can prevent the development of more serious musculoskeletal conditions in the future.\nProlotherapy, also known as nonsurgical ligament reconstruction, is a medical treatment for the repair of torn or weak tendons and ligaments and for chronic pain.\n“Prolo” is short for proliferation, because the treatment causes the proliferation (growth, formation) of new connective tissue in areas where it has become weak. Clinical results using prolotherapy in dogs and cats appear to indicate the same response. Many elite human athletes use prolotherapy to strengthen their weak ligamentous tissues to prevent against future tears and injury.\nProlotherapy is helpful for many different types of chronic musculoskeletal pain including: chronic osteoarthritis, intervertebral disk disease, chronic back and neck pain, degenerative joint disease, strengthen weak tendon and ligaments and repair torn joint ligaments, particularly the cranial cruciate ligament. Not all animals are candidates for prolotherapy. Each pet is evaluated on an individual case by case basis, and an examination is required to determine if prolotherapy is an appropriate therapy for your pet.\nThe type of laser used at IVC is the Companion Therapy Class IV Laser. Laser therapy has been shown to accelerate the body’s natural healing process through photo-bio-modulation. Laser clinical studies over several decades have shown that laser therapy relieves pain and inflammation, decreases swelling, stimulates nerve regeneration and promotes tissue repair. Therapy Lasers have been scientifically proven and successful in treating post-surgical pain and inflammation and many acute and chronic pain conditions.\nConditions that can be treated with Laser Therapy\n→ Acute Conditions\n→ Cuts/ Bites\n→ Tooth Extraction Pain Relief\n→ Sprains, Strains & Fractures\n→ Post-Surgical Healing / Pain Relief\n→ Chronic Conditions\n→ Degenerative Joint Disease\n→ Inflammatory Bowel Disease\n→ Periodontal Disease\n→ Lick Granulomas\n→ Geriatric Care\n→ Hip Dysplasia\n→ Feline Acne\n→ Anal Sacculitis\n→ Perianal Fistulas\n“Let food be your medicine, and your medicine be your food.”\nHippocrates – The Father of Medicine\nAt the Integrative Veterinary Center we believe that many of our pet’s health problems can be traced to feeding species inappropriate diets. We do not follow or advocate a single dietary program for animals with a “one size fits all” approach. Instead, our specially trained veterinarians can prescribe a nutritional therapy plan that is tailored to your animal’s specific needs.\nOur dietary recommendations are formulated taking into account a variety of factors such as the species, age, breed, weight, work the animals is expected to perform and disease condition. Individual food therapy programs suitable for your lifestyle that range from complete and balanced homemade diets to commercially available pet foods can be formulated for your pet.\nFor more information please visit bensbarketplace.com\nChinese Food Therapy\nChinese food therapy is one of the five branches of Traditional Chinese Medicine (TCM) and is the study of food as therapeutic agents for the preservation of health and the treatment and prevention of disease. For over 2000 years, doctors in China evaluated and recorded the properties of foods and their effects on the body. Our doctors can formulate Chinese food therapy programs to treat your pet’s specific disease condition.\nChinese food therapy follows the same diagnostic and treatment principles as acupuncture and Chinese herbal medicine. Chinese food therapy can be thought of as food used as medicine. Diets are designed to bring the body back into balance and work synergistically with the other TCM modalities.\nFood is considered to have the same energetic actions as herbs (cooling, warming etc) for treating disease and its application is based on similar principles but with a much broader range of applications. Food energetics refers to the effects food has on the digestion, physiological processes and metabolism of the body.\nFood is grouped into 4 basic energetic classifications:\n- Thermal nature (hot, warm, neutral, cool, cold)\n- Flavor (sour, bitter, sweet, pungent, salty)\n- Organ association (a food can affect specific internal organs)\n- Channel affiliation (a food has a definite effect on a particular acupuncture channel more than any others)\nNutritional consultations are 30-45 minutes in duration and can be scheduled at the center or via the telephone by calling 916-454-1825\nConventional (Western) Medicine\nAt IVC all of our doctors are trained in conventional medicine and we provide the same veterinary services as those in a strictly conventional veterinary medical practice.\nThe goal of an integrative approach to veterinary medicine is to provide clients with all the available options for pet care. This is achieved by using conventional medicine, diagnostics and procedures together with all other reasonable systems of medicine (Chinese medicine, chiropractic) or therapies (prolotherapy, gold bead implants) to obtain the best possible results.\nEvery system of medicine has its strong and weak points and each is utilized according to what tool is best needed for a particular animal’s problem. The goal is to try and cure disease and not to suppress symptoms alone. In cases where the animal is at the end of its lifespan or has a terminal condition, the goal is to provide as high a quality of life as possible for that animal.\nWe carry a full line of conventional pharmaceutical drugs and offer the following services:\nIVC offers non-anesthetic dental cleaning through the Animal Dental Care. Non-anesthetic dental cleaning is performed without general anesthesia or sedation using the same cleaning techniques and instruments as dental cleanings performed under general anesthesia. This type of dental is indicated for animals that require routine dental cleaning more often than once per year, those that are sensitive to general anesthesia and for pets whose age and condition will not allow for general anesthesia.\nYour pet will have their mouth examined by one of our veterinarians and then the dental technician with assess the mouth by examining and probing each tooth. Any visible abnormalities of the teeth and or mouth will be recorded on a customized patient dental chart. Most dental cleanings take 20-30 minutes to complete. Due to limited kennel space, we kindly ask that you wait for your pet during this procedure. If your pet has a large amount of tartar or inflamed gums, our doctors may prescribe antibiotics to be given 48 hours before the dental cleaning and continued for at least 5 days after the procedure. They are not required in all patients.\nYour pet’s teeth will be scaled and polished and the oral cavity rinsed. Minor tooth extractions can be performed by our doctors under light sedation and or injectable anesthesia with appropriate monitoring. Major tooth extractions or other dental work such as root canals, fillings, etc, can’t be performed with this dental technique. If major dental work is required you will be referred to have your animal evaluated and treated for dental disease under general anesthesia.\nPost-dental, the doctor and dental technician will make recommendations as to how to keep your pets teeth clean and healthy and how often they will need to be cleaned in the future.\nFor more information about anesthesia-free dental services including an instructional video, please visit: animaldentalcare.info.\nIntravenous Vitamin C\nIntravenous (IV) Vitamin C Therapy involves the administration of Vitamin C directly into the bloodstream. This delivery system is very powerful because it allows the plasma concentration of Vitamin C to reach levels high enough to kill cancer cells.\nIV Vitamin C Therapy is a frequent treatment option for cancer, but it can treat much more than that. Vitamin C Therapy can also treat atopic dermatitis, gingivitis, chronic nasal discharge, chronic upper respiratory infections, chronic infections, autoimmune disease and immune deficiency conditions.\nFor more information on IV Vitamin C go to our Cancer Treatment page.\nWounds, both surgical and non-surgical can be difficult. At IVC we have a number of unique techniques to promote wound healing in addition to antibiotics and surgery.\nWe understand that many people live far away, and the ability to talk to a veterinarian regarding integrative treatment options for your pet is often requested. A phone consultation can be the first step in deciding what direction to pursue for your pets condition. For this reason, we offer phone consultations with Dr. Signe Beebe. This option provides flexibility for individuals that live long distances from our center, those out of state and internationally who are interested in obtaining information on an Integrative and or Traditional Chinese Medicine approach to healthcare for their pets.\nWe can provide dietary recommendations, herbal therapy and other integrative therapies after a review of your pet’s medical records. We may also be able to refer you to a veterinarian closer to your area that practices Integrative and or Chinese veterinary medicine.\nAs no physical examination of the pet was performed during a phone consult, we can’t prescribe any medication. Instead, you will need to follow up with a primary care veterinarian or schedule an examination of your pet with our office so that we may legally prescribe any recommended medications.']	['<urn:uuid:3c782127-20fd-40b3-b60b-deef425296d4>', '<urn:uuid:3cbff71c-1a55-478f-a542-273f3594a981>']	open-ended	direct	concise-and-natural	distant-from-document	comparison	expert	2025-05-01T22:36:12.692263	12	68	3490
206	Hi, I'm learning about sound engineering - did the Abbey Road chambers and Lucy In The Sky With Diamonds both use tape delay effects in a similar way?	While both used tape delay effects, they used them differently. The Abbey Road chambers incorporated tape delay through the STEED system (Send, Tape, Echo, Echo, Delay) to extend reverb decay time, using feedback loops and EQ in the signal path. In contrast, Lucy In The Sky With Diamonds used tape effects primarily for vocal enhancement, with John's vocals featuring varying degrees of Artificial Double Tracking (ADT) and echo, particularly heavy in the bridge sections where he sounds 'like he's exhaling helium'.	"['Notes on ""Lucy In The Sky With Diamonds"" (LITSWD)\nKEY G Major (but ...!)\nMETER 3/4 alternating with 4/4\nFORM Intro -> Verse -> Bridge ->Refrain ->\nVerse -> Bridge ->Refrain ->\nVerse -> Refrain/Outro (fadeout)\nGENERAL POINTS OF INTEREST\nStyle and Form\n- ""Lucy ..."" is comparable in many respects to\n""Tomorrow Never Knows""\n""Strawberry Fields Forever.""\nIt is less subtle than either of\nthose two songs, but it also all the more outrageous and not the least\nbit less ingenious.\n- It\'s also the most explicitly DRUGS-oriented of the three; even the\nearlier precedents such as\n""I\'m Only Sleeping""\nand ""Dr. Robert"" sound\ntame in comparison. Don\'t ever forget that just because the title\nof the song matches the name of picture painted by toddler Julian\ndoesn\'t mean that the song ISN\'T\'s about the so-called ""dreaded""\nLysergic Acid :-) Plasticene porters with looking glass ties, indeed.\n- The music is certainly as mercurial and elusive as the imagery of the\nwords, especially in terms of the constantly shifting key structure and\nthe rhythmic alternation of 3/4 and 4/4 meters. There\'s also that\ntypically Beatlesque manipulation of form in the way the bridge section\nis dropped for the final Verse sequence.\n- The use of drone-like harmony in the verse and rote repetition of a\nsingle phrase in the refrain lends an appropriate eyes-pinned hypnotic\nfeeling to the piece.\nMelody and Harmony\n- The melodic material is kept exceedingly simple in consideration of\nthe combined metrical and harmonic challenges which underlie it. Hum\nit to yourself and listen to what it sounds like independently of the\naccompaniment. I mean, there\'s not much there if you take it out of\n- The song\'s three sections each have a distinct harmonic and melodic\n- The verse is in the key of A and consists of a repeated chromatic\nfilling out of the I chord. The tune just noodles around the five\nnotes that outline the A Major triad.\n- The bridge starts off in the key of B flat but finishes up in the\nkey of G. This seemingly remote modulation belies a loose relation\nbetween the two keys: G is the parallel Major of g minor, and\nthe latter is the relative minor of B flat. The tune here is\nalmost monotonously stuck on the note D.\n- In order to provide some well-needed ballast-like oases of\npredictability, the Refrain is in G and stays close to home with the\nold I-IV-V progression. Howeve, it also pivots on the D chord to\nget back to the key of A for the verses which follow it. The\nmelody this time consists of a plain downward scale.\n- Lewisohn says the opening ostinato lick is played on a special Hammond\norgan stop that sounds like a celeste. Fine; the end result still sounds\nto my ears sounds like a harpsichord played back with as much seasick\nflutter as you\'d get from my 35 year-old (and counting) Wollensak\nreel-to reel tape deck.\n- Paul\'s standout peformance on bass is ample proof of how the magical\ncollaborative abilities of Messrs L & M was extended well beyond the\narbitrary task divisions of words-versus-music, or verses-versus-\nmiddle eights. I am especially impressed by the amount of variation\nprovided by the bass part:\n- Verse 1: downbeats only\n- Bridge 1: every beat, largely with repeated notes\n- Refrain 1: running eighth notes in Baroque fashion\n- Verse 2: downbeats only, again\n- Bridge 2: every beat, with more in the way of arpeggio outlines\n- Refrain 2: running eighth notes, again\n- Verse 3: more active and in a less regimented manner than\n- Outro: more running eighth notes, this time with arpeggios as\nwell as melodic runs\n- The vocal parts show similar attention to structured variation:\n- Verses: John solo; at first with so little ADT that\nyou can isolate a pristine single-track vocal\nby blocking out either of the stereo channels.\nFinal phrase is more truly double-tracked.\n- Bridges: John solo; heavily echoed with mild ADT, and\nsounding like he\'s exhaling helium :-)\n- Refrain 1: First phrase sounds like Paul solo but with ADT;\nSecond phrase has John & Paul singing in unison;\nThird phrase has them singing in parallel thirds;\nwith Paul as usual ""on top"", so to speak.\n- Refrain 2: The parallel thirds start right in the first phrase.\n- Outro: First phrase has John & Paul in unison, but the\nrest of the entire outro is in parallel thirds.\n- Other instrumental details of note include the way the lead guitar\nalways doubles the lead vocal in the bridges, the prominence of the\norgan during the outro, and the repeated, ultra closeup, yet sparing\nuse of the tamboura drone; ""is that you buzzin?""\n- The intro is a four measure presentation of the harpsichord ostinato\nwhich happens to contain within it the complete design of the verse\n| E | E | E | DC# |\n| A | A | A | A |\n| A |G |F# |F-nat |\n|E | | | |\n- It\'s very Baroque-like in the way it uses a single melodic line to\nsuggest a complete four-part linear texture. Play it at parties and\namaze your friends :-) And let me encourage ALL of you to sharpen\nyour listening skills by forcing yourself to transcribe such things\nby dictation, rather than turning immediately to the sheet music!\n- The verse contains two long and roughly parallel vocal phrases\nthat sit on top of a limping uneven quatrain of phrases in the\naccompaniment; note the 4/5/4/6 phrasing of the backing track:\nmelody: |C# C# C# |C# B A |C# B A |C# B A |\nbassline:|A |G |F# |F-nat. |\n|C# B A |C#\n- C# |E D C# |A | |\n|E |G |F# |F-nat C F|C D|\n|C# D E |C# B A |C# B A |C# B A |\n|E |G |F# |F-nat. |\n|C# B A |E D C# |A | |\n|E |G |F# A F |A F# A|\n| | |\n|D D D |C C C |\n- The ostinato is allowed in to fill out the A Major chord in the\nfirst and third phrases. In the second phrase, it ends with an implied\nmove to the flat VI (""Peggy Sue"") chord, of F Major. This gesture is\nstretched out in the fourth phrase where the bassline first lingeringly\nspells out the D Major chord (the V of G Major -\n- intimations of the\nRefrain yet to come!), before it chromatically descends through d minor\nto F Major. This time, the F Major chord is ""given its head"" to serve\nas a V chord to the B-flat key of the Bridge which follows.\n- The bridge ""should be"" 16 measures long with four phrases. At least\nit starts off that way, but it is foreshortened at the beginning of\nwhere the fourth phrase would be by a switch to 4/4, with the quarter\nnote of the 3/4 measures being equal to an eighth note of the new\n|D |- |- |- |- |- |- B-f|lat |\n|B-flat |- |C |- |F |- |B-flat |- |\nB-flat: I V-of-V V I\n|D |- |- |- C B |A - - - |\n|C |- |G |- |D 2 3 4 |\nG: IV I V\n- The tune of this section rides roughshod over the chords with the\nrepeated note, D, creating a freely (i.e. ""gratuitous"") dissonant\n9th chord on C and a 13th chord on F. The effect is one of I\'m-So-Tired\n(and can\'t be bothered) enervation; as if the singer didn\'t have the\nenergy or motivation to nudge the tune to move along more in lock step\nwith the chords.\n- The Refrain is a spirited albeit deliberately paced rock march whose\nenergy level contrasts nicely with the other sections. The section is\nan unusual 7 measures long with the opening phrase repeated three times,\nfollowed by a one-measure transition back to the next verse:\n--------------- 3X --------------\n|G C |D |\nG: I IV V\n|D ||A 2 3|\nA: IV I\n- The outro grows directly out of the final refrain, turning it into\nan eight measure section in which the meter is kept constant and the\nA Major chord, which earlier had signaled a return to the key of A, now\nis left hanging an unresolved V-of-V; certainly not the first or last\nexample of this particular chord left hanging.\n--------------- 3X --------------\n|G C |D |- |A |\nI IV V V-of-V\n- The fadeout starts relatively early and is done gradually, becoming\ncomplete about half way through the third iteration.\nSOME FINAL THOUGHTS\n- This song maintains a sublte and paradoxical hold on the forces of\nfoundation-level deep (throated) structure in spite of the way it appears\non the surface to be caught up entirely in those equally opposing forces\nof free-wheeling and unbound consciousness. In my analyses I don\'t usually\nindulge in the music theory equivalent of Chomskian linguistics, but in\nthis case the evidence seems just too compelling.\n- Cutting right to the chase ..., I think the harmonic structure of the\noverall song is characterized by the following Moebius Strip of a chord\n|A |F |B-flat |(C) |G |D |A |\nA: I flat-VI IV I\nBb: V I\nG: flat-III (IV) I V\n- Most salient in this scheme is the repeated motif of root harmonic\nmotion by a 3rd (rather than along the cycle of fifths), creating in\neach case a tangy cross relation; i.e. the move from A to F pits F#\nwith F natural, and the move from Bb to G pits B-flat with B natural.\n- What really sparks my imagination here is the way in which this same\nmotif of motion in 3rds is carried through in the melodic material.\nFor example, in the verse you have triadic outlining (C#->A, C#->E),\nand in the bridge you have that slide from D->Bb (on the two syllables\nof ""away."") For that matter, you can also point to those parallel\nthirds harmonizing the refrain!\n- And yes, I\'ll grant you that John was an essentially intuitive composer\nworking entirely without awareness aforehand of such precious internal\ndetails. But that doesn\'t mean the effect is not implanted in the music.\nAttribute it to, or blame it on, George Martin, if you will.\n- I leave you with one final detail in the song that, intuition aside,\nconvinces me that what I\'m describing is no random accident:\nDid you ever notice how, in the transition from verse to bridge, the\nbassline outlines a D Major triad (|F#-A-F#|A-F#-A|D ...|) and immediately\nfollowing, the so-called harpsichord part mimics the bass\'s melodic\noscillation over a minor 3rd using notes chosen for the extent to which\nthey emphasize the cross relation between F# and F natural; |E-C#-E|\nGo check it out -- in the second verse/bridge combination they execute\nit more sloppily than the first time around, but it\'s there both times,\nno question. No coincidence.\n""You\'re imagining it. You\'re letting things prey on your mind.""\nCopyright (c) 1995 by Alan W. Pollack\nAll Rights Reserved\nThis article may be reproduced, retransmitted, redistributed and\notherwise propagated at will, provided that this notice remains\nintact and in place.', 'Waves’ latest plug‑in takes us into the bowels of the world’s most famous studio!\nWhile not everybody gets to record at London’s most famous studio, Waves have made it possible to add some genuine Abbey Road flavour to your recordings, with plug‑ins that model the studio’s reverb plates, tape machines and vinyl‑cutting systems. The latest of these is Abbey Road Chambers. Developed in collaboration with Abbey Road Studios, this plug‑in replicates the acoustic spaces that have been used as reverb chambers, and the hardware that was used to capture the sound, including a tape delay integrated into the signal path that was used to extend the reverb decay time. This setup was used on countless classic recordings in the ’60s and ’70s — including some Beatles tracks — and the sound is still valid in today’s world of digital reverb. As is usual with Waves plug‑ins of this type, different components are available for mono, stereo, and mono‑in/stereo‑out processing.\nThe signal chain feeding the chambers was given the name STEED, standing for ‘Send, Tape, Echo, Echo, Delay,’ and comprised a buffer stage, a tape‑delay stage with an adjustable feedback loop, some basic EQ applied to the feedback path, and post‑delay EQ. Adding feedback around the tape delay, to produce the now‑familiar recirculating delays, allowed the reverb tail to be extended significantly without the delay element becoming too obvious.\nThe plug‑in version allows modulation of amplitude and/or pitch to be added to the tape‑delay stage, and also models the transformer saturation that was characteristic of this signal chain. The main live chamber, Abbey Road Chamber Two, has a moveable speaker and a left/mid/right array of three microphones, along with reflective cylindrical columns in the room that help diffuse the sound; all these are faithfully recreated in the plug‑in. The plug‑in uses modelling to replicate the electronic and tape signal paths, combined with impulse responses for the actual acoustic spaces and mic/speaker setups. This includes the original RS106 and RS127 filters used to EQ the output of the tape‑delay section. Unlike the original tape‑based system, however, there’s the added ability to dial in different left and right delay times when working with a stereo output.\nThe half‑tiled Chamber Two is probably the most famous of the Abbey Road chambers, and is characterised by a low‑mid emphasis that gives it a quite warm sound. The plug‑in gives you a choice of two speaker types: B&W 802 has the more hi‑fi sound, while the Altec 605 has noticeably less low end. There’s also a choice of Neumann KM53 or Schoeps MKH2 microphones, plus control over where both the mics and the speakers are positioned. These parameters have quite a significant effect on the sound: putting both the mics and speakers close to the same wall emphasises the early reflections, producing a more direct sound that picks out transients, whereas a more distant spacing gives a more diffuse reverb. When the mono version of the plug‑in is active, only the middle mic signal is used.\nWaves also supply impulse responses recorded in the brighter‑sounding Mirrored Room, as well as the Stone Room from Abbey Road’s now‑deceased sister studio Olympic, but these don’t have a choice of speakers or mics, only a choice of near or far mic positions. As its name suggests, the Mirrored Room is fitted out with mirrors on all sides, making it bright‑sounding and very reflective. Both these additional chambers can, however, access the full STEED delay section, with its feedback and post‑delay filtering.\nThe plug‑in GUI has a suitably old‑school look to it, with a bird’s‑eye view of the currently selected chamber and its current mic/speaker setup at the top, between the input and output meters and faders. Buttons in the centre strip select the mic type and position, which of the three chambers is in use, and the type of speaker, again with a choice of positions within the room. There’s also a control that can adjust the reverb time, multiplying the length of the IR by between 0.5 and 1.5 and thus varying Chamber Two’s normal 1.8‑second decay time over the range 0.9 seconds to 2.7 seconds.\nIn the lower half of the window are the controls for the STEED delay section, which has its own top‑cut and bass‑cut filters plus mid‑range cut/boost, all affecting the feedback loop. There are also Drive and Mod amount controls plus a large dial for Feedback, above a numeric display for setting the delay time — with a tempo‑sync option that wasn’t available ‘back in the day’. A Link switch enables the delay values of the left and right channels of a stereo channel to be adjusted together. If left and right have different delay values, any offset will be preserved when they are linked.\nTo the right are the output filter sections, the RS106 providing switchable top and bottom cut frequencies and the RS127 cut or boost at a choice of 2.7kHz, 3.5kHz or 10kHz. Quadrant‑style faders set the reverb chamber in/out balance and overall wet/dry mix respectively. Individual sections, including the tape‑delay Drive, can be bypassed if not required.\nOnce you’ve chosen an appropriate chamber complete with mic and speaker options, setting up is easy enough. After setting an input level that leaves a bit of headroom, it is a matter of adjusting the tape‑delay time and feedback, tweaking the high‑ and low‑cut filters and then setting a wet/dry balance. The Reverb Chamber fader regulates how much of the signal is taken from the reverb chamber mics and how much from its input. If set all the way across to input, then you hear only the tape delay with no reverb. Up to 500ms of delay time is available, so it is possible to set up a useful range of tape echo, reverb pre‑delay and slap‑back echo effects as well as Abbey Road’s unique combination of tape echo and reverb chamber.\nIn theory, you could set up a very similar signal chain using standard tape delay, EQ and IR‑based reverb plug‑ins. In fact I tried exactly that, but although I achieved some very usable results, the Abbey Road Chambers plug‑in always managed to sound more earthy and organic. This plug‑in has applications on guitars, drums, vocals and other instruments, and I’m betting it would sound really authentic on an old Dobro. I would have liked separate modulation speed and depth controls but I’m guessing that things are done the way they are to maintain authenticity. Whether you need Abbey Road Chambers or not depends very much on the type of music you make, but anything with a vintage pop, rock, blues or rootsy flavour would certainly benefit.\n- Easy to use.\n- Authentic live chamber sound.\n- All the original hardware is modelled to recreate the STEED signal path.\n- Parameters for the Mirror Room and Olympic Stone Room are more limited than for the Abbey Road Chamber Two.\nAbbey Road Chambers is an easy-to-use package of audio nostalgia that can add a vintage UK vibe to your recordings.']"	['<urn:uuid:6278508c-b634-4b03-82a2-06dd1936aa1d>', '<urn:uuid:cb672c8c-f5f0-41fa-92f2-9c580bd443c9>']	factoid	with-premise	verbose-and-natural	similar-to-document	comparison	novice	2025-05-01T22:36:12.692263	28	81	3059
212	When did spiders first appear in the fossil record?	Spiders have a fossil record that dates back to the Devonian Period, approximately 380 million years ago. They are one of the oldest and most diverse groups of species on earth.	['Printer friendly version\nSpiders, webs and insects: A new perspective on evolutionary history\n24 November 2011\nUniversidad de Barcelona\nThe orb web, typical of a large number of spider species, has a single evolutionary origin, according to molecular phylogenetic research reported in the Proceedings of the Royal Society. The study in question, which was contributed to by the lecturer Miquel A. Arnedo from the Department of Animal Biology, who conducts research for the Institute for Research on Biodiversity (IRBio) of the University of Barcelona, also presents the hypothesis that the diversification of spider webs is motivated by the need to occupy new natural habitats (trunks, stems, etc.) and to make more efficient use of natural resources.\nSpiders are one of the oldest and most diverse groups of species on earth, with a fossil register that dates back to the Devonian Period (some 380 million years ago). With almost 40,000 identified species, spiders are the predominant arthropod predators of microfauna in the natural environment. The study, which applied molecular biology and bioinformatic techniques for examining evolutionary patterns, focused on the phylogenetic analysis of DNA sequences. Specifically, the team of experts studied the molecular differences in six genetic markers taken from a taxonomic sample of 291 spider species, representing 21 of the 22 families of Orbiculariae (used in the study to refer to Deinopoidea, Araneoidea and Nicodamidae).\nAs Miquel A. Arnedo explains, “This scientific study looks at the most complete taxonomic sample examined to date, in terms of the number of species and families represented, to understand the phylogeny of spiders that weave orb webs, analysing the DNA sequences of all available genetic markers.”\nWhy did spider webs diversify?\nOrb weavers appeared approximately 200 million years ago, in the Middle Triassic, and underwent rapid diversification during the latter stages of the Triassic and the Early Jurassic. What are the causes of this evolutionary process?\nTraditionally, the diversification of spider webs has been linked to the spread of insects, which are the spider’s main prey, and flowering plants (angiosperms). The authors of the new study formulate a new hypothesis to describe this evolutionary phenomenon. “In the article, we suggest that the changes in spider webs are intended to facilitate the move to new habitats and to make better use of the trophic resources in different ecosystems. In other words, the abundance of prey and the structural complexity of the habitat are more influential factors than the actual diversification of the prey. Moreover, according to our study, the biological explosion of orb webs would not have coincided with the rapid diversification of insects,” says Miquel A. Arnedo.\nAccording to Arnedo, “Spiders are generalist predators, and few cases have been found in which they specialize in a particular type of prey. In addition, most spiders do not weave orb webs or produce more irregular forms. It is not the capacity to weave webs that has enabled spiders to diversify but rather their ability to produce silk, and this is not the same thing. Silk threads, which are produced by many arachnid species, can be used for anchorage, movement, nest-building, protecting eggs, and so on.”\nTraps that also evolved\nOver their evolutionary history, spiders have come up with different strategies for catching prey. Orb webs, which are difficult to construct but extremely flexible and resistant, are the result of a complex stereotyped pattern of behaviour in spiders. In the article, the experts also consider a reconstruction of the evolution of webs, referring to examples such as the families Linyphiidae and Theridiidae, which weave simple webs that are easier to build, in which the spider is protected from predators, or the Mimetidae family, which prey on other spiders on their own webs by simulating the vibrations caused by trapped prey.\n“The great diversification began with sticky silk, which is a more efficient material and easier for spiders to produce. In our study, we found that all of the evolutionary innovations that have occurred since the first orb webs emerge independently, require less energy to be expended by the spider, and demand fewer behavioural patterns,” explains Arnedo. This suggests that spiders, rather than following the evolution of insects, design new strategies that allow them to occupy the largest possible ecological space.\nMiquel A. Arnedo, winner of the 2009 ICREA Academia award, directs the UB’s Arthropod Systematics and Evolution Laboratory, which focuses on the study of factors that determine the diversification of living species. The group works on various research areas based on the use of molecular markers to study the function and evolution of arachnids, a field in which next-generation sequencing technologies will pave the way for a more complete understanding of evolutionary processes.\nThe article published in the Proceedings of the Royal Society is also signed by the experts Gustavo Hormiga (George Washington University), Dimitar Dimitrov (University of Copenhagen), Lara Lopardo (University of Greifswald), Gonzalo Giribet (Harvard University) and Fernando Álvarez-Padilla (National Autonomous University of Mexico).']	['<urn:uuid:4878416e-9c27-448d-9cca-57cc123cc7b8>']	open-ended	direct	concise-and-natural	distant-from-document	single-doc	expert	2025-05-01T22:36:12.692263	9	31	819
215	martin gerlach photographer and sigmund freud work timeline comparison vienna	Martin Gerlach relocated his photography publishing house to Vienna in 1872, while Sigmund Freud began offering therapy to patients in Vienna in 1886, showing they both worked in Vienna during overlapping time periods in the late 19th century.	"['Festoon made from vegetables and beets, from Festons und Decorative Gruppen aus Pflanzen und Theiren, or, Festoons and decorative groups of Plants and Animals, published in Vienna in 1893 by Martin Gerlach. Images courtesy of the Museum für Kunst und Gerwerbe, Hamburg\nThese festoons with their sumptuous cascades of ripe fruits and fragrant roses suspended from a striped silk ribbon resemble at first glance sections of stone ornament, or plaster moulding. But closer inspection reveals the roses to be cabbages, the delicious looking fruits are in fact beetroots and onions, the elaborate silk bow is a curtain cord, and a wooden finial has been pressed into service as a classical-looking prop, hiding the ends of plant stems at the top of the arrangement.\nAll the festoons, swags, garlands and other embellishments in Festons und Decorative Gruppen aus Pflanzen und Theiren, or, Festoons and decorative groups of Plants and Animals, are constructed using similarly inventive combinations of flowers, vegetables, taxidermy and domestic objects. Published in Vienna in 1893 by Martin Gerlach, this book of elaborate photographic collages was intended both as reference and inspiration for artists working across a range of crafts using pattern, from wood carving, plaster work, textiles, illustration and wallpaper design.\nJudging by the seasonality of the plant materials Gerlach used, the photographs were taken over the course of many months. Early spring blossoms of apple and cherry with nesting birds give way to the lilac, roses and hollyhocks of summer, while autumn provides a profusion of gourds, sweetcorn, grapes, apples and pumpkins. Winter is represented by arrangements of pine cones and stuffed squirrels placed amongst evergreen conifer branches.\nSome of the most effective designs use only leaves – the winding stems of creeping cinquefoil form a delicate narrow border, while larger sprigs of oak leaves and acorns could be imagined as infill sections for fabric or wallpaper. Peony flowers and leaves carefully spaced over a diamond grid background would have been helpful for an artist designing a repeat pattern.\nGarlands of citrus fruits are shown in half-sections, the smaller fruits at the edges, gradually increasing in size towards the middle. Some of the most elaborate festoons include tools and musical instruments – in one example a gardener’s spade intersects with a watering can, while a straw basket (or maybe an upturned straw hat?) overflows with produce, celebrating the bounty of harvest.\nFrom the middle of the 19th century photographers such as Adolphe Braun (1812 – 1877) and Charles Aubry (1811 – 1877) saw a commercial opportunity to produce still life studies of flowers as reference material for artists. Although photographs could not entirely replace living specimens, it must have been an immense advantage to be able to see forms of flowers, their leaves and the growing patterns of stems and branches throughout the year, especially in winter, when it was not possible to observe these from life. Gerlach produced a number of reference books in this genre, including plant forms, trees, examples of wrought iron and other architectural details.\nMartin Gerlach (1846 – 1918) was born in Hanau, Germany and trained as an engraver. He established a jewellery business in the 1860s but this enterprise was unsuccessful. Having become interested in photography, Gerlach started a publishing house in the 1870s in Berlin which produced his reference books and a crafts magazine, Die Perle. He re-located his company to Vienna in 1872 and continued his work there, eventually publishing more than forty books about design and a series of books for children including songs, poems and fairytales.\nBy the end of the 19th century decorative motifs like those celebrated in Festons und Decorative Gruppen, and popular in Europe since Roman times, were soon to be swept away by new ideas and fashions associated with Modernism. Today Gerlach’s plant and vegetable festoons and garlands have almost a contemporary feel to them – it’s not hard to imagine a photographer inspired, perhaps, by carvings or plaster work in a historic house, deciding to re-create them with real materials as a post-modern photographic project. More than one hundred years after publication, this collection of images continues both to inspire and document the complex role of photography in design.\nLinks to source materials below:\nFestoons and decorative groups of plants and animals by Martin Gerlach, Vienna. Gerlach & Schenk\nFestoons and still lifes made from sunflowers, mallow, lilies, vegetables, paradise apples, melons, radishes, peppers, crabs, goblets, grapes, bottles, hay, etc\nFestoon made of chestnuts, fruits, medallion and bird\nFrieze and festoons made from pumpkins, medlar leaves, corn, etc\nFrieze, festoons and vignette made of hazelnut, oak, grapes, pumpkins, paradise apple, Kukuk, etc\nGroup of apple blossoms with birds\nGroup of cherry plum and almond blossoms with a bird\nGroup of apple blossoms with medallion\nGroup of apple blossoms with butterflies\nInfill and festoon of apple blossoms with fruits, orange branch with fruits and kingfisher\nFestoons made from thorn blossom, lilac, garlic and pomegranate\nInfill and festoon made from laurel, lemon and orange with butterflies\nGroups of plums and Reine-Claude branches\nFestoon groups made of quince, sweet chestnut, tulip tree fruit, lemons, pumpkin, pomegranate\nFestoons made from vegetables, beets, cereals and garden tools\nThreads made of grapes, apple of paradise and hops\nFestoons made of musical instruments, palms, pomegranates, lemons, grapes, pumpkins, bay leaves, quinces, corn, coconuts, etc\nDecorative stripes and threads made of roses with mask, shell and medallion\nHanging groups of pumpkins and cucumbers\nVignettes made of roses, sign, bottle, palette, palm and mallow\nBorders and still lifes made of house leek, carrion flowers, orchids, water lilies, grapes, crabs, lobsters, fish, mussels, reeds, vessels, musical instruments, books, sheet music, laurel etc\nHanging groups and moldings made of thorn, peonies (seed pods), blackberries, marshmallow, mountain ash and apples\nFestoon, vignette and group of coconuts, quinces, corn, animal skulls and conifers with birds\nFrieze, group and decorative strip of laurel, animal skulls and butterflies\nGroup of hazelnut branches with squirrels\nFestoons and conifer infill with fox heads and squirrels\nTrims and infill made of strawberry, cypress and oak (note: I think the plant at the top of the photograph is actually cinquefoil which has strawberry-like fruits)\nGroups of peonies\nFriezes made from firethorn fruit, silver spruce, aralia, silver bush and trout\nGroup of acanthus\nFestons und Decorative Gruppen aus Pflanzen und Theiren – pages from the book digitized by the MK&G here\nMartin Gerlach on Wikipedia here\nGerlach’s photographs are collotypes – Wikipedia definition here\nThe Photographer in the Garden (EastmanMuseum/Aperture) here', 'Psychology Events: 19th Century\n19th century was when psychology was established as an empirical,\naccepted science. While measures would change within that 100-year\nspan, the model of research and evaluation would begin to take\n- 1878: G.\nStanley Hall becomes the first American to\nearn a Ph.D. in psychology.\n- 1879: Wilhelm\nWundt establishes the first\nexperimental psychology lab in Leipzig,\nGermany dedicated to the study of the mind.\nG. Stanley Hall opens the first experimental psychology lab in\nthe U.S. at Johns Hopkins University.\nHerman Ebbinghaus publishes his seminal ""Über das Gedächtnis""\n(""On Memory"") in which he describes learning and memory\nexperiments he conducted on himself.\n- 1886: Sigmund\nFreud begins offering therapy to patients in\n- 1888: James\nMcKeen Cattell becomes the first professor\nof psychology at the University of Pennsylvania. He would later\npublish ""Mental Tests and Measurements,"" marking the advent of\n- 1890: William\nJames publishes ""Principles of Psychology.""\nSir Francis Galton establishes correlation techniques to better\nunderstand the relationships between variables in intelligence\nG. Stanley Hall forms the American\nPsychological Association(APA), enlisting 26\nmembers in the first meeting.\nLightner Witmer establishes the first psychology clinic in\n- 1898: Edward\nThorndike develops the Law\nPsychology Events: 1900 to 1950\nfirst half of the 20th century was dominated by two major figures:\nSigmund Freud and Carl Jung. It was a time when the foundation of\nanalysis was built, including Freud\'s examination of\npsychopathology and Jung\'s analytic psychology.\nSigmund Freud publishes his landmark book, ""Interpretation\nThe British Psychological Society is established.\n- 1905: Mary\nWhiton Calkins is elected the first woman\npresident of the American Psychological Association. Alfred\nBinet introduces the intelligence\n- 1906: Ivan\nPavlov publishes his findings on classical\nJung publishes ""The Psychology of Dementia\n- 1911: Edward\nThorndike publishes ""Animal Intelligence,"" which leads to the\ndevelopment of the theory of operant\n- 1912: Max\nWertheimer publishes ""Experimental Studies\nof the Perception of Movement,"" which leads to the development\nCarl Jung begins to depart from Freudian views and develops his\nown theories, which he refers to as analytical psychology. John\nB. Watson publishes ""Psychology as the Behaviorist Views""\nin which he establishes the concept of behaviorism.\nFreud publishes work on repression.\nWatson and Rosalie Rayner publish research on classical\nconditioning of fear with their subject, Little\n- 1932: Jean\nPiaget becomes the foremost cognitive\ntheorist with the publication of his work ""The Moral Judgment of\n- 1942: Carl\nRogers develops the practice of client-centered therapy,\nwhich encourages respect and positive regard for patients.\nPsychology Events: 1950 to 2000\nlatter half of the 20th century was centered around\nthe standardization of the diagnostic criteria of mental illness,\nhallmarked by the release of the Diagnostic\nand Statistical Manual of Mental Disorders (DSM) by\nthe American Psychiatric Association. It is the foundational tool\nstill in use today to direct diagnosis and treatment.\nThe first Diagnostic and Statistical Manual of Mental Disorders\n- 1954: Abraham\nMaslow publishes ""Motivation and\nPersonality,"" describing his theory of a hierarchy\nof needs. He is one of the founders of humanistic\nHarry Harlow publishes ""The\nNature of Love,"" which describes the importance\nof attachment and love in rhesus monkeys.\n- 1961: Albert\nBandura conducts his now-famous Bobo\ndoll experimentin which\nchild behavior is\ndescribed as a construct of observation, imitation, and modeling.\nBandura first describes the concept of observational learning to\n- 1974: Stanley\nMilgram publishes ""Obedience to Authority,""\nwhich describes the findings of his famous obedience\nThe DSM-III is published.\nNoam Chomsky publishes ""On the Nature, Use, and Acquisition of\nSteven Pinker publishes an article introducing his theories as\nto how children acquire language, which he later publishes in\nthe book ""The Language Instinct.""\nThe DSM-IV is published.\nPsychology Events: 21st Century\nthe advent of genetic science, psychologists are\nnow grappling with the ways in which physiology and genetics\ncontribute to a person\'s psychological being.\nSteven Pinker publishes ""The Blank Slate,"" arguing against the\nconcept of tabula\nrasa (the theory that the mind is a blank\nslate at birth). Avshalom Caspi\noffers the first evidence that genetics are associated with a\nchild\'s response to maltreatment.3 Psychologist\nDaniel Kahneman is awarded the Nobel Memorial Prize in Economics\nfor his research on how people make judgments in the face of\nGenetic researchers finish mapping human genes, with the aim of\nisolating the individual chromosomes responsible for\nphysiological and neurological conditions.4\n- 2010: Simon LeVay publishes\n""Gay, Straight, and the Reason Why,"" which argues that sexual\norientation emerges from prenatal differentiation in the brain.\nThe DSM-5 is\nreleased. Among other changes, the APA removes ""gender identity\ndisorder"" from the list of mental illnesses and replaces it with\n""gender dysphoria"" to describe a person\'s discomfort with their\nJohn O\'Keefe, May-Britt Moser, and Edvard Moser share\nthe Nobel Prize for their discovery of cells\nthat constitute a positioning system in the brain that is key to\nmemory and navigation.\nDarren Stevens creates Constructed Development\nTheory and unites previously asynchronous theories within\npsychology by exposing our Self-Awareness. He later releases a\nbook called ""Thinking Deliberately"" to bring his idea to the']"	['<urn:uuid:2ab7aefd-2d54-4547-a95c-c6195ab45ddd>', '<urn:uuid:5ca9bcdc-556f-4544-814c-be5aec5b276a>']	factoid	with-premise	long-search-query	similar-to-document	comparison	novice	2025-05-01T22:36:12.692263	10	38	1920
216	radiation exposure compensation act guam nuclear	Robert Celestial, a citizen of Guam and retired US army sergeant, is currently advocating to include Guam in the Radiation Exposure Compensation Act. This act, passed by Congress in 1990, provides payments to individuals who developed certain cancers and diseases due to radiation exposure from above-ground nuclear weapons tests or uranium mining. Celestial became ill after participating in post-war nuclear waste cleanup at Enewetak Atoll, and now works to document the history of nuclear testing and its health impacts in the region.	['Vol. 2, No.2, July 2006\n[Download $ at Ingenta]\nProtesting Cartography: Places the United States has Bombed is a series of protest drawings of US military interventions. Utilizing surveillance imagery, military websites such as the US Department of Defense battle plans, aerial photography, mass media, and maps, each drawing is based on a rendering of a place, almost always viewed from the air, which has been targeted by US bombers. I choose to make these drawings by hand rather than to employ photographic or other mechanical means in the hope that people will take their time with them This project is an attempt to provide: a comprehensive and more humane acknowledgement of war; a revelation and analysis of our own complicity and passive acceptance of things as they are; different and multiple ways to access, interpret, and act on the magnitude of war and its aftermath; the truth; an uncovering of covert operations; and a remembrance of the dead for the living.\nELIN O’HARA SLAVICK IS A PROFESSOR OF ART AT THE UNIVERSITY OF NORTH CAROLINA AT CHAPEL HILL, USA, WHERE SHE TEACHES STUDIO ART PRACTICE AND THEORY (WWW.UNC.EDU/~EOSLAVIC). SLAVICK HAS EXHIBITED HER WORK IN HONG KONG, CANADA, FRANCE, ITALY, SCOTLAND, ENGLAND, CUBA, AND THE NETHERLANDS, AND ACROSS THE UNITED STATES AND HOPES TO SEE THE TRANSFORMATION OF GLOBAL CAPITALISM INTO SOME MORE EQUITABLE AND DEMOCRATIC FORM BEFORE SHE DIES.\nHistory is amoral: events occurred. But memory is moral; what we consciously remember is what our conscience remembers. If one no longer has land but has memory of land, then one can make a map.\n--- Anne Michaels, Fugitive Pieces\n> PROTESTING CARTOGRAPHY: PLACES THE UNITED STATES HAS BOMBED\nProtesting Cartography: Places the United States has Bombed is an ongoing series of more than fifty drawings begun in 1999. They are first and foremost protest drawings,taking as their subject US military interventions utilizing the geography, politics, history, cartography, art, and the language of war as their source material. Each drawing is based on a rendering of a place, almost always viewed from the air, which has been targeted by US bombers.\nAn important common formal element in the drawings is that each one begins with ink or watercolor dropped onto the wet paper. When it dries this becomes the foundation or “blank page” upon which to tell a violent story. I chose this common ground of abstract swirling or bleeding to depict the manner in which bombs do not stay within their intended borders. Depleted uranium and other chemical agents contaminate the soil, traveling in water and currents of air for decades. Mines and unexploded bombs lay in wait for unsuspecting victims who were not even alive during the war. Bombs penetrate the planet’s surface and lay the groundwork for genocide, cancer, more war, terrorism, widows, orphans, and a vengeful populace on all sides of conflict. All this seems impossible to comprehend, much less change. However, Protesting Cartography attempts to do just that by illuminating US foreign policy, by making it visually accessible and by graphically revealing its part in the dire situation in which we find ourselves today.\nPlate 1: World Map, Protesting Cartography: Places the United States has Bombed, 2002–ongoing (Detail), with pins marking each bombed site for which there is a corresponding drawing. Photo credit: Karen Malinofski and Christopher Ciccone, North Carolina Museum of Art, Raleigh.\nAs an interdisciplinary artist, studio art professor, activist, and an American, I am compelled to confront difficult and complex issues in my work out of a deep sense of responsibility. I work from the privileged position of an American academic, but I am filled with guilt, shame, and horror due to my government’s policies and actions. The American media fails us day in and day out by providing propaganda and half-truths. Although I do not believe that people are tired of knowing the truth or incapable of empathy, I understand that it may be easier for most Americans to choose a state of denial. Protesting Cartography is my personal creative response, my attempt to confront and unravel this criminal knot of lies.\nArt has had a traditional role as a catalyst for change. Lewis Hine’s photographs of children toiling in factories in the early twentieth century were instrumental in bringing about child labor laws. Picasso’s infamous painting of Guernica continues to provoke international and governmental debate about war and peace, the use of violence against civilians, and the power of art itself. From German artist Kathe Kollwitz’s expressive drawings and prints done during the First World War to Hans Haacke’s Vietnam-era antiwar pieces, protest art has utilized a variety of strategies to provoke viewers into becoming actively engaged participants rather than remaining passive receptacles of (mis)information.\nSue Coe, one of the most important political artists today, prod-uces graphic and dark images of homelessness, AIDS, the American meat industry, labor, protest, war, and more wars. She creates biting illustrations for magazines such as The Progressive, Rolling Stone and Mother Jones,(1) providing incentives for turning people into vegetarians and activists. If one is already an activist or vegetarian, her work provides courage to persevere. While Sue Coe’s work has inspired me since childhood and has had perhaps the most influence on me as an artist, I use an entirely different strategy in my own work.\nSue Coe, US Military Successfully Bombs a Mental Hospital in Grenada, 1984, Oil on paper, 44 × 37.5”, Collection of the Metropolitan Museum of Art, New York. Courtesy of the artist.\nFor example, Coe’s painting of the US bombing of a hospital in Grenada (plate 2) is far more representational than any of my bomb drawings. Red flames leap across the high horizon line. There is a dark and tragic sense of perspective. A person on fire falls to his death into the hellish pit where civilians cower and embrace their wounded loved ones. A corpse missing a right foot lies at the base of the stairs while planes fly over another figure hanging from a gallows on the horizon. Coe never shies away from gory details, bringing to mind such artists as Goya and Kollwitz. But for Protesting Cartography I deliberately choose the different visual strategy of colorful abstraction, a form I had never before employed. I chose relative abstraction (“relative” since the drawings are literally maps and include recognizable cartographic symbols and forms, as well as some architectural and geographical details) to reach people who otherwise might turn away from the bloody realities that Coe depicts. People are apt to approach abstraction with fewer defenses. Since the drawings are intentionally beautiful, they seduce the viewer into taking a closer look at the accompanying information that explains the horror beneath the surface.\nEach drawing is distinctive in color, form, and tone. Some are purely abstract and expressive; others like the World Map, which opens this field report, with pins marking each bombed site for which there is a corresponding drawing (plate 1), and Haiti (plate 3), are recognizably and semiaccurately cartographic, whilst Shifa Pharmaceutical Plant, Sudan (plate 4), for example, depicts specific topographical details like landed planes, buildings, and roads.\nSources for these drawings include surveillance imagery, military websites such as the US Department of Defense battle plans, aerial photography, mass media, and maps. Also, to further my intention of seducing the viewer, I choose to make these drawings by hand rather than to employ photographic or other mechanical, less visceral means, in the hope that people will take their time with them and not just quickly turn the page, change the channel, or close the website.\nWhile working on this project I have communicated about its form and content with a group of scholars, playwrights, geographers, art historians, anthropologists, writers, veterans, activists, historians, and participants in or witnesses to the bombings I have depicted in the drawings. They have contributed writings that often become part of the title information.(2) The variety of perspectives – from ex-soldiers and bombardiers to survivor-activists and geographers – presents a complex story to accompany the “illustrations” of bombsites.\nMost of the people with whom I am in dialogue about this project are Americans, except for Chilean exile Ariel Dorfman, British expatriate in France John Berger, Swedish writer Sven Lindqvist, and Guam citizen Robert Celestial.\nAriel Dorfman, author of Death and the Maiden, for instance, was invited to speak at the first American teach-in days after September 11th that I organized with a few members of the Progressive Faculty Network at the University of North Carolina at Chapel Hill. We naïvely thought that we could stop our government from bombing Afghanistan (plate 5) in retaliation. (Subsequently, I and two other organizers of the event received death threats, calls for our termination, and appeals for us to be tried for treason.) In his address, Dorfman linked the American September 11th in 2001 to the Chilean September 11th in 1973 when Chile lost its democracy in a military coup supported by the United States. John Berger, meanwhile, has compared September 11, 2001 to the bombing of Hiroshima on August 6, 1945 (plate 6). He writes, “The differences of scale and context are of course enormous. Both attacks, however, were planned as announcements.”(3)\nAnother contributor to my project, Robert Celestial, a citizen of Guam and retired US army sergeant, who was assigned to the Enewetak Atoll to participate in the postwar clean-up of nuclear waste, became sick from cleaning up the toxic residue and from living “downwind” of the tests. Celestial is spearheading the current advocacy to include Guam in the Radiation Exposure Compensation Act.4 As an activist and survivor, he tries to provide a historical account of nuclear testing – not just on the Enewetak Atoll but also on the Bikini Atoll (plate 7) and elsewhere – and the subsequent fallout and cancer clusters to anyone who will listen and who could possibly help.\nIt is no accident that Protesting Cartography comes into being at a time when US bombing campaigns are being carried out relentlessly. While we may imagine and try to believe that the wars are happening “over there,” they are always begun here at home. The first nuclear test was in Alamogordo, New Mexico. The cancer rate on Vieques Island, Puerto Rico (plate 8), is ten times that of the national average due to decades-long nuclear testing by the US government.\nWhen I exhibit these drawings there are always people who ask me if I worked for the CIA or where I found all this information, because they never knew we bombed so many places. This project is an attempt to provide: a comprehensive and more humane acknowledgement of war; a revelation and analysis of our own complicity and passive acceptance of things as they are; different and multiple ways to access, interpret, and act on the magnitude of war and its aftermath; the truth; an uncovering of covert operations; a remembrance of the dead for the living.\n1. Sue Coe has many publications of her work, including the books: Pit’s Letter (Four Walls Eight Windows, 2000); X (A book about Malcolm X) (The New Press, 1986); Dead Meat, with an essay by Alexander Cockburn (Four Walls Eight Windows, 1995).\n2. This project is currently under consideration at Duke University Press in book form with essays by eighteen contributing writers.\n3. John Berger, “War Against Terrorism or a Terrorist War?” While this has never been printed in the United States, it appeared in the London Guardian, Spain’s El Pais, Mexico’s La Jornada, France’s Le Monde Diplomatique, and Germany’s Frankfurter Rundschaun, 2002.\n4. On October 5, 1990, Congress passed the Radiation Exposure Compensation Act (RECA), providing payments to individuals who contracted certain cancers and other serious diseases as a result of their exposure to radiation released during above-ground nuclear weapons tests or as a result of their exposure to radiation during employment in underground uranium mines.\nBlum, William. 2000. Rogue State: A Guide to the World’s Only Super-power. Monroe, ME: Common Courage Press.\nLindqvist, Sven. 2000. A History of Bombing. London: Granta Publica-tions; New York: The New Press.\nMichaels, Anne. 1998. Fugitive Pieces, First Vintage International Edition, p. 138. New York: Vintage Books.']	['<urn:uuid:762cf2b8-de66-4fc2-a6bb-a5b427709530>']	open-ended	direct	short-search-query	similar-to-document	single-doc	expert	2025-05-01T22:36:12.692263	6	82	2021
217	how many people orange county recycling plant serve	The Orange County water recycling plant produces enough water to serve 800,000 people.	"['The liquid in the trough below looks remarkably like iced tea. But trust me, you don\'t want to drink it.\n""This is the first step of our treatment process,"" says Denis Bilodeau, vice-president of the Orange County Water District, on a metal catwalk next to a canal of municipal sewage.\n- California drought: \'Water cops\' hope to curb water waste\n- Farmers hit with record $1.5M fine for allegedly stealing water\nWater is precious in the drought-plagued region, and this massive water recycling plant in Fountain Valley, an hour south of Los Angeles, was built to convert raw sewage into drinkable H20.\nThe brown liquid begins to bubble. Then it will be drawn into straw-like filters 1/300th the size of a human hair.\n""That will keep all of the bacteria and viruses out,"" Bilodeau says.\nThe sewage will go through reverse osmosis and then be treated with intense UV light from bulbs manufactured by Ontario company Trojan UV.\n"" It\'s actually clean down to the atomic level, where all we have left is the H20 molecules,"" Bilodeau says. ""And now this plant produces enough water to serve 800,000 people.""\nGot any more sewage?\nAccording to the Orange County Water District, the facility is the largest of its kind in the world. Built in 2008, it has already gone through one expansion, and now Bilodeau says they\'re preparing for a second.\n""Our only limiting factor now is that we need more sewage water to process,"" Bilodeau says. ""Here in Orange County we actually have less sewage than we did 20 years ago because of all of the water conservation that takes place with low-flow toilets and low-flow shower heads.""\nUrban Californians are using a third less water than they were two years ago. But letting lawns go brown and fountains go dry isn\'t enough. Many here realize that at home they have to not just use less, but re-use more.\nThat\'s why Laura Allen decided to modified some of her appliances. Half of California\'s urban water is used on landscaping. But the garden at her apartment building gets most of its water from its sinks and washing machines.\nAs she washes her hands, the dirty water is piped from the sink into small underground reservoirs covered with small round covers. Water trickles out of the pipe and into the reservoir through a layer of wood shavings.\n""The greywater flows through, it soaks through the wood chips. And they are actually the filter, so they catch all the lint or debris in the water, and the greywater soaks down into the soil,"" Allen says.\nThe washing machine, too, has been retrofitted with a simple valve.\n""One side of the valve sends the water back to the sewer or the septic, the other side goes into our irrigation system,"" Allen says. ""You have to make sure you\'re using plant-friendly products… if you use that, the water\'s great quality for irrigation.""\nAs founder of the group Greywater Action, she now teaches people how to install their own water recycling systems, which are becoming more popular as Californians become more aware of the drought and receive generous incentives from water utilities.\n""Generally speaking, you can save 16 to 40 per cent of your water consumption,"" Allen says.\nThat\'s about 56,780 litres a year for an average household. Which is helpful, but some cities are starting to think a lot bigger.\nThis week, the the Metropolitan Water District of Southern California presented a plan to develop a water recycling plant in the Los Angeles area that could provide enough water for 300,000 people for a year. It would be even bigger than the mega-plant in Orange County, which generates enough to cover a quarter of the needs of the district\'s more than two million residents.\n""Once we explain to people that the water we create here is actually cleaner than bottled water or what\'s in their tap,"" Bilodeau says, ""then they understand that this water is very safe to drink.""\nExcept no-one will actually drink this water — at least not right away.\nRegardless of how much the water is filtered, health officials here still don\'t allow it to go directly from toilet-to-tap.\n""We\'re very mindful that perhaps the public isn\'t quite ready for that step yet,"" Bilodeau says.\nInstead, it\'ll be piped underground to replenish California\'s dwindling groundwater, which may eventually get drawn back into the municipal water supply.\nBut he\'s certain that soon Californians will have no choice.\n""The future is here,"" Bilodeau says.']"	['<urn:uuid:78034183-2d3f-4cb9-bcc0-a9ec9df69ac2>']	factoid	with-premise	short-search-query	distant-from-document	single-doc	novice	2025-05-01T22:36:12.692263	8	13	750
225	gas industry waste money energy efficiency solutions	The global oil and gas industry is wasting significant resources through gas flaring, which amounted to 143 billion cubic metres in 2021, representing $47 billion in lost revenue at conservative pricing. This waste occurs while the industrial gases market, valued at 88.4 Bn in 2021, continues to grow, demonstrating a disconnect between resource wastage and market demand.	"['Profligacy amid scarcity\nThe insanity of gas flaring during a global energy crisis\nUkraine is smouldering. The EU is paying a fortune to import LNG. Yet the global oil and gas industry is still flaring off as much gas as the EU buys from Russia each year. Plus ça change?\nSome things never change. The energy world has been turned upside down by Russia’s invasion of Ukraine and European politicians have woken up to the urgent need to wean their economies off Russian gas. Yet the deplorably wasteful practice of routinely flaring off excess upstream gas at the well head is, sadly, still going strong.\nAs Europe contemplates the long and painful process of extricating itself from heavy dependence on Russian gas, it should come as a galvanising shock to learn that the global oil industry flared enough upstream gas in 2021 to replace Russian methane molecules in the European energy mix almost entirely.\nNew data from the World Bank reveals that worldwide gas flaring rose marginally to 143 billion cubic metres (Bcm) last year. That equates to roughly 93% of Europe’s gas purchases from Russia. Another way to look at it is that those 143 Bcm could have generated some 1,800 terawatt-hours (TWh) of electricity, almost two-thirds of the EU’s net domestic power generation, according to the World Bank.\nIf you add in the flaring of petroleum liquids and the venting and leaking of methane from oil and gas infrastructure, the amount of primary energy wasted by the oil industry comes to a staggering 264 Bcm of gas-equivalent — roughly 1.7 times Europe’s total Russian gas imports in 2021, or 7% of the entire world’s natural gas consumption.\nThat’s according to flare capture specialist Capterio, which analysed the data to put the sheer volume of waste into perspective. If priced at a conservative $7.50 per million British thermal units (MMBtu), gas flaring accounted for $47 billion of lost revenue. In Europe, gas is trading at several multiples of that, and in any case, the emissions damage is significant: flaring emitted one billion CO2-equivalent tonnes of greenhouse gas emissions last year.\n“This waste is unacceptable, especially in today’s world of energy insecurity, sky-high energy prices and a global climate crisis,” — Capterio CEO Mark Davis\nEnd flaring, alleviate scarcity\nOf course, very little gas is flared in Europe, so ending the practice would not make much more gas available within this region. On a global basis, however, the net supply-demand balance would look quite different with 5–7% more upstream gas being brought to market.\nGlobal gas markets were already tight before the EU set highly ambitious targets to replace Russian supplies with imports of liquefied natural gas (LNG). This is driving up spot prices and pitting European gas buyers against rivals in Asia, depriving parts of the developing world of gas.\nA swift end to flaring would make more gas available in the world’s biggest oil provinces, which would lower natural gas prices in markets where the captured molecules are monetised. This would create pockets of very cheap (or negatively priced) gas in the Middle East, Central Asia, North and West Africa, and parts of North and South America.\nTo the extent these extra volumes are monetised within existing gas markets — either by increasing supplies to domestic consumers or boosting pipeline/LNG exports — the knock-on effect would be lower prices elsewhere.\nGreater upstream supply in major LNG-exporting countries means cheaper feed gas. This improves margins for existing LNG producers, which would allow them to offer spot cargoes at more competitive rates to gain market share. Ultimately, this could translate into lower spot prices – potentially making incremental LNG purchases affordable in price-sensitive markets such as India and Pakistan, which are being priced out as Europe and China bid up the LNG market.\nSign up for original analysis of issues moving the energy transition needle, and support independent energy journalism:\nEnding flaring in the US would go some way towards ameliorating the impact of record US LNG exports on American consumers. Prices on US benchmark Henry Hub have spiked to multi-year highs, triggering renewed calls in some quarters to cap US LNG exports.\nThe US exported 100.2 Bcm of LNG in 2021 and flared 8.8 Bcm of gas. Capturing those volumes would almost certainly bring down US gas hub prices and reduce tensions between the US domestic economy and foreign policy priorities, such as maximising energy exports to allies in Europe and addressing the US-China trade deficit.\nRussia: the bear in the room\nRussia’s status as the world’s biggest gas flaring country by volume presents a big headache. Russia flared 25.4 Bcm in 2021, ahead of Iraq, Iran and the US (17.8, 17.4 and 8.8 Bcm, respectively). How can Russia end gas flaring if its main customer base – Europe – wants to buy less of its gas, not more?\nRussian gas has nowhere else to go because existing pipelines flow west towards European markets. Without Europe as a willing buyer, Russia would have to mothball scores of gas-producing wells in western Siberia. Russia is sitting on a growing surplus of gas as Gazprom’s European exports fall, so capturing associated gas would only add to the glut. Russia is expanding its pipeline capacity to China, but this will take time.\nThe Western world wants to exclude Russian oil from the global market, but that is proving tricky as China, Brazil, India and other importers are lured to heavily discounted barrels shunned by Europe and its allies.\nThere is no clear answer to the question of how to end Russian gas flaring amid the geopolitical bifurcation of global energy markets – unless Russian oil production itself is comprehensively mothballed. Russia’s crude output rose 2.5% in 2021, which drove a 0.9% increase in flaring. While this indicates a -1.5% reduction in Russia’s flaring intensity, it illustrates the environmental benefits of excluding Russian oil from the market.\nAs Western oil companies divest from Russia en masse, there will be less transparency and scrutiny of environmental transgressions in the Russian oil patch. Mobilising capital into Russia to build infrastructure to capture associated gas volumes is trickier than ever under a blanket of Western sanctions. All of this adds an environmental justification to the West’s political movement to shrink Russia’s oil industry.\nPaying lip service to morality\nWar in Ukraine and a global shortage of gas only add to the moral imperative to end gas flaring. Even in a well-supplied peacetime market, the practice is egregious.\nThere is no better measure of an industry’s sincerity to clean up its act than its performance on wasteful practices that harm both the environment and its own bottom line. Routine flaring of natural gas is the oil industry’s bête noire.\nThe dirty black plumes billowing endlessly from many thousands of flare stacks across five continents are now visible for all to see thanks to satellite monitoring technologies and data visualisation.\nYet the flares continue to boil the air and light up the night sky, offering a stark reminder of the yawning gap between the oil industry’s rhetoric on scope 1 emissions — the easiest to mitigate — and progress on the ground.\n“The status quo is increasingly becoming untenable. Not delivering zero routine flaring — especially when it clearly could have been achieved, whilst making money, with proven technology — will negatively impact the industry’s license to operate.\n“The oil and gas industry cannot afford to miss out on the opportunities from its own ‘low-hanging fruit’.” — Capterio CEO Mark Davis\nThat ‘fruit’ has gone unpicked for so long it is practically dying on the vine. Flaring volumes have plateaued over the last decade despite pledges from governments, oil companies and development institutions to end the practice of routine flaring by 2030.\nSignatories to the World Bank’s Zero Routine Flaring by 2030 (ZRF) pact cover 70% of all gas flared globally, including five of the ten worst culprits by volume: Russia, Iraq, the US, Nigeria and Mexico.\nOf these countries, only the US has reduced the flaring intensity of its oil. In order to hit the 2030 ZRF target, global flaring would have to fall by a daunting 44% every year this decade from a standing start.\nEnergy Flux is a reader-supported publication. To receive new posts and support my work, consider becoming a free or paid subscriber.\nWhere is the political will?\nIt is a dispiriting state of affairs, and one made all the more galling by the fact that progress does not require any great technological breakthrough or even particularly large amounts of capital.\nThe missing ingredient is the political will and robust governance required to implement and enforce meaningful legislation that makes capturing waste gas less costly than flaring it. Since this is the industry’s own product, many off-the-shelf mitigation options would pay for themselves in just a few short years. Some offer months-long paybacks.\nAs ever, some countries are faring better than others. The US, Algeria and Nigeria achieved the fastest reductions in gross flaring volumes (down by 3.1, 1.0 and 0.6 Bcm, respectively) last year, but these gains were more than offset by alarming increases elsewhere, namely in Iraq, Mexico, Libya and Iran – which increased their aggregate flaring volumes by 8.8 Bcm in 2021.\nThere are meagre signs of progress. Since gas flaring is a function of oil production, the fact that crude output rose more quickly than flaring volumes (1.4% versus 0.6%, respectively) means the underling ‘flaring intensity’ of each barrel produced fell by 0.7% last year to 5.1 cubic metres per barrel (cm/b) – but this is an underwhelming achievement; the flaring intensity of oil production rose strongly over the previous three years to hit an all-time high in 2020.\nThe disparity in flaring intensity between the cleanest and dirtiest oil producers is mind-boggling. Venezuela’s rate of 37 cm/b is 157 times greater than that of Norway, according to Capterio – despite the troubled South American country achieving a 33% reduction in its flaring intensity, the quickest reduction of that metric by any country in 2021.\nFlaring is everybody’s problem\nIt should come as no surprise that those countries with the highest flaring intensity tend to be the least stable, prone to conflict and with the weakest systems of governance. Venezuela, Syria and Yemen are among the worst performers, flaring more gas per barrel of oil produced than any other country.\nThis is not merely another developing world problem that rich countries can wash their hands of. The World Bank last year introduced a new metric, the Imported Flare Gas (IFG) Index, to highlight the flaring associated with crude oil imports.\nThis metric highlights the flaring consequences of certain crude imports and shares the responsibility for reducing flaring between exporters and importers. It is based on the premise that a country imports the flaring intensity of the country where its oil is produced.\nRich Western countries might have impeccably low gas flaring rates of their own, but they have among the highest ratings on the IFG index. Estonia, Australia and Switzerland are the three worst offenders because they import most of their oil from countries with high flaring intensities: Malaysia, Libya, Gabon and others. Greece, Italy and Spain all have higher IFG ratings than India or China. France, Germany and the Netherlands are all above the global IFG average too.\nThis underscores the pressing need for oil importers to face up to their role in perpetuating gas flaring in far-flung parts of the world that lack the means to address the problem. The time to act on flaring passed long ago, but it is never too late for wealthy nations to atone for past sins. Routine gas flaring is an eminently fixable problem, if only the world would try.\nAn earlier version of this article first appeared in Energy Monitor on 18th May 2022. Reproduced here with permission.\nVery much like the framing of ascribing the flaring intensity to the importing nation. Has anyone done a similar look with regard to venting?', ""Industrial Gases Market by Application Type (Healthcare, Manufacturing, Metallurgy & Glasses, Food & Beverages, Chemical and Energy, Retail, and Others); By Product (Nitrogen (N2), Oxygen (O2), Hydrogen (H2), Argon, Acetylene, Helium and Others); and Region -Analysis of Market Size, Share & Trends for 2016 - 2019 and Forecasts to 2030\nIndustrial gases market size was valued 88.4 Bn in 2021 and is expected to reach 169.2 Bn by 2031, at a CAGR of 6.7% in the forecast period.\nIndustrial gases are gaseous products manufactured in huge volumes for multiple processes of production. Their reactivity, inertness, and other superior physical properties are rated for industrial gases. Few examples of industrial gasses are oxygen (O2), Carbon dioxide (CO2), hydrogen (H2), nitrogen (N2), Argon (AR), and many others. These industrial gasses find their area of application in a form of gas bottles in therapeutic oxygen, balloon helium, welding and welding devices, beer containers, and LPG. A variety of small gas-pumped containers are also available for the production of industrial gases. These small gas cans include the supply of LPG, propane (C3H8), butane (C4H10), nitrous oxide (N2O), or carbon dioxide (CO2) in a form of cylinders, flasks, bottles, capsules, or canisters.\nThe rising demand for industrial gases in oil, food & beverage, medical, electronic, and petroleum & gas applications fueled the global market for industrial gases. Significant demand from the oil and gas industries is experiencing for industrial gases. To monitor different processes, refineries need huge amounts of industrial gases. Furthermore, high environmental requirements for reducing Sulphur content allowable in refining products encourage refining operators to desulfurize oil, offering the potential for industrial gas development opportunities the growth can be attributed to expanding energy demand, the adequacy of energy-efficient technology, surging demand for natural gas power plants, the effect of the shale gas revolution and a decrease in carbon dioxide emissions.\nGlobal Industrial GasesMarket: Segments\nGlobal Industrial Gases Market has been segmented based on product type, application type and location. It has been further segmented based on region into North America, Europe, Asia-Pacific, Mid East, and Africa\nOxygen dominated the market with over XX% of the market share in 2019\nGlobal Industrial GasesMarket is segmented by product into nitrogen (N2), oxygen (O2), hydrogen (H2), argon, acetylene, helium, and others. Oxygen is known to increase the thermal efficiency of fuel, and hence to be used to get more energy from the fuel, oxygen is utilized for manufacturing, melting of steel, medical applications, smelting of copper. Oxygen is used for the treatment and gasification of contaminated wastewater, contaminated water and biomass. To minimize emissions, chlorine may also be substituted by it in the production of pulp and paper. In future years, therefore, large-scale oxygen application in different industries is expected to boost demand for industrial oxygen.\nNitrogen is used to a broad extent in the health sector, and the developing North America and Asia-Pacific healthcare and pharmaceutical industries could fuel demand growth in the next few years. Nitrogen is an inert gas that can be used in heat treatment to create a stable atmosphere. Due to its neutral properties, gas is often used in large amounts in explosive furnaces and many other furnace applications.\nManufacturingdominated the market with XX% Market share in 2019 and is anticipated to witness significant growth in the forecasted period\nGlobal Industrial Gases market is segmented by Application type into Healthcare, manufacturing, metallurgy & glasses, Food & beverages, chemical and energy, Retail, and others. In the manufacturing sector demand for industrial gases such as N2, O2, CO2, H2, etc. is anticipated as the result of the increasing production activities in nations like India, China, Brazil, and South Korea to be significant growth of developing economies. A further boost is projected to be the growth of the sector in the rising adoption of advanced industrial gases in the electronic industry.\nHigh environmental requirements for reducing Sulphur content allowable in refining products encourage refining operators to desulfurize oil, offering the potential for industrial gas development opportunities. The growth can be attributed to expanding energy demand, the adequacy of energy-efficient technology, surging demand for natural gas power plants, the effect of the shale gas revolution, and a decrease in carbon dioxide emissions.\nHigh demand from the end-user:\nThe rising demand for industrial gases in oil, food & beverage, medical, electronic, and petroleum & gas applications fueled the global market for industrial gases. Significant demand from the oil and gas industries is experiencing for industrial gases. To monitor different processes, refineries need huge amounts of industrial gases.\nHigh initial cost\nIndustrial gasses are capital intensive and require a huge initial investment and high maintenance cost of the equipment thus restraining the market growth. Strict government policies and laws and orders to carry out the energy production by gas turbines in the industry hinder the market growth over the forecasted period.\nNorth America is anticipated to dominate the market with XX% market share in 2019 growing at a CAGR of XX% over the forecasted period.\nThe North American market is anticipated to witness the highest growth due to the growing emphasis on the Combined Cycle Gas Turbine (CCGT) capacity additions. The availability of enormous gas reserves, improved production and a lower build-up period helps power generation by CCGT.\nAsia Pacific: China, Japan, India, and Rest of Asia Pacific\nEurope: Germany, the UK, France, and Rest of Europe\nNorth America: The US, Mexico, and Canada\nLatin America: Brazil and Rest of Latin America\nMiddle East & Africa: GCC Countries and Rest of Middle East & Africa\nThese actors adapt policies to further improve their footprints in the market, such as providing multi-annual services contracts for current and emerging power plant shareholders. Competition among the leading suppliers is based on their gas turbines 'productivity and effectiveness, as well as their customers' associated services. To boost its market dominance due to the rapid technological change and fierce competition, technical capability and R&D are one of the most important focus areas of industry.\nSelect License Type\nUS : +1 (716) 218-3733\nUK : +44 (208) 1235555\nSelect License Type\nFATPOS CLIENT Appriciation DURING THE PROJECT""]"	['<urn:uuid:ead2696c-bcd8-4f36-afc7-50d9e8edbbc4>', '<urn:uuid:c81637f6-f42d-4bf3-adad-788f17337417>']	factoid	with-premise	short-search-query	distant-from-document	three-doc	expert	2025-05-01T22:36:12.692263	7	57	3016
230	hitler otto great leadership differences similarities	Hitler and Otto the Great both achieved leadership positions in Germany/Germanic territories but through vastly different means. Otto I became King of the Lombards in 951 through military intervention in Italy and was later crowned Emperor of the Holy Roman Empire in 962 by Pope John XII, establishing legitimate rule. In contrast, Hitler gained power through political manipulation during the Great Depression, when German unemployment reached 43%. He was appointed Chancellor in 1933 and used the Reichstag fire to persuade President Hindenburg to grant him emergency powers, eventually establishing dictatorial control through the Enabling Act and dismantling all opposition to create a one-party state.	"['What were the significant events that took place as Nazism became powerful?\nThe first significant event in the rise of National Socialism (""Nazi"" was a pejorative term) was the failed Beer Hall Putsch in which Hitler and other National Socialists attempted to take over the government of Munich by coup, much as Mussolini had taken over the Italian government. Upon the failure of the Putsch, Hitler was sent to prison where he wrote his political testament, Mein Kampf. The National Socialists were aided by the Great Depression when German unemployment reached 43 per cent.\nOther political ideologies at the time were the Communists and the Social Democrats.The Communists refused to cooperate with the Social Democrats even though the two parties together outnumbered the Nazis in the Reichstag. German Communists were blinded by the hatred of socialists and by the belief that Hitler’s fascist ideas represented the last throes of capitalism and a communist revolution would soon follow. Social Democratic leaders pleaded with the Communists for a temporary alliance to stop Hitler, at one point even posing their pleas at the Soviet Embassy, but there was no use. This lack of cooperation was exacerbated by a fire which destroyed the Reichstag. The fire was blamed on a young Communist radical who was subsequently guillotined. There was substantial thinking among historians for many years that the Nazi’s had started the fire to intensify the dispute with the Communists; however recent historical evidence indicates that the young man was indeed a Communist agent intent on bringing down the government by any possible means. Ironically, his actions played into the hands of Hitler.\nHitler was an expert in dirty backroom politics. He gained the support of people in the army and big business, who thought they use him to their own advantage. Conservative and nationalistic politicians also thought that they could use him. Thus, when Hitler demanded that he be named Chancellor as a condition of joining the government, they accepted his demand. On January 30, 1933, President Hindenburg named Hitler as Chancellor. The Reichstag fire, after a particularly raucous election, played easily into Hitler’s hands. He used the fire to persuade President Hindenburg to invoke the Emergency Powers provision of the Constitution, which allowed rule by decree. Emergency acts were passed which practically abolished freedom of speech and assembly as well as most personal liberties. When the Nazi’s won only 44 per cent of the Reichstag seats Hitler outlawed the communist party and had its representatives in the Reichstag arrested. On March 23, 1933, the Reichstag passed the Enabling Act which gave Hitler absolute dictatorial power for four years. Under the guise of legality, the Nazi’s slowly dismantled the opposition, and Germany was soon a one party state in which only the National Socialist Party was legal.\nThere were a number of significant events in Germany as the Nazi Party rose to power.\nThe first was the Beer Hall Putsch in Munich. This attempted rebellion did not work, but it pushed the Nazis to prominence.\nThe second was the election of 1930. In this election, the Nazis gained enough seats in the Reichstag to become the second largest party in German politics.\nThis led eventually to the third, and most importatnt, event in the Nazis\' rise to power. That event was the appointment of Adolf Hitler as chancellor of Germany. This happened in January of 1933.\nOf course, behind all of this was the economic and social turmoil that was rocking Germany in the years after WWI. There are no single important events in that process, but the turmoil allowed the Nazi ideology to become popular and allowed the Nazis to rise to power.', 'Two things of historical significance took place that day\nBy Joe Cannavo\nAlmost every month Italy has a public or national holiday that celebrates a religious or political event. For workers it means a paid day off. September is one of three months that does not have any such “official” holiday. However, two events occurred on Sept. 23 that have historical significance, one of which could have resulted in the breakup of a united Italy just 82 years after its unification in 1861.\nThe first one is the least known of the two and occurred on Sept. 23, 951, long before Italy’s unification in 1861. It all began in 949 when Italy fell into political chaos. One year later with the death, possibly by poisoning, of Lothair of Arles, the Italian throne was inherited by a woman, Adelaide of Italy, the respective daughter, daughter-\nin-law, and widow of the last three kings of Italy. A local noble, Berengar of Ivrea, declared himself king of Italy, abducted Adelaide, and tried to legitimize his reign by forcing Adelaide to marry his son Adalbert. However, in 951 Adelaide escaped to Canossa and requested German intervention. Otto I, traditionally known as Otto I the Great, the German king, invaded Italy. He received the homage of the Italian nobility, assumed the title “King of the Lombards” and in 952 forced Berengar and Adalbert to pay homage, allowing them to rule Italy as his vassals. Having been widowed since 946, he married Adelaide himself.\nOtto’s later years were marked by conflicts with the Papacy and struggles to stabilize his rule over Italy. Reigning from Rome, Otto sought to improve relations with the Byzantine Empire, which opposed his claim to emperorship and his realm’s further expansion to the south. To resolve this conflict, the Byzantine princess Theophanu married his son, Otto II, in April 972. Otto finally returned to Germany in August 972 and died at Memleben in 973. Otto II succeeded him as Emperor. In 962 Otto was crowned Emperor of the Holy Roman Empire by Pope John XII in Rome.\nThe other Italian historically significant event that took place on Sept. 23 could have undone the 1861 “Risorgimento” unification of Italy.\nOn that date in 1943, Benito Mussolini, deposed dictator of Italy, fashions a new fascist republic, by the leave of his new German masters, which he ruled from his headquarters in northern Italy.\nIn July 1943, after the Italian Grand Council’s vote of “no confidence,” Mussolini was thrust from power and quickly placed under house arrest. The Italian masses, who had so enthusiastically embraced him for his promises of a new Italian “empire,” now despised him for the humiliating defeat they had suffered during the war. But Mussolini still had one fan, Adolf Hitler.\nGen. Pietro Badoglio, who had assumed authority in Mussolini’s absence, knew there might be an attempt to break the former Duce out of his confinement, and so moved him to a hotel in the Apennine Mountains. Despite the presence of an entire army of armed police, German commandos in a bold move swept onto an Apennine mountain peak from the air, overran the hotel, and flew Mussolini to Hitler’s headquarters on the Russian front.\nMussolini could not sit still long and wanted to return to Italy to reassume power. But his German “patrons” had no intention of allowing him, whom they regarded as incompetent, to return to the scene of the disaster. So in order to pacify and control him, he was set up in a German-controlled area of northern Italy, Gargnano, on Lake Garda. Mussolini set about creating a reformed version of fascism, one that supposedly had learned from past mistakes and included elections and a free press. His “Verona Manifesto” was the blueprint for this new fascist republic, the Republic of Salò where his government departments had fled in light of the Italian surrender to the Allies.\nThough in theory there were to have been “free and fair” elections, there were never any elections in the new fascist republic, or for that matter, freedom of anything. Salò was little more than a police state clogged with aging Black Shirts — corrupt, viscous and delusional. And Mussolini, geographically removed from Salò, ensconced at Lake Garda as he was, controlled nothing. He was little more than a puppet of the Germans, spewing anti-Allied propaganda and avenging himself and his masters on traitors to the party by ordering the executions of former Grand Council members, including his own son-in-law, Count Ciano. Eventually, the Allied advance into northern Italy, and the brave guerilla warfare waged by the Italian partisans, spelled the end of Salò and its paper ruler, Benito Mussolini.\nWhen even Mussolini realized that all was lost, he conceded: “I am close to the end … I await the epilogue to this tragedy in which I no longer have a part to play.”']"	['<urn:uuid:7805bf01-b6d4-4718-8ee2-aa4a999a406c>', '<urn:uuid:fde16587-5f61-4216-9155-05064b8b6c82>']	open-ended	direct	short-search-query	similar-to-document	comparison	expert	2025-05-01T22:36:12.692263	6	104	1423
231	How fast can an E. coli bacteria swim?	E. coli bacteria can swim at a velocity of 20 microns per second.	"['Physics 434, 2014: Homework 1\nBack to the main Teaching page.\nPlease turn on the assignment either as a PDF file to me by email, or as a printout to my mailbox in physics. Detailed derivations (with explanations) and calculations must be present for the problems for full credit.\n- In class, we have discussed E. coli chemotaxis. I told you that once the bacterium reverses the direction of a motor rotation, the flagella bundle falls apart, and the bacterium instantaneously stops and reorients. Nobody objected, even though we all remember that inertia generally does not let a moving particle to stop instantaneously. So let\'s see if I cheated you or not. Following our ""order of magnitude"" style of estimates, let\'s assume that E. coli is a sphere of a radius of 1 micron. The Stokes\' law relates the drag force exerted on spherical objects moving in a fluid to the radius of the object and the fluid viscosity, . In this equation, is the viscosity, which for water is 1 mPa*s at 20 degrees Centigrade; is the velocity of the particle; and is its radius. Notice the peculiar dependence of the force on the radius -- the linear dependence. This is the property of laminar (or low velocity) flows. Write down the second Newton\'s law that describes the motion of E. coli once its propulsion mechanism stops. The bacterium is largely made out of water, and so its mass density is about 1 g/cm^3. Solve the equation of motion and find the duration of time it will take for the drag to decrease the bacterial velocity by a factor of two from the initial velocity of 20 micron/s. Then find the total distance the bacterium will move until it stops. How does this distance compare with the size of the bacterium? With a diameter of a water molecule? Was it OK for me to say that E. coli stops instantaneously once its flagella leave the bundle? Consider reading the Physics at low Reynolds number article by Purcell. It has a beautiful pedagogical description of this regime of microscopic fluid flows.\n- The first part of the problem is for those of you who had Physics 142 or 152: Let\'s fill in the blanks in our in-class discussion about photon counting in vision. Let\'s recall our knowledge of electromagnetism and estimate what would be the size of a diffraction spot created on a retina by a point source far away. We take the size of the pupil ~2mm, and the distance from the pupil to the retina ~2cm. Recall also that humans see colors from violet (about 450 nm) to red (about 700nm); so a number around 500nm is a reasonable number to estimate the wavelength of visible light. How does this size compare to the size of a human photoreceptor? (You may want to search for the photoreceptor size online; Wikipedia is a good starting point). Comment on why do you think this is. If a fly or a bee is sensitive to ultraviolet light, what would you expect the size of the photoreceptor to be? (An insect eye has a very different geometry, but the same laws of physics apply.) And this is for everyone: Let\'s say that there\'re about receptors covering 1 steradian (you may want to search Wikipedia for better estimates). Aimed with the typical photon flux number of (which we take from the paper by Stavenga; find it on the class web site), we can calculate the number of photons each photoreceptor gets in ~100 ms of decision-making time. What is this number? Do you expect fluctuations to be important?\n- This week I would like you to install Matlab or Octave on your computers and make it run. This is really your main ""computational"" assignment. The rest of this problem will not be graded. I am providing it only as a task that you can attempt in order to start learning the Matlab language. Don\'t worry if you do not know it yet -- you will by the end of the semester. Let\'s start with writing a program that will demonstrate the main topic of our Lecture 1 -- that much of biological information processing is probabilistic. We have discussed this for E. coli in class, and let\'s now think about a totally different example -- a neuron. Once a human sees a still image, s/he can make a decision if the image contains a certain object, such as an animal, in less than 100 ms. At the same time, an active neuron in the primary visual cortex will fire with a rate of up to 60 spikes/second or so, that is, only about 6 spikes over 100 ms. These come at random times. We will simulate this process in Matlab as follows. Make a vector of 100 numbers, each representing 1 ms of the 100 ms window. These numbers will correspond to whether a spike happened in a particular millisecond. For each of these hundred entrees, draw a random number using the rand function, and set the entree to 1 if the random number is below 0.06 and to 0 otherwise. Using the function sum, find the total number of the spikes that happened in these 100 ms. Repeat the procedure 1000 times using the for loop. Use the mean function to assure yourself that the mean number of spikes in 1000 repetitions of our 100 ms window is, indeed, about 6. Then use the std function to calculate the standard deviation of the number of spikes -- you should get about 2.4. That is, in each of our 1000 repetitions, we may have typically anywhere from 4 to 8 spikes. This spread is very large, and yet a human is able to make a decision about what s/he sees in 100 ms with almost 100 per cent accuracy. Amazing, isn\'t it? Even though we are so much bigger than E. coli, our information processing is still probabilistic.\n- (from Nelson, 2014, book) Use Matlab to plot functions and in the range of . The functions appear qualitatively similar. Now make a semi-logarithmic plots of these two functions. What outstanding feature of the exponential functions jumps out in this representation? Finally, make a log-log graph of both functions and comment.\n- For Graduate Students Only: You should read the Physics at low Reynolds number article by Purcell (find it on the main course page). Find the scallop theorem there, which tells that a microscopic organism cannot move directionally using a one-dimensional reciprocal motion, like scallop opening and closing its halves. (a) What if the motion is two-dimensional? Think of the symmetry properties of the low Reynolds number (overdamped) equations of motion and write down a general form of a displacement as a function of two arbitrary shape coordinates changing in time. Analyze your expression -- does it remind you of any other expressions you\'ve seen in classical or quantum mechanics? Try read the article by Shapere and Wilczek on this topic. (b) Can you think of a way how the scallop theorem can be violated? Hint: what if the water is moving around the scallop while it\'s going through its open/close cycle? The strategy I am suggesting is called ratcheting.\n- For Graduate Students Only: I have also thrown around some numbers describing how long it will take for a molecule of a chemical to leave the area around the bacterium, and for a new molecule to diffuse in. Let\'s look at the Einstein Relation, which relates diffusivity of a spherical particle in a fluid to the viscosity of the fluid, the particle radius, and the temperature. What will be a diffusion coefficient of a spherical particle of a radius of 1 nm in water at 20 degrees C? Assuming that the mean squared displacement in diffusion goes as (where is the dimensionality of the space), how long will it take for this particle to move 1 micron away from the E. coli? We have discussed that the bacterium can only go straight for about 10 seconds, before its own direction of motion changes due to rotational Brownian motion. How fast should the bacterium\'s speed be so that in this time it can move away about ten times farther that the diffusing particle would? ""Outrunning diffusion"" is a crucial criterion that shapes the bacterial run-and-tumble behavior.\n- Open ended problem, not graded: In class we briefly mentioned the Berg-Purcell limit on the concentration estimation. What is the similar limit on estimating a concentration gradient?']"	['<urn:uuid:d4f71b6d-0abf-4078-8197-490ca1deb985>']	factoid	with-premise	concise-and-natural	distant-from-document	single-doc	novice	2025-05-01T22:36:12.692263	8	13	1421
232	how many residents michigan wind farm opt out	More than 50 residents signed documents requesting to be removed from the commercial wind overlay district, with signatures dated between April 6 and April 14. According to Jeff Smith, the county's building and zoning director, the county has never had so many opt-outs.	['BAD AXE – The county is considering lawyering up in response to a list of more than 50 residents asking to be excluded from an area being primed for a batch of 50 to 70 wind turbines.\nCounty attorney Stephen Allen this week said county commissioners should hire outside legal counsel to determine whether allowing that many residents to opt out would create spot zoning.\nSpot zoning, which many sources say is generally a bad practice, can occur when officials zone a small area or parcel for uses contrary to surrounding areas.\nThe zoning could conflict with a county’s master plan and allow for land use not afforded to the large majority of nearby parcels.\nPut simply, officials say it creates a zoning area that looks like Swiss cheese.\nSpot zoning is typically ruled invalid if challenged in court, according to the nonprofit Michigan Association of Planning. Michigan’s Zoning Enabling Act of 2006 and Planning Enabling Act of 2008 make no mention of the term.\nJohn Nugent, a county commissioner and planner, says there will be a resolution on the board of commissioners’ agenda next week to spend up to $2,500 to clarify whether Huron’s scenario would create spot zoning.\nNugent says the list of residents wanting out of the project creates an “extraordinary situation.”\nDocuments included in a packet for a board of commissioners meeting read: “We the undersigned residents of Lincoln Township hereby request to be removed from the commercial wind overlay district. Signed April 2016.”\nThe documents list more than 50 signatures with addresses, dated between April 6 and April 14. Some are from landowners already under easement with DTE, including Lincoln Trustee John Wisneski.\nJeff Smith, the county’s building and zoning director, says the county has never had so many “opt-outs.”\nSmith also asked why some who signed leases with DTE now want out of the project, without giving explanation – considering some may have already cashed checks, he said.\nAllen says he’s worked as corporate counsel for the board of commissioners since 1999, but that he doesn’t get involved in the wind energy overlay process. He advised the county seek Detroit-based Clark Hill PLC for legal counsel.\nDTE Energy is in early stages to build 50 to 70 turbines across four townships.\nA project planning area covers 61 square miles and more than 39,000 acres – 22,000 in Lincoln Township. DTE says it has 21,000 acres under contract for wind development with about 100 landowners and is talking with other landowners.\nDTE says its plan far exceeds county requirements.\nProject Manager Matt Wagner says Allen’s advice applies to site plan review, a stage that planners aren’t at.\n“I have no doubt that we’ve met the requirements,” Wagner told county planners.\nMember Terry Heck asked how “overwhelming opposition” factors in if all planning and zoning requirements are met.\n“It doesn’t matter if people … don’t like it,” Allen said.\nIf all requirements are met and officials make a decision based on reason, “they’re stuck with it,” he said. Disallowing the project in such case would be capricious, according to Allen.\nHowever, officials noted the option of a referendum, which a resident may initiate by collecting signatures within the zoning jurisdiction to reverse such a decision.\n“People always have the final say,” Planning Vice Chair Bernie Creguer said.\n|Wind Watch relies entirely\non User Funding']	['<urn:uuid:cc6dfe54-6374-4877-b491-b3c7171b77e6>']	factoid	with-premise	short-search-query	distant-from-document	single-doc	novice	2025-05-01T22:36:12.692263	8	43	558
238	what did sam bak paint about holocaust	Rather than depicting grim images of the Holocaust directly, Bak used symbols in his paintings such as dismembered objects including teddy bears, pitchers, and teapots. His paintings show bleak scenes of destruction, broken pieces of life, and lost family members appearing as mere shadows. He painted about the human condition and felt the necessity to bear witness to those times, hoping that future generations might be spared a similar fate.	"['Testimonies of creative minds affected by brutalities of our times\nArtists at War\nView Sam Bak\'s painting series at\nSAM BAK - Poland - America\n“I’m painting something about human condition and what I know. I feel the necessity to remember and take it upon myself to bear witness to the things that happened in those times, so that human beings today and those of tomorrow, if it were only possible, are spared a similar destiny on earth.""\nThe video interview with Samuel Bak is an excerpt from The Art of Speaking About the Unspeakable documentary produced by Rob Cooper in cooperation with Pucker Gallery in Boston, Massachusetts and graciously offered by Bernie Pucker to be part of the Artists at War project.\nWhen I approached Sam Bak for yet another interview, he expressed in his ever eloquent manner, “It is not anymore a question of time, one hour or two hours, but the inalterable fact that there is no energy left for a challenge that your important project would require. I hope you will understand.”\nOf course I did understand – and knowing that he had just suffered a minor stroke, left me with an urgency to complete the project as soon as possible.\nI first met the artist in his paintings when Bernie Pucker invited me to the caverns of Pucker Gallery on Newbury Street in Boston and graciously agreed to have me select a collection of Bak’s works for the “Survival Through Creativity” exhibit I was planning for my art gallery in Kittery, Maine in commemoration of the 90th anniversary of the 1915 Armenian Genocide and the 60th anniversary of the Jewish Holocaust.\nI was not familiar with Bak’s works. As Bernie turned one painting after another, I found myself lost in the multi-layered symbols, details, and Hebrew letters that embodied the large and small paintings. Each one revealed bleak scenes of destruction, broken pieces of life reflected in shattered teapots, tea cups, toys, furniture, clothes, and more. Every painting offered allegory, metaphors of a narrative of symbolism projected a clear message from a witness whose childhood memories unfolded upon countless canvases. Each painting held time prisoner – pushing the viewer to the front seat view of man’s inhumanity to man.\nWhen I met Sam Bak for the first time, his gracious warm handshake projected a graceful resilience. As he sat in our living room hours before the start of the opening reception of the “Survival Through Creativity” exhibit, Sam talked about how his mother – the only surviving family member – had given him Franz Werfel’s book on the Armenian Genocide – 40 Days of MusaDagh. He knew well of the Armenian history and the atrocities that paved the path to Hitler’s actions that unfolded across Europe. In his slight accent, he articulated so well the emotions of loss – comfortably switching from one language to another (fluent in seven languages), he never lost a beat and always remained humble for an artist whose works have toured the world and are included in many prestigious museum collections.\nSam was born on August 12, 1933 in Vilna, Poland (now Vilnius, Lithuania). His family was forced into the Vilna ghetto and later into a labor camp. He was smuggled from the camp and given refuge in a monastery – and along with his mother was the only survivor of his entire family. He has spent his entire artistic life reflecting on his childhood memories of destruction and dehumanization. Whether symbolizing pears (instead of apples) to offer the lost paradise, or wondering how our world, “can integrate the history of violence which has been our legacy,” Sam argues with those who dismiss his paintings as mere “holocaust paintings.”\n“I’m painting something about the human condition and what I know. I feel the necessity to remember and take it upon myself to bear witness to the things that happened in those times, so that human beings today and those of tomorrow, if it were only possible, are spared a similar destiny on earth.”\nInstead of reflecting grim images of the holocaust, Sam symbolizes dismembered objects including teddy bears, pitchers, teapots, and more. Lost and disappeared family members appear in mere shadows. It’s difficult to choose a “favorite” Bak painting, but perhaps what touched me the most are symbols of “Tikkun” – the repair of the universe. The act of turning broken elements into good deeds in a reparative effort. To repair that which cannot be repaired as it’s broken forever. Sam explained how his art is a process of repairing the broken vessel. After all, that\'s what survivors are: “They are in disrepair, not whole anymore.”\nTikkun is testament that you can perhaps, “repair, but can’t restore” that which is destroyed, annihilated, massacred, and abolished. The patched-up are still fragmented. In some ways, Tikkun reminds me of the 15th-century Japanese Kintsugi tradition whereby cracked pottery is restored by incorporating the damage into the aesthetic of the restored item – hence making the crack part of the object’s history. Using lacquer resin mixed with powdered gold, copper, bronze, silver, or platinum the breakage is pieced together to enhance the original look.\nWhat I see in Bak’s Tikkun – the broken, although not fully repaired – is a masterpiece that makes audible the quiet of sufferance – giving words to the unspeakable.\nPaintings of a childhood “lost, interrupted, and ended” ask, force, and provoke an analysis of reasons for man’s inhumanity against man. They don’t focus only on the Jewish Holocaust – but on the universality of wars.\nIn June of 1941, Sam was eight when the Germans occupied Vilna forcing the Jewish population to wear the yellow Jewish Badge. He was put in charge of preparing badges for his parents and extended family. By September the deportations of Jews to the Vilna Ghetto started and Sam’s father was sent to a labor camp, while he and his mother were able to flee to the home of Janina Rushkevich, his grandfather’s sister who had been baptized in her youth. Janina sheltered them in a Benedictine convent, where the nun Marija Mikulska took Sam under her wing providing him with paint and paper. When the Germans placed the convent under military jurisdiction, Sam and his mother had to flee once again and returned to the Vilna Ghetto. In 1943 poets Avrom Sutzkever and Szmerke Kaczerginski invited the nine-year-old Sam to participate in an exhibition organized in the Ghetto. Sensing that their end was near, the poets trusted the young Sam with the Pinkas (the official record of the Jewish community) hoping that both would survive. Paper was a precious commodity during the war, so Sam, unable to resist the white pages of the Pinkas, used the margins for his drawings – leaving no empty pages.\nWhen in March of 1944 a children’s Aktion in the camp ended in the deaths of 250 children, Sam’s mother ran away and he hid under a bed in the living quarters of a camp building. Days later he was smuggled out of the camp by his father in a sack of sawdust to reunite with Janina Rushkevich and his mother. They returned to the Benedictine convent, where they were sheltered for 11 months, until liberation. Ten days before Vilna’s liberation, forced laborers, among them Sam’s father, were rounded up at the city’s camps and executed.\nFollowing the liberation, Sam began formal art studies with Prof. Serafinovicz, and later in Poland with Prof. Richtarski. After a short time in Berlin, Sam and his mother moved to Landsberg Displaced Persons Camp in 1945. His mother later remarried a survivor, Natan Markowsky, a senior administrator at the Camp.\nSam continued his art studies in Munich with Prof. Blocherer and in 1947 exhibited his works during David Ben-Gurion’s visit at Bad Reichenhall. Images were also published in the Hebrew newspaper, Davar HaShavuah, and the Yiddish Forverts in New York. At age 15, Sam moved to Israel to continue his studies at Bezalel Academy of Art and Design before entering the military for his mandatory service. Interest in designing theatre backdrops and costumes brought him to Paris in 1956, where he enrolled at the École des Beaux-Arts.\nMoving to Rome in 1959, Sam had a solo exhibition at Robert Schneider Gallery and later exhibited at the Carnegie International in Pittsburgh. After intervals of living in Paris, New York, Israel, and Switzerland, he finally settled in Weston, Massachusetts where he lives with his wife, Josée.']"	['<urn:uuid:bae50f06-cf32-4a7f-a424-4efffd44bed1>']	open-ended	with-premise	short-search-query	similar-to-document	single-doc	novice	2025-05-01T22:36:12.692263	7	70	1412
239	jennie wade death circumstances gettysburg civilian casualties statistics	Jennie Wade, a 20-year-old civilian, was the only civilian to die at Gettysburg during the battle. She was killed by a minnie ball that went through two doors while she was baking bread for Union soldiers. This is remarkable considering there were 125,000 people involved in the battle. Her house was hit about 150 times during the three-day battle, and she was later buried at Evergreen Cemetery.	"['People across the United States, and indeed the world were keeping score of Gettysburg last week, In fact they were also reflecting on the terrible tragedy that took the life of John F Kennedy twoscore and ten years ago.\nBut sevenscore and ten years ago the 272 words including that ""the world will little note nor long remember what we say here,"" were spoken to thousands gathered, and they are still very well known today. As they should be!\nAbraham Lincoln had taken the noon train the day on 18 November 1863 at Washington DC and travelled with a large entourage of officials to Gettysburg in the late afternoon and spent the night at the Wills house. Wills being the very lawyer who was so instrumental in helping to start a cemetery for the thousands that were still laying on the ground they died on days after the horrendous battles across some 25 acres of land named in honour of Sam Gettys. Those horrific days of July 1-3, to be remembered forever.\nMany of the public raced on ahead of the parade and entered to get best viewing by using the adjoining Evergreen and passed through the gatehouse shown above. A sign then posted at its entrance warned that..."" All persons found using firearms on these grounds will be prosecuted with the utmost rigor of law."" One must wonder if that sign existed three months months earlier during the deady battle, fought in part, on the very land that was then, and is today, part of Evergreen.\nThe Tyson Brothers Photography Studio of Gettysburg were two of over 500 photographers that made pictures during the Civil War. The brothers were among about 45 at Gettysburg. The image on the left was taking by them about 11.30 in the forenoon and shows a street now called Baltimore, and heading into the town. You are looking Northbound. The building on the left is at the corner of a street heading of to the left, as you look at the picture (Westbound) and is today known as Steinwehr Avenue. The building still stands today.\nA few minutes later the parade started to arrive and head off up Steinwehr to the entrance of the National Cemetery. If you enlarge the image on the right several ranks of military become quite obvious.\nHere\'s a view on the same area taken not long ago, and a map of the immediate area. The intersection is just above the letter ""A"" on right image.\nThe ""A"" actually marks the spot where Jennie Wade was killed. Twenty year old Jennie was visiting a sister who had just given birth a few days earlier. Jennie and family were visiting and helping out. The house was located between no mans\' land between the Confederates off to the left and the Union off to the right. During the three day battle Jennie and others baked bread and biscuttes for the Union soldiers and had awaken earlier one morning to place the bread kneaded the day before into an oven when a minnie ball shot rang out, traveled right through two doors and instantly killed her.\nWhile the house was hit about 150 times during the three day battle, Jennie would become the ONLY civilian to die at Gettysburg. With some 125,000 battling it out, she\'d be the only civilan casualty. She would later be buried at Everygreen, and quite close to the fence seperating it from the national cemetery.\nNote both cemeteries also on the above map.\nAs you look at the photo you are looking eastbound. The town is off to the left. The flag pole on the left is now marked by the National Monument shown within the semi-circle in the photo 2 down. The Evergreen Cemetery\'s gatehouse shown above, and also in the top picture in this blog, is also shown in the picture below this one. It is just left of the green arrow locating on the highway running from the top to bottom near the right side of image.\nBut this gatehouse is further back and at the road. The crowd scene is much closer to the foreground in the image.\nStill farther down slightly... and to the left is another marker. It is in this very area that it is believed Abraham Lincoln stood on a makeshift wooden platform and delivered his memorial speech.\nBut more on that on Monday.']"	['<urn:uuid:a3def8e6-22c9-43d3-a1ee-dc4bf08a60b6>']	open-ended	direct	long-search-query	distant-from-document	single-doc	expert	2025-05-01T22:36:12.692263	8	67	734
242	What characteristics defined Sergeant Baker as a soldier?	SGT Baker was described as agile and physically strong despite his short height. He was characterized as quiet, respectful, punctual, hard working, and dedicated to the Army and his battery.	['By Colonel Eric Robyn, Aide to the Supreme Allied Commander Europe, 1983-1985\nA Day with Sergeant John Baker,\nMedal of Honor Recipient\nAs a Field Artillery Battery Commander assigned at Herzo Base (a former Luftwaffe base near Erlangen and Nuremberg) in Germany in 1973, I was used to preparing for, and enduring, all manner of inspections and visits from higher headquarters routinely. One inspection that always added stress to my life was the old-fashioned, compliance-oriented Annual Inspector General (IG) Inspection, made especially stressful because my unit was a nuclear-armed Honest John Rocket firing battery. Every aspect of the battery would be scrutinized in detail: not only soldiers, weapons, equipment, barracks, and vehicles, but also all written training records, manuals, forms, and files had to be in perfect order.\nAbout a month prior to one of those IG inspections in 1973, a new soldier was assigned to my battery as Training NCO. His name was SGT John Baker.\nSGT Baker had been awarded the Congressional Medal of Honor (MOH) in 1968 for actions in Vietnam on 5 November 1966. In fact, his company commander, CPT Robert Foley (USMA ’63), was also awarded the MOH for actions that same day. SGT Baker told me that when President Lyndon Johnson made the presentations, he looked down at SGT Baker, at 5’2” the shortest MOH recipient, and up at CPT Foley, at 6”7’ the tallest MOH recipient, and exclaimed, “You two look like Mutt & Jeff!”\nKnowing that a dreaded Inspector General (IG) Inspection was coming up, and painfully aware of how many training aids and various updated training publications we needed, I planned a trip to the USAREUR Publications and Training Aids Center in Frankfurt. I asked SGT Baker to compile a list of everything we needed, and invited him to accompany me. In those days, we wore fatigues every day, so I was surprised when SGT Baker hopped into my car the next day wearing his Army Greens with the distinctive Medal of Honor ribbon showing five white stars on a field of blue. Noticing my puzzled look, he said, “Don’t worry, Sir, you’ll see.” During our long drive to and from Frankfurt, we had plenty of time to talk and of course, he told the story of that day in November 1966. His citation for valor is well worth reading: http://homeofheroes.com/moh/citations_living/vn_a_baker.html.\nWhen we arrived at the huge supply warehouse, manned primarily by active and retired NCOs, I confidently strode up to the counter and handed my long requisition list to the NCO in charge. He took my list, and looking it over, said it would take some time to gather all the materials and to prepare for a long wait because they were very busy that day. SGT Baker, who had been standing unseen behind me, then stepped to my right and up to the counter. I watched the look of complete surprise on the face of the NCO and others standing around as they recognized the venerable blue ribbon. They immediately came to attention and asked SGT Baker how they could be of service to him. When SGT Baker said he was with me and we needed the materials on the list right away, the response was awe-inspiring: “Not a problem, Sergeant, we’ll get everything right away! What else can we do to help you?” Not that I needed to be reminded of this simple fact, but that day I pleasantly observed how the MOH trumps a captain’s bars. With SGT Baker’s quiet – but visible – assistance, we returned with more than we needed and did well on the IG inspection.\nAlthough short in height, SGT Baker was agile and physically strong. He was quiet, respectful, punctual, hard working, and dedicated to the Army and my battery. To this day, I don’t know how he ended up in my unit, but I was, and am, very thankful for him!']	['<urn:uuid:a48f65e1-f4f5-4419-b77b-c419be6fb53c>']	open-ended	direct	concise-and-natural	distant-from-document	single-doc	expert	2025-05-01T22:36:12.692263	8	30	650
243	As someone studying military medical history, I'm curious about how U.S. Army nurses served during WWII and how this led to changes in the Air Force Medical Service structure. What were their combat roles, and how did this influence the later organization of the Air Force Nurse Corps?	U.S. Army nurses in WWII served directly in combat zones, with 59,000 women volunteering and participating in major operations like D-Day North Africa. They worked under enemy fire on beaches and in field hospitals, with 217 losing their lives and over 1,600 receiving decorations for bravery. This experience influenced the later establishment of the Air Force Nurse Corps in 1949 as part of the newly created Air Force Medical Service. The Air Force Nurse Corps became a fully commissioned officer corps, requiring a Bachelor of Science in Nursing degree, and its members could serve in various roles including flight nurses in aeromedical evacuation missions, nurse practitioners, and nurse anesthetists.	"['- STAFF PICKS\n- GIFTS + GIFT CARDS\n- SELL BOOKS\n- FIND A STORE\nThis item may be\nCheck for Availability\nAnd If I Perish: Frontline U.S. Army Nurses in World War IIby Rosemary Neidel-Greenlee\nSynopses & Reviews\nOperation Torch--U.S. Army Nurses in the Invasion Force\nD-Day North Africa\n8 November 1942\nI spotted Lt. Vilma Vogler descending a ladder at my side. Our eyes met for a moment in mutual shock, and then we quickly descended into a waiting barge. At that moment she and the other nurses had ceased to be ""the women."" We were all comrades in equally dangerous footing, trying to survive the insanity of combat.\n-Edward E. Rosenbaum, MD, former captain, U.S. Army Medical Corps, ""Wartime Nurses: A Tribute to the Unsung Veterans,"" New Choices (July 1989)\nAn artillery shell exploded sixty yards off the starboard side of HMS Orbita. Lieutenant Helen Molony, seated on board in the officers\' mess hall, felt her hand shake as she raised her coffee mug to her mouth. It was early morning, 8 November 1942. A convoy of Allied war- and transport ships, including the Orbita, the Santa Paula, and the Monarch of Bermuda, lay two miles off the coast of Algeria. On board these British ships were not only combat troops but the men and women of the 48th Surgical Hospital, including Lieutenant Molony. She was one of 57 U.S. Army nurses who, along with the hospital\'s 48 officers and 273 enlisted men, were waiting to land, side by side with the combat troops, on the beachheads of Arzew and Oran in Algeria.\nThe sun had not risen yet and the ships were still under cover of darkness. Molony glanced around the officers\' mess. The thunder of artillery had begun an hour earlier, and now, at 0515, she saw that the tables in the mess were crowded with officers, male and female, dressed in combat gear. Aside from the clanking of silverware and an occasional word or two spoken in hushed tones, the large wardroom was strangely quiet. In less than an hour, Molony knew that her part in Operation Torch-the invasion of North Africa-would begin. What she could not know was that her participation in the D-Day invasion would become a landmark in U.S. military history.\nOnly a few months earlier, in midsummer, the 48th Surgical Hospital had crossed the Atlantic on the USS Wakefield as part of what was, at that time, the largest convoy ever to sail from the United States. On 6 August, the 48th Surgical had disembarked at Greenock, Scotland, and taken a one-day train ride to Tidworth Barracks in the area of Shipton-Ballanger and Kangaroo Corners in southern England. The unit remained there for two and a half months, and Molony underwent the closest thing to military training the army nurses would receive, a regimen of hardening exercises of five- and ten-mile hikes, complete with field packs.\nFor the nurses of the 48th Surgical Hospital, as for all the army nurses sent overseas before July 1943, uniforms presented a definite problem. Before America entered World War II, the sole uniform the U.S. Army nurses had was a white duty nurse\'s uniform and white nurse\'s shoes. The only thing military about the uniform was the second lieutenant\'s gold bar, worn on the right lapel, and the caduceus with an ""N"" superimposed upon it on the left lapel. The caduceus had been a symbol of the Army Medical Department for decades. Doctors wore the caduceus plain, while nurses had a superimposed ""N"" for nursing, the dentists a superimposed ""D,"" and veterinarians a superimposed ""V.""\nAs for the clothing itself, the army provided blue seersucker dresses for the nurses in\nIn World War II, 59,000 women voluntarily risked their lives for their country as U.S. Army nurses. When the war began, some of them had so little idea of what to expect that they packed party dresses; but the reality of service quickly caught up with them, whether they waded through the water in the historic landings on North African and Normandy beaches, or worked around the clock in hospital tents on the Italian front as bombs fell all around them.\nFor more than half a century these women’s experiences remained untold, almost without reference in books, historical societies, or military archives. After years of reasearch and hundreds of hours of interviews, Evelyn M. Monahan and Rosemary Neidel-Greenlee have created a dramatic narrative that at last brings to light the critical role that women played throughout the war. From the North African and Italian Campaigns to the Liberation of France and the Conquest of Germany, U.S. Army nurses rose to the demands of war on the frontlines with grit, humor, and great heroism. A long overdue work of history, And If I Perish is also a powerful tribute to these women and their inspiring legacy.\nA galvanizing narrative of the wartime role played by U.S. Army nurses—from the invasion of North Africa to the bloody Italian campaign to the decisive battles in France and the Rhineland.\nMore than 59,000 nurses volunteered to serve in the U.S. Army Nurse Corps alone: 217 lost their lives (16 by enemy action), and more than 1,600 were decorated for meritorious service and bravery under fire. But their stories have rarely been heard. Now, drawing on never-before-published eyewitness accounts—many heroic, some mundane and comic—Monahan and Neidel-Greenlee take us to the front lines, to the withering fire on the beaches of Anzio and Normandy, and to the field and evacuation hospitals, as well as bombed and burned hospital ships. We witness the nurses—and the doctors with whom they served—coping with the physical and psychological damage done to the soldiers in combat. We see them working—often with only meager supplies and overwhelmed by the sheer number of casualties—to save the lives and limbs of thousands of wounded troops. With them we experience the almost constant packing up and moving on to keep up with advancing troops, foxholes dug under camp beds, endless mud, and treacherous minefields. The vividness and immediacy of their recollections provide us with a powerfully visceral, deeply affecting sense of their experiences—terrifying and triumphant, exhausting and exhilarating.\nA revelatory work that at last gives voice to the nurses who played such an essential role in World War II.\nFrom the Hardcover edition.\nAbout the Author\n\\Evelyn M. Monahan, a retired psychologist, served in the Women\'s Army Corps from 1961 until 1967 as a corpsman and psychiatric technician. She subsequently took her M.Ed. and Ph.D. at Georgia State University and her M.Div. in theology and ethics at Emory University. She worked at the Department of Veterans Affairs from 1980 to 1996.\nRosemary Neidel-Greenlee served in the U.S. Navy Nurse Corps on active duty from 1962 until 1965, and on reserve duty between 1989 and 1991. She has a master\'s degree in nursing from Emory University, and worked at the Veterans Affairs Medical Center in Atlanta from 1981 to 2002.\nMonahan and Neidel-Greenlee are co-authors (with Agnes Jensen Mangerich) of Albanian Escape: The True Story of U.S. Army Nurses Behind Enemy Lines and co-authors of All This Hell: U.S. Nurses Imprisoned by the Japanese.\nWhat Our Readers Are Saying\nHealth and Self-Help » Health and Medicine » History of Medicine', ""The United States Air Force Medical Service (AFMS) consists of the five distinct medical corps of the Air Force and enlisted medical technicians. The AFMS was created in 1949 after the newly independent Air Force’s first Surgeon General, Maj. General Malcolm C. Grow (1887–1960), convinced the United States Army and President Harry S. Truman that the Air Force needed its own medical service.\nIn the summer of 1949, Air Force General Order No. 35 established a medical service with the following officer personnel components: Medical Corps, Dental Corps, Veterinary Corps, Medical Service Corps, Air Force Nurse Corps, and Women's Medical Specialist Corps.\nThe AFMS is led by The Surgeon General of the Air Force, who holds the rank of lieutenant general. The AFMS is found in all three components of the Air Force, including the Active Air Force, the U.S. Air Force Reserve, and the Air National Guard. Headquartered at The Air Staff, Bolling Air Force Base, Washington, D.C., AFMS senior leaders can be found in all of the Major Commands and in the Pentagon.\nBiomedical Sciences CorpsEdit\nEstablished in 1965 from the defunct Women’s Medical Specialist Corps and components of the Medical Service Corps, the Biomedical Sciences Corps (BSC) consists entirely of commissioned officers. This is the most diversified of the Medical Corps, consisting of members in Physical Therapy, Optometry, Podiatry, Physician Assistant, Audiology/Speech pathology, Psychology, Social Worker, Occupational Therapy, Aerospace physiology, Biomedical Scientists, Clinical Dietitian, Bioenvironmental Engineering, Public Health Officers, Entomology, Pharmacy, Medical lab Officers, and Health Physicists. The Chief of the Biomedical Sciences Corps is a brigadier general.\nThe Dental Corps consists of commissioned officers holding the Doctor of Dental Surgery degree or Doctor of Dental Medicine degree or a further, post-graduate degree. The chief of the Dental Corps is a major general.\nThe Medical Corps consists entirely of commissioned Air Force physicians, including holders of the Doctor of Medicine (MD) degree and the Doctor of Osteopathic Medicine (DO) degree. A member of the Medical Corps can also become a Flight Surgeon. The Chief of the Medical Corps is a brigadier general.\nPhysicians can enter service into the Air Force through several different paths. Cadets at the US Air Force Academy can compete for selection to medical school at the Uniformed Services University of the Health Sciences (USUHS) or at any CONUS medical school though HPSP. An academy graduate who attends USUHS will incur a twelve-year (seven for USUHS and five for the Academy) service commitment not counting any training such as residency and fellowship; an academy graduate who attends a civilian medical school will incur a nine-year service commitment not counting any training such as residency and fellowship. Civilian undergraduates can also apply to USUHS, they incur a seven-year service commitment. USUHS student are commissioned officers at the rank of Second Lieutenant (O-1) and are paid as full-time active duty members. All of their school and expenses are paid by the US Air Force. USUHS graduates must complete residency training in a military residency program. Civilian medical school students can apply for the Health Professions Scholarship Program (HPSP). HPSP medical students have their medical school tuition paid by the US Air Force and receive a monthly stipend for living expenses, but they are not on active duty. These graduates can usually attend a civilian or military residency training program and incur a three or four-year service commitment (one year commitment per year of scholarship assistance). Civilian resident physicians can enter Air Force service through the Financial Assistance Program (FAP). FAP physicians receive payment while in residency, but do not receive funds to pay for medical school. Unlike all other programs in the Air Force, they incur a service commitment of based on their length in the program, plus one year (e.g. two years in the program incurs a three-year service commitment). All graduates of residency training enter active duty at the rank of Captain (O-3). Most of the US Air Force Academy graduates pursue a career as an Air Force physician, while the vast majority of HPSP graduates leave the service as soon as their commitment is completed.\nThe Air Force also recruits fully trained and practicing physicians to enter active duty. Their rank at entry is based on their experience.\nMedical Service CorpsEdit\nThe Medical Service Corps (MSC) consists entirely of commissioned officers. Members are required to hold a bachelor's or master’s degree in Healthcare, Management, Economics, Finance, Operations Research, Business Administration or similar degree before receiving a commission, and must complete a specialized Air Force healthcare administration course. This course, conducted at Fort Sam Houston, Texas, provides new MSC officers with the knowledge needed to perform as an entry level department manager in an Air Force Medical Treatment Facility (MTF). The Health Service Administration (HSA) Course is a 5-week course designed to train newly commissioned Medical Service Corps officers for their first duty assignment. The course is accredited for 11 graduate credit hours by the American Council on Education (ACE). MSCs serve as hospital administrators, resource management officers, directors of information systems/technology, managed care and patient administrators, group practice managers, medical logisticians, and medical readiness officers. MSC officers are also expected to become Board certified by one of several national healthcare administration organizations. This is usually done while the officer is in the rank of captain or Major. The Chief of the Medical Service Corps is Brigadier General Charles Potter.\nThe Nurse Corps consists entirely of commissioned officers. New members of the Air Force Nurse Corps are required to hold at minimum a Bachelor of Science in Nursing degree prior to receiving a commission. Members of the Air Force Nurse Corps work in all aspects of Air Force Medicine and can serve as Flight Nurse in aeromedical evacuation missions, nurse practitioner, and nurse anesthetist.The first Chief of the Air Force Nurse Corps was Colonel Verena Marie Zeller (1949–1956). The first two-star general Chief of the Air Force Nurse Corps was Major General Barbara Brannon; she was replaced in 2005 by Maj Gen Melissa Rank. In 2008, it was announced that Colonel Kimberly Siniscalchi would be promoted to the rank of Major General and serve as the Chief of the AF Nurse Corps, thereby bypassing the rank of Brigadier General (1-star).\nAir Force Enlisted Medical personnel perform in over twenty different medical fields including medical administration, mental health, dental care, optometry, physical therapy, aeromedical evacuation, medical logistics, laboratory sciences, surgical care, emergency care, radiology, pharmacy, etc. Enlisted medics are led by a Chief Master Sergeant.\n|Biomedical Science Corps Badge|\n|Dental Corps Badge|\n|Medical Corps Badge|\n|Medical Service Corps Badge|\n|Nurse Corps Badge|\n|Enlisted Medical Badge|\n- 15th Medical Group:\n- 15th Aeromedical-Dental Squadron\n- 15th Medical Operations Squadron\n- 15th Medical Support Squadron\n- AFMS Home Page\n- AFMS online history\n- Virtual Naval Hospital - a digital library of military medicine and humanitarian medicine\n|This page uses Creative Commons Licensed content from Wikipedia (view authors).|""]"	['<urn:uuid:8ba889f2-5f55-4a5e-99c3-34117ea80e83>', '<urn:uuid:ab47f4cc-2bec-47f4-962f-0ca5e9f51074>']	open-ended	with-premise	verbose-and-natural	similar-to-document	multi-aspect	expert	2025-05-01T22:36:12.692263	48	109	2361
247	As someone studying Pacific naval operations, I'm particularly interested in the battle stars awarded to Nassau and Princeton - how did their combat decorations compare during their respective service periods?	The USS Nassau earned five battle stars for World War II service, while the USS Princeton received eight battle stars specifically for Korean War service. Additionally, Princeton received the Navy Unit Commendation for four distinct periods: December 5, 1950 to August 10, 1951, April 15 to October 18, 1952, March 13 to May 15, 1953, and June 11 to July 27, 1953.	"[""Nassau received five battle stars for World War II service.\nThe USS Nassau (CVE-16) (originally AVG-16 then ACV-16) was laid down 27 November 1941 by the Seattle-Tacoma Shipbuilding Corporation of Tacoma, Washington, as M.C. Hull No. 234; launched 4 April 1942; sponsored by Mrs. G. H. Hasselman, Tongue Point, Oregon; acquired by the Navy 1 May, towed to the Puget Sound Navy Yard, Bremerton, Washington, and converted to an escort aircraft carrier; and commissioned 20 August, Captain Austin K. Doyle in command.\nOn 10 October, Nassau arrived at the Naval Air Station, Alameda, California, loaded aircraft, and four days later steamed for Pearl Harbor, thence to Palmyra Island, arriving 30 October. For the next four months, she operated between Palmyra and Nouméa, New Caledonia and Espiritu Santo, New Hebrides.\nNassau was one of thirty-seven Tacoma-built C3 CVE's, of which twenty-six went to the Royal Navy. It was one of the ten Bogue class escort carriers that served in the U.S. Navy. Nassau returned to Pearl Harbor 14 February 1943, embarked personnel and aircraft, and sailed 21 February on a ferry mission to Espiritu Santo.\nPoint of Contact:\nIf you know the contact name for any\nof the CVEs and you would like to\nshare, please send an email to:\nClick here to see our expanded\nWould you like to upload your Nassau photos to our archives?\nShe returned to Pearl Harbor in mid-March and then continued on to Alameda, California. In April, she moved to San Diego and conducted flight training operations, after which she rendezvoused with Task Group 51.1 and steamed for Cold Bay, Alaska with Composite Squadron 21 (VC-21) embarked.\nNassau got underway on a search mission 4 May and conducted flight operations with Task Force 51, providing air cover for the occupation of Attu Island from 11 May through 20 May. She returned to San Diego in late May, arrived at Alameda 8 June and onloaded 45 aircraft destined for Brisbane, Australia. She delivered the aircraft 2 July and returned to San Diego via Nouméa, New Caledonia.\nIn August, she trained off San Diego before ferrying planes to Samoa. Returning to San Diego from Samoa, 19 October, Nassau embarked Marine Fighter Squadron 225 (VMF-225) for passage to Pearl Harbor. Arriving 30 October, she conducted air operations off Pearl Harbor during the early days of November and on 7 November, she embarked Fighter Squadron 7 (VF-1) and steamed for the Gilbert Islands for operations with Task Force 52.\nNassau's mission was to transport VF-1 to Tarawa and to send it ashore as soon as facilities were available. The invasion of Tarawa commenced 20 November but encountered bitter resistance. As a result, VF-1 was assigned combat air patrol and flew bombing and strafing runs from the carrier in support of the assault troops. The squadron flew a total of 106 missions and spent 237 hours of flying time in four days of operations without losing a single plane or pilot.\nNassau returned to Pearl Harbor on 5 December following flight operations. She then sailed to the Marshall Islands with Task Group 51.2 and launched strikes 29 January 1944 against Taroa Field on Maloelap Atoll. The next day, the Task Group centered its operations around Kwajalein, Wotje, and Maloelap Atolls, with Nassau conducting both anti-submarine and combat air patrols.\nNassau returned to Pearl Harbor 3 March, disembarked VC-66, and took on aircraft, cargo, and passengers for ferry to the Marshall Islands. Throughout March, ferry missions were performed between Kwajalein, Majuro, and Pearl Harbor. After repairs and alterations at Mare Island Navy Yard, the carrier sailed with 51 aircraft for Finschhafen, New Guinea 5 May. The next four months she performed ferry missions from San Diego to Pearl Harbor, the Admiralties and the New Hebrides Islands.\nUpon arrival at Seeadler Harbor 1 September, Nassau reported to Commander Task Group 30.8. Thus began her tour of duty with Admiral Halsey's 3rd Fleet, which made unprecedented naval history in the following months. Nassau's mission was to operate out of the Admiralties with other escort carriers to provide replacement aircraft and pilots for the attack carriers of Task Force 38. Steaming in company with the oiler groups, which refueled the ships of the Task Force at sea, Nassau made three cruises into the western Pacific. She returned to the Admiralties with disabled aircraft which were destined for shipment to Pearl Harbor or the United States for reconditioning.\nThe first of these replacement trips was in support of the strikes against Palau; the second in support of operations against the southern and central Philippines. Then Task Force 38 shifted to more northerly targets in the Philippines and Formosa. Nassau reached Manus on 20 October. After offloading old aircraft and taking on new ones, she departed on her last replacement trip. Steaming to Ulithi Atoll in the Caroline Islands, she joined up with Task Groups 38.1 and 38.3 on 28 October and transferred 70 aircraft and 43 pilots to the attack carriers.\nTask Unit 12.6.1, composed of Nassau, Tennessee and four other ships steamed for Pearl Harbor 5 November, arriving 16 November. Two days later, Nassau was dispatched to San Diego. Among her passengers were 382 survivors of Princeton, which was sunk in the Battle of Leyte Gulf, 24 October 1944. Another ferry mission to Pearl Harbor followed in mid-November, with three more runs to Guam in December, January 1945, and February. Nassau returned to Alameda, California, 23 March and through the remainder of the war, performed transport and ferry missions between Alameda, Pearl Harbor, Guam, Manus, Samar and Saipan.\nNassau departed Alameda 13 May 1946 for Tacoma, Washington. On 28 October, she decommissioned and entered the Pacific Reserve Fleet. Designated for modification for aircraft transportation purposes, her classification was changed to CVHE-16, 12 June 1955. Shortly thereafter she transferred to the Bremerton Reserve Group, and was struck from the Navy Register, 1 March 1959. In June 1961, she was towed to Japan for scrapping.\nTaken from Wikipedia"", 'USS Princeton (CV-37)\nUSS Princeton underway\n|Career (United States)|\n|Namesake:||Battle of Princeton, 1777|\n|Operator:||United States Navy|\n|Builder:||Philadelphia Naval Shipyard|\n|Laid down:||14 September 1943|\n|Launched:||8 July 1945|\n|Commissioned:||18 November 1945|\n|Decommissioned:||21 June 1949|\n|Recommissioned:||28 August 1950|\n|Decommissioned:||30 January 1970|\n|Renamed:||PCU Valley Forge to PCU Princeton|\n|Reclassified:||CVA-37, CVS-37 and LPH-5|\n|Fate:||Sold for scrap in 1971|\n|Class and type:||Essex-class aircraft carrier|\n27,100 tons standard\n888 feet (271 m) overall\n93 feet (28 m) waterline\n28 feet 7 inches (8.71 m) light\n8 × boilers\n4 × Westinghouse geared steam turbines\n4 × shafts\n150,000 shp (110 MW)\n|Speed:||33 knots (61 km/h)|\n|Complement:||3448 officers and enlisted|\n4 × twin 5 inch (127 mm)/38 caliber guns\n4 × single 5 inch (127 mm)/38 caliber guns\n8 × quadruple Bofors 40 mm guns\n46 × single Oerlikon 20 mm cannons\n4 inch (100 mm) belt\n2.5 inch (60 mm) hangar deck\n1.5 inch (40 mm) protectice decks\n1.5 inch (40 mm) conning tower\n|Aircraft carried:||As built:\nUSS Princeton (CV/CVA/CVS-37, LPH-5) was one of 24 Essex-class aircraft carriers built during and shortly after World War II for the United States Navy. The ship was the fifth US Navy ship to bear the name, and was named for the Revolutionary War Battle of Princeton. Princeton was commissioned in November 1945, too late to serve in World War II, but saw extensive service in the Korean War, in which she earned eight battle stars, and the Vietnam War. She was reclassified in the early 1950s as an attack carrier (CVA), then as an Antisubmarine Aircraft Carrier (CVS), and finally as an amphibious assault ship (LPH), carrying helicopters and marines. One of her last missions was to serve as the prime recovery ship for the Apollo 10 space mission.\nAlthough she was extensively modified internally as part of her conversion to an LPH, external modifications were minor, so throughout her career Princeton retained the classic appearance of a World War II Essex-class ship. She was decommissioned in 1970, and sold for scrap in 1971.\nConstruction and commissioning\nThe ship was laid down as Valley Forge — one of the ""long-hull"" Essex-class — on 14 September 1943 at the Philadelphia Navy Yard. She was renamed Princeton on 21 November 1944 to commemorate the light carrier USS Princeton (CVL-23), which was lost at the Battle of Leyte Gulf on 24 October 1944. The new Princeton was launched on 8 July 1945, sponsored by Mrs. Harold Dodds, and commissioned on 18 November 1945, Captain John M. Hoskins in command.\nAttack carrier (1945–1954)\nThen transferred to the Pacific Fleet, she arrived at San Diego, departing again on 3 July 1946 to carry the body of Philippine President Manuel L. Quezon back to Manila for burial. From Manila, Princeton joined the 7th Fleet in the Marianas, becoming flagship of Task Force 77 (TF 77). In September and October 1946, she operated in Japanese and Chinese waters, then returned to the Mariana Islands where she remained until February 1947. In 1947 she had Carrier Air Group 13 on board, and in October 1948 evacuated dependents from Tsingtao, returned to San Diego Dec 1948 and unloaded CAG13 Maneuvers in Hawaiian waters preceded her return to San Diego until 15 March. She cruised the West Coast, Hawaiian waters, and the Western Pacific (1 October – 23 December) in 1948. She then prepared for inactivation, and on 20 June decommissioned and joined other capital ships in the Pacific Reserve Fleet.\nReactivated with the outbreak of hostilities in Korea 15 months later, Princeton recommissioned on 28 August 1950. Intensive training refreshed her Reservist crew, and on 5 December she joined TF 77 off the Korean coast, her planes and pilots (Air Group 19) making possible the reinstitution of jet combat air patrols over the battle zone. She launched 248 sorties against targets in the Hagaru area to announce her arrival, and for the next six days continued the pace to support Marines fighting their way down the long, cold road from the Chosin Reservoir to Hungnam. By the 11th, all units had reached the staging area on the coast. Princeton \'s planes, with other Navy, Marine, and Air Force squadrons, then covered the evacuation from Hungnam through its completion on the 24th.\nInterdiction missions followed, and by 4 April Princeton \'s planes had rendered 54 rail and 37 highway bridges inoperable and damaged 44 more. In May, they flew against the railroad bridges connecting Pyongyang with Sunchon, Sinanju, Kachon, and the trans-peninsula line. Next, they combined close air support with raids on power sources in the Hwachon Reservoir area and, with the stabilization of the front there, resumed interdiction. For much of the summer they pounded supply arteries, concentrating on highways, and in August Princeton got underway for the U.S., arriving at San Diego on the 21st.\nOn 30 April 1952, Princeton rejoined TF 77 in the combat zone. For 138 days, her planes flew against the enemy. They sank small craft to prevent the recapture of offshore islands; blasted concentrations of supplies, facilities, and equipment behind enemy lines, participated in air-gun strikes on coastal cities, pounded the enemy\'s hydroelectric complex at Suiho on the Yalu River to turn off power on both sides of that river, destroyed gun positions and supply areas in Pyongyang; and closed mineral processing plants and munitions factories at Sindok, Musan, Aoji, and Najin.\nReclassified CVA-37 (1 October 1952), Princeton returned to California on 3 November for a two-month respite from the western Pacific. In February 1953, she was back off the Korean coast and until the end of the conflict launched planes for close air support, ""Cherokee"" strikes against supply, artillery, and troop concentrations in enemy territory, and against road traffic. She remained in the area after the truce on 27 July, and on 7 September got underway for San Diego.\nAnti-submarine carrier (1954–1959)\nIn January 1954, Princeton was reclassified CVS-37 and, after conversion at Bremerton, Washington, took up antisubmarine/ Hunter-Killer (HUK) training operations in the eastern Pacific. For the next five years she alternated HUK exercises off the West Coast with similar operations in the western Pacific and, in late 1957-early 1958, in the Indian Ocean–Persian Gulf area.\nAmphibious assault carrier (1959–1970)\nReclassified again, 2 March 1959, she emerged from conversion as an amphibious assault carrier, LPH-5. Capable of transporting a battalion landing team and carrying helicopters in place of planes, Princeton \'s mission became that of vertical envelopment—the landing of Marines behind enemy beach fortifications and providing logistics and medical support as they attack from the rear to seize critical points, cut enemy supplies, sever communications, and link up with assault forces landed on the beaches. Since this was a Marine Corps mission, Marines made up a major portion of the ship\'s company in the Air, Operations, and Supply Departments.\nFrom May 1959 – January 1960, Princeton trained with Marine units from Camp Pendleton, then deployed to WestPac to train in Okinawan waters. For the next three years, she followed a similar schedule, gaining experience in her primary mission. Interruptions came in October 1961 when she rescued 74 survivors of two merchantmen Pioneer Muse and Sheik grounded on Kita Daito Shima and in April 1962 when she delivered Marine Corps advisors and helicopters to Sóc Trăng in the Mekong Delta area of the Republic of Vietnam (South Vietnam). From September–November 1962, Princeton served as flagship of Joint Task Force 8 during the nuclear weapons test series, Operation Dominic.\nIn October 1964, Princeton exchanged WestPac training for the real thing as she returned to Vietnam and joined the Pacific Fleet\'s Ready Group in operations against North Vietnamese and Viet Cong forces. Combat operations, interrupted in November for flood relief work, continued into the new year, 1965, and culminated in May off Chu Lai as she carried out her primary mission, vertical envelopment, for the first time in combat.\nReturning to her homeport, Long Beach, California, after that operation, she transported Marine Aircraft Group 36 to Vietnam in August, and in February 1966 got underway for another tour in the combat zone. Relieving Okinawa (LPH-3) as flagship for the Amphibious Ready Group, she engaged the enemy in operations ""Jackstay"", 26 March – 6 April, to clear the Rung Sat Special Zone of Viet Cong guerrillas, and ""Osage"", 27 April – 4 May, to protect Vietnamese in the Phu Loc area from Viet Cong ""harassment.""\nSearch and destroy missions against Viet Cong and North Vietnamese Army units followed as Princeton provided transportation, medical evacuation, logistics and communication support for the amphibious operation ""Deckhouse I"", 18 – 27 June, in the Song Cau district and the Song Cai river valley, then supported 1st Air Cavalry and 101st Airborne units engaged in ""Nathan Hale"" to the south of the ""Deckhouse I"" area. ""Deckhouse II"" and support for ""Hastings"" followed as Navy, Marine, and Army units again combined, this time to impede enemy infiltration from the DMZ.\nAfter ""Hastings"", Princeton sailed for home, arriving on 2 September. She deployed again to Vietnam from 30 January–19 June 1967, and again ranged along that long embattled, highly indented coast. In March, she assisted in countering an enemy threat to the Marine artillery base at Gio Linh and evacuated wounded from Con Thien mountain. In April, she participated in ""Beacon Star"", in the Khe Sanh area, and supported search and destroy operations in conjunction with ""Shawnee"". In May, her helicopters lifted Marines to the DMZ to block enemy forces withdrawing across the Bến Hải River.\nA much-needed overhaul followed Princeton \'s return to the west coast, and in May 1968 she again sailed west to Vietnam. There, as flagship for Amphibious Ready Group Alpha, she provided amphibious assault carrier services for operations ""Fortress Attack"" III and IV, ""Proud Hunter"", ""Swift Pursuit"", and ""Eager Hunter"". In December, she returned to the United States and in April 1969 she was designated the prime recovery ship for Apollo 10, the lunar mission which paved the way for Apollo 11 and the first manned landing on the Moon. Apollo 10 was recovered in the South Pacific on 26 May.\nOn 30 January 1970, Princeton was decommissioned and struck from the Naval Vessel Register, and sold for scrapping in May 1971.\nPrinceton received the Navy Unit Commendation for four periods: 5 December 1950 to 10 August 1951, 15 April to 18 October 1952, 13 March to 15 May 1953, and 11 June to 27 July 1953.\nThe flag of USS Princeton is now in Princeton University in the University Chapel.\nThe USS Princeton was used during the filming of the 1952 Monogram Pictures feature Flat Top\n|Wikimedia Commons has media related to USS Princeton (CV-37).|\n- This article incorporates text from the public domain Dictionary of American Naval Fighting Ships. The entry can be found here.']"	['<urn:uuid:b2a09c42-9248-4ddb-8b49-519d0e36c48e>', '<urn:uuid:ff3f8323-89d1-421c-ac55-34b652d07d4d>']	factoid	with-premise	verbose-and-natural	similar-to-document	comparison	expert	2025-05-01T22:36:12.692263	30	62	2782
248	What are some of the key things that theaters should consider when making their shows more welcoming for people with special needs?	The most important aspects include providing flexible options in three main areas: time/timing (including opportunities for additional preparation), forms of communication (offering written, verbal, and visual ways to receive information), and environments (ensuring wheelchair accessible spaces and clearly explained social expectations). It's also crucial to plan ahead for any accommodations needed, whether they involve monetary costs or reorganization of staff time. However, theaters shouldn't wait for everything to be perfect before taking action - the most successful inclusive companies are those willing to try new approaches, reflect on what works and what doesn't, stay connected to the disability community, and revise their practices.	"[""Accommodations for Professional Performers with Disabilities\nThis article summarizes a breakout session at the 2017 Theatre Communications Group Annual Conference of the same name in Portland, Oregon on June 9, 2017. During the session, I facilitated a conversation with performers Regan Linton and Monique Holt. Artists who contributed via an online survey were Claudia Alick, Megan Bartlett, Christine Bruno, Cheryl Green, Anita Hollander, Eliza Jensen, Brianca Knight, Michael Maag, Anne-Marie Plass, Mickey Rowe, and Ali Stroker.\nThe session was intentionally designed with practicality in mind, with the assumption that the attending theatre professionals find the inclusion of artists with disabilities socially and aesthetically valuable. You can find a video of the session here.\nThe most 'successful' inclusive companies are willing to try new things, reflect on what worked and—more importantly—what didn’t, stay connected to the disability community, and revise.\n1. Words Are Important (and should propel the work forward)\nIn my work as an access and inclusion consultant, I have yet to meet a client who wants to be intentionally exclusive to the disability community. Nevertheless, several of my clients feel nervous about even starting a conversation about accessibility because they do not want to sound offensive.\nThe default for uncomfortable silence can often be exclusion. There is a long history of language that has been used to describe the disability community. This history is important in understanding the ways in which society has understood and understands disability. But at the risk of writing a whole other article on the specifics of language, two words that embrace best practices in customer service, social justice, and human rights are accessible and accommodation.\nUsing the word accessible re-frames the conversation from an individual understanding of disability to an environmental and social one—your staff is looking not at individual patrons or artists and their personal history, impairments, etc, but at the space around them. In the same way, the tools that make an environment accessible are reasonable accommodations. These two words have legal weight. You and your staff are not simply picking and choosing to address preferences of artists, patrons or co-workers, you are making reasonable accommodations that create a legal, accessible work environment.\nOnce your staff feels empowered to make a space accessible, start with a concrete environmental assessment: What is the physical environment like? Once you’ve examined physical space, how are you working to make the communication environment accessible? The information environment? The social environment?\n2. Acknowledge both expertise and ignorance, and then move the work forward\nThe best advisors for how to make a production experience accessible are the individuals who will be participating in said production. The most effective way to know whether or not a specific accommodation is going to work is to ask the individual who will utilize that accommodation.\nIn other words, you and your staff are the experts on your theatre environment, and disabled artists, patrons, and staff members are experts on their own needs and accommodations. Most likely, you will not know the ins and outs of an artist’s personal experience, and that’s OK. Similarly, an artist might not know the details of how your space, rehearsal calendar, or staff etiquette works and that’s OK, too. Commit to learning together!\n[Please note: Best practices in access and inclusion strongly encourages direct communication with the disability community. If your theatre is looking to make your place of business more accessible for patrons and/or employees, consider creating an access committee, peopled by self-identified advocates from your local disability community.]\n3. Practice Radical Hospitality: Be Flexible (in other words, give options)\nWhether you are re-vamping your audition notices, your auditions and callbacks, your rehearsals and performances, or you are simply updating the access section of your organization’s website, embrace the idea of radical hospitality and radical communication. Patrons, artists, employees, and guests alike benefit from knowing what to expect in a welcoming, relaxing, come-as-you-are approach.\nIn the spring of 2017, I surveyed several professional performers with disabilities about the accommodations they request most often. If I had to summarize the accommodations that are most often requested, it comes down to:\n- Flexible time/timing, including opportunities for additional preparation, and knowing what will happen next.\n- Flexible forms of communication, including options for written, verbal, and visual ways to receive information.\n- Flexible environments, including wheelchair accessible spaces, clearly articulated social expectations, and intuitive and welcoming intellectual spaces.\nFinally, as any good host would do, take care not to over-do it. For better or worse, people in the disability community are used to all kinds of un-invited “hospitality,” so be welcoming, reach out, present multiple options to artists, and be willing and ready to take “no thank you” for an answer.\n4A. Plan Ahead\nIn order to make environment more accessible, there are some real, tangible costs—monetary costs, as well as uses of time and resources. So, plan ahead.\nIf you want to produce a play that has three Deaf characters, start allocating money for professional ASL interpreters several months in advance. If you want to stage an inclusive musical in a “historical” venue that is inaccessible to performers who use wheelchairs, start researching retro-fits and accessible ramps, and make friends with an architect or designer who can help. At the same time, many accommodations can be accomplished with very little money, but rather with a re-organization of staff time and human resources:\n- How might you re-organize to dedicate one or more staff members to accessibility throughout the production process? (In my experience, adding an “access coordinator” to the stage management team is a natural fit)\n- How might your production staff make time for performers with disabilities to orient themselves in your space prior to auditions, callbacks, or rehearsals?\n- How might a few adjustments to communication protocol and rehearsal paperwork help the stage management team anticipate any accommodations that might be needed in tech or performances?\n- How might your casting department make it clear in audition notices that you are truly interested in hiring performers with disabilities? I get this question a lot from my clients, so here’s my latest draft of sample language:\n- “[Name of theatre] encourages performers with disabilities to audition and will provide reasonable accommodations to individuals who request them in advance. Accommodation requests may include: ASL Interpretation, Braille or Large Print Materials, Physical Access, and Social Narratives. To request an accommodation please call _______________ or email ______________.”\nWith advanced planning in mind, here are some tips from Actors Theatre of Louisville’s Company Manager, Dot King, in preparing to host a performer with a disability:\n- Preparation is key! Most accommodations are very reasonable when arranged in advance, but very tricky if needed on the fly.\n- Arm yourself with the language to make you a confident access provider (see above re: accessible and accommodation)\n- Communicate early and often!\n- Specificity is your friend! If you reach out to an artist asking about general “accommodations” you might get a general yes or no back. Bravely take the lead and offer details, for example:\n- What bed height is most comfortable for you?\n- Do you prefer a stacked refrigerator/freezer, or side-by-side?\n- Do you prefer a traditional stove/stovetop, or is there a more accessible option for you?\n- Utilize other resources: In most cities, local hotels can be a great resource for best practices in accessibility. If you are faced with a request that you are not familiar with or aren’t sure how to provide an accommodation, a colleague at a hotel may be able to help!\n4B. Be in the Moment\nThose of us in the theatre know that even the best-laid plans require an element of improvisation. This is where theatre people have an advantage. We know how to adapt in the moment. We know how to make things happen with little time and no resources, and this same skill is key in accessibility.\nEmbrace the inherent creativity in accessibility! The best producers, production managers, and stage managers I know secretly (and not so secretly) love to problem-solve creatively. Know that many disabled artists are also seasoned problem-solvers, so as things change in the moment, stay connected with each other, keep communicating, and move forward together.\n5. Imperfect Implementation: Aim for Possible, Not Perfect\nDon’t wait until your entire building is physically accessible and your entire staff is thoroughly trained on exactly what to say and do. If you’ve thoughtfully explored the talking points above, but have not taken any action steps, you might be feeling both excited and nervous—just go for it!\nBest practices in access and inclusion do not indicate a super-power bestowed upon companies who regularly host artists with disabilities. Rather, the most “successful” inclusive companies are willing to try new things, reflect on what worked and—more importantly—what didn’t, stay connected to the disability community, and revise.\nIf you are doing it right, your access experience will be a beautiful, messy paradox. Welcome. You have arrived.\n[Post-Script: If you’re thinking, “Talleri, this article is great but you promised me practical, nuts-and-bolts accommodations for auditions, rehearsals, and performances,” click here for a comprehensive list of accommodations implemented by Phamaly Theatre in Denver, CO.]""]"	['<urn:uuid:f7b79929-7afc-4e56-a5c1-a0a73e162f94>']	open-ended	direct	verbose-and-natural	distant-from-document	single-doc	novice	2025-05-01T22:36:12.692263	22	103	1528
249	glacier express switzerland bridges vs trift bridge	The Glacier Express route in Switzerland crosses 291 bridges during its journey, while the Trift Lake area features a single spectacular suspension footbridge (Triftbrucke) that was built in 2004 to make the hiking trail accessible again after the glacier melted.	"['Culture & Living\nFrom the Island Express, which takes you to the southernmost point of India, to the Jacobite Steam Train that leads you right into Harry Potter universe, these are some of the most beautiful train journeys you can take\nThere’s something so very special about train journeys—they’re reminiscent of simpler times, and the perfect companion for unhurried holidays. Train rides are for reading, playing board games with the entire family and, most importantly, stumbling upon small junctions and quaint towns that you’d never even heard of before. The more romantic way to travel, trains allow its passengers to watch the world go by and really savour the journey.\nIf you’d like to relive the joy that train rides bring, we’ve curated a list of 10 stellar experiences you can hop on board for. From passing by the Grand Canyon to travelling across Russia from east to west, these are the some of the most scenic train journeys you can take.\nBuilt between 1879 and 1881, the Darjeeling Himalayan Railway (or the Toy Train, as it is known) is a two-feet gauge railway running between New Jalpaiguri and Darjeeling in West Bengal. Passing through snow-capped mountains, verdant forest, tea plantations and villages, it’s one of the most scenic experiences you can undertake. The Darjeeling Himalayan Railway was first declared a UNESCO World Heritage Site in 1999. Today, the accreditation is also extended to include the Nilgiri Mountain Railway and the Kalka Shimla Railway—the three are called Mountain Railways of India together, and are a designated UNESCO World Heritage Site.\nWith a round trip that covers 210km, the Grand Canyon Railway offers breathtaking views of the iconic national park in the US. Opened in 1901, the restored rail cars feature different classes of service. The train departs from Williams, Arizona, and passes through a wide variety of landscapes—including Ponderosa and Pinion pine forests, the prairie, and the highest elevation in Arizona, San Francisco Peaks—before reaching the Grand Canyon National Park.\nMake sure to book a window seat on the Glacier Express for unparalleled views. The route goes through three cantons of Switzerland—Valais, Uri and Graubünde, starting from St Moritz and coming to an end in Zermatt. The entire journey takes eight hours to complete, crosses 291 bridges and 91 tunnels, and reaches a highest elevation of 2,033m .\nEver thought about witnessing the scenery of southern British Columbia from the comfort of a luxurious carriage? Thanks to the Rocky Mountaineer’s First Passage to the West, it’s possible. The route starts at Vancouver and concludes at Banff, and provides panoramic views at every interval, including the Fraser Canyon’s Hell’s Gate and the Canadian Rockies.\nBeginning at Christchurch, the TranzAlpine takes you through the fertile fields of the Canterbury Plains before going up the mountains to pass by Staircase Viaduct, and crossing the beautiful snow-capped mountains of Arthur’s Pass National Park. The journey continues through sub-tropical rainforests with the last stop being the historic former gold-mining town, Greymouth.\nOne of the world’s longest train journeys, the Trans-Siberian is an eight-day journey covering almost 9,290km. It begins at the westward terminus in Moscow and takes you across the country all the way to Vladivostok in the east. On this journey, you will be going travelling through Ural Mountains, the Siberian forest and the magnificent Lake Baikal, the world’s oldest freshwater lake that was formed 25 million years ago.\nSouth Africa is known for breathtaking landscapes, so of course we had to add a train journey through the country to this list. The Rovos Rail’s Namibia Safari departs from Pretoria and goes through Kimberly (home to the Big Hole, one of the world’s largest hand-dug mines), crossing the Northern Cape, the Fish River Canyon and Namibia, before coming to a stop at the coastal city of Swakopmund.\nThough some of you might want to climb Machu Picchu, the Belmond Hiram Bingham is great for those who want to visit the UNESCO World Heritage Site without undergoing too much physical activity. The journey begins in the ancient capital city of Cusco and passes through the Sacred Valley of the Incas, as well as a tiny village called Ollantaytambo. The final destination is obviously the cherry on the cake—Machu Picchu, the ancient Inca citadel set high in the Andes Mountains.\nDescribed as one of the greatest railway journeys in the world, the Jacobite Steam Train’s route from Edinburgh to the Highlands at Fort William passes the deepest seawater loch in Europe, Loch Nevis, the highest mountain in Britain, Ben Nevis, and the deepest freshwater body in the British Isles, Loch Morar. On the bucket list of true Harry Potter fans, the train journey retraces the 135km journey that the boy wizard takes to reach Hogwarts at the start of every school year. While you may not actually make it in time for Dumbledore’s welcome address, you’re still guaranteed a pretty magical train ride.\nZipping past beautiful villages, plantations and lush countryside, The Island Express takes you through the picturesque landscape of south India over a 19-hour journey. Train No 16526 goes from Bengaluru to Kanyakumari (the southernmost point of India), and offers stunning views of the Pamban Bridge, which held the title of India’s longest bridge until the Bandra-Worli Sea Link in Mumbai became operational. Meanwhile, Train 16525, which runs in the reverse direction, journeys through Kerala, taking you through Kottayam, Trivandrum and Palakkad.', ""Advertise Lake Vacation Rentals\nTrift Lake and Rhone Glacier Lake are two of newest attractions in the Bern and Valais regions of the Swiss Alps. These two recently-formed glacier lakes are the result of water from melting glaciers trapped by the surrounding terrain. Only about 10 miles apart in air-miles but 30 miles by road, the two lakes have formed in recent years as the Trift and Rhone glaciers melt. Trift Lake, also known as Triftsee, dates back to 2002 when the peak of the glacial mass burst into many pieces, having shown signs of cracks for over 10 years. The resulting water was trapped in a hollow instead of flowing downhill.\nA spectacular suspension footbridge across the lake (Triftbrucke) makes Trift See a popular spot for hikers. The former hiking trail to the Trift Hut of the Swiss Alpine Club was no longer passable across the melting glacier. The pedestrian bridge, built in 2004, made the popular trail available again, but with an additional spectacular view of the lake and the glacial valley from the bridge high above. The trail itself is reached by the Triftbahn cable car, offering even more aerial views of the unusual scenery. A bus station is conveniently located near the cable car access, making the beautiful views available to those who wouldn't ordinarily take the long hike across the glacier to see it. There are no measurements of water depth or even size of the lake at this point, although it is assumed to be quite deep. The lake is still growing and its size will no doubt change in coming years.\nTrift Lake adds to the number of tourism attractions in the central Bern region. Bus service can be accessed from Meiringen, about 10 miles to the west. Meiringen is a popular destination for holiday visitors, with nearby attractions such as the Sherlock Holmes Museum, excellent ski resorts, two of Switzerland's most popular boating lakes, plus a variety of glaciers, waterfalls and scenic overlooks. South of Meiringen, the small Rosenlaui Glacier gives rise to the Reichenbach Brook, which thunders below a catwalk footpath secured above a narrow ravine with steep rock walls up to 250 feet high. The brook becomes a seven-tiered waterfall known worldwide from a scenario in one of Sir Arthur Conan Doyle's Sherlock Holmes novels. A cable car travels to the observation platform. An excellent public transit system gets visitors nearly anywhere they want to go by train or bus.\nMeiringen also makes a great base for visiting Rhone Glacier Lake just over the border in the Valais region, but visitors will also be well-served finding lodgings around the old village of Gletsch or Furka Pass. In years past, the Rhone Glacier was within sight of the hotel in the town. Now, it has receded more than a mile up the valley but still accessible by a short hike. Ample car parking is available near Rhone Glacier Lake. The lake itself was formed in 2005 when rock, freed from its stabilizing coating of ice, created landslides down the side of Eiger Mountain. The landslides trapped the melt water, creating Rhone Glacier Lake. The Rhone Glacier itself is still popular for hiking. The newly-formed lake has changed the topography and created some concerns as well. Thawing caused the lake to overflow in 2008, and there are concerns that a major overflow could flood hotels, railroad tracks, campsites and roads.\nBesides hiking, skiing and glacier viewing in the area, the Rhone Glacier Ice Grotto is carved out each year to give visitors a chance to walk inside a living glacier. Over the course of the tourism season, the 300 foot-long cavern loses as much as 100 feet in length to ice and must be re-carved each year. Other popular activities in the area include a steam excursion train. Originally beginning operation as a necessary mode of transportation across the Furka Pass, the Furka Mountain Route was scheduled to close in the 1980s, but a large voluntary organization keeps the scenic route in operation. The original engine and carriages provide a historic ride from June to October through long tunnels and over folding bridges with a stop at Furka Station at the base of Rhone Glacier.\nThe entire area surrounding Trift Lake and Rhone Glacier Lake is well-supplied with holiday cottages, ski cabins, farm stays, camp grounds and small and quaint hotels, often more like inns or bed-and-breakfasts. The glaciers are awe-inspiring, the surrounding Alps majestic, and the well-established tourism facilities well-organized and convenient. Based on computer modeling of the land contours underneath the glaciers, scientists believe that Aletsch, Gorner, Otemma, Corbassiere, Gauli and Plaine Morte glaciers could eventually produce some of the world's largest lakes. While some mourn the melting glaciers, others see possibilities of increased hydroelectric potential from the newly-forming lakes. As the Rhone glacier melt water has been the source of both Lake Geneva and the Rhone River for thousands of years, such water potential isn't to be overlooked in planning for the future.\nOther scientists are concerned over the possibility of a glacial dam giving way and releasing massive amounts of water, drowning everything in its path. Such catastrophes have occurred among glacier-formed lakes in Nepal. Therefore, scientists are carefully monitoring the stability of the structures holding back the water and have already built a water tunnel from Rhone Glacial Lake to release water should a breach appear imminent. In more remote nations, the United Nations has a team of scientists monitoring glacial-melt lakes to prevent loss of life in such instances.\nAlthough many attribute the new lakes to recent climate change, the glaciers here have been melting and receding for at least 200 years. The question is whether the melting is occurring faster than in the past. Science has little factual basis for past ice thickness over periods of hundreds of years. The two lakes are simply the latest evidence of how climate changes the landscape. A mid-20th century scientist attempted to explain glacial changes based on astronomical cycles in what is called the Milankovitch Cycle. Many of the world's largest lakes and a large number of its most scenic landscapes have been created by glacial lakes, some of which burst forth with a resulting wall of water hundreds of feet high, destroying everything in its path and carving a new landscape in a matter of days. Careful monitoring and modern technology can now prevent the worst damage. Meanwhile, the opportunity to enjoy these new scenic lakes isn't to be missed. Put Trift Lake and Rhone Glacial Lake on your bucket list to be seen at your earliest opportunity.\n*No statistics are available for these very new lakes.\nCopyright © 2007-2017 Lakelubbers LLC. All Rights Reserved.\nPlease LINK to our homepage or to\nthis Trift Lake and Rhone Glacier Lake page.\nTrift Lake and Rhone Glacier Lake""]"	['<urn:uuid:86285e84-3729-45dd-9ac2-a3e5017dad99>', '<urn:uuid:e6f64e46-e7f1-424a-96eb-4300e367ceba>']	factoid	with-premise	short-search-query	similar-to-document	comparison	novice	2025-05-01T22:36:12.692263	7	40	2037
253	I'm replicating old paint colors. Why do standards shift?	Paint color standards, particularly color chips on color cards, are not absolute and change over time. These changes occur due to exposure to heat, light, and simply the passage of time. Different pigments change at different rates - some get lighter, some darker, and when multiple pigments are present, the hue might change since different pigments change at different rates. This means that even if you match a color perfectly using a standard, remaking the same formula a year later may not match because the chip itself may have changed.	['Color matching is not always easy. There are many factors that affect color beginning with the color standard. Color chips used on color cards are not absolute color standards. These chips are not made from the same paint you use to tint colors. Rather, the paint chips are made from lacquers and pigments that are not always the same as the colorants used in tinting paint bases. The chips do not remain constant. Over time, they change color. If exposed to heat, they change color. If exposed to light they change color. Time, heat and light cause chips to change. Some pigments are more prone to change and some are fairly stable, so colors don’t change uniformly. Some get lighter and some get darker. If more than one pigment is present, the hue might also change, since the different pigments change at different rates. Many colors change very little.\nOf course, paint also changes color as it ages. Everyone has seen how colors change outdoors. Even indoors, paint on a wall will change color over time. In fact, all colored objects change color over time. Drapes, furniture, automobiles, etc. are all subject to change caused by UV lighting, aging, exposure to household chemicals, smoke, etc. Some coatings, such as oil based finishes containing linseed oil change color in total darkness!\nIf you make a color using a standard and it matches a color on a chip very closely, remaking the same formula a year later may not match the chip because the chip may have changed. If you have ever compared a new color with an old one, you may think the manufacturer has changed the color standards. In fact, the manufacturer intends the colors to be the same, but the color chips have drifted and look different.\nMetamerism complicares the color-matchers work even more. Matamerism is when a color looks different in different kinds of light. A color may look redder and more yellow under a tungsten light, but look bluer under daylight. This really becomes apparent if one is comparing the color of two samples and one of the samples is metameric and the other is not.\nThey might look very similar in one light source and look like night and day under a different light source. Metamerism is caused by using a combination of different pigments to achieve a color. If only one color pigment is used, metamerism usually doesn’t occur. Sometimes color card manufacturers make paint chips that are metameric. When this happens, it is especially important to check the color under the type of light that will be in use.\nAnother factor that affects paint color substantially is gloss and sheen. If two samples don’t have the same gloss, the color may appear to be different. Gloss fools the eye into seeing a different color. If you are trying to match a glossy sample versus a flat one, you need to hold the panels at such an angle so as the gloss appears the same.\nB & P Painting Company always applies a sample brushout of all your finish paint drawn from existing formulas, computer spectrophotometer color matches, sample jars or color card selections. All paint colors are approved for coverage and appearance by you prior to the start of finish painting.']	['<urn:uuid:64fbf7a6-83fc-4d75-96db-49e6b6ab7ccb>']	open-ended	with-premise	concise-and-natural	distant-from-document	single-doc	expert	2025-05-01T23:21:14.341336	9	90	547
256	How long could the powered hip exoskeleton run between charges?	The ATOUN MODEL Y had an operating time of about 4 hours.	['The Japanese pioneer of wearable robotics and exoskeleton technology, ATOUN Inc, is closing its doors. The company will officially dissolve at the end of April 2022. The liquidation is scheduled to be completed by the end of July 2022. The dissolution of ATOUN is a blow to the entire exoskeleton industry, and the company and its often quirky prototypes (like the wheeled exo Koma 1.5) will be missed.\n“We would like to express our sincere gratitude to everyone who took care of us.” reads on the ATOUN website (using Google Translate). “Since its founding in 2003, ATOUN Inc. has been developing its business entered on wearable robotics, but due to various circumstances, it will be dissolved as of the end of April 2022… We would like to express our sincere gratitude to all of you for your warm support and cooperation over the years.”\nIn addition to its multiple prototypes and projects, ATOUN had two powered back support exoskeletons on the market: Model Y (AWN-12) and Model +kote (AWN-32). The second model is the same exoskeleton but with integrated cables to assist in holding boxes.\nFor those who have purchased either ATOUN exoskeleton products, Advance Co. Ltd. will take over the after-sales services. The support site and Frequently Asked Questions about the products have already been transferred. Link to Advance Co.: https://atoun.force.com/s/\nPreviously in the news:\nIn 2020, the Model Y was a winning entry in the 59th Business Advertising Awards sponsored by Fuji Sankei Business. The image (above) artfully combines the mundane with the modern. Traditional farming by hand is performed using top-of-the-line wearable robots. (Robots to Wear by Panasonic Wins The 59th Business Advertising Awards).\nIn 2017, ATOUN was also a co-creator of the World’s First Performance Standard for Hip Type Wearable Robots: JIS 8456-1 together with Cyberdyne and Innophys.\nPanasonic – ActiveLink\nAccording to its LinkedIn page, ATOUN is composed of ‘A’ (symbolizing ‘human’), ‘TO’ (meaning ‘and’ in Japanese), and ‘UN’ (symbolizing ‘robot’). This name embodies the company’s philosophy based on the concept of “aun” — Harmony on a mental and physical level between two parties, in our case, humans, and robots. But some might associate ATOUN and its projects with ActiveLink (see Panasonic, ActiveLink – Company Profile 2015).\nAbout the ATOUN Model Y (discontinued):\nAWN-12, also known as ATOUN MODEL Y is an occupational powered hip exoskeleton. This wearable robot is designed to assist workers with lifting heavy objects by providing torque at the hips and reducing the stress on the spine. The AWN-12 builds on the knowledge gained from previous models, especially the AWN-03B (ATOUN MODEL A) which has been discontinued since June 2019. It is the follow-up wearable robot to the AWN-03 by ActiveLink which has been developing exoskeletons for the workplace for more than a decade. The primary goal for this occupational wearable is to reduce the burden on the body when lifting and lowering heavy or large objects that do not lend themselves to proper ergonomic lift guidelines. ATOUN was continuously building a case for the use and benefit of its exoskeleton at multiple sites in the fields of logistics, manufacturing, construction, and civil engineering.\nThe developer branded the ATOUN MODEL Y as a “POWERED WEAR, a wearable robot that alleviates burden to the waist when lifting heavy objects, through powerful motors as well as sensors that detect the movement of the waist. This is achieved by the AWN-12 intuitively switching (no sensors are attached directly to the body of the user) between lift-assist for raising objects or support for lowering them, and “off” to reduce any obstruction while walking.\nSimilar to the previous model, the ATOUN MODEL Y is both dust and water-resistant (IP55 equivalent). The new carbon fiber frame has dramatically reduced the weight of the exoskeleton from 6 kg without the battery to 4.5 kg (10 lb) with the battery. Another new design innovation is the increased focus on wearability and breathability of the exoskeleton.\nThe device could also have been purchased with an annual maintenance/service program. The program includes inspection of the robot’s exterior and functions, cleaning, internal inspection of the drive mechanism, replacement of some movable parts, lubrication, software updates, and inspection (which will now be administered by Advance Co.: https://atoun.force.com/s/).\nSpecifications for ATOUN MODEL Y / AWN-12 (from 2021):\nAssumed work: loading and unloading heavy loads\nAssisting force: maximum 10 kgf (2 independent motors)\nOperating time: about 4 hours\nDevice outer dimensions: height 81 cm x width 48.4 cm x depth 28 cm\nSuitable User Height: 150 cm to 190 cm (4’11” to 6’3″)\nATOUN Inc.,Head Office: Sakyo 6-5-2, Nara City, 631-0801 JAPAN']	['<urn:uuid:c6d60c6c-70b7-4c55-a3cb-e59f848fc851>']	factoid	with-premise	concise-and-natural	distant-from-document	single-doc	expert	2025-05-01T23:21:14.341336	10	12	767
257	quick money options sports betting business financing	Both sports betting and working capital loans offer ways to access quick funds, but through different mechanisms. Sportsbooks allow immediate betting on sporting events with the possibility of quick returns, though they require careful odds consideration and money management. Working capital loans provide fast business financing through various options like term loans, business lines of credit, merchant cash advances, and invoice financing, with funding amounts ranging from $2,000 to $500,000 depending on the lender. Both options require thorough evaluation of terms and conditions before proceeding.	['A sportsbook is a place where a person can make a wager on a sporting event. There are a variety of ways to bet, such as putting money on which team will win or how many points or goals a certain team will score. The odds of winning or losing a bet are established by the sportsbook’s management. The goal is to provide the best possible return for bettors and make a profit from those who lose their bets.\nAlmost all sportsbooks are legal gambling establishments that have been licensed and regulated by the state in which they operate. They must adhere to strict operating standards, including ensuring that their employees are properly trained and following proper security procedures to protect customer information. They must also pay out winning bettors promptly and accurately. In the United States, there are over 100 licensed sportsbooks, including some large and small chains.\nIn the US, legal sports betting is now commonplace, a remarkable development considering that it was banned for much of the country only a few years ago. According to the American Gaming Association, the industry has already seen over $170 billion wagered on sports this year, with most of that coming from bets placed at legal sportsbooks. This is a massive increase from the previous year and is expected to double in 2021.\nThe legalization of sportsbooks has also brought a number of problems. Unlike the reputable bookmakers in Las Vegas, offshore sportsbooks often fail to uphold key principles, such as consumer protection and data privacy. Moreover, these operations don’t pay taxes that support local communities. In addition, they can be shady and unreliable, and it’s often difficult to get in touch with their customer service representatives.\nA good sportsbook will have a wide range of betting options for every sport, league and event. They should also offer fair odds and a great experience for players. Choosing the right one for you may involve some quick research, which should include reading independent/unbiased reviews and making sure that the sportsbook treats its customers fairly, has adequate security measures, and efficiently (plus accurately) pays out winning bets.\nLastly, a sportsbook should have an easy-to-use interface and be compatible with all major devices, from PCs to smartphones. They should also have a variety of payment options, such as credit or debit cards, Play+, PayPal, ACH (eCheck), online bank transfers, and more.\nIf you’re interested in trying your hand at sports betting, a free account is a great way to get started. Most sportsbooks let you chart bets without risking any of your own money, which is a good way to get a feel for the odds and how they work. You can also find out about any restrictions or terms and conditions before placing a real bet.\nThe most important thing to remember is that you should always shop around for the best lines. This is money-management 101, and it’s a crucial step in finding the most value out of your betting experience. It’s not uncommon to see a difference of a few cents on a line, and while that might not break your budget immediately, it can add up over time.', 'Best Working Capital Loans\nWorking capital loans for small businesses are one way to access quick and affordable financing. Business owners need to know what working capital is along with where they can secure a working capital loan for their financing needs.\nIf you run a small business, you know how vital it is to have enough cash on hand to pay bills, respond to unforeseen issues, take advantage of sudden business opportunities, and manage day-to-day expenses.\nWhether that means paying for an important marketing campaign, meeting payroll obligations, or paying for goods and services from vendors, having sufficient resources to do what is necessary to sustain and grow your business is a must. Each of these common finance issues among small businesses is covered by working capital.\nCash and other assets easily converted into cash are part of working capital. However, not all small businesses have available working capital lying around that can be used to cover what’s needed quickly.\nIn these scenarios, small businesses need to have options for working capital financing, often in the form of either a term loan or a business line of credit.\nThis guide offers insight into what working capital is, how it is acquired and the application process, and lenders that provide financing solutions to meet working capital needs.\nOn this page:\n- What is Working Capital?\n- How Can You Get Working Capital?\n- Lenders That Offer Working Capital Loans\n- How Do You Apply?\n- Difference Between a Small Business Loan & Working Capital Loan\nWhat is Working Capital?\nIn the simplest terms, working capital, sometimes referred to as net working capital, is the difference between current assets and current liabilities.\n- Current assets include accounts receivable, inventory of certain raw materials, finished goods, and of course cash on hand.\n- Current liabilities, on the other hand, are debts owed by the business that are due within the next 12 months.\nThis could mean accounts payable, salaries due to employees, or credit line payments to vendors or suppliers. The extent to which your current assets exceed your current liabilities is a measure of your business’s efficiency and short-term financial well-being.\nSecuring working capital through a loan allows you as the business owner to protect your own money. Instead of supplementing the business with your personal cash, a working capital loan provides short-term financing to help cover short-term needs. Also, having access to working capital provides a solution when cash flow is tight. Making payments to vendors on time, along with employee payroll and other debts are necessary to keep the business in good financial health for the long haul.\nHaving access to working capital allows you to steer clear of equity investors in your business. Some companies will seek out investors to help fund their business needs who ultimately inject capital into the business in exchange for ownership in the company.\nHowever, when this takes place, business owners forfeit some of their ownership stake in the business and the decision-making power that goes with it. Having enough working capital on hand eliminates this need. Some available funding and working capital lines of credit will only be available to established businesses, while other financial institutions will lend to new businesses. It’s important to find the right fit.\nHow Can You Get Working Capital?\nFortunately for small business owners, working capital can be acquired in several ways, including:\n- Working capital loans – these are the most common funding sources for short-term working capital needs, offered by a variety of small business lenders.\n- Merchant cash advance – working capital may also be available through a merchant cash advance in which a lender provides funds equal to daily or monthly credit card sales. The business then repays these funds with new card sales in the future.\n- Invoice financing and factoring – small businesses with outstanding invoices may sell these accounts for upfront cash. Invoice factoringcompanies then collect on the invoices as repayment from the business.\nEach method for receiving working capital outside what is currently available in the business comes with advantages and drawbacks of which business owners should be aware. It is always important to look at the costs, terms, and collateral needs for a working capital financing solution before signing on the dotted line.\nBest Lenders Offering Working Capital Loans\nSeveral lenders offer working capital loans to qualified businesses as a form of business credit, but each has a different set of eligibility criteria, interest rates, loan terms, and application processes.\nAs an online small business lender, Kabbage focuses on providing quick funding companies in need of short-term working capital for daily operations. With Kabbage, small businesses may apply for a loan amount between $2,000 and $250,000, with interest rates ranging from 24% to 99%.\nThe business must have an annual revenue of at least $50,000 to qualify, as well as at least one year in business. Kabbage is a good fit for small business owners who are willing to provide a personal guarantee, those who have less than perfect credit, or businesses that want fast working capital funding.\nAnother online lender offering working capital loans is OnDeck. The finance company provides working capital loans to small businesses that have been in business at least one year and have annual revenue of no less than $100,000. The working capital loans from OnDeck can range from $5,000 up to $500,000, with interest rates as low as 16.7%.\nOnDeck is best for small businesses with strong cash flow and those that do not mind a relatively short repayment term.\nA newer entrant to the small business lending market, StreetShares is a viable option for some small businesses with working capital needs. The online lender provides working capital loans to businesses in amounts ranging from $2,000 to $250,000 and interest rates ranging from 9% to 40%. Businesses must have annual revenue of at least $75,000 and be established for at least one year to qualify.\nStreetShares may require a personal guarantee from the business owner, as well as a minimum credit score of 600. This online lender is best suited for small businesses that want lower interest rates on working capital loans who have strong credit and steady cash flow from the business.\nHow Do You Apply for Working Capital Loans?\nThe application process for securing a working capital loan is not much different from any other small business financing application. Businesses need to provide the following information in order to show the lender they are a good fit for borrowing short-term funding:\n- Business owner’s social security number\n- The small business EIN or tax identification number\n- Recent bank account statements for the business\n- Recent personal and business federal tax returns\n- Financial statements like profit and loss statements or balance sheet\n- Cash flow details for the past several months\n- Outstanding business debts\nThis information is provided to a working capital lender either in person or online, and then it is reviewed in depth. Lenders want to know that businesses have the capacity to repay working capital loans in a timely fashion.\nIf business or personal financials are not strong, a working capital loan may require collateral to secure the loan or a personal guarantee from the business owner that promises repayment from personal assets. Once the lender feels confident in the small business’s ability to repay the loan, funds are deposited into the business bank account and can be used.\nDifference Between a Small Business Loan & Working Capital Loan\nWorking capital loans are beneficial to small business owners in need of financing because of the inherent differences they have from small business loans.\nWith a working capital loan, business owners have far more flexibility in what the loan proceeds may be used to cover. Items like payroll, overhead of the business, vendor payments, and inventory may be covered with a working capital loan. In many cases, small business loans are more specific. A business owner has less flexibility to pay for what is needed if it falls outside the reason for the small business loan, as listed on the application.\nAdditionally, working capital loans are much faster than small business loans as far as the application process and approval. However, working capital loans also have much shorter repayment terms than small business loans. Most working capital lenders require full repayment within six to 12 months, while small business loans may extend up to three or five years. Because of the shorter repayment timeframe and the fast access to cash, working capital loans may also have higher costs, including the interest rate, compared to small business loans.\nIt is important for business owners to consider their options for financing, including working capital and small business loans, before making a decision.']	['<urn:uuid:9ee9c5ad-2655-4fc0-9968-1e31eb25df09>', '<urn:uuid:9d641d5d-46bd-4839-8fd6-98a547088f03>']	open-ended	direct	short-search-query	distant-from-document	comparison	novice	2025-05-01T23:21:14.341336	7	85	1992
260	My family has German roots and I'd like to know how language use has changed in Lutheran churches - what's the difference between St. James Lutheran's historical language practices and modern Lutheran churches like the Missouri Synod?	St. James Lutheran Church, founded by German immigrants, initially conducted all communications, worship services, meetings, education and documents exclusively in German. They gradually transitioned to English, starting with one monthly English service in 1917, English Catechism classes in 1919, and finally discontinuing German services entirely in the 1930s. Today's Lutheran Church-Missouri Synod congregations conduct services in English and use English translations of the Bible, with the New Revised Standard Version (NRSV) being commonly used in Lutheran liturgical resources and educational settings.	['In the mid 1800’s, groups of immigrants from Scandinavia, The Netherlands, Germany, France and England settled in the Western Michigan counties of Muskegon and Oceana. Most employment was in the lumbering business. As the lands were cleared of timber, agriculture became the prevalent occupation.\nOn September 15, 1872, the first Lutheran service was led by Reverend Torney and held in a private residence in Ludington, Mi. The attendees decided regular services should continue and asked Rev. Torney to prepare a document stating that the Bible is divinely inspired and the inerrant Word of God, and the Augsburg Confession and Martin Luther’s Small Catechism were in full accord with Holy Scripture.\nOn February 16, 1873, the document was agreed upon and signed by twenty individuals. The Evangelical Lutheran Congregation of Saint James, Montague, Muskegon County began meeting in the German Baptist Church of Montague until their church could be erected in the coming year.\nMany members lived to the north in Claybanks Township. The distance, weather and poor road conditions made travel to Montague difficult. In 1879, they requested a release from St. James and formed the Evangelical Lutheran Congregation of Peace in Claybanks Township, Oceana County. They built their church and adjacent cemetery. Peace Lutheran remained a dual parish with St. James, shepherded by the same pastor. In 1961, due to declining membership, Peace Lutheran was closed and the remaining members merged back with St. James. The church was razed but the cemetery remains and is under the care of St. James.\nIn 1894, the Evangelical Lutheran Congregation of Emmaus was founded about three miles east of the Village of Rothbury in Oceana County. After World War I the membership was declining and the congregation also merged with St. James Lutheran in Montague.\nFrom the very beginning the members of St. James Lutheran Church realized the value of religious education and training. Mindful of the Lord’s command to “bring up the children in the nurture and admonition of the Lord’, and that this is not a directive to parents only, but to a Christian congregation also, it was decided to establish Christian Day School.\nA schoolhouse was built in 1885 on the corner of Dicey and Lasley. Diligently and faithfully the respective Pastors carried out this part of teaching and training. For nearly three decades this institution was a valuable asset to the congregation. As the century turned enrollment began to decline due to travel issues with the enlarging rural areas. The Day School was closed in 1912, but religious instruction continued with summer and Saturday School along with Catechism lessons during Sunday worship hours. In 1939, the school building was in need of major repair and it was decided to sell to a private party. The building was demolished and the lot remains vacant except for a boulder with a commemorative plaque.\nIn the late 1920’s, Pastor Krug continued summer classes, Saturday School and Sunday Catechism lessons, but also implemented Sunday School with four teachers, the Misses Marion Carleton, Marie Heitman, Louise Mangold and Ruth VanFrank. Enrollment in the Sunday School program grew every year. It was a true blessing but also meant more space was needed to function properly. The former C. F. Cordes home was purchased and used for this program. The Cordes home was located on the corner of Stebbins and Lasley, directly across Lasley from the church. The building was removed in 1968 and the site is now parking for the congregation.\nThe original members of St. James were German. All communications, spoken or written, were in the German language. All worship services, meetings, education and documents were in German. In 1917, the congregation approved one evening service a month to be conducted in English. In 1919, Catechism classes and the Rites of Confirmation were conducted in English. In 1928, at the beginning of Pastor Krug’s pastorate, weekly services were conducted in both German and English. In the 1930’s, the German services were discontinued and all services, meetings and documents were in English.\nThe original parsonage was constructed in 1880 on the corner of Dicey and Lasley. In 1950, the house was sold and moved to another location. It was replaced by the current brick home. It has undergone many renovations and has been used by past pastors and many of our staff, including several Directors of Christian Education, a Deaconess and our current Vicar.\nThe original church building was started in 1873 and dedicated the following year. The original site, the corner of Stebbins and Lasley, was donated by the lumbering firm, Ferry and Company. After fifty years of faithful service the building was considered unsafe and was replaced by the current brick structure. The new construction began in 1929 with many members doing the excavation work. The building was erected by the J. Olsen and Sons Construction Company. The interior work was completed during the winter and the new church was dedicated in the spring of 1930.\nIn 1968, expansion was needed, especially for education purposes. Adjoining property to the north of the church was purchased and the plans were to include a narthex, offices, restrooms and classroom on the main level and a new kitchen, fellowship hall with stage and restrooms in the basement of the new addition.\nIn 1996, plans were made to expand the narthex, add new office spaces, a conference room and two new classrooms for Good Shepherd Preschool. The new expansion also created handicap accessibility to the church with ground level entrances, handicap accessible restrooms and an elevator.\nIn 2010, the current church spaces were inadequate for a quality Junior High and Senior High Youth program. The Youth House was designed and built by members of the congregation. A construction company owned by one of the members donated materials and oversight.\nIn 2022, St. James Lutheran Church – Missouri Synod will recognize and celebrate our Sesquicentennial. We are honored and privileged to continue to display the Banner of Jesus Christ. “God’s Word and Luther’s Doctrine Pure” has endured by the grace of God. May God the Father, Jesus Christ His Son and the Holy Spirit continue to bless St. James Lutheran Church.\n|Henry Torney||1872 to 1890|\n|William Randolph||1891 to 1893|\n|Frederick Hahn||1894 to 1905|\n|J. George Neuchterlein||1905 to 1912|\n|Frederick Schriefer||1912 to 1927|\n|Albert G. Krug||1928 to 1964|\n|Robert Seizinger||1966 to 1967|\n|Lorne Rhul||1967 to 1977|\n|Walter Teske||1977 to 1989|\n|John Brooks||1990 to present|', '- 1 What do Missouri Synod Lutherans believe about communion?\n- 2 Does Missouri Synod practice closed communion?\n- 3 Can ELCA take communion at LCMS?\n- 4 What Lutherans believe about communion?\n- 5 Does Missouri Synod have female pastors?\n- 6 What Bible do the Missouri Synod Lutherans use?\n- 7 What is the difference between the Missouri Synod and Wisconsin Synod?\n- 8 Is the Missouri Synod conservative?\n- 9 Why should Christians practice closed communion?\n- 10 What does ELCA stand for in the Lutheran church?\n- 11 What is the difference between Lcmc and ELCA?\n- 12 What is the difference between Lutheran and Pentecostal?\n- 13 Do Lutherans believe you have to be baptized to go to heaven?\n- 14 What are the two types of Lutherans?\n- 15 Can a Catholic take communion at a Lutheran church?\nWhat do Missouri Synod Lutherans believe about communion?\nThe LCMS endorses the doctrine of close or closed communion —the policy of sharing the Eucharist ordinarily only with those who are baptized and confirmed members of one of the congregations of the Lutheran Church— Missouri Synod or of a congregation of one of its sister churches with which it has formally declared altar\nDoes Missouri Synod practice closed communion?\nConfessional Lutheran churches, including the Lutheran Church– Missouri Synod and the Wisconsin Evangelical Lutheran Synod, practice closed communion and require catechetical instruction for all people before receiving the Eucharist. Failing to do so is condemned by these Lutherans as the sin of unionism.\nCan ELCA take communion at LCMS?\nUnlike certain other American Lutheran church bodies, the ELCA practices open communion, permitting all persons baptized in the name of the Trinity with water to receive communion. Some congregations also commune baptized infants, similarly to Eastern Orthodox practice.\nWhat Lutherans believe about communion?\nLutherans believe that the Body and Blood of Christ are “truly and substantially present in, with and under the forms” of consecrated bread and wine (the elements), so that communicants eat and drink both the elements and the true Body and Blood of Christ himself in the Sacrament of the Eucharist whether they are\nDoes Missouri Synod have female pastors?\nThe General Lutheran Church ordains women. The Lutheran Church– Missouri Synod (LCMS), which is the second largest Lutheran body in the United States, does not ordain women. The Lutheran Congregations in Mission for Christ (LCMC) also allows for the ordination of women.\nWhat Bible do the Missouri Synod Lutherans use?\nThe Lutheran body to which I belong, The Evangelical Lutheran Church in America (ELCA) has a strong preference for the New Revised Standard Version (NRSV). Our Liturgical resources all use the NRSV, the Lutheran study Bible we use and the accepted text to use at seminary and I assume the colleges as well is the NRSV.\nWhat is the difference between the Missouri Synod and Wisconsin Synod?\nThe main facets of doctrinal difference between the WELS and the Lutheran Church– Missouri Synod ( LCMS ) include: The LCMS teaches that only the pastoral office is divinely established, while all other church offices are human institutions.\nIs the Missouri Synod conservative?\nLutheran Church– Missouri Synod, conservative Lutheran church in the United States, organized in Chicago in 1847 by German immigrants from Saxony (settled in Missouri ) and Bavaria (settled in Michigan and Indiana) as the German Evangelical Lutheran Synod of Missouri, Ohio, and Other States.\nWhy should Christians practice closed communion?\nThe practice of giving Holy Communion to only those of your denomination is what many Catholic, Orthodox, confessional Lutheran and other Christians call “ closed Communion.” It upholds a deep, reverent understanding of the Lord’s supper and limits it to those instructed about the supper and all other doctrines of\nWhat does ELCA stand for in the Lutheran church?\nBACKGROUND. Of the three leading Lutheran organizations operating in the United States, the Evangelical Lutheran Church in America (ELCA) is considered the most welcoming and inclusive of LGBTQ members.\nWhat is the difference between Lcmc and ELCA?\nLCMC is congregational in structure, rejecting the historic episcopate which was adopted by the ELCA, the denomination to which many LCMC members had previously belonged, in the (CCM) Call to Common Mission. The beliefs of the LCMC are based on the Bible and the Lutheran confessions in the Book of Concord.\nWhat is the difference between Lutheran and Pentecostal?\nPentecostal: Perhaps the main difference between Lutheran and Pentecostal churches is that Pentecostal churches tend to emphasize the importance of personal and spiritual “experiences” (such as “Baptism in the Holy Spirit” and speaking in tongues), while the Lutheran doctrine emphasizes the importance and centrality of\nDo Lutherans believe you have to be baptized to go to heaven?\nAccording to the Lutheran church, baptism isn’t necessary for salvation. A baby’s entrance into Heaven doesn’t depend on whether his parents had the time to get him baptized prior to his death.\nWhat are the two types of Lutherans?\nThe Evangelical Lutheran Church in America was formed in 1988 by the merger of two major Lutheran denominations, the American Lutheran Church and the Lutheran Church in America, along with the much smaller Association of Evangelical Lutheran Churches.\nCan a Catholic take communion at a Lutheran church?\nCatholics believe these become the body and blood of Christ; some Protestants, notably Lutherans, say Christ is present in the sacrament. Protestants are currently allowed to receive Catholic communion only in extreme circumstances, such as when they are in danger of death.']	['<urn:uuid:f944d3d3-3719-440e-8f04-b6802e9737bd>', '<urn:uuid:542e1b9f-6ce0-46db-8382-592ea652ba47>']	open-ended	with-premise	verbose-and-natural	distant-from-document	comparison	novice	2025-05-01T23:21:14.341336	37	81	1980
262	What security measures should be taken for parking and vehicle safety?	For parking and vehicle safety, you should park in well-lit secured areas, use a locking gas cap, visually check passenger compartments before entering, keep doors locked while driving, and avoid parking lots where keys must be surrendered. Additionally, be alert for vehicles following you and park in busy areas near busy bus stops. Lock your car immediately upon entering or leaving it, and always check the back seat before entering.	['Power Through Partnership…\nTaking Back Control of Your Life\nThis booklet will provide you with some practical guidance, including information to help you deal with a situation you may have previously thought was controlling your life. It will help you realize you are not alone; that there are countless resources available to you, just for the asking. However, the contents are by no means all-inclusive.\nAs a victim of stalking, you certainly realize that it is not only your life that is being impacted, but your family, friends, and/or co-workers as well. Therefore, relevant information contained herein should be shared with all concerned parties.\nYou may or may not have experienced some frustration in the past with the response from the police, or other agencies you have contacted, to help you with your situation. Hopefully, that frustration will shortly be alleviated. Herein lies the “Power Through Partnership” aspect of taking back control of your life. However, for proper management of your case, it is extremely important that you cooperate fully with the police, the detective assigned to your case, and any subsequent judicial proceedings along the way.\nThis booklet is meant to educate you in understanding the dynamics of stalking, as well as providing some common behavioral modifications that will assist in your case management.\nWHAT IS STALKING?\nAccording to California Penal Code Section 646.9, a stalker is “Any person who willfully, maliciously, and repeatedly follows or harasses another person and who makes a credible threat with the intent to place that person who is the target of the threat in reasonable fear for his or her safety, or the safety of his or her immediate family and made with the apparent ability to carry out the threat.”\nSimply speaking, stalking involves one person’s obsessive behavior toward another person, causing that victim to fear for his/her safety. The stalker usually begins his stalking behavior with annoying, threatening, or obscene telephone calls or written communications. The stalker may ultimately follow the victim of his obsession, often staking out the victim’s home and/or workplace.\nWHO CAN BECOME THE TARGET OF A STALKER?\nAnyone. Targets, as well as stalkers, traverse all economic, ethnic, and religious boundaries. The stalker’s actions rarely affect only the target. Family, friends, and co-workers are also impacted. A victim can be stalked from several days to many years.\nA few victims are picked at random by their stalker, but most stalking victims know their stalker, usually having had some type of past or present relationship. These are often referred to as Domestic Violence Stalkers. Although we often hear of celebrities who are being stalked, they constitute less than 15% of reported stalking victims, and involves a different type of stalker than most. Domestic Violence Stalkers are far and above the most dangerous and lethal type of stalker.\nWhat Should a Stalked Victim Do?\n- Get a restraining order. Keep a copy with you at all times.\n- Do your best to safely avoid all contact with the stalker.\n- Inform family, friends, and co-workers of what is going on in regard to the stalking.\n- Report the stalking to the police in your area and follow their advice.\n- Keep an accurate journal or log of all incidents connected to the stalking.\n- Keep all letters, packages, taped telephone messages, etc…received from the stalker.\nThe following are some suggestions on how you can enhance your security arrangements:\n- Be alert for any suspicious person.\n- Positively identify callers before opening doors. Install a wide angle viewer in all primary doors.\n- Install a porch light at a height which would discourage removal.\n- Install dead bolts on all outside doors. If you cannot account for all keys, change door locks. Secure spare keys. Place a dowel in sliding glass doors and all sliding windows. Engage these locking devices without fail when leaving the residence for any period of time, as well as when household members are at home.\n- Keep garage doors locked at all times. Use an electric garage door lock.\n- Install adequate outside lighting.\n- Trim shrubbery. Install locks on fence gates.\n- Keep fuse box locked. Have battery lanterns in residence.\n- Install loud exterior alarm bell that can be manually activated in more than one location.\n- Maintain an unlisted telephone number. Alert household members to unusual and wrong number calls. If such activity continues, notify local law enforcement agency.\n- Any written or telephone threat should be treated as legitimate, and must be checked out. Notify the appropriate law enforcement agency.\n- All adult members of the household should be trained in the use of any firearm kept for protection. It should be stored out of the reach of children.\n- Household staff should have a security check prior to employment and should be thoroughly briefed on security precautions. Strictly enforce a policy of the staff not discussing family matters or movement with anyone.Be alert for any unusual packages, boxes or devices found on the premises. Do not disturb such object, instead call the authorities.\n- Maintain all-purpose fire extinguishers in the residence and in the garage. Install a smoke detector system.\n- Tape emergency numbers on all phones.\n- When away from the residence for the evening, place lights and radio/TV on a timer.\n- Prepare an evacuation plan. Brief household members on the plan procedures and test them periodically. Provide ladders or rope for two-story residences.\n- A family dog is one of the least expensive, but most effective, alarm systems.\n- Know the whereabouts of all family members at all times.\n- Children should be accompanied to school or bus stops.\n- Routes taken, and time spent walking should be varied.\n- Require identification of all repairmen and salesmen prior to permitting them entry into the residence.\n- Inform a trusted neighbor regarding the situation. Provide the neighbor with a photo and good description of the suspect and any possible vehicles.\n- Inform trusted neighbors of any anticipated vacations, business trips, etc. and arrange for them to pick up mail, papers, etc.…\n- If residing in a complex with on-site manager, provide the manager with a photo of the suspect. If in secured building, provide information to the doorman or valet.\n- Central reception should handle visitors and packages.\n- Office staff should be alerted of suspicious people, parcels, and packages that do not belong in the area.\n- Establish key and lock control. If keys possessed by terminated employees are not retrieved, change the locks.\n- Park in secured area if available.\n- Have your name removed from any reserved parking area.\n- If there is an on-site security director, make him/her aware of the situation. Provide him/her with suspect photo and information.\n- Have a secretary of co-worker screen calls if necessary.\n- Be aware of anyone possibly following you to/from work.\n- Do not accept any package unless you personally ordered the item.\n- Park vehicles in well-lit areas. Do not patronize parking lots where car doors must be left unlocked and keys surrendered; otherwise surrender only the ignition key. Allow items to be placed in, or removed from the trunk only by your presence.\n- When parked in the residence garage, turn the garage light on and lock the vehicle and garage door.\n- Equip the gas tank with a locking gas cap. The hook-locking device should be controlled from inside the vehicle.\n- Visually check the front and rear passenger compartments before entering the vehicle.\n- Select a reliable service station for vehicle service.\n- Keep doors locked while vehicle is in use.\n- Be alert for vehicles that appear to be following you.\n- When traveling by vehicle, plan ahead. Know the locations of police stations, fire stations, and busy shopping centers.\n- Always park in a secured garage when possible.\n- Remove home address on personal checks and business cards.\n- Utilize a private mailbox service to receive all personal mail.\n- Place real property in a trust, and list utilities under the name of the trust.\n- File for confidential voter status or register to vote utilizing mailbox address.\n- Destroy discarded mail.\n- Telephone lines can be installed in a location other than the person’s residence and call-forwarded to the residence.\n- Place residence rental agreements in another person’s name.\n- The person’s name should not appear on service or delivery orders to the residence.\n- Do not obtain a mailbox with the United States Post Office.\n- Mailbox address now becomes the person’s official address on all records and in all rolodexes. It may be necessary or more convenient to list the mailbox as “Suite 123” or “Apartment 123”, rather than “Box 123.”\n- File a change of address card with the U.S. Post Office giving the mailbox address as the person’s new address.\n- Send postcard to friends, businesses, etc. giving the mailbox address, and requesting that they remove the old address from their files and rolodexes.\n- All current creditors should be given a change of address card to the mailbox address. (Some credit reporting agencies will remove past addresses from credit histories if a report is made. We recommend this be done.)\n- File a change of address with DMV to reflect the person’s new mailbox address. Get a new driver’s license with the new address on it.', 'Safety During an Explosive Incident\n- If an argument seems unavoidable, move to a room with easy access to an exit – NOT a bathroom, kitchen or anywhere near weapons.\n- Identify which door, window, stairwell or elevator offers the quickest way out of your home – and practice your route.\n- Find neighbors you can tell about the violence, and ask that they call the police if they hear a disturbance.\n- Devise a code word to use with your children, family and friends when you need the police.\n- Decide and plan where you will go if you have to leave home, even if you don’t think you will need to.\n- Use your best instincts and judgment. Think of how best to keep safe until help arrives. If the situation is very dangerous, consider giving your abuser what he/she wants to calm him/her down. You have the right to keep yourself safe until you are out of danger.\nSafety When Preparing to Leave\n- Identify a safe place. Determine who will be able to let you stay with them or lend you some money.\n- Have a bag packed and ready. Keep it hidden but easy to get to – for instance, at the house of a trusted friend or relative.\n- Leave money, an extra set of keys, copies of important documents, extra medicines and clothes with someone you trust so you can leave quickly. (See the Checklist of items to take with you.)\n- Get information about protective orders from the House of Ruth, Domestic Violence Legal Clinic, your local police, victim assistance or the court.\n- Call a domestic violence hotline. They can help you with support information and housing.\n- Remember - leaving your batterer is the most dangerous time. Review your safety plan as often as necessary so you know the safest way to leave.\nSafety at Home: After You Have Separated\n- Change the locks and install safety devices on windows.\n- Change your phone number and request to have an unlisted phone number.\n- Develop a safety plan, and discuss it with your children, explain to your children what is going on in an age appropriate way. Review the plan as often as possible.\n- Make sure your children’s school, day-care or camp knows who has permission to pick up your children.\n- Tell your neighbors and landlord that your abuser no longer lives there, and ask them to call the police if they see that person near your home.\n- Before you get back into a potentially abusive relationship, discuss alternatives with someone you trust.\n- Get a Protective Order or Peace Order from the Circuit Court or District Court.\nWays to Make Travel Safe\n- Always park in well-lit area/use busy bus stops.\n- Always lock your car right away (when you leave or enter it).\n- Ask someone to walk you to your car/bus stop.\n- Always check the back seat before you enter your car.\n- Never wait alone at a bus stop.\n- Always carry pepper spray or mace with you.\n- Use different streets to drive home.\n- Look around at every stop light and before you get out of your car.\n- If you see that your abuser is following you or waiting for you, go away and get to a phone and call 911.']	['<urn:uuid:4088d2e7-a0f0-48d1-aa37-f7d6f9cad043>', '<urn:uuid:6012f83c-7c2e-4076-8c23-d283b1caf3cd>']	factoid	direct	concise-and-natural	similar-to-document	three-doc	expert	2025-05-01T23:21:14.341336	11	70	2123
266	what natural winemaking methods used modern winery burgenland austria	The winery in Burgenland, Austria employs several natural winemaking methods. They use only ambient yeasts that naturally grow in the vineyards and cellar, avoiding cultivated yeasts. The wines are neither filtered nor fined, and they use minimal to no sulfur. They age many wines in amphora rather than wooden barrels to better express the grape and soil characteristics. They also use partial carbonic maceration for Blaufränkisch grapes to achieve vivacity and fruitiness in the wines.	['Vintner Stories - January 4, 2022\nClaus Preisinger is pushing boundaries in the progressive region of Burgenland in Eastern Austria\nIn the vast farmland region of Burgenland in Austria, there is a modern building that stands out from the rest of its surroundings. It is the winery of Claus Preisinger, a winemaker at the forefront of the natural wine movement in Austria. His charming presence, strong surfer vibes, and sarcastic sense of humor make visiting this estate very memorable, welcoming, and engaging. This energy translates into the wines and ciders that boast minimalistic yet recognizable labels that feature Preisinger’s signature on the white background.\nPreisinger was born in 1980 in Eisenstadt. He went to a viticultural high school in Klosterneuburg. After graduating, he crossed the pond to build on his winemaking experience in the Californian vineyards. Upon returning to the homeland, he worked at another well-respected biodynamic wine estate in Burgenlad – Anita & Hans Nittnaus. He would spend the next three years there before eventually making wines with his father in 2002. Since then, he still makes wine on the north shore of Lake Neusiedl in the wine-famous Burgenland town of Gols.\nFollowing what he learned at Nittnaus, he converted his vineyards to biodynamic. In 2004, the renowned Pannobile association of wineries, where Hans Nittnaus is one of the founders, accepted him into the organization. In 2006, he officially converted all his vineyards and winery to biodynamic production. A few years later, he was certified by the Austrian biodynamic group Respekt.\nIn 2009, Preisinger built his new modern winery on the periphery of Gols, overlooking his vineyards. However, visitors should not let the look of the building fool them. Regardless of the aesthetic, everything else about the winery moves away from modern protocols. Credit this to Preisinger, who is deeply committed to working manually and as naturally as possible, without the latest machinery. He firmly believes that winemakers should be in the vineyards to produce pure, balanced wine that is expressive of the terroir.\nIn that sense, his approach is very traditional. However, this doesn’t stop him from being innovative. Preisinger is well-known in the wine world as someone who loves to experiment and try new things. A testament to that is his co-ferment of apples and grapes which resembles a mixture of cider and pet-nat. One of the first vintners in the area to experiment with skin-macerated white wines and use amphorae, he uses no set formula, instinctively making important farming and wine-making decisions.\nPreisinger works primarily with the indigenous grape varieties, such as Blaufränkisch, Zweigelt, Grüner Veltliner, and St. Laurent, but also with a little bit of Pinot Noir and Pinot Blanc. Grapes come from the west and east sides of Lake Neusiedl from 64 different plots. Naturally, he works with different microclimates and soil types, from limestone to loess.\nTo best express the differences of his terroirs, but also the purity of his healthy, natural grapes, Preisinger’s winemaking approach is very minimal. He does not use any cultivated yeast but rather depends on the ambient ones that grow in his vineyards and cellar. He doesn’t filter or fine his wines and only uses a very small amount of sulfur or none. At times, this has made it difficult for Preisinger to have his wines approved by the officials and to label them under specific appellations.\nHe ages many of his wines in amphora rather than wooden barrels, which he views as a conscious step back, a reduction to the essential - the grape and the soil. He also uses partial carbonic maceration to produce Blaufränkisch, which gives this grape vivacity and fruitiness. It is a conscious move to produce wines that are intriguing when young but also have good aging potential.\nOver the years, Preisinger gradually expanded his land. Today, he owns around 25 hectares (62 acres) of vineyards. He also leases another 15 hectares (37 acres), which are solely used for production of his entry-level cuvée Puszta Libre. His total production is around 200,000 bottles a year.\nPreisinger has obtained several accolades from famous wine publications and is one of the movers and shakers in Burgenland. His wines range from being fun, easy drinking with interesting labels to the more serious wines that require meditation and time. At the forefront of the natural wine movement in Burgenland and Austria, he is always pushing the envelope to make unapologetic wines that best portray himself and his homeland.']	['<urn:uuid:1db4dc71-ba2b-40c8-9e54-d95faad8602c>']	open-ended	direct	long-search-query	similar-to-document	single-doc	novice	2025-05-01T23:21:14.341336	9	75	741
267	Can ACFM and Hall probe field measurements both work through surfaces without direct contact?	Yes, ACFM can test through coatings up to 5mm thick without contact, while Hall probes for undulator measurements also work without contact, though Hall probes face challenges with DC offset drift that can affect measurement accuracy.	"['Undulator Field Integral Measurements Page: 1 of 9\nThis report is part of the collection entitled: Office of Scientific & Technical Information Technical Reports and was provided to Digital Library by the UNT Libraries Government Documents Department.\nThe following text was automatically extracted from the image on this page using optical character recognition software:\nUndulator Field Integral Measurements\nAugust 5, 2005\nThe LCLS undulator field integrals must be very small so that the beam trajectory slope\nand offset stay within tolerance. In order to make accurate measurements of the small field\nintegrals, a long coil will be used. This note describes the design of the coil measurement\nThe primary tuning of the LCLS undulators will be done by sampling the magnetic field at many\npoints and numerically calculating quantities of interest. The sampling will be done with Hall\nprobes. For some measurements, however, the errors associated with this technique are too large.\nAn example is the calculation of the field integrals. A small DC offset from the Hall probe, when\nintegrated over the undulator length, can exceed the required field integral tolerances. A better\ntechnique to measure field integrals involves the use of a long coil. As the coil is moved through\nthe field, the induced voltage is integrated to give the flux change. The field integrals can be\ncalculated from the measured flux changes. Small offsets are easily dealt with by measuring in both\nthe forward and backward directions. In this note, the coil measurement system under construction\nThe maximum values for the field integrals have been specified2. The first integral of both Bx\nand By must be less than 40 x 10-6 Tm. The second integral of both Bx and By must be less than\n50 x 10-6 Tm2. The exact definitions of these integrals and a discussion of their importance will\nbe given below.\nThe field integrals should be measured better than the required maximum values for the undu-\nlators. This is very difficult, if not impossible, to do even with the best Hall probes. Consider a\nSentron Hall probe as used at ANL and many other laboratories for precision undulator measure-\nments. The specified DC offset drift of the Sentron probe is 0.1 G, or 10-5 T (average output\nnoise in the bandwidth 0.01 Hz to 100 Hz3). Over the 3.4 m length of the undulator, a 10-5 T\noffset would contribute 3.4 x 10-5 Tm to the first field integral, which is roughly the specified limit.\nBecause the required Hall probe offset is at the limit of what can be achieved, a second method of\nmeasuring the field integrals is desired.\nField integral measurements are fairly easy to do with a long integrating coil, and offsets can\nbe easily dealt with by measuring as the coil moves both forward and back, then subtracting and\ndividing by 2. An additional benefit is that the equipment is somewhat mobile, unlike the granite\nbench required for Hall probe measurements, allowing measurements to also be done in the tunnel.\nCoil measurements similar to those required for the field integrals are done routinely in the magnetic\n\'Work supported in part by the DOE Contract DE-AC02-76SF00515. This work was performed in support of the\nLCLS project at SLAC.\n2H. D. Nuhn et al, ""LCLS Undulator Requirements"", LCLS Specification # 1.4-001 rev 2.\n3Sentron model 3M12-2-2-0.2T data sheet.\nSLAC National Accelerator Laboratory, Menlo Park, CA 94025\nHere’s what’s next.\nThis report can be searched. Note: Results may vary based on the legibility of text within the document.\nTools / Downloads\nGet a copy of this page or view the extracted text.\nCiting and Sharing\nBasic information for referencing this web page. We also provide extended guidance on usage rights, references, copying or embedding.\nReference the current page of this Report.\nWolf, Zachary. Undulator Field Integral Measurements, report, December 7, 2010; United States. (digital.library.unt.edu/ark:/67531/metadc836025/m1/1/: accessed April 19, 2018), University of North Texas Libraries, Digital Library, digital.library.unt.edu; crediting UNT Libraries Government Documents Department.', 'Alternating Current Field Measurement Testing\nA number of industries use ACFM to inspect welded connections for surface-breaking defects.\nFirst, a little history. The alternating current field measurement (ACFM) nondestructive testing technique was developed in the ‘80s to detect and estimate penetration depth of fatigue cracks in underwater welded tubular intersections of offshore oil platforms. Prior to the advent of ACFM, these defects were generally detected and their length measured with magnetic particle inspection.\nThe severity of fatigue cracks (directly related to the remaining life of structures) is commensurate with how deep they are. At the time, conventional eddy current testing systems were not well suited for use underwater or for welds in ferritic steel. They were unable to accurately measure defects deeper than 5 mm (0.2 in). Alternating current potential drop (ACPD) was the technique used to measure depth, but it was slow and very difficult to use underwater because of the need to maintain very good electrical contact between the voltage probe and the steel surface.\nAddressing this problem required a noncontact equivalent to ACPD. A group of United Kingdom oil companies approached the University College London to develop the new technique: ACFM.\nACFM locally induces a uniform current into the component under test and measures the density of the magnetic flux over the component surface. The electric field is typically induced at a frequency of 5 kHz which, on carbon steel, results in the currents being confined to a thin skin at the material’s surface. Surface-breaking defects perturb the induced current, thus the magnetic flux density. ACFM measures two components of the magnetic flux density: one offers information about the position of defect ends (ergo the defect’s length). The second component provides the aspect ratio (and hence depth) of the defect. The components combined to confirm defect presence and, with a sizing algorithm developed from theoretical models, establish surface length and depth.\nThe primary direction of induced currents is designated as the Y axis, while the direction of the associated magnetic field in and immediately over the surface is designated as the X axis (as shown in Figure 2).\nWhen the component under test is devoid of defects, the current flows along the Y axis and the magnetic field along the X axis. The magnetic field’s Y and Z components (designated By and Bz) are zero, while the X component (Bx) is proportional to the magnitude of the electric current.\nFields Around Defects\nWhen a linear surface-breaking defect is present in the component under test along the X axis, cutting across the electric current lines, the current is forced to flow around and under the defect’s ends.\nAs it flows under the defect, some of the current is forced away from the surface. This reduces the strength of the magnetic field in the middle of the defect (blue in Figure 3). Some of the current flows around the ends of the defect, strengthening the magnetic field at the ends (red in Figure 3). As it does, a partly circular flow appears. This rotation around the ends of the crack produces a measurable, non-zero Bz.\nACFM produces a third trace, referred to as a butterfly plot. It is composed of the Bx and Bz sensor data, plotted against each other. The Bx amplitude is plotted on the vertical axis and the Bz amplitude is plotted on the horizontal axis. (See Figure 5.)\nThe resulting display removes the time element from the scan, removing scan speed variation effects.\nPros and Cons of ACFM\nACFM has several advantages and, of course, disadvantages.\nThe main advantages of ACFM include:\n- Test through coatings as thick as 5 mm (0.2 inch)\n- Measure the depth of surface-breaking cracks as deep as 25 mm (1 inch)\n- Easy to test material boundaries (e.g., welds) because they are parallel to scan paths\n- No on-site calibration necessary\nACFM has the following disadvantages:\n- On smooth, clean surfaces, ACFM is generally less sensitive to short/shallow defects than conventional eddy current testing.\n- Geometry changes such as edges and corners can produce confusing signals\n- The sizing model is based on linear fatigue cracks—other forms of defects can lower sizing accuracy.\nAnatomy of ACFM Equipment\nThe basic ACFM probe contains a minimum of three elements:\n- Magnetic field inducer\n- Magnetic sensor to measure flux density along the X axis\n- Magnetic sensor to measure flux density along the Z axis\nBasic ACFM probes can only inspect a narrow strip 10–15 mm (0.4–0.6 inch) wide, centered on the probe sensors.\nArray ACFM Probes\nTo inspect wider areas in one pass, array ACFM probes are engineered to contain several sensor pairs adjacent to each other. The sensor array profile can have multiple configurations.\nSome array probes feature a Y-field inducer perpendicular to the primary, X-field inducer, and an additional By sensor, making them capable of inspecting in two orthogonal directions simultaneously to detect and size defects in any direction.\nArray data can be displayed as traditional trace plots or as C-scans, where red peaks and blue troughs appear against a green background level (See Figure 8).\nTypical ACFM Applications\nA number of industries use ACFM to inspect welded connections for surface-breaking defects. Because array ACFM probes offer a wide coverage and relative tolerance to liftoff, they can be part of remotely deployed solutions, such as scanners and crawlers. Applications where this is useful are where direct human access is difficult, unsafe, or costly.\nACFM is usually used on ferromagnetic materials, where it achieves the highest sensitivity. However, it’s also been used on non-ferromagnetic materials such as austenitic stainless steel (nuclear storage tank pools), titanium (offshore risers), and Inconel (threaded connections on down-hole motors) with great success.\nAcceptance and Standards\nACFM is widely accepted by major organizations in the oil and gas, petrochemical, and marine industries, as well as others. Approval takes various forms, sometimes issued asset owners, insurance companies, or certification bodies.\nIn the oil and gas industry, a number of the certification authorities approved ACFM to inspect offshore installations in above water and subsea applications. Several recommended practice and procedure documents include ACFM.\nACFM is also the accepted MPI alternative when inspecting drill string threads in the North Sea and recommended practices were issued.\n- ABS, Guide for Nondestructive Inspection of Hull Welds, 2018. ww2.eagle.org/content/dam/eagle/rules-and-guides/current/survey_and_inspection/14_ndi_hullwelds/NDI_Guide_e-Feb18.pdf\n- ASTM, Standard Practice for Examination of Welds using the Alternating Current Field Measurement Technique (E2261-03), latest revision: E2261-17. www.astm.org/Standards/E2261.htm\n- ASME V Article 15, Alternating Current Field Measurement Technique (ACFMT), 2006. www.asme.org/products/codes-standards/bpvcv-2017-bpvc-section-vnondestructive\n- North Sea standard NS-2 (1999), latest revision 2012. www.fearnleyprocter.com/ns-2-standard']"	['<urn:uuid:32a88dd4-3072-4dd4-9cd8-2b0eab550d4b>', '<urn:uuid:1c7f15f3-a32b-4d39-9055-5159d057d2f7>']	factoid	with-premise	concise-and-natural	similar-to-document	comparison	expert	2025-05-01T23:21:14.341336	14	36	1750
269	ballet schools chicago history types training	Chicago has a rich history of ballet schools, including the Stone-Camryn School of Ballet founded in 1941 and Edna McRae's ballet school which operated from 1925 to 1964. Modern ballet training encompasses multiple levels, from introductory classes using French terminology to advanced pointe work. Classical Ballet technique includes barre, allegro, adagio, and fundamentals of technique and placement, with students progressing through levels based on age, experience, skill-level, and maturity. Pointe work requires special approval, with dancers under 12 needing physician clearance to prevent injury.	"[""Manuscripts, American -- Illinois -- Chicago\nSubject Source: Library of Congress Subject Headings\nFound in 10 Collections and/or Records:\nIdentifier: Midwest-MS-Chicago-Allied Arts\nAbstract Records kept by Thomas Hart Fisher, secretary for the Chicago Allied Arts, Inc., a short-lived organization which produced a series of programs of new music and dance in Chicago from 1924-1927. Includes business correspondence and financial information, with some program planning information.\nAbstract Dancer, choreographer, and teacher Edna McRae started dancing in Chicago Public Schools and studied with Andreas Pavley, Serge Oukrainsky, and Adolph Bolm, among others. She operated a ballet school in Chicago from 1925 to 1964, becoming known as the grande dame of the Chicago Ballet community. Papers include correspondence, biographical information, brochures, clippings, programs, numerous photographs, personal and dance notation notebooks, card files, address books, and eight albums relating...\nAbstract Large collection of photographs relating to the ballet, opera and cinema, dating from the 1940s through the early 1970s, amassed by Ellen (Teddy) Goldsmith, backstage worker at the Civic Opera House, home of the Lyric Opera of Chicago. Many of the photographs are professional portraits of opera stars and ballet dancers – many autographed – and hundreds of personal and backstage snapshots. Also, a group of photos of movie stills, popular celebrities and performers, plus a small amount of...\nAbstract Material relating to the life and career of dancer, poet and painter Mark Turbyfill, including three copies of his unpublished autobiography and many copies of published and unpublished poems. Also, articles and reviews by and about Turbyfill, a few pieces of correspondence, clippings, dance programs, photographs, a cassette tape of him reading, and a published genealogy of the Turbyfill family.\nAbstract Ruth Levy, who performed as a dancer with the Pavley/Oukrainsky Junior Ballet, received a master’s degree in photography at the Art Institute of Chicago in 1972. This collection includes her slides, negatives, proof sheets, and prints of dancers in several companies, including the Alvin Ailey American Dance Theater, the American Ballet Theatre, the Dance Theatre of Harlem, the Joffrey Ballet, the New York City Ballet, and the Ruth Page Chicago Ballet among others. Some of these photographs were...\nDates: 1928-1976; Majority of material found within 1970 - 1973\nAbstract Records of the Ruth Page Foundation, a cultural non-profit organization committed to the education, promotion, and presentation of dance in Chicago. Founded by Ruth Page in 1970, the Foundation continues to support a number of dance initiatives. Includes administrative, personnel, financial, and publicity materials for both the Foundation and the Ruth Page School of Dance.\nAbstract Personal papers of dancer and choreographer Ruth Page. Materials include correspondence, choreographic and technical notes, address books, programs, press clippings and scrapbooks, journals writings, photographs, business records, audio recordings, and musical scores. Featured dance works include The Bells, Carmen, Nutcracker, Romeo and Juliet, Frankie and Johnny, and Billy Sunday.\nAbstract Malkind, a Chicago photojournalist, worked for the Ruth Page Foundation from 1981 to 1992. Her photographs primarily feature cultural life in Chicago, dance and performing arts events, as well as her personal life. The collection also includes clippings, correspondence, publicity materials, written work by Malkind and Ruth Page, and audio recordings.\nDates: 1960-2003; Majority of material found within 1985 - 1993\nAbstract Chicago's Stone-Camryn School of Ballet was founded in 1941 by established dancers Walter Camryn and Bentley Stone. It became one of the most successful American ballet schools in placing its graduates in professional companies, and in creating new generations of dance teachers. Archives include personal and biographical material from Stone and Camryn, school records, scrapbooks, diaries, photographs, programs, clippings, and choreographic notes.\nDates: 1865-1988; Majority of material found within 1910 - 1988"", 'Intro to Ballet & Tap using proper French terminology for Ballet and methods appropriate to the age and attention span of the dancer. A routine is followed to encourage learning the dance class environment. Giraffes Dance Too (Ages 3-4) may include Pre-Ballet, Pre-Tap, Pre-Jazz & Acro; Tutus & Top Hats (ages 5-7) may include Ballet, Tap, Jazz, Acro, & Hip Hop.\nClassical Ballet technique is taught, appropriate to the level and age. Barre, Allegro, Adagio, and fundamentals of technique and placement with the use of all French terminology. Levels are determined based on the age, experience, skill-level, and maturity of the dancer. Level III-VI Ballet students should also enroll in Lyrical and are strongly encouraged to enroll in Pointe classes for optimal progression at the advanced level.\nA class for the Intermediate to Advanced Ballet dancer, who already has a foundation of Classical Ballet and wishes to further their ballet training to include dancing en pointe. While the pre-pointe class can be taken without pointe shoes to develop ankle strength and in preparation of pointe work, pointe shoes should only be obtained under the direction of the instructor, with much guidance and pre-approval. The instructor will determine when a student is ready for pointe and guidance on pointe shoes. Elite\'s policy is that dancers under the age of 12 must be given clearance from their physician before beginning pointe work, to ensure growth plates are fused and to prevent injury resulting from going en pointe too soon.\nJazz, Funk, and various styles (Fosse/Broadway vs. Street Jazz) are taught using center work, across the floor, leaps, and turns. Emphasis on placement and attention to detail of proper execution. Levels are determined based on the age, experience, skill-level, and maturity. Levels 2-4 should accompany this class with the appropriate Leaps/Turns class for optimal development.\nVarious styles of tap are taught (Broadway or Classical Tap) as well as \'new\' styles of the latest and greatest tap experts, appropriate to level and age. Rhythm, sound, and timing are emphasized. Serious tap students are encouraged to take two tap classes, one in their level and one of a level up or down to further develop clean sounds and technique.\nOne definition of \'lyrical\' is expressing deep personal emotion or observations. Lyrical dance is the merging of Classical Ballet with Jazz and Contemporary styles of dance. It is usually performed with music which has \'lyrics\' and is very expressive, to convey feeling and musicality. Students wishing to take Lyrical must have a foundation in Ballet and Jazz. Level 2-Advanced, mature students will be successful in this class.\nBorrowing from modern, classical, and jazz styles, contemporary has grown in popularity. Focus on technique with a modern base, and unpredictable changes in rhythm, speed, and direction, Contemporary classes are for the more experienced, classically trained dancer. Prerequisite: Intermediate or Advanced Ballet taken concurrently.\nThis is a street-style of dance, executed to Hip Hop music or as evolved from Hip Hop culture. The term \'hip hop\' is vague as it can encompass a wide range of styles from Jazz/Funk to Poppin\', Lockin\', Jerking, Breakdance, or whatever the latest trend is, which is constantly changing. Each instructor has a diverse style and approach to this genre. Dress is not as strict, nor is the tone of the class. This style is completely independent of most other styles.\nA class to elaborate on various jumps, leaps, turns, and variations in ballet and jazz. Designed to be taken concurrently with ballet and/or jazz levels 2 and up.\nAn elective class to further train students in flexibility and strength, which can vary between cardio training for stamina, flexibility exercises, and strength training in a variety of different methods. This is sometimes offered as a workshop but, is combined with Acro classes, as well.\nTumbling is included in all Acro classes with the intent to create a more diverse dancer, with the skills necessary to incorporate increased flexibility, acrobatic tricks, and tumbling passes into their dance repertoire. Pre-tumbling is for the preschool dancer who will learn basic tumbling skills, strength, and flexibility. Each level will progress into more advanced tumbling skills and passes such as roundoffs, aerials, walkovers, handsprings, and staging for tucks/layouts. We are not a gymnastics gym, however, our training fulfills the dancer\'s need for certain acrobatic and tumbling skills to make a well-rounded dance athlete. Those intending to train for cheerleading learn necessary skills in our program.\nCertified by Acrobatic Arts, this class series is based on safe and effective progressions combining flexibility, strength, balancing, limbering, and tumbling, which has been designed mindful of dance, contortion, rhythmic gymnastics, and more. Combining artistry of the dancer with acrobatics, this class takes the classical dancer to a new level. *Certified studio as of August 2018\nAlways a front runner in Musical Theater, our Dazzlin\' Dolls competition team has been competing in Musical Theater for many years. We hold a National Title in Musical Theater for our rendition of ""Newsies"". We offer a Junior and Teen Musical Theater class. It is recommended that students have dance experience in Jazz, Tap, & Ballet or take them concurrently in order to get the best experience in this class.\nAn intro into our Pre-Dance program, little ones ages 2-3 can join Mommy for an age-appropriate introduction to dance, music, and creative movement.\nAs a well-known tap studio, we pride ourselves in offering the best, most progressive tap program in the area and competitive with the most successful tap programs in the country. In keeping with our reputation, we offer this class to further enhance our tap students\' experience. The class will increase students\' knowlege and proficiency in tap skills, beyond what is covered in their weekly tap technique class. A foundation is required in order to benefit from this class as it is geared toward the Level 2 through Intermediate tap dancer. Students wishing to gain more practice in tap tricks should enroll in this class. Must be enrolled in another tap technique class as this does not replace a tap technique class.\nHeels Class is a high-heel infused dance class with the everyday woman in mind. It is intended to bring out your confidence and your inner Diva! Various styles of dance are incorporated in this class.']"	['<urn:uuid:58a88d43-f1a4-4947-b735-c368df6ae1ec>', '<urn:uuid:727dfed0-410a-4780-a5c0-e045657e5565>']	open-ended	direct	short-search-query	similar-to-document	three-doc	expert	2025-05-01T23:21:14.341336	6	84	1647
270	I'm curious about how Islamic scholars dealt with religious texts - what are the two main approaches they used to interpret difficult passages, and how did they decide who could use which method?	The two main approaches were ta'wīl (figurative interpretation) and tafwīḍ (a simpler, unexplainable 'non-method'). For difficult passages, ta'wīl became the standard position in later Sunni orthodoxy. According to the scholars, only the educated elite were permitted to use allegorical interpretations, while the masses were restricted to accepting apparent meanings. Revealing allegorical interpretations to unqualified persons was considered dangerous and could lead to unbelief. The scholars believed there were three classes of people in relation to interpretation: the majority who could only understand rhetorical meanings, some who could handle dialectical interpretation, and a philosophical elite who could use demonstrative methods.	['THE REFUTATION OF HIM [IBN TAYMIYYA] WHO ATTRIBUTES DIRECTION TO ALLAH\nAuthor: Ibn Jahbal Al Kilabi\nIntoroduction by: Shaykh Wahbī Sulaymān Ghāwjī\nForward by: Shaykh Muhammad Afifi Al-Akiti\nTranslated by: Shaykh Gibril Fouad Haddad\nAvailable now from www.aqsapublications.com\nForward by Shaykh Muhammad Afifi Al-Akiti\nLike the Judaic and Christian theological traditions, the Islamic one also, – arguably with less crassness – faced the problems of scriptural literalism that result in an anthropomorphic theology. As the early (salaf) Muslim community became more sophisticated and began to lead the world in scientific progress – and especially from the time of Islam’s Doctor Angelicus, al-Ghazālī (d. 505/1111) – Muslim theologians came to embrace and institutionalize the case for ta’wīl. This was Islām’s systematic solution of the problem, through a canon of figurative interpretation of scripture as a necessary tool of hermeneutics.\nNot only did the method of ta’wīl keep anthropomorphism in check through offering a middle way in the understanding of Divine Attributes as limited by human language, but it served to reconcile Divine Scripture with the discoveries afforded by human reason. This legitimization of ta’wīl by the classical ‘ulamā’ and its systematic treatment in the Golden Age of Islām made it an established doctrine among Muslim theologians. It became the standard position in later (khalaf) orthodoxy within the Sunni tradition (alongside the formerly dominant, simpler alternative, and utterly unexplainable “non-method”: tafwīḍ) – the cultural milieu that brought forth this work.\nThis short theological tract, Fī Nafī al-Jiha, or On Denying Direction to God, by the Ash’ari theologian and celebrated Shafi’i jurist, Qāḍī Ibn Jahbal (d. 733/1333), is a clinical rebuttal of the controversial fatwā, the ‘Aqīda Ḥamawiyya, penned by his legendary contemporary, Ibn Taymiyya (d. 728/1328). It is considered, rightly, a classic manifesto of anti-literalism, which embraces the successful pro-ta’wīl Ghazālīan theses advocated centuries earlier – to the extent that Ibn al-Subkī (d. 771/1370) reproduced the whole of Ibn Jahbal’s work in his magisterial\nThe present volume is a special “all-Damascene” edition, which contains the very first (and definitive) English translation of Ibn Jahbal’s Arabic text; completed by an authorized, nay Damascus-trained and native scholar, Shaykh Gibril Fouad Haddad, who possesses the complete and exclusively Dimashqī ijāza going back to the original Damascene author; and supplemented by superb scholarly documentation and a running commentary. The volume includes the Muqaddima of one of Damascus’s senior living Ḥanafī jurists, Shaykh Wahbī Sulaymān Ghāwjī, which presents an up-to-date explanation of figurative interpretation in Islamic theology. The volume is also prefaced by another introduction, which catalogues the problematic positions of the redoubtable Ibn Taymiyya raised by scholars throughout the ages including his own students, regarding which a Dimashqī muḥaddith recently quipped: “The mistakes of the great are the greatest mistakes.”\nThis convenient Collectio Errorum by Shaykh Haddad is not a zero-sum critique. In fact, it will be appreciated for it isolates Ibn Taymiyya’s unquestionably controversial materials from the rest of his vast corpus – thus enabling one to take the good and leave the bad; and this list will be a service to the non-scholar who might want to benefit from reading the works of this prolific Ḥanbalī jurist, one who is now enjoying a greater following and who indeed can be said to be a phenomenon of present-day\nAlong with a work by an earlier Ḥanbalī theologian, the Daf’ Shubah al-Tashbīh of Ibn al-Jawzī (d. 597/1200), this medieval contribution by Ibn Jahbal remains one of the most important texts refuting the anthropomorphists of the Muslim world. This will be an indispensable reference for advanced students of Islamic theology, other professional theologians, and modern academics needing primary source materials in English or a source book on the controversies surrounding Ibn Taymiyya’s theology.\nThis same work embodies, moreover, a contemporary exercise in polemic representing the longstanding views in the conformist tradition of Muslim theology, whether via ta’wīl or tafwīḍ, and whether in the schools of the Ash’arīs, Māturīdīs or Ḥanbalīs. In particular, it pits itself against one of the two opposite non-conformist readings of the Qur’ān and Sunna; and in general, it highlights the pitfalls of a literalistic mindset which plagues all scripturally-based religions.\nMuhammad Afifi al-Akiti\nResearch Fellow in Islamic Theology\nOxford Centre for Islamic Studies', 'Notes on the Sociology of Religion (4)\nJohn C. Rankin\nAverroes (Ibn Rushd): On the Harmony of Religion and Philosophy (London, Trustees of the E.J.W. Gibb Memorial, 1976).\n- Background: Ibn Rushd, a/k/a Latinized name Averroes, 1126-1198 A.D.; Andalusian scholar and famous Islamic philosopher and polymath; born in Cordoba, died in Morocco; influenced by Avicenna (Ibn Seena, ca. 980-1037), Persian scholar and influence of neoplatonism; lived in both Almoravid and Almohad dynasties; banished to Morocco for rationalist views in contrast to ascendant Sufi mysticisms.\n- Commentator on Aristotle (in Arabic translations, which did not include Politics); jurist in the Maliki school.\n- Key work: The Incoherence of the Incoherence, defending Aristolelian philosophy against al-Ghazali’s claims in The Incoherence of the Philosophers; a) Al-Ghazali believed Aristotelianism, as represented in Avicenna, was inconsistent with and an affront to Islam; b) Averroes argued that Avicenna was a distortion and Al-Ghazali was wrong, thus aiming at the wrong target.\n- Nature of connection between religion (Islam) and philosophy: a ) if teleological study of the world (study of existing beings) = philosophy, then the Law commands it; b) Qur’an: “Reflect, you have vision”; c) the text is urging the study of the totality of beings; c) study of logic and religion go hand in hand; not heretical; d) nor is it heretical to study prior non-Muslim thinkers.\n- Means of study: a) demonstration (empirical data of the sciences); b) dialectical; c) rhetorical.\n- Obligation to “know various kinds of legal syllogisms”: a) it existed among first believers, and thus cannot be heretical; b) unexamined subjects merit de novo study; examined subjects require attention to their history first; c) analogy to study of geometry and astronomy.\n- Philosophy contains nothing opposed to Islam: a) if apparent meaning of Qur’an conflicts with the demonstrative, it must be interpreted allegorically; b) standard metaphorical practices of Arabic; c) all Muslims accept this – disagreement only comes concerning the extent of the application; d) double meanings and apparent contradictions are purposed for the learned (elite) to study deeper.\n- Allegorical interpretations must never violate Islamic consensus, when certain: a) unanimity on the theoretical not possible; only with the practical; b) distinction between apparent and inner meanings; c) debate over pre-eternity of the world and Allah’s knowledge of particulars = a debate over naming – created or self-existent + intermediate position of not created, but was brought into existence (ex nihilo?) + “So those who are more impressed with its resemblance to the pre-eternal than its resemblance to the originated name it ‘pre-eternal,’ while those who are more impressed with its resemblance to the originated name it ‘originated.’ But in truth it is neither really originated or pre-eternal, since the really originated is necessarily perishable and th erally pre-eternal has no cause” d) never a consensus against allegorical interpretations – thus freedom given here to the elite; e) “There are allegorical interpretations which ought not to be expressed except to those who are qualified to receive allegories”; f) “Their apparent meaning imply that the heavens were created from something”; h) theologians interpret this allegorically: “For it is not stated in Scripture that God was existing with absolutely nothing else”: i) a learned elite is excused for erring here; but not an unqualified person; j) central elitist/masses distinction: inexcusable for “lower classes” to interpret with allegory for texts w/apparent meanings; equals unbelief; k) double meaning in Qur’an (apparent v. inner) is for purpose of distinguishing the “demonstrative class” or “the best class or beings,” from the “lower classes”; l) in middle case, where there is no agreement as to whether a text is apparent or allegorical, liberty on secondary matters, but unity demanded on primary matters (e.g., the nature of the afterlife v. the existence of the afterlife); m) demonstrative books should be banned for the unqualified.\n- Prohibition of philosophical Interpretations of Qur’an to the majority: a) simple truths to the masses – right practices that yield happiness and misery, here and in the next life – Qur’an teaches directly; and by symbols (demonstrative, dialectical and rhetorical arguments; former accessible only to the elite; not everyone has “the ability to take in the demonstrations”); b) methods in religion are of four classes: 1. common – direct meaning without symbolism, 2. certain premises – admit of allegorical interpretation, 3. premises based on accepted ideas without being “accidentally certain,” and do not admit of allegorical interpretations, 4. premises based on accepted ideas and accidental certainty, but symbols are unclear; domain of the elite to interpret them allegorically, while the masses take them in their apparent meaning; c) the people in relation to the Qur’an are of three classes” – 1. rhetorical class = majority of people, not people of interpretation, 2. dialectical interpretation class = some people, by nature or habit, 3. demonstrative class = philosophic elite; d) “To explain the inner meaning to people unable to understand it is to destroy their belief in the apparent meaning without putting anything in its place. The result is unbelief in learners and teachers. It is best for the learned to profess ignorance, quoting the Qur’an on the limitations of man’s understanding” – 1. “Certain people have injured the masses particularly, by giving them allegorical interpretations which are false. These people are analogous to bad medical advisers”, 2. “As for the man who expresses these allegories to unqualified persons, he is an unbeliever on account of his summoning people to unbelief”, 3. “It was due to the wrong use of allegorical interpretations by the Mu’tazilites and Ash’arites that hostile sects arose in Islam” (calling unbelievers those who did not accept their methods, when they themselves, says Averroes, were the unbelievers), 4. There are proper methods for teaching the people, in the Qur’an, popular portions and not esoteric ones; e) “Summoning the masses to a middle way of knowing God the Glorious.”\n- Allah’s foreknowledge: a) “The problem: How can God be aware of a change in reality without a corresponding change occurring in His eternal Knowledge?”, and hence, the question of state of existence of these realities – in pre-eternity, eternity; b) “God’s foreknowledge of all change does not solve the problem, as the theologians think, for the actual occurrence of the change presumably adds something new to His Knowledge” and “Thus the difficulty is compelling. In sum, it can hardly be conceived that the knowledge of a thing before its exists can be identical with the knowledge of it after it exists”; c) “Nor is Ghazali’s solution satisfactory. He regards God’s Knowledge as a term in a relation, which does not change in itself when that to which it is related, the known object, changes its relation to it. But knowledge is a relation, not a related term”; d) answer lies in distinguishing cause and effect – “The correct solution is that the eternal Knowledge if the cause of all things, not their effect as originated knowledge is. Therefore It does not change when they change.”\n- The future life: Three interpretations of symbols of afterlife: a) the life beyond is the same in kind, but not limited in duration; b) it is different in kind, spiritual – suitable for the masses; c) it is corporeal in nature, but bodies are different – suitable only for the elite (Platonic nuances and immortality of the soul); d) this leads to three sects in Islam; d) where the apparent meaning is apparent, allegory is impermissible; e) where there is symbolism – 1. when it is difficult to distinguish between the symbol and the symbolized, only the educated elite may interpret allegorically, 2. when it is easy to know both the symbol and the symbolization, the masses are allowed to interpret allegorically, 3. when the symbol is unclear, but the symbolization is clear, only the educated elite can understand the true interpretation, and they must give an easy allegorical explanation for the masses, 4. when the symbol is clear, but the symbolization is unclear, it is preferable to deny the existence of symbolization (if made known, it will confuse the masses and lead to popular and erroneous); f) “It now remains for us out of our programme only to study what portions of Scripture it is permissible and what it is not permissible to interpret allegorically, and, when it is permissible, to whom permission is given” – 1. idea as outwardly expressed is the idea really intended, 2. Idea as outwardly expressed is not the idea really intended, thus need for i] reality only known through difficult composite syllogisms – elite, ii] Idea and symbol easily known – for the masses, iii] symbol easily perceived, but not so its reality – elite territory, iv] Easy to know it is a symbol, but difficult to know what it symbolizes – elite; g) “From our account you have now become aware of the amount of error that occurs as a result of allegorical interpretation.”\n- Observations: a) war between theology that divides Islam into sects, and proper use of philosophy which unifies the umma; b) unity gained through elitism of philosophers in deciding what the masses may learn and what they may not learn – 1. Plato’s philosopher-king. 2. Dostoevsky’s Grand Inquisitor; c). speculative nature rooted in confusion among masses when reading the Qur’an d) question of the nature of Allah and his knowledge relative to time, space and number, in terms of cause and effect: unidimensional or multidimensional?']	['<urn:uuid:64eb80ba-712d-4415-b488-8beb561b6883>', '<urn:uuid:223d7425-c82b-4bde-99fe-ec0116088408>']	factoid	with-premise	verbose-and-natural	distant-from-document	multi-aspect	novice	2025-05-01T23:21:14.341336	33	99	2271
272	scientific analytical methods significance historical ethiopian church art physical chemical analysis earliest christian illustrations world	Scientific analytical methods have revealed important information about Ethiopian Christian art. Physico-chemical techniques ranging from light microscopy to synchrotron-based X-ray diffraction have been used to identify pigments, binders, and artistic techniques in Ethiopian church paintings. These methods have proven particularly significant as they helped establish that the Garima Gospels, containing vivid Byzantine-style illustrations including the Jewish Temple in Jerusalem and various bird images, are potentially the oldest surviving illustrated Christian works in existence, dating between 330-650 AD, much earlier than the previously assumed 12th century date.	['Ethiopian Christian Paintings from a Physico-chemical Perspective: The Wall Paintings of Yemrehanna Krestos, Petros Paulos and Abune Yemata Guh Churches\nMetadataShow full item record\n- Institutt for kjemi \nSummary of thesis: During the past decades there has been an increasing application of scientific analytical methods in the area of conservation of cultural heritage objects and to address art historical and archaeometric questions. Heritage science and conservation science cover knowledge not only from the natural sciences and technology, but also humanities and art. The combination of these perspectives provides useful information about production of materials and technologies, provenance of raw materials and the objects themselves, authentication and dating. The insight acquired from the diverse disciplines contributes to the traditional art historical studies and well-informed conservation interventions. Ethiopia harbours a rich and unique Christian cultural heritage of importance not only to Ethiopians but also to humanity as the country represents one of the oldest states with the traditional Christian practices preserved and passed down over the centuries. This is witnessed by the intangible and tangible heritage continuously recognized as world heritage by UNESCO. Paintings in the form of murals, icons and manuscript illuminations are found among the numerous traditions associated with the Christian heritage. Nevertheless, there have been few studies on them and mostly from an art historical standpoint. Even fewer are the investigations from a physico-chemical perspective, and those that have been carried out are on the paintings in museums abroad. The conception of this thesis, and its presence here and now, is therefore a wish to contribute to fill this void. In this thesis wall paintings from three Ethiopian Churches dating from different periods are investigated using physico-chemical techniques ranging from light microscopy and X-ray fluorescence spectroscopy to synchrotron-based X-ray diffraction. All together, microscopic, spectroscopic, mass spectrometric and chromatographic methods were used. These complementary methods allowed identification of pigments, binders and artistic techniques employed. An investigation normally commenced with close-up visual examinations, at times using digital microscopes, and on-site non-destructive analysis with a portable X-ray fluorescence analyzer. This was followed by laboratory-based investigations on micro-samples collected. Synchrotron-based techniques from a large-scale accelerator facility have also been employed. As such this study represents the first exhaustive examination, using both on site and laboratory based instrumental techniques, of Ethiopian paintings situated in Ethiopia. In the thesis the major analytical techniques used are presented in a short review form highlighting their developments, advantages and drawbacks, as well as applications in the investigations of diverse paintings. An account of the nature of the fieldwork is also given. Though a number of murals, icons and illuminated manuscripts have been investigated, the emphasis in this thesis is the analysis of mural paintings of Yemrehanna Krestos Church using a portable X-ray fluorescence analyser, and physicochemical characterizations of the wall paintings of Petros Paulos and Abune Yemata Guh Churches using a combination of analytical techniques. These church paintings represent different periods and provenances. The studies aim to provide a slice of information from the scarcely studied tradition of Ethiopian painting and initiate further investigations. The current work adds to the knowledge about materials and artistic techniques of Ethiopian paintings. It extends the pool of data for comparative studies of painting materials and artistic techniques across periods and provenances within the country and beyond with other painting traditions. Moreover, the experience gained in the investigation of the complex, heterogeneous, and often highly degraded painting samples was found to be useful in characterization of other cultural heritage objects and archaeological materials.', 'Radiocarbon testing has revealed that a pair of illustrated gospels kept in a remote monastery in Ethiopia may have been made as early as the 4th century and are perhaps the oldest surviving illustrated Christian works in existence. The Garima Gospels were first reported on in the 1950s, but it has only been within the last couple of years that scholars have been able to examine the work and help conserve it.\nIn 2006 the British-based Ethiopian Heritage Fund began a project to examine the Garima Gospels, which have been kept at the Monastery of Abba Garima in northern Ethiopia for hundreds of years. Scholars were allowed to take two parchment fragments from the manuscripts, and testing at Oxford University revealed that they date back to somewhere between 330 and 650 AD. It had previously been believed that the texts were no older than the twelfth century. According to legend, the manuscripts were brought to Ethiopia from Constantinople by Abba Garima in the year 494.\nJacques Mercier, a French specialist in Ethiopian art, believes that the manuscripts may have been created around 600. Both of them contain several pages of vivid illustrations typical of early Byzantine style, which include a depiction of the Jewish Temple in Jerusalem, a portrait of Saint Luke, and images of over twenty different birds.\nMichelle Brown, a former British Library curator, tells the Art Newspaper that, “the Garima Gospels case vital light upon early Christian illuminated manuscript production and upon the role of sub-Saharan Africa…It is the sort of model the inspired such vibrant later Ethiopic art and is an important witness to the way in which the churches of the Christian Orient both absorbed the courtly Christian culture of Constantinople and developed their own voices and styles.”\nThe texts also received some conservation work, which was done in the monastery, as the texts were not allowed to leave its premises. Blair Priday of the Ethiopian Heritage Fund explained to the Daily Mail, “all the work on the texts was done in situ and everything is reversible, so if in future they can be taken away for further conservation we won’t have hindered that. The pages had been crudely stitched together in a restoration in the 1960s and some of the pages wouldn’t even turn. And they were falling to pieces. The Garima Gospels have been kept high and dry which has helped preserve them all these years and they are kept in the dark so the colours look fresh.”\nThe Ethiopian Heritage Fund was established in 2005 to undertake conservation of manuscripts and paintings in churches. They have worked on other medieval treasures, including two 15th century paintings of St. Mary. Priday added: ‘Ethiopia has been overlooked as a source of these fantastic things. Many of these old Christian relics can only be reached by hiking and climbing to remote monasteries as roads are limited in these mountainous regions.”\nWant more medieval? Take a look at our digital magazine – The Medievalverse – Click here to see our latest issues']	['<urn:uuid:e0542480-6ac9-49d1-aa53-73cd8eb52ccd>', '<urn:uuid:1ba90022-4560-4f37-9e2d-16e82bc8eb22>']	factoid	with-premise	long-search-query	distant-from-document	multi-aspect	expert	2025-05-01T23:21:14.341336	15	86	1087
280	when was panteon de mezquitan established	Panteón de Mezquitán was established in 1896	"['(Wikimedia Commons/TanyaCh Sa)\nTwo votive candles burn behind me.\nThese illuminate an ofrenda, a seasonal altar that occupies my living room. Assembling an ofrenda for Día de Los Muertos is an annual tradition, and this year, mine honors my family\'s Mexican matriarchs. On its lower tier, jars brim with flowers. Pink and orange tissue paper banners brighten the table. Incense spices the air while a cup of water offers relief to thirsty travelers. A dish of salt purifies and preserves. A picture of my grandmother Arcelia beautifies. A crucifix and rosary that belonged to my grandmother Esperanza evoke her long-suffering presence.\nOn the ofrenda\'s second tier, above a grinning clay itzquintli, a canine believed to chaperone souls to the afterlife, appears a sepia-toned studio portrait, a widow and her daughter dressed in Victorian garb. The widow, Narcisa, is my great-great grandmother. She sits, hands in her lap, peering at someone, or something, to the left of the camera. Felipa, my great grandmother, stands beside her, clutching a dainty purse.\nNext to their portrait rests a green-eyed sugar skull, his fedora hat, iced in pastel colors, tipped to one side. He represents Magdaleno, my great-great grandfather. Federal officers executed him during the Mexican Revolution.\nDuring childhood, my Mexican mother and Mexican American father taught my brother, sister and me about Día de Los Muertos, a religiously syncretic holiday that unites Catholic symbols, beliefs and practices with cosmologies indigenous to the Americas and Africa. Historically, this tradition has been observed in various parts of Mexico, including Oaxaca, Michoacán, Guanajuato and Jalisco, my mother\'s birthplace.\nCelebrating Día de Los Muertos, which falls on Nov. 2, was one way that I came to weave ancestral veneration into the fabric of my daily life, and I relished the lore narrated by parents and other family members regarding the spirits.\nI especially enjoyed stories involving the fate of food.\nFood items, including a seasonal bread, pan de muerto, may be placed on a home altar or taken directly to a loved one\'s gravesite. Their purpose is to nourish hungry souls, and my father told us of a doubtful aunt who dared question the usefulness of feeding the departed. To prove that ofrendas served no purpose, she snatched pan de muerto from an altar and gobbled it. In horror, she announced, ""It has no flavor!""\n""Of course, it has no flavor!"" her family admonished. ""The spirits enjoyed it! They sucked the taste right out of it!""\nMy mother was raised near the second-oldest cemetery in Guadalajara, Panteón de Mezquitán. Established in 1896, murals cover the high walls surrounding its terrain. Some of these artworks feature incarnations of Death herself, and, depending on the weather, one can find Mezquitán\'s graveyard dogs sunbathing, hiding from the rain or scratching mosquito bites. During my grandmother Arcelia\'s funeral procession, a yellow canine appeared beside her coffin. My mother nudged me.\n""It\'s your grandfather,"" she whispered. ""He\'s accompanying my mother.""\nA breeze rustled the palm trees. The gold dog trotted alongside my grandmother, chaperoning her across cobblestones, dirt and grass. The animal watched as cemetery workers lowered her casket. At last, my grandparents were reunited.\nPanteón de Mezquitán, Guadalajara, Mexico (Flickr/Enrique Vasquéz)\nMy mother tells me that as a child, she visited the graves of her ancestors and played in the cemetery. She says that she knew it was time to go to the cemetery when ants materialized everywhere, the proliferation of sugar skulls drawing them out of the ground.\nMy father also has childhood memories of Panteón de Mezquitán. He lived in Guadalajara until age 5 and recalls visiting the graveyard with an uncle. This relative found a human skull and sadistically chased my father through the headstones, terrorizing him.\nAlas, poor Yorick!\nThe last time I visited Guadalajara, it was shortly after All Souls\' Day. My beau and I strolled past the cemetery dogs, following the path to my family\'s tomb. The remnants of Día de Los Muertos surrounded us, the ghost of the holiday visible in all four directions. Faded and torn paper banners danced. Flowers wilted. Plush toys at children\'s graves oozed rainwater. Flies feasted on rotting fruit. Clearly, a party had happened.\nArriving at the tomb, the urge to hug my grandmother overwhelmed me. She had held me when I was a newborn, having taught my mother to swaddle me. Later, my grandmother, a portrait painter, taught me to make art and tell stories. I lay down on the blue slab covering her tomb and embraced the stone, sending love and appreciation to my grandmother. I thought of the white dress in which she was buried, how stunningly royal she looked at her viewing, her casket\'s glass pane letting us admire the graceful curve of her slumbering cheeks, her cloud of white curls resting against a pillow. I continue to honor my grandmother\'s creativity, placing a brush and tube of paint on my altar.\nThis essay is part of her ofrenda.\n*An earlier version of this essay incorrectly listed Día de Los Muertos as Nov. 1.']"	['<urn:uuid:53cb02e0-2f9c-40bc-9e01-192f2323dc94>']	factoid	direct	short-search-query	similar-to-document	single-doc	expert	2025-05-01T23:21:14.341336	6	7	839
284	I'm interested in Portuguese shoes - how did their industry survive China?	The Portuguese footwear industry survived China's 2001 WTO entry through thorough preparedness by entrepreneurs, supported by a strong active association and technological center that provided management and technical support, strengthened links between them, and stimulated coordinated actions.	['Browse by title\nEdited by Jean-Christophe Dissart and Natacha Seigneuret\nKatalin Erdős and Attila Varga\nHarvey Goldstein, Verena Radinger-Peer and Sabine Sedlacek\nResearch universities fill a variety of roles within contemporary society (Goldstein et al., 1995). Arguably the most important role has been providing advanced education to a segment of the population so that they have the requisite know-how to enter the professions. A second has been to generate knowledge through research that leads to scientific progress over time and indirectly often leads to productivity growth in the economy. These have been the traditional missions of research universities since their founding in the late nineteenth century.\nYuzhuo Cai, Po Yang and Anu Lyytinen\nThe literature on the role of universities in regional innovation systems mainly deals with research universities, for example, with an emphasis on knowledge transfer (Anatan, 2015). This is also the case in the Chinese context (Cai, 2018). In recent years, the importance of non-research universities in regional development and innovation has been increasingly recognized (Taylor et al., 2008). Among a small volume of studies exploring the role of universities of applied science (UASs), or non research universities, in the process of regional innovation, a constant challenge has been that of applying appropriate theoretical or analytical frameworks. Currently, most studies in this field apply theoretical insights originally developed for under standing the relationship between research universities and regional innovation systems. The most commonly used frameworks are, for instance, the Triple Helix model (Etzkowitz, 2008; Etzkowitz and Leydesdorff, 1995, 1997) for analysing the UASs and industry links (Yang et al., 2016), and the ‘five pathways to an entrepreneurial university’ (Clark, 1998) for understanding the organizational responses of UASs to the emerging demands of regional development (Lyytinen, 2011).\nEdited by John R. Bryson, Lauren Andres and Rachel Mulhall\nMaria Estela Ferreira\nThis chapter aims to illustrate the main outcomes and the characteristics and factors of the resilience of the footwear industry in the northern region of Portugal as performed in the last 30 years. This industry acts in a cluster located in a number of towns around Porto, within a maximum distance of 50 km from this city. Such cluster is responsible for more than 90 per cent of Portuguese footwear exports. Along the analyzed period, and among other difficulties, two main shocks are identified which the industry had to face: the full membership of China in the WTO, in 2001, which carried the delocalization of most foreign footwear companies, mainly to the Far East, and the sub-prime world crisis in 2008. The industry survived and surpassed these shocks thanks to a thorough preparedness sustained by the action of entrepreneurs, together with a strong and active association and a technological center, which provided management and technical support and strengthened links between them, stimulating coordinated actions. This chapter suggests, through a non-linear approach, that Portuguese footwear exports are about to reach the level they would have attained if China hadn’t joined the WTO.\nTüzin Baycan and Berna Sezen Özen\nThis chapter focuses on to what extend the innovation performance of EU countries has been affected by the global economic crisis and aims to investigate the relationship between the crisis and innovation performance while addressing the changes in the indicators of the Innovation Union Scoreboard Index after 2008. Focusing on these changes over the last ten years, the chapter compares and evaluates the innovation performance of EU countries and highlights which countries were more resilient in dealing with the recession.\nYannis Psycharis, Dimitris Kallioras and Panagiotis Pantazis\nThis chapter sets out to provide empirical evidence regarding the impact of economic crisis on the employment changes in the NUTS III Greek regions, during the period 2008_2012. With the application of trade-adjusted shift-share analysis, the chapter provides additional explanatory evidence on whether openness and trade have affected the resilience of regions. Results indicate that economic crisis has impacted asymmetrically on regional employment losses, leading to a widening of regional employment disparities. Construction and manufacturing have been hit severely by the crisis. Agriculture constitutes a resilient sector, while knowledge- and technology-intensive sectors are also more resilient to crisis. The less well-off regions dependent on more traditional sectors proved to be more resilient. However, trade relations and openness are offering as stabilizers to economic downturn.']	['<urn:uuid:cea5120a-f720-443d-ab9e-c129c5269d70>']	factoid	with-premise	concise-and-natural	distant-from-document	single-doc	novice	2025-05-01T23:21:14.341336	12	37	709
286	cancer research data storage safety issues	Cancer research involves massive amounts of genomic data storage and faces significant security challenges. The Cancer Genome Atlas alone has collected over 2.5 petabytes of data (equivalent to 530,000 DVDs) from over 11,000 tumors and 33 cancer types. While this data is crucial for developing personalized cancer treatments, storing and protecting it presents major cybersecurity concerns. Security experts warn that data storage systems are vulnerable to ransomware attacks, particularly from hackers in countries like Russia, China, and North Korea. The complexity of genomic data makes ensuring its accuracy and security especially challenging, as it involves numerous contributors worldwide inputting critical information that must be carefully verified and protected.	['Cancer genomics is a relatively new area of scientific study that lies at the heart of personalized medicine, an ever-expanding field of medical care aimed not merely at treating the external symptoms, but also at tackling disease on a tailor-made, cellular level. Here, we take a look at cancer genomics, including how it began, how people use it today, and how experts hope this innovation could pave the way for eradicating cancer completely.\nWhat is cancer genomics?\nYour genome is your complete set of DNA, which is present in every cell of your body. This DNA is divided into two groups of chromosomes—one from each of your parents. Each chromosome is composed of 6 billion DNA letters, which are grouped together in certain arrangements to form a genetic blue print that dictates your physical characteristics, such as height and eye color.\nGenomics is the study of the order, or sequence, of these DNA letters. Sometimes chromosomes contain a fault that can cause cells to generate proteins that prevent individual cells from working as they should. This can make cells grow very quickly and damage neighboring cells, resulting in a tumor.\nScientists study the cancer genome to gain a greater insight into the sequencing fault that causes cancer. Understanding the cancer genome is arguably the greatest breakthrough in 21st-century oncology, allowing experts to not only diagnose and treat patients, but, in some cases, to stop cancers from developing in the first place. In cases when individuals have a family history of certain cancers, genome mapping helps medical practitioners assess the risk of them developing those cancers in their lifetime and, in some cases, recommend precautionary steps they can take to reduce or eliminate their risk.\nHow did cancer genomics start?\nThe National Cancer Institute created the Cancer Genome Anatomy Project in 1997 with the aim of studying and documenting RNA sequences in tumor cells. In 2003, the organization released the largest collection of cancer expressed sequence tags ever made available to the public.\nIn 2005, the Sanger Institute founded the Cancer Genome Project, focusing primarily on DNA sequencing. The group published a registry of cancer-linked genes, as well as a selection of genome sequencing screens to detect genes implicated in cancer.\nA team of scientists founded the International Cancer Genome Consortium in 2007, with the aim of creating a central registry of genomic, epigenetic and transcriptomic data gathered from numerous research groups around the world. By the end of 2011, organization had amassed data from 2,961 cancer genomes.\nHow is cancer genomics helping people with cancer today?\nPersonalized cancer therapy involves using cellular-level diagnostics to customize the treatment to the individual. This groundbreaking innovation is slowly becoming available to the general public, though it is subject to stringent controls, regulation, and testing. Thus far, personalized cancer therapy has been used with success in the treatment of lung and skin cancer, and scientists believe that next-generation sequencing techniques will facilitate the taxonomy of tumors and the identification of biomarkers to predict responses to individualized therapy. Numerous genomic studies are currently being conducted by experts worldwide on a variety of different cancer types, including the following:\n- Breast cancer\n- Lung cancer\n- Bone cancer\n- Prostate cancer\n- Pancreatic cancer\nWhat are the limitations of cancer genomics?\nCancer is notoriously inconsistent and unpredictable—from patient to patient, tumor to tumor, and even on a cellular level within the same tumor. Moreover, genomic data is extremely complex. With each genome comprising billions of chromosomes, dredging data and making comparisons in the hope of finding correlations and markers is like looking for a needle in a haystack. With such a huge volume of data, the possibility for confusion and error is vast. Since the inception of the Human Genome Project, scientists have recognized the need for a central database in order to process this huge volume of data. Nevertheless, with data of such critical importance being entered by numerous contributors worldwide, ensuring the veracity and accuracy of that data as well as careful curation of the database as a whole is a monumentally difficult task.\nWhat role will cancer genomics play in finding a cure for cancer?\nScientists expect the Cancer Genome Atlas to play an integral role in the future of cancer research. This decade-long initiative has already amassed a huge archive, documenting information on over 11,000 tumors and 33 cancer types in 27 white papers cataloging the initiative’s findings. It has collected over 2.5 petabytes of data: the equivalent of 530,000 DVDs.\nThe Cancer Genome Atlas is an international collaboration with three primary goals:\n- To gain better insight on cancer on a cellular level\n- To derive original cellular taxonomies\n- To identify potential cellular therapeutic targets\nIn this way, experts hope the Cancer Genome Atlas will reveal markers and correlations pinpointing the various cancer types. This will enable experts to develop and deliver tailor-made medicine at a cellular level, in the hope of finally achieving an effective cure for cancer.', 'Employees who work from their homes may be putting their companies’ systems at risk.\n“Many employees do company work from personally managed and owned systems and these machines are often the ‘Wild, Wild West’ in terms of how they are secured,” said Mike Gentile, the chief executive of San Clemente-based cybersecurity company Cisoshare.\n“The majority of complex attacks, such as ransomware, etc., right now are still often caused by a simple phishing attack or an employee mistake like clicking on a bad link.”\nCisoshare is one of several cybersecurity firms that are emerging in Orange County, which is carving a strong position in internet security due to the proliferation of hackers from Russia, China and North Korea who demand eye-popping sums in ransomware.\nCrowdStrike Holdings Inc. (Nasdaq: CRWD), a Sunnyvale-based firm that now has a $55 billion market cap, started in Orange County where it still has a large local presence. Irvine’s Cylance sold for about $1.4 billion to BlackBerry in 2019 and also counts a base of operations here.\nIn Newport Beach, the ioXt Alliance started by Mobilitie founder Gary Jabara, wants to make sure the interconnections among the various devices used each day—such as cellphones, smart home lighting controls and automotive technology—are also secure.\nUC Irvine’s Cybersecurity Policy & Research Institute studies ways to make the internet and networks safer, including running mock attack drills. Cybercriminals\nIrvine-based Netwrix Corp. is expanding so quickly that it’s made four acquisitions since January.\n“Most organizations did not have time to prepare a transition plan and provide security training to the employees” when they started working from home last year, said Ilia Sotnikov, security strategist and vice president at Netwrix.\n“Hence the increase in reported incidents that included data loss or oversharing.”\nAttackers know that ransomware is arguably the quickest way to get money from a company without breaking into its system, he said.\n“The cybercriminals took advantage of the global pandemic and highly divisive political scene in the U.S. last year,” Sotnikov said. “We’ve seen considerable changes in how the threat landscape evolved over the last couple years with ransomware as a service, more specialized groups.”\nThe Coronavirus Chaos\n“There was so much chaos during the first few months of the lockdown that every CISO will need to go back and review all of the access and changes that happened,” said Bil Harmer, who is the chief information security officer (CISO) and chief evangelist at computer identity security software maker SecureAuth.\n“When there is chaos and change, the threat actors will be there looking for ways in.”\nHe predicted that companies “will begin putting more and more focus on digital identities and a continuous authentication methodology that will allow them to adjust access on the fly as the landscape or the user behavior changes.”\nCisoshare, founded by Gentile, placed No. 21 on this year’s Business Journal list of Best Places to Work in Orange County and No. 2 on last year’s list of fastest-growing companies, both in the small-firm category.\nCompanies who let employees work from their homes face an increasing threat level similar to that of an apartment owner who adds more apartments to a portfolio: the more units there are, the greater the business risks, Gentile said.\n“When employees are working from home, it expands the digital footprint and perimeter of the organization,” Gentile said during a recent interview.\nProviding security also requires using precious resources and talent—both of which are in short supply at plenty of companies, Gentile said.\n“The majority of security risk lives in the cracks when people don’t effectively collaborate and ‘cover all the bases’ when building something,” he said.\nTraining on workstations from which a network is accessed can reduce the risks when employees work from home in a decentralized environment, Gentile said.\nCompanies that opt for a “hybrid” model combining both work-from-home and the office should be wary.\n“Hybrid can be risky due to any time rules change, there is a higher likelihood of mistakes,” Kevin McDonald, the chief operating officer and chief information security officer of Alvaka Networks in Irvine lists 16 points of vulnerability. They include use of bootlegged software, browsing illicit sites, opening infected files that would otherwise be blocked, communicating with unverified individuals and illegal sharing of various contraband such as movies, images, and games.\n“Gambling, pornography, sports, gaming sites, alternative bulletin boards, messengers, even terrorism and extremist sites lead to infections of the host that then connects to the company,” he said.\n“We all suffer from a bit of that-won’t-happen-to-me syndrome. We’re not a target, we don’t have anything they want, we’re not that rich of a company.”\nHe says ransomware attackers are well aware of the potential payoffs: “One hit and you can retire.”\nCompanies are starting to nudge employees into coming to their offices though the daily back-and-forth from the COVID-19 Delta variant makes it difficult to set firm guidelines.\nFor example, data analytics software maker Alteryx Inc. has “voluntarily opened a number of our offices, including our Irvine location for those who are comfortable coming in,” Chief Financial Officer Kevin Rubin said on Aug. 5. “There’s no mandate that they do.”\n“We will more officially begin asking associates to start coming back no sooner than January,” he added.\nSotnikov sees some bright spots.\n“I think many of the WFH (work-from-home) specific dangers were mitigated over the last 12 months, as organizations had a chance to catch their breath, get new budgets in 2021, catch up on trainings for both admins and employees,” he said.\nThe Senate included more than $1.9 billion in cybersecurity funds as part of the roughly $1 trillion bipartisan infrastructure package, The Hill website said on Aug. 10.\nThe funds will go toward securing critical infrastructure against attacks, helping vulnerable organizations defend themselves and providing funding for a key federal cyber office, among other initiatives.\nExperts point to the targeting of Colonial Pipeline and JBS meat packers earlier this year as examples of the dangers of ransomware demands.\nThe picture is acute on the international front, with both Sotnikov and McDonald noting President Joe Biden’s warning last month that a significant cyber-attack on the U.S. could lead to “a real shooting war” with a major power, highlighting the growing threats posed by Russia and China.\n“That is a very aggressive and provocative statement,” McDonald said. He points to China in particular as he surveys global cybersecurity threats to the U.S.\n“I should be worried about China finally deciding it’s time to become the sole world power and using its understanding of our weak infrastructure to show us how much we don’t really have control of the world anymore,” McDonald said.\nAnd the ultimate piece of bad news?\n“Replacements are made in China,” he said.\nDangers, Positive Signs: OC Cybersecurity Experts Look at Internet Risks\nOC Cybersecurity Experts Give the Business Journal These Tips:\nKEVIN MCDONALD, chief operating officer/chief information security officer, Alvaka Networks in Irvine\nSome dangers are “removed or reduced” if the equipment is owned by the employer.\n“Employee-owned computers are far less likely to be patched and kept up-to-date against vulnerability. This includes the operating systems, office applications, third party applications such as Adobe, Internet browsers, etc.\n“Having a system shared with non-employees (of unknown behavior tendency, character, education, intent) means that there is a high potential for risky behaviors that can result in a compromised local computer.\n“Big time execs and powerful people are targets and they’re the most reticent to participate in this whole process.\n“Cryptocurrency is the “primary reason” for the rise in ransomware in which hackers hijack a computer system and demand payment to release it.”\nMIKE GENTILE, founder/chief executive, Cisoshare in San Clemente\nThe biggest risk to work from home or hybrid for security “is that collaboration and effective small team dynamics are hindered when people can’t work together in person.”\n“The good news is that some of the strongest safeguards when a workforce is decentralized is a strong security training and awareness program, as well as a communication system so employees know how to get in touch with the security team and vice versa. Both of these items are highly effective, but also much more inexpensive than almost all technical safeguards.”\nBIL HARMER, chief information security officer/chief evangelist, SecureAuth in Irvine\n“The hybrid model will not go away, there is far too much upside for companies in it. From 48 extra minutes per day per employee in productivity to reduced footprints in the office (desks, power, coffee, etc), this is a model that will continue.\n“Companies will begin moving to Secure Identity as the first line of defense. They will begin putting more and more focus on digital identities and a continuous authentication methodology that will allow them to adjust access on the fly as the landscape or the user behavior changes.\n“This will allow the user to move around the physical world and have their authentication and authorization adjust as they do to keep them within the acceptable risk profile.”']	['<urn:uuid:fda3608d-e8a5-4e62-8fc9-7e91022f7707>', '<urn:uuid:ad45c4f6-8fbd-4d17-b17d-404d81708d47>']	open-ended	with-premise	short-search-query	distant-from-document	multi-aspect	novice	2025-05-01T23:21:14.341336	6	108	2326
288	wisconsin ohio adopt kid age difference	In Wisconsin, you must be at least 21 years old to adopt a child, while in Ohio the minimum age requirement is 18 years old.	"['As a hopeful adoptive parent or pregnant mother considering adoption in the Badger State, you may feel overwhelmed by adoption processes, laws and qualifications. If you live in Milwaukee, Madison, Green Bay, or anywhere else in the state, read on to learn how to adopt or place a child for adoption in Wisconsin.\nLaws, Rules and Qualifications for Adopting a Child in Wisconsin\nEvery state has laws regulating the adoption process, from who can adopt to allowable adoption expenses. The following section provides information on basic laws and guidelines for adopting a baby in Wisconsin.\nWhat are the laws and qualifications for adopting a child in Wisconsin?\nAn unmarried adult, stepparent or husband and wife jointly may adopt in Wisconsin.\nWhat adoption expenses can be paid by adoptive families in Wisconsin?\nAdoptive families are permitted to pay the actual cost of the following:\n- Birth parent counseling\n- Maternity clothes up to $300\n- Transportation for the birth parents related to the pregnancy or adoption\n- Medical and hospital care in connection with the pregnancy and birth\n- Medical and hospital care received by the child\n- Legal services for the child and/or birth parents\n- Living expenses up to $5,000 if necessary to protect the health of the birth mother and baby\n- Birthing classes\n- A gift to the child’s birth mother, not to exceed $100 in value\n- The actual cost of services provided by a licensed child welfare agency\n- The cost of the home study investigation\nThe Department of Children and Families may charge a $75 fee to review, certify and approve foreign adoption documents.\nAn accounting of expenses must be provided to the court at the time of the hearing on the adoption petition. The report will include an itemized list of all transfers of anything of value made or agreed to be made in connection with the adoption. The list will show the goods or services for which each payment was made, as well as the date of each payment and the name and address of each attorney, doctor, hospital, agency or other professional receiving payment.\nWhat are the laws to become a foster parent in Wisconsin?\nProspective foster parents in Wisconsin must meet the following minimum qualifications:\n- Be at least 21 years old\n- Have sufficient income to cover your financial needs\n- Have enough room for the child\n- Complete training\n- Pass criminal background checks\n- Be in good physical and mental health\nFor more information about foster care in Wisconsin, visit the Wisconsin Department of Children and Families.\nWhat are the requirements to finalize an international adoption in Wisconsin?\nIf a Wisconsin resident adopts a child born outside of the United States, and if the adoptive parent presents proof of the facts of birth to the state registrar, the registrar will prepare a birth certificate for the adopted child indicating the child’s date and place of birth, adoptive name, the adoptive parents’ names and the source of information of each of these facts.\nIs it legal to use advertising or facilitators to adopt in Wisconsin?\nOnly the following may use advertising in connection with adoption:\n- The department, a county department or licensed child welfare agency\n- A person or agency providing information through the state adoption information exchange\n- A foster care and adoption or post-adoption resource center\n- An adoptive parent who has received a favorable recommendation from the department, a county department or licensed child welfare agency\n- A person seeking to place a child for adoption\nIt is a felony to place or agree to place a child for adoption in exchange for anything exceeding actual authorized costs. It is a felony to solicit, negotiate or arrange the placement of a child in exchange for anything of value. Adoptive parents may only pay the actual cost of legal and other services connected with the adoption in order to receive a child for adoption.\nLaws, Rules and Qualifications for Placing a Baby for Adoption in Wisconsin\nThere are many Wisconsin adoption laws in place to protect birth parents’ rights throughout the adoption process. If you are considering adoption for your child, it is important to understand the basic rules and regulations of placing a baby for adoption in Wisconsin.\nWhen and how can birth parents consent to the adoption?\nIn Wisconsin, birth parents must file a petition for voluntary termination of parental rights. A hearing will be held within 30 days of filing the petition, but not before the birth of the child. If the child is of Indian heritage, consent cannot be executed prior to or within 10 days after birth.\nThe parent must personally appear at the hearing to give his or her consent to termination of his or her parental rights. The court may also accept written consent given before an embassy official, military judge or a judge of any court. A birth father may consent to the adoption by signing a written, notarized statement saying he has been informed of and understands the effect of termination of parental rights and voluntarily relinquishes any rights he has to the child.\nIf the child is of Indian heritage, consent must be executed in writing, recorded before a judge and accompanied by a written certification by the judge that the consequences were fully explained in English or interpreted into a language that the parent understands.\nWho must consent to the adoption?\nThe child’s parents may consent to a voluntary termination of parental rights. The following people must be notified of any hearing for termination of parental rights:\n- The parent(s) of the child, unless the child’s parent has waived the right to notice\n- A man who has filed an unrevoked declaration of paternal interest before the birth of the child or within 14 days of the child’s birth\n- A man alleged to be the father based on information presented to the court, unless he has waived the right to notice\n- A man who has lived in familial relationship with the child and may be the father\n- The guardian or legal custodian of the child\nIf the child is age 12 or older, he or she must be notified to attend his or her adoption hearing.\nWhen is consent not needed?\nNotice of a hearing to terminate parental rights does not need to be sent to a man who may be the father of a child if he meets all of the following requirements:\n- He is not married to the child’s mother\n- His paternity has not been established\n- He failed to establish his right to notice\nIn addition, consent is not required from a parent whose rights have been terminated involuntarily. A parent’s rights may be terminated if the parent has abandoned or abused the child, the parent has failed to assume responsibility for the child or establish a relationship with the child, the parent caused the child’s conception as a result of incest or sexual assault, etc.\nWhen does the birth parents’ consent become irrevocable?\nA parent who has given consent may file a motion within 30 days of the entry of judgement or order terminating parental rights to withdraw consent based on the following grounds:\n- Mistake, surprise or excusable neglect\n- Newly discovered evidence that entitles the parent to a new trial\n- Fraud or misrepresentation\n- A voided judgment\n- A prior judgement upon which the judgment is based has been reversed or vacated\nWhat rights does the father of the baby have in Wisconsin adoptions?\nA man is considered to be the parent of a child if he is a biological parent, a husband who has consented to the artificial insemination of his wife, or a parent by adoption. A man is presumed to be the natural child of a father if he and the child’s mother have acknowledged paternity.\nAn unmarried man claiming to be the father of a child may file with the department a declaration of paternal interest. A declaration may be filed any time before the birth of the child or within 14 days after the child is born.\nHome Study and Post-Placement Requirements in Wisconsin\nOne of the most important steps for prospective adoptive and foster parents in Wisconsin is the home study. The home study determines whether prospective parents are able to provide a safe, nurturing home to a child. The following section answers common questions about the Wisconsin home study process.\nWhat is included in the Wisconsin home study process?\nThe Wisconsin home study includes the following:\n- Criminal background checks\n- Child abuse registry checks\n- Pre-adoptive training\nWho is included in the home study process?\nThe Wisconsin home study includes the adoptive parents and any other adults residing in the home.\nWho will conduct the home study?\nIf an agency has guardianship of the child, the agency will conduct the home study. In a relative adoption in which an agency does not have guardianship of the child, the department, a county department or a licensed child welfare agency will complete the home study. If the child is a foreign citizen and is under the guardianship of an individual, the agency that conducted the home study prior to the child’s entry into the United States will conduct the home study.\nOn what grounds will the home study not be approved in Wisconsin?\nThe home study may not be approved if the petitioner has been convicted of murder, homicide, battery, sexual assault or exploitation, child abuse or neglect, incest, child prostitution or child pornography.\nWhen should the home study be completed?\nThe court will order a home study investigation after an adoption petition is filed. The agency conducting the home study must file its report at least 10 days before the hearing on the petition.\nWhat are the post-placement study requirements for Wisconsin?\nThis issue is not addressed in Wisconsin adoption laws.\nWhat are the home study requirements for stepparent or relative adoptions in Wisconsin?\nIn a stepparent adoption, the department, a county department or a licensed child welfare agency will conduct an interview with the petitioner and check the petitioner’s background through public records, including those maintained by the department or any county department.\nWhat are the home study requirements to adopt a child from another state?\nIf a child born in Wisconsin is being placed in an adoptive home outside of the state, an appropriate agency in that state must complete the home study and ensure the adoptive placement meets the criteria established by that state’s laws. Any interstate placement is subject to the provisions of the Interstate Compact on the Placement of Children (ICPC).\nWhat are the requirements to adopt a child that is currently in my care?\nIf the adoptive parents have previously completed the home study and foster care licensing process, the agency will obtain criminal history and child abuse and neglect records checks.\nTo start the home study process, contact one of these trusted Wisconsin home study providers:\n- Adoption Choice\nAdoption Choice Inc. is a Wisconsin licensed nonprofit child placing agency with offices in Green Bay, Milwaukee and Madison. The agency provides services for international, domestic, independent, out-of-state, relative and stepparent adoptions.\n- Adoptions of Wisconsin\nAdoptions of Wisconsin, Inc. (AOW) is a full-service licensed adoption agency providing services for interstate, independent, stepparent, relative and LGBT adoptions, as well as home studies for embryo adoption.\n- Adoption Babylink (WI)\nAdoption Babylink is a licensed child-placing agency in Wisconsin and Georgia. The agency assists families with domestic and international home studies, home study updates and post-placement reports.\nVisit 1800HomeStudy.com to learn more about Wisconsin home study providers.\nWisconsin Adoption Professionals\nFor more information about adoption in Wisconsin or to begin the adoption process, contact one of these local adoption professionals:\nFor more information about foster care in Wisconsin, visit the Wisconsin Department of Children and Families.\nThings to do in Wisconsin\nWhether you find yourself in the Badger State for visits with prospective birth parents or you’re waiting for ICPC approval, here are a few fun places for adoptive families to visit in Wisconsin:\n- Olbrich Botanical Gardens (Madison)\n- Wisconsin State Capitol (Madison)\n- Peninsula State Park (Fish Creek)\n- Devil’s Lake State Park (Baraboo)\n- Harley-Davidson Museum (Milwaukee)\n- Bay Beach Amusement Park (Green Bay)\n- Cave Point County Park (Sturgeon Bay)\nMore information about visiting Wisconsin is available at http://www.travelwisconsin.com/.', ""If you’re contemplating becoming a foster parent or adoptive parent, no doubt you have questions about how the foster care and foster-to-adoption process in Ohio works, including parental qualifications and the home study process.\nFor your convenience, Summit County Children Services has listed the most frequently asked questions and answers regarding the foster care and adoption process. If you have additional questions, please feel free to call the Adoption and Foster Care Inquiry Line at (330) 379-1990.\nHow old do you need to be?\nYou must be at least 18 years old to become a foster parent and to adopt a child.\nDo you have to earn a certain income?\nNo, there is no income requirement. You must be able to meet your current household needs.\nDo you have to be married?\nNo, you can be married, single, divorced, widowed or be a co-parent.\nDo you have to own your own home?\nNo, you can rent. But you must have adequate space available and your landlord’s approval to care for foster children.\nCan you be a foster parent if you work?\nYes. Extra help for the cost of child care may be available.\nDo foster children have to have separate bedrooms?\nNo, but each child must have a separate bed. Foster children cannot have a bedroom in the attic or basement. After age five, boys and girls must sleep in separate rooms.\nHow many foster children can I take?\nFor the first two years, licensed foster parents may take up to three foster children. After two years of service, they may take up to five children with a total of 10 children maximum including your own children, foster children and any children for whom you provide care.\nCan a foster parent request specific ages or sex of foster children?\nYou may ask for the age and gender of children you think would fit in best with your family situation and needs.\nCan I be a foster parent if I have a criminal record?\nPossibly, each situation would be reviewed under the Ohio Department of Jobs and Family Services rules for family foster care. If it is found that the person’s criminal record meets the rehabilitation requirements of the State of Ohio rules, then the person could be considered as a potential foster parent. All adult household members must have a criminal background check.\nWhat happens after training is completed?\nOnce you have completed the required pre-service training AND completed and turned in all required paperwork, you will fill out and submit an application. Some of the required paperwork includes: a fire inspection and safety audit of the home, a medical statement from a doctor for each member of the family, and police checks and fingerprints for all adults in the household. Then a social worker, known as a Licensing Specialist, will be assigned to begin the home study process.\nWhat is the home study?\nThe home study is a process that involves information sharing and gathering for the purpose of determining an applicant’s suitability in meeting the general criteria to be licensed and/or approved as a foster or foster-to-adopt parent based on state and agency eligibility requirements.\nThe home study is a detailed process that involves all household members. During the home study, all family members will be interviewed by the Licensing Specialist. The process affords applicants the opportunity to assess whether or not foster care and/or adoption is the appropriate option for their family. The home study process also provides the applicants and the agency an opportunity to mutually assess which child(ren) in the agency’s care the applicants are best suited to parent.\nWho will do my home study?\nOnce your completed application and required paperwork have been submitted, a social worker, referred to as a Licensing Specialist, will be assigned to begin the home study process. All Licensing Specialists have received specialized Adoption Assessor Training that qualifies them to conduct home studies.\nHow long does all this take?\nThe home study process usually takes three to six months.\nWhen can I have foster children come to my home?\nAfter your home study has been completed and approved, the agency recommends the family to the Ohio Department of Jobs and Family Services for licensing. When you receive your license, the agency can begin placing foster children with your family.\nWhat kind of assistance does the agency provide to foster parents in caring for children?\nFoster parents receive a reimbursement check each month for the care of each child. This reimbursement check may include child care assistance if a foster parent is employed. Foster parents also receive mileage reimbursement and are provided with ongoing training opportunities. Medical care is provided for foster children at Akron Children's Hospital. A foster home coordinator is also assigned to each foster home to provide personal support. The agency also offers regular support group meetings for foster parents.\nCan I adopt a child of a different race?\nYes. We do not discriminate on the basis of race, color, national orientation, sexual orientation, age or gender. All of our available children will be placed with the family who can best meet their needs.\nWhat is meant by children with “special needs”?\nIn adoption, “special needs” include a wide variety of characteristics. This could simply include children of a minority race, sibling groups, and older children. It could also include a child with a medical condition, developmental disability, behavioral problem, or even a child who has been in permanent custody for more than a year. What all these children have in common is a “special need” to become part of a caring family.\nAre there babies or young children available for adoption at Summit County Children Services?\nThe highest number of children coming into the care of Children Services is children under age two. Many of these children become available for adoption. However, they are typically adopted by their foster parents who have cared for them during the reunification process. At Summit County Children Services, you must become a foster parent if you want to adopt. Training and counseling are available to assist you in deciding if foster-to-adopt parenting is right for you and your family.\nFor more information about the foster care or foster-to-adopt process, fill out our Foster Care & Adoption Inquiry form or contact:\nSummit County Children Services\nTelephone: (330) 379-1990\nFax: (330) 379-1924""]"	['<urn:uuid:0112c321-06d1-4d04-b178-6ae1aae877a7>', '<urn:uuid:eab4bb46-bca3-48fd-b349-8c11ad6890e8>']	factoid	with-premise	short-search-query	distant-from-document	comparison	expert	2025-05-01T23:21:14.341336	6	25	3133
291	What makes Neptune blue and how hot is it?	Neptune's blue color comes from atmospheric methane absorbing red light, though its particularly dark and vivid blue hue is thought to involve some unknown atmospheric constituent. Despite being far from the Sun, Neptune has unusually high temperatures - its thermosphere reaches about 750 K (476.85°C). The planet actually emits 2.6 times more energy than it receives from the Sun, making it glow even without solar input. At the cloud tops, however, temperatures can be extremely cold, reaching minus 260 degrees Fahrenheit.	"['The gas giant planet Neptune takes center stage in a series of sharp new photos snapped by the Hubble Space Telescope in honor of the blue-green world\'s first Neptunian year around the sun since it was discovered in 1846.\nYesterday, Neptune completed its first trip around the sun since being discovered nearly 165 Earth years ago — on Sept. 23, 1846, to be exact, by German astronomer Johann Galle.\nNeptune takes about 165 years to complete one orbit around the sun. It is about 30 times farther from the sun than Earth and typically orbits at a distance of about 2.8 billion miles (4.5 billion kilometers). [Photos of Neptune: Latest Hubble and Voyager Views]\nBig, blue Neptune\nThe four new Hubble photos show Neptune in stunning detail.\nThe images were taken about four hours apart and show the planet as it appeared between June 25 and 26 over the course of a single Neptunian day, which lasts about 16 hours, yielding a complete view of the distant world.\nIn a photo description, scientists said the new Hubble photos revealed more high-altitude clouds on Neptune than those seen in recent observations within the last few Earth years.\nThe clouds are composed of methane ice crystals and hover over parts of Neptune\'s northern and southern hemisphere, Hubble scientists said.\nLike Earth, Neptune spins on a tilted axis, which gives the planet its own set of seasons. Earth\'s axis is tilted about 23 degrees, but Neptune has a more pronounced 29-degree tilt.\nWhile Earth\'s seasons tend to last a few months each, a single season on Neptune runs for about 40 Earth years, scientists explained. Currently it is early summer in Neptune\'s southern hemisphere and winter in the north, they added.\nThe large temperature differences between Neptune\'s warm interior and its super-chilly cloud tops, which can reach minus 260 degrees Fahrenheit (minus 162 Celsius), may be responsible for large-scale weather changes, Hubble scientists said.\nDiscovering the eighth planet\nThe story of Neptune\'s discovery in the 19th century is unique among the planets of the solar system. It was the first planet to be discovered using mathematics, with astronomers predicting Neptune\'s position after observing that the orbit of Uranus — the seventh planet from the sun — did not exactly match up with Newton\'s theory of gravity.\nAccording to NASA, it was the French astronomer Alexis Bouvard in 1821 who first speculated that another planet was tugging on Uranus and tweaking its orbit. By 1841, mathematician-astronomers Urbain Le Verrier of France and John Couch Adams of England had each independently predicted the location of this mystery planet.\nLe Verrier passed the information on to the man who would actually discover Neptune — German astronomer Johann Gottfried Galle of the Berlin Observatory — and Galle spotted the planet less than a degree from its predicted location during a two-night campaign in September 1846.\n""The discovery was hailed as a major success for Newton\'s theory of gravity and the understanding of the universe,"" Hubble scientists said.\nStill, while Galle is credited as Neptune\'s discoverer, he wasn\'t the first person to actually see the planet.\nIn December 1612, the famed astronomer Galileo Galilei recorded an observation of Neptune, which he described as a ""star"" in his notebook while making observations using a handmade telescope, Hubble officials said. Later, in January 1613, Galileo noticed that the so-called ""star"" had shifted position in relation to other stars, but he never actually identified the object as a planet or followed up that initial observation.\nThat leaves the honor of Neptune\'s discovery securely with Galle.\nNeptune is so far away that it cannot be seen with the unaided eye. A small telescope or binoculars can resolve the planet. Currently, Neptune can be found in constellation Aquarius, close to the boundary with Capricorn, Hubble officials said.\nPhoto: NASA, ESA, and the Hubble Heritage Team\nThis article was reprinted with permission from SPACE.com.\nRelated on SPACE.com:\n- Top 10 Extreme Planet Facts\n- Perplexing Neptune: Our Outermost Major Planet\n- Solar System Explained From the Inside Out\nAlso on MNN:', ""As a gas giant (or ice giant), Neptune has no solid surface. In fact, the blue-green disc we have all seen in photographs over the years is actually a bit of an illusion. What we see is actually the tops of some very deep gas clouds, which in turn give way to water and other melted ices that lie over an approximately Earth-size core made of silicate rock and a nickel-iron mix. If a person were to attempt to stand on Neptune, they would sink through the gaseous layers.\nAs they descended, they would experience increased temperatures and pressures until they finally touched down on the solid core itself. That being said, Neptune does have a surface of sorts, (as with the other gas and ice giants) which is defined by astronomers as being the point in the atmosphere where the pressure reaches one bar. Because of this, Neptune’s surface is one of the most active and dynamic places in entire the Solar System.\nComposition and Structure:\nWith a mean radius of 24,622 ± 19 km, Neptune is the fourth largest planet in the Solar System. But with a mass of 1.0243 × 1026 kg – which is roughly 17 times that of Earth – it is the third most massive, outranking Uranus. Due to its smaller size and higher concentrations of volatiles relative to Jupiter and Saturn, Neptune (much like Uranus) is often referred to as an “ice giant” – a subclass of a giant planet.\nAs with Uranus, the absorption of red light by the atmospheric methane is part of what gives Neptune its blue hue, although Neptune’s is darker and more vivid. Because Neptune’s atmospheric methane content is similar to that of Uranus, some unknown atmospheric constituent is thought to contribute to Neptune’s more intense coloring.\nAlso like Uranus, Neptune’s internal structure is differentiated between a rocky core consisting of silicates and metals; a mantle consisting of water, ammonia and methane ices; and an atmosphere consisting of hydrogen, helium and methane gas. It’s atmosphere is also divided into four layers, consisting of (from innermost to outermost) the lower troposphere, the stratosphere, the thermosphere and the exosphere.\nThe two main regions of Neptune’s atmosphere are the two innermost ones: the lower troposhere, where temperatures decrease with altitude; and the stratosphere, where temperature increases with altitude. Within the troposphere, pressure levels range from one to five bars (100 and 500 kPa), hence the surface of Neptune is defined as being within this region.\nNeptune’s “surface” can therefore be said to be composed of about 80% hydrogen and 19% helium, with a trace amount of methane. The surface layer is also permeated by roving bands of clouds with varying compositions, depending on altitude and pressure. At the upper-level, temperatures are suitable for methane to condense, and the pressure conditions are such that clouds consisting of ammonia, ammonium sulfide, hydrogen sulfide and water can exist.\nAt lower levels, clouds of ammonia and hydrogen sulfide are thought to form. Deeper clouds of water ice should be also found in the lower regions of the troposphere, where pressures of about 50 bars (5.0 MPa) and temperature of 273 K (0 °C) are common.\nFor reasons that remain obscure, the planet’s thermosphere experiences unusually high temperatures of about 750 K (476.85 °C/890 °F). The planet is too far from the Sun for this heat to be generated by ultraviolet radiation, which means another heating mechanism is involved – which could be the atmosphere’s interaction with ion’s in the planet’s magnetic field, or gravity waves from the planet’s interior that dissipate in the atmosphere.\nBecause Neptune is not a solid body, its atmosphere undergoes differential rotation. The wide equatorial zone rotates with a period of about 18 hours, which is slower than the 16.1-hour rotation of the planet’s magnetic field. By contrast, the reverse is true for the polar regions where the rotation period is 12 hours.\nThis differential rotation is the most pronounced of any planet in the Solar System, and results in strong latitudinal wind shear and violent storms. The three most impressive were all spotted in 1989 by the Voyager 2 space probe, and then named based on their appearances.\nThe first to be spotted was a massive anticyclonic storm measuring 13,000 x 6,600 km and resembling the Great Red Spot of Jupiter. Known as the Great Dark Spot, this storm was not spotted five later (Nov. 2nd, 1994) when the Hubble Space Telescope looked for it. Instead, a new storm that was very similar in appearance was found in the planet’s northern hemisphere, suggesting that these storms have a shorter life span than Jupiter’s\nThe Scooter is another storm, a white cloud group located farther south than the Great Dark Spot. This nickname first arose during the months leading up to the Voyager 2 encounter in 1989, when the cloud group was observed moving at speeds faster than the Great Dark Spot. The Small Dark Spot, a southern cyclonic storm, was the second-most-intense storm observed during the 1989 encounter. It was initially completely dark; but as Voyager 2 approached the planet, a bright core developed and could be seen in most of the highest-resolution images.\nFor reasons that astronomers are still not clear on, the interior of Neptune is unusually hot. Even though Neptune is much further from the Sun than Uranus and receives 40% less sunlight, its surface temperature is about the same. In fact, Neptune gives off 2.6 times more energy than it takes in from the Sun. Even without the Sun, Neptune glows.\nThis high amount of interior heat matched with the coldness of space creates a huge temperature difference. And this sets the winds blasting around Neptune. Maximum wind speeds on Jupiter can be more than 500 km/hour. That’s twice the speed of the strongest hurricanes on Earth. But that’s nothing compared to Neptune. Astronomers have calculated winds blasting across the surface of Neptune at 2,100 km/hour.\nDeep down inside Neptune, the planet might have an actual solid surface. At the very core of the gas/ice giant is thought to be a region of rock with roughly the mass of the Earth. But temperatures at this region would be thousands of degrees; hot enough to melt rock. And the pressure from the weight of all the atmosphere would be crushing.\nIn short, there is simply no way one could stand on the “surface of Neptune”, let alone walk around on it.\natmosphere, atmosphere layers, atmosphere of neptune, core, gas giant, great dark spot, ice giant, Jupiter's great red spot, mantle, Neptune, scooter, small dark spot, surface, surface of Neptune, surface temperature of Neptune, Voyager 2""]"	['<urn:uuid:f39dc8ed-678a-461b-8c43-24fff47a28f1>', '<urn:uuid:150e5e94-8a31-43dc-975b-51e8b9274210>']	open-ended	direct	concise-and-natural	distant-from-document	multi-aspect	novice	2025-05-01T23:21:14.341336	9	81	1785
292	what was role ra egyptian god	Ra was the sun god and the most important deity in ancient Egyptian religion. According to creation myths, Ra emerged from an egg on the surface of primordial waters and brought forth four children who became the atmosphere, earth, and sky. Ra was consistently worshipped throughout Egyptian history and early kings claimed descent from him. During the Middle Kingdom (2040-1640 BC), Ra worship became the state religion. Later, Ra was combined with another god to become Amon-Ra, the supreme deity. Ra was typically depicted with a hawk's head, as the hawk was sacred to him due to its swift flight across the sky.	"['The religious beliefs of the ancient Egyptians were the dominating influence in the development of their culture. The Egyptian faith was based on a collection of ancient myths, nature worship, and innumerable deities. In the most influential and famous of these myths a divine hierarchy is developed and the creation of the earth is explained.\nAccording to the Egyptian account of creation, only the premordial waters existed at first. Then Ra, the sun, came out of an egg (a flower, in some versions) that appeared on the surface of the water. Ra brought forth four children, the gods Shu and Geb and the goddesses Tefnut and Nut. Shu and Tefnut became the atmosphere. They stood on Geb, who became the earth, and raised up Nut, who became the sky. Ra ruled over all. Geb and Nut later had two sons, Set and Osiris, and two daughters, Isis and Nephthys. Osiris succeeded Ra as king of the earth, helped by Isis, his sister-wife. Set, however, hated his brother and killed him. Isis then embalmed her husband\'s body with the help of the god Anubis, who thus became the god of embalming. The powerful charms of Isis resurrected Osiris, who became king of the netherworld, the land of the dead. Horus, who was the son of Osiris and Isis, later defeated Set in a great battle and became king of the earth.\nFrom this belief of creation came the conception of the ennead, a group of nine divinities, and the triad, consisting of a divine father, mother, and son. Every local temple in Egypt possessed its own ennead and triad. The greatest ennead, however, was that of Ra and his children and grandchildren. This group was worshiped at Heliopolis, the center of sun worship. The origin of the local deities is obscure; some of them were taken over from foreign religions, and some were originally the animal gods of prehistoric Africa. Gradually, they were all fused into a complicated religious structure, although comparatively few local divinities became important throughout Egypt. In addition to those already named, the important divinities included the gods Amon, Thoth, Ptah, Khnemu, and Hapi, and the goddesses Hathor, Mut, Neit, and Sekhet. Their importance increased with the political ascendancy of the localities where they were worshiped. For example, the ennead of Memphis was headed by a triad composed of the father Ptah, the mother Sekhet, and the son Imhotep. Therefore, during the Memphite dynasties, Ptah became one of the greatest gods in Egypt. Similarly, when the Theban dynasties ruled Egypt, the ennead of Thebes was given the most importance, headed by the father Amon, the mother Mut, and the son Khonsu. As the religion became more involved, true deities were sometimes infused with human beings who had been glorified after death. Thus, Imhotep, who was originally the chief minister of the 3rd Dynasty ruler Djoser, was later regarded as a demigod. During the 5th Dynasty the pharaohs began to claim divine ancestry and from that time on were worshiped as sons of Ra. Minor gods, some merely demons, were also given places in local divine hierarchies.\nThe Egyptian gods were represented with human torsos and human or animal heads. Sometimes the animal or bird expressed the characteristics of the god. Ra, for example, had the head of a hawk, and the hawk was sacred to him because of its swift flight across the sky; Hathor, the goddess of love and laughter, was given the head of a cow, which was sacred to her; Anubis was given the head of a jackal because these animals ravaged the desert graves in ancient times; Mut was vulture headed and Thoth was ibis headed; and Ptah was given a human head, although he was occasionally represented as a bull, called Apis. Because of the gods to which they were attached, the sacred animals were venerated, but they were never worshiped until the decadent 26th Dynasty. The gods were also represented by symbols, such as the sun disk and hawk wings that were worn on the headdress of the pharaoh.\nThe only important god who was worshiped with consistency was Ra, chief of cosmic deities, from whom early Egyptian kings claimed descent. Beginning with the Middle Kingdom (2040-1640 BC), Ra worship acquired the status of a state religion, and the god was gradually fused with Amon during the Theban dynasties, becoming the supreme god Amon-Ra. During the 18th Dynasty the pharaoh Amenhotep III renamed the sun god Aton, an ancient term for the physical solar force. Amenhotep\'s son and successor, Amenhotep IV, instituted a revolution in Egyptian religion by proclaiming Aton the true and only god. He changed his own name to Akhenaton, meaning ìHe who is devoted to Aton.î This first great monotheist was so iconoclastic that he had the plural word gods deleted from monuments, and he relentlessly persecuted the priests of Amon. Akhenaton\'s sun religion failed to survive, although it exerted a great influence on the art and thinking of his time, and Egypt returned to the ancient, labyrinthine religion of polytheism after Akhenaton\'s death.\nBurying the dead was of religious concern in Egypt, and Egyptian funerary rituals and equipment eventually became the most elaborate the world has ever known. The Egyptians believed that the vital life-force was composed of several psychical elements, of which the most important was the ka. The ka, a duplicate of the body, accompanied the body throughout life and, after death, departed from the body to take its place in the kingdom of the dead. The ka, however, could not exist without the body; every effort had to be made, therefore, to preserve the corpse. Bodies were embalmed and mummified according to a traditional method begun by Isis, who mummified her husband Osiris. In addition, wood or stone replicas of the body were put into the tomb in the event that the mummy was destroyed. The greater the number of statue-duplicates in his or her tomb, the more chances the dead person had of resurrection. As a final protection, exceedingly elaborate tombs were erected to protect the corpse and its equipment.\nAfter leaving the tomb, the souls of the dead may be beset by innumerable dangers, and the tombs were therefore furnished with a copy of the Book of the Dead. Part of this book, a guide to the world of the dead, consists of charms designed to overcome these dangers. After arriving in the kingdom of the dead, the ka was judged by Osiris, the king of the dead, and 42 assistants. The Book of the Dead also contains instructions for proper conduct before these judges. If the judges decided the deceased had been a sinner, the ka was condemned to hunger and thirst or to be torn to pieces by horrible executioners. If the decision was favorable, the ka went to the heavenly realm of the fields of Yaru, where grain grew 3.7 m (12 ft) high and existence was a glorified version of life on earth. All the necessities for this paradisiacal existence, from furniture to reading matter, were, therefore, put into the tombs. As a payment for the afterlife and his benevolent protection, Osiris required the dead to perform tasks for him, such as working in the grain fields. Even this duty could, however, be obviated by placing small statuettes, called ushabtis, into the tomb to serve as substitutes for the deceased.\nThe mummy and coffin of Meresamun are excellent examples of the skill of the ancient embalmer and coffin maker of Dynasty 22, about the year 950 B.C. Where Meresamun lived and died is unknown, although the style of the coffin suggests that she was originally from the Theban (modern Luxor) area. Meresamun\'s form-fitting sheath-like coffin is made of cartonnage, a type of papiÈr-m’chÈ, composed of layers of fabric, glue and plaster. It is 63 inches (1.6m) long. Cartonnage coffins were formed over a temporary inner core made of mud and straw. After the coffin shell was completed, the wrapped mummy was inserted into the case through the back, and the back seam was then laced up. The separate footboard was laced on, the entire case covered with another layer of thin white plaster and then painted. The colored areas of the coffin were painted with a final layer of protective varnish which has turned slightly yellow with age. This type of mummy case was normally part of a more complex set of coffins. It would probably have been placed within a wooden anthropoid (human-shaped) coffin, or even in a series of two or three nested coffins, all of which would have been painted with religious scenes.\nThe coffin is painted with scenes which allude to life after death. They were intended to ensure Meresamun\'s successful rebirth. The head of the coffin is decorated with a headband of flower petals with wings of a protective vulture by each cheek, and a small vulture head on the forehead. This type of headgear is worn by queens, priestesses and goddesses. Over the chest are layers of wide floral necklaces. Not only were flowers beautiful and sweet smelling, but they were considered to symbolize regeneration. Below the floral collars, right and left, are two pairs of gods who were entrusted with the protection of the internal organs that were removed during the mummification process. These gods also appear on the lids of canopic jars, the containers in which the embalmed viscera were stored. Here the gods appear as wrapped mummies. To the right are the hawk-headed god, Quebehsenuef, who guarded the intestines, and the jackal-headed Duamutef, who guarded the stomach. To the left is the human-form Imseti, who guarded the liver, and the ape-headed Hapy, who guarded the lungs. Between and slightly below these gods is a large representation of the falcon god Horus (or, perhaps, Re), with the sun\'s disk on his head, clasping a round shen (""eternity"") sign in each talon. A feather fan, a symbol of divinity emerges from each shen sign. The solar Horus, as a symbol of the eternally reborn sun, signified rebirth.\nOn either side of the central band on the leg area of the coffin are wedjat eyes, also called the ""Eye of Horus,"" which symbolized health and regeneration. Behind the eyes are winged serpents with sun disks on their heads. They symbolized protection. The serpent to the right hovers above the hieroglyphs for eternity, life and dominion. Below the serpents are rams which functioned on several different levels. They may be a pun for the word ""soul"" (both the word ""soul"" and ""ram"" sounded the same in the ancient Egyptian language). The ram may also be the god Khnum, one of the primary creator gods, or Banebdjed, who was associated with the soul of Osiris, one of the deities of the Afterlife. Larger scale hieroglyphs cover the lower leg area. To the far right is the symbol for the west, the area of the setting-or dying-sun, which was associated with the land of the deceased. Between that sign and the central band of hieroglyphs is the djed pillar, which symbolized the backbone of the god Osiris, the main deity of the Afterlife. The djed indicates the deceased\'s association with Osiris in the Afterlife.\nOn the opposite side of the central band of hieroglyphs is the tiet (so-called ""Isis knot""), a symbol with broad meaning, generally associated with health and well-being. To the left of the tiet is the symbol for the east, the realm of the reborn sun, hence the land of the living. It is paired with the djed, the symbol of the god Osiris, the husband/brother of Isis, to create a balanced composition.\nTwo images of the jackal god Wepwawet, protector of the necropolis, decorate the upper surface of the feet. The footboard of the coffin is decorated with a leaping bull, a symbol of fertility. The inscription down the front of the coffin is a prayer which calls upon gods to give Meresamun offerings in the Afterlife: ""A gift which the king gives to Re-Horakhty-Atum, Lord of the Two Lands and Heliopolis [and to] Ptah-Sokar-Osiris, Lord of Shechet, and Wennefer (a form of Osiris), Lord of the Sacred Land (ie: the Necropolis), the Great God, Lord of Heaven that he [the king] may give funerary offerings to the Osiris, the Singer in the Interior of the Temple of Amun, Meresamun, the One Beneficial to Amun, justified.""\nBoth the inscription and the style of coffin indicate that it was made for a woman named Meresamun (""She Lives for Amun""). According to the inscription, she held the title ""Singer in the Interior of the Temple of Amun."" Women who held this title were the elite in a complex bureaucracy of many other women who held the title ""Singer in the Temple of Amun."" We assume that these other women performed music during certain temple rituals on a part-time basis. In contrast, many of the women like Meresamun, who held the more exalted title ""Singer in the Interior of the Temple,"" were known to come from the finest families of Thebes. Some of them served as valets or stewards to members of the ruling family. It is not known exactly when Meresamun lived, and so we do not know which royal administration she may have served.\nThe coffin has never been opened and the mummy has never been unwrapped. In 1989, a preliminary study of the mummy within the coffin was done with x-rays. Three years later, the mummy of Meresamun was examined at the University of Chicago hospitals by CT scans (computed tomography or ""CAT""). During that study, the radiologist suggested that, on the basis of her teeth and bones, Meresamun may have been about 30 years old at the time of her death. This was not considered to be an old age for an upper class woman of the period; however we do not know the cause of Meresamun\'s premature death. Radiologists could also determine that she had, at some point in her life, been injured, for her left jaw and left arm had been fractured. However, those injuries were completely healed at the time of her death. A swelling on her neck may be a goiter or tumor, however this cannot with any certainty be associated with her death. A preliminary study of the CT scans suggest that Meresamun never bore children. This finding is not necessarily associated with her role in the temple bureaucracy, for other Singers in the Interior of the Temple of Amun were known to have born children.\nMeresamun was slightly under five feet tall.\nDuring the CT examination, researchers learned much more about the way that Meresamun was mummified. As was normal for mummification during most of Egypt\'s history, the brain was removed by breaking through the ethmoid sinus behind the nose. No material was introduced into the cranium. CT scans show that small objects, perhaps oval stones or pieces of faience, were placed under each eyelid to restore a fuller, lifelike appearance. Meresamun was mummified with her arms extended, her hands crossed over her pubic area. The embalming incision was made on her left abdomen to remove her internal organs. A considerable amount of fabric was stuffed into the embalming incision, and packets of some unidentified material were inserted directly into the abdomen. Her fingers and arms were encircled with linen bandages before they were wrapped close to her body. This extra effort and lavish use of wrappings is a sign of a superior mummification process, suggesting that Meresamun came from a family that could devote considerable resources to her funeral arrangements. The heart, which was often left in the chest during mummification because it was considered to be the seat of thought, is not visible on the CT scans. No amulets or jewelry were left within the wrappings.\nMummy masks were a traditional part of the funerary equipment with which ancient Egyptians supplied their burials for the life they believed would continue after death. This example is a stylized portrait of the deceased, evidently a woman. It originally covered the head and shoulders of her mummified body. The medium is cartonnage, a kind of ancient Egyptian papier- mache made from used linen and papyrus. The cartonnage was coated with gesso before the paint and gilding were applied. The deceased is shown wearing a necklace at the throat with a heart amulet as a pendant. Below is a broad collar necklace fringed with drop pendants. A representation of funerary shrines with double doors appears on each shoulder. The god Osiris sits on top of each shrine. These divine figures were intended to represent the deceased after death, for it was believed that all were reborn as Osiris. The feather which the god holds is an allusion to the deceased successfully being reborn after passing a judgement before the tribunal of the gods.\nThe need to preserve the body from decay was probably the most important part of the Egyptian belief in a life after death because the spirit was thought to inhabit it at times. In the Predynastic period before 3,000 B.C. and the beginning of the Pharonic Age, the body was placed in a grave in the sand with some simple offerings. The natural heat and dryness preserved it with little need for embalming or other preparation. As society developed in Egypt and tombs became much more elaborate, it was necessary to treat the body to protect it from decay. Mummies could be elaborately wrapped in decorative patterns, as on the examples of the Roman Period. The face was usually covered with a mask of plaster or precious metal fashioned as a likeness of the deceased.']"	['<urn:uuid:0bfaabfa-dba4-471a-a573-02ba6b5e8fc1>']	open-ended	with-premise	short-search-query	similar-to-document	single-doc	novice	2025-05-01T23:21:14.341336	6	103	2941
296	home clinic baby development checkup difference	Health and development reviews can be conducted either at home or at various clinical settings (GP surgery, baby clinic, or children's centre). The location choice applies throughout the child's first two years, including the new baby review (10-14 days), 9-month review, and 2-2.5 year review. For specific hearing tests like behavioral audiograms, these must be done in a clinical setting with a soundproof booth at facilities like Riley Hospital.	"[""You will be offered regular health and development reviews (health visitor checks) for your baby until they are 2. These are to support you and your baby, and make sure their development is on track.\nThe reviews are usually done by your health visitor or a member of their team. They may be done in your home or at the GP surgery, baby clinic or children’s centre.\nIt’s helpful, where possible, for both parents to attend. This gives you both a chance to ask questions and talk about any concerns you have.\nThe personal child health record (red book) What happens at your baby's reviews\nDuring your baby’s reviews your health visitor will discuss your baby’s health and development, and ask if you have any concerns.\nIf your baby is gaining weight and you and your health visitor have no concerns, they should only be weighed once a month. This gives a clear idea of your baby’s weight gain over a period of time.\nIf your baby was born prematurely, their developmental age will be calculated from your original due date, not from the actual date they were born, until they are 2 years old.\nThe Ages and Stages Questionnaire (ASQ-3)\nYour health visiting team will send you a questionnaire, known as the Ages and Stages Questionnaire or ASQ-3, to fill in before your child’s 9-month and 2-year development reviews.\nThis allows you to try out some of the activities covered by the questionnaire with your baby at home, where they are comfortable and in familiar surroundings.\nWhen your baby will have their reviews\nYour baby will usually have reviews at the ages listed below. If you have any concerns at other times, you can contact your health visitor or GP, or go to your local baby clinic.\nShortly after birth\nYour baby will be weighed at birth and again during their first week. They will also have a thorough physical examination within 72 hours of being born. A health professional will usually check your baby’s eyes, heart, hips and – for baby boys – testicles.\nRead more about the newborn physical examination.\nSee more about the blood spot (heel prick) test.\nYour baby will have a hearing test soon after birth. If you have your baby in hospital, this may happen before you leave. Otherwise, it will be done some time in the first few weeks in your home, at an outpatient clinic, or at your local health centre.\nSee what the newborn hearing test involves.\nYour midwife and health visitor will also support you with breastfeeding, caring for your new baby, and adjusting to life as new parents.\nOne to two weeks\nYour health visitor will carry out a new baby review within 10-14 days of the birth.\nThey can give you advice on:\n- safe sleeping\n- feeding your baby (breastfeeding and bottle feeding)\n- caring for your baby\n- your baby’s development\n6 to 8 weeks\nYour baby will be invited for a thorough physical examination. This is usually done by your GP.\nYour baby’s eyes, heart, hips and – for boys – testicles will be checked. They’ll also have their weight, length and head circumference measured.\nYour GP or health visitor will discuss your baby’s vaccinations with you. These are offered at 8 weeks, 12 weeks, 16 weeks and 1 year old, and before your child starts school.\nThey’ll also ask you how you’ve been feeling emotionally and physically since the birth of your baby.\n9 months to 1 year\nDuring this time, your baby should be offered another review looking at, among other things, language and learning, safety, diet and behaviour.\nThis is usually done by a member of your health visiting team. It’s an opportunity for you to discuss any concerns you may have.\nYour health visiting team will send you an ASQ-3 questionnaire to fill in before the review. This helps you and your health visitor understand how your baby is developing.\nDon’t worry if you can’t fill in the whole questionnaire – your health visitor will help you complete it.\n2 to 2-and-a-half years\nAt 2 to 2-and-a-half years your child will have another health and development review. It’s best if you and your partner can both be there.\nThis is usually done by a nursery nurse or health visitor, and may happen at your home, baby clinic or the children’s centre.\nIf your child has started going to nursery, playgroup or a childminder, the review may be done there. You, your health visitor, your child’s early years keyworker or childminder will all do the review together.\nYou’ll be sent an ASQ-3 questionnaire about your baby’s development to fill in before the review. Your health visitor or your child’s keyworker or childminder can help you with this.\nThis review will cover:"", 'Improving Children’s Hearing And Speech\nAudiologists at Riley Hospital for Children at Indiana University Health perform a variety of tests to determine how well a child is hearing and the functional status of the child’s ears. They share the results of these tests with physicians and hearing aid professionals to help them develop treatment plans to improve the child’s hearing. Our audiologists can perform these tests on children of any age, even newborns.\nMany children with hearing loss require hearing aids. We have a referral list with a variety of pediatric dispensing audiologists who fit and adjust hearing aids to fit each child’s need.\nTypes of Audiology Testing\nOtoscopy: Otoscopy is visual inspection of the ear canal to make sure the pathway for sound to travel to the middle and inner ear is clear of debris or cerumen (ear wax). It is performed by using an otoscope, a special flashlight, to look into the ear canal.\nTympanometry: Tympanometry is a pressure test that determines how well the eardrum is functioning. This testing is performed by placing an ear tip in the opening of the ear canal for a few seconds. The test is done because if an eardrum is not functioning normally, it may impact hearing ability.\nBehavioral Audiogram: Behavioral testing can determine the softest level of sound to which a child can respond. This testing allows us to determine how well the child can hear speech and sounds through the pitch range most important to understanding speech. It can be performed in a variety of ways depending on the age and ability of the patient, but often we use speakers or headphones in a soundproof booth. The child must have a developmental age of at least six months. They should be awake and alert for the test, which takes about 15-30 minutes.\nOAEs (Otoacoustic Emissions): This testing is an objective measure of cochlear function to help determine how the inner ear system is working. It is performed by placing an ear tip in the child’s ear and then playing some frequency-specific sounds while measuring that ear’s responses to the sounds. The child must be able to sit quietly for two to five minutes.\nUnsedated ABR (Auditory Brainstem Response): An ABR test is primarily recommended for infants who did not pass their universal newborn hearing screening before discharge from the hospital. This test allows us to obtain frequency- and ear-specific information about the auditory pathway. In order to achieve these results the baby must sleep soundly for approximately 45 minutes. An unsedated ABR is only performed in natural sleep on babies who are four months adjusted age or younger.\nSedated ABR (Auditory Brainstem Response): This test is recommended only if a behavioral audiogram is unsuccessful or if the child has previously not passed ABR testing. Sedation medications are given and monitored by a physician and a nurse. The child sleeps for approximately one hour. This test can be coordinated with other sedated procedures if necessary.\nBalance Testing: Because the inner ear is responsible for balance, we also provide balance testing.\nWhy Choose Our Audiology Program?\nAudiologists at Riley Hospital for Children at IU Health are highly trained and experienced and are familiar with complex hearing disorders. We also work collaboratively with radiologists who perform MRIs and CT scans as needed to diagnose a child’s hearing loss correctly.\nMembers of the team are also involved in studies that monitor the hearing effects of medications used to treat sickle cell anemia, cancer, cystic fibrosis and other disorders.']"	['<urn:uuid:588e3442-3613-4f5f-9ba3-b618a54b0a0c>', '<urn:uuid:0c5b8953-2b68-410c-84d1-131326d2aec6>']	factoid	with-premise	short-search-query	distant-from-document	comparison	novice	2025-05-01T23:21:14.341336	6	69	1385
305	identify significant characteristics traditional sibling relationships according dunn 2002	According to Dunn (2002), there are three significant characteristics of sibling relationships: 1) the intensity and expression of both positive and negative feelings during childhood and adolescence, 2) the closeness of the relationship which can be either a source of conflict or support, and 3) these relationships vary according to individual differences between siblings, with some showing positive feelings and affection, others showing hostility, and some being ambivalent.	"[""1.1 Sibling Relationships”Sisters and brothers are the truest, purest formsof love, family and friendship, knowing when to hold you and when to challengeyou, but always being a part of you.” (Eastman,2017).\n“They love each other. They’rebrother and sister. It’s one for all and all for one.” (Joe Ziemba)”Siblings are those with whom one most closely shares genetic, family,social class and historical background and to whom one is tied for a lifetimeby a network of interlocking family relationships” (White, 2001, p555). Siblingrelationship is incorporates activities as well as verbal and nonverbalinteractions between people who share the same biological parents (Cicirelli,1991).\nSiblings assume a vital part in each other’s development throughoutlifespan (Yeh and Lempers 2004), also incorporated into young adolescent(Jensen et al. 2013).Siblings are aninstallation in the family lives of children and adolescents, and an assemblageof work documents their part in each other’s regular experiences as friends,associates, combatants, and as the center of social comparisons (McHale, Kim,and Whiteman, 2006). Thesibling’s relationship isn’t only influenced by them yet may likewise beinfluenced by other individuals, circumstances and conditions (Furman andLanthier, 1996). Indeed, even inside the same family, one sibling get alongbetter with sibling or siblings than another.1.1.1 Traditional Perspectives on Sibling RivalryBrothers and sisters are among therelatives with whom Islam commands us to uphold ties.\nThe Messenger ofAllaah (peace and blessings of Allah be upon him) said: “Allah says: ‘I amal-Rahmaan (the Most Merciful) and this rahm (tie of siblingship) has a namethat is derived from My name. Whoever uphold it, I will take care of him, andwhoever severs it, I will cut him off.'” (Narrated by al-Tirmidhi, 1907; AbuDawood, 1694; classed as saheeh by Shaykh al-Albaani in al-Silsilahal-Saheehah, 520). The Prophet (peace and blessings ofAllah be upon him) said: “Whoever would like his lifespan to be extended andhis provision to be increased, let him uphold the ties of siblingship.”(Narrated by al-Bukhaari, 1961; Muslim, 2557).\nTheir rights also include: that youshould not harm any of them in word or deed. The Prophet (peace and blessingsof Allah be upon him) said: “The Muslim is the one from whose tongue and handthe Muslims are safe.” (Narrated by al-Bukhaari, 10; Muslim, 40). And he (peaceand blessings of Allah be upon him) said, in a lengthy hadith in which heenjoined a number of virtues, “… If you cannot do that, then leave people alone(and do not offend them), for that is an act of charity that you do foryourself.” (Narrated by al-Bukhaari, 2382; Muslim, 84).Some of the sibling rivalryincidents among different religious books i.\ne., Qur’an, the Torah and in theBible are presented like the account of Cain and Abel relate one sibling’sjealousy after God seems to support his sibling, and the envy at last promptskill. Jacob traps his brother Esau out of his legacy and blessing; Sisters Leahand Rachel rival for the love of Jacob; In the renowned story in the Qur’anabout Joseph, Joseph’s siblings endeavored to hurt him, prodded on by jealousyand rivalry.\nThe Qur’an says, “Assuredly, in (this account of) Josephand his brothers there are many sans (messages) for seekers of truth”(Yusuf 12:7). As is renowned, Prophet Jacob fathered twelve sons.Notwithstanding, Jacob observed incredible potential in Joseph and in this wayhe gave careful consideration to Joseph. Since this was self-evident, the othersiblings’ envy developed against Joseph.\nOne night Joseph had a dream. When hewoke he said to his dad, “0 my father! I saw in a dream eleven stars, aswell as the sun and the moon: I saw them prostrating themselves before me”(Yusuf 12:4).Jacob considered this dream, and he trusted it implied God wouldgive Joseph opportunity, gave on him an high level of respect and fame, andmake him a very important leader. Mindfulof the sentiments of alternate siblings toward Joseph, Jacob dreaded they wouldattempt to hurt him. So he let him know, “0 my son! Do not relate yourdream to your brothers, lest (out of envy) they devise a scheme against you.For Satan is a manifest enemy to human siblings (and can incite them to do sucha thing)” (Yusuf 12:5). The Qur’an goes ahead to depict the arrangementthe siblings brought forth, a ghastly case of exactly how far rivalry betweenkin can go: When they (the siblings tending to each other) stated, “Josephand his brother are indeed more loved by our father than we are, even though weare a powerful band (of greater use to him). Surely, our father is manifestlymistaken.\n” (One of them said :)”Kill Joseph, or cast him out in some distant land so that your father’sattention should turn only to you, and after that you may again becomerighteous people.” (Yusuf 12:8-9)One can trace the instances of siblingrivalry in literature as well. Some of Shakespeare’s plays showed theoccurrences of sibling rivalry. King Lear incited rivalry among his threelittle girls by approaching them to portray their adoration for him; in asimilar play, Edmund thinks up to drive his stepbrother Edgar into cast out. InThe Taming of the Shrew, sisters Kate and Bianca were demonstrated fightingharshly. In Richard III, the title character was to some extent propelled byrivalry with his sibling, King Edward.\nIn As You like It, there was clearsibling competition and enmity amongst Orlando and Oliver, and furthermorebetween Duke Frederick and Duke Senior. Most adjustments of Sherlock Holmes portrayedsibling rivalry with his sibling, Mycroft Holmes (Wikipedia).In the light of various traditionalperspectives, sibling relationships are seen as multidimensional as variousaspects of sibling relationship is acknowledged and we have elaborate exampleof such aspects of their relationship as well.\nBoth positive and negative sides of these relationships and itsassociate interactions are also acknowledge like sibling rivalry, jealousy,warmth, affection and competition. 1.1.2 Factors Influencing Sibling RelationshipSiblingsfor the most part of their childhood spend with each other than they do withtheir parents.\nThe sibling relationship wasgenerally been disregarded by researchers until the 1980s (Dunn, 2002). It wasfrequently an unpredictable and complex relationship, like for some people itcan be a tremendous fountain of companionship and support (O’Bryant, 1988) yetit can likewise be a wellspring of rivalry, discord or uncertainty (Connidis,2007).Dunn(2002) refered to the three significant attributes of sibling relationships: 1)the strength and articulation of both positive and negative feeling amidchildhood and pre-adulthood, 2) the closeness of the relationship which wasfrequently a wellspring of either strife or support, and 3) these relationshipsdiffered as per the individual differences of the sibling with somedemonstrating positive sentiments and love, others indicated antagonistic vibeor animosity but others being undecided.\nSibling’s influence had gotten through avariety of ways including sibling modeling (Whiteman et al., 2014),differentiation between sibling (Schachter et al., 1976), and parentaldifferential treatment (Jensen et al., 2013). These processes were establishedon the concept that siblings compare themselves with each other, yet social comparisonbetween siblings had gotten insufficient consideration. Considering theapparently general nature of comparison, and additionally the behavioral andpsychological correlates of social comparison (Buunk and Gibbons, 2007), it wasessential to comprehend what part comparison plays inside family dynamics,particularly between siblings.1.1.\n3 Sibling Interdependent RelationsAs indicated by researchers Mack(2004) and White (2001), relationships with family, especially kin, were seenas gatherings of “nested circles” initially proposed by Parsons(1943). The “inner circle” consisted of two conjugal families, those which wereusefully distinguished as the “family of orientation,” into which the child wasborn, and the “family of procreation,” which was started by marriage. The “outer circle” consisted offour pairs of family; the first pair was called the “first ascendant” whichincluded the families of one’s parents. Second pair was called “collateral families”the families of procreation of one’s own siblings and the third pair were knownas “the first descendant families” the families of procreation of one’s ownchildren. The last of “outer circle” family was the “in-law” family which isthe family of one’s spouse (Parsons, 1943).Siblings, on the whole,tend to fall in one’s “inner circles” in childhood, howeverfrequently move to the external circles as individuals’ age and consolidatelife partners and kids into the inner circles (White &S Riedmann, 1992).\nMack (2004) discussed about the infrequent situations of losing a parent inchildhood. In these cases, a kin may dependably stayed in an inner circle as asource of support, as the kin may have fortified because of such a traumaticincident.Lempersand Clark-Lempers in 1992 looked into the relative effective significance ofadolescents’ relations with their fathers, their mothers, their nearestsibling, their best same-sex companions, and their most essential teacher,separately. Adolescents’ closest sibling were positioned higher than theirparents, yet lower than their best same sex companions, for the traits ofamity, closeness, and nurturance.Inan examination by Seginer (1998), 147 eleventh-grade teenagers reported theirsiblings as a distinctive source of emotionally supporting partner, well beyondparental help and peer acknowledgment. An aggregate of 75% of young people inWoodward and Frank’s (1988) research asserted that sibling are the ones theyswing to for solace and talk while encountering lonesomeness.1.\n1.4 Siblings and Identity/SelfSignificant continuity in the siblings’ relationships from childhood toadolescence had been found in the Cambridge Sibling Study in England (Dunn,1996). Positive and negative behaviors and sentiments of siblings about eachother in early years were significantly correlated with the nature of siblingrelationships later in adolescence. The nature of sibling relations may changeamid adolescence, in concurrence with the biological, cognitive, and social changesthat happened during that period of adolescence (Dunn et al., 1994).Theconflict in the sibling relationship might be assessed by the personality andindividuality traits of the sibling (Dunn, 2002).\nResearch demonstrated thatpeople who grow up with aggressive older sibling are themselves in peril ofnegative consequences, for example, poor execution in school, involved withpeers and rising behavioral issues (Bank, Patterson, and Reid, 1996). Researchby Updegraff et al. (2005) demonstrated that sibling’s relational aggression wascorrelated to more prominent negativity and lesser emotional support in theirsibling relationshipRegardless of whetherthe impacts of positive sibling relations on development of adolescent aredirect or whether the connections between positive sibling relations andadolescent development are intervened by different factors has not beenexamined in previous researches.""]"	['<urn:uuid:f0a21dc2-0510-472a-a3eb-e2032afecb26>']	factoid	with-premise	long-search-query	similar-to-document	single-doc	expert	2025-05-01T23:21:14.341336	9	68	1615
308	What makes gophers come into people's yards and gardens in the first place?	Gophers move onto properties because landscapes supply them with abundant food sources, including garden crops, vines, ornamental plants, shrubs, trees and more to feed on. Additionally, real estate expansion and property development into suburban areas drives increased gopher activity.	['Gopher traps are one of the more reliable and tested forms of gopher control used to get rid of gophers. A key step however in using gopher traps is to keep in mind that gopher traps usually differ from mole traps. In fact, very few traps are effective for both ground mole control and gopher control. Accurately determining the type of burrower in your lawn is a critical step.\nWhy We Need Gopher Control\nGophers move onto our property and into our lawns because our landscapes supply to them a cornucopia of garden crops, vines, ornamental plants, shrubs, trees and more to feed on. Adding to the this, real estate expansion and other types of property development into once suburban areas only drives additional gopher activity.\nHow Do You Get Rid of Gophers?\nMany experts and professionals deem pocket gopher traps to be one of the more effective forms of gopher control and ways to get rid of gophers. Instrumental to the art of gopher trapping, however, is to first understand the biology and behavior of these creatures. Understanding gopher behavior helps property owners improve their efficiency in using gopher traps. You become enabled to more accurately develop strategies on how to trap gophers.\nGopher Biology and Behavior\nThe pocket gopher is active throughout the year and is a herbivore. As herbivores, a gopher’s standard diet includes a wide variety of vegetation, but generally herbaceous plants, roots, shrubs and trees. In many yards it is often common for these ground creatures to completely destroy the roots and the fleshy portions of plants encountered while tunneling. Hence, if you are trying to determine where to find gophers in your lawn, you should typically first start in areas of dense vegetation. As mentioned in our yard mole trapping article, this is similar to one of those “in order to make money, you must follow money” theorems.\nLike that of yard mole traps, gopher traps can be deployed during any time of the year. Gophers are active year round and do not hibernate. Therefore, do not immediately conclude that you have gotten rid of all the gophers simply because you fail to see new gopher mounds or runs.\nNOTE: You may indeed no longer have a gopher control issue. We at Gopher and Mole Control HQ simply want to inform you that it has been a common occurrence in the past for people to no longer see surface tunnels, often leading property owners to believe they have obtained gopher control, when in reality the gophers have only gone deeper underground.\nWhy Gopher Traps are Effective\nGophers unlike yard moles do not leave behind visible surface tunnels. However, gophers too create vast networks of underground tunnels and often their feeding tunnels lay only about five inches below the ground. Should you not understand the difference between mole and gopher mounds, please be sure to take a quick look at our article on the difference between gopher mounds and mole mounds for a brief lesson on the topic.\nAs gophers often use networks of feeding tunnels as tools for acquiring food, the burrowing herbivores are often compelled to keep such tunnels open.\nTHIS VERY FACT IS THE BASIS FOR GOPHER TRAPS AND IS WHAT MAKES THE GOPHER TRAP MOST EFFECTIVE!\nTo be effective, the trap must be set to catch the gopher underground. The goal is to trap (kill) the gopher when it travels through or attempts to plug one of its tunnels. As the gopher maneuvers through its’ gopher tunnel, the idea is to have it trigger the trap by having it press against the trigger pan. In triggering the pan, the gopher trap is released and the gopher is skewered or crushed by the trap. A frequently asked question is why would gophers attempt to plug tunnels that appear to be tampered with or open? The short answer to this question is because pocket gophers are not fond of light in their tunneling systems.\nThe Key to How to Trap a Gopher and Tunnel Selection\nThe key to how to trap a gopher is to first determine where the active gopher tunnels are. As mentioned above, gophers dig systems of deep tunnels with the exception of feeding tunnels. The issue is that most feeding tunnels are only used temporarily. Therefore, the feeding runs may not always be the ideal location to set good pocket gopher traps. Permanent or deeper tunnels typically yield the best results since these gopher tunnels may be used several times daily.\nTo identify such tunnels in your yard or property, look for freshly plugged gopher mounds. In doing this, remember that gopher mounds are not symmetrical like ground mole mounds; instead they are unique fan-like shapes. Gopher mounds are formed in this manner because as gophers dig tunnels and push dirt to the surface, they do so at an angle resulting in crescent and irregular shaped mounds. Also, recognize that you will rarely be able to see gopher tunnels running throughout your yard unlike yard moles.\nNOTE: Should you like to view the manner in which pocket gophers tunnel, you can do so by watching our video of a pocket gopher digging.\nProbing for the Gopher Tunnel\nHere are the three basic steps to probing for a gopher tunnel:\n- Purchase a gopher probe or fashion one from a long pipe or metal rod. Tools such as screw drivers can also be effective. In the event that you choose to create your own probe, add something sturdy to the end of the shaft such as a small piece of metal. This modification enlarges the tip of the gopher probe and makes probing the surrounding dirt easier.\n- Use the probe to dig into the earth 6 to 12 inches deep, approximately 8 to 12 inches on the opposite side of the hole or plugged opening of the mound. This will help you to locate the active tunnels off of the main gopher burrow. When you locate the main burrow, you will notice a sudden drop of the probe of approximately two inches. This is a great sign that you have discovered the gopher tunnel.\n- Keep poking around until you find the main burrow. This can require patience. However, once you have located the tunnel, you will have access to the best tunnels to set your gopher traps.\nSelecting a Gopher Trap\nThere are several different types of gopher traps available on the market. The most common types of traps used for gopher control are the two-pronged pincer-style traps and the choker-style box trap. Popular brands include Macabee, Cinch, Gophinator and Victor.\nGopher trap manufacturers often provide detailed instructions, which should be followed carefully.\nAs gopher traps are fairly expensive, people often choose to only buy one. One gopher trap may very well solve the problem, but increasing the number of gopher traps used can greatly impact the speed and overall success of your gopher trapping program.\nHow to Set a Macabee Pincer-Style Gopher Trap:\nPincer traps are best when set in one of the pocket gopher’s feeding tunnels. Feeding tunnels usually span anywhere from one to twelve inches underground. The Macabee pincer trap is a pocket gopher trap that allows you to dig into an active tunnel to place the trap directly into the gopher tunnel.\nThe following steps should be taken:\n- Swing trigger wire up from under frame.\n- Spread jaws, using thumbs, by pushing up downward.\n- Use left index finger to guide trigger wire hook over the end of the frame.\n- Continuing to push down on the frame, place the straight end of the trigger wire through the small in hole on the silver plate.\n- Place the set trap into the pocket gopher hole.\nAdditional Pocket Gopher Trapping Notes:\n- Use shovels or garden trowels to open gopher tunnels wide enough to set gopher traps in pairs. Such gopher traps placed in pairs should face opposite directions. This method of trapping increases success as it threatens the gopher from two directions. Nevertheless, only using one gopher trap will not compromise your gopher trapping system.\n- Most gopher tunnels will have a circumference of roughly three to four inches allowing the use of pincer traps. Should you find that your pincer style traps do not fit within the tunnels and you are not comfortable further modifying the tunnel, the box style trap will likely be the optimum solution.\n- It is not necessary to bait gopher traps although different professionals claim that baiting yields better results. Should you want to bait your gopher trap, try applying peanut butter, alfalfa greens, carrots or lettuce. A yard mole poison (or talprid poison) could even be used.\n- Last, but not least, be sure to exclude all light from the tunnel after setting your gopher trap or traps. There have yet to be scientific studies conducted to determine whether this last step is absolutely crucial. Nonetheless, we at Gopher and Mole Control HQ believe re-covering the rigged tunnels provides for the best results. You can cover tunnels by laying plywood over the openings or by covering with dirt clogs.\nTo find out more information and resources about gopher control, continue reading here at the Gopher and Mole Control HQ Learning Center.']	['<urn:uuid:cf53abe6-8683-4f80-afa8-4c0e10961ffe>']	factoid	direct	verbose-and-natural	distant-from-document	single-doc	novice	2025-05-01T23:21:14.341336	13	39	1545
313	compare shell weight heavy artillery world war railway guns versus warship guns massive projectile size	The railway gun 'Cleo' used shells weighing a third of a ton, while the Japanese 14-inch naval guns fired various projectile types including APC Type 91 weighing 1,485 lbs (673.6 kg), Common Type 0 HE weighing 1,378 lbs (625 kg), and Common Type 3 IS weighing 1,485 lbs (673.6 kg). Both types represented massive artillery pieces - the railway gun weighing 85 tons total and the naval gun weighing around 189,586 lbs (86,000 kg).	"[""Barrington's memories of the School of Artillery\nAfter some weeks at Young Officers’ Course at the School of Artillery at Larkhill, with all the practical training at Salisbury Plain, I saw on the order board that I was being posted to the School of Super Heavy Railway Artillery at Catterick in Yorkshire. Having trained at the Officer Cadet Training Unit (OCTU) on 13-pounder guns last used in the First World War and on 18-pounder field guns again of First World War vintage when I was in the T.A., I had no idea what “Railway Super Heavy” meant.\nA tiresome and lonely journey by rail at 19 years of age and under war time conditions saw me ending up on the station at Catterick. On enquiry to the Rail Transport Officer (RTO) as to the location of the School of Super Heavy Railway Artillery, I was somewhat mystified to be informed he had never heard of it! Such was the chaotic state of affairs in this country at that time that I was beginning to wonder whether I myself was not the victim of some subversive movement!\nHowever, this rather nice old RTO with First World War ribbons suggested I go to the Royal Corps of Signals Headquarters’ mess in Catterick where I would be given accommodation. After a week or so, I was joined by a distinguished Captain R.A. with First World War medals on his chest and Observer Wings. He too had been directed to join the school of Super Heavy Railway Artillery and no-one seemed any the wiser what this meant.\nIn the course of the next week we were conducted by a team of London N.E. Railway officials, led by a red hat Brigadier General R.A., to the railway sheds at Darlington. It was there that we were introduced to massive 84 ton guns which had last seen action on the Somme, together with guns which had been taken off warships in the interim period between the two world wars in accordance with several naval treaties decreeing that guns of such calibre were no longer to be employed. Allegedly, they had been destroyed but, in fact, were preserved, minus the gun sights and range tables, in mineral jelly in railway sheds,\nIn a matter of weeks we were joined by chaps from coastal batteries, mainly Territorials, who had been employed on coastal defence and, like ourselves, had no experience of these particular “railway guns”. Eventually, I found myself as a Second Lieutenant in command of “Cleo”, one of the first two 12 inch railway Howitzers, with orders to be ready with gun crews and Sappers (Royal Engineer locomotive crews) to make our way down to the Dover area - presumably to repel the threat, that was now becoming very real, of a German invasion. Needless to say, we still had no such things as range tables, no gun sights or the technical equipment required for firing such ordnance!\nWe were billeted under canvas on the moors outside Catterick. As Troop Commander, I was privileged to be housed in a bell tent (including a camp bed and basin which my father had sent).\nIt took some time to travel down south. It was an arduous and prolonged journey, not least because the gun itself on its carriage weighed 85 tons and various bridges had to be reinforced before we could cross them! On route we stopped off at Immingham, near the mouth of the Humber, and we did fire some rounds. Indeed, these were very precious because there were not more than about 21 rounds of 12 inch ammunition suitable for this particular gun in the U.K. For this particular calibration exercise I found myself at the Dock tower at Grimsby taking part in spotting the fall of shot in the Humber estuary.\nThe gun members were not instructed to use earplugs but we were told how important it was to breathe out and relax the stomach muscles when the gun was fired. However, the evening newspaper for Immingham and Stalingborough did warn the citizens to leave their windows open the following morning. Indeed, our calibrating rounds smashed all the lamps and windows on Stalingborough railway station and several in the village.\nThe Duke of Kent (later killed flying with the RAF) visited us unexpectedly sometime between June and July and had breakfast in the mess railway coach. I was Orderly Officer of the day and turned out the guard to salute the car flying its pennant.\nEventually, in late August, we arrived at a little railway halt near Dover, at a village called Shepherdswell approx 12 miles from Dover. We shunted the gun into a siding and pushed it into a tunnel where we protected its position with barbed wire and First World War vintage Lewis guns (the troops themselves being armed with Ross Canadian rifles) while wondering what our fate would be.\nIn fact, from Shepherdswell we were to take the gun by rail closer to the Dover area. The air combat in S.E. England, particularly over Kent toward Canterbury and London, was critical at that time. The Battle of Britain was being fought out: parachutes were coming down quite frequently from the battles in the air and we did have German airmen in our guardroom on two occasions.\nAs already mentioned, this 85 ton gun “Cleo”, was one of two – its sister gun was called “Sheba”. Together they formed what was called the Fifth Super Heavy Battery.\nThe shell weighed a third of a ton. It had to be hoisted on the loading cradle and rammed into the breech. The breech block was then closed and the loaded gun elevated. There were sixteen men per gun and the whole crew was housed in a train comprising two carriages, one being the Officers’ Mess for the Battery Commander, the Command Post Officer and the two Gun Position Officers. The second carriage provided quarters for the two Warrant Officers plus cooking facilities. The other ranks were housed in bunks fitted into the old type wagons marked “40 hommes” or “8 chevaux” (relics of First World War days.)\nNext page 'Invasion Beckons'"", 'This could well be said to be the best battleship gun built by Japan, as it was quite accurate and reliable. The original design was by the famous British armament firm of Vickers and guns manufactured by that firm were first used to arm the battlecruiser Kongô, built at the Vickers-Armstrong yard at Barrow.\nNomenclature for these weapons is somewhat complicated. The original design was submitted by Vickers to the Japanese in November 1910. In an effort to hide their true size, Vickers designated these guns on their internal documents as the 12-in Vickers Mark ""J"" and the Japanese documented them as the 12-in Meiji 43 Type (the 43rd year of the Meiji era being 1910). Later, the guns built by Vickers were known as the 14-in Vickers Mark ""A"" and to the Japanese as the 14-in 43rd Year Type (Model 1910). Guns manufactured in Japan were known as 14-in 41st Year Type (Model 1908). In 1917, when the Japanese converted to metric, all of these guns were then designated as ""36 cm"" (14.2 inches) but their bores remained unchanged at 14.0 inches (35.6 cm). For more information on Japanese designations, see Gun Data.\nIn addition to those guns on Kongô, Vickers supplied a number of complete guns and individual forgings to the Japanese for a few years but most guns were built by Kure Arsenal and by Japan Steel Works, LTD (Muroran Plant). A total of about 100 guns from all sources were produced. There were several versions of the Japanese type, but they and the Vickers guns had similar performance and can be considered together. The Vickers guns were the customary full-length wire wound type and used cannelured rings at the tube shoulders to reduce ""steel choke"" problems. The early 41st Year Type guns were similar, but later ones are believed to have had the inner A tube radially expanded into position. Vickers ""pure couple"" breech mechanism was used with a Welin block on all of these guns, similar to British guns of the same era.\n|Designation||Vickers built guns - Vickers designation: 14""/45 (35.6 cm) Vickers Mark ""A""\nVickers built guns - Japanese designation: 14""/45 (35.6 cm) 43rd Year Type (Model 1910)\nJapanese built guns (before 1917): 14""/45 (35.6 cm) 41st Year Type (Model 1908)\n|Ship Class Used On||Kongô, Ise and Fuso Classes|\n|Date Of Design||Vickers design submitted to Japan in 1910|\n|Date In Service||1918|\n|Gun Weight||189,586 lbs. (86,000 kg)|\n|Gun Length oa||648.4 in (16.469 m)|\n(see Note 1)\n|540 in (13.737 m)|\n|Grooves||(84) 0.12 in deep x 0.349 in (2.048 mm x 8.865 mm)|\n|Lands||0.175 in (4.435 mm)|\n|Twist||Uniform RH 1 in 28|\n|Chamber Volume||17,996 in3 (294.9 dm3)|\n|Rate Of Fire||2 rounds per minute|\n- Rifling shown as for Model Type II and III barrels. Model Type III2 and III4 barrels had the same chamber volume, but had a 0.04 in (0.10 cm) shorter chamber and 1.22 in (3.1 cm) less rifling length.\n- US Naval Technical Mission to Japan report O-54(N) states that guns meant to be loaded at high elevations had ""ridges around the compression slope, to aid in gripping the projectile rotating bands and prevent the projectile from slipping back after seating.""\n|Projectile Types and Weights\n(see Notes 1, 2 and 3)\n|World War I\nAPC Type 3 - N/A, but probably 1,400 lbs. (635 kg)\nCommon Type 3 HE - N/A, but probably 1,400 lbs. (635 kg)\nWorld War II\n|Bursting Charge||APC Type 91 - 24.5 lbs. (11.1 kg)\nCommon Type 0 HE - 65.1 lbs. (29.5 kg)\nOthers - N/A\n|Projectile Length||APC Type 91 - 60.03 in (152.5 cm)\nCommon Type 0 HE - 47.25 in (120.0 cm)\nCommon Type 3 IS - 55.1 in (140 cm)\nOthers - N/A\n|Propellant Charge||313.8 lbs. (142.3 kg) 85 DC|\n|Muzzle Velocity||APC Type 91 - 2,526 - 2,543 fps (770 - 775 mps)\nCommon Type 0 HE - 2,641 fps (805 mps)\nCommon Type 3 IS - 2,641 fps (805 mps)\nOthers - N/A\n|Working Pressure||19.0 to 19.2 tons/in2 (3,000 to 3,020 kg/cm2)|\n|Approximate Barrel Life||250 - 280 rounds|\n|Ammunition stowage per gun||About 90 rounds|\n- Common Type 3 HE shells of the World War I period were developed from shells imported from Britain and were adopted on 26 May 1915. These should not be confused with the Common Type 3 Incendiary Shrapnel (IS) rounds used during World War II. The original Type 3 had a shimose filler and had a tendency to detonate on impact, similar to British shells of the era. It is probable that APC and CPC shells were also imported from Britain at this time but I have been unable to confirm that hypothesis.\n- IS is my abbreviation for the incendiary shrapnel round (sankaidan) intended for AA use.\n- The APC Type 3 was adopted in 1917. Following World War I, the Japanese obtained some German AP shells and also purchased some British Hadfield AP shells in 1924. Examination of these examples and the results of their own extensive firing trials resulted in the APC Type 5 which was adopted on 15 June 1925. This was superseded by the APC No. 6 which was adopted on 17 November 1928. APC No. 6 was essentially similar to the Type 5 in terms of armor penetration but was better protected from premature detonation and had enhanced underwater performance. APC No. 6 was redesignated as the Type 88 on 6 April 1931. On that same date, the improved APC Type 91 was adopted.\n- Type 91 shells were all 6 / [infinity] crh with boat tail and two copper driving bands. The diameter of the bourrelet was 13.970 in (35.484 cm). AP Cap, cap head and windshield together weighed 229 lbs. (104 kg).\n- The propellant charge was in four bags.\n- Dye for AP shells was introduced in 1941\nand these projectiles were designated as Type 1. The following\ndye colors were assigned:\nHiei: None (White)\n|Elevation||Range||Striking Velocity||Angle of Fall|\n|2.6 degrees||5,470 yards (5,000 m)||2,198 fps (670 mps)||3.5|\n|6.1 degrees||10,940 yards (10,000 m)||1,890 fps (576 mps)||7.5|\n|9.9 degrees||16,400 yards (15,000 m)||1,673 fps (510 mps)||12.4|\n|14.4 degrees||21,870 yards (20,000 m)||1,506 fps (459 mps)||18.9|\n|20.0 degrees||27,340 yards (25,000 m)||1,378 fps (420 mps)||27.5|\n|28.7 degrees||32,810 yards (30,000 m)||1,358 fps (414 mps)||35.9|\n|38,770 yards (35,450 m)||---||---|\n|43.0 degrees||30,650 yards (28,025 m)|\nKongô (4), Ise (6) and Fuso (6)\n(see Note 5)\n|Kongô Class: About 654 tons (664 mt)\nIse and Fuso Classes: About 688 tons (699 mt)\n(see Note 1)\n|Original: -5 / +25 degrees\nAs modified in the 1920s: -5 / +33 degrees\nAs rebuilt in the 1930s: -5 / +43 degrees\n|Elevation Rate||5 degrees per second|\n(see Note 2)\n|Forward and aft turrets: about -150 / +150 degrees\nAmidships turrets: about 30 to 150 degrees on either side\n|Train Rate||3 degrees per second|\n|Loading Angle||All except Fuso: -5 to +20 degrees\nFuso: +5 degrees\n- Gun elevation was first increased in the 1920s by enlarging the gun port openings. A later increase in the 1930s was achieved by deepening the gun wells and lowering the revolving structure deeper into the ships. Ise and Hyuga lacked sufficient depth in the aftmost two turrets to allow this last change, so only the four forward and amidships turrets were modified for greater elevations. It should be noted that even the original +25 degree elevation was greater than that of contemporary British designs which were generally limited to +15 or +20 degree elevations.\n- Q turret on the Kongô class was in a more favorable position than those on earlier British battlecruisers, increasing its firing arc to about 60 degrees before the beam and 90 degrees abaft it on either side, although it could not fire directly aft at elevations below about 10 degrees.\n- These mountings used Kenyon Doors to transfer projectiles onto the turret stalks. Auxiliary electric power was provided. Magazines were above the shell rooms in the original British design, although later ships and the modernized Kongôs had this arrangement reversed, showing the influence of a similar change in British thinking of the 1920s. Compressed air runout was added in the 1920s rebuilds.\n- The gun axes were 90 in (229 cm) apart.\n- The weight differences was mainly the result of thicker armor on the battleship turrets.\n- During gunnery practice on 5 May 1942, the left gun breech of Turret #5 on Hyuga suffered a catastrophic failure and the resulting explosion and fire killed fifty-one officers and crewmen. During repairs at Kure over the next few weeks, Turret #5 was removed from the ship and replaced with a circular armor plate atop the barbette. Four triple 25 mm gun mounts were placed on top of the plate. Later during 1943, the after two turrets and barbettes on Ise and Hyuga were removed and these ships were then converted into hybrid battleship-seaplane carriers. See the Naval Technical Board essay The Japanese Ise and Hyuga Hybrid Battleship-Carriers for additional information.\n- The US Naval Technical Mission to Japan report O-47(N)-1 states that ""Japanese major caliber turrets (14 and 16-inch) are all of old design and were copied from the British-built turrets for the BB Kongô. In general arrangement and in most details, they are similar to the British 15-inch turrets, but some improvements have been made by the Japanese . . .[including] Better flash tightness in gunhouses and working chambers. All battleships were fitted with longitudinal flashtight bulkheads between the guns, and between the gun loading hoists in the working chambers.""\n""Naval Weapons of World War Two"" by John Campbell\n""The Big Gun: Battleship Main Armament 1860-1945"" by Peter Hodges\n""Battleships of World War I"" by Peter Hore\n""Japanese Cruisers of the Pacific War"" by Eric Lacroix and Linton Wells II\n""The World Wonder\'d: What Really Happened Off Samar"" by Robert Lundgren\n""Japanese Warships of World War II"" by Anthony Watts\nUS Naval Technical Mission to Japan report O-19: Japanese Projectiles General Types\nUS Naval Technical Mission to Japan report O-47(N)-1: Japanese Naval Guns and Mounts-Article 1, Mounts Under 18""\nUS Naval Technical Mission to Japan report O-54(N): Japanese Naval Guns\nCombined Fleet TROM for Hyuga (accessed on 19 February 2009)\nSpecial help from Yasufumi Kunimoto (Manager, Japan Steel Works, LTD) and Robert Lundgren\n13 October 2007 - Benchmark\n26 February 2009 - Added information regarding turret explosion on Hyuga\n28 September 2010 - Added photograph of shell fragment\n01 May 2012 - Added sketch of Shell Cages\n11 July 2015 - Added to note about splash colors\n01 November 2015 - Added photograph of projectiles\n20 December 2015 - Added photographs of Kongo, Fuso, Ise, salvaged turret and changed Vickers Photographic Archive links to point at Wayback Archive\n28 October 2016 - Converted to HTML 5 format']"	['<urn:uuid:fd91a440-bc04-4251-98bc-04a4eecb35b9>', '<urn:uuid:29635683-4925-43e1-b77e-89e705df6f6e>']	open-ended	direct	long-search-query	distant-from-document	comparison	expert	2025-05-01T23:21:14.341336	15	74	2808
314	violin bow string maintenance cleaning	Proper maintenance of violin bows and strings involves several key practices. The bow requires regular re-hairing as finger oils make the bow hair slippery, preventing rosin from sticking effectively. Strings should be changed approximately every 12 months to maintain optimal performance. For cleaning, the violin should be cleaned after each use with a fine instrument cloth, paying attention to all sides, including front, back, and strings. Regular cleaning prevents rosin dust buildup and string stiffening. When applying rosin, it should be done in long slow strokes along the full bow length, and excess rosin residue should be cleaned from the bow stick, violin, and strings, though the bow hair should not be cleaned. When placing the violin down, it should always be positioned string side up to prevent damage from string pressure on the bridge.	"['Violin Rosin - What you really need to know about one of the smallest violin accessories!\n""Johnny you rosin up your bow and play your fiddle hard."" Most of us have heard that line of lyrics from Charlie Daniels popular \'Devil Went Down to Georgia\', but how many of us really know what it means to ""rosin up your bow"".\nRead below to discover which violin rosin is perfect for you. Or skip right to the bottom of the page for fun, fast facts and rosin tips.\nWith an exception of one or two brands, most rosins hover in a very affordable price range of $5.00 to $12.00. And unlike other routine maintenance costs like new strings, and re-hairing the bow, rosin will last a long time. So, find the brand that you like and that you feel compliments your strings the most.\nAnother big thing you\'ll need to decide is whether you want more grip and grit or a lighter and smoother feel to your bow.\nSee the differences in color below, the dark one on the left will give your bow more grip, bite, and traction because it is softer. The light amber one on the left is harder and leaves a finer smoother powder finish on your bow.\nViolin rosin for students on a budget.\nSometimes you will run across student-grade rosins that are just a couple of dollars. These rosins will work, however they are stickier than more expensive rosins and can leave a thick residue on the strings, instrument, and bow.\nKaplan Dark Artcraft Rosin - An affordable alternative to \'cheap\' gritty rosins, this student-grade violin rosin is made out of a finer resin than other cheap rosins.\nA. B. Dark Rosin - Is another dark rosin for beginners and students. Unlike many student-grade rosins, this one does not come in a box but in \'cake\' form. Most violinist prefer non-boxed rosin.\nFor a couple of dollars more try Dominant Violin Rosin - This rosin was designed specifically for synthetic strings. It produces less dust than other \'light\' or hard rosins. Reviews are excellent on this rosin, and most violinist agree that it is a solid choice.\nWhat are the benefits to buying a more expensive rosin?\nCheap student-grade rosins tend to be sticky, and sounds grainy, and produce more powder than the professional grades. Professional-grade rosin helps renders a smoother, controlled tone. Because it is usually a made from a purer resin, expensive rosin produces less powder and sticky messes. Some of the finest expensive rosins, that also elicit top notch reviews are:\nAndrea Bang Rosin by far is one of the most talked about rosin\'s on violinist forums. It is pricey, but some claim the benefits far out-weight the $30 or $40 you\'ll pay for a \'cake\' of rosin. It comes in two varieties for violinist, Solo and orchestra. Solo rosin provides powerful, yet sensitive sound for the soloist. It enables maximized projection and extra clear bow articulation. Orchestra rosin is designed to provide a more blended sound for ensemble playing, without sacrificing clarity or articulation."" Andrea Bang is the new name for the very popular Tartini line of violin rosin.\nAnother rosin that is gaining a lot of recognition is Bakers Rosin. After checking into it, I am definitely curious and want to try it myself. Here\'s the link to their website, bakersrosin.com.\nThis rosin has been featured on countless forums, websites as well as in Fiddler Magazine. If you want to give it a try, you\'ll have to sign up on their mailing list and become a \'member\'. Due to limited production, clients on their mailing list receive first chance at ordering.\nLiebenzeller Gold was a very popular violin rosin for many years until they discontinued it. Some violinist and luthiers claim that Melos Violin Rosin is a complimentary substitute for Liebenzeller. Each rosin type is especially designed for that specific instrument and season, softer dark for winter and harder light for summer. Because it is made when the order is placed it is always fresh and is 100% handmade.\nChoosing a rosin for specific instrument needs.\nSome rosin makers are even beginning to add precious metals to their \'secret\' rosin recipes. It is believed that these metals change the friction of rosins, creating different tonal qualities. The debate is out as to whether or not violinist think that precious metals really make a difference. But if you think it might, here are some options to try:\nDoes your instrument need extra warmth and added softness?\nTry Gold rosin. It is said to produce a warm tone, soften a harsh-sounding instrument, and produce a clearer, more defined tone. Pirastro Goldflex is a leading brand that uses gold.\nWant to brighten the sound of your violin?\nSilver rosin creates a bright focused tone that is especially good for high notes and strings.Geipel Silver Rosin is a great option for violinist looking to enhance the quality of their upper registers.\nLooking for a rosin that makes playing easier for beginners?\nCopper can help! It creates a warm velvety-soft tone, similar to that of a muted instrument. This enable beginners to create a nice tone more easily.\nChoosing a rosin to compliment your strings.\nMany string companies are beginning to produce violin rosin that compliments their line of violin strings. Pirastro and Dominant are two of the leading brands of violin strings that have added rosins to their line of violin products.\nChoosing a rosin that fits your climate.\nWeather can have a big impact on the effectiveness of your rosin, this is due to the rosins\' hard or soft consistency. For dry cool climates dark rosin is a great match. For hot humid weather light rosin is a better fit.\nHill Dark Rosin - This dark rosin is very popular amongst students and professionals. It is your basic rosin, but grips the string well, and aids in projecting the sound of your violin. Choose this rosin for cool dry climates or for use during the winter.\nHill Light Rosin - A good hard rosin suited for hot humid weather, and summertime. Goes on smooth with a light grip.\nTips on applying violin rosin ""Cake"" rosins or those that aren\'t in boxes, should be rotated to keep the rosin top flat; deeply grooved rosin can damage the sides of the bow. Apply rosin in long slow strokes back and forth along full length of bow. Frequently clean excess rosin residue off of bow stick, violin, and strings. Do not clean bow hair. If you feel like your rosin is no longer working, it may be that your bow hair needs to be replaced.\nDid you know.....\n1. Rosin is also known as colophon, and colophony.\n2. Rosin is a resin collected from pine trees.\n3. The process of collecting the resin is similar to collecting maple syrup. A small cut is made into a live tree, and then the tree is fitted with a drip channel just below the cuts.\n4. Rosin makers use individualized recipes. All recipes vary, sometimes additional tree saps or precious metals are added to the rosin. After getting the rosin\'s mixture just right, makers will allow it to set up and harden.\n5. Rosins come in different colors, dark and amber-gold. The color is determined by the time of year the resin is collected. Late winter and early spring will produce a hard, gold rosin. If the resin is collected in summer or fall, the color darkens and the consistency soften.\n6. Rosin helps to create a better friction, or grip between the bow and the strings. Without this friction, there wouldn\'t be very much musical sound!\nRosin (in a powder form) is used in many sporting events. Ballet dancers rub their shoes in powdered rosin to prevent slipping on the stage floor. Boxers use rosin to avoid slipping in the rink. Gymnast use it on their hands to improve grip. Bull riders wanting a better grip, will rub rosin on their rope and glove. Baseball pitchers and professional bowlers use a small amounts of rosin on their hands for better ball control. The starting line of drag races are covered in rosin to improve traction.', 'Violins are delicate instruments. It is very important to take good care of your violin to ensure optimum performance and to prevent it from damage. Keeping your violin in working condition requires time and attention. Below are a couple of useful tips that will help you keep your violin working in top shape:\nKeep it Clean and Spotless!\nThe first step to maintain a musical instrument is to keep it clean. Whenever your violin gets dusty due to the dust or grime in the air or due to rosin dust, use a fine instrument cloth to clean the violin. Make sure that you clean it on all sides, front and back as well as the strings. It is preferable to use an instrument cloth as it is designed to be soft and gentle on the instrument.\nViolins should be cleaned regularly, preferably after every time you play it. The longer the time lapse between the cleaning, the more difficult it will be to clean the violin. In addition to that, lack of cleaning can stiffen up the violin strings.\nGet a Violin Hanger\nAvoid placing your violin in places where you (or others) might regularly sit or walk. Even a table may not be such a good place to keep your violin. To prevent unwanted accidents that might cause damage, it is best to get a wall hanger. This is an inexpensive options — most violin hangers cost around $10 — and will keep your violin safely stowed away.\nPlace Violin String Side Up\nWhenever you place your violin down on a table or a flat surface, make sure that you place it string side up — even if the violin is stowed inside its protective case. This is because the strings usually tend to exert a good amount of pressure onto the instrument via the bridge. Placing the violin face down can increase the possibility of damage and can hamper the performance of the instrument.\nSince violins are made of fine woods, subjecting your violin to extreme temperatures, either hot or cold, can damage your violin or make it go out of tune. It can also cause cracks on the body of the violin. Exposing the violin to the sun for extensive periods of time is also not recommended. Whenever you have to play outdoors, try to play in a shady area or under a tent, away from the direct heat of the sun. Also, try not to leave your violin in the car unattended, regardless of the outside temperature.\nAnother possible factor that can cause damage to your violin is humidity. Humidity can cause the wooden body of your violin to contract and expand. You should make sure that the level of humidity remains stable around your violin at all times. A lack of humidity in winter can also damage your violin. To solve this, you can use devices to humidify your home during winters.\nAnother option can be to use in-case violin humidifiers which can keep the humidity around the violin stable inside its case. This will prevent the violin from getting damaged or having any tuning issues.\nKeep Your Violin Strings Fresh\nIt is recommended to change the strings of your violin after every 12 months. This will keep the violin working perfectly. It is better to ask an expert violinist for assistance if you are a beginner. An experienced violinist will be able to teach you how the strings are changed.\nCare for Your Violin Bow\nYou need to re-hair your bow regularly, depending on how often you play your instrument. When you play the violin, the oils in your fingers tend to make the bow hair slippery. This will prevent the violin rosin from sticking. This is when you need to re-hair your bow.\nTaking care of your violin will increase its lifespan. It will also keep producing good sound quality and will not get damaged carelessly.']"	['<urn:uuid:9c43caf5-bcb3-4792-9765-8e06c36e906e>', '<urn:uuid:b7c1ac0f-11d4-4653-992f-0df246086e16>']	open-ended	direct	short-search-query	distant-from-document	multi-aspect	novice	2025-05-01T23:21:14.341336	5	135	2020
315	I live in Mali. How much has rainfall decreased here in the past 50 years?	In Mali, average rainfall has decreased by about 200 millimeters over the past 50 years.	['Africa’s climate already poses grave risks to the continent’s people and economies, and global warming promises to intensify the problem. A factual risk-management solution can help.\nEven before global warming became an issue, many African countries were unusually vulnerable to floods, droughts, and heat waves. Indeed, if there were to be no further change in Africa’s climate, its current state already presents grave risks to the continent’s people and economies. Global warming could trigger more frequent and severe weather disasters, shifts in rainfall patterns and climate zones, and rising sea levels.\nFor African nations, adapting to these possibilities is an urgent necessity. To do so, their leaders must answer some difficult questions. What climate-related losses could these economies sustain over the coming decades? How much can be averted and through what measures? Which investments will be required to finance them? Will the benefits outweigh the costs? We believe that such questions can be answered systematically through a factual risk-management approach that African leaders can use to assess climate’s impact on their countries and to find ways of minimizing it at the lowest cost to society.\nKnowledge about future climate trends—particularly their local impact—is incomplete, so policy and investment choices must be made under uncertainty. Yet enough is known to build plausible climate change scenarios as a basis for these decisions, even in developing countries. Such scenarios can help decision makers to identify adaptation measures useful against a range of climate change outcomes. Cost-effective responses can address much of the identified risk: depending on the country studied, 40 to 70 percent of the losses expected by 2030 could be averted—even under severe climate change scenarios—through adaptation measures whose economic benefits outweigh their costs. In almost all cases, however, at least some risk cannot be averted through known measures.\nMany adaptation measures would strengthen economic growth in developing countries; in Mali, for instance, climate-resilient agricultural development could generate millions of dollars annually in additional revenues. Measures with demonstrated net economic benefits could also attract investments and trigger valuable new innovations and partnerships. Indeed, well-targeted, early investments to improve climate resilience—through infrastructure development, technological advances, capacity improvements, new systems and behavior, and risk transfer measures—will probably be cheaper and more effective for the world community than complex disaster relief efforts after the event.\nA fact-based approach can provide valuable input into the overall decision-making process. Among other things, it recognizes the importance of cost–benefit considerations, makes it possible to put “price tags” on current and future climate risks, and lets decision makers develop plans to help businesses adapt to them.\nMali: Climate zone shift\nIn northwestern Africa, stretching deep into the Sahara, Mali is a mostly dry nation, subject to frequent droughts. Increasing temperatures and decreasing rainfall tell of a shift in climate zones as the desert moves south over productive land. In these regions, farmers dependent on agriculture and livestock already face trying periods of drought and have few options to overcome them. Many are moving to the cities, others to the country’s less arid south. Our study focused on Mopti, an important agricultural area in the central region.\nMali has a wide variety of natural environments, ranging from a Saharan climate in the north to the more tropical south. From year to year, its rainfall levels are among the world’s most variable. Annual floods during the rainy season in the Niger River’s interior delta benefit agriculture but may harm local populations (Exhibit 1). Mali also faces additional hazards from climate change: drought is expected to increase in frequency and severity, weakening the country’s agriculture and GDP. The climate zone shift—the combined effect of rising average temperatures and declining average rainfall—has already pushed the country’s agroecological zones to the south over the past 50 years, with average rainfall down by about 200 millimeters and average temperatures up by 0.5°C over the same period.\nDesertification and climate zone shift have multiple causes, with complex interactions. The impact from climate change is aggravated by farming and domestic practices, such as slash-and-burn agriculture (which erodes the soil) and deforestation, mostly to meet 90 percent of Mali’s cooking and heating requirements. (Forest cover has decreased by almost 50 percent since the 1980s.) Nonetheless, local adaptations could eliminate a significant share of the loss due to climate change, and it is important to recognize that farmers have already developed the kinds of techniques that will help them cope. Diversity in crop cycles—already widely practiced by Malian farmers—will be essential. Genetic variation in plants helps to make agriculture in areas with higher climate risks more resilient to them. Also advantageous will be the farmers’ tendency to spread out geographically for access to different types of soils and water sources.\nIn 2006, the value of Mali’s crops and livestock was estimated at $840 million and $620 million, respectively. Projections to 2030 take into account the most valuable agricultural crops (cotton, maize, millet, rice, and sorghum) and livestock (for eggs, meat, and milk). Following historical expectations, the five main crops’ value would increase by 46 percent, to $1,220 million (1.6 percent annual growth). In a more optimistic scenario, that level would more than double, to $2,470 million (4.6 percent annual growth).\nScenarios and responses\nThe significant uncertainty about climate change has spawned a range of climate projections for rainfall, while temperatures are consistently projected to increase significantly. Local climate models allowed us to consider three scenarios for a climate zone shift by 2030. Under the moderate-change one, temperatures would rise by 1.2°C and annual rainfall would decrease by 2.2 percent. The high-change positive scenario projects an increase in rainfall and temperatures of 8.1 percent and 0.9°C, respectively, while the high-change negative scenario anticipates a decrease in rainfall of 10.6 percent and an increase in temperatures of 1.4°C. Under all three, Mali would suffer economic losses by 2030. The pessimistic high-change scenario could involve losses of about $300 million annually (some 15 percent of the value of agriculture and livestock); the optimistic scenario, losses of $120 million annually (6 percent).\nThese losses will probably be offset, to some extent, even in the absence of specific adaptation measures. Agricultural production in Mali is likely to increase in value through the encouragement of farming in the regions best suited to it and the promotion of the right mix of crops. The human migrations required should happen naturally. Still, such measures would not cover the full expected climate-related economic decline.\nMeasures to increase productivity by encouraging the development of assets primarily in the most promising areas could compensate for losses elsewhere. Simulations show that by 2030, a migration of one million people could raise agricultural production by 6 percent more than population growth spread evenly across regions would. The migration of 1.5 million people by 2030 could raise production by an additional 8 percent—an overall 14 percent increase compared with the base case. But such controversial measures might promote conflict and increase competition for resources. Infrastructure and asset-based measures could make semi-arid areas substantially more resilient, however, so accelerated migration isn’t essential.\nSuch measures depend on the specifics of each natural environment, so we assessed a few promising possibilities for the Mopti region (in the middle of the country), which well represents Mali’s diverse agroecological zones. The southwest of Mopti, near the Niger River’s internal delta, is suitable for rice cultivation, horticulture, fishing, and livestock. The east and north, with a hotter and drier climate typical of the Sahel (the region on the fringe of the Sahara), is more appropriate for dry crops such as millet and sorghum—and threatened by the desert’s advance and the struggle to find water.\nAsset-based adaptation measures, such as soil techniques, irrigation systems, and the provision of additional water for cattle, would help to “climate proof” yields. Of the measures reversing the losses, about three-quarters would have benefits higher than their costs. Other measures would generate additional agricultural revenues—for instance, by extending the land area suited to horticulture, providing for two harvests a year rather than one, or encouraging additional products and practices (for instance, by mixing agriculture and forestry in crop fields). The generation of new revenue, essentially another adaptation alternative, has massive potential but requires careful consideration of its secondary effects on society. For the Mopti region alone, revenue-generating cash crops could cover much if not all of the expected loss for the entire country. In other words, these measures are essentially economic-development activities.\nEnablers and barriers\nMany measures we identified are labor-intensive, so the availability and use of local workers can constrain both the potential and the speed of deployment. Labor is an additional cost, but nongovernmental organizations (NGOs) often finance measures in exchange for free work by farmers. Since machinery frequently produces better cost–benefit ratios, however, the desire to help the local workforce must be weighed against the advantages of using more efficient but expensive machines. Building local water holes for livestock close to villages during the dry season, for example, can take two months for a team; a bulldozer can dig one in a day. The workforce is usually idle during the dry season, though, so the choices are quite complex.\nThe many cost-effective measures—which were analyzed, through local experiences and suggestions, and which make sense from a purely developmental perspective—should be led by the players typically involved. Government engagement will be required for larger-scale infrastructure measures, such as irrigation in the delta. NGOs are likely best suited for smaller-scale measures. International institutes can provide important expertise on issues such as crop engineering and meteorology. Given the complexity and magnitude of the challenges, support from the international community will be critical.\nAn effective portfolio of climate resilience measures can be assembled at limited cost. The key is to create the right enabling environment to provide for effective adaptation to climate change as well as economic development.\nTanzania: The impact of drought\nDuring the past 30 years, Tanzania has experienced six major droughts. The most recent, in 2006, is estimated to have cut GDP growth by 1 percent. Two specific effects of drought are of special concern. The first is the threat to human health posed by malnutrition and the spread of cholera and other water-borne diseases resulting from fresh-water shortages. Second, power generation in Tanzania depends predominantly on hydroelectric plants; during the 2006 drought, for example, the country faced severe power rationing because of a shortfall of water in reservoirs.\nOur study focused on the drought-prone central regions (Dodoma, Singida, and Tabora)—where various local climate models allowed us to build realistic scenarios for climate evolution. Under the moderate-change scenario, these regions are projected to experience a 10 percent decrease in annual rainfall and a 25 percent increase in the variability of the amount of rainfall—changes that would lead to more severe and frequent droughts. Under the high-change negative scenario, rainfall would decline by 20 percent and variability increase by 50 percent.\nThe central regions are primarily rural, and a majority of their 4.4 million inhabitants are poor subsistence farmers. This population faces a range of serious drought-related health risks: for example, in 2003 a survey reported that 19 percent of children under five had suffered from diarrhea during the previous two weeks to the survey. Hydropower generation is also critically important in the central regions: the Kidatu and Mtera dams, located in or near them, contribute 50 percent of Tanzania’s hydropower production capacity.\nHealth: Effects and adaptation measures\nThe most important drought-related diseases prevalent in the central regions are cholera, diarrhea, dysentery, malnutrition, and trachoma (which causes blindness). By 2030, even if the frequency or intensity of droughts doesn’t change, 5 percent of the regions’ population is projected to endure hunger from poor yields; the same percentage will suffer from trachoma. Cholera and dysentery will be common as well, and diarrhea will afflict almost 200,000 children under five.\nIn the moderate-climate-change scenario, by 2030 a 10 percent decrease in average rainfall levels could raise the proportion of the population under food stress by 60 percent, with a significant increase in the number of cases of cholera and dysentery. Trachoma cases could double. The high-climate-change scenario worsens the prognosis, particularly for trachoma.\nOur study analyzed measures that could protect Tanzanians against drought-related health risks. Some are preventive: for instance educational programs for hygiene, sanitation, and breastfeeding; the building of covered wells with pipes and ventilated pit latrines; and the harvesting of rainwater. Others are treatments, such as oral rehydration therapy and the administration of antimicrobials and zinc supplements.\nIt will not always be easy to distinguish spending for adaptation to climate change from development spending on health. Water access measures, for instance, could prevent thousands of cases of cholera, diarrhea, dysentery, and trachoma but could be considered sound policy no matter how the region’s climate evolves. Health spending should become more forward-looking rather than reactive.\nPower generation: Impacts and adaptation\nIn 2030, Tanzania is predicted to rely on hydropower for more than half of its electricity. Ninety-five percent of this hydropower will come from the central regions, but drought will decrease the water flow in rivers and thus cut the amount of electricity generated. The Tanzania Electricity Supply Company will have to make greater use of more expensive natural gas and coal—thus also increasing greenhouse gas emissions—or cut the supply of electricity. In the latter case, companies with diesel generators will bear the extra cost of using them, and the production of other 40 percent will fall.\nIn the high-change negative scenario, the expected losses would cut the national GDP by 1.7 percent in 2030. Even in the moderate-climate-change scenario, GDP will fall by 0.7 percent, solely because of climate change–induced droughts. Tanzania could close most of the expected shortfall in power production if it were to implement energy efficiency measures, such as reducing demand by encouraging less (or more careful) usage in the residential and commercial sectors—moves that would save more money than they would cost. In addition, reducing spillage at hydro stations could significantly increase the power supply almost free of charge. No-regrets energy efficiency measures such as these could be implemented immediately.\nWe do not know how much or how soon the global climate will change because of rising greenhouse gas emissions, but we do know that a country’s ability to cope with climate change will depend on its socioeconomic position. The poorest developing economies face especially difficult challenges both in addressing their current climate risks and adapting to new ones. For them, linking climate responses with economic-development strategies will be vital. A fact-based approach that considers both costs and benefits can help.']	['<urn:uuid:1ffc3654-ce67-4c2c-9fa3-80cb3775f998>']	factoid	with-premise	concise-and-natural	similar-to-document	single-doc	novice	2025-05-01T23:21:14.341336	15	15	2421
316	irish monasticism spiritual elevation compared mendicant orders urban ministry	Irish monasticism, exemplified by Eriugena's teachings, emphasized spiritual elevation toward theosis and transcendent spiritual flight, as modeled by St. John the Evangelist who rose above nature to grasp divine principles. In contrast, the mendicant orders emerged specifically to address urban needs, responding to the revival of urban centers and trade expansion, providing theological education, preaching, and confessional services to growing urban populations.	"['The mystery of God in John Scotus Eriugena\nWorking and writing at the Carolingian court, in the time of Charles the Bald, grandson of Charlemagne (Charles the Great), was an Irish master of the liberal arts, John Scotus (‘the Scot’) Eriugena (810-c.880). His soubriquet ‘Eriugena’ (‘born of Erin’) - was a mixed term of his own invention from the old Celtic language (Eriu is the Celtic name for Ireland) and from the Greek (‘gena’ = ‘born, originating from’) - on which language he was perhaps the only true expert in the Medieval West . The Emperor Charles the Bald therefore entrusted to him the task of translating the precious Codex he had been given by his Byzantine counterpart Michael III, containing the Corpus Areopagiticum, the complex of writings that at that time went under the name of Dionysius the Areopagite, and which have come to be known today as the Pseudo-Dionysius.\nScotus Eriugena’s translation became, therefore, vital for the Latin West’s knowledge and understanding of Dionysius, and of other important Greek patristic writers, such as Maximus the Confessor, the brilliant commentator on Dionysius, and Gregory of Nyssa. The Irishman was also the greatest theologian and philosopher before St. Anselm, and in his most famous work, the Periphyseon, constructed the Medieval Latin West’s first system of thought.\nHere, he joins the philosophical notion of natura (borrowed from Boethius) with the theological one of creation: the coupling of these two concepts, he believed, would enable the interpretation of all truth. In this he is strongly influenced by Dionysius, so much so as to constitute the first Christian neo-Platonic system. Paradoxically, his thought brings us back to the present, because some of his intuitions, impregnated as they are with idealism and Nominalism, were taken up by Hegel and his interpreters, whether in philosophy or in contemporary theology. He divided all reality into four parts:\n1) Nature which creates and is not created (God)\n2) Nature which creates and is created (the primordial, or first, cause)\n3) 1) Nature which does not create and is created (all created things, animate and inanimate)\n4) Nature which does not create and is not created (representing creation in its ultimate transformation, but also the mystery of evil, not created by God and capable only of destruction)\nAs will be evident, John Scotus Eriugena is capable of expressing, with the few intellectual means available in his own time, a vigorous and almost ‘modern’ philosophical construct, very full and articulate. He saw the reality of God and of the world united inseparably in one single movement of emanation and return (exitus et reditus), following neo-Platonic philosophy. The created world therefore has no consistency except as a theophany, that is to say, a manifestation of God, insofar as it is created by Him and returns to Him. The reality of God in himself is in fact unknowable, but creation is one manifestation of Him. The Incarnation of the Word, masterfully commented on in the Homily on the opening of the Gospel of John, is the historical moment when He who is by nature indefinable is personally united with Man, who is, by contrast, subject to limits and definitions. The Incarnate Word, testified to in the Gospel of John, is the ultimate manifestation of God, of his full and complete revelation, its highest theophany. This ontological (concerning the nature or essence of the person of Christ) union between the two natures constitutes the model, the first cause and the end of all creation.\nHowever, Eriugena occasionally goes to extremes in his efforts to show and explicate this union, falling into a complex and daring language which resulted in his doctrine, based on divine theophany, being accused later of pantheism, that is, of believing that the divine nature is immanent in all creation. His search, though, was sincerely Christian, despite its many limitations. He was, perhaps, ahead of his time, in that his understanding of Greek theology looks forward almost 300 years to the contemporary Palatine and Benedictine masters.\nThe limits of Carolingian culture appear, therefore, a little too tight for this brilliant Irish master, whose theology would be taken up in various ways by the great masters of Scholasticism, above all by St. Albertus Magnus and St. Thomas Aquinas.\nEriugenan spirituality is therefore essentially optimistic: Man is destined to divine transfiguration, that is, to the transformation of the self in the image of the Incarnate Word. All are predestined to such transformation. But in order to achieve it, the individual man must embrace the Christian faith, the one true religion, and therefore the only true philosophy. Predestination is tied therefore to the free choice of the individual for or against the Incarnate Word, as set out in the treatise (Of Predestination), written by the Irishman in 851. The important point is that this is the sole certitude about our human life in our possession.\nThe spiritual model for the Christian, according to Eriugena, is St. John the Evangelist, who, by transcendent spiritual flight, elevated himself like an eagle above the realm of Nature and the realm of Scriptural revelation (the Creation and the Old Testament), to grasp the supreme Principle of all things, the generation of the Word. Thus St. John had become more than man, more than human, in that God had rendered him capable of knowing this profound spiritual reality, and of transmitting it in his scriptural writings, the Gospel and the Letters (Epistles).\nWe can say then that in John Scotus Eriugena we find expressed the spiritual yearning that has its roots in the Irish monasticism of St. Patrick and St. Colombanus. He showed to the Christians (monastic and lay) of his times the path to theosis (attaining the divine) as a universal call to sanctity for all humankind. Therefore and thereby, true believers can become, by gradual progress, transformed in and into the image of the Son, and may arrive at a knowledge of the mystery of God, in that “No man hath seen God at any time; the only begotten Son, which is in the bosom of the Father, he hath declared him”.\nBiblioghaphy back ahead summary', ""Our editors will review what you’ve submitted and determine whether to revise the article.Join Britannica's Publishing Partner Program and our community of experts to gain a global audience for your work!\n- History of Roman Catholicism\n- The church of the early Middle Ages\n- The church of the High Middle Ages\n- From the late Middle Ages to the Reformation\n- The age of Reformation and Counter-Reformation\n- The church in the modern period\n- Structure of the church\n- The papacy\n- The offices of the clergy\n- Beliefs and practices\n- The order of the mass\n- The church since Vatican II\nReligious orders: canons and monks\nInterest in the humanity of Christ and the desire to live the apostolic life in imitation of him influenced religious orders in the 12th century. The reformed orders of canons represent one aspect of this trend. The founder of the Premonstratensian order, Norbert of Xanten, was recognized for inspiring many to imitate the life of Christ. The order spread throughout Europe after its founding in 1120 and cultivated both the active and the contemplative religious life. Norbert’s order was part of a broader movement to regularize the life of all canons by enforcing monastic rules.\nTraditional monastic life also underwent an apostolic-inspired reform in the late 11th and 12th centuries. Beginning with a few relatively small quasi-eremitic orders in Italy, such as the Camaldolese and the Vallombrosans, the movement spread to France with the founding of the extreme eremitic Grandmontines in 1077 and the eremitic Carthusians in 1084; it became as wide as Christendom with the multiplication of the daughter monasteries of Cîteaux (founded in 1098). The guiding principle of the Cistercians (based at Cîteaux) was exact observance of the Rule of St. Benedict, with emphasis on simplicity, poverty, and manual work. The addition of lay brothers tapped a large reservoir in an age of increased religious devotion and economic and population growth, and the organization of the order—which featured annual visitations and a general chapter—ensured good discipline and enabled the Cistercians to accommodate a vast family of houses scattered throughout the Latin church.\nThe success of Cîteaux owed much to the genius of St. Bernard, abbot of Clairvaux from 1115 to 1153, who was for 30 years the untitled religious leader of Europe. Owing to his influence, other new orders—such as the Premonstratensians, the English Gilbertines, and the military Knights Templars—accepted or imitated Cistercian practices. By the end of the 12th century, however, changing social conditions and growing urbanization necessitated a new kind of religious order that would assume the prominence in society once held by the monks.\nThe mendicant orders\nIn the early 13th century a new manifestation of the apostolic life appeared in the form of orders of mendicant preachers. The rise of the mendicants was in part a response to the revival of urban centres and the expansion of trade. The Waldenses, one of the first groups to adopt a life of evangelical poverty, were declared heretical for refusing to submit to ecclesiastical authority and for criticizing the church and its wealth. But the idea of adopting the apostolic life, prefigured by Robert d’Abrissel in the 12th century, was a powerful one that recalled the original purity and simplicity of the church at a time when both church and society were becoming increasingly wealthy and complex. Showing considerable foresight and discernment, Innocent III embraced the movement and made it part of the church when he approved the Franciscan and Dominican orders.\nFrancis of Assisi, a man of magnetic personality who believed that he was called by Christ to preach poverty, had no thought of founding an order, but his message and his genius exactly suited the age, and the vast concourse of his followers gradually transformed itself from a homeless, penniless band of preachers and missionaries in Italy into an international body governed by a single general and devoted to the service of the papacy. In contrast, Dominic de Guzmán (c. 1170–1221), whose vocation was preaching against heretics and whose followers kept a canonical rule, changed his existing institute into one of friars. Gradually the two groups became similar: international, articulated groups of men bound to an order but not to a community. They took the customary monastic vows of poverty, chastity, and obedience but dropped the vow of stabilitas (“stability”) in favour of mobility, and they were governed by elected superiors under a supreme chapter and a general. Remarkably, first the Dominicans and then the Franciscans entered and soon dominated the theological schools of Paris and Oxford. Two similar bodies joined them, the Carmelites and the Austin Friars, and for almost a century the members of the various mendicant orders were the theologians, the preachers, and the confessors of the Christian people.\nThe rise of heresy\nThe same religious enthusiasm that contributed to the rise of Gregorian Reform and the orthodox movements of the late 11th and 12th centuries also inspired movements of religious dissent or heresy. The earliest episodes of heresy in the West predate the Gregorian Reform, and their ideals may have been absorbed by the Gregorians. In the early 12th century Gregorian Reform movement may have given rise to a wave of radical reformers whose religious zeal led them to excessive criticism of the church. The early dissenters, such as Tanchelm and Peter of Bruys, attracted large but ephemeral followings of clergy and laity. In the 1150s the Italian canon Arnold of Brescia (died 1155), an outspoken critic of clerical wealth and corruption, assumed the leadership of a revolt against the pope in Rome. Despite their popular appeal, these dissident leaders failed to inspire the kind of broad movement that would emerge later in the century.\nBy the 1140s and possibly earlier, Bogomil missionaries from the eastern Mediterranean or the Balkans appeared in parts of western Europe. Their preaching and ascetic lifestyle gave rise to the Cathari (from Greek katharos, meaning “pure,” from the ascetic lives of their leaders), a sect that became prominent in northern Italy and southern France. Although the Cathari maintained that they alone were true Christians, their leaders, the “perfects,” overtly denied many traditional Christian doctrines, such as the Incarnation of Christ (they taught a Docetist Christology, which maintained that Christ only appeared to assume the flesh). Cathari teachings were dualistic, regarding matter and the human body as evil and spirit as good. Consequently, the perfects ate no meat and practiced celibacy. The sect’s emphasis on poverty and its practice of mutual assistance appealed to many who were repelled by the luxury and wealth in which the Catholic hierarchy then lived. In the 1170s the Waldenses (named after their founder, the French merchant Valdes [often incorrectly known as Peter Waldo]) initiated another type of dissent in the Rhône valley and Piedmont. Anticipating St. Francis of Assisi, Valdes adopted a life of poverty and evangelism, and the movement grew in the newly emerging towns of Europe.\nThese groups, basically and professedly orthodox, together with the reform-minded Humiliati of Lombardy (Italy), practiced poverty, Scripture reading, and preaching. The Cathari were proscribed as heretics by the papacy and were attacked by a Crusade and later by the Inquisition, and they gradually disappeared. The Humiliati remained orthodox as a quasi-religious order. The Waldenses, largely through mismanagement by the bishops and papal refusal to allow them to preach, drifted away from the church. Officially condemned as heretical by Pope Lucius III (reigned 1181–85), they remained a non-Catholic body through the Middle Ages and afterward.\nThese heretical movements suggest that the great sense of purpose and energy that had opened the 12th century had been lost by the century’s last decades, which were notably barren of saints and other leaders. They also reflected the church’s inadequate response to changing social and economic conditions, such as the growth of towns and trade, and to the spiritual needs of the growing urban population of Europe. Moreover, the church was deemed too materialistic, and the pope himself seemed either part of the problem or unable to resolve the church’s difficulties.\nReligious life in the 13th century\nThe 13th century was an age of fresh endeavour and splendid maturity in the realms of philosophy, theology, and art, and it has traditionally been regarded as the high point of medieval civilization. The revival of religious life and culture in the period was heralded by the vigorous papacy of Innocent III, one of the youngest and most energetic popes to hold the throne of St. Peter. As pope, Innocent intervened in the political affairs of various European rulers and expanded the jurisdictional claims of his predecessors, preparing the way for the great lawyer-popes of the 13th century. He was an advocate of Crusades in the Holy Land and against heretics. Concerned as well with the religious life of the church, he co-opted the mendicant movement of the Waldenses by recognizing the order of St. Francis and some groups of Humiliati. He also held the fourth Lateran Council (1215), one of the most important church councils of the Middle Ages.\nThe coming of the friars and the legislation of the fourth Lateran Council—including requirements of annual confession and Communion and a reduction in the number of impediments to marriage—saved the lower classes for the church and silenced many critics of the establishment. Well-trained and extremely mobile, the friars were able to reach and hold regions and peoples that the static monks and clergy had failed to persuade. The friars were also closely associated with the Beguines, a laywomen’s religious movement with roots in the late 12th century.\nThe 13th century in Europe as a whole was a time of pastoral activity in which bishops and university-trained clergy perfected the diocesan and parish organization and reformed many abuses. Nevertheless, the period was not without its share of controversies. The Beguines faced skepticism and prejudice despite their promotion of chastity, contemplation, and labour. The mendicants also encountered opposition. The early friars served and were welcomed by the bishops and parish clergy, but clashes soon occurred; the papacy gave the friars exemptions and privileges so wide that the basic rights of the secular clergy were threatened. An academic “war of pamphlets” led to an attack on the vocation and work of the friars. Finally, Boniface VIII (reigned 1294–1303) arranged a compromise that was just and workable; under a revised form it lasted for two centuries. A bishop could refuse friars entry into his diocese, but, once they had been admitted, the friars were free of his control.""]"	['<urn:uuid:cdc6e8e9-f939-4067-b095-7796c7805970>', '<urn:uuid:cead7d51-1ed4-4986-b10b-dad885b57ab1>']	factoid	with-premise	long-search-query	similar-to-document	comparison	expert	2025-05-01T23:21:14.341336	9	62	2774
325	When comparing chicken biryani and chickpea pilaf preparation methods, which one takes longer to make using a pressure cooker?	A chicken biryani in pressure cooker requires marination time and is made in dum style, while chickpea pilaf in a pressure cooker takes just 5 minutes of pressure cooking plus 15 minutes of natural pressure release. The pilaf is a quicker preparation since it just requires sautéing onions and spices before pressure cooking.	['Biryani recipes – This post on collection of 30 vegetarian and non-vegetarian biriyani recipes will teach you how to make biryani at home. Hyderabadi biryani is one of the most loved rice dishes among Indians. The term “BIRYANI” is derived from the Persian word “BERIAN” meaning fried before cooking.(source:wiki). Traditionally, rice was fried in ghee until aromatic before cooking with meat.\nBiryani is dated back to the mughal reign during which Begum Mumtaz Mahal had ordered her chefs to make something special for the undernourished soldiers. The chefs came up with a rice dish which was layered with meat, rice, nuts and spices and was highly nutritious and delicious too. It was steam cooked in the “DUM PUKHT” method which means “slow cooked” in Persian language. Thus delicious aromatic meat Biryani was born. There are many such stories and this is one among them.\nOver the years it has been adapted to suit one’s personal liking or taste. Today we can find so many versions that the authentic way of cooking is almost not found in many recipes and very much they are made using vegetables alone without meat and not even dum cooked.\nAcross India one can find different kinds of biriyani made in their own regional style but inspired from the mughal cuisine. This is one of the dishes that makes its appearance in weddings, celebrations and parties.\nThe difference between a pulao and biriyani is that, pulao is made with very few spices while biriyani is made with lot more spices and even spice powders. There is no yogurt used in pulao while most biriyani recipes use yogurt, especially the ones made with meat which also helps to tenderize the chicken or mutton.\nThe quality of spices, basmati rice and saffron contribute to the unique flavors of the dish. So it is highly recommended to use pure and premium quality spices.\nIn this post, You can find biryani recipes that are made in different styles along with a few close to the authentic style from the Mughlai cuisine, Hyderabadi and Awadhi cuisnes. Biriyani is usually served with a raita (a yogurt based dish ) or with a shorba / sherva or salan (thick or thin gravy). You can find raita recipes here . I will share non-vegetarian shorba recipes soon.\nBiryani recipes – Collection of 30 biriyani varieties\nChicken biryani in pressure cooker – Spicy, flavorful and delicious chicken biriyani made in pressure cooker in dum style. This is a quick one pot recipe for students, working women and bachelors which can be made even on busy week nights.\nVeg biryani Restaurant style : A one pot dish similar to the one we get in Indian restaurants. Very very aromatic and delicious dish. One of the top recipes on the blog. Recipe includes making spice powder or masala needed for the dish.\nHyderabadi kachi chicken biryani. This is a super simple recipe made the authentic way by marinating chicken with spices, curd and herbs. Then Dum cooked to perfection to yield fragrant & delicious rice with tender & soft chicken.\nAmbur chicken biryani : Tamilnadu style popular rice dish from Ambur. This is prepared using short grain rice called as seerga samba rice or Jeera rice. This is served with Ennai kathrikai and raita. This dish is mostly made with mutton but one can also find the one made with chicken in most Ambur Biriyani centers.\nEgg roast biryani recipe : Kerala style egg roast biryani is one of its kinds that is similar to the Kerala street food that is sold as Neichoru / ghee rice topped with egg roast. This is very flavorful with an unique aroma that comes from the blend of kerala spices.\nVeg biryani in cooker : Quick one pot dish made with mixed vegetables and rice in pressure cooker. A 30 mins recipe, great for lunch box or quick dinner. It can also be made in a pot. A must try for beginners, students and bachelors.\nChettinad chicken biryani with coconut milk – A unique combination of spices and coconut milk makes this dish taste delicious and aromatic.\nHyderabadi veg biryani cooked in dum style with mixed veggies and nuts, similar to the authentic dish.\nAwadhi chicken biriyani :Lucknowi style dum biriyani made with chicken. This is popular mostly in north Indian restaurants and is well known for its unique aroma & simplicity.\nMalabar or Thalassery chicken biriyani recipe : One of the popular dishes prepared with a premium quality fragrant short grain rice known as Jeerakasala or kaima rice. This dish has originated in the malabar region of kerala. It is served with chamanthi or raita.\nHyderabadi pakki chicken biryani. In this recipe chicken is cooked first with the marinade and then parboiled basmati rice is layered. Then dum cooked for a short time.\nHyderabadi Mutton Biryani : This is another hyderabadi popular recipe made with mutton. This post also explains in detail how to soft cook mutton before layering.\nEasy mutton biryani in cooker : Simple beginners recipe to make yummy lamb biriyani in pressure cooker. The recipe can be easily adapted to make south Indian or North Indian dish.\nEgg biriyani in cooker : A quick and easy one pot spicy rice made with biriyani spices, herbs and boiled eggs. Makes a great dinner on a week night.\nChicken fry biriyani: Layered chicken biriyani popular in most andhra restaurants in Singapore. It has a unique taste and aroma. If you love spicy and hot andhra foods then you will love this.\nHyderabadi egg biryani Made in dum style and is easy to make even for parties or family get together.\nFish biryani : Did you ever think of making a unbeatable dish using fish? Then this is a must try. The flavor of spiced & fried fish is special in this dish.\nHyderabadi biryani restaurant style chicken biriyani: If you have ever been hooked to the restaurant flavors of Hyderabadi biriyani then you will like this. This can also be made in oven.\nHyderabadi mutton dum biryani : This is made in kachi style, mutton is marinate with spices, herbs and yogurt. Then half cooked rice is layered and dum cooked.\nPlain Biryani rice or kuska One pot dish made with basic spices and no veggies are used. This is usually served in some restaurants in a thali or a meal. It is served with a gravy dish & raita.\nMuslim biryani : A one pot dish, can be made using chicken or mutton. This tastes similar to the one that is served in south Indian muslim weddings mostly in Tamil nadu and Andhra pradesh.\nSoya chunks Biryani : If you trying to be on a vegetarian diet, but missing your meat. You can try this meal maker one pot rice dish.\nPaneer Biryani: Made in hyderabadi style dum cooked marinated paneer and rice. Kids’ friendly and can be made for parties as well.\nTomato biryani : One pot simple biriyani made in pot or pressure cooker along with some veggies. This goes great in lunch boxes and for quick dinner even on week nights.\nSoya keema biryani recipe: Inspired from the popular keema biriyani from hyderabadi cuisine.\nPotato biryani Dum style & made with aloo. This can also be made with baby potatoes.\nPaneer dum biryani recipe : This is one of the oldest recipes on the blog. Made in hyderabadi style this paneer biryani is surely going to impress your guests. One of the best vegetarian biriyani anyone can make.\nMushroom Biryani recipe made in pot or cooker. Very flavorful and quick to make for lunch box or even dinner.\nIf you are a beginner you can also learn how to cook basmathi rice for biriyani here', 'Chickpea Pilaf is a light, fragrant rice dish. It is a delightful combination of lightly spiced rice and protein-rich, buttery chickpeas. Serve it as a one-pot meal on a busy day or as a side dish for a more elaborate meal. The dish itself is vegan and pairs well with riatas (yogurt dip), kabobs, chutneys, or spicy curries. This instant pot, pressure cooker-friendly meal is a good reason to ditch takeout and eat more real food at home. Vegan Gluten Free\nI love the buttery chickpeas here. The flavors are mild, each grain of rice is separate, light, and fragrant. A side of sliced cucumbers, onions, carrots, and raita is my favorite way to polish off this entire plate.\nWhat is pilaf\nPilaf or pulao or pilav is a dish where rice or wheat or other grains are cooked in a flavored broth. Often some protein is added to the dish to make it a one-pot meal. There are variations of this dish from the Caribbeans to Bangladesh to Azerbaijan to Turkey. The spices and herbs used vary depending on the region but almost always the finished dish will have rice or other grains just cooked right and not sticking to each other.\nIn terms of spiciness, this chickpea pilaf is on the light and fragrant side. Each of the basmati rice grains is cooked just right and stays separate from the other. There are just enough spices to complement the rice and the garbanzo beans without overpowering them. Here is a light meal that is going to make everyone happy including the cook.\n- Rice: Basmati rice is the best for this recipe and the cooking time and amount of water are based on this type of rice.\n- Chickpeas / Garbanzo Beans: Cooked garbanzo beans are used here. You can use either the canned beans or cook them separately. Often when I make dishes like Hummus or Chole, I cook more beans than required for the dish. The extra beans can be easily frozen or refrigerated for a few days without loss of flavors.\n- Spices: Whole spices are what I use here. Whole spices gently infuse this dish with flavors. Whole spices have much more complex flavors and the aromatic oils just seep into the water as it cooks. It makes it easy to fish it out later as well.\n- Additions: Onions are important to this recipe as much as the spices. At times I like to add a few peas or carrots (used here), these are optional, used in moderation.\nMaking the Pilaf\nOnions are as important to this recipe as the spices and this dish starts with cooking onions. Slicing the onions thin to about the same size make them cook evenly at the same time.\nSet the instant pot on saute mode and cook the onions until they begin to turn golden in the edges. If you prefer to give the rice a darker color cook the onions until they are brown. Remember to stir often to prevent them from burning.\nAdd the spices, ginger and garlic to the pot. The order does not matter much. Heating the spices releases the fragrances (the essential oils), which in turn makes the pilaf very aromatic. Cooking the ginger garlic changes the flavors a little and flavors infuse the oil. Care should be taken not to burn the ingredients.\nAdd the chopped carrots or peas (if using) and the washed and drained rice to the cooked onions. Sauté the rice for 1 to 2 minutes stirring a few times to coat all the grains with oil. Add the water and salt. Taste the water at this point. The water should taste salty. Cancel the sauté mode.\nClose the lid with the vent sealed. Set the IP in manual mode, high pressure for 5 minutes. Let the pressure release naturally for 15 minutes before opening.\nOpen the lid and fluff the rice with a fork and serve.\nCooking on stovetop\nYou can make this dish in a Dutch Oven or stovetop pressure cooker as well. If using Dutch Oven increase water to double the quantity of rice and in stovetop pressure cooker increase it to 11/2 times the quantity of rice.\nPilafs are great as a side to grilled meat or kabobs. These are great as main course as well. Usually an assorted accompaniments are served along with it when Pilaf is the star of the dining table. Sliced vegetables, chopped salad, raita (yogurt flavors with herbs), pickles, chips, and papad are popular accompaniments.\nIt tastes best when served fresh but stays fresh in the fridge for 2 to 3 days.\n- Instant Pot\n- 2 Cups Basmati rice\n- 1 ½ Cups Cooked Chickpeas 15 oz can drained\n- 3 Tbsp Oil (Notes)\n- 1 Cups Onion thinly sliced\n- 4 Cloves Garlic grated or finely minced\n- 1 Inch Fresh Ginger grated or finely minced\n- 1-2 Bay Leaves\n- 1 Cinnamon stick 2 inch piece\n- 3 Pods Green Cardamom\n- 4 Whole Cloves\n- 1 Tsp Cumin Seeds\n- 1 Tsp Fennel Seeds\n- 1 1/2 Tsp salt adjust to taste\n- 2 1/2 Cups water\n- ½ C Carrots Diced\n- 2 Tbsp Golden Raisins\n- ½ C Peas\n- Wash and drain the rice. Slice the onions thin. If adding carrots chop them into small pieces. Assemble all ingredients.\n- Turn on the sauté mode. Add 3 tbsp oil. Add the sliced onions and whole spices. Sauté the onions stirring often until the onions turn golden on the edges (see notes). Add the garlic and ginger.\n- Once the onions reach the desired color add the vegetables, chickpeas, salt, raisins (if using), and the drained rice. Mix and add the water. Close the lid and seal the vent. Turn on the manual mode and set the time to 5 minutes. Let the pressure release naturally. Open the lid and fluff the rice before serving.\nStove Top pressure cooker\n- Follow the recipe above but use 11/2 C water for 2 C rice. Turn off once the whistle blows. Wait for at least 5 minutes before releasing the pressure to open the lid.\n- Traditionally ghee or a mix of ghee and oil was used. Any neutral vegetable oil will work in this recipe.\n- If you want darker color and caramel flavor to the rice let the onions cook till browned nicely. Optionally you can add a ½ tsp sugar to help with caramelization. In this case wait for the onions to begin browning before adding the spices.\n- The order of adding vegetables and whole spices does not matter much in pressure cooking. Other than caramelizing onions you can add all the other ingredients together and cook.\nImportant: Values are only estimates. Actuals vary depending on ingredients and serving size.\nMore Instant Pot Dishes\n- Shrimp Biryani with Vegetables\n- Instant Pot Bulgogi Bowl\n- Brown Chickpeas Curry\n- Everyday Black Lentils\n- One Pot Spicy Chicken Stew\n- Ribolita – Tuscan Bean and Vegetable Soup\n- All Instant Pot Recipes']	['<urn:uuid:0b003b88-4503-42ab-ad05-3e6843a751e1>', '<urn:uuid:f301c665-d96a-4974-82d3-50a349402229>']	factoid	direct	verbose-and-natural	distant-from-document	comparison	novice	2025-05-01T23:21:14.341336	19	53	2472
326	I'm researching historical art - how did ancient Jewish and Egyptian cherubim compare?	The Egyptian and Jewish cherubim designs showed remarkable similarities. The Egyptians had arks decorated with winged guardian figures that were carried by priests using two poles, just like the Israelite Ark of the Covenant which had two permanent poles and cherubim on top. These similarities can be seen in Egyptian artifacts like Tutankhamun's Shrine. Both cultures used their arks in military contexts - Egyptian reliefs show their ark with cherubim in battle scenes, while biblical accounts describe the Israelite ark being carried into battles against the Midianites, at Jericho, and during the reigns of Kings Saul and David. These parallels reflect how the Israelites, having lived in Egypt, likely adapted and modified certain Egyptian practices while rejecting others. The cherubim in both cases were winged figures meant to guard and protect sacred objects.	['Maimonides taught that the Torah only “allowed” sacrifices because the Israelites saw pagans showing love of their gods by offering them, but the Torah restricted how the offerings should be made (Guide of the Perplexed 3:32). The Cherubim is an example of how the Israelites copied pagan practices.\nOne of the most perplexing ancient Jewish articles is the Ark of the Covenant that tradition states contained both the shattered and whole Decalogue (Ten Commandments). The Ark had two poles that were never removed from the box. No reason is given for this practice. The cover of the Ark contained two winged figures called cherubim. No explanation was offered in the Bible for their presence, leaving us with only speculation. What is most bothersome is that the presence of two winged creatures seems to violate the biblical law prohibiting the building of such figures.\nWhat were the cherubim?\nThe cherubim were two figures placed on top of the ark which was set in the holiest place in the tabernacle and later temples, the “holy of holies.” Some scholars and rabbis say that perhaps the purpose of the cherubim was to screen the ark with their wings so that the ark would not be seen. Others say that the cherubim were guards protecting the ark. A decorative representation of the cherubim was also placed on many parts of the tabernacle and temples. What were the cherubim?\nThe term cherubim is obscure. Some scholars think it is an inversion of letters and is derived fromrekhuv, which means “chariot.” Others suggest that it is from the Akkadian karabu, “to pray” or “to bless” and that the cherubim were beings who interceded and brought the prayers of humans to the gods. We simply do not know.\nScripture does not describe the cherubim. Based on the Babylonian Talmud, Sukkah 5b, Rashi relates a tradition that they had children’s faces, although when cherubim are first mentioned in Genesis 3:24, both Saadiah Gaon and Rashi described them as angels. Rashbam, Rashi’s grandson, suggested that they had the form of birds.\nTwo biblical sources, Exodus and II Chronicles, give different descriptions of the cherubim arrangement. Exodus states that the two figures had “faces [turned] to the other.” Chronicles says instead that they “faced the house,” the temple. The Babylonian Talmud offers a homiletical explanation for the difference: when Israel did the will of God, the cherubim faced each other; but when they did not do God’s will, they faced away from each other.\nThis is a nice sermonic lesson; however, we know that the biblical book of Chronicles has many differences from the Five Books of Moses. It even changed names of biblical characters and spelled names differently. While the authors of the biblical books Judges, Joshua, Samuel, and Kings told about the ancient Israelites and included their faults and failures, the author of Chronicles wrote his book to show the glory of the past and omitted the ancestors’ faults. Thus he was not careful to copy what others wrote before him. It seems clear that even in the far ancient time, centuries before the Common Era, biblical writers did not know what the cherubim looked like or anything about its origin and purpose.\nJosephus, writing in his book Antiquities during the first century CE, admits that we no longer have any idea what the cherubim looked like or what their function was. We know that other ancient cultures had similar if not the same structures. The Babylonians, for example, used winged bulls with human faces set at the entrance to their temples and palaces to protect them.\nDid the ancient Israelites copy the Babylonian idea or an even earlier one? Are these figures a violation of the Decalogue command not to make figures? Many rabbis say that that the commandment only prohibited making idols to worship them and didn’t prohibit making other statutes and paintings.\nThe Egyptians had them before the time of the Torah\nThe ark and covering figures used by the ancient Egyptians was startlingly similar to the Israelite ark and cherubim. Pictures of the ark and its winged guardians can be found in several places in Egypt today, including on Tutankhamen’s Shrine and on top of King Tut’s Tomb. The pictures can be seen on www.thelivingmoon.com/42stargate/03files/Egyptian_Arks.html.\nEgypt was the most powerful nation in the world in biblical times. Its culture was very advanced. Living in Egypt for centuries, the Israelites, which my friend Hessel Meilech called “the world’s chameleons,” probably absorbed and improved many Egyptian ideas while, at the same time, rejecting many of them, such as the Egyptian ceremonies and theology regarding the dead.\nThe Israelites must have seen the Egyptian ark decorated with its cherubim carried by Egyptian priests by means of the two poles that extended from its base.\nScholars have been puzzled for ages why the Israelite ark had two poles that were never removed even when the ark and its cherubim were placed in the “holy of holies,” hidden behind a curtain. Arnold Ehrlich suggested in his book Mikra Ki-Pheschuto that the poles were left in the ark because from time to time the priests or levites would carry the ark to various communities so that the people could see it and perhaps donate toward the maintenance of the temple.\nNow we know that Ehrlich was right. The Egyptian ark not only had cherubim but also poles, and we have pictures of the Egyptian priests carrying their ark from place to place while holding it by its poles.\nAdditionally, it appears that the Israelites used their ark in another way similar to the Egyptians. Reliefs illustrating Rameses military camp at the Battle of Kadesh depict an ark with cherubim in the center of the battlefield (See here: http://www.amazon.com/The-warfare-Biblical-lands-archaeological/dp/B0007DK08C ). Likewise, Moses told the priests to lead the ark into battle against the Midianites (Numbers 31:6). In the Israelite’s conquer of Jericho, the ark went in front of the marchers around the city (Joshua 6:6-8). King Saul had the ark carried into battle (1 Samuel 14:18), as did King David (2 Samuel 11:11).\nThis raises an issue far more bothersome than the question of the violation of the divine prohibition against making images: adopting non-Jewish practices. Actually, this copying of the cherubim is far from unique. Judaism incorporated many non-Jewish practices and theological notions, some of which are bizarre and totally contrary to basic Jewish beliefs.\nWe changed the concept of when the day begins from morning to evening, when the year starts from the spring to the fall, we took the names of the “Hebrew” months from the Babylonians despite at least one being the name of a Babylonian idol, we accepted the Babylonian notion that God judges people during the fall new year (and not before?), and much more. Even many rabbis were and are convinced that St. Augustine’s view that there is an “original sin” which soiled humanity is Jewish. The idea is found in the writings of rabbis in the middle ages and we hear it in sermons today. Augustine (354-430) developed the concept to explain why Jesus had to die: “he died for our sin.” While this notion did not exist before the fourth century and is a basic Christian belief, many Jews bought into it without realizing its origin and without seeing that it is inexplicable: although Augustine said that Jesus died to save humanity by removing “original sin,” people believe they are still stained by it today.\nMaimonides’ Guide of the Perplexed 3:32 explains the ark\nMaimonides’ explained in his Guide of the Perplexed 3:32 that the relatively primitive ancient Hebrews needed to be weaned from old beliefs and customs such as sacrifices. God “allowed” sacrifices to continue in a restricted manner, although God did not want or need them, because the people needed them: they saw that other nations used sacrifices to show their love of their gods. The ark is a good example of his insight.\n Biblical citations for the cherubim, for example, are Genesis 3:24; Exodus 25:18–20, 26:1, 31, 36:8, 35; I Kings6:27–29, 32, 35, 7:29, 36; I Samuel 4:4; II Samuel 6:2, 22:11; II Kings 19:15; Isaiah 37:16; Ezekiel 1ff, 10ff, 28:13ff, 37:7–9, 41:18–20, 25; Psalms 18:11, 80:2, 99:1; I Chronicles 28:18; and II Chronicles 3:13. See also the Babylonian Talmud, Bava Batra 99a and Yoma 54a-b.\n Exodus 25:20 and 37:9.\n II Chronicles 3:13.\n Bava Batra 99a.', 'What Kind of Creatures Are the Cherubim?\nThe centerpiece of a typical temple in the ancient world was a statue of a god. The tabernacle (משכן) is different in that it does not have such a statue. What it does have are two golden statues of cherubim (כרובים) who spread their wings over the kapporet, the lid of the ark of the testimony (Exodus 25:18–20 ≈ 37:7–9). Above the kapporet from between these two cherubim, YHWH meets with Moshe and speaks to him (Exodus 25:22 ≈ Numbers 7:89; cf. Leviticus 16:2).\nThe impression given by Exodus, that cherubim played a central role in the earliest stage of Judaism, is reinforced by references to cherubim elsewhere in the Tanakh:\n- Statues of cherubim, of a somewhat different form, also spread their wings over the ark in the Jerusalem temple (1 Kings 6:23–28 ≈ 2 Chronicles 3:10–13; 1 Kings 8:6, 7 ≈ 2 Chronicles 5:7, 8; 1 Chronicles 28:18).\n- Two-dimensional representations of cherubim decorate surfaces of the tabernacle (Exodus 26:1 = 36:8, 26:31 = 36:35) and the temple (1 Kings 6:29, 32, 35; 7:29, 36; Ezekiel 41:18, 20, 25; 2 Chronicles 3:7, 14).\n- Living cherubim are associated with the Garden of Eden (Genesis 3:24; Ezekiel 28:14, 16)\n- They are, apparently, described as being with YHWH as something he rides or sits upon (2 Samuel 22:11 ≈ Psalms 18:11; Ezekiel 9:3; 10:1–22; 11:22).\n- Cherubim constitute a component in an epithet of YHWH which can be translated provisionally as “the cherubim sitter” or “the cherubim dweller”: י(ו)שב הכר(ו)בים / ישב כרובים (1 Samuel 4:4; 2 Samuel 6:2 ≈ 1 Chronicles 13:6; 2 Kings 19:15 ≈ Isaiah 37,16; Psalms 80:2; 99:1).\nWhat, specifically, is a cherub? In other words, what form or forms of creatures does the word כרוב designate?\nThe first recorded attempt to identify the form of the cherub was made by the amora R. Abbahu of Caesarea (ca. 279–320), who employed a midrashic reading of כרוב as כרביא, which can be translated from Aramaic as “like a lad,” to assert that the cherub resembles a child (b. Ḥagigah 13b, Sukkah 5b). However, the cherubim are said to have wings (Exodus 25:20 = 37:9; 1 Kings 6:24, 27 ≈ 2 Chronicles 3:11–13; 1 Kings 8:6–7 = 2 Chronicles 5:7–8), and winged children are not attested in the iconography of the Land of Israel in the biblical period.\nThis identification is likely prompted by the erotes and cupids, the oft-winged boys that personified amorousness in the Greco-Roman art of R. Abbahu’s time. This conclusion can also explain the existence of several peculiar talmudic homilies attributing an erotic aspect to the cherubim of the Jerusalem temple (b. Yoma 54a–b).\nAn anonymous sage in Midrash Hagadol asserted that the cherub resembles a human in all respects except that it has the wings of a bird; the anonymous exegete, unlike R. Abbahu, did not specify an age and presumably had in mind an adult. This view was endorsed in part by Radak (ca. 1160–1235) and Ralbag (1288–1344). The identification of cherubim as winged humans, whether adults or children, found early expression in Jewish and Christian visual art. For example, an illuminated Hebrew manuscript from northern France, dated to 1277–1286, shows the tabernacle ark cherubim as childlike creatures with six wings each, as influenced by Isa 6:2 [Figure 1].\nIt is now known that the winged adult human is a common denizen of ancient Near Eastern iconography, and several modern scholars have identified the cherub with it, including Carl F. Keil and Franz Delitzsch, Robert Pfeiffer, and Louis-Hugues Vincent.\nRashbam (ca. 1085–1158) and Hizkuni (thirteenth century) stated that cherubim are birds. This identification enjoys visual expression in a fifteenth-century drawing by the prolific Jewish illuminator Joel b. Simeon Feibush showing the biblical ark surmounted by two pigeon-like birds [Figure 2]. In the modern era, François Lenormant expressed the same idea regarding the tabernacle ark cherubim, writing that they were probably birds fashioned in the Egyptian artistic style.\nAn intermediate position between this view and the preceding one was taken by Abraham b. Moses Maimonides (1186–1237), who suggested that the ark cherubim in the tabernacle had human heads and faces and avian wings, bodies and feet. He admitted the speculative nature of the suggestion and adduced no arguments in its favor.\nRashbam’s student Joseph Bekhor Shor (second half of the twelfth century), whose name means “firstborn of an ox” – coincidence? – along with Isaac of Vienna (ca. 1180–1250) and other tosafists, proffered the view that typical cherubim are “angels in the image of oxen.” Later scholars, such as the seventeenth-century Protestant polymath Hugo Grotius, promoted similar views. One reason for this suggestion is the fact that the word “שור” in Ezekiel 1:10 is replaced by “כרוב” in Ezekiel 10:14, implying the terms are synonymous.\nBy the end of the eighteenth century, material evidence was adduced to support these views: the human-headed winged bull colossi of Persepolis, which were known from a drawing and description by Dutch traveler Cornelis de Bruyn [Figure 3]. Later, the publicity received by colossal human-headed winged bulls in Assyrian palaces excavated in the mid-nineteenth century [Figure 4], along with the mistaken belief that the Akkadian words kirûbu or kāribu designated these beings, boosted the view that cherubim shared the form of these colossi.\nDoubting the association of the cherub with the human-headed winged bull, the nineteenth-century biblicist August Dillmann preferred to connect the cherub with the griffin, or raptor-headed winged lion. The griffin appears in ancient Levantine iconography; for example, on a thirteenth-century B.C.E. ivory plaque from Megiddo [Figure 5].\nThe prevailing opinion in current scholarship is that the cherub is a winged sphinx, i.e., a human-headed winged lion, such as that depicted on the sarcophagus of the late second-millennium B.C.E. Phoenician king Ahiram [Figure 6]. However, numerous indications found in the descriptions of the sculpted cherubim over the ark (Exodus 25:18–20 = 37:7–9; 1 Kings 6:23–26) reveal that their authors presupposed upright creatures.\nEvidence that the Cherubs Stand Upright\nSheltering with Wings - In the tabernacle, the ark cherubim are described as facing each other and “sheltering the kapporet with their wings” (Exodus 25:20 = 37:9). As noted by Umberto Cassuto and Richard Barnett, if the cherubim stood on four feet, they would shelter the כַּפֹּרֶת with their bodies, not with their wings.\nStanding on the Edge - It can be added that the cherubim are said to be located on either “edge” (קצה) of the kapporet (ibid. 25:18–19 = 37:7–8). If they stood on four legs and their bodies stretched over the length of the kapporet, the word “edge” would be inappropriate.\nAwkward Position for Four-Legged Creature - Moreover, the statement that the cherubim shelter the kapporet with their wings indicates that the wings are extended forward (toward the center of the kapporet), beyond their heads. No depiction of a creature standing on four legs with its wings extended in such an awkward and clumsy position can be found in ancient Near Eastern visual art.\nNo Length Measurement - In the case of the ark cherubim in the temple, the biblical text notes their height and “width” (wingspan), but not their length (1 Kings 6:23–28). As argued by Otto Thenius and many subsequent scholars, this can only be understood if we assume that the cherubim are upright and therefore have no significant length.\nWingspan Equal to Height - An additional indication that the temple ark cherubim are upright creatures is that they are described as possessing a wingspan, 10 cubits (1 Kings 6:24, 25; cf. 2 Chronicles 3:11–13), that equals their height, also 10 cubits (1 Kings 6:23, 26). Franz Landsberger noted that this proportion does not evoke animal forms. Martin Metzger developed the argument in light of his investigation of composite creatures in the ancient Near East. He stated that a composite four-legged creature whose height when standing on its four feet is 10 cubits would have wings of 12–15 cubits each – a length significantly greater the 5 cubits specified in the Bible.\nThe uprightness of the cherub precludes its identification with the winged sphinx, as well as the winged bovine and griffin, which are all non-upright, four-legged creatures.\nA final possibility, first proposed by the tenth-century Jewish grammarian Menahem ibn Saruq, is that כרוב simply means “figure.” Abraham ibn Ezra (ca. 1090–1160s) later elaborated on this idea, stressing that in different contexts the word can refer to different types of creatures. Ibn Saruq and Ibn Ezra follow an older tradition expressed in Targum Neofiti and Saadia b. Joseph Gaon, both of whom rendered the word כרבים in the descriptions of the tabernacle tapestries as “figures.”\nAn entirely different view etymologically, but one which leads to a similar, generalized identification of the cherub, was expressed by the thirteenth-century tosafist Isaac b. Judah Halevi in his work Panah Raza. He explained the root כרב as carrying the meaning “mix.” Thus, he characterized the cherubim of Eden in Genesis as “angels in the form of demons” and argued that their name is a reflection of the fact that they contain a mixture of two species. This identification seems essentially the same as what today would be called a composite or hybrid creature (German: Mischwesen).\nLike the previously cited views, the understanding of כרוב as referring to composite creatures generally, or to a class thereof, has been revived in modern times. Contemporary scholars advocating this position rely on the existence of what they see as contradictory descriptions of cherubim within the Hebrew Bible.\nThis view is challenged by the fact that the biblical writers usually neglect to specify the form of the cherub, even when specifying other details such as materials, position, and dimensions (Exodus 25:18–20 = 37:7–9; 1 Kings 6:23–28 ≈ 2 Chronicles 3:10–13). This omission indicates that there was assumed to be a typical form, with which the reader would be familiar.\nWinged Adult Revisited\nI believe that the the anonymous sage in Midrash Hagadol was correct, and the cherubim are winged humans. Recall that the ark cherubim in the temple are described as having a wingspan that equals their height (1 Kings 6:23–26). Not only four-legged animals, but also upright creatures, whether real ones such as birds or fantastic ones such as winged snakes, would have to have comically short wings in order for their wingspan to be only as great as their height.\nIndeed, we don’t find any depictions of these creatures in the iconographic record that have these proportions. Only humans, who stand erect on long legs and are by far the tallest of any of the candidates in proportion to their other dimensions, can have wings whose span equals their height that still look respectably long. Indeed, humans normally possess an arm-span that precisely equals their height. The Roman architect Vitruvius observed this fact long ago, writing in the context of proportionality in temples (De architectura 3.1.3):\nIf we measure the distance from the feet [of a man] to the top of the head, and we copy the measure to the outstretched arms, we find that the width equals the height, as with surfaces that are perfect squares.\nThis principle was famously illustrated in Leonardo da Vinci’s Vitruvian Man drawing [Figure 7]. When depicting a winged human, it would make sense to portray the wings as having the length of arms.To be sure, winged humans in ancient Levantine iconography often have wings that are extravagantly long, far longer than their arms. But, as noted below, instances are known where the artist portrays the wings as being equivalent to arms and possessing the same length that the arms do (when they exist) or would (when they do not exist).\nIllustrating Wings as Arms\nThree examples will suffice:\nFirst, a stamp seal from Beth Shemesh, which, according to Keel, should probably be dated to ca. 1100–900 B.C.E., depicts an armless, winged human whose wings are spread straight out to his sides [Figure 8], like the ark cherubim in the temple (1 Kings 6:24–27 ≈ 2 Chronicles 3:11–13).\nSecond, a cylinder seal from Tell el-Ajjul, in the vicinity of Gaza, dated by Teissier to the period of ca. 1820–1740, portrays a pair of armless, winged humans spreading their wings out in front of them, like the ark cherubim in the tabernacle, and sheltering a tree [Figure 9].\nThird, a fragmentary Phoenician openwork ivory found in Nimrud, probably from the ninth or eighth century B.C.E., shows a winged human with wings extended in the same position; the upper wing is preserved and is the same length as the adjacent arm [Figure 10].\nConclusion – Winged Humans on the Ark\nThus, the author of the passage in Kings describing the temple ark cherubim could only have had winged humans in mind. If so, we should regard it as probable that other biblical authors writing about cherubim did, too.\nTheTorah.com is a 501(c)(3) nonprofit organization.\nWe rely on the support of readers like you. Please support us.\nFebruary 7, 2016\nApril 12, 2021\nPrevious in the Series\nNext in the Series\nDr. Raanan Eichler is a Senior Lecturer of Bible at Bar-Ilan University in Israel. He received his Ph.D. from the Hebrew University of Jerusalem and completed fellowships at Harvard University and Tel Aviv University. He is working on his first book, The Ark and the Cherubim, to be published with Mohr Siebeck. His recent publications include “Jeremiah and the Assyrian Sacred Tree”, Vetus Testamentum 67/3 (2017): 403–413.\nEssays on Related Topics:']	['<urn:uuid:c0953aeb-78ec-44d9-909f-3e42ca5de0f3>', '<urn:uuid:6646c2e5-0e03-48ce-a44d-42702a5f1464>']	open-ended	with-premise	concise-and-natural	distant-from-document	multi-aspect	expert	2025-05-01T23:21:14.341336	13	133	3640
329	I'm fascinated by local food traditions and heard about a big bean festival somewhere in Piedmont - could you explain what this event is all about?	The Carnevale di Santhià features Italy's largest fagiolata (bean festival), where around 20,000 portions of beans are distributed. This event begins with a unique wake-up call at 5 AM, when the Corpo Pifferi e Tamburi, one of Italy's oldest and most important bands, starts playing to wake up the townspeople, especially the Piazza commanders who run the bean festival.	"['The Carnival in the Province of Vercelli\nThis Carnival celebration is one of the most renowned in the Vercelli province and throughout Piedmont. The most typical characteristic of the Carnevale di Borgosesia - the Mercû Scûrot - first occurred in 1854 when a group of merrymakers did not want the fun to stop. On that day, elegant men held a sort of ""funeral” for Carnival on Ash Wednesday, and accompanied a casket containing a straw puppet representing Carnival through the streets of the Borgo.\nThe next year, the puppet was named ""Peru Magunella”: the first name derived from a dialectal pronunciation of the patron saint’s name (Saint Peter) and the second name came from ""Magoni”, the nickname used to identify people from Borgosesia. Only 30 years later, a person began to interpret the puppet and they also found the puppet a wife, called""Gin Fiammàa”. The Mercû Scûrot, considered to be a unique event in Europe, is held on Ash Wednesday, the day on which the Borgosesia Carnival finishes traditionally, unlike the other celebrations in surrounding towns, which end on Shrove Tuesday. According to tradition, in 1854 at the end of the Carnival celebrations, a group of German and Alsatian businessmen employed at a wool factory founded a few years prior - the first nucleus of what would evolve into Manifattura Lane Borgosesia - were unhappy that the celebrations were over, and decided to have a funeral for the festivity on the morning of Ash Wednesday. Dressed elegantly, they paraded a fake casket through the town in an improvised funeral procession and stopped for a drink in the osterie.\nThis tradition still continues today. Participants dress up in top hats and capes and carry wooden ladles that they use to drink wine that is distributed in specific locations along the procession route. They start their walk after lunch, and end the procession with a reading of the last will and testament of Peru Magunella. Then, they burn the puppet for good luck.\nCarnevale di Crescentino\nThe masks of the historical celebration Carnevale Storico Crescentinese, which has taken place since 1929, are ""Regina Papetta” and ""Conte Tizzoni”, who are crowned according to a particular rite on the day before the parade of allegorical floats. This Carnival tradition is linked to an actual event that happened in 1529, when a group of young Crescentino citizens, allied with the city of Vische, rebelled against and killed their despot ruler, Count Riccardo IV Tizzoni.\nThe legend starts with historical facts: in the year 1529, Count Riccardo IV Tizzoni added to the oppression that he already subjected the people to by imposing the ""ius primae noctis” law, or rather his right to sleep with brides on their wedding nights. During the night between 14 and 15 February 1529, as the town appeared to be quietly awaiting the last days of Carnival, the daughter of the miller from the Mulino Stella cut off the tyrant’s head as the people began a revolt signalled by the bell in the Torre Civica. According to tradition, the name ""Papetta” derives from the maize (corn) used to make cornmeal for polenta, since the girl was the miller’s daughter. The festival ends with a masked parade featuring allegorical floats, musical bands, folkloric groups, majorettes and flag throwers.\nCarnevale di Santhià\nThe Carnevale di Santhià is the oldest Carnival celebration in Piedmont. It was created by Abbadia, a lay association that used to organise dances and Carnival celebrations. The Abbadia is mentioned for the first time in a document dated 1338, but in the 15th century it was replaced by the Antica Società Fagiolesca, the predecessor of the current Comitato Carnevale.\nEvery year on 6 January, they open the celebrations: the main characters and rites connected with the event have maintained their significance over time. These are the characteristics of the Carnevale di Santhià, and they transform the festival into an essential event for that time of year.\nThe masks are Majutin dal Pampardù and Stevulin ‘dla Plisera, and they rule the city during the three-day celebration. According to legend, Stevulin and Majutin were two peasants, a farmer and his wife, who came to the city for their honeymoon. The local governor, with the townspeople’s consent, gave the keys to the city to the newly-weds and allowed them to administer justice and govern the city for three days. This fact is the origin of the modern ""key ceremony”, after which Stevulin reads a speech to the population in the local dialect, which contains humoristic commentary about current events.\nDuring the presentation ceremony of Stevu and Majot, the new couple receives the typical objects that make up their costumes: the ""caplin”, the ""cavagna”, the ""umbrela” for him and the ""spunciun, scusal and mantlin-a” for her, while the two actors from the previous year are inducted into the group of ""Stevu e Majot Früst”.\nSome of the most memorable moments and rites of this Carnival tradition include: the ancient rite of the Salamanda, in which a group of people dressed up like pigs form a procession in the city streets and distribute porchetta sandwiches; Italy’s largest fagiolata (bean festival) which involves distributing around 20,000 portions; the wake-up call at 5 am before the fagiolata, during which the Corpo Pifferi e Tamburi (one of the oldest and most important bands in Italy) starts playing at 5 o’clock to wake the townspeople up, especially the Piazza commanders who run the bean festival.\nThe final ceremony is the Rogo del Babciu, during which the papier-mâché puppet representing the essence of Carnival is burned and the statue of Ganduja is taken down from its throne.\nCarnevale di Varallo\nThe Carnevale di Varallo, one of the city’s oldest traditions, is called the ""day of the old Pasquetta” locally. It ends on the first day of Lent with the Processo al Marcantonio (Trial of Marcantonio, the main mask of the celebration).\nThe origins of this celebration date back to 1595, when a group of friars from the Sacro Monte di Varallo were discovered as they celebrated Carnival. Today, the masked group impersonating the spirit of Carnival consists of twelve people with two main characters, King Marcantonio and his wife, Cecca.\nIn the past ""Pasquetta” symbolised Epiphany, and was celebrated with a large bonfire to welcome the new year. It was a festival to bury the past and invoke prosperity for the New Year and the start of Carnival. Over time, the popular tradition turned ""Pasquetta” into the mother of Marcantonio and Carnival in general. This character is a perpetually fertile woman who, each year, is entrusted with birthing a new Carnival and a new child called Marcantonio, the King of the Dughi and Falchetti. The parade held each year on Epiphany features masks representing the ""vecchio Bacucco”, Pasquetta’s husband, and the ""Balia” (the wet nurse). Vecchio Bacucco is only Marcantonio’s nominal father, and this is the subject of the trial and bonfire for Pasquetta on the Mastallone.\nAnother unmissable event featured in the Varallo Carnival celebration is the ""Gran Bal dla Cecca” dance held at the Teatro Civico. ""Cecca” is the wife of Marcantonio, and the Queen of Carnival. Since 1950, tradition commands that Cecca is elected the night before the patron saint celebration, during the Gran Veglione di San Gaudenzio, and now she is chosen from one of the girls from Varallo, but her identity is kept secret until the night of the ""Ballo della Cecca” dance. On Sunday, Marcantonio receives the keys to the city, and then later a parade with the Carnival masks lightens the atmosphere in the streets of Varallo.\nVisitors should not miss the events on Shrove Monday, the ""Giurnàa ‘dla leugna” and the ""Bal ‘dla Lüm”. For this tradition, on this day, Varallesi from the Crevola frazione cross the bridge over the Sesia River to get wood from the inhabitants to cook the paniccia on the following day. The origin of this tradition is unclear, but the official reason is that in the past there was a sentence that had given the Varallesi a sort of feudal right over the community of Crevola. Now, this practice has become a custom. The day ends with a traditional dance called ""Lum”, after the old stable lights that provided light during vigils of Valsesian mountain people. Now, it is a symbol of the Carnevale di Varallo. The dance dates back to 1876 when the Osteria del Lupo in Varallo Vecchio organised a dance for Carnival with rustic decorations, including iron ""Lum” lamps to embellish the dining hall. Prizes are given during the evening for the best costume and the best masked group.\nTuesday celebrates traditional Paniccia, a nutritious soup with rice and vegetables prepared in enormous pots, which at one time was the only guarantee of a hot meal for the poor and needy. Tradition commands that the fires be lit at 6 AM in Piazza San Carlo.\nThese Carnival celebrations conclude with the Processo al Marcantonio (Trial of Marcantonio), and the bonfire on the evening of Ash Wednesday, with a performance that makes fun of the most important news of the city.\nCarnevale di Vercelli\nThe Carnevale di Vercelli has become an important celebration, well-known even outside the region. It starts with the presentation of the main masks of Vercelli, ""Bicciolano” and his consort ""Bela Majin”, and amid evening celebrations, bean festivals in the city rioni, and children’s dances, the most important moment of Carnival finally arrives: the parade with floats and groups of people in costume.\nThe story of the Bicciolano mask dates back to the end of the 1700s, when the French Revolution was coming to Piedmont. Vercelli was governed by a rich untouchable ruling class that imposed taxes and duties for personal reasons. In defence of the people, Carlin Belletti (nicknamed ""il Bicciolano”) a legendary figure at the time, started a protest. Imprisoned by the powerful rulers in the castle of Ivrea, Belletti was freed and then returned to Vercelli in triumph. His name went down in history linked with the ideals of justice and equality.\nThe most important events of Carnival - after the proclamation of the ""Bela Majin” - are the arrival of Bicciolano and his consort, with the symbolic Key Ceremony and the parade of allegorical floats. These unique moments contain the true spirit of Carnival and, for this reason, feature the participation of several Carnival committees from all over the province. This popular event records an increase in the number of visitors every year, because people want to enjoy this happy, carefree time of year in which everything is possible.\nBicciolano has been included in the list of official masks of the Associazione Centro Coordinamento Maschere Italiane.']"	['<urn:uuid:55b2af4a-eecc-4b4c-8f80-e989a9f7de72>']	open-ended	with-premise	verbose-and-natural	distant-from-document	single-doc	novice	2025-05-01T23:21:14.341336	26	59	1777
333	maximum precision machined springs versus wire	Both wire wound and machined springs readily offer a precision of 10%. Machined springs can achieve 1.0% precision, while wound springs can only reach this level when using statistical methods for selection. A finer precision of 0.1% is generally not available from wire wound springs and is only achievable with machined springs using post-processing techniques.	['By Gary L Boehm\nGary L Boehm, PE Helical Products Company, Inc.\nWire springs appeared early in the Industrial Revolution and established their value immediately. The basic concept has not changed much, though there have been enhancements in materials and manufacturing. Typically, spring wire is coiled hot or cold with ends configured within the limits of coil wire, creating an industrial tool that exhibits elasticity.\nMachined springs function similarly to wire wound springs, but they are manufactured in a different way. Although any machinable material including plastics can be used, bar stock metal is the most common starting point for machined springs. The bar stock is first machined into a thick wall tube form. Then a helical slot is cut revealing multiple coils that when deflected, provide the desired elasticity.\nThe cost to manufacture machined springs exceeds that of winding wire springs. Wire wound springs can be created with just a few seconds of process time while a machined spring requires a minimum of several minutes. Plus, the machines used to create both forms are highly specialized.\nSpring into Shape\nThe coils found on wire wound springs are typically round. Sometimes they come in rectangular or rectangular with rounded OD and ID surfaces. These two latter forms are less common due to cost, however, they offer higher stiffness and are more compact than the typical form. The rectangular coils are normally used so that the long leg is radial, but the long leg can also be made longitudinal.\nRectangular wire comes in set sizes. You can venture from those sizes, but at an increased cost and lead time.\nCoils used on machined springs are square, rectangular (radial or longitudinal), and trapezoidal. Trapezoidal coils are common to springs used in lateral bending and lateral translation. The shape allows for the additional lateral motion without coil contact. The size of the coil is easily changed to fit the spring’s needs. No standard sizes apply.\nSlots. On wire wound springs the space between the coils (slots) is uniform for torsional springs and compression springs, but with compression springs the end slots tend to taper to zero. This process is called “closing” the ends, and is created by an additional forming process. Optional grinding makes the ends nearly flat.\nExtension springs can have a uniform width from zero to most any size. If desired, the coils can be pre-stressed so that this spring shows a zero slot, however, you may need to exert additional force to overcome the coil separation threshold.\nCurrently, machined springs come with a minimum slot of about 0.020 in. (0.51 mm). Wider slots that do not exceed 0.250 in. (6.35 mm) are possible. The slot width can be closed to near zero using a stress relieving process, but no pre-stressing is currently available.\nNumber of coils. Wire wound springs can be made very long, such as garter springs for example. The quantity of continuous wire available on the feed spool limits this spring’s length. Machined springs are limited to about 30 coils depending upon size, however, rarely are coil numbers above 20.\nIn a wire spring, the entire length of the wire contributes to the elasticity because the forces and moments are distributed end to end with the ends providing the interface with adjoining equipment.\nMachined springs are different. The flexure—the section providing the desired elasticity—is captive between the end sections, which provides structure and attachment. The end sections have infinite stiffness when compared to the flexure. Furthermore, the slots do not taper to zero at the ends; they remain at the full or initial width, as seen at free length. Thus, to achieve the same elastic performance, machined springs likely need to be longer than wire ones.\nPrecision. In general, machined springs can be made to precise dimensions more easily than wire springs. Both wire wound and machined springs readily offer a precision of 10%. Machined springs can offer 1.0% precision. Wound springs can too, when statistical methods are used for selection. A finer precision of 0.1% is probably not available from wire wound springs and only available from machined springs using post-processing techniques.\nCost. Production time is the major influence on cost. Wire wound springs have short production times. Machined springs cannot approach the low cost of wire product. It would be surprising to find a simple and inexpensive machined spring, produced in high quantities costing less than $2 dollars each. However, machined springs offer features that validate their use. These features include; integrated attachment points, higher precision, reduced assembly and acquisition effort, and quiet and clean contacts.\nUsually, at least one of these benefits is necessary to justify the selection of machined springs.\nWire wound springs are typically made from medium and high strength steels, nickel alloys, titanium and stainless steels that have undergone heat-treating and cold reduction. Machined springs use somewhat similar materials. Spring wire and malleable bar are common to wound springs, but cannot be used for machined springs. A completed wound spring will retain various amounts of residual stress. While stress relieving processes can reduce residuals in wound product, the sum is not zero.\nA machined spring with residual stress in the free state will be subject to freestate deformation, which is always undesirable. Materials subjected to solution annealing resist residual stress, as do materials that undergo heat treatment with no cold reduction or quenching. Quenching will, by itself, induce residual stress. Therefore, good choices are martensitic corrosion resistant steels (CRES) and martensitic steels.\nTypical Machined Spring materials include moderate to high strength CRES, such as 17-4 PH per AMS5643, 15-5PH per AMS5659, CC455 per AMS5617, and very high strength steels like C300 per AMS6514.\nOther good materials include 7075-T6 aluminum (high strength), 7068-T6511 aluminum (very high strength), 38644 Beta C Titanium (very high strength and corrosion resistant), Delrin 100 (machinable plastic), and Ultem 2300 (machinable plastic). Any machinable material that can be made free of residual stresses is a valid candidate for use for a machined spring.\nImproving spring materials\nWire springs are often shot peened to enhance fatigue resistance. The gaps between the coils are usually wide enough to let the shot pass through and condition the inside of the opposite coil, as well as the outside of the coils.\nMachined springs’ coil slots are often too small to pass shot. Hence, shot peening is not common. Fatigue resistance often comes from stress relief holes and slots added to the slot ends. You can also select high strength, fatigue-resistant materials.\nWire springs can be plated with zinc and nickel for corrosion protection. Plating machined springs is uncommon because of the sharp edge corners, which typically receive insufficient coverage. The use of CRES and titanium materials provides excellent corrosion protection for most machined spring applications. Aluminum machined springs are typically anodized or coated to prevent corrosion.\nMachine spring sizes are limited by machining practicality. The smallest springs are about 0.100 in. (2.54 mm) in diameter, and the largest are 6.0 in. (152 mm). Maximum length is about 24 in. (610 mm), but this applies to 1.0 in. (25.4 mm) to 3.0 in. (76 mm) diameter springs. Smaller or larger diameter springs will need to be shorter.\nMake the attachment\nWire wound spring attachments include compression springs, clipped end or natural, closed, and closed and ground. Closed and ground attachments are a little more expensive, but they provide the most perpendicular surface to the spring centerline.\nWhile wire springs are limited to the use of wire form attachments, creativity has provided many, cost effective versions. Machined springs can possess any feature that can be machined.\nCompression springs are fully machined. The ends can be flat and very perpendicular to the longitudinal axis of the spring. Extension springs can have machined studs, threaded holes, and flanges.\nTorsion springs can have a rugged tang similar to that found in wire spring. Tang usage provides a moment on a torsion spring. To accomplish this, a force at a distance is employed. The spring provides the moment action, but needs additional reaction to the force. Typically, torsion springs using a tang rub on a guide on either the OD or ID to resolve this force.\nIn a machined torsion spring, a pure couple can provide the moment. A pure couple can come from double tangs (external, internal and longitudinal), slots, splines (internal and external) and bolt circle configurations. One can also resolve the moment by an integral torque restraint on the coil side.\nWhile wire wound springs are limited to single start configurations, machined springs handle single and multiple starts. In the world of springs, the double start machined spring goes from basic function to concepts that are intrinsic to the function of mechanical devices.\nMultiple start springs allow for a pure force reaction. A moment is created by compression or extension forces occurring at the spring coil’s width center, which is distant from the spring centerline. In multiple start springs these moments resolve to zero within the body of the spring. Hence, compression and extension springs with multiple starts provide elastic motion without the need of corrective moments. In single start springs, wound or machined, these moments must be resolved at the interface between the spring and the components providing the force and deflection.\nMultiple start spring configurations unify the lateral bending and lateral translation forces and moments around a spring’s circumference given a lateral deflection. Configurations as high as five have been used to unify the lateral reaction of machined springs. Multiple Starts also add to the length of machined springs. Should a failure occur, the remaining coil(s) provide some functionality albeit degraded due to the missing coil.\nStresses in both machined and wire wound springs used in compression and extension are dominantly torsional shear. The maximum stresses are located on the spring ID and on the coil sides. It is very rare to find maximum stresses on the spring OD. Stresses at the sharp corners are functionally, very low.\nMachined springs used in compression may benefit from stress relief holes (SRH) or elongated holes at the slot ends, but that is your call. Machined extension springs nearly always require a SRH, or equivalent, at the slot ends to mitigate the effects of harmful, tensile stresses. Without SRH, the spring’s performance must be reduced to avoid failure caused by the tensile stress riser at the coil ends.\nLinearity of compression and extension springs is influenced by five factors: Geometric changes in the spring during elastic deformation from free length, residual stresses in the material, increasing coil contact during deflection (compression springs only), boundary condition fixation, and spring rotation during deflection.\nWhen helical springs are compressed and extended, end-to-end twisting occurs. Three remedies exist with machined springs to eliminate the torsional deformation. Fix the end of the spring using any of the attachment techniques available. Or, constrain the spring end to increase the elastic rate. Or, use two concentric springs one with a right hand flexure and the other a left hand. When properly designed, the twisting of the inner spring counteracts that of the outer one. An option is to place two flexures on a single spring blank, one right hand and the other left hand. This configuration allows the interface between the two flexures to twist, but the ends do not.\nMachined springs have a constant slot dimension, thus, there exists a slot width at both ends that does not close. When that dimension is added to the solid structural end, you’ll find that a machined spring used in compression is longer than an equivalent wire spring. This means that a machined spring cannot be configured to provide the same performance of a wire spring used in compression. Hence, in compression springs, equivalent machined springs are always longer than wire ones.\nCompression and extension machined springs with multiple starts are successful in systems that operate at resonance. The features that contribute to this success include low tolerance elasticity, continuous slot dimension (no touching at coil ends at any time guarantees clean and quiet operation), internally resolved moments and uniform cross axis stiffness.\nWhen considering any compression springs, review the issue of static instability (buckling). This issue becomes more prevalent as the number of coils increases. Because of their inherent stability, extension springs are not subject to bucking.\nMachined springs used in torsion\nTypically, torsional machined springs are a little longer than equivalent wire ones. These springs benefit from attachments, however, they differ from wire torsion springs in that the coil ID can be reduced to add stiffness to the torsional rate. Adding stiffness to wire torsional springs requires a change in the basic configuration, such as OD, ID, wire size, or number of coils, or a change in the wire shape. Wire is available in rectangular and trapezoidal sections. Trapezoidal sections are generally selected for smaller ID springs so that post wound sections will approach being rectangular.\nIf you want to double the stiffness of a torsional machined spring, double the coil thickness or employ a double start configuration using the original coil thickness for both starts. A double start spring would provide more stiffness, but it would also be more expensive, longer and possibly experience static instability (buckling).\nBuckling is important in torsion springs and becomes an issue when the number of coils increases and the coil width decreases. Both wind-up and unwind directions should be analyzed for buckling.\nThe maximum tensile beam stresses are located on the OD when the spring is subject to windup deflections; conversely, the stresses on the ID are at maximum compression. When the spring is subject to unwind, the stresses are the opposite. It is critical that there be no nicks or cuts at the area where the stresses are at maximum. These flaws would increase the stresses, and possibly initiate cracks. For the same reason, machined torsional springs should contain stress relief holes or slots to help mitigate “stress risers” as the coil section changes into the solid structural section of the spring end.\nIf a machined spring were subject to equal deflections in wind-up and unwind, stress would be considerably higher in the unwind condition. Geometry causes this situation and is unavoidable.\nIf a spring is anchored at one end and the other is subject to a moment, the load case is labeled as lateral bending. While it is possible to subject a wire spring to lateral bending, machined springs are more commonly used because of their numerous attachment options. Buckling is rarely a concern for lateral bending springs.\nLateral Translation occurs when one end of a spring is anchored and the other end is laterally displaced by a force plus a moment to insure the end faces of the spring remain parallel. Such deflections are better suited to machined springs because of attachment options. Similarly, buckling is rarely a concern for lateral translation springs.\nAt one time wrap spring clutches were major components in motion control systems, but with the growth of electronic motor controls, the demand for wrap spring clutches has declined. However, markets such as avionic flight controls prefer these devices because of their nonelectrical needs and rugged nature.\nWrap spring clutches function basically in two ways. They engage and disengage torque transfer in a torque line by the selection of rotation direction and engagement or disengagement of a tang. The avionic industry has a component called a No Back that limits the amount of torque transferred in a torque line and is used to protect flight controls from damaging, over-torque situations.\nWorking the math\nMuch analytical work has been accomplished by such experts as A. M. Whal, S. P. Timoshenko, and J. N. Goodier. The SAE provides design guides in the Spring Design Manual AE21, the Spring Manufactures Institute, and others. For the most part, all this work provides closed form equations for wire products. Since the geometries can be similar between wire and machined springs, it is not uncommon to try to use the equations sets for both.\nWith machined springs, though, closed form equations may not fully apply. The equations do not account for all boundary conditions and actual geometries for wire springs. Displacement affects geometries, and must be included in the computations as well.\nClosed form solutions for machined springs may be inaccurate. As a general rule, equation accuracy wanes when the number of coils is less than three or the ratio of coil sides exceeds two, height to width. For these reasons, quality FEA is nearly always needed for elastic and stress computations related to machined springs.']	['<urn:uuid:29be0e86-f55b-413d-86af-9cefbf9a52b4>']	open-ended	direct	short-search-query	similar-to-document	single-doc	expert	2025-05-01T23:21:14.341336	6	55	2749
334	What kind of editing do alpha and rush readers focus on?	Alpha readers focus on big-picture issues in early drafts and don't do line-level editing, while rush copyediting focuses only on fixing major mechanical errors and clarity issues without addressing stylistic elements like sentence structure or wordiness.	"['Every great writer relies on great readers. Who should you enlist to read your work as it’s in development? In this article, I’ll cover the following (click to navigate to that section).\n- Begin with a receptive mindset\n- Know that readers vary according to how much and whether they want you to succeed. That’s filter #1\n- Diverse readers will be critical\n- You may need specialists\n- You might want alpha readers\n- You’ll definitely want beta readers, volunteer or paid\n- I offer some places you can find betas\n- You should help betas help you\n- And you may want to hire professional readers; there are four kinds\nFirst of all, if you’re going to write a good book, your first step is to write a book that is not as good as it ultimately will be. You’ll spend a lot of time with this book, and as a result, you will not be able to look at it objectively. So you’ll need to rely on other people to tell you how it’s affecting them.\nThis whole arrangement means that even if you occasionally have people telling you that what you’ve written is wonderful, you’ll also get people telling you where it failed. Because that’s what you’re asking for when you request knowledge on how your art can be better.\nSomething to keep in mind.\nThe Disapproval Matrix\nGiven that you’re going to receive criticism, it’s worth having some perspective on where that criticism might be coming from. I’m in love with Ann Friedman’s Disapproval Matrix, which is “one way to separate haterade from productive feedback.”\nNow, you won’t be seeking out Haters for feedback, but if you’re like me, you may occasionally end up in a writing group or a workshop with people that fall into this category, so they may indeed get their grubby hands on your work. Ignore them.\nThen there are Frenemies, who know you personally, but whose criticism is really about you, not your work. Friedman adds to this quadrant “The Hater Within, aka the irrational voice inside you that says you suck.” Again, ignore these people.\nLovers and Critics are the ones to listen to. Sometimes, Lovers might be too soft on you. And because you don’t know Critics as well, you may not know whether they’re in some other category, but let their feedback speak for itself. If it’s rational and convincing, listen to it.\n(That said, sometimes you have to sit with feedback for a day or three before you realize how valuable it is.)\nJeff VanderMeer in his Wonderbook has some advice about readers, one piece of which echoes Friedman’s perspective above: “You want readers who are good at providing cogent, analytical comments on your work and who don’t get hung up on petty details or are unable to sympathize with what you are trying to do.”\nVanderMeer also has some very good points about the necessity of diverse readers.\n- First of all, you want “true gender and multicultural diversity” because such readers “may expose you to different ideas about fiction and about life that impact elements of your manuscript.”\n- Diversity also entails readers who don’t read “the kind of fiction you write.”\n- And readers who are not writers. (Which will constitute a significant portion of your ultimate readership most likely.)\n- Also: readers of varying levels of experience. It’s absolutely essential to seek out readers with more writing experience at some point.\nThere is such a thing as a “sensitivity reader,” whom you might enlist if you’ve written a book that includes experiences outside of your culture/ethnicity/race/gender/ability, etc. Such people look for misrepresentations and stereotypes. (Here’s an article about them.)\nDepending on the kind of story you’re writing, you may want experts in various fields to read through your work. As VanderMeer points out, “Karin Lowachee had her novel Warchild critiqued by a group that included an ex-military man because that book dealt with war and post-traumatic stress disorder.”\nIf you have scenes involving violence, talk to EMTs or doctors. If your story is set during the Civil War, maybe contact a Civil War re-enactor. If your protagonist is a computer programmer and you’re not, seek out a programmer. And for everything else, get a librarian to read your work. They know ALL.\nAlpha readers, as the name suggests, are first readers, but they’re also early-stage readers. That is, they might look at your story before it’s been polished enough for others. As such, they’re usually people you’re well acquainted with, who can look past small issues and give a pretty holistic assessment.\nYou want alphas to look at big-picture stuff. Plenty of time for the line-level thing later on.\nSome writers skip alphas altogether. But those who use alphas don’t use many. One or two.\nBeta readers read your next draft. But there’s some variation in how people think about beta readers and at what point they enter the scene.\nSome see betas as unpaid volunteers, usually other writers with some level of ability in writing. Some see beta readers more as a focus group—the potential audience for your book, many of whom are not writers. And then developmental editors can also fall under the category of beta readers.\nIt’s worth noting, however, that the purpose of beta readers is to help you write a book that your ideal readers would consume. As Kristin Kieffer points out, “There’s no use in sending your manuscript to an uninterested reader”; you want to “cultivate a list of betas who most accurately represent your future readers.”\n(You might make an exception for developmental editors, who should be able to give you valuable feedback despite perhaps not being your ideal reader. But there’s also something to be said for seeking out experts in your particular genre.)\nBeta readers are often not people you know as well. They can be friends or acquaintances, but part of the point is to get some fresh eyes on your manuscript.\nHow Can You Find Beta Readers?\nThese days, mostly online. You can certainly search locally for such people—perhaps a writing group at a local library or someone you meet through a class offered in your area—but I’ve found that it’s the rare local group that will read full manuscripts of novels.\nYou can ask around on social media. Folks on Twitter’s #WritingCommunity will hook you up. And there are lots of Facebook groups where you can find beta readers (10 Minute Novelists, Beta Readers and Critiques, and Indie Author Group to name a few).\nGoodreads has a forum for those seeking beta reads.\nAnd there are also some websites dedicated to connecting people with beta readers:\n- Critique Circle\n- My Writers Circle\n- Writers Carnival\n- WANA Tribe\n- Find Beta Readers\n- Swoon Reads\n- Crit Collective\nNow, if your ideal reader is a child, then online may not be where you want to go soliciting favors from minors. So if you’re writing children’s lit, in addition to getting some adult writers with experience in children’s lit, I’d push you back toward using local connections and your network of friends and asking parents or teachers to help you organize a way to get your work in front of child readers.\nHelp Your Betas\nThe first rule of beta reading, if you’re going to go seeking out volunteer betas, is to offer beta reading yourself. Give to the community if you’re going to take from it.\nRegardless of where you find your betas or how you think of them (experts, writer buddies, a focus group), help them focus their feedback. What questions you use will depend a little on your goal, but here are some:\n- Where did it bore you and where did it captivate you?\n- Were there any things that ripped you from the story? (Plot holes, irrelevancies, inconsistencies)\n- Overall, did you like it? Why or why not? (You might even ask for a starred rating on a 1-to-5 scale).\n- Did you identify with the characters and/or did you find them engaging?\n- How did it make you feel?\n- What was it about?\n- Would you recommend it to a friend? Why or why not?\nYou might consider giving them the questions ahead of time and having them focus on the first two questions as they read. And it also might help to have a dialogue. It’s often more respectful of people’s time—especially for writers—to have them talk through their ideas rather than ask them to articulate them all in writing.\nProfessional editors usually give you detailed and actionable advice on how to improve your book. Some professional editors have been doing this for a very long time and do it constantly and therefore do it very well.\nIt’s hard for most volunteer beta readers to compete with critiques and insights offered by a professional.\nI want to be clear, though: you can get all the feedback you need for free.\n(But you know, you can start a diet and exercise routine without relying on anyone else either.)\nSo, what kinds of professional readers might you hire?\n- Developmental editors look mostly at the extent to which the story is working. You might think of them as professional beta readers. They examine the story’s structure, point out plot holes or inconsistent behavior in your characters, and look at where you might be boring the reader with big info dumps or excessive backstory. They’re basically investigating how well you’re piecing together the puzzle of your story.\n- Line editors look at your sentence- and paragraph-level craft. They’ll edit for clarity, eliminate needless repetition, examine the rhythm of your prose, read for consistency in voice and tone, interrogate your word choice, and make sure you’re not abusing dialogue tags or resorting to cliched behavior or gestures for your characters.\n- Copy editors go in a little closer than line editors. They look at grammar and usage—style manual stuff. They’ll make sure your capitalization and punctuation is correct.\n- Proofreaders do a final pass to eliminate errors and typos. Proofreading as a term has come to mean scanning for errors, but in publication, proofreading refers to looking over the galley proof of a book prior to its being printed for wider consumption.\nKeep in mind that there’s some overlap between each of the above. A proofreader looks for a lot of the same things a copy editor would look for; it’s just that the proofreader’s timing is later in the process.\nEach level of editing bleeds into the next. When I do developmental edits, I often do a little line and copy editing, too.\nSome professionals can do what they might call a comprehensive edit, in which they’re intentionally looking at developmental, line, and copy editing. It’s often not worth doing much copy editing until the big developmental ones are figured out, but a comprehensive edit can be great for learning purposes: it will help you discover trends in your micro-level craft that may be affecting your storytelling writ large.\nThe bottom line: it takes a small village to write a book. Seek out readers, cultivate your relationships with the good ones, and appreciate them.\n- Dealing with Rejections and Criticism\n- Approaching the Workshop\n- Should You Hire a Professional Editor?\n- 4 Levels of Editing Explained\n- How to Find and Work with Beta Readers\n- The Complete Guide to Beta Readers\n- Five Questions to Ask a Beta Reader When They Critique Your Manuscript\n- Finding Your Best Beta\n- Beta Readers: Who, When, Why, and So What?\nThis article is part of the Author Toolbox Blog Hop. To continue hopping through other great blogs in the monthly hop or to join, click here and/or search #AuthorToolboxBlogHop on Twitter and Pinterest (here’s the group board).', ""What does copyediting actually look like?\nUpdated: Jul 19, 2021\n**Update July 2021: As an experiment, I've changed the names of my services! You can still get copyediting; it's just called Detail Debug.\nYou’ll find a lot of editing terms around the internet, but a little more digging will show that often, people don’t define these terms the same way. That’s why when you’re looking for an editor, you should read that particular editor’s definition of the services they offer. Otherwise, you might end up with an edit you didn’t expect!\nFor maximum clarity, I’ve written this blog post to show you exactly what you’re getting when you ask for a copyedit from me. Complete with examples!\nHere are some notes about Stephanie’s sample piece:\nGenre: high fantasy\nWord count: 1515\nNo special requests or notes\nBIG NOTE: What you’re about to see is just the way I copyedit. Other editors may handle this same sample totally differently from me. This is why it’s so important to get a sample edit from an editor before hiring them.\nFirst, let me show you my standard. This is the way I copyedit by default. If you don’t give me any special requests or instructions, this is what I’ll do.\nThe key to my standard copyedit is that I only fix outright mistakes on the page itself. For everything else, including style options, I ask a question instead. This includes awkward sentence structures. If I think the reader could understand the sentence as-is, I leave it alone, even if it’s awkward. Instead, I make a comment suggesting a smoother alternative.\nTake a look at the sample below before moving on to my breakdown. This sample includes my edits on her document itself and a basic style sheet. (My style sheets for fantasy novels are usually a lot more complex than this. Here's a dedicated post on the subject!)\n(This is just the first page of the sample edit. Click the image to download the entire PDF!)\nNow that you’ve seen the sample, let’s take a closer look at what I did:\nYoung Stephanie really liked semicolons. She used six of them in this short sample. I ended up changing four of them to other, better-fitting punctuation.\nI adjusted the capitalization of several words, including capitalizing proper names and making general terms lowercase.\nIt seems like young Stephanie might have changed her mind about the tense while working on this project, and she missed a few verbs when she self-edited. So I changed present-tense verbs to past tense in a couple of places.\nA lot of the dialogue punctuation needed alterations. Many writers seem to struggle with this, so fixing it is pretty routine in my copyediting work.\nI also adjusted some other punctuation—mostly apostrophes and commas. These are by and large the most troublesome punctuation marks in most of the pieces I work on.\nA couple of the proper nouns in this excerpt had different spellings. (See: Tirivia/Tiruvia) These are Stephanie’s original proper nouns, so I can’t go in and change them without consulting her first. I’ve left comments addressing these.\nSome words are alternately capitalized or lowercased with no discernible pattern. (See: Panthers/panthers) Because I don’t know how Stephanie wants to treat the capitalization going forward, I have to leave a comment asking her how to handle it.\nSome words have multiple potential spellings that are all correct when checked in the dictionary. (See: traveling/travelling) I’ve noted these words in the style sheet so that the next time I see the word, I can check that it has the same spelling as before.\nOne sentence had a bit of an awkward construction. I wasn’t worried about readers understanding it, but I did want to suggest a smoother alternative, so I left a comment.\nThe prose also got a bit too wordy in one spot. This, again, is not a clarity issue, so I flagged this with a comment suggesting that Stephanie delete the wordy parts.\nStephanie used straight quotes and apostrophes when writing this sample. For publishing purposes, these need to be made curly. I made this change silently, meaning I didn’t turn on Track Changes while I did it, because it would leave way too many red marks in the manuscript and be distracting. Instead, I left a note in the style sheet.\nI also changed all double spaces after punctuation to single spaces. Double spaces are for typewriters—we don’t use double spaces in on-screen writing. I changed this silently as well.\nNOTE: For a couple of the consistency questions (Tirivia/Tiruvia, capitalize Panthers or not, etc.) that would affect the entire novel, I would not normally leave them as comments on the manuscript. Instead, I would compile a list of these questions during my first pass to send via email before I started my second pass. This way I could address these potential edits myself rather than leaving them for Stephanie to deal with by herself.\nStandard Copyedit Stats\nFor this particular sample, here were my stats:\nTime: 142 minutes\n*Truthfully, this is quite slow. My editing speed always goes up as I get familiar with the characters, story logic, and writer’s habits. I tend to average about seven pages per hour for this type of edit.\nNow that you’ve seen my standard, let’s take a look at a rush copyedit. This is the type of copyedit I do for clients who are in a hurry. I may only have a chance to do two passes instead of my standard three. Sometimes I can only do one pass.\nFor a rush copyedit, I’m not focusing on catching as much as possible, I’m focusing on catching the major stuff. I ask myself two main questions during this type of copyedit: Is it wrong? (If yes, I fix it.) and Is it confusing? (If no, I leave it alone.)\nCAUTION: If you ask an editor to do a rush edit, they could miss more errors than they normally would. Editing is a profession that requires slow, methodical reading and multiple passes. If your editor is in a hurry, they can’t read as slowly or complete as many passes as they normally would, which means more errors may stay in the manuscript. Plan far ahead when you’re looking for an editor!\nTake a look at the sample of a rush copyedit below. (I left the style sheet out of this one for space-saving purposes.)\n(Once again, click the image to download the whole version!)\nNow that you’ve had a look, let’s talk a little about the differences.\nThese are all still the same! Mechanical edits are pretty straightforward—either it’s a mistake or it’s not. Either it matches the standard style or it doesn’t. I still correct all of these, even in a rush edit. (But as I mentioned above, editing fast means that more mistakes get left behind, so I might have missed some of these in a truly fast edit.)\nNotice that I still asked the questions about consistency issues. Again, I would normally address these in an email, probably about halfway through my first pass during a rush edit. If the author doesn’t give me an answer in time, then I will have to pick whichever spelling/capitalization pattern is used more and go with that one.\n(You’ll also notice that my comments are much, much shorter and more businesslike. In a rush job, I don’t have time to beat around the bush!)\nYou’ll see here that I ignored the awkward sentence structure and wordiness, both of which I had addressed in my standard copyedit. In a rush job, I do not address these—there’s generally no time to do so. (However, in this writing sample, both of these instances were still clear, even if they weren’t exactly smooth. If there’s a clarity issue, I will address it even in a rush job.)\nRush Copyedit Stats\n*Note: These stats are estimates based on previous rush jobs. Rather than redo the entire edit from scratch, I went through and removed anything from the standard edit that I would not have done in a rush edit.\nTime: 90 minutes\nWith the standard and the rush jobs behind us, let’s take a look at my final style of copyediting: a heavy copyedit. A heavy copyedit encroaches into line editing territory a bit. In addition finding and fixing errors and inconsistencies, in a heavy copyedit I also focus on making the prose smoother and more concise.\nI recommend this type of copyedit for clients who need their word counts significantly cut, who are writing in their second language, or who are brand new to writing. This type of copyedit is more labor intensive and thus more expensive. I only do this type of edit by request.\nLet’s take a look at my heavy copyedit:\n(Click the image to download the entire PDF!)\nNow let’s take a closer look at the differences between this and the other two styles of copyedit.\nOnce again, these are all the same as both the rush and standard copyedits. No matter what kind of edit you receive, you’ll always get these basic mechanical corrections.\nIn a heavy copyedit, you’ll see that I still leave a comment about consistency issues (which I would normally address via email), but I do go ahead and use whatever seems to be the preferred style directly in the text until I get an answer from the author.\nThis part is the biggest deviation from the standard and rush copyedits. Rather than just leaving a comment for the author to resolve, I edit all of the awkward sentences and wordiness directly in the text. Then I leave a comment to draw the author’s attention to the edit, and the author can either agree or disagree with what I’ve done. You’ll also see that I addressed several cases where the writing could have been more concise, which I left alone in the other types of copyedits.\nHeavy Copyedit Stats\nAs you might imagine, a heavy copyedit takes longer than other types of copyedits because I am altering the text more directly and in more detail.\nTime: 185 minutes\nI hope this post has given you a better idea of what to expect from a copyedit. I'll mention again that you should always get a sample edit from your potential editor to make sure they are doing exactly what you hope for. This post is not intended to replace a sample edit, but rather to give you a general mental picture of what to expect when you hire a copyeditor.\nDoes your novel need a copyedit? Whether it’s a standard, rush, or heavy job, I’m here to help you make your words shine on the page. Get a free quote here!""]"	['<urn:uuid:855ade1b-8109-43d8-b911-d1d0b9414f52>', '<urn:uuid:1ec0cbc4-f988-4db1-b9aa-5fe669f55a4e>']	factoid	direct	concise-and-natural	distant-from-document	comparison	expert	2025-05-01T23:21:14.341336	11	36	3762
335	Where can I find hidden chests in Hera's Garden hedge maze?	In Hera's Garden hedge maze, there are several hidden chests: A Phoenix Feather chest at the start (go straight, left, then up), a Gorgon Eye chest in the Satyrs hallway area, and two Minotaur Horn chests - one accessible by flying left over a gap after using Hera's Chalice, and another after defeating the Cyclopes on the moving cube.	['This God of War 3 locations guide shows Gorgon Eyes locations, Phoenix Feathers locations, Minotaur Horns locations, and how to find all hidden treasures locations including the 10 Godly Possessions. We’ll get you started with this God of War III collectables video guide.\nTable of Contents\n- Mount Olympus Items Video\n- Hades Items Video\n- The City of Olympia\n- The Flame and the Box (Act 5)\n- Daedalus’ Workshop Items\n- Olympus Gardens Items\n- The Light in The Dark Items\nINDEX OF GOD OF WAR 3 GUIDES:\n1. Gorgon Eye: For every 3 Gorgon Eyes you collect, you increase your overall health. On-screen shown as the green bar.\n2. Phoenix Feather: For every 3 Phoenix Feathers you collect, you increase your overall magic. On-screen shown as the blue bar.\n3. Minotaur Horn: For every 3 Minotaur Horns you collect, you increase your overall item power for special attacks. On-screen shown as the yellow bar.\nShows where Zeus’s Eagle is located on the first level which is inside of the Heart of Gaia. This is the only treasure chest you should be concerned with on first level. Any other treasure currency orbs are lost when Kratos falls into the underworld.\n* You might be tempted to just grab on to the moveable wall and pull it to the other side, but don’t do that. First climb up to the right side of the wall to the top to grab Zeus’s Eagle.\nMore of the items in Mount Olympus: Part 1:\nGoing through Mount Olympus including Aphrodite’s Chamber for more items: Part 2:\nMore of the items in Olympus Gardens:\n* Phoenix Feather can be found at the start of Hera’s Garden hedge maze. Go straight ahead. Go left. Walk up. There, at a passage that seemingly ends at a steel-barred gate, you’ll see the sparkly dust in the air. Use Helios’ head to reveal a chest that holds a Phoenix Feather.\n* Gorgon Eye can be found at the start of the Hera’s Garden hedge maze. Go to the hallway with the Satyrs (the goat-men with the double-bladed staffs). In the next part past the hallway, go to the right until you see the blue/magic chest. Go right again to find two chests and some sparkly dust in the air. Use Helios’ head to reveal a third chest with a Gorgon Eye.\n* Minotaur Horn. When you use Hera’s Chalice for the first time and walk up the stairs, open the gate on the right. Once you go down to a new part of the maze, double-jump and fly over the gap you find there, but aim your flight to the left of the gap to land on a new area. There you’ll spot the chest that holds a Minotaur Horn.\n* Minotaur Horn. After you finish and exit the hedge maze, you’ll enter the caverns to fight lots of Cyclopes on top of a moving cube. When you’re done finishing all the enemies off, look around for two chests. One holds a Minotaur Horn.\nCovers the hidden treasure locations on the next level inside the underworld. Learn where all the Gorgon Eeye treasures, phoenix feathers, minotaur horns, and bonus play items are located.\nHades items video part 1:\nHades items video part 2:\nHades items video part 3:\nMore of the items in Hades:\n* The first Gorgon’s Eye treasure chest is located under the very first platform Kratos leaps to after he finishes his conversation with Athena.\n* In the area right before the chamber where you face the first Medusa, there are two treasure chests behind you under the cliff you just jumped down from.\n* On your way from the Chamber with the first Medusa Battles, there is a hole in the ground. Do NOT just jump over it and keep moving, there are hidden treasures inside.\n* After you receive Apollo’s Bow and kill all the enemies in the room. Charge up Apollo’s Bow to destroy red vines in the upper left coverner. Get up there to get your first Phoenix Feather.\nMore of the items in The City of Olympia:\nAll of the items in The Flame and the Box (Act 5) Part 2:\nMore of the items in Daedalus’ Workshop:\n* Minotaur Horn is located up high in this workshop. Shoot the harpoon through the portal on the left, then cross through them using the rope you shot through them. After you get to the red orbs chest, jump to the next rope by making a double-jump towards the screen and using your wings to float to it. Proceed to the top-left side of the room to find two chests, one being for a Minotaur Horn.\n* Minotaur Horn is located at the bottom of the pole in this workshop. Go all the way down it, and then run in the hallway towards the screen to find two chests, one being for a Minotaur Horn.\n* Phoenix Feather is in a well-hidden chest. As you enter the workshop, pull the lever on the right, shoot at the gate with the harpoon, which now goes through the portal. Use Hermes’ running shoes to go up the indicated wall on the right side and run into the gold portal. Once through, pull another lever. Now you must hurry down to find two chests have been lowered. Shoot the harpoon at the chain holding them up to put the chests on the floor, so you can reach them for one has a Phoenix Feather.\n* Gorgon Eye can be reached after climbing more rope. Pull the lever on the right of the room. Shoot the harpoon to the left, getting it stuck on a wall on the right as it passes through a portal. Use all of the rope to cross through the gate. When you reach the wall, you’ll find the chest with the Gorgon Eye.\nI don’t think I need to point this out, but it can’t hurt, as this is something you need. As you approach the maze entrance, a cutscene with Hera will play, during it she throws her Chalice away on the ground. Be sure to remember where it fell and after the cutscene go there to pick it up. You’ll need it to solve the maze puzzle.\nHaving finished the game already with 100% of the health, magic and power upgrades on my first go, I can tell you to keep your head of the Sun God Helios handy (press and hold the L2 + Triangle buttons) when you see that lightly sparkling golden dust in the air. Because there are lots of hidden treasure chests near the sides of the main path you travel through the game on.\n10 Godly Possessions locations: Each one gives you an ability (listed below) and collecting them all earns you a Gold Trophy.\nAll Godly Possessions in chronological order:\n* 1) Zeus’ Eagle: Infinity Rage of Sparta.\n* 2) Hades’ Helm: Max out Health, Magic & Item meters.\n* 3) Helios’ Shield: Increase the Hits counter by 3 times.\n* 4) Hermes’ Coin: Collect 10 times the amount of Red Orbs.\n* 5) Hercule’s Shoulder Guard: Decrease damage taken by 1/3.\n* 6) Poseidon’s Conch Shell: Infinite Magic.\n* 7) Aphrodite’s Garter: Continue to use Athena’s Blades.\n* 8 ) Hephaestus’ Ring: Automatically win all context sensitive attacks.\n* 9) Daedalus’ Schematics: Infinite Item.\n* 10) Hera’s Chalice: Cause the Health meter to slowly drain over time, never completely emptying it.\nFor a complete look at the game, watch our God of War 3 walkthrough guide.']	['<urn:uuid:11760eff-3a6b-45a8-a8c8-2d558f742af6>']	open-ended	direct	concise-and-natural	similar-to-document	single-doc	expert	2025-05-01T23:21:14.341336	11	59	1265
336	What countries did the gemstones in Anglo-Saxon jewelry originate from?	X-ray fluorescence analysis revealed that while some garnets came from Bohemia, the larger cabochons originated in Sri Lanka, arriving in England through Roman trade networks.	['One of the most invigorating elements of studying the material culture of the early Middle Ages is that the field continues to expand in a very real way: hundreds of new objects have come to light in recent years. This was particularly true during the boom of the early 2000s, which saw archaeological surveys throughout Europe for building and infrastructure projects, but the work of amateur enthusiasts with metal detectors has been a major source of discovery, too. When it was announced in September 2009 that a detectorist had uncovered a very large hoard of Anglo-Saxon metalwork, the news excited the public nearly as much as it did scholars. The Staffordshire Hoard, as it was dubbed, encompassed over 3,500 separate items, comprising 5.094 kilograms of gold (over three times more than was discovered at the famous Sutton Hoo site), 1.442 kilograms of silver, and thousands of garnets: it was truly a spectacular find. After exhibitions in Birmingham, Stoke-on-Trent, and London, staged in part to inspire public support for the purchase of the hoard by two museums in England, select items travelled to the National Geographic Museum in Washington, DC, for their sole American appearance. Clearly conceived as a popular exhibition, this public presentation of the Staffordshire Hoard nonetheless raises interesting questions about how we relate to things of the past and how they relate to us.\nA visitor to the exhibition first finds himself in a narrow space with faux shields painted on the walls and, more conspicuously, large and rather loud projected images of Anglo-Saxon warriors at battle, as portrayed by modern reenactors. Most scholars will immediately feel their skepticism rise: the hoard looks to be captive to an imaginative medievalism of the present-day, and the chance of a real examination of the objects outside such fantasies seems slim. The question of how the show will present its materials is further complicated by the next room, which first meets the visitor with a case containing a leather satchel with small gold objects falling out of it, accompanied by no information save a line from Beowulf: “hurry to feast your eyes on the hoard.” But such a feast has not been laid, for next one sees two large photographs of white-haired, portly men: Terry Herbert, the metal detectorist who discovered the hoard, and Fred Johnson, owner of the farm which yielded the gold. From the outset, then, the narrative of the exhibition is tangled: Is it about Anglo-Saxon England? Is it about treasure hunters? Is there any chance it will be about the actual artifacts in the hoard?\nHappily, the distracting nature of the first rooms does not extend to the core of the exhibition, a large, open-plan room featuring focus displays on particular objects and groups of objects from the hoard. Whereas the video and graphics of the first rooms distracted from the objects, here they focus your attention: a short video showing how garnets were cut and set by Anglo-Saxon smiths, again shot with reenactors, is exemplary in its clarity and attention to detail. These videos, created with the significant involvement of the living-history society Regia Anglorum, are a fine testament to the potential benefits when amateur enthusiasts work with trained scholars to create vivid images of the past. When viewed again with this perspective, in fact, the introductory video looks a lot better: the costume, weaponry, and regalia are expertly made, and they cast familiar museum pieces (such as items from Sutton Hoo) in the real world of their initial use. Some of the modern reconstructions from the videos, such as a sword and processional cross, are included in the exhibition and serve well to help visitors understand how certain fragments from the hoard might fit together. Touch-screen displays accompanying select objects allow the visitor to view the pieces from several different angles and investigate their details and possible meanings more carefully, again giving fuller sense of what these things are and were. Since many of the objects are small, and appear smaller still in capacious display cases, these alternate presentations allow visitors different points of access to the objects.\nIt is striking that, even in the face of an extensive interpretive apparatus—encompassing graphics, reconstructions, and audio, video, and computer modules—the objects themselves remain undoubtedly the star of the show. They are small and mangled, they are fragments and often themselves fragmented, yet they have remarkable pull. As I watched and eavesdropped on other visitors, it was clear that even casual beholders were subject to their charms. The gold-lust they inspire is very real, and the objects have been presented, both in the images provided to the media and in the exhibition, to maximize that effect. In the display cases, they are brilliantly lit and set against rich fabrics, while the images distributed to the media (and illustrating the exhibition) have clearly been carefully manipulated to make the objects pop.\nThe desire to emphasize the hoard’s status as “treasure” has been a crucial component of its presentation and reception from the very first.1 The hoard was, of course, discovered not by an archeologist but by a treasure hunter, and the payout that Herbert and Johnson received from the British government for the hoard is mentioned in nearly every comment on the find. The compulsory sale of the objects to public collections is an element of the Portable Antiquities Scheme (PAS), a government program which requires and encourages members of the public to report any finds of gold and silver objects over three hundred years old, as well as prehistoric base-metal assemblages. While the general consensus has been that the PAS has been a great success, resulting in the tracking of 764,861 artifacts at last count, there has been some concern, primarily expressed informally, that the emphasis on the material benefit Herbert and Johnson derived from the find will result in something of a gold rush across the English countryside. Detectorists are by and large not trained in proper archaeological excavation and documentation, and the desire for a big strike may lead to hasty and careless excavations. Indeed, the excavation of the Staffordshire Hoard site subsequent to Herbert’s discovery has come under serious criticism, with some archeologists charging that it was conducted hastily with more of an eye to maximizing public relations impact than methodical record keeping.2 The blurred distinction between historical artifact and modern-day treasure might prevent us from gaining any real insight into the culture in which such objects were made.\nIn part due to the as-yet inconclusive archaeological surveys of the find spot, no satisfactory explanation for the origins of the hoard or the reasons for its deposit in the ground has yet been put forth.3 In a video documentary accompanying the exhibition, Kevin Leahy, National Finds Adviser of the Portable Antiquities Scheme, muses: “[The Staffordshire Hoard] doesn’t have a context. Its context is itself.” Whether intentionally or not, Leahy articulates the core problem that the exhibition and accompanying publication by Caroline Alexander are unable to solve: How, exactly, are we to imagine the Staffordshire Hoard? As described above, the first rooms of the exhibition put forth three different answers in quick succession: the objects are war regalia, they are the contents of a leather satchel (whose intended destination is unknown), and (or?) they are a lucky find. The exhibition succeeds best in answering the question in the main room, where it focuses on individual pieces and groups of like objects, but it falters again in later rooms as it attempts to create something of a broader context by including components about Old English poetry and cultural change in Anglo-Saxon England. Alexander’s book, though engagingly written and beautifully illustrated, similarly attempts to shed light on the objects by conjuring the social and cultural changes of the early Anglo-Saxon period, but the things themselves end up buried in context, to be excavated again only in an appendix of beautiful but sparsely annotated photographs.\nThe anxiety of context continues to vex many curators and art historians: How can we properly consider objects within their historical setting while allowing for the very real presence they have in the present day? The Staffordshire Hoard brings this question into sharp relief because the narrative of its discovery powerfully amplifies the beauty and mystery of its contents. There is a clear sense, in the fitful attempts to interpret and contextualize the objects, that their mysteriousness is to be understood as an essential part of their nature. Consider how most of the objects are reproduced (fig. 1): against black backgrounds, conjuring memories of the rich soil from which they were unearthed, but with digitally inserted “reflections,” hinting at something left behind, unknown and only dimly glimpsed. We literally see them in a mirror, darkly. This photoshopped conceit must be rooted in part in the popular conception of the early medieval period as the “Dark Ages,” but I think it also accentuates our sense that objects have an inner life that we can only imagine.4 This intuition is brought out in the nearly contemporary Old English riddles, in which things speak of themselves enigmatically. One riddle, for example, intones\nMy race is old, my seasons many,\nMy sorrows deep . . .\n. . . I remember\nwho ripped our race, hard from its homeland,\nstripped us from the ground. I cannot bind\nor blast him, yet I cause the clench of slavery\nround the world . . .5\nIt is gold who speaks here, and as in many of the other riddles that conjure metals and precious stones, gold seems to mourn for its lost origins in the earth. In the exhibition, the objects are constantly being excavated and cleaned in photos and videos; one touch-screen program allows visitors virtually to brush the dirt off a star-shaped mount. The narrative of these objects as born of, returned to, and resurrected from the earth is constantly present. But their histories encompass much more: nearly all the materials in these objects were recycled. Gold was not mined in the British Isles at this time, so new gold objects needed to be made from recycled materials. X-ray fluorescence analysis of the garnets revealed that while some of them came from Bohemia, the larger cabochons originated in Sri Lanka, and almost certainly came to England through Roman trade networks. Each of these objects thus has the memory of previous forms within them.\nThe Staffordshire Hoard is, in many ways, a construction of the early twenty-first century. For the foreseeable future, scholars interested in the objects that have been forged together into this new collective identity will have to keep the particular nature of its construction firmly in mind. Far from being a barrier, however, I think this provides an important opportunity to analyze objects as existing in a historical continuum that extends to our present as well as into the distant past.\nBenjamin C. Tilghman specializes in the art of early medieval Europe, with particular interests in the symbolic aspects of ornament, the visual nature of writing, cross-cultural interchange in the North Sea basin, and phenomenological and object-oriented analyses of art. From 2007 to 2010, he served as a curatorial fellow at the Walters Art Museum, where he curated exhibitions on the Saint John’s Bible, miniature books, and Hubble Space Telescope imagery.\n- 1. And was almost immediately cause for comment, as for example Karl Steel, “On the Staffordshire Hoard: A Rich Glowing Effect,” In the Middle, September 24, 2009, http://www.inthemedievalmiddle.com/2009/09/on-staffordshire-hoard-rich-glowing.html.\n- 2. Catherine Hills, “The Primacy of Context,” Antiquity 85 (2011), 226–28.\n- 3. For a good overview of the problems and possibilities, see Leslie Webster et al., “The Staffordshire (Ogley Hay) Hoard: Problems of Interpretation,” Antiquity 85 (2011), 221–29.\n- 4. The idea that things “withdraw” from each other is a core component of recent work in object-oriented ontology, particularly that of Graham Harman. See, for example, The Quadruple Object (Washington: Zero Books, 2011), 35–50.\n- 5. Translation from Craig Williamson, A Feast of Creatures (Philadelphia: University of Pennsylvania Press, 1982), 141.']	['<urn:uuid:a381c5b3-bc74-490c-97d0-1e147db7ec55>']	factoid	direct	concise-and-natural	distant-from-document	single-doc	expert	2025-05-01T23:21:14.341336	10	25	1998
338	awards european film festival cannes 2014 2023 comparison	In 2014, several European films received recognition at Cannes, with 'Force Majeur' winning Un Certain Regard Jury Prize and 'White God' winning Un Certain Regard Award. In comparison, at Cannes 2023, European films achieved significant success with 'Anatomy Of A Fall' winning the prestigious Palme D'Or, and 'How To Have Sex' winning the top Un Certain Regard prize.	['A Man Called Ove by Hannes Holm. Nominated Oscar for Best Foreign Language Film and Best Makeup and Hairstyling 2017. Won European Comedy European Film Awards 2016.\nThe Nile Hilton Incident by Tarik Saleh. Won Grand Jury Prize in the World Cinema Competition, Sundance 2017.\nThe Commune by Thomas Vinterberg. Starring Trine Dyrholm. Won Silver Bear, Best Female Actor.\nUnited States of Love by Tomasz Wasilewski. Won Silver Bear, Best Script.\nThe Hundred Year-Old Man Who Climbed Out of the Window and Disappeared by Felix Herngren. Nominated Oscar Best Makeup and Hairstylling.\nMy Skinny Sister by Sanna Lenken. Won Crystal Bear 2015, Special Mention of the Generation Kplus International Jury, nominated European Film Award, Young Audience Award.\nFlocking by Beata Gårdeler. Won Crystal Bear Generation 14plus Berlin 2015.\nForce Majeur by Ruben Östlund. Won Un Certain Regard Jury Prize 2014 and nominated Golden Globe Best Foreign Language Film and BAFTA Best Film not in the English Language.\nWhite God by Kornel Mundruczó. Won Un Certain Regard Award 2014.\nOnly God Forgives by Nicolas Winding Refn. Starring Ryan Gosling. Official Competition Cannes 2013.\nFilth by Jon S. Baird. Starring James McAvoy. Won Best Actor British Independent Film Awards 2013.\nLove Is All You Need by Susanne Bier. Starring Pierce Brosnan and Trine Dyrholm. Won European Film Award Best Comedy 2013.\nThe Hunt by Thomas Vinterberg. Starring Mads Mikkelsen. Won Best Actor in Cannes and European Film Award Best Screenwriter 2012; nominated Golden Globe and Oscar Best Foreign Language Film.\nKon-Tiki by Joachim Rønning and Espen Sandberg. Nominated Golden Globe and Oscar for Best Foreign Language Film 2012.\nA Royal Affair by Nikolaj Arcel. Won two Silver Bears in Berlin 2012 for Best Actor and Best Script, nominated Golden Globe and Oscar for Best Foreign Language Film.\nThe Woman in Black by James Watkins. Starring Daniel Radcliffe.\nMelancholia by Lars von Trier. Starring Kirsten Dunst, Kiefer Sutherland, Charlotte Gainsbourgh, Charlotte Rampling, Stellan Skarsgård and John Hurt. Won Best Actress Award in Cannes and three European Film Awards 2011.\nPlay by Ruben Östlund. Won Coup de Couer Directors’ Fortnight 2011.\nIn A Better World by Susanne Bier. Won Oscar and Golden Globe for Best Foreign Language Film and European Film Award Best Director 2011.\nEasy Money Trilogy by Daniel Espinosa, Babak Najafi and Jens Jonsson. Starring Joel Kinnaman and Fares Fares.\nIf I Want To Whistle, I Whistle by Florian Serban. Won Silver Bear and Alfred Neubauer Prize in Berlin 2010.\nThe Millennium Trilogy directors Nils Arden Oplev and Daniel Alfredson. The Girl With The Dragon Tattoo*, The Girl Who Played With Fire, The Girl Who Kicked The Hornets Nest. *Won BAFTA, Best Film Not in English Language 2011.\nAntichrist by Lars von Trier. Starring Willem Dafoe and Charlotte Gainsbourg. Won Best Actress Cannes 2009.\nInvoluntary by Ruben Östlund. Un Certain Regard 2008.\nDogville by Lars von Trier. Starring Nicole Kidman, Paul Bettany and Lauren Bacall. Official Competition Cannes 2003.\nTogether by Lukas Moodysson. Independent Spirit Awards 2002.\nDancer In The Dark by Lars von Trier. Starring Björk, Catherine Devenue and David Morse. Won Palme d’Or in Cannes 2000. Oscar nominated Best Music, Original Song 2001.\nUnder The Sun by Colin Nutley. Nominated Oscar Best Foreign Language Film 2000.\nShow Me Love by Lukas Moodysson. Won Teddy Awards Best Feature Film Berlin 1999.', 'The first titles in the running for the 2023 European Film Awards have been revealed by the European Academy, including Cannes premieres Anatomy Of A Fall, How To Have Sex, The Old Oak and Firebrand.\nAnatomy Of A Fall won the Palme D’Or for French director Justine Triet at Cannes. The Hitchcockian mystery thriller is about a woman, played by Sandra Hüller, accused of murder when her husband dies of suspicious causes. Marie-Ange Luciani and David Thion produce.\nHow To Have Sex won the top Un Certain Regard prize at Cannes for debut UK filmmaker and Screen Star of Tomorrow 2021 Molly Manning Walker. The feature follows a group of teenage girls on a rite-of-passage clubbing holiday, shot in Greece. It is produced by Wild Swim’s Ivana MacKinnon and Emily Leo alongside Heretic’s Konstantinos Kontovrakis, who produced Triangle Of Sadness, which swept the board with four big wins at the 2022 ceremony.\nThe Old Oak is directed by UK filmmaker Ken Loach, made with his long-time creative partners writer Paul Laverty and producer Rebecca O’Brian of Sixteen Films. The film portrays the struggle of a landlord to hold onto a pub called The Old Oak as the only remaining public space where people can meet in a once thriving mining community, following the arrival of Syrian refugees who are placed in the village without any notice.\nFirebrand stars Alicia Vikander as Katherine Parr, the sixth wife of Henry VIII, played by Jude Law. Brazilian Karim Aïnouz directs, with Brouhaha Entertainment producing.\nFurther Cannes titles in the mix include Fallen Leaves, La Chimera, The Animal Kingdom, Blackbird Blackbird Blackberry, The Goldman Case and Close Your Eyes.\nEligible for the European Film Awards are European feature films which, among other criteria, had their first official screening between June 1 2022 and May 31 2023 and have a European director, with some stipulations for if a non-European director is Europe-based or has worked in the European film industry for five consecutive years or more.\nFurther titles will be announced in September.\nIn the coming weeks, the 4,600 members of the European Film Academy will start to watch and vote for the selected films. Based on the votes of the participating members the nominations in the feature film categories European film, director, actor, actress and screenwriter, as well as in the category European documentary, will be made public on November 7. The winners will be announced at an awards ceremony that takes place on December 9 in Berlin.\nAdditionally, an eight-member jury will decide on the award recipients for European cinematography, editing, production design, costume design, make-up and hair, original score, sound and visual effects. There will be no nominations in these categories.\nEFA Feature Film Selection 2023 – Part 1\n20,000 Species of Bees (Sp)\nDir. Estibaliz Urresola Solaguren\nDir. Christian Petzold\nAnatomy Of A Fall (Fr)\nDir. Justine Triet\nBehind The Haystacks (Greece-Ger-North Macedonia)\nDir. Asimina Proedrou\nBlackberry Blackbird Blackberry (Switz-Geo)\nDir. Elene Naveriani\nClose Your Eyes (Sp-Arg)\nDir. Víctor Erice\nFallen Leaves (Fin-Ger)\nDir. Aki Kaurismäki\nDirs. Sam H. Freeman, Ng Choon Ping\nDir. Karim Aïnouz\nHow To Have Sex (UK-Greece)\nDir. Molly Manning Walker\nDir. Marco Bellocchio\nLa Chimera (It-Fr-Switz)\nDir. Alice Rohrwacher\nSafe Place (Cro-Slovenia)\nDir. Juraj Lerotic\nDir. Marija Kavtaradze\nThe Animal Kingdom (Fr)\nDir. Thomas Cailley\nThe Goldman Case (Fr)\nDir. Cedric Kahn\nThe Happiest Man In The World (North Macedonia-Bos & Her-Belg-Slovenia-Cro-Den)\nDir. Teona Strugar Mitevska\nThe Old Oak (UK-Fr-Belg)\nDir. Ken Loach\nThe Teachers’ Lounge (Ger)\nDir. Ilker Çatak']	['<urn:uuid:13424a27-cdbe-4b2f-b519-4dcd81684917>', '<urn:uuid:9ecd458f-8452-488c-a70d-ef3bb610a35b>']	open-ended	with-premise	short-search-query	distant-from-document	comparison	expert	2025-05-01T23:21:14.341336	8	58	1134
340	What percentage of performance horses have gastric ulcers?	Over 60% of performance horses have gastric ulcers.	"[""How Supplements Complement Horse Feed\nBy: Dr. Lydia Gray\nEvery horse owner wants to make the best decisions when it comes to caring for their horse, and that includes feeding the “best” diet. We all know that forage (like hay and pasture) is the foundation of equine nutrition, but somehow the horse industry developed the mindset that horses “need” grain. Actually, what horses need is a diet based on high-quality forage; then their calorie or energy needs met; followed by nutrients such as protein, vitamins, and minerals; and finally additional ingredients to address any specific issues that individual horses might be facing. Let’s look at each of these areas a little bit closer.\nFocus on Forage\nHorses get most of their nutrition from the forage or roughage they eat. Considering that horses are designed to take in 1-2% of their body weight each day in hay or pasture, it should be no surprise that 10 to 20 pounds (for a 1,000 pound horse) of long-stem plant matter supplies most of the calories, protein, vitamins, and minerals required by the average horse, along with fibrous bulk for a healthy gastro-intestinal tract. To get a better idea of exactly how much of each nutrient is being provided by the roughage you’re providing for your horse, hay analysis or forage testing can be performed. Armed with these “nutrition facts,” the rest of the horse’s diet can be adjusted to ensure he is getting the right amounts and the right ratios of nutrients. Analysis or testing can also be used to select more appropriate hay for a horse on a low non-structural carbohydrate (NSC) diet, a low potassium diet, or other special need.\nAs forage makes its way through the intestinal tract to the cecum and colon, its fiber component begins to be digested or fermented by the microscopic organisms that live in the hindgut. When these bacteria or “good bugs” break down the structural carbohydrates that the horse himself cannot, some of the end products are volatile fatty acids (energy), amino acids, and vitamins. Thus, forage is a major source of energy or calories for the horse and additional roughage should not be overlooked as a weight-gain strategy. Because the horse can only eat so much hay or grass in a day though, horses that require more calories to maintain their body condition score, such as hard-working athletes or pregnant and lactating mares, may need a more calorie-dense feedstuff, and that’s where grain comes in.\nThe word “grain” means many things to many people. To some, it is synonymous with “meal” as in: “my horse gets grained twice a day.” To others, it means any kind of pelleted feed or textured sweet feed, as in: “my horse gets two pounds of grain morning and night.” And finally there is a third group of people who literally mean whole cereal grain such as oats, corn, or barley. None of these definitions are wrong, they just point out how important it is to be sure and talk apples to apples and oranges to oranges when discussing a horse’s diet. So here are some definitions to make sure everyone is on the same page:\nComplete Feed: a manufactured feed that combines grain and roughage; designed to partially or completely replace a horse’s forage, usually due to dental problems or because quality hay is not available (aka “senior” feed, serving size 15-20 lbs daily).\nFortified Grain: a manufactured feed that includes added guaranteed levels of protein, vitamins, and minerals; common types include pelleted and sweet feeds (aka “concentrate,” serving size 5-9 lbs daily).\nWhole Grain: a cereal grain that has not been fortified with additional nutrients; may be processed by cracking, crimpling, rolling, or heating (examples: oats, corn, barley; serving size 1-5 lbs, or quarts daily).\nRation Balancer: a concentrated feedstuff, usually a pellet, designed to complete and balance a forage-only diet by providing protein, vitamins, and minerals; not a significant source of calories or sugars/starches so ideal for easy-keepers and others who don’t need or can’t have additional sugars and/or calories (serving size 1-2 lbs daily).\nMulti-Vitamin/Mineral Supplement: a powder or pellet designed to fill in some of the\ngaps between the vitamins and minerals provided by forage containing a sufficient\nlevel of high-quality protein; not a significant source of calories or sugar/starches so also\nideal for easy-keepers and others who don’t need or can’t have additional sugars and/or calories (serving size 1-2 ounces daily).\nNow that the horse is receiving a complete and balanced, forage-based diet, it’s time to see if there are any issues being faced that could benefit from the additional support of targeted ingredients. Sixty percent of lameness is due to arthritis – could a joint supplement with glucosamine, chondroitin sulfate, hyaluronic acid, MSM, and other ingredients complement veterinary recommendations? Colic is the leading cause of death in horses after old age, so consider supplement ingredients like prebiotics, yeast, and enzymes that support hindgut health for high-risk individuals. “No hoof, no horse” is a common saying because it’s so true. A hoof supplement containing biotin and other ingredients may be helpful for the horse that struggles to maintain healthy feet. Don’t let inadequate levels of nutrients like magnesium, B vitamins, and even certain amino acids contribute to a worrisome demeanor in your horse; support a normal disposition with a supplement from the calming category. Finally, it has been shown that over 60% of performance horses have gastric ulcers. Talk to your veterinarian about the research behind a supplement with ingredients like sea buckthorn, glutamine, aloe vera, pectin, lecithin, and licorice.\nThe point is: feed your horse appropriately by first, focusing on forage; second, ensuring he’s getting the right amount of calories for his workload; third, rounding out his diet with the rest of the vital nutrients protein, vitamins and minerals; then finally, work with your veterinarian to address unique concerns that may benefit from a targeted supplement approach.\nSmartPak strongly encourages you to consult your veterinarian regarding specific questions about your horse's health. This information is not intended to diagnose or treat any disease, and is purely educational.""]"	['<urn:uuid:891e44d5-e1b9-4d2c-9bcc-159eaa66209f>']	factoid	direct	concise-and-natural	similar-to-document	single-doc	expert	2025-05-01T23:21:14.341336	8	8	1016
341	pilots landing gear canyon facts dangers	Early pilots faced numerous challenges related to both landing gear and flying conditions in the Grand Canyon. Initial fixed landing gear designs created significant drag and reduced aircraft performance, with landing gear contributing up to 40% of fuselage drag. In the Grand Canyon specifically, there were widespread beliefs about dangerous conditions, including 'tempestuous air currents' and risks of crashing into canyon pillars. However, Lieutenant Alexander Pearson proved these fears unfounded in 1921 when he successfully surveyed the Canyon, though he did discover that airfields needed to be at least two miles from the rim due to turbulence. He even managed to land at Indian Garden below the Bright Angel Trail, with the main challenge being motor overheating due to hot air at the canyon bottom.	"['The year 1921 stands unique in the history of United States aeronautics. World War I had just ended, and a stimulus of popular curiosity emerged regarding the aircraft that essentially won the war.\nAmerica was uncertain of what would happen with aviation after the war and some believed it would be similar to the emergence of the steamboat and railroad which were at first ridiculed, then doubted and then enthusiastically embraced. Today it would be similar to the introduction of the smartphone.\nIn the years after war, countries worked to push the boundaries of what aircraft could do. In the United States, Americans broke the altitude record by reaching 33,114 feet. Air Service planes flew from New York to Nome, Alaska and back. Americans set new speed records in the Pulitzer race on Thanksgiving Day, and Grand Canyon National Park was surveyed by aircraft for the first time.\nBetween the Army Air Service, Naval Aviation, Aerial Mail and civilian aircraft, Americans logged over 15,250,000 miles in 1920.\nAviator Alexander Pearson\nLieutenant Alexander Pearson became a pilot in the United States Air Service in 1917. During the war, he was a flight instructor for various air fields for the military. After the war, as most squadron members left the Air Service and returned to civilian life, Pearson stayed with the Air Service and became a highly accomplished aviator.\nThe 1920s was the introduction of barnstorming, during which pilots went from town to town demonstrating their piloting skills. Air Service pilots and mechanics were encouraged to engage in barnstorming and air races to help aircraft manufacturers recognize the flaws in their own designs and learn from each other.\nIn October 1918, Pearson entered the first transcontinental air race that took off from Roosevelt Field in Long Island, New York and ended at Crissy Field in San Francisco.\nThe race had 100 entrants — 50 began in New York and 50 began in San Francisco. The race only included Army pilots, recommended by their commanding officers, who all flew de Havilland DH-4 aircraft.\nUsing a Rand McNally Railroad map as a guide, Pearson recorded the fastest actual time, and in turn a world record. He crossed the continent twice in 40 hours. He won a Thermos bottle, a leather flying suit and $825 of liberty bonds.\nPearson was stationed with the 12th Observation Flying Squadron in Douglas, Arizona. There he was utilized by the U.S. Army Border Air Patrol to fly along border between the United States and Mexico to watch for bandits and cattle rustlers.\nIn 1920, Pearson became famous when he was involved in an aviation incident along the U.S. — Mexico border. Pearson had been traveling to Florida for a transcontinental flight from Jacksonville to San Diego, California. His de Havilland DH-4 began having engine trouble and he was forced to land in the shrub and rocks near the Rio Grande River.\nBeing resourceful, Pearson gathered the engine water, once it had cooled, and began traversing the rocky terrain of south Texas.\nA large search ensued, with 65 planes searching the ground for the aviator, and most people feared Pearson had perished in a crash. However, Pearson emerged several days later and reported that beaver trappers with burros helped him ride out of a canyon to a ranch where he eventually made his way to Sanderson, Texas.\nSearchers eventually found his plane, repaired it, constructed a runway and returned the plane to San Antonio, Texas.\nGrand Canyon and Williams\nIn May 1921, Pearson was commissioned to survey the Grand Canyon for possible commercial air travel and mail service. He was to locate landing fields and make observations about air conditions for mail and passenger services between the Union Pacific Railroad in Utah and the Santa Fe Railroad in Arizona.\nAccording to the June 10, 1921 edition of The Williams News, Pearson surveyed northern Arizona for a suitable location to be a base for his surveys. After looking at several airfields in the area, he chose the Williams field as the best field for his purposes.\nAccording to The News, “Arrangements were made for landing at the east side of the field (the old Fair ground). The straightaway was lengthened by taking down the fence at the south of Ed Hoffmeyer’s ranch.”\nBrush had to be cleared away from the east side of the oval race track. Gas and oil were available to Pearson and this field remained the official landing site for Williams until Webber Field was built in 1925.\nThe News reported, “This field, so Mr. Pearson states, offers the best opportunity for landing and taking off, of all the prospective fields in northern Arizona, that he has viewed.”\nAccording to Arizona aviation historian Ruth Reinhold, Flagstaff landing strips at that time were in poorer condition than the Williams fairground track. They were small, surrounded by trees and usually muddy. The poor field conditions, the high altitude and unpredictable weather kept pilots from wanting to land in Flagstaff.\nThe Williams News said airmen had formerly flown near the rim of the Grand Canyon, but Pearson’s attempt to fly across and descend into the Canyon would be a first.\nPearson was inundated with tales of how dangerous flying over the Canyon could be. He was told of the hazardous storms and air currents and was “Almost scared to death of the job that has been assigned to him.”\nOn June 4, Pearson arrived at the Grand Canyon and met with the park’s superintendent. They evaluated possible landing sites near the rim, but the dense forest pushed the best site back 11 miles from the rim. He did find a possible emergency landing strip near the Anita Mine, along the railway.\nPearson returned to Nogales, but headed back north June 9 and landed in Williams and spent several weeks flying around the Canyon and northern Arizona. Williams became his base for his Grand Canyon surveys as he inspected Cataract Canyon and as far west as Seligman. He also circled over Flagstaff, the San Francisco Peaks and north over the Grand Canyon.\nPearson reported that flying over the Grand Canyon was better than he imagined. He reported good conditions and is believed to be the first person to cross the canyon, land on the North Rim and return.\nAccording to Reinhold, Pearson even landed at a small airstrip cleared for him at Indian Garden below the Bright Angel Trail in the Canyon.\nDuring his flights, he descended 3,500 feet below the South Rim and 4,500 feet below the North Rim. He said the only difficulty he found was the motor became very hot because of the hot air at the bottom of the Canyon.\nUntil his historic flights, people assumed flying over the Canyon was too dangerous because of the “tempestuous air currents tumbling into and out of the canyon.” People also believed there was a “danger of being dashed against the upstanding pillars and peak of the canyon,” and “It was impossible to take off from a landing of 9,000 feet above sea level.” He proved all of this was possible in his survey flights.\nIn total, Pearson made 14 flights with a total of 22 hours of flying. He reported many findings, including his recommendation that air fields be at least two miles from the rim because of turbulence from the Canyon’s air currents. He suggested using the air strip at the Anita Mine and using vehicles to haul passengers to the park.\nLife after the surveys\nAfter finishing his surveys, Pearson returned to Douglas, where he married Margaret Shannon and honeymooned at the Grand Canyon.\nIn 1922, Pearson completed another transcontinental trip from Fort Bliss to Portland, Oregon, which he completed in 29 hours.\nPearson was involved in several mishaps and crashes during his aviation career like many pilots during this time in aviation history. He was forced to land on a highway north of Roswell, New Mexico with carburetor trouble in 1922. He had another crash near Ft. Bliss with a propeller malfunction. That same year, he also was forced down in a windstorm west of El Paso.\nPearson went on to participate in stunt fairs and air shows, and attended numerous celebrations to display his aircraft. He broke several speed records and became famed as a stunt flyer.\nOn Sept. 2, 1924, Pearson was making test flights for the Pulitzer Race at Wilbur Wright Field when he died in an airplane crash. He was flying a Curtiss R-8 Navy racing plane at 200 mph when a strut failed and the plane’s wings collapsed.\nAn airfield in Vancouver, Washington was designated Pearson Field in May 1925. The dedication included an air show with over 52 planes and 20,000 people in attendance. The field is currently a municipal airport for the city of Vancouver and is one of the oldest operating airfields in the United States. A museum is dedicated to Pearson at Fort Vancouver National Historic Site.\nMore like this story\n- Williams aviation history Part II: Where was the Spirit of St. Louis?\n- Williams aviation history Part I: Charles Lindbergh makes pit stop in Williams\n- Air show features slice<br>of U.S. aviation history\n- Editorial: Celebrate Museum Month by visiting Planes of Fame\n- Warbirds from the past<br>put on big show in Valle', 'This is an example of a tricycle landing gear that is found in newer aircraft models. This type of landing gear makes the aircraft easy to steer because the nose gear is steerable.\nConventional fixed landing gear consists of two wheels forward of the aircraft\'s center of gravity and a small tail wheel located in the rear. This configuration is nicknamed the ""taildragger. ""\nThe Lockheed Y1C-25 had the same type of ""trouser"" landing gear as the Sirius.\nThe Northrop Gamma shown here, as well as the Alpha and Beta, all produced in the 1930s, had landing gear with streamlined coverings that extended down from the fuselage with the wheels sticking out from the bottom.\nRetractable Landing Gear\nAircraft designers of the 1920s knew that reducing drag on an airplane in flight was important to improving speed and fuel efficiency, as well as maneuverability and controllability. But they still had relatively little understanding of what actually caused drag on airplanes. Various structures obviously caused drag, but they had first to identify the most important sources before they could address them.\nIn 1927, the National Advisory Committee for Aeronautics (NACA) opened its new Propeller Research Tunnel (PRT) at Langley Memorial Aeronautical Laboratory in Virginia. The PRT was a very large wind tunnel for the time, with a diameter of 20 feet (6.1 meters). It was designed to allow the testing of an entire airplane fuselage with engine and propeller, as opposed to simply a part of an airplane or a scale model. NACA aeronautical engineers suspected that the aircraft landing gear contributed to much of the drag of an airplane, and the PRT was the first wind tunnel that would allow them to test this.\nLanding gear consists of the wheels that stick out below the fuselage so that an airplane can roll down the runway during landing and takeoff. In early aircraft, they were fixed in an open position so that they protruded at all times, even while the plane was flying and nowhere near the ground. Tests in the PRT immediately demonstrated that landing gear contributed up to 40 percent of fuselage drag, which shocked the researchers. They realized that reducing the drag produced by the landing gear would significantly improve the performance of the airplane in flight.\nThere were several ways to reduce the drag of the landing gear. The two most obvious methods were to either retract the landing gear inside the aircraft or redesign a fixed landing gear so that it produced less drag while still protruding below an aircraft.\nRetracting landing gear were not a completely new idea in the 1920s. J.W. Wartin\'s Kitten, built in 1917, had retractable gear (but could not actually fly). The Dayton Wright RB-1 of 1920 and the Verville Sperry R-3 of 1922 also had retractable gear. But these aircraft were rarities and most airplanes had fixed landing gear at the end of metal struts because they were easy to design, strong, and relatively lightweight.\nWhen designing an aircraft, engineers have always had to address five conflicting requirements. These are: performance, weight, cost, reliability, and maintenance. The best solution to the performance requirement was to pull the landing gear completely inside the fuselage and cover them over, presenting a smooth surface that produced no drag. But while ideal from a performance standpoint, this approach affected all of the other requirements—it weighed more, cost more, was less reliable, and required more maintenance. The wind tunnel data from the PRT caused aircraft designers to look immediately for ways of developing landing gear that provided better performance and hopefully did not have too many other costs associated with them.\nThe Boeing Monomail, which first appeared in 1930, and the Lockheed Orion are generally considered pioneers in the development of retractable landing gear, proving that it was practical. But airplane designer Jack Northrop, who was very interested in streamlining aircraft to improve performance, produced the Northrop Alpha, Beta, and Gamma with fixed landing gear during the 1930s. These aircraft had streamlined coverings that extended down from the fuselage, with the wheels sticking out at the bottom. These were generally referred to as ""trouser"" gear. The Lockheed Sirius, which was built for Charles Lindbergh, had streamlined coverings over the wheels themselves that were referred to as ""pants""-type landing gear. Although trouser and pants gear produced more drag than fully retracted gear, they were still a substantial improvement over uncovered landing gear. More importantly, they were still lighter, cheaper, more reliable, and easier to maintain than the retractable gear. But during the 1930s, numerous designers embraced retractable gear—they were willing to accept the other drawbacks of retractable landing gear simply to achieve the better performance.\nAirplane designers explored numerous ways to retract aircraft landing gear into the fuselage. In some aircraft they were pulled straight up, usually into cowlings behind the engines (as in the DC-1, 2 and 3), sometimes with part of the wheels protruding outside the airplane. In other cases, particularly with smaller aircraft, the struts folded inward so that the wheels fit into the bottom of the fuselage horizontally, sometimes covered with a door to further reduce drag. Some of the drive mechanisms were electric, whereas others were hydraulic. The designers had to ensure that the gear deployed and locked in place. Landing gear that collapsed when a plane landed could cause the plane to tumble out of control and kill the pilot, or at least seriously damage the airplane.\nFor early retractable landing gear not even the performance improvements were clearly achievable, since a retractable landing gear with its motors and associated machinery weighed more than a fixed gear, thereby requiring greater lift from the aircraft and negating some of the benefits of the reduced drag of the retracted gear. While retracting the gear could improve the performance of the plane, it might require a bigger engine and more fuel—not to mention more money.\nIn fact, it was this delicate tug-of-war between the extra weight of the gear and the reduced drag that was most important for the overall acceptance of retractable landing gear. Drag increases with speed and therefore reducing drag becomes more important as an aircraft\'s speed increases. As aircraft speeds continued to increase during the 1930s, particularly as aircraft began to reach speeds of 200 miles per hour (322 kilometers per hour), the increased weight of retractable gear became less important than reducing drag, and retractable landing gear became commonplace to most aircraft.\nToday, many low-speed private aircraft still have fixed landing gear because of cost and maintenance concerns. Some even have the streamlined ""pants"" coverings over their wheels. But virtually all larger and faster aircraft have completely retractable landing gear. Designing such gear presents engineers with a number of problems, particularly how to mount them on the airplane without affecting other parts of the aircraft design. Large commercial airliners like the 747 and Airbus A340 have enough internal volume so that the landing gear can fit inside the fuselage diameter. But some smaller commercial aircraft have to compromise. Their fuselages are so small that fitting the landing gear inside the primary fuselage would result in a large bump inside the cabin that passengers would have to walk over. So their landing gear are often fitted inside bulges that stick outside of the fuselage. This is also common to large military transport aircraft like the C-5 and C-17, which use up every inch of interior space and need long flat floors inside so that tanks and other equipment can be rolled inside.\n--Dwayne A. Day\nSources and Further Reading:\nBrooks, P.W. The Modern Airliner: Its Origins and Development. London: Putnam, 1961.\nMiller, R., and Sawers, D. The Technical Development of Modern Aviation. New York: Praeger, 1970.\nRae, J.B. Climb to Greatness: The American Aircraft Industry, 1920-1960. Cambridge, Mass.: MIT Press, 1968.\nVincenti, Walter G., ""The Retractable Airplane Landing Gear and the Northrop ‘Anomaly\': Variation-Selection and the Shaping of Technology."" Technology and Culture, January 1994, 1-33.']"	['<urn:uuid:abe3c37c-fc51-4200-85ac-b2bfefba674d>', '<urn:uuid:2b07dbc2-5fdc-4d79-aae4-64169b2dbdc9>']	open-ended	with-premise	short-search-query	distant-from-document	multi-aspect	novice	2025-05-01T23:21:14.341336	6	125	2873
344	How did generational knowledge transfer work in religious versus secular institutions?	In Mesopotamian temples, priestly knowledge was passed down within families, with offices typically transferring from father to son, particularly for high-status priests who needed specialized liturgical and ritual training. Similarly in ancient Egypt, civilian and military positions in palace administration were often staffed by the same families across generations, using education as the primary means of transferring institutional knowledge. Most Egyptian boys would become apprentices in their fathers' trades after completing formal education at age 14.	"[""- Mesopotamian temples commanded considerable manpower to work the agricultural estates, the various workshops, administration, and general maintenance of buildings and equipment. The service of the cult, the care for the divine statues residing in inner precincts of the temple, the daily offerings, and the liturgies also demanded considerable personnel. There was no general distinction between those who worked in the “secular” sector and those who performed “priestly” functions. In fact, a number of sacerdotal functions could be carried out on a part-time basis (so-called prebends). Those who had any contact with the sacred precincts of the temple had to ensure that they were in a state of ritual purity, attained by ablutions as well as by the incantation of purificatory formulas.Some categories of priests, especially those with intimate contact with divine statues, had to fulfill specific physical, ethical, and psychological requirements to qualify for the profession. Like scribes, certain high-status categories of priests belonged to families where the office passed from father to son. Literacy was mandatory for most cult specialists, who had to be knowledgeable in liturgical procedures, chants, and prayers. Highly trained staff performed exorcistic and healing rituals, solicited and interpreted omens, and advised the king. Some classes of temple personnel wore distinguishing clothing, hats, and other accoutrements that are depicted on cylinder seals or in Assyrian reliefs. Ritual nudity, as shown on Early Dynastic plaques, was discontinued after the Akkadian period. The daily services included musicians, singers, cult performers, and dancers, both male and female.Agreat number and variety of professional titles for temple personnel have been preserved in the administrative records as well as in lexical lists, but it is not always clear which function was implied at any given period. The highest office in the administrative hierarchy during the Uruk periodwas that of the EN.In the Predynastic period, this was used as the title of the city ruler, especially at Ur; in later times, however, it denoted purely cultic responsibility. Great prestige was given to the office of the female EN (Akkadian entu), who served the moon god (see NANNA) at Ur and who was often of royal blood. During the Old Babylonian period, the institution of the naditu women, who lived in a cloisterlike enclosure, flourished. The function of many other female cult specialists who appear in administrative, omen, and literary texts remains obscure.See also RELIGION.\nHistorical Dictionary of Mesopotamia. EdwART. 2012.\nLook at other dictionaries:\nPriests — Shamans are commonly distinguished from priests in academic discussions of distinctions between kinds of religious leaders. Although some cultures recognize that there are some situations in which a person may act as both shaman and priest, or … Historical dictionary of shamanism\npriests — prÉªËst n. clergyman, minister; one who performs religious rites … English contemporary dictionary\npriests — 1) persist 2) stripes … Anagrams dictionary\nPriests — Members of the second rank of Christian ministry, below Bishops but above deacons … Who’s Who in Christianity\nPriests — Dr Introduction of, from France, prohibited, 257 … The makers of Canada\nPRIESTS — … Useful english dictionary\nPriests' Eucharistic League — • Established in Paris by Pierre Julien Eymard Catholic Encyclopedia. Kevin Knight. 2006. Priests Eucharistic League Priests Eucharistic League … Catholic encyclopedia\nPriests' Communion League — • Association of priests established at Rome in 1906 Catholic Encyclopedia. Kevin Knight. 2006. Priests Communion League Priests Communion League … Catholic encyclopedia\nPriests for Life — (PFL) is a Roman Catholic pro life organization based in New York. It functions as a network to promote and coordinate pro life activism with the primary strategic goal of ending abortion and euthanasia and to spread the Gospel of Life according… … Wikipedia\nPriests of the Sacred Heart of Jesus — may refer to two distinct Roman Catholic orders: Congregation of the Sacred Heart of Jesus, founded by Joseph Marie Timon David in 1852 Priests of the Sacred Heart, founded by Leon Dehon in 1878 This disambiguation page lists articles associated… … Wikipedia"", 'Education in ancient Egypt was shaped by its conservative social system. While education was valued, it was largely restricted to the children of those with means. As the same families often staffed civilian and military positions in the palace administration across generations, education was one of the means by which institutional memory was transferred down the generations.\nThe history of ancient Egyptian education system remains unclear and its origins have not come down to us. However, an education system in one form or another existed throughout ancient Egypt’s long history. Its roots possibly lie at the beginning of the Egyptian Kingdom in 3000BC, although in the absence of any corroborating archaeological or historical evidence this is largely speculation.\nFacts About Education In Ancient Egypt\n- Ancient Egypt’s education syllabus included reading, writing, morality, mathematics, sports and religious instruction\n- The Egyptians used hieroglyphs or symbols in their written language. Their language was primarily comprised of consonants and had few vowels\n- Formal education for young boys began when they turned 7\n- Most boys were apprenticed to their father’s trade after completing their formal education\n- Scribes provided secular instruction on reading, writing, medicine and mathematics\n- Priests taught lessons on religion and morality\n- Surviving images show children seated at their desks in a classroom, while a teacher is seated at a larger desk\n- Most women in ancient Egypt were not allowed to receive a formal education but were homeschooled\n- Lower-class women could rarely read or write\nAccess To Education\nHence, it was customary for children of the elite of Egyptian society to attend school as members of these families required instruction in a range of disciplines to ensure the efficient governance of the country. Common subjects covered by ancient Egypt’s education syllabus included reading, writing, morality, mathematics, sports and religious instruction.\nGirls were not sent to school but were home educated by their mothers. Girls received instruction on reading cooking, sewing and managing the household. These topics were seen as socially important for women and education beyond these topics was considered to be superfluous.\nChildren from Egypt’s lower classes rarely received an education due to its cost, the limited number of schools available and reservation of school places for children from royal and wealthy backgrounds.\nAncient Egypt’s Education System\nMothers were responsible for educating their children, both boys and girls until the boys reached 4 years of age. From that age onwards, their fathers took on the responsibility for teaching their boys. Respect for parents, particularly for their mothers, was ingrained in the children and there was a keen focus on morals, manners and developing a work ethic. Disrespect and slothfulness were punished severely.\nArchaeological evidence suggests parallels exist between ancient Egyptian and modern education settings. Images on tombs and temples show children seated at their desks in a classroom, while a teacher is seated at a larger desk.\nWhen young boys turned 7, they began their formal education. Students read educational texts, called Kemty. These were written vertically rather than in the left to right\nAncient Egypt’s Teachers\nAncient Egypt’s teachers fell into two categories: priests and scribes. The role of priests was to provide lessons on religion and morality. Scribes provided secular instruction on reading, writing and subjects including medicine and mathematics. In the ancient Egyptian education system, the same scribe would teach all the school’s subjects. This was especially common in village schools.\nSpecialised teachers taught in schools dedicated to teaching a specialised stream of education. One type of education was known as “Instruction of Wisdom.” Its syllabus consisted of lessons on morality and ethics. Other specialised educational streams included medicine for doctors and mathematics for construction work.\nAncient Egypt’s Education Curriculum\nA diverse range of subjects was taught in ancient Egyptian schools. The focus for younger students was usually confined to reading, writing, and basic mathematics. The range of topics expanded as students progressed through to system to include such subjects such as mathematics, history, geography, medicine, ethics, science, morality and music.\nAfter finishing their education, most students followed the professions of their fathers. However, it was also not unusual for students to choose a specialised educational path. Egypt’s higher education system was focused on producing skilled practitioners and also included the children of Egypt’s nobility and royal office holders.\nAt the age of 14, the children of lower and middle-class parents finished their formal education and began working as apprentices to their fathers. Typical occupations operating an apprentice system included farming, carpentry, stone masonry, leather and fabric dying, metal and leather working and jewellers. Craftsmen expected their sons to become apprentices to their trade. Upward mobility in ancient Egypt was rare.\nYoung girls remained in their households with their mothers. They were taught how to run a household, cooking, baking, child rearing and basic medical skills including the use of oils and herbs. Girls of higher social status were instructed on entertaining high-status visitors and overseeing household servants and slaves.\nSo, like the boys, girls were trained in skills that were deemed to be suitable for their social class and likely responsibilities. As career choices for women were severely restricted vocational apprenticeships were mostly limited to training as a baker, weaver, entertainer, or dancer.\nGirls of high birth sometimes received additional education. Depending on their father’s place in society, a high-born girl could be expected to assist with running the family business while the father was away. Noble-born women occasionally received additional formal education to enable them to read, write and cipher.\nA knowledge of the arts, history and politics, were features of their education as noble women needed to be sufficiently educated to make them an acceptable wife for an upper-class husband as well as being able to manage the family business.\nScribes as a Profession\nOne of the few career choices proving upward mobility in ancient Egypt was to successfully apprentice to a scribe. Girls were usually banned from becoming scribes, although exceptions existed.\nSurviving documents describe a few female doctors in ancient Egypt and those women received training as scribes to enable them to read medical texts and treatises.\nA scribe’s extended education included practising writing hundreds of hieroglyphs and symbols that made up the Egyptian language. Scribes practised writing on wood, pottery and stone to ensure their words were accurate and legible. Beatings were common punishment for substandard penmanship. Papyrus; it was scarce and expensive and wasn’t used for practice exercises.\nReligious education was taught with other subjects in ancient Egypt. Ancient Egyptians were polytheists. They worshipped many gods rather than one God. As all ancient Egyptians worshipped the same gods and goddesses, religious education was fairly uniform. Children were taught to honour and respect the gods from a young age and disrespect or disobedience resulted in harsh punishments.\nThe Prince’s School\nThe Prince’s School educated the sons of the king and the nobility or high officials. No girls were allowed to attend it. Promising young boys were also allowed to attend and this was considered a great honour. It was also one of the few ways for a pupil from the lower class to rise in society.\nYounger students received training in writing and maths. Older students received training in reading, writing, mathematics and history. Mathematics was based on a decimal system and included arithmetic, geometry, science, astronomy, music and medicine.\nAncient Egypt’s Concept Of Wisdom\nFor the ancient Egyptians wisdom came from obeying the natural laws that governed their day-to-day lives. Wisdom was gleaned from abiding by the concepts of truth, integrity and justice. Hence, Egyptian students were taught these concepts so they could attain true wisdom.\nPhilosophy was not seen as a separate educational stream in ancient Egypt. Philosophy was taught in conjunction with moral and religious instruction. All students were expected to both understand and practice philosophical concepts.\nReflecting on the Past\nAncient Egypt’s rich cultural and religious life was based on an education system that while delivering a broad syllabus to its male students was primarily designed to perpetuate its conservative and inelastic social structure.\nHeader image courtesy: via maxpixel']"	['<urn:uuid:020ec36a-ab33-4a98-a9f3-07aa1c6f7f41>', '<urn:uuid:c8750ff8-517d-427f-af3c-34a49514173f>']	open-ended	direct	concise-and-natural	distant-from-document	comparison	expert	2025-05-01T23:21:14.341336	11	76	2009
345	wanted expert opinion ancient egyptian musicians temple performances status levels	Professional musicians in ancient Egypt were divided by social levels that determined where they could perform. Higher status musicians were allowed to play at religious ceremonies in temples, while lower class musicians could only perform for regular community members. The highest status was 'shemayet', mostly held by women, which allowed them to play for specific gods or goddesses.	"['Music has been an integral part of Egyptian culture since antiquity. The Bible documents the instruments played by the ancient Hebrews, all of which are correlated in Egyptian archaeology. Egyptian music probably had a significant impact on the development of ancient Greek music, and via the Greeks was important to early European music well into the Middle Ages. The modern music of Egypt is considered Arabic music as it has been a source for or influence on other regional styles. The tonal structure of Arabic music is defined by the maqamat, loosely similar to Western modes, while the rhythm of Arabic music is governed by the iqa\'at, standard rhythmic modes formed by combinations of accented and unaccented beats and rests.e your paragraph here.\nMusic was as important to the ancient Egyptians as it is in our modern society. Although it is thought\nthat music played a role throughout the history of Egypt, those that study the Egyptian writings have\ndiscovered that music seemed to become more important in what is called the ‘pharaonic’ period of\ntheir history. This was the time when the Egyptian dynasties of the pharaohs were\nestablished (around 3100 BCE) and music was found in many parts of every day Egyptian life.\nAncient Egyptians had a number of professional musicians that performed for many occasions.\nSince their society was set up with social levels, this meant that different musicians could play only\nfor specific events. A musician with a high status could play for religious ceremonies at the temples,\nwhere a lower class musician might only be able to play for regular community members.\nThe highest honor to achieve was the status of ‘shemayet’, which gave these musicians the\nability to play for a particular god or goddess and these musicians were mostly women.\nThe ancient Egyptians were very organized and this included how they organized and arranged music\nand musicians. They brought music to their religious ceremonies, but it was also played and\nperformed in workshops, palaces, the farms, on the battlefield and even in their tombs.\nThe Egyptian gods Hathor and Bes were their gods of music and they had many ceremonies\ndevoted to them that involved song and dance to accompany the playing of musical instruments\nThe ancient Egyptians credited the goddess Bat with the invention of music. The cult of Bat was eventually syncretised into that of Hathor because both were depicted as cows. Hathor\'s music was believed to have been used by Osiris as part of his effort to civilize the world. The lion-goddess Bastet was also considered a goddess of music.\nIn prehistoric Egypt, music and chanting were commonly used in magic and rituals. Rhythms during this time were ovular and music served to create rhythm. Small shells were used as whistles.(pp26–30)\nDuring the predynastic period of Egyptian history, funerary chants continued to play an important role in Egyptian religion and were accompanied by clappers or a flute. Despite the lack of physical evidence in some cases, Egyptologists theorize that the development of certain instruments known of the Old Kingdom period, such as the end-blown flute, took place during this time.(pp33–34)\nThe evidence is for instruments played more securely attested in the Old Kingdom when harps, flutes and double clarinets were played. Percussion instruments and lutes were added to orchestras by the Middle Kingdom. Cymbals frequently accompanied music and dance, much as they still do in Egypt today.\nTypically ancient Egyptian music was composed from the phrygian dominant scale, phrygian scale, double harmonic scale (Arabic scale) or lydian scale. The phrygian dominant scale may often feature an altered note or two in parts to create tension. For instance the music could typically be in the key of E phrygian dominant using the notes E, F, G sharp, A, B, C, D and then have an A sharp, B, A sharp, G natural and E to create tension.\nArabic music is usually said to have begun in the 7th century in Syria during the Umayyad dynasty. Early Arabic music was influenced by Byzantine, Indian and Persian forms, which were themselves heavily influenced by earlier Greek, Semitic, and ancient Egyptian music.\nEgyptians in Medieval Cairo believed that music exercised ""too powerful an effect upon the passions, and leading men into gaiety, dissipation and vice."" However, Egyptians generally were very fond of music. Though, according to E.W. Lane, no ""man of sense"" would ever become a musician, music was a key part of society. Tradesmen of every occupation used music during work and schools taught the Quran by chanting.(p359)\nThe music of Medieval Egypt was derived from Greek, Persian and Indian traditions. Lane said that ""the most remarkable peculiarity of the Arab system of music is the division of tones into thirds,"" although today Western musicologists prefer to say that Arabic music\'s tones are divided into quarters. The songs of this period were similar in sound and simple, within a small range of tones. Egyptian song, though simple in form, is embellished by the singer. Distinct enunciation and a quavering voice are also characteristics of Egyptian singing.(pp360–361)\nMale professional musicians during this period were called Alateeyeh (plural), or Alatee (singular), which means ""a player upon an instrument"". However, this name applies to both vocalists as well as instrumentalists. This position was considered disreputable and lowly. However, musicians found work singing or playing at parties to entertain the company. They generally made three shillings a night, but earned more by the guests giving more.\nFemale professional musicians were called Awalim (pl) or Al’meh, which means a learned female. These singers were often hired on the occasion of a celebration in the harem of a wealthy person. They were not with the harem, but in an elevated room that was concealed by a screen so as not to be seen by either the harem or the master of the house. The female Awalim were more highly paid than male performers and more highly regarded than the Alateeyeh as well. Lane relates an instance of a female performer who so enraptured her audience that she earned to fifty guineas for one night\'s performance from the guests and host, who were not considered wealthy.\nModern Egyptian classical and pop music\nEgyptian music began to be recorded in the 1910s, when Egypt was still part of the Ottoman Empire. The cosmopolitan Ottomans encouraged the development of the arts, encouraging women and minorities to develop their musical abilities. By the fall of the Empire, Egypt\'s classical musical tradition was already thriving, centered on the city of Cairo. In general, modern Egyptian music blends its indigenous traditions with Turkish, Arabic, and Western elements.\nSince the end of World War I, some of the Middle East\'s biggest musical stars have been Egyptian. Contemporary Egyptian music traces its beginnings to the creative work of luminaries such as Abdu-l Hamuli, Almaz and Mahmud Osman, who were all patronized by the Ottoman Khedive Ismail, and who influenced the later work of the 20th century\'s most important Egyptian composers: Sayed Darwish, Umm Kulthum, Mohammed Abdel Wahab, Abdel Halim Hafez, and Zakariyya Ahmad. Most of these stars, including Umm Kulthum and Najat Al Saghira, were part of the classical\nReligious music in Egypt\nReligious music remains an essential part of traditional Muslim and Coptic celebrations called mulids. Mulids are held in Egypt to celebrate the saint of a particular church. Muslimmulids are related to the Sufi zikr ritual. The Egyptian flute, called the ney, is commonly played at mulids. The liturgical music of the Alexandrian Rite also constitutes an important element of Egyptian music and is said to have preserved many features of ancient Egyptian music.\nLute and double pipe players from a painting found in the Theban tomb of Nebamun, a nobleman of the 18th Dynasty of the New Kingdom, c. 1350 BC\nEgyptian folk music, including the traditional Sufi dhikr rituals, are the closest contemporary music genre to ancient Egyptian music, having preserved many of its features, rhythms and instruments.\nFolk and roots revival\nThe Egyptians even used their own teeth as instruments they would make tapping noises and would use special plucks to make interesting noises with their teeth. The 20th century has seen Cairo become associated with a roots revival. Musicians from across Egypt are keeping folk traditions alive, such as those of rural Egyptians (fellahin), the Nubians, the Arabs, the Berbers, the Gypsiesand the Bedouins. Mixtures of folk and pop have also risen from the Cairo hit factory.\nSince the Nasser era, Egyptian pop music has become increasingly important in Egyptian culture, particularly among the large youth population of Egypt. Egyptian folk music continues to be played during weddings and other traditional festivities. In the last quarter of the 20th century, Egyptian music was a way to communicate social and class issues. Among some of the most popular Egyptian pop singers today are Mohamed Mounir and Amr Diab.\nSawahli (coastal) music is a type of popular music from the northern coast, and is based around the simsimiyya, an indigenous stringed instrument. Well-known singers include Abdo\'l Iskandrani and Aid el-Gannirni.\nSaidi (Upper Egyptian)\nEgyptian musicians from Upper Egypt play a form of folk music called Ṣa‘īdi (Upper Egyptian). Metqal Qenawi\'s Les Musiciens du Nil are the most popular saidi group, and were chosen by the government to represent Egyptian folk music abroad. Other performers include Shoukoukou, Ahmad Ismail, Omar Gharzawi, Sohar Magdy and Ahmed Mougahid.\nNubians are native to the south of Egypt and northern Sudan, though many live in Cairo and other cities. Nubian folk music can still be heard, but migration and intercultural contact with Egyptian and other musical genres have produced new innovations. Ali Hassan Kuban\'s efforts had made him a regular on the world music scene, while Mohamed Mounir\'s social criticism and sophisticated pop have made him a star among Nubians, Egyptians, and other people worldwide. Ahmed Mounib, Mohamed Mounir\'s mentor, was by far the most notable Nubian singer to hit the Egyptian music scene, singing in both Egyptian Arabic his native Nobiin. Hamza El Din is another popular Nubian artist, well-known on the world music scene and has collaborated with the Kronos Quartet.\nWestern classical music\nWestern classical music was introduced to Egypt, and, in the middle of the 18th century, instruments such as the piano and violin were gradually adopted by Egyptians. Opera also became increasingly popular during the 18th century, and Giuseppe Verdi\'s Egyptian-themed Aida was premiered in Cairo on December 24, 1871.\nBy the early 20th century, the first generation of Egyptian composers, including Yusef Greiss, Abu Bakr Khairat, and Hasan Rashid, began writing for Western instruments. The second generation of Egyptian composers included notable artists such as Gamal Abdelrahim. Representative composers of the third generation are Ahmed El-Saedi and Rageh Daoud. In the early 21st century, even fourth generation composers such as Mohamed Abdelwahab Abdelfattah (of the Cairo Conservatory) have gained international attention.\nAncient Egyptians Music']"	['<urn:uuid:865ceb5b-33d9-4021-ae3d-e88a53e20ffb>']	factoid	with-premise	long-search-query	distant-from-document	single-doc	expert	2025-05-01T23:21:14.341336	10	58	1812
347	who were first people interviewed monthly newsletter eso 2019	The 2019 interview series began with Alastair Webb from the University of Oxford, UK, followed by Anita Arsovska from the University Ss Cyril and Methodius, Skopje, Republic of North Macedonia.	['Each month, the PR Committee interviews an ESO Fellow (FESO) to feature in the newsletter.\nTo qualify as an FESO, members must demonstrate scientific quality and a willingness to actively volunteer in ESO. There are no age requirements, but FESO must meet minimum standards. FESO receive additional benefits, including participation in the Council of Fellows. Visit our website for more information on how to distinguish yourself as a FESO.\nWe hope you will enjoy getting to know the Fellows who participate in the 2019 interview series and thank them in advance for taking the time to share with our readers. The series began with Alastair Webb, University of Oxford, UK, next we interviewed Anita Arsovska, University Ss Cyril and Methodius, Skopje, Republic of North Macedonia.\nThis month, we present Francesco Corea, Stroke and Neurology Units, Ospedale San Giovanni Battista Foligno, Italy. He is an active FESO, Chair of the ESO Social Media Committee and a member of the Telestroke Committee.\nWhat are your main fields of interest in stroke medicine and research?\nMy interest on Stroke started in the late 90s during Medical School. Initially, the main work was in the acute phase. I had the privilege to be involved in pivotal RCTs from Ancrod to Alteplase. This brought me from initial deep frustration to the final exciting success. Later once Stroke Units became the standard of care I found new challenges in the rehab field. I was always interested in innovative technologies from diagnostics to therapy. Internet and telemedicine where promising tools for Stroke doctors in the 2000s. Many were still skeptical that either could become a high-profile medical subject. Now working with e-health is more and more a reality.\nWhat is the role of ESO in facilitating and promoting the projects you are coordinating or where you are involved?\nThe working market in Europe changed dramatically in the last decade.The shortage of physicians with specific profiles lead to the emergence of a new generation of dynamic Stroke doctors. The chance of being involved in ESO was thereby crucial in my career.\nThe place for Stroke professionals to share practice standards and update their competence is ESO (Summer/Winter Schools, main ESOC). In ESO, I found the right contacts to develop an efficient regional Telestroke network. This would have been impossible otherwise. The ESO international panel of experts on Telestroke succeeded to produce a unique recommendation paper on the topic (1). This lead to encourage the standardization in the field at continental and national levels.\nRecently ESO members joined their efforts in the Social Media committee. What role do social media play in Stroke medicine? We have tried to understand the drivers of interest on the web with an Infodemiology analysis. What are the effects of global Stroke campaigns on internet public ? (look for our presentation in Milan ESOC19). Where else it would be possible other than in ESO ?\n(1) Hubert, Gordian J, Gustavo Santo, Geert Vanhooren, Bojana Zvan, Silvia Tur Campos, Andrey Alasheev, Sònia Abilleira, and Francesco Corea. “Recommendations on Telestroke in Europe.” European Stroke Journal, (October 2018). doi:10.1177/2396987318806718.\nWhat do you expect from ESO in the future to support research?\nThe best strategy to find resources for stroke is to invest in a renewed care pact. To gain the attention not only of traditional mass media but also of the web public. The access to stroke care and research funding is not homogeneous in large areas of Europe. Further efforts must be made for a renewed alliance between health care professionals and citizens. This will empower the community that supports the fight against stroke in Europe.\nWhat do you think a mentor should do to support the projects and the career of a mentee and, conversely, what should a mentee expect from a mentor?\nLong time ago I participated in a consensus (2) suggesting a model for harmonizing Stroke training in Europe. The topic of mentoring and environment was central. Seen the wide curricula needed for Stroke experts (e.g.: from diagnostics, to acute phase and rehabilitation) the team-work model was the main solution guaranteeing results. We wrote: “Whatever the main background the most important aim is to ensure that the stroke trainee is competent in practicing Stroke medicine and that he or she can function effectively as a Stroke specialist leading a hospital stroke team”. As a mentee generally I expected to receive solid knowledge, as a mentor I encourage to build organizational skills to develop an effective leader.\n(2) Corea F, Gunther A, Kwan J, Petzold A, Debette S et Al. Educational approach on stroke training in Europe. Clin Exp Hypertens. 2006 Apr-May;28(3-4):433-7']	['<urn:uuid:399ad0e8-0da4-486f-9971-efc3c0b44930>']	factoid	direct	long-search-query	distant-from-document	single-doc	novice	2025-05-01T23:21:14.341336	9	30	768
349	multiple sports games single day safe teenager playing basketball	Multiple-games-in-a-day events are less common beyond youth level because they take a toll on athletes' bodies and increase injury risk when playing in a fatigued state. However, the slower pace of most youth sports allows young athletes to better withstand two or even three games in a day, though they should still take proper recovery measures between games.	['Recovery During Sports Tournaments\nDay and weekend-long tournaments are a staple of modern youth sport, especially in soccer, lacrosse, baseball, and basketball.\nBut there’s a reason these multiple-games-in-a-day events aren’t common beyond the youth level: they take a toll on athletes’ bodies, and the more an athlete plays in a fatigued state the more vulnerable they are to injury.\nThankfully, the slower pace of most youth sports allows athletes to better withstand two or even three games in a day. Even still, there are many physical and food-related measures athletes can take in between games to increase their recovery during sports tournaments and reduce the risk of injury.\nMuscle and Mobility Maintenance\nThere’s a fair amount of overlap between recovering the body from the last game and preparing for the next one. This is especially true for tournaments where the window between events is small.\nWhile a good coach should walk athletes through a team cool down, there are also exercises athletes can do in their hotel room or back at home to help better recover for the next game:\n• Lacrosse ball massage: Take a lacrosse ball (can be purchased at most sporting goods aisles for cheap—a tennis ball can work too), put it on the ground, and rub a foot on top of it while applying pressure. This loosens the tendons, ligaments, and muscles within the feet and ankles. The same ball can also be used to loosen up the shoulders, back, glutes, hips, forearms, and other muscles.\n• Lunge and reach: Loosen up the core by stepping out into a forward lunge (bent front leg, straight back leg). Place the palm opposite the front leg (e.g., left leg forward, right palm) on the ground and raise the other palm toward the ceiling and look up. Hold for a few seconds, then alternate sides.\n• Hamstring stretch: Help your athlete loosen tight hamstrings by having them lay on their back with legs flat against the ground. Wrap a towel folded longways, elastic band, or similar around the arch of one of their feet. With legs remaining as straight as possible, have them raise the banded leg toward the ceiling while applying resistance with the band, also flexing the ankle so their toes are pointed at their face. Hold for 10-15 seconds, then switch legs.\nEating to Refuel\nIt’s best to prepare food for athletes specifically to help their recovery during sports tournaments and fuel up for their next game. This increases the importance of packing a smart tournament cooler in case there isn’t enough time in between events for a real meal or the venue’s choices aren’t the healthiest.\nNo matter if you are packing a cooler, eating the food provided by organizers, or have time to eat at a nearby restaurant, keep the following CHEF guidelines in mind (and try to encourage your athletes to do the same):\n• Carbs: While fats do many important tasks in our body, they digest slowly and do not convert quickly into energy. When eating to recover from the last game and prepare for the next one, focus instead on carbohydrates and some protein.\nWhen there is even less time in-between games, try and stick to simple carbs like the ones in fruit, as opposed to heavier ones like in whole grain breads and pastas.\n• Hydrate: Athletes should always increase their fluids in the days leading up to a tournament (especially outdoor summer ones), but their intake also needs to remain steady during and in-between games.\nFor especially-demanding tournaments, beverages like sports drinks and coconut water can help both hydrate and replenish lost carbohydrates and electrolytes.\n• Eat Early: The importance of a hearty breakfast that keeps in mind the above recommendations can’t be understated.\nIf your athlete’s first game or event for the day is early and eating four hours before game time isn’t possible, try and have a big meal the night before followed by a lighter, carb-heavy meal the following morning.\n• Familiar: As tempting as that local favorite in a new city might be, in between games is not the time for an athlete to experiment with eating new foods.\nInstead, stick with what you know works for your athlete and that they like. The adventurous eating can then be a nice treat for playing hard after the games are over.\nFinally, the time between games and events is for mental recovery, too. Letting your athletes have some down time with friends or by themselves will allow them to play their best again when it comes time to re-focus.']	['<urn:uuid:dc461a5f-cdb7-4be1-9c6a-2907fd487bd7>']	factoid	with-premise	long-search-query	distant-from-document	single-doc	novice	2025-05-01T23:21:14.341336	9	58	763
356	traditional fishing methods impact marine ecosystem dungeness bay research	In Dungeness Bay, traditional crabbing methods range from using baited traps from boats to the simpler 'Poor Man's Crabbing' technique with pitchforks during low tide. These activities take place in seagrass meadows, which scientists consider as important as tropical rainforests in terms of biodiversity. Research shows that these underwater grasslands are affected by multiple factors, including fishing pressure and water quality changes. Scientists are conducting extensive monitoring and experiments across different locations to understand how human activities, including fishing, impact these ecosystems. The health of seagrass beds is crucial as they provide essential services like stabilizing sediments, protecting shorelines, and serving as nurseries for commercial and recreational fisheries, including the crab population.	['By Bret Wirta-The Incidental Explorer\nDistance: A couple of miles or so\nTime out: Half Day\nDegree of Difficulty: Pretty Darn Easy\nJuly 14th 2011\nCatching a crab\nI was skeptical when my friend Dave invited me to go “Poor Man’s Crabbing,” specifically because he said all I needed was a pitchfork to catch all the Dungeness Crab I could eat for lunch. I’ve been crabbing enough to know how it works. You find a friend with a boat or with an expensive beachfront home with a pier on Puget Sound. You bait the crab trap with chicken and throw it into the water. After a tide change you pull up your trap and if you’re lucky you’ll have a “keeper” or two. The night I proposed to my wife we were eating crab over a campfire on Orcas Island caught using this time-honored method. Plus I’m a big fan of TV’s “Deadliest Catch” where the crew baits crab pots the size of small cars. But it’s all the same – nobody shows up with a pitchfork.\nAfter much insistence, I called Dave’s bluff and decided to see if we could really catch any Dungeness crab. I met him at Dungeness Bay. Lots of Dungeness’s, but the crab is named after the bay which is named after Dungeness Spit which was named by Captain George Vancouver in 1792 who said it looked like the Dungeness on the English Channel.\nI arrived at Dungeness Bay in the morning during an ultra-low tide. The clouds clung to the beach and the primeval smell of rotting and decaying sea life was strong. Sure enough, Dave handed me a pitchfork (with guards to blunt the tips) and we walked out a mile from shore. Dave’s theory of crab psychology goes like this; after the crabs mate some of the males, too spent to move (or they are smoking a cigarette), are left behind hiding in the knee-deep water and eel grass of a low tide. Sure enough, after about half an hour of walking about, we spotted the brownish-purple shell of a large Dungeness crab moving slowly across the sandy bottom.\nCleaning a crab\nThe technique of Poor Man’s Crabbing is to basically sneak up on the crab and lift it gently out of the water with your pitchfork before it can scurry away into the eel grass or sea lettuce and hide. The weather was calm and the surface of the water still, so it was easy to see the crab. Dave lifted up the first one and then held it against the tines of his pitch folk. He flipped over the pitchfork and checked if it was a male, if it was bigger than six and a quarter inches and had a hard shell. It was too small so Dave dropped it back into the bay. I spotted my first crab, a big guy that was a keeper. We carefully put him into the floating cage that was tied to Dave’s belt with a ten foot rope. We ended up with five more crab as we spent a few pleasant hours walking back and forth in the knee deep water. It was a quiet morning. There in limbo between the faint sounds of fishing boats far offshore and the sight of houses far away onshore, it was easy to imagine Native Americans or early pioneers walking alongside me catching their dinner too.\nThe tide was coming so we waded back to shore where Dave showed me how to clean our crabs. He laid the crab upside down on its shell and deftly severed it in two. He removed the shell, guts and gills and threw the rest into a pot of boiling water. In a few minutes we were feasting on sweet crab. It was all so enjoyable and inexpensive. I attended college at the University of New Hampshire on the East Coast. Back there, catching yourself a lobster dinner is called poaching and it costs you a hefty fine if the police grab you or your arm if a commercial lobsterman does.\nHere in Washington State, in addition to a pitchfork, you’ll need a crabbing license. Make sure you are familiar with all the Washington Department of Fish and Wildlife crabbing regulations before you go. Dave says that you don’t catch Dungeness crab every day, but since there is parking right across from the 3 Crabs Restaurant, which has been serving Dungeness Bay seafood for over a generation, it would be next to impossible to leave without a succulent crab feast one way or another.\nTo get to the parking lot on Dungeness Bay from the Holiday Inn Express or the Quality Inn and Suites in Sequim\n- From Washington Street in downtown Sequim turn north on Sequim Avenue\n- Drive north for six miles – Sequim Avenue Turns into Sequim-Dungeness Way\n- Follow the signs for the 3 Crabs Restaurant until you reach Dungeness Bay\n- Park on the left side, not in the restaurant parking lot. Walk straight out, not to the left into the bird sanctuary\nThe thumbnail images below can be viewed as a slide show, just click on an image to start slideshow. Click or tap on the right or left side of the image to view the next or previous image. Click or tap outside the slideshow image and the slideshow will close.\nTo “Pin” an image, click the “Pin It” button and select image from list.', 'Underwater Meadows and Resilient Seas\nSmithsonian scientists work to solve how water quality, fishing pressure, and herbivore grazing determine the future of underwater grasslands.\nIf not for the flash of an octopus as it propels through the water or the swish of sediment as a manatee lumbers through an expanse of emerald green fronds, seagrass meadows might be mistaken for a lush and unruly lawn, maybe even the tall grasses of a mountain meadow. To scientists, however, they are more like tropical rainforests. Home to an amazing diversity of life, seagrass beds are important indicators of the overall health of coastal ecosystems—and they can be just as sensitive as their terrestrial counterparts to changes in the environment.\nSeagrasses are angiosperms—plants that produce flowers and seeds—that have adapted to life in the sea. With long narrow blades, they grow in extensive meadows throughout the world’s shallow coastal regions, both temperate and tropical, providing important ecosystem services. Seagrasses help stabilize sediment, recycle nutrients, and protect our shorelines. They also serve as juvenile nurseries for fishes and shellfish, homes for endangered animals like manatees and sea turtles, and as habitats for commercial and recreational fisheries.\nBut these complex ecosystems are in danger, says Justin Campbell, a Smithsonian postdoctoral fellow who developed an interest in the effects of climate change on seagrasses during his graduate work at Florida International University in Miami. “In addition to climate change, there are a number of local and regional factors harming seagrasses, such as shifts in water quality, overfishing, and shoreline modification. We need rigorous, powerful experimentation to begin to understand how these stressors interact and ultimately influence seagrass beds.”\nA network of experiments to understand seagrass ecology\nAs a Smithsonian postdoctoral fellow, Dr. Campbell has continued his work with seagrasses by helping launch the Thalassia Experimental Network (TEN). A MarineGEO initiative, TEN has established monitoring and parallel experiments in beds of turtlegrass (Thalassia testudinum), the dominant seagrass found throughout south Florida and the Caribbean. Based at the Smithsonian Marine Station (SMS) at Ft. Pierce, Florida, TEN is replicating these experiments at a Smithsonian field site in the Florida Keys as well as at the Smithsonian Tropical Research Institute (STRI) at Bocas del Toro, Panama, and the Smithsonian’s Caribbean Coral Reef Ecosystems Program (CCRE) at Carrie Bow Cay, Belize.\nThe goal of TEN is to understand vulnerability of seagrasses to nutrient pollution (eutrophication) and decline of grazing animals, and to investigate how those mechanisms vary among locations. This issue is important for coastal systems worldwide, where fertilizer and septic runoff are common contributors to altered ecosystems. Results from this project will provide scientists with a wealth of data on how human impacts affect vegetated near-shore ecosystems and, by extension, the species that depend on them for shelter and sustenance.\nJust like any other plant, seagrasses need sunlight to thrive and reproduce. Excess nutrients can increase the growth of algae, which cloud the water and overgrow the seagrasses, reducing the amount of sunlight reaching the plants. Although such algal blooms represent a major cause of seagrass decline around the world, the complex interactions among nutrients, plants, and grazers that influence them remain poorly understood.\nThe TEN experiments mimic these stressors, says Campbell, thus examining how seagrasses at different locations respond to nutrient loading and fishing pressure. Each site consists of 60 small field plots of turtlegrass in shallow waters that receive similar amounts of light. Half the patches are treated with the same amount of slow-release nutrient fertilizer. The other 30 seagrass plots are left untreated. These beds are being monitored over time to describe and compare the structure and functioning of the seagrasses within the plots. “We monitor various aspects of seagrass health, such as growth rates and shoot density,” says Campbell. “It is vitally important that we do exactly the same thing in exactly the same way across all four sites. That way we ensure that differential responses between sites are not due to distinctions in our experimental design or methods.” This standardization of methodology among sites is a key theme of MarineGEO, and TEN represents an important first set of coordinated experiments across the sites.\nFull analysis of the data gathered by the TEN experiment will start in fall 2014, but early findings are compelling. “What seems to be emerging initially is that nutrients influence vulnerability of seagrasses to grazing, but that there are differences in how seagrass beds respond,” says Campbell. Attention now is shifting to what parameters vary across geographic location that might explain these differences. The coordinated experiments thus open up a host of opportunities for further research.\nOther factors affecting seagrass beds\nCampbell and the other researchers are also interested in the role that larger herbivores such as turtles and urchins play in determining the health of tropical seagrasses. “These animals can consume substantial quantities of seagrass vegetation, and in some locations drastically change the structure of the seagrass bed,” Campbell explains. “While seagrasses are sensitive to ‘bottom-up’ influences of excessive nutrients in certain regions of the world, other areas may be increasingly influenced by changes in these herbivore populations.” The TEN experiment thus is also assessing changes in herbivory. Of the 60 plots at each site, half are grown in cages to exclude these herbivores, while the other half are left exposed.\nFinally, increased acidification of seawater is another factor impacting seagrass health. Oceanic CO2 levels have been increasing over the past 200 years, and the Smithsonian has recently begun to develop a baseline for measuring CO2 concentrations in their marine monitoring sites at SMS in Ft. Pierce, at SERC in Maryland, and at STRI’s Bocas del Toro facility in the Caribbean. These measurements are tracking variations in pH and acidity but—importantly—also assisting scientists to identify reasons for those variations.\nFor instance, monitoring has revealed extreme variability in pH at local levels. Campbell explains: “Just like terrestrial plants, seagrasses use CO2 during the day in order to produce carbohydrates, which are essentially their fuel. During the day CO2 levels decline, due to photosynthesis. At night they increase, due to respiration.”\nAnd while excess CO2 has proven generally to slow growth of coral reefs, Campbell’s research shows that certain seagrass beds actually thrive in waters with high acidity. Those studies could prove invaluable to understanding how certain marine ecosystems can resist, or even thrive under, increased levels of CO2.\nThe power of MarineGEO partnerships\nCampbell is excited to be part of research that meshes so closely with his own long-term goals. “I’m broadly interested in how coastal environments respond to environmental change. Many of these changes stem from human activity, and my research examines the ultimate consequences of our actions. Seagrass decline can result from multiple factors, thus we have a complex interplay of local and regional stressors such as eutrophication, and broader global stressors such as elevated temperatures and CO2 from climate change. My work aims to address these factors, both singly and combined, across a variety of spatial and temporal scales.”\nTracking and understanding these causes and effects is a rigorous and long-term challenge. “These systems are amazingly complex and comprised of a diverse array of organisms, and they all show slightly different responses. Which means, unfortunately, there is no general blanket statement that we can make regarding how a particular organism will respond to some sort of stress, whether nutrient enrichment, CO2, or even elevated temperature.”\nThe Smithsonian’s MarineGEO initiatives make it possible for the kind of in-depth, broadly based, long-term research necessary to understand this complexity—and the role human beings play in changing the coastal environments of which seagrass beds are such a vital part. “The work that we can do across the network is increasingly powerful,” says Campbell, “because now we can paint a picture of how these systems respond not only in one location but across larger geographic scales, such as across the Caribbean.”']	['<urn:uuid:83fb3ca3-b019-405d-8221-4415499a1404>', '<urn:uuid:68f0596e-5d5f-4f28-9a40-05b6600d33fd>']	open-ended	with-premise	long-search-query	distant-from-document	multi-aspect	novice	2025-05-01T23:46:40.222380	9	112	2220
357	food photography freezing motion techniques comparison	There are two main approaches to freezing motion in food photography. In the studio flash setup, the very short duration of the flash freezes motion like splashing liquid, using three lights at different power levels, with the shutter speed synchronized to the flash timing (typically 1/200s). For the overhead rig setup typically used in recipe videos, motion is controlled through lockoff shots at deeper apertures (f/5.6 or higher), relying on static positioning rather than freezing movement.	['It’s right in the middle of a filming day when the client springs it on you…“Can we film this from overhead? You know, like one of those Tasty recipe videos on Facebook?” The sort of question that would have been good to hear about two days ago when you were finalizing your grip order.\nNow, if you’ve got a studio dolly with an offset and riser (or a really solid short jib), you might be good to go. But if not, here’s a quick and dirty recipe for an overhead filming rig that a reasonably well-equipped grip truck likely has the parts for. And you can hack in replacement components if you’re missing anything.\nNote that this setup only works for lockoff shots. It’s a really good fit for simple top-down tabletop work, but would also work for narrative or anything else as long as the frames don’t need to be very wide, and you don’t need to operate the camera. With the right gear on hand, you can build this rig in 15 minutes or less. Here’s a rough list of the parts that you need:\n- 2x 8ft speedrail\n1x 2-4ft speedrail crossbar\n2x truss crossbars w/ junior pins (Dana Dolly end blocks also work well)\n1x cheese plate w/ locking ball head (add a QRP for simpler mounting)\n2x combo stands (add wheels for simpler adjustments and fine-tuning)\n2x 90-degree grid clamps\n2x flat-top grid clamps\n2x 3/8″ bolts\nTake a look at these rough overhead sketches. If your table is short, you could certainly span it on the x-axis. But after doing a few of these videos, I find that spanning with 8ft speedrail on the y-axis tends to work better. For one, that allows you to frame up a fairly wide shot, taking full advantage of a 16:9 aspect ratio without showing the legs of the stands. Combo stands allow you to quickly raise and lower the rig to make adjustments or change the framing, and they are rock-solid once locked down. And if you put the combos on wheels, you will find that this simplifies fine tuning the final frame. Here are a few rig pictures with a very simple camera setup, using an FS5 camera tethered to an Odyssey 7Q recorder.\nI like to hang the monitor on an arm close to the hand model so that they can see the frame for themselves. Most of the time, you can get away with locked-off focus on these types of shoots, as long as you can get an f/5.6 stop or deeper. The camera shown here is super lightweight, but you can easily support 30-40lbs without any issue on this rig. Just ensure you have a good solid cheeseplate w/ locking ballhead, the type you’ll often find in a basic car rigging kit. You’ll also want to make sure you have a remote trigger for the camera within reach, and some way of playing clips back without having to climb up on a ladder.\nOne last tip for these type of shoots: have a few white and black v-flats on hand. If you aren’t familiar, these are simple 4×8 foamcore panels taped together on the long edge to create a flexible hinge, so that you can stand them up in a v-shape. It’s a quick and easy way to fly in some bounce or negative as needed. Easy to make, and ridiculously handy on studio shoots! They’re big enough to affect lighting even when you position them away from the table (to allow crew access), and they’re easy to adjust simply by walking the vee around. You can see several of them in the background of these bts photos.\nIf you film enough of these overhead setups to buy the parts, here are the bits that I would purchase:\n2x 8ft Schedule 40 Speedrail Pipe\n1x 2ft Schedule 40 Speedrail Pipe\n2x Ladder Truss w/ Jr Pin for 1-1/4 pipe\n1x Ball Camera Leveling Mount w/ cheese base\n2x 90-degree Fixed Grid Clamps\n2x Grid Clamp w/ 3/8″ female thread\n2x 3/8 bolts from any hardware store\n2x combo stands with Jr receiver\n6x wheels for the combos\nSeason and adjust to taste. Hope this helps, happy shooting!', 'Home Photography Ideas: Make a splash with food and drink photography\nWatch Video: Home Photography Ideas – Add a twist to food photography\nIf you’ve run out of ideas to photograph during the current isolation period, we’ve got the remedy for what’s ailing you…a nice splash of your favorite drink for a still life with a difference!\n• Have more Home Photography Ideas\nStill life photography allows us to control every aspect of our image. We can arrange our props however we want and change the lighting to our liking, until we get the exact image we want. With the camera on a tripod, we can change compositions and shoot in low light if we want; with static shooting, shutter speed becomes irrelevant.\nHowever, we’ll show you how to add some expression to a still life by including a sense of movement in your scene. Our subject is a bottle of rose lemonade, and to add interest we’ll dress the scene with a glass of the fizzy drink, include a real rose and some lemons as the backdrop – frozen as they splash in a container of water.\n• See also Best camera for food photography\nWhile our camera is still locked securely in place on a tripod, timing becomes everything. As well as making sure we hit the shutter just when the falling lemons enter the frame, we need to freeze the moment to avoid unsightly subject blur – and we’ll achieve that with a set of studio lights.\nWe will also use other tricks. We want our lemonade to look ice cold and refreshing, with that look straight out of the fridge. However, the warm studio lights would quickly melt the ice cubes in our drink and evaporate any condensation forming on the bottle and glass, so we’re going to have to simulate things a bit…\n• The best food photography books\n01 Prepare your frame\nYou will need two bottles of your chosen drink. It’s best to choose stylish ’boutique’ bottles, rather than something from the supermarket’s ‘economy’ range. Coat the label of one of them with clear varnish so that it remains waterproof when the water droplets are applied. Then pour some of the fizzy drink from the second bottle into a clean glass tumbler until it’s half full, and place them on a reflective surface.\n02 Dressing the scene\nWe positioned a rose between the bottle and the glass, in front of a tank full of water. Fill the tumbler with acrylic ice cubes – real ice will melt too quickly. Next, mix a combination of water and glycerin in a ratio of about 2:1 and spray on the bottle and glass tumbler to make them look refreshing and cool.\n03 Camera settings\nSet the shutter speed to the flash timing determined by your camera body – in this case we’re shooting at 1/200s. Set an aperture of f/11 to give great depth of field and your lowest possible ISO for maximum image quality. Focus on the bottle, then switch to manual focus to lock it in place and turn off the lights. A test shot should produce a very underexposed dark frame.\n04 Let there be light\nIn this project, we use three Profoto studio lights – an inset, a fill and a backlight – all set to different output powers to illuminate our scene in a subtly balanced way. (You can also use speed lights to get the same results, though you’ll need to pump the power since strobes are less powerful.) Position the light key to the right of the setup; the filler on the left and the third light behind the tank, with a translucent diffuser in between to soften the lighting in the background.\n05 Power to the Lights\nAfter lighting our scene, the very short duration of the flash will freeze the lemons as they splash into the tank behind. It is the variable power of the key and the filling that gives shape to our bottle and our accessories. The back light diffuses through the liquid in the bottle and the glass, highlighting the drink. Take a test shot and adjust the power of the lights until you have a balanced setup. We had the key at three-quarter power (7.5), half-fill (5), and backlight at full (10), creating soft, even light through the dual diffuser we used.\n06 Dive in\nAsk your assistant to drop the lemons into the reservoir on the count of three and estimate when to release the shutter. It will take a few tries to get the job done, so use a squeegee to clean the front and back of the water tank from spills, ready for the next shot. If you’re shooting tethered, you’ll be able to better inspect details on your computer screen.\n147 photography tips, video tutorials and techniques for taking photos of anything\nWhat is the exposure triangle?\nWhat is the aperture on a camera?\nWhat is depth of field in photography?']	['<urn:uuid:c5ff52f4-d34a-4f47-bb40-f00b6f9913a1>', '<urn:uuid:7bade0af-debb-48cf-a577-466862782290>']	open-ended	direct	short-search-query	distant-from-document	comparison	expert	2025-05-01T23:46:40.222380	6	76	1536
358	Which approach emphasizes support resources more - ABA or online education?	ABA provides more intensive support resources. While online learning offers discussion boards, virtual office hours, live chat and tutoring services, ABA therapy provides comprehensive support through board-certified behavior analysts, trained therapists, parent/teacher training, and continuous one-on-one professional guidance. ABA's support system involves direct oversight and customized treatment plans, making it more resource-intensive than online education's largely self-directed support options.	"['Online learning has become increasingly popular in recent years, offering students the flexibility to study anywhere, anytime. It can be an ideal way to learn if you are working full-time, have a busy family life, or are geographically distant from a school. However, succeeding in an online learning environment requires a certain level of commitment, organization, and discipline. We will discuss some tips for online students to help them succeed in their online learning endeavors.\nBenefits of Online Learning\nOnline learning offers a number of advantages, such as flexibility and convenience. You can study at any time of the day or night, and you don’t have to travel to a physical campus or attend classes in person. This gives you the freedom to learn while also managing other commitments. Additionally, online learning offers access to a broader range of courses and instructors than might be available at a physical campus.\nDeveloping an Effective Online Learning Schedule\nOne of the key ingredients to success in online learning is creating an effective schedule. This requires commitment and discipline. To create an effective schedule, start by creating a list of all your course requirements. This should include assigned readings, lectures, assignments, and exams. Then, create a timeline for completing each of these tasks. The timeline should also include time for breaks, social events, and other activities. You should also plan out when you will devote time to studying, as this is essential for success in online learning.\nStrategies for Maintaining Engagement and Motivation\nLearning online can be challenging, and it can be easy to get discouraged. It’s important to stay motivated and engaged in your online coursework. One way to do this is to connect with other students in the course. This can be done in person, through social media, or via online discussion boards. Additionally, setting goals and rewards for yourself can be a great way to stay motivated.\nTips for Staying Organized and Keeping up with Assignments\nStaying organized and on top of your assignments is essential in online learning. Developing a system for keeping track of due dates, assignments, and other course materials can help you stay on track. Consider creating a spreadsheet or digital calendar to help you keep track of deadlines and assignments. Additionally, setting reminders for yourself can be helpful.\nUtilizing Support Resources\nOne of the great benefits of online learning is the availability of support resources. Many online courses feature discussion boards, virtual office hours, or even live chat features. Utilizing these resources can help you stay on track and get the most out of your online learning experience. Additionally, many online learning platforms offer tutoring services, which can be a great way to get extra help with difficult topics.\nEssential Habits for Success\nSuccess in online learning requires more than just good organization and scheduling. Developing good habits is essential for success. This includes habits such as studying regularly, attending online classes and discussion boards, and seeking help when needed. Additionally, it’s important to practice self-care, such as getting enough sleep, eating well, and exercising regularly.\nOnline learning is an excellent way to pursue your education while managing other commitments. However, succeeding in an online learning environment requires commitment, discipline, and good habits. In this blog post, we discussed some tips for online students to help them succeed in their online learning endeavors. These tips include developing an effective online learning schedule, maintaining engagement and motivation, staying organized and keeping up with assignments, utilizing support resources, and developing essential habits for success. By following these tips, online students can maximize their success in their online learning endeavors.', 'What is Applied Behavior Analysis (ABA)?\nApplied Behavior Analysis (ABA) is the practice of applying the psychological principles of learning theory in a systematic way to alter behavior in humans or animals. The practice is used extensively in education, healthcare, animal training, and business management. It is particularly prominent in the treatment of Autism Spectrum Disorder (ASD), for which it is one of the only scientifically valid therapies available.\nHow It Works\nABA takes a research approach to therapy based on proven theories of learning and behavior. Therapists who use ABA understand how human behaviors are learned and how they can be changed over time. The therapist evaluates a client’s behavior and develops treatment plans to help improve the communication and behavior skills necessary for success in their personal and professional lives. ABA therapists can also provide training to parents and teachers. For the greatest results, ABA requires heavy monitoring and continuous evaluation. Therapists and other health professionals work within settings such as schools, homes, and community centers to evaluate and modify treatment as it progresses.\nWhat to Expect\nWhen working with an ABA therapist, you will:\nDetermine which behaviors require change\nSet goals and expected outcomes\nEstablish ways to measure changes and improvements\nEvaluate where you are now\nLearn new skills and/or learn how to avoid negative behaviors\nRegularly review your progress\nDecide whether or not further behavior modification is necessary\nHow does ABA therapy work?\nApplied Behavior Analysis involves many techniques for understanding and changing behavior. ABA is a flexible treatment:\nCan be adapted to meet the needs of each unique person\nProvided in many different locations – at home, at school, and in the community\nTeaches skills that are useful in everyday life\nCan involve one-to-one teaching or group instruction\nPositive reinforcement is one of the main strategies\nused in ABA.\nWhen a behavior is followed by something that is valued (a reward), a person is more likely to repeat that behavior. Over time, this encourages positive behavior change.\nFirst, the therapist identifies a goal behavior. Each time the person uses the behavior or skill successfully, they get a reward. The reward is meaningful to the individual –examples include praise, a toy or book, watching a video, access to playground or other location, and more. Positive rewards encourage the person to continue using the skill. Over time this leads to meaningful behavior change.\nAntecedent, Behavior, Consequence\nUnderstanding antecedents (what happens before a behavior occurs) and consequences (what happens after the behavior) is another important part of any ABA program.\nThe following three steps – the “A-B-Cs” – help us teach and understand behavior:\ntthis is what occurs right before the target behavior. It can be verbal, such as a command or request. It can also be physical, such a toy or object, or a light, sound, or something else in the environment. An antecedent may come from the environment, from another person, or be internal (such as a thought or feeling).\nA resulting behavior:\nthis is the person’s response or lack of response to the antecedent. It can be an action, a verbal response, or something else.\nthis is what comes directly after the behavior. It can include positive reinforcement of the desired behavior, or no reaction for incorrect/ inappropriate responses.\nLooking at A-B-Cs helps us understand:\nWhy a behavior may be happening\nHow different consequences could affect whether the behavior is likely to happen again\nThe teacher says “It’s time to clean up your toys” at the end of the day.\nThe student yells “no!”\nThe teacher removes the toys and says “Okay, toys are all done.”\nHow could ABA help the student learn a more appropriate behavior in this situation?\nThe teacher says “time to clean up” at the end of the day.\nThe student is reminded to ask, “Can I have 5 more minutes?”\nThe teacher says, “Of course you can have 5 more minutes!”\nWhat Does an ABA Program Involve?\nGood ABA programs for autism are not “one size fits all.” ABA should not be viewed as a canned set of drills. Rather, each program is written to meet the needs of the individual learner.\nThe goal of any ABA program is to help each person work on skills that will help them become more independent and successful in the short term as well as in the future.\nPlanning and Ongoing Assessment\nA qualified and trained behavior analyst (BCBA) designs and directly oversees the program. They customize the ABA program to each learner\'s skills, needs, interests, preferences and family situation.\nThe BCBA will start by doing a detailed assessment of each person’s skills and preferences. They will use this to write specific treatment goals. Family goals and preferences may be included, too.\nTreatment goals are written based on the age and ability level of the person with ASD. Goals can include many different skill areas, such as:\nCommunication and language\nSelf-care (such as showering and toileting)\nPlay and leisure\nPlay and leisure\nLearning and academic skills\nABA Techniques and Philosophy\nThe instructor uses a variety of ABA procedures. Some are directed by the instructor and others are directed by the person with autism.Parents, family members and caregivers receive training so they can support learning and skill practice throughout the day.\nThe person with autism will have many opportunities to learn and practice skills each day. This can happen in both planned and naturally occurring situations. For instance, someone learning to greet others by saying ""hello"" may get the chance to practice this skill in the classroom with their teacher (planned) and on the playground at recess (naturally occurring).\nThe learner receives an abundance of positive reinforcement for demonstrating useful skills and socially appropriate behaviors. The emphasis is on positive social interactions and enjoyable learning.\nThe learner receives no reinforcement for behaviors that pose harm or prevent learning.\nABA is effective for people of all ages. It can be used from early childhood through adulthood!\nWhat Can Children Learn Through ABA?\nMost of the time, ABA is intended to ""extinguish"" undesirable behaviors and teach desired behaviors and skills. For example, ABA may be used to reduce outbursts and tantrums or to teach a child to sit quietly, use words to make requests, or wait their turn in the playground. ABA can also be used to teach simple and complex skills. For example, ABA can be used to reward a child for brushing his teeth correctly, or for sharing a toy with a friend.\nWhile classic ABA can be used in a ""natural"" setting (a playground, for example), it is not intended to build emotional or social skills. So, for example, while ABA might teach a child to shake hands or greet another person with a handshake, it won\'t help that child to feel an emotional connection with another person. It takes an extraordinary therapist to use ABA to teach academic content, imaginative or symbolic thinking, or empathy; as a result, those skills are usually taught in other ways.\nWho provides ABA services?\nA board-certified behavior analyst (BCBA) provides ABA therapy services. To become a BCBA, the following is needed:\nEarn a master’s degree or PhD in psychology or behavior analysis\nPass a national certification exam\nSeek a state license to practice (in some states)\nWhat is the evidence that ABA works?\nABA is considered an evidence-based best practice treatment by the US Surgeon General and by the American Psychological Association. “Evidence based” means that ABA has passed scientific tests of its usefulness, quality, and effectiveness. ABA therapy includes many different techniques. All of these techniques focus on antecedents (what happens before a behavior occurs) and on consequences (what happens after the behavior).\nMore than 20 studies have established that intensive and long-term therapy using ABA principles improves outcomes for many but not all children with autism. “Intensive” and “long term” refer to .programs that provide 25 to 40 hours a week of therapy for 1 to 3 years. These studies show gains in intellectual functioning, language development, daily living skills and social functioning. Studies with adults, though fewer in number, show similar benefits.\nStudies that have shown positive progress with ABA\nChance a child will move into general curriculum classes after 2–3 years of intensive ABA therapy*\nDecades of proven results from ABA therapy\nIs ABA covered by insurance?\nSometimes. Many types of private health insurance are required to cover ABA services. This depends on what kind of insurance you have,and what state you live in.\nAll Medicaid plans must cover treatments that are medically necessary for children under the age of 21. If a doctor prescribes ABA and says it is medically necessary for your child, Medicaid must cover the cost.\nPlease see our insurance resources for more information about insurance and coverage for autism services.\nYou can also contact the Autism Response Team If you have difficulty obtaining coverage, or need additional help.\nIs it right for my child?\nOnly you can decide which therapy is right for your kiddo, and we recommend discussing the options with the pediatrician. ABA’s scope is broad, so to arm you with the proper knowledge and direction for that conversation, here are some areas where your child may benefit from it.\nABA Therapy is provided in the child’s own environment. It facilitates active family participation\nCommunity-based ABA Therapy\nABA Therapy is provided in the child’s daycare. It enables generalization of skills and peer interaction.\nABA in a Group Setting\nGives your child tools to improve social skills, emotional intelligence and self-confidence..\nCenter-based ABA Therapy\nABA Therapy is provided in a structured environment. It facilitates planned socialization with peers.']"	['<urn:uuid:4aaf59b2-b725-4928-b735-0717d5c2b84b>', '<urn:uuid:df306e36-ebd9-4193-bb1b-1eb680987de7>']	open-ended	direct	concise-and-natural	distant-from-document	comparison	expert	2025-05-01T23:46:40.222380	11	59	2204
360	I notice most circuit boards I see are green in color - I've always wondered why they chose this particular color for circuit boards?	Circuit boards are green due to the solder mask, which protects the copper circuits printed on the fibre glass core to prevent short circuits and soldering errors. The color of the solder mask is what gives the board its appearance.	['- Is PCB design hard?\n- Which software is used for circuit design?\n- Which software is used for electrical design?\n- Which PCB design software is the best for beginners?\n- What is PCB design software?\n- Is Eagle PCB free?\n- What is PCB and types of PCB?\n- What is full form of PCB?\n- What is the best free circuit simulator?\n- Which is the best circuit design software?\n- How do I start a PCB design?\n- Is Altium Designer free?\n- How do you become a professional PCB designer?\n- What is PCB diagram?\n- Why are PCB green?\nIs PCB design hard?\nOnce an electrical schematic is complete, the hard work is over.\nThe layout of a PCB from an electrical schematic seems like a simple two-step process: Place the required components and connect the wires/traces to the appropriate point on the components..\nWhich software is used for circuit design?\nWe share our top 46 PCB design software tools for electronics engineers here, in no particular order.PCB Artist. @AC4PCB. … Ultiboard. @NIglobal. … Altium Designer 17. @altium. … SOLIDWORKS PCB. @SOLIDWORKS. … DipTrace. @DipTrace. … PCBWeb. @PCBWeb. … BSch3V. … XCircuit.More items…\nWhich software is used for electrical design?\n10 Must Learn Electrical Engineering Software for EE Graduates. … MATLAB (Software for Numerical Computing) … Simulink (GUI based software for Dynamic System Simulation) … Pspice (Electrical Schematic Software) … Multisim (Circuit Simulation & PCB Design Software) … ETAP (An Electrical Engineering Software for Power Systems)More items…\nWhich PCB design software is the best for beginners?\nTop 10 Best PCB Design Software of 2020PROTEL (Altium Designer) … PADS (PowerPCB) … ORCAD. … Allegro. … Eagle（Easily Applicable Graphical Layout Editor） … Kicad. … EasyEda. … Fritzing.\nWhat is PCB design software?\nPCB is a free and open-source software suite for electronic design automation (EDA) – for printed circuit boards (PCB) layout. It uses GTK+ for its GUI widgets.\nIs Eagle PCB free?\nPCB design software for everyone. Included with a Fusion 360 for personal use subscription, EAGLE free download is a limited version for hobbyists including 2 schematic sheets, 2 signal layers, and an 80cm2 (12.4in2) board area.\nWhat is PCB and types of PCB?\nA printed circuit board (PCB) is a thin board made from fiberglass, composite epoxy, or other laminate materials. PCBs are found in various electrical and electronic components such as beepers, radios, radars, computer systems, etc. Different types of PCBs are used based on the applications.\nWhat is full form of PCB?\nA printed circuit board, or PCB, is used to mechanically support and electrically connect electronic components using conductive pathways, tracks or signal traces etched from copper sheets laminated onto a non-conductive substrate.\nWhat is the best free circuit simulator?\nBest Free electronics Circuit Simulation SoftwareCircuit Sims. It was one of the first open source web based circuit simulation software, It’s an excellent tool for both students and electronic enthusiasts. … DcAcLab. It has visual and attractive graphics, but limited circuit simulation software. … DoCircuits. … PartSim. … 123D Circuits. … TinaCloud.\nWhich is the best circuit design software?\nTop 7 PCB Design Software ToolsAltium Designer. Altium Designer is the most famous PCB design tool in the market. … PCB Artist by Advanced Circuits. Advanced Circuits is famous in the industry for its active customer base and best shipping record. … SOLIDWORKS PCB. … Ultiboard by National Instruments. … DipTrace. … XCircuit. … KiCad EDA.\nHow do I start a PCB design?\nPCB Design: How to Create a Printed Circuit Board From ScratchStep 1: Create Or Find A Circuit Diagram. Before you start drawing wires and stuff, you need to know what circuit you want to build. … Step 2: Draw Your Schematics. … Step 3: Design Your Board Layout. … Step 4: Get Your PCB Made. … Step 5: Order Components. … Step 6: PCB Assembly – Soldering the Components to the Board.\nIs Altium Designer free?\nA free community-driven PCB design tool. The streamlined user interface makes it easy to get started, and an industry leading design platform underneath helps bring your creative ideas to life.\nHow do you become a professional PCB designer?\nMany engineers are laying out their own PCBs today. Depending on the exact role that you are going to be applying for, you might need to have a BS degree in engineering or a related field. The courses that you will complete at university teach you everything from electronic design to drafting and CAD.\nWhat is PCB diagram?\nA PCB schematic is a simple two-dimensional circuit design showing the functionality and connectivity between different components. … Once the blueprint has been completed, the PCB design comes next. The design is the layout, or physical representation of the PCB schematic and includes the copper track and hole layout.\nWhy are PCB green?\nIt is due to the solder mask, which protects the copper circuits printed on the fibre glass core to prevent short circuits, soldering errors, etc. … The colour of the solder mask gives the board its appearance.']	['<urn:uuid:2d623838-7379-4895-b697-fc85016d0ed7>']	factoid	with-premise	verbose-and-natural	similar-to-document	single-doc	novice	2025-05-01T23:46:40.222380	24	40	844
361	what is used to study meaning of words that describe truth levels	Hedge algebras are algebraic structures used to interpret and model domains of linguistic variables, particularly for studying the structure of linguistic truth values.	['A theory of refinement structure of hedge algebras and its applications to fuzzy logic\nIn , an algebraic approach to the natural structure of domains of linguistic variables was introduced. In this approach, every linguistic domain can be interpreted as an algebraic structure called a hedge algebra. In this paper, a refinement structure of hedge algebras based on free distributive lattices generated by linguistic hedge operations will be examined in order to model structure of linguistic domains more properly. In solving this question, we restrict our consideration to the specific hedge algebras called PN-homogeneous hedge algebras. It is shown that any PN-homogeneous hedge algebra can be refined to a refined hedge algebra (RHA, for short) and every RHA with a chain of the primary generators is a distributive lattice. Especially, we shall examine RHAs with exactly two distinct generators, which will be called symmetrical RHAs. Furthermore, in the symmetrical RHAs of the linguistic truth variable, we are able to define negation and implication operation, which, according to their properties, may be interpreted as logical negation and implication in a kind of fuzzy logic called linguistic-valued logic. Some elementary properties of these operations will be also examined. This yields a possibility to construct a method in linguistic reasoning, which is based on linguistic-valued fuzzy logic corresponding to the symmetrical RHAs of the linguistic truth variable.\n-  G. Birkhoff, Lattice Theory (Providence, Rhode Island, 1973).\n-  S. Burris & H. P. Sankappanavar, A Course in Universal Algebras, (Springer-Verlag: New York-Heidelberg-Berlin, 1981).\n-  Z. Cao and A. Kandel, Applicability of some fuzzy implication operators, Fuzzy Sets and Systems 31(1989), 151-186.\n-  N. Cat Ho, Generalized Post algebras and their application to some infinitary many-valued logic, Dissertationes Math. 107 (1973) 1-76.\n-  N. Cat Ho, Fuzziness in structure of linguistic truth values: A foundation for development of fuzzy reasoning, Proc. of ISMVL 87, Boston, USA (IEEE Computer Society Press, New York),1987, 326-335.\n-  N. Cat Ho, Linguistic-valued logic and a deductive method in linguistic reasoning, Proc. of the Fifth IFSA 93, Seoul, Korea, July 4-9, 1993.\n-  N. Cat Ho, A method in linguistic reasoning on a knowledge base representing by sentences with linguistic belief degree, Fundamenta Informaticae Vol. 28(3,4) (1996), 247-259.\n-  N. Cat Ho & H. Rasiowa, Plain semi-Post algebras and their representability, Studia Logica 48(4) (1989), 509-530.\n-  N. Cat Ho & H. Van Nam, A refinement structure of hedge algebras, Proc. of the NCST of Vietnam, Vol. 9(1) (1997), 15-28.\n-  N. Cat Ho & H. Van Nam, Lattice character of the refinement structure of hedge algebras, J. of Comp. Sci. and Cyber., Vol. 12(1) (1996), 7-20.\n-  N. Cat Ho & H. Van Nam, Refinement of hedge algebras based on free distributive lattices generated by hedge operations, Research Report at Workshop on Information Technology: R & D, IOIT, 5-6 Dec. 1996, 156-182 (in Vietnamese).\n-  N. Cat Ho & H. Van Nam, Refinement structure of hedge algebras: An algebraic basis for a linguistic-valued fuzzy logic, Present at Inter. Conf. on Discrete Mathematics and Allied Topics, 10-13 Nov. 1997, India.\n-  N. Cat Ho & W. Wechler, Hedge algebras: An algebraic approach to structure of sets of linguistic truth values, Fuzzy Sets and Systems 35(1990), 281-293.\n-  N. Cat Ho & W. Wechler, Extended hedge algebras and their application to fuzzy logic, Fuzzy Sets and Systems 52(1992), 259-281.\n-  R. Giles, Łukasiewicz logic and fuzzy set theory, Inter. J. of Man-Machine stud. 8 (1976), 313-327.\n-  J. B. Kiszka, M. E. Kochańska and S. Śliwińska, The influence of some fuzzy implication operators on the accuracy of a fuzzy model-Part I, Fuzzy Sets and Systems 15(1983), 111-128.\n-  J. B. Kiszka, M. E. Kochańska and S. Śliwińska, The influence of some fuzzy implication operators on the accuracy of a fuzzy model-Part II, Fuzzy Sets and Systems 15(1983), 223-240.\n-  G. Lakoff, Hedges: A study in meaning criteria and the logic of fuzzy concepts, J. Philos. Logic 2 (1973) 458-508 (also presented at the 8th Regional Meeting of the Chicago Linguistic Society, 1972).\n-  M. Mizumoto and H.-J. Zimmermann, Comparison of fuzzy reasoning methods, Fuzzy Sets and Systems 8(1982), 253-283.\n-  H. Rasiowa, An Algebraic Approach to Non-classical Logic (North-Holland, Amsterdam-New York, 1974).\n-  H. Rasiowa & R. Sikorski, The Mathematics of Metamathematics, second edition (Polish Scientific Publ., Warszawa, 1968).\n-  D. B. Rinks, A heuristic approach to aggregate production scheduling using linguistic variables, Proc. of Inter. Congr. on Appl. Systems Research and Cybernetics, Vol. VI (1981) 2877-2883.\n-  R. Sikorski, Boolean Algebras, third edition, (Springer-Verlag, Berlin-Heidelberg-New York, 1969).\n-  H. J. Skala, On many-valued logics, fuzzy sets, fuzzy logics and their applications, Fuzzy Sets and Systems 1 (1978) 129-149.\n-  Y. Tsukamoto, An approach to fuzzy reasoning method, in M. M. Gupta, R. K. Ragade, R. R. Yager, Eds., Advances in Fuzzy Set Theory and Applications (North-Holland, Amsterdam, 1979) 137-149.\n-  L. A. Zadeh, Fuzzy-set-theoretic interpretation of linguistic hedges, J. of Cybernetics 2 (1972) 4-34.\n-  L. A. Zadeh, A theory of approximate reasoning, in: R. R. Yager, S. Ovchinnikov, R. M. Tong and H. T. Nguyen, Eds., Fuzzy Sets and Applications: The selected papers by L. A. Zadeh (Wiley, New York, 1987) 367-411.\n-  L. A. Zadeh, The concept of linguistic variable and its application to approximate reasoning Inform. Sci. (I) 8(1975) 199-249; (II) 8(1975) 310 -357; (III) 9(1975) 43-80.']	['<urn:uuid:ca5a38e5-25d1-4a25-a9a2-bd90dc5e8a17>']	factoid	direct	long-search-query	distant-from-document	single-doc	novice	2025-05-01T23:46:40.222380	12	23	890
368	blank canvas opera premiere location date	The Blank Canvas premiered at the King's Head Theatre in London on August 31st 2014	['Spyros Syrmos is an award – winning Composer based in Athens. His work include orchestral and chamber music, opera, film music, ballet, sound art installations and traditional music arrangements from south Italy.\nSpyros was born in Athens.\nHe studied guitar with Kostas Grigoreas at the National Conservatory of Athens and with John Mills and Eleftheria Kotzia at the Royal Welsh College of Music and Drama, where he gained the PGdip in performance.\nHe also had Lute lessons with Nikos Panagiotidis in Athens and Mathew Nisbet in Wales as a second study.\nHe continued studies in composition with Ioannis Metallinos in Athens and Peter Reynolds at the contemporary music departement of the Royal Welsh College of Music and Drama in Cardiff, where he gained the PGdip in Composition.\nOperatic Novices make their mark\nOPERA – “The Blank Canvas”\n“He won the “Flourish Opera competition 2013”.\nPremiered at the King’s Head Theatre in London in 31st August 2014.\nFILM MUSIC – “Bright”\nIn 2021 he completed the score for the film “Bright” directed by Samuel R. Gibson and produced by Electradome Pictures in the US.\nLondon Shorts Film Festival Nominee “Best Short Drama“\nBright will release November, 11th 2021 exclusively at Louisville’s International Festival of Film\n“Evocative and unsettling” The Guardian\nTRADITIONAL MUSIC FROM SOUTH ITALY\nAfter many years of studying the music of South Italy, under the motivation and supervision of his close friend Vangelis Haramis (Sociologist/musician/Universtita di Salerno) he has arranged a large number of traditional songs and music, giving them a “nowadays” perspective as well as he has composed several pieces inspired by this music. The group ANTIDOTUM TARANTULAE of which Spyros was a principal member, had performed often at festivals and music theaters in Greece.\nReviews – Interviews – Links\nSpyros Syrmos: Opera, the meeting point of all the arts\nRead Full Review ” operatic novices make their mark “\nΣπύρος Σύρμος, ο Ελληνας που έγραψε νέα όπερα για το Λονδίνο\nΣυνέντευξη στη Βασιλική Χρυσοστομίδου\nLIST OF WORKS\n3 Inventions (for piano solo)\nA Brawny Tree (for reed quintet)\nFast Forward (for string quartet)\nHabanera (for clarinet quartet)\nHabanera (for piano trio)\nTres La Lune… (for piano, violoncello and flute)\nThe Adventure of an Exhibit (for double bass, bassoon and violoncello)\nK.P.I.S.N. (for two violins and violoncello)\nMilonga para un Amante Uruguayo (for piano and flute)\nMid Winter’s Summerdream (for violonello and piano)\nHonoris Causa (for violoncello and piano)\nPersistent Galiard (for violoncello and harpsichord)\nSoneto de separacao (for voice and piano) Poetry by Vinicius de Moraes\nΒάο, Γάο, Δάο (for voice and piano) Poetry by Napoleon Lapathiotis\nTrilce (for voice and guitar) Poetry by Cesar Vallejo\nNight Flight – In the Time Zone\nThe Road from Colonus\nThe Blank Canvas (libretto by Fay Wrixon)\nBright (directed by Samuel R. Gibson)\nBallet Camouflage (for violoncello solo and electronics)\nWaving Trees (electroacoustic)\nBeyond Everything (electroacoustic)\n3 Διηγήματα (3 short stories, text by Vania Syrmou)\nAntidotum Tarantulae – Sed Nove (traditional music from south Italy)\n“Every so often you uncover a gem like this\nwhich may actually play a part in securing opera’ s future”\nTO CONTACT A&R REPRESENTATIVE\nGözde Sezgin (A&R Representative)\nNo 24 Sariyer st.\nIstanbul – Turkey\nPlease fill in the form below :\nTO CONTACT LEGAL AGENT\nMargarita Giannopoulou (Legal agent)\n6 Phidiou st.\nAthens – Greece\nPlease fill in the form below :\nTo contact Spyros\nPlease fill in the form below:']	['<urn:uuid:40f32cae-a449-4bb7-965d-f6405cf7c555>']	factoid	direct	short-search-query	similar-to-document	single-doc	novice	2025-05-01T23:46:40.222380	6	15	567
370	What's different between film storage past and present?	In the present day, films receive careful preservation and high-quality releases, exemplified by Criterion's treatment of 'Ride the Pink Horse' with comprehensive supplementary materials and Blu-ray quality. This contrasts sharply with historical practices where films, especially silents, were considered to have no commercial value and were frequently destroyed due to storage difficulties and fire hazards. For instance, many films were cut into pieces with chain saws and burned to salvage silver content, while others were lost to storage facility fires, such as those at Bekins Storage Company and Warner Brothers.	"['To sing the song of noir — it’s not as easy as it once was, when critics like Raymond Durgnat and Paul Schrader were busy cataloging and specimen-boxing the genre as if it were a breed of black butterfly that had long lived on our streets and escaped our notice. In terms of utilizing the genre ourselves, nowadays we’re somewhere near post-retro-neo-meta-noir; the original tropes are no longer recyclable even as TV commercials, and the Jim Thompson–rediscovery school has long been garnering yawns on the straight-to-video indie shelf. Sin City sequels — please.\nAptly, reverent video releases of noirs keep coming, and today we’re talking about Robert Montgomery’s magnificent cataract of dyspepsia Ride the Pink Horse (1947), out on Blu-ray from Criterion with all the typical whistles and supplementary fanfare the average Netflixer might be surprised to find attached to a 68-year-old crime drama starring an all but forgotten star.\nMontgomery had been acting since before the stock market crash, and would only continue for a few more years, and this is his second shot at directing. The first, 1944’s The Lady in the Lake, famously attempted Chandler using the camera as snoop Philip Marlowe’s p.o.v. (You only saw him in mirrors.) Presaging both the Islamic diktats of Mohammad: Messenger of God (1977) and a hundred handheld mock-doc horror films since, Montgomery’s experiment led clearly to Ride the Pink Horse, which while thankfully orthodox about point of view is a feast of complex traveling shots.\nThe first is a hypnotic doozy, roving around almost wordlessly as Montgomery’s testy, wary ex-G.I. in a suit gets off a bus in a small Mexican town, makes his way into the depot, hides something in a locker, buys gum, and then secretly wads the locker key with the gum behind a giant wall map. This hostile, inarticulate American, as eloquent a personification of WWII PTSD and moral desperation as any noir hero, is naturally in town to collect a debt from a malevolent gangster/war profiteer (Fred Clark), and it’s a slow burn, roping in Thomas Gomez’s avuncular carousel manager (in one timeless shot, a brutal beating is sporadically seen while the camera takes a revolving ride) and Wanda Hendrix’s puppy-like teen Mexicana as allies in the wasteland. Up against him are an irritable army of henchmen with knives, and a smooth-talking ice queen of a femme fatale (Andrea King).\nNoirs can be measured by how little weakness they exhibit when dealing out their bad-luck hands, and Montgomery’s movie (written by acid-tongue twins Ben Hecht and Charles Lederer) is a cynical, strong-spined sonofabitch, with one of the genre’s lowest sentiment dosages. The Criterion disc comes with the usual phalanx of audio commentaries, new interviews, radio-broadcast variations, and an indispensable essay by filmmaker Michael Almereyda.\nRampant misfortune practically monsoons in another overlooked film out on video, from First Run Features: Brillante Mendoza’s Captive (2012), a topical suspenser that, remarkably, pits Islamic terrorists against Isabelle Huppert. Released nearly everywhere but in the U.S., the Filipino movie dives into the weeds of the Dos Palmas kidnapping crisis of May 2001, in which armed members of Islamic separatist group Abu Sayyaf abducted twenty hostages from a tourist area (including Americans, Europeans, and Chinese) and dragged them into the jungle for over a year. As the Filipino army searches and assaults, the prisoners end up being either parceled out to the jihadis as wives or coming down with a grand case of Stockholm syndrome. Huppert, as a French social worker, is to our eyes the hot core of indignation and horror, but in truth Mendoza spreads the angst out across a varied cast, and makes us feel the time spent trudging aimlessly and waiting for international rescue that doesn’t come. There are actionful peaks — a battle against the army in and around a country hospital is hair-raising — but the film’s strategy doesn’t condense or dramatize for convenience’s sake; the ordeal is open-ended, maddening, sometimes dull, always open to ambivalence and disappointment. At the same time, Mendoza’s in-your-grille filmmaking keeps us lost in the jungle, and we can feel the fire ants and smell the rot.\nAn even blacker dream from the past, Juraj Herz’s The Cremator (1969) — found in the unpublicized corners of the Criterion detour on Hulu Plus — constitutes what might be the Czech New Wave’s most nihilistic vision. Chubby, comb-over monster Kopfrkingl (Rudolf Hrusinsky) is a crematorium pro on the eve of the Nazi rise, talking right to the camera about the glory and honor of his work, giving us tours of his facility and their guests, and selling the advantages of believing in reincarnation. (The possibility of premature cremations — a prepped woman “is very likely really dead” — keeps arising, ironically, given the history to come.)\nA tireless rationalizer, old-school family man, and ready-made Fascist, our hero eventually crosses the National Socialist party’s path, and in classic proto-Conformist style begins to talk himself into genocidal practice, turning on his own half-Jewish nuclear unit. Kopfrkingl’s obsequious surface never changes, but both he and the society he lives in slowly turn into homicidal psychos — the new normal. Rarely seen here and still unavailable on video, it’s a darkling essay on Mitteleuropan conscience that makes most other Czechs of the day look like garden parties.\nHunting for alternatives, don’t forget to look off the grid: The bootleg outfit j4hi.com sports a catalog of pristine DVRs that runs from Olsen and Johnson’s manic meta-spoof Hellzapoppin’ (1941) to Dennis Hopper’s doper requiem The Last Movie (1971) to Alex de la Iglesia’s Acción Mutante (1993), with a ton of psychotronic exploitation in between, all of it unavailable in legit releases, and had here for a Jackson each. I saw their edition of Buñuel’s deranging, farcical masterpiece The Criminal Life of Archibaldo de la Cruz (1955), having only accessed it decades ago on a beat-up television print at the Bleecker Street Cinema, and it was a brand-new experience, digitally clean and picture-perfect. We shouldn’t, after all, let the whimsical, likely larcenous judgments of rights owners and market-timid distributors keep us from the cinephilic grist we want and need.', 'Along with Marilyn Ferdinand of Ferdy on Films, Greg Ferrara of Cinema Styles, and more than fifty other bloggers from around the world, the Siren urges anyone reading us this week to give something for our film heritage.\nPlease also check with your employer; some corporations match funds donated to the NFPF. If you know of such companies, please post them in comments.\nTo start things off, the Siren offers part one of a primer on Why We Fight (which film series, by the way, is on the list of films preserved by NFPF).\nFrom A Cast of Killers, Sidney D. Kirkpatrick\'s book about King Vidor\'s quest to film, and solve, the William Desmond Taylor murder. It\'s 1967 and Vidor is visiting the Paramount lot:\nIn front of the white post-production building, teeming with activity from the Christmas releases, he saw an old friend, an attractive blonde, who worked in the film library. He complimented her miniskirt, then asked if he could take a look at some of William Desmond Taylor\'s films. He was particularly interested in Taylor\'s last production, The Top of New York. She went to the office to see what she could do.\nOver the years Vidor and [Colleen] Moore had seen many of their own films destroyed. In the early sixties, silent films were thought to have no commercial value. They were difficult to store, dangerous to handle, and a fire hazard. Vidor\'s had been destroyed in a Bekins Storage Company fire, and Colleen\'s entire collection had burned up in a fire at Warner Brothers.\nVidor\'s friend brought him the news of Taylor\'s films. What titles had not disintegrated by the fifties were in such bad condition that they were taken out of the vaults, cut into small pieces with a chain saw, then burned, to salvage the silver content of the film stock.\nThe picture above is from the set of The Sky Pilot, the film Moore and Vidor made together; according to the Silent Era website, a print survives. Of Flaming Youth, the movie that made Moore\'s name and gave the world the flapper, only one reel survives in the archives of the Library of Congress.\nFrom Anita Loos\'s screenplay for A Virtuous Vamp, starring Constance Talmadge; included as an appendix to The Talmadge Girls. The movie opens just after the San Francisco earthquake of 1906. Gwen (Constance Talmadge), whose sole salvageable possession was a mirror, has just found her mother wandering near their former home, carrying a bicycle wheel and a garbage can.\nThe mother finally comes to and realizes what she has been carrying all the while, looks at the bicycle wheel and the garbage can and then at Gwen and says:\nSP. HAVE I BEEN CARRYING THESE THINGS ALL THE WAY FROM THE HOUSE?\nGwen says yes, evidently she has. Mrs Armitage shakes her head in despair, looks up at Gwen and says, ""Whatever will become of us?"" and begins to weep. Gwen puts her arms about her and comforts her. The mother then looks up at Gwen and says:\nSP. DO YOU REALIZE, CHILD, THAT ALL WE HAVE IN THE WORLD IS A BICYCLE WHEEL AND A GARBAGE CAN?\nGwen then holds out her mirror and says, ""But we have a mirror,"" and then looks at [her brother] Eddie who enters with his contribution, saying, ""Look what I got."" The mother takes it and looks at it:\nSP. YOUR FATHER\'S FAMILY CREST! THAT WILL HELP A LOT.\nShe takes the crest, lifts the garbage can lid, and drops it in. The kid, resenting this, goes around and fishes it out. The mother turns to Gwen and says:\nSP. WHY COULDN\'T ONE OF US HAVE SAVED A CAN OF SOUP?\nThe Silent Era website lists the survival status of A Virtuous Vamp as ""unknown.""\nFrom Peter Bogdanovich\'s interview with Raoul Walsh, in Who the Devil Made It?:\nNo print of The Life of General Villa is known to have survived.\nRaoul Walsh: (discussing The Life of General Villa) I spent four or five months with Villa, photographing some of the battles..Then I\'d photograph all the executions. In the morning they\'d line up these Federales against the wall and shoot them. I remember the first morning we set up to photograph this and I looked around: there was a bunch of Mexicans there, some with rocks in their hands and another bunch there with knives. I said, ""Jesus, this doesn\'t look too good."" The cameraman was Dutch (I can\'t think of his name); I said, ""You\'d better be able to run, Schultz--I don\'t like the look of things."" So this guy sat there, looked at us and said, ""We are ready now."" They shot these guys, and the bastards with the rocks ran in, opened the guys\' mouths and knocked the gold teeth out. And the others with the knives went in and started to cut their pants and take their boots off.\nBogdanovich: Did you photograph all that?\nWalsh: Yes. When I got home, [D.W.] Griffith said, ""My God, Raoul, you\'ve scared us all out of the projection room."" I said, ""Well, you wanted the life of Villa--you got it.""\nFrom Betty Blythe\'s interview with Kevin Brownlow in The Parade\'s Gone By:\n[Director J. Gordon] Edwards returned to this country, and his whole flash of genius as a director just went to ashes...Now I just carry in my heart the memory of this beautiful thing--The Queen of Sheba.\nThe Queen of Sheba is a lost film.\nJohn Ford, quoted in Bogdanovich\'s On Ford:\nIt was quite novel at the time--instead of riding to the rescue through Western scenery--they rode down Broadway at full tilt, weaving in and out. We went to downtown Los Angeles and rode the cowboys down the streets with a camera car ahead of them. And not a horse slipped.\nBucking Broadway was presumed lost until 2002, when it was located in the archives of the French National Center for Cinematography. The film was restored by Archives Françaises du Film in cooperation with the Museum of Modern Art.\nFrom The Los Angeles Times, Jan. 6, 1985; ""Old Films Are Getting a New Look,"" by Kevin Thomas:\nWhen construction was started on a skating rink on the site of a long-filled-in swimming pool in Dawson, the historic old gold-rush town in the Yukon, workers struck another kind of lode-a whopping 550 reels of film preserved half a century beneath the permafrost.\nIt seems that Dawson had been the end of the line on the old movie circuits-and the local bank, which had been storing the film in its basement, early on ran out of space for so many cans. Among other treasures, the trove yielded Douglas Fairbanks\' long-lost The Half Breed (1916).\nMore recently, a couple remodeling their porch found two reels of film buried under it that turned out to be the Civil War drama An Angel in Contention (1914) with Lillian Gish. But in the couple of months that it took for the American Film Institute to get hold of it, the nitrate had disintegrated so rapidly that now only seven frames exist.\nAfter publication of this article, it turned out that only two reels of The Half Breed, which was directed by Alan Dwan, had survived.']"	['<urn:uuid:d260b053-40d7-4764-904a-a20f11362029>', '<urn:uuid:dab06378-d0f8-4490-83b5-25bd0e933818>']	open-ended	with-premise	concise-and-natural	distant-from-document	multi-aspect	expert	2025-05-01T23:46:40.222380	8	90	2230
373	professor asking twitter book suggestions law students what was main conclusion	The consensus from the Twitter discussion was that there is no single book that would suffice for law students. Instead, law students should be well-read before, during, and after their degree.	"[""This has got to be the weirdest time for students about to start their degrees. Following the corona-related shutting down of all schools, and the suspension of entrance exams, potential university undergraduates are probably feeling like they have been cast adrift on a sea of uncertainty. The guiding hand which represents the world they have known since they started formal education at the age of four, abruptly yanked away. Almost every year, I get asked for recommendations of books for aspiring law students. The stakes are so high this year. Therefore, when I received a similar request this year, I decided to crowd-source my response on Twitter, and received an overwhelming response.\nCrowdsourcing request: I would really appreciate suggestions on this as it's something that I have thought a lot about myself too.\nSomeone asked me: If there were to be one book which you wished law undergraduates arrived at university having read, what would it be?\n— Dr Folúkẹ́ Adébísí (@folukeifejola) April 2, 2020\nThe question of what to read is one legal academics actually get quite often, so it was interesting to see what other legal academic colleagues across the UK and the world thought about the question. The results [which includes talks, movies and articles] are reproduced below. There was also some interesting discussion about the question too. The consensus seems to be that there is no one book that will suffice, and law students should be well read, before, during and after their degree. I like to divide the list into two somewhat overlapping ‘genres’: on the one hand the perspective that law is an objective science; and on the other, more socio-legal. This, in some ways also reflects students aspirations within the law as well as the nature law itself, having both the potential for freedom and unfreedom. This is why I often advise students to read across the divide and beyond their interest. We cannot really understand the law, if we only study one of his faces.\nThe list is by no means exhaustive, so further suggestions are most welcome. Let me know what you think in the comments section. Shukraan\nHighlighted material added in 2022\nBooks and Articles\nAdichie, Chimamanda Ngozi. Half of a yellow sun. Alfred a Knopf Incorporated, 2006.\nAdichie, Chimamanda Ngozi. We should all be feminists. Vintage, 2014.\nAngelou, Maya. I know why the caged bird sings. Bantam, 1997.\nBeatty, Paul. The sellout. Oneworld Publications, 2016.\nBingham, Tom. The rule of law. Penguin UK, 2011.\nBoll, Heinrich. The lost honour of Katharina Blum. CONNOISSEUR, 1995.\nChinua, Achebe. Things fall apart. London: Heinemann, 1958.\nDavis, Angela Y. Are Prisons Obsolete?. Seven Stories Press, 2011.\nDayan, Colin. The Law Is a White Dog-How Legal Rituals Make and Unmake Persons. Princeton University Press, 2013.\nDenning, Lord, Alfred Thompson, and Denning Denning Baron. Landmarks in the Law. London: Butterworths, 1984.\nDenning, Lord. The Discipline of Law. Butterworths, (1979).\nDostoyevsky, Fyodor. Crime and Punishment:(Penguin Classics Deluxe Edition). Penguin, 2015.\nDuBois, Page. Torture and truth. Routledge (1991).\nEbadi, Shirin. Until we are free: My fight for human rights in Iran. Random House, 2016.\nElgin, Suzette Haden. Native tongue. The Feminist Press at CUNY, 2013.\nErdrich, Louise. The round house. Hachette UK, 2013.\nFoucault, Michel. ‘Discipline and Punish: The Birth of the Prison’, in On Violence: A Reader (Duke University Press, 2007), 445–71,\nGilmore, Ruth Wilson. Golden Gulag: Prisons, Surplus, Crisis, and Opposition in Globalizing California, Golden Gulag (University of California Press, 2007),\nGolding, W., 1987. Lord of the Flies. Penguin.\nhooks, bell. All about love: New visions. Harper Perennial, 2001.\nKennedy, Helena. Eve was framed: Women and British justice. Random House, 2011.\nLlewellyn, Karl Nickerson. The bramble bush: On our law and its study. Oceana, 1978.\nLyall, Andrew. Granville Sharp’s Cases on Slavery. Bloomsbury Publishing, 2017.\nMarx, Karl, and Friedrich Engels. The communist manifesto. Penguin, 2002.\nMoraga, Cherríe, and Gloria Anzaldúa, eds. This bridge called my back: Writings by radical women of color. Suny Press, 2015.\nMorrison, Toni. Beloved. New York 1987.\nO’Neill, Louise. Asking for it. Quercus, 2016.\nOyěwùmí, Oyèrónkẹ́. The invention of women: Making an African sense of western gender discourses. U of Minnesota Press, 1997.\np’Bitek, Okot. Song of Lawino. Vol. 2. East African Publishers, 1995. [Song of a prisoner, highly recommended]\nPistor, Katharina. “The Code of Capital: How the Law Creates Wealth and Inequality–Core Themes.” Accounting, Economics, and Law: A Convivium 11, no. 1 (2021): 1-7.\nSachs, Albie. The strange alchemy of life and law. Oxford University Press, 2011.\nThe Secret Barrister. The Secret Barrister: Stories of the Law and how It’s Broken. Pan Macmillan, 2018.\nThe Uluru Statement and Megan Davis’ explanation of the process, in ‘The long road to Uluru: Walking together – truth before justice’ is highly recommended\nUnger, Roberto Mangabeira. What should legal analysis become? Verso, 1996.\nWilliams, Patricia J. The alchemy of race and rights. Harvard University Press, 1991.\nWi Parata v Bishop of Wellington (1877) NZJurRp 183; (1877) 3 NZ Jur (NS) 72 (SC); 1 NZLRLC 14\nGregson v Gilbert (1783) 2 Douglass 233\nRe Southern Rhodesia (1919) AC 211\nAnother very helpful list: (check the comments!)\nAnna Grear The DNA of our Legal System | TEDxBonn\nBryan Stevenson |We need to talk about an injustice\nChimamanda Ngozi Adichie | The danger of a single story""]"	['<urn:uuid:42faa191-10b1-41be-a5b3-83ef03cdfae8>']	factoid	with-premise	long-search-query	similar-to-document	single-doc	novice	2025-05-01T23:46:40.222380	11	31	880
375	what link between classical jazz concert halls historical significance modern day	The relationship between classical music and jazz in concert halls has a rich history. It began notably at venues like Aeolian Hall in Manhattan, which hosted both classical virtuosos like Rachmaninoff and Prokofiev, as well as jazz performances, including Paul Whiteman's historic 1924 concert that bridged both worlds. This integration developed over time, as exemplified by Leonard Bernstein's educational programs, which explained how jazz gradually entered American concert halls over forty years, initially as two separate streams that occasionally merged. The 'third stream' movement further formalized this fusion, with composers like Gunther Schuller creating works that deliberately combined symphony orchestras with jazz combos, establishing a lasting connection between these musical traditions.	"['Aeolian Hall (Manhattan)\n|This article needs additional citations for verification. (March 2008) (Learn how and when to remove this template message)|\nAeolian Hall was a concert hall in midtown Manhattan in New York City, located on the third floor of 29-33 West 42nd Street (also 34 West 43rd Street, from the other side) across the street from Bryant Park. The Aeolian Building was built in 1912 for the Aeolian Company, which manufactured pianos. Located on the site of the former Latting Tower, which during the 19th century was a popular observatory, the 18-story building contained the 1,100-seat Aeolian Hall. The building stands next to the Grace Building.\nDesigned by the architects Whitney Warren and Charles Wetmore the building was completed in 1912 with its name referring to the Aeolian Company which manufactured pianos. It is 80 meters high and has 18 floors. The concert hall, which could seat 1100 spectators, was on the third floor of the building. In the summer of 1922, the company sold the building to the department store Schulte Cigar Stores Company for over $5 million.\nThe building continued to host concerts by the International Composers Guild up to January 1926, at least, when the appearance of African American Broadway performer Florence Mills, singing jazz-based pieces by William Grant Still, caused a minor sensation. Nadezhda Plevitskaya reportedly delighted the Aeolian Hall audience with her Russian folk songs in April 1926.\nThe concert hall closed in May 1926, with a performance by violinist Leon Goldman.\nFrom 1961 to 1999, the building housed the Graduate Center of the City University of New York, and today houses the State University of New York\'s College of Optometry.\nAeolian Hall also featured concerts by leading musical figures such as Sergei Rachmaninoff, Josef Hofmann, Sergei Prokofiev, Ferruccio Busoni, Guiomar Novaes, and Ignacy Jan Paderewski, as well as Paul Whiteman and his Orchestra; upon its return to the United States after several years in Europe, the Zoellner Quartet gave its first New York performance there on January 7, 1914. The hall is most famous for a concert given by Whiteman\'s orchestra on February 12, 1924, titled ""An Experiment in Modern Music"". Intended to be an educational demonstration on how far American music had progressed in recent decades and how jazz could be performed in the concert hall, the concert included a suite by Victor Herbert and closed with the Pomp and Circumstance marches by Edward Elgar. The concert is remembered, however, for the penultimate piece, the world premiere of George Gershwin\'s Rhapsody in Blue with the composer at the piano, orchestrated by Whiteman\'s arranger Ferde Grofe. This concert is today considered a defining event of the Jazz Age and the cultural history of New York City.\n- ""Aeolian Hall Sold"". Time Magazine. August 11, 1924. Retrieved September 5, 2009.\n- ""Aeolian Hall Opening"". The New York Times. October 13, 1912.\n- ""Social News"". The New York Times. April 3, 1926, page 14.\n- ""Thurber, James"". ""Swan Song"". The New Yorker. May 27, 1927.\n- ”Zoellner Quartet Plays”. The New York Times. January 8, 1914.', 'Young People\'s Concerts\nOverview | Letters & Telegrams | Publications | Scripts\nYoung People\'s Concert: Jazz in the Concert Hall [back to script index]\n[COMBO ON STAGE. LB TURNS TO CONDUCT; GIVES DOWNBEAT; COMBO ONLY PLAYS JAZZ LICK.]\nNow that\'s about the last sound in the world you\'d expect to hear in Philharmonic Hall, isn\'t it? Sounds more like your next-door neighbor\'s radio, or the Newport Jazz Festival. And yet, that\'s a sound that\'s been coming more and more often into our American concert halls, ever since American composers began trying, about forty years ago, to get some of the excitement and natural American feeling of jazz into their symphonic music.\nEven so, in spite of these tries at combining jazz and symphonic writing, the two musics have somehow remained separate, like two streams that flow along side by side without ever touching or mixingexcept every once in a while. But it\'s those once-in-a-whiles that we\'re interested in today: those pieces in which the jazz stream now and then does sneak over to the symphonic stream, and for a moment or two, flows along with it in happy harmony. And these daysat least, for the last five or fifty years, that isthere is a new movement in American music actually called ""the third stream"" which mixes the rivers of jazz with the other rivers that flow down from the high-brow far out mountain peaks of twelve-tone, or atonal music.\nNow the leading navigator of this third streamin fact the man who made up the phrase ""third stream""is a young man named Gunther Schuller. He is one of those total musicians, like Paul Hindemith whom we discussed on our last program, only he\'s American. Mr. Schuller writes musicall kinds of musicconducts it, lectures on it, and plays it. Certainly he owes some of his great talent to his father, a wonderful musician who happens to play in our orchestra. We are very proud of Arthur Schuller.\nBut young Gunther Schullerstill in his thirtiesis now the center of a whole group of young composers who look to him as their leader, and champion.\nAnd so I thought that the perfect way to begin today\'s program about jazz in the concert hall would be to play a piece by Gunther Schullerespecially this one particular piece which is an introduction to jazz for young peoplea sort of Peter and the Wolf of jazz. Like Peter and the Wolf, it is written for orchestra with a speaker; and it also tells about a young boy named, of all things, Peter. One thing is different though: it calls for a symphony orchestra that also includes a jazz combo; and that is why you see up there five very distinguished young stars of the jazz world Richard Davis [DOUBLE BASS], Don Ellis [TRUMPET], Benny Golson [TENOR SAXOPHONE], Eric Dolphy [ALTO SAXOPHONE], Joseph Cocuzzo [DRUMS].\n[STAND AND BOW]\nNow because Mr. Schuller is such a fine conductor, as well as a composer, I have invited him to come conduct his piece himself; and I will step down and become the speaker taking my orders from him. So without any further explanation, here is Gunther Schuller\'s third-stream composition, Journey into Jazz, with a narration written by the well-known jazz critic Nat Hentoff; and here is Gunther Schuller himself.\n[ORCH: Schuller - Journey into Jazz]\n""This is the story of Peter Parkera boy who learned about jazz.\nThe JOURNEY INTO JAZZ you\'ve just heard was written by Mr. Schuller and Mr. Hentoff only a year or so ago. But much longer ago, before you all were born, way back in the prehistoric days of 1926, a man called Aaron Copland was experimenting with jazz in the concert hall, and turning out some pretty marvelous pieces. Of course, today, Mr. Copland is America\'s leading composer, loved, admired and respected all over the world by all the world of music, including you all because, if you recall, he\'s appeared on these programs twice before. But at the time he wrote his jazzy Piano Concerto in 1926, he was only twenty-six years olda young pioneer of American music. And when that Piano Concerto was first heard a year later in 1927, in the stately town of Boston, Massachusetts, with the great Koussevitsky conducting and Mr. Copland himself at the piano, there was a good deal of shock in the air. The Bostonians just couldn\'t accept the idea of a third stream, way back then; but today, with the stream in full flow, the music sounds perfectly right and natural to us.\nWhen he was still quite small, Peter Parker had strong musical tastes. For instance, when his father sang, Peter moaned. When his mother sang, Peter howled.\nBy the time he was five, Peter had his own toy trumpet. At six, he was given a phonograph that was as small and sturdy as he. And at seven, a transistor radio was added to help satisfy Peter\'s huge hunger for music.\nOne day Peter taped a bold sign outside the door of his room which said, MUSIC IS BEING MADEDO NOT ENTER.\nThe door was then closed. And from that day on, the sign appeared and remained in place from three to six every afternoon. From behind the door, Peter\'s parents could hear the trumpet, or the phonograph playing Prokofiev or the radio playing Rossini.\nAnd usually, all three at once.\nOf course, the trumpet was loudest.\nSoon Peter had a real trumpet and a real teacher whose tastes in music were as strong as Peter\'s. Peter\'s parents began to hear scales. First simple scales that soared slowly and floated back down again, sometimes stumbling on the way.\nThen more and more difficult scales that climbed quickly and fell with dizzying speed and soaring arpeggios...\nFrom exercises, Peter went on to play real tunestunes that sometimes sounded like a small stream in a great hurry, or sometimes like a deep peaceful river, or an electric storm, or sometimes like nothing Peter\'s parents could imagine at all.\nPeter told them that these very advanced tunes were called \'modern music.\'\nThey nodded, but were not quite sure they understood.\nSoon Peter and his teacher began to play duets. Gradually, it became difficult to tell Peter apart from his teacher, and by the time he was fourteen, Peter was a most accomplished and exceedingly proud trumpet player. There was no music printed that he couldn\'t read.\nOne summer afternoon, although the sign was on Peter\'s door and he was not disturbed, he could not concentrate.\nSomewhere, in some other house nearby, a small jazz band was playing.\nLeading all the other instruments was a tenor saxophone-player who sounded more daring and full of surprises than any musician Peter ever heard. Peter was curiousand he was disturbed.\nPeter took his trumpet, left his room, followed the sound, and discovered four young men in the garage of a house on the next block. Seeing his trumpet, the young musicians asked Peter to join them.\nPeter looked, and looked again, but nowhere could he see any printed music.\nHe tried to join in with them, but something was terribly wrong.\nPeter could not find a place for himself. Every time he tried, the music would simply sputter to a stop. He just didn\'t fit.\n\'Look,\' the tenor sax man told him, \'you know your way around that horn all right, but you don\'t know jazz. When you do, come back again. We\'ll be around.\'\nPeter sadly trudged home. But he had been excited by the music he heard in that garage.\nSo he began to listen to jazz records, especially records which featured trumpet players, and soon he was having fun trying to play some of his classical pieces in jazz time.\nPeter also began to realize that each jazz trumpet player had his own way of playing.\nIt was almost like people talking\nwith growls and\nand funny in-between notes.\nHe also discovered the fun of different sounding mutes.\nFinally Peter Parker felt ready.\nHe ran to the garage in the house on the next block.\nBut when he started to play with the other young musicians, there was still something terribly wrong.\nHe just didn\'t fit. Whatever he tried, the result was the same. Peter\'s horn stuck out as if he were all alone. He still could not find a place for himself.\nThe others seemed to be having a conversation, but when he started to blow, it was like another language.\nHe looked at his trumpet, but nothing was wrong with it.\nAnd he looked at the other players, and they were shaking their heads.\n\'Look,\' the tenor sax man told him. \'You know how to play jazz on the trumpet now, but you don\'t know how to play with people. When you do, come back again. We\'ll be around.\'\nPeter sadly trudged home. He thought and thought and finally realized that on all the records he had heard, he had been listening only to the trumpet player, and not to what the other musicians were doing. So Peter began to listen to his records in a new way.\nHe learned about blending with other instruments. He learned about improvising countermelodies, tunes that fitted in with the solos other people were playing.\nYou see, up to now, Peter had been playing along with his records on top of the music; but now he tried to get inside the music, until he felt as if he were part of the conversation.\nAnd little by little, he became a living part of every record he played.\nNow once again, Peter felt ready, and returned to the garage of the house on the next block.\nAnd this time, when he started to play with the other young jazz musicians he thought he fitted in perfectly.\nBut after awhile, the other musicians stopped, and they stared at him mournfully.\n\'Look,\' the tenor sax man said, \'you know everything except what to say in the music. You and that trumpet make a fine machine, but jazz isn\'t a machine; jazz is how you feel. What do you feel? When you know, come back again. We\'ll be around.\'\nPeter sadly trudged home. At first he was puzzled, but little by little he began to be angry. He ran home and looked fiercely at that sign on his door \'DO NOT ENTERMUSIC BEING MADE HERE.\' He grabbed his trumpet, and began to play.\nThe first notes were full or rageraw and ugly.\nBut for some strange reason, playing them made Peter feel good. He looked at the trumpet, and he thought, \'These are my notes. This music is me.\'\nAs the hours went by, the angry notes turned into triumphant notes, then into happy onesall kinds of notes, filling the room. \'And all of these notes are mine,\' Peter said. \'These notes are how I feel.\'\nAnd that day Peter felt really ready, and he went back to the garage on the next block.\nAnd this time, when he started to play with the other jazz musicians, he knew right away that he belonged. They played together for a long time, full of the pleasure of just making music.\nNow Peter was listening to the tenor sax man.\nNow he listened to the alto mana whole other style.\nPeter thought, \'Hey, all this music is us! Jazz is PEOPLE!\nLate that night Peter Parker returned home, he made a new sign and put it on his door. It said: MUSIC IS BEING MADECOME ON IN.""\nNow we\'re going to hear that same Piano Concerto, thirty-seven years later; and I want you to realize that the kind of jazz you\'ll be hearing is from another time. It\'s jazz of the twenties, full of Charleston rhythms, boop-poop-a-doops, and a certain Gershwin-like sentimentality. And the wonderful thing is that, old as it is, it still sounds as fresh and charming and full of zip as it did in 1927.\nNow we\'re going to hear it played. It\'s in two movementsa slow and a fast onethat are played without any pause between them. And our piano soloist, I am proud and happy to say, is none other than the original soloist from 1927, the one and only Aaron Copland.\n[ORCH: Copland - Concerto for Piano and Orchestra]\nNow, to end this exciting look into jazz in the concert hall, we\'re going to come back to the music of today, and see what our younger composers are up to. We\'ve brought back our jazz combo (or three fifths of it, as you see), to play for you an unusual and strange new work by a young Californian named Larry Austin. Mr. Austin is as serious a composer as you can find anywhere; he is a master of all the techniques of modern music, and, at the age of thirty-three, he is an assistant professor of music at the University of California. So this is no tossed-off stuff, but a really serious symphonic piece.\nIn fact, it is such a serious piece, in spite of its jazz combo and its hair-raising ending, which is like a tremendous jam-session, that I think you may not ever realize there\'s jazz in it, especially during the first part. But the jazz is there, all right; only it\'s gotten thoroughly mixed with the serious, or symphonic writing so that it\'s almost unnoticeablein other words, it\'s a real third stream.\nThe other thing that makes this piece so special is the amount of improvisation that goes on in it. There are two times during the music when we long-hairs just stop playing, and let the combo invent whatever notes they happen to feel at the time. And even more unusual is the fact that certain members of the Philharmonic are also asked to improvise, every now and then, and that\'s a new wrinkle.\nSo now, we\'re going to play for you this fascinating new piece called Improvisations for Orchestra and Jazz Soloists, by Larry Austin. It\'s in three movementsfast blues, slow blues, and very fast bluesall played without pause. And, as you may notice, without violins.\n[ORCH: Larry Austin - Improvisations for Orchestra and Jazz Soloists]']"	['<urn:uuid:f112011c-159d-4207-a30e-9b1ea41ff50c>', '<urn:uuid:dabf76b1-bc8d-46d9-8ab7-10cd2a3b13f9>']	open-ended	with-premise	long-search-query	distant-from-document	three-doc	novice	2025-05-01T23:46:40.222380	11	111	2872
376	genetic treatment success rate retinal cells vs amoeba reproduction	CNTF gene therapy in retinal cells shows significant success, preserving over 50% of cone photoreceptors and maintaining useful vision even in later disease stages. In comparison, when slime mold amoeba cells lack the dimA gene, they show severely reduced success in spore production despite initially having an advantage in development, demonstrating that genetic manipulation can have opposite effects on survival in these different cellular systems.	"['A collaboration between scientists in the UK and the USA has shown that gene therapy can give life-long protection to the light-sensitive photoreceptor cells responsible for colour vision in a mouse model of the most common inherited eye disorder.\nResults published in the journal Molecular Therapy demonstrate that the preserved cells were able to drive visually-guided behaviour, even in later stages of the condition and despite becoming less sensitive to light.\nPrevention of retinal degeneration using CNTF gene therapy applied to one eye of a mouse model of retinitis pigmentosa, which also has fluorescent cones that can be counted. At 8 weeks (PW8) both eyes appear similar, but by 30 weeks retinal pigment changes can be seen in the sham injected eye (c) as the degeneration progresses with all cones lost (d). In contrast, the CNTF treated eye (g, h) has a virtually unchanged fundal appearance and over 50 percent of cones surviving (from Lipinski et al., 2015).\nCredit: University of Oxford/ Robert MacLaren\nThese findings are significant because they open up a new line of research to prevent nerve cell death in retinitis pigmentosa and age-related macular degeneration. They may also have a wider application to neurodegenerative disorders such as amyotrophic lateral sclerosis (ALS).\nThe research was led by Professor Robert MacLaren at the University of Oxford\'s Nuffield Laboratory of Ophthalmology and funded in the UK primarily by Fight for Sight, with addition support from the Wellcome Trust, the Health Foundation, the Medical Research Council, the Royal College of Surgeons of Edinburgh, the Oxford Stem Cell Institute and the NIHR Ophthalmology (Moorfields) and Oxford Biomedical Research Centres.\nRetinitis pigmentosa (RP) affects 1 in 4000 people, with symptoms that typically appear between age 10 and 30. Night vision and peripheral vision go first, as the photoreceptors active in low light - the \'rods\' - start to degenerate. Eventually the condition affects the \'cones\' - the photoreceptors responsible for central, detailed, colour vision.\nThe current study looked at a mouse model of retinitis pigmentosa in which the mice lack rhodopsin - the main pigment in rod photoreceptors. At age 4 weeks - after rod degeneration was underway and before cones were affected - the mice were dosed with a virus modified to produce human ciliary neurotrophic factor (CNTF) protein in the retina.\nCNTF is a compound previously shown to prevent the loss of photoreceptors and retinal ganglion cells. However its use as a potential treatment has been in question because of concerns about toxicity. The unique approach in this study was to use a mouse which had fluorescent green cone photoreceptors which could be counted by examining the living retina with a modified ophthalmoscope at various timepoints during the course of the degeneration. This allowed precise titration of the gene therapy dose which minimised any toxic effects.\nTreatment was given to one eye, while saline was given to the other eye as a control. At 8 weeks, non-invasive imaging showed similar numbers of cones in all treated and untreated eyes. However, the number of cones decreased rapidly over the time course of the experiment in low-dose and control eyes, reaching 0 by week 24.\nWhat\'s really interesting is that, in contrast to previous CNTF studies, the research team was able to show that the preserved cones were functional by using behavioural tests and imaging blood flow in the visual cortex.\nNext-generation sequencing at 30 weeks revealed that a group of genes previously linked to retinal disease were up to 89 times more active in high-dose eyes than in controls. Several genes usually active in the retina were also found to be less active in both medium- and high-dose eyes.\n""Our results in this mouse model of retinitis pigmentosa clearly show that CNTF treatment can both give life-long protection to cone photoreceptors and preserve useful vision. While there remains a lot to understand, for example on the role of rods in cone preservation and translation to human retinal anatomy, this is a very promising study,"" said MacLaren, Professor of Ophthalmology at the Nuffield Laboratory of Ophthalmology.\n""We already know from clinical trials aimed at preventing motor neuron loss in ALS that high-dose systemic treatment with CNTF causes too many adverse reactions to be tolerated by patients. However, our results suggest that directly increasing activity in the class of genes that were upregulated in our high-dose CNTF group has the potential to provide a novel, targeted treatment for retinitis pigmentosa and a range of neurodegenerative diseases.""\nDr Dolores M Conroy, Director of Research at Fight for Sight, said:\n""One of the most exciting prospects about these results is that the CNTF treatment was able to preserve vision even though rod degeneration had begun. This is a top priority for people with inherited and progressive eye conditions such as retinitis pigmentosa and AMD. As with any new line of research there is still a long way to go before any treatment could reach the clinic, but it is certainly possibly to look ahead and see that there will be a day when we can prevent sight loss with complex genetic involvement.""\nLipinski, D.M., Barnard, A.R., Singh, M.S., Martin, S., Lee, E., Davies, W.I.L. & MacLaren, R.E. CNTF gene therapy confers lifelong neuroprotection in a mouse model of human retinitis pigmentosa. Mol. Ther., 2015.\nImage URL, caption & credit\nCaption: Prevention of retinal degeneration using CNTF gene therapy applied to one eye of a mouse model of retinitis pigmentosa, which also has fluorescent cones that can be counted. At 8 weeks (PW8) both eyes appear similar, but by 30 weeks retinal pigment changes can be seen in the sham injected eye (c) as the degeneration progresses with all cones lost (d). In contrast, the CNTF treated eye (g, h) has a virtually unchanged fundal appearance and over 50% of cones surviving (from Lipinski et al., 2015).\nCredit: ©University of Oxford\n* More than 190 genes are linked to inherited retinal disease of which about half cause retinitis pigmentosa (RP).\n* We still don\'t know the exact genetic cause of photoreceptor loss in 30% of people with autosomal recessive RP (inherited from both parents) and 50% of people with autosomal dominant RP (inherited from one parent).\n* Retinal ganglion cells form the optic nerve - the specialised cable that transmits visual signals from eye to brain.\n* Age-related macular degeneration (AMD) is one of the leading causes of sight loss in the UK. Most of the sight loss due to AMD happens during the later stages, which affect around 0.5 million over 50s in the UK and counting.\n* Genetics is an important factor in the risk of developing AMD.\nFight for Sight is the leading UK charity dedicated to funding pioneering research to prevent sight loss and treat eye disease. Fight for Sight is funding research at leading universities and hospitals throughout the UK.\nMajor achievements to date include: saving the sight of thousands of premature babies through understanding and controlling levels of oxygen delivery; restoring sight by establishing the UK Corneal Transplant Service enabling over 52,000 corneal transplants to take place; providing the funding for the research leading to the world\'s first clinical trial for choroideremia; bringing hope to children with inherited eye disease by co-funding the team responsible for the world\'s first gene therapy clinical trial; and identifying new genes responsible for keratoconus, Nance-Horan syndrome, achromatopsia and retinitis pigmentosa.\nFight for Sight\'s current research programme is focusing on preventing and treating age-related macular degeneration, diabetic retinopathy, glaucoma, cataract and corneal disease. We are also funding research into the causes of childhood blindness and a large number of rare eye diseases.\nFor more information, please contact: Ade Deane-Pratt on 020 7264 3906 or firstname.lastname@example.org\nThe Nuffield Laboratory of Ophthalmology is part of Oxford University\'s Medical Sciences Division, one of the largest biomedical research centres in Europe, with over 2,500 people involved in research and more than 2,800 students. The University is rated the best in the world for medicine, and it is home to the UK\'s top-ranked medical school.\nFrom the genetic and molecular basis of disease to the latest advances in neuroscience, Oxford is at the forefront of medical research. It has one of the largest clinical trial portfolios in the UK and great expertise in taking discoveries from the lab into the clinic. Partnerships with the local NHS Trusts enable patients to benefit from close links between medical research and healthcare delivery.\nAde Deane-Pratt | EurekAlert!\nTeam discovers how bacteria exploit a chink in the body\'s armor\n20.01.2017 | University of Illinois at Urbana-Champaign\nRabies viruses reveal wiring in transparent brains\n19.01.2017 | Rheinische Friedrich-Wilhelms-Universität Bonn\nAn important step towards a completely new experimental access to quantum physics has been made at University of Konstanz. The team of scientists headed by...\nYersiniae cause severe intestinal infections. Studies using Yersinia pseudotuberculosis as a model organism aim to elucidate the infection mechanisms of these...\nResearchers from the University of Hamburg in Germany, in collaboration with colleagues from the University of Aarhus in Denmark, have synthesized a new superconducting material by growing a few layers of an antiferromagnetic transition-metal chalcogenide on a bismuth-based topological insulator, both being non-superconducting materials.\nWhile superconductivity and magnetism are generally believed to be mutually exclusive, surprisingly, in this new material, superconducting correlations...\nLaser-driving of semimetals allows creating novel quasiparticle states within condensed matter systems and switching between different states on ultrafast time scales\nStudying properties of fundamental particles in condensed matter systems is a promising approach to quantum field theory. Quasiparticles offer the opportunity...\nAmong the general public, solar thermal energy is currently associated with dark blue, rectangular collectors on building roofs. Technologies are needed for aesthetically high quality architecture which offer the architect more room for manoeuvre when it comes to low- and plus-energy buildings. With the “ArKol” project, researchers at Fraunhofer ISE together with partners are currently developing two façade collectors for solar thermal energy generation, which permit a high degree of design flexibility: a strip collector for opaque façade sections and a solar thermal blind for transparent sections. The current state of the two developments will be presented at the BAU 2017 trade fair.\nAs part of the “ArKol – development of architecturally highly integrated façade collectors with heat pipes” project, Fraunhofer ISE together with its partners...\n19.01.2017 | Event News\n10.01.2017 | Event News\n09.01.2017 | Event News\n20.01.2017 | Awards Funding\n20.01.2017 | Materials Sciences\n20.01.2017 | Life Sciences', 'Biologists ID molecular block for social ’cheaters’\nSocial cooperation is one of the most difficult adaptations for evolutionary biologists to explain because competition for resources inside the collective should lead to evolved traits that allow individuals to ""cheat"" the collective, win more resources and reproduce faster than their more cooperative neighbors -- thus undermining the social collective. In new research, evolutionary biologists and geneticists at Rice University and Baylor College of Medicine have isolated a genetic mechanism that counters competitive pressures and stabilizes cooperation. Their research appears in the Oct. 7 issue of the journal Nature.\nUsing the latest tools of molecular genetics, the researchers found that the phenomenon known as pleiotropy -- which occurs when a gene affects more than one inherited trait -- plays a crucial role in preventing ""cheaters"" from exploiting their neighbors within slime mold colonies that are formed by the social amoeba Dictyostelium discoideum. ""What we’ve found is a molecular block to cheating and the genetic mechanism it relies on-- tying cooperative genes tightly with the essential function of reproduction,"" said paper co-author Joan Strassmann, professor of ecology and evolutionary biology at Rice. ""Such a mechanism makes the loss of social genes costly to cheaters, and we believe this pleiotropic mechanism may be indicative of a general mechanism that’s employed in many species to stabilize cooperation.""\nThe Rice-Baylor experiments draw upon one of the most extraordinary examples of social cooperation among microorganisms: when slime mold amoebae run out of the bacteria they eat, they group, then form a fruiting body in which about one-fifth of the single-celled individuals within the colony sacrifice themselves to form the stalk that holds up the spores. Before forming a stalk, the colony goes through a stage where it forms a slug-like structure. During this stage, cells produce a signaling molecule called DIF-1 that causes some members of the colony to differentiate themselves from the rest of the group and enter a prestalk stage of development. Using biotechnology, the research team created a mutant strain of Dictyostelium without the gene dimA, which codes for a key protein that Dictyostelium cells use to recognize DIF-1. ""We wanted to see if cells without dimA could cheat the system by ignoring DIF-1 and thereby increase their chances of becoming spore cells rather than stalk cells,"" said paper co-author David Queller, professor of ecology and evolutionary biology at Rice. ""We created colonies that contained roughly a 50-50 mix of our mutants and wild type strains of Dictyostelium, As expected, the dimA knockouts -- the cheaters -- were predisposed to move to the back of the slug, the position occupied by cells in the prespore stage of development.""\nBut despite this advantage during stalk development, the cheaters were far less likely than their native counterparts to make it into the actual spores atop the stalk, a finding that surprised the entire research team. The researchers conducted a series of tests to determine whether the dimA mutants had an unexpected competitive disadvantage that was skewing the results of the experiment. One of those tests involved looking for a marker gene expressed only in prestalk cells. Using this marker gene, they determined that many cells in the spores were wild type cells that were initially tagged to become stalk cells. These cells underwent a late-stage developmental about-face and supplanted dimA knockout cells that were initially targeted to become spores.\n""This test confirmed that the dimA gene was essential not only for DIF-1 recognition but also for spore production,"" said paper co-author Gad Shaulsky, associate professor of molecular and human genetics at Baylor College of Medicine. ""We don’t know the precise biomolecular pathway for this second function, but we know that dimA codes for a transcription factor that binds with DNA in the nucleus to control gene expression. Because transcription factors often control more than one gene, we believe the absence of dimA may be interfering with an unknown recognition pathway that is essential for spore selection.""\nThe results are the first published by a unique Rice-Baylor collaborative that won $5 million from the National Science Foundation last year to apply the latest techniques of modern molecular genetics and large-scale genomics to the study of social evolution. The project was one of the first funded by the NSF’s new Frontiers in Integrated Biological Research program.\nOther co-authors on the paper, ""Pleiotropy as a mechanism to stabilize cooperation,"" are Kevin Foster, a former Huxley Fellow in ecology and evolutionary biology at Rice who is now a Fellow at the Wissenschaftkolleg in Berlin, and Chris Thompson, a former post-doctoral researcher at Baylor College of Medicine who is now at The University of Manchester.\nJade Boyd | EurekAlert!\nThe most recent press releases about innovation >>>\nDie letzten 5 Focus-News des innovations-reports im Überblick:\nResearchers from the University of Hamburg in Germany, in collaboration with colleagues from the University of Aarhus in Denmark, have synthesized a new superconducting material by growing a few layers of an antiferromagnetic transition-metal chalcogenide on a bismuth-based topological insulator, both being non-superconducting materials.\nWhile superconductivity and magnetism are generally believed to be mutually exclusive, surprisingly, in this new material, superconducting correlations...\nLaser-driving of semimetals allows creating novel quasiparticle states within condensed matter systems and switching between different states on ultrafast time scales\nStudying properties of fundamental particles in condensed matter systems is a promising approach to quantum field theory. Quasiparticles offer the opportunity...\nAmong the general public, solar thermal energy is currently associated with dark blue, rectangular collectors on building roofs. Technologies are needed for aesthetically high quality architecture which offer the architect more room for manoeuvre when it comes to low- and plus-energy buildings. With the “ArKol” project, researchers at Fraunhofer ISE together with partners are currently developing two façade collectors for solar thermal energy generation, which permit a high degree of design flexibility: a strip collector for opaque façade sections and a solar thermal blind for transparent sections. The current state of the two developments will be presented at the BAU 2017 trade fair.\nAs part of the “ArKol – development of architecturally highly integrated façade collectors with heat pipes” project, Fraunhofer ISE together with its partners...\nAt TU Wien, an alternative for resource intensive formwork for the construction of concrete domes was developed. It is now used in a test dome for the Austrian Federal Railways Infrastructure (ÖBB Infrastruktur).\nConcrete shells are efficient structures, but not very resource efficient. The formwork for the construction of concrete domes alone requires a high amount of...\nMany pathogens use certain sugar compounds from their host to help conceal themselves against the immune system. Scientists at the University of Bonn have now, in cooperation with researchers at the University of York in the United Kingdom, analyzed the dynamics of a bacterial molecule that is involved in this process. They demonstrate that the protein grabs onto the sugar molecule with a Pac Man-like chewing motion and holds it until it can be used. Their results could help design therapeutics that could make the protein poorer at grabbing and holding and hence compromise the pathogen in the host. The study has now been published in “Biophysical Journal”.\nThe cells of the mouth, nose and intestinal mucosa produce large quantities of a chemical called sialic acid. Many bacteria possess a special transport system...']"	['<urn:uuid:6738fb17-a2c0-4a0d-9742-8fc868637654>', '<urn:uuid:0858312e-83c6-4dd4-b9c9-855a951e067a>']	factoid	direct	long-search-query	distant-from-document	comparison	novice	2025-05-01T23:46:40.222380	9	65	2947
379	community based environmental practices compare traditional hunting modern water management systems	Both traditional hunting and modern water management systems emphasize community-based approaches. In Utqiaġvik, whaling practices focus on feeding the entire community, with hunters sharing their catch with friends, family, and all community members. Similarly, water conservation programs are typically initiated at the local level by municipal utilities or regional governments, involving community-wide measures such as public outreach campaigns and tiered water rates. Both systems require community participation and understanding - traditional hunting through generational knowledge sharing and practice, and water conservation through education and communication programs that reach land managers, policy makers, and the general public.	"['AK Natives on the Front Line: Hunting & Whaling Practices\nThis episode features brothers Jack and Brower Frantz, Iñupiaq hunters and whalers born and raised in Utqiaġvik, Alaska. Brower Tiġitquuraq Frantz is a subsistence research coordinator for the Wildlife Department at the North Slope Borough, and a father of five children. And Jack Ikusik Frantz, also a father and step father to seven children is an avid hunter/gatherer with an associates degree in media arts and currently works as an advisor to the mayor of the North Slope Borough. AK Natives on the Front Line is a special series of Coffee & Quaq highlighting the adaptability and resilience of the Iñupiat in the face of climate change, a project funded by the Pulitzer Center Connected Coastlines program, done in partnership with journalist Jenna Kunze. We travelled up to Utqiaġvik earlier this year at the peak of winter when the sun had returned back to the Arctic and interviewed residents about the various aspects of how Iñupiat life has changed, but also how it has remained the same. Throughout this series we explore topics like subsistence whaling practices, research, anthropological work, and more.\n""We’ve always hunted and we’ve always hunted with an umiapiaq, skin boat, in the spring time. Really, that was how we had to do it back then. That was how we had to get meat on the table. If you look at it from our perspective, that’s the most important thing: we get food on the table. Personally, I love using the umiapiaq. I love sitting there discussing stuff with my uncles, discussing how to hunt, discussing stories, discussing how they want to hunt the whale and waiting for the whale at the edge of the ice. That’s how I would prefer to hunt in the spring time, but if that’s not available, I’m all for getting in the aluminum boat and going out and catching a whale because that might be the only way to do it. If that’s how we have to do it, then that’s how we have to do it. The Utqiagvik mentality, for the most part, is that we want to feed our community. We want to make sure to get whales and bring them in and share it with our friends, our family, and everybody in the community."" -Jack Frantz\nRapid environmental changes have pressured Iñupiaq hunters to adapt and find new ways to fill freezers and put food on the table, not just individually, but for the entire community. The knowledge and expertise needed to hunt and whale safely in the Arctic requires years of patience, observation, and practice. And even more so now that the sea ice conditions are changing. The Iñupiat have relied on hunting and whaling since as far back as we can remember, and the general consensus seems to be that our people will continue to hunt and whale well into the future. The unique relationship that Iñupiaq hunters have with the environment is intimate and strong and one built on thousands of years of trial and error. Quyanaqpak to Jack and Brower Frantz again for shedding light on hunting and whaling practices in Utqiagvik, especially knowing that all too often our knowledges, practices, and traditions have been knowingly or unknowingly used against us in the past. Keep on whaling, folks.\nStay tuned for more episodes. Special thanks to Tripp Crouse for assisting in editing this episode.\nCheck out the accompanying written article on this project by Jenna Kunze here: https://pulitzercenter.org/reporting/what-choice-do-we-have\nCheck out Jack and Brower\'s family Facebook page for more pictures of their trek from Utqiagvik to Fairbanks!', 'Water conservation includes all the policies, strategies and activities made to sustainably manage the natural resource fresh water, to protect the water environment, and to meet the current and future human demand. Population, household size, and growth and affluence all affect how much water is used. Factors such as climate change have increased pressures on natural water resources especially in manufacturing and agricultural irrigation. Many US cities have already implemented policies aimed at water conservation, with much success.\nThe goals of water conservation efforts include:\n- Ensuring availability of water for future generations where the withdrawal of freshwater from an ecosystem does not exceed its natural replacement rate.\n- Energy conservation as water pumping, delivery and wastewater treatment facilities consume a significant amount of energy. In some regions of the world over 15% of total electricity consumption is devoted to water management.\n- Habitat conservation where minimizing human water use helps to preserve freshwater habitats for local wildlife and migrating waterfowl, but also water quality.\nThe key activities that benefit water conservation are as follows :\n- Any beneficial reduction in water loss, use and waste of resources.\n- Avoiding any damage to water quality.\n- Improving water management practices that reduce the use or enhance the beneficial use of water.\nOne strategy in water conservation is rain water harvesting. Digging ponds, lakes, canals, expanding the water reservoir, and installing rain water catching ducts and filtration systems on homes are different methods of harvesting rain water. Harvested and filtered rain water could be used for toilets, home gardening, lawn irrigation, and small scale agriculture.\nAnother strategy in water conservation is protecting groundwater resources. When precipitation occurs, some infiltrates the soil and goes underground. Water in this saturation zone is called groundwater. Contamination of groundwater causes the groundwater water supply to not be able to be used as resource of fresh drinking water and the natural regeneration of contaminated groundwater can takes years to replenish. Some examples of potential sources of groundwater contamination include storage tanks, septic systems, uncontrolled hazardous waste, landfills, atmospheric contaminants, chemicals, and road salts. Contamination of groundwater decreases the replenishment of available freshwater so taking preventative measures by protecting groundwater resources form contamination is an important aspect of water conservation.\nAn additional strategy to water conservation is practicing sustainable methods of utilizing groundwater resources. Groundwater flows due to gravity and eventually discharges into streams. Excess pumping of groundwater leads to a decrease in groundwater levels and if continued it can exhaust the resource. Ground and surface waters are connected and overuse of groundwater can reduce and, in extreme examples, diminish the water supply of lakes, rivers, and streams. In coastal regions, over pumping groundwater can increase saltwater intrusion which results in the contamination of groundwater water supply. Sustainable use of groundwater is essential in water conservation.\nA fundamental component to water conservation strategy is communication and education outreach of different water programs. Developing communication that educates science to land managers, policy makers, farmers, and the general public is another important strategy utilized in water conservation. Communication of the science of how water systems work is an important aspect when creating a management plan to conserve that system and is often used for ensuring the right management plan to be put into action.\nWater conservation programs involved in social solutions are typically initiated at the local level, by either municipal water utilities or regional governments. Common strategies include public outreach campaigns, tiered water rates (charging progressively higher prices as water use increases), or restrictions on outdoor water use such as lawn watering and car washing. Cities in dry climates often require or encourage the installation of xeriscaping or natural landscaping in new homes to reduce outdoor water usage. Most urban outdoor water use in California is residential, illustrating a reason for outreach to households as well as businesses.\nOne fundamental conservation goal is universal metering. The prevalence of residential water metering varies significantly worldwide. Recent studies have estimated that water supplies are metered in less than 30% of UK households, and about 61% of urban Canadian homes (as of 2001). Although individual water meters have often been considered impractical in homes with private wells or in multifamily buildings, the U.S. Environmental Protection Agency estimates that metering alone can reduce consumption by 20 to 40 percent. In addition to raising consumer awareness of their water use, metering is also an important way to identify and localize water leakage. Water metering would benefit society in the long run it is proven that water metering increases the efficiency of the entire water system, as well as help unnecessary expenses for individuals for years to come. One would be unable to waste water unless they are willing to pay the extra charges, this way the water department would be able to monitor water usage by public, domestic and manufacturing services.\nSome researchers have suggested that water conservation efforts should be primarily directed at farmers, in light of the fact that crop irrigation accounts for 70% of the world\'s fresh water use. The agricultural sector of most countries is important both economically and politically, and water subsidies are common. Conservation advocates have urged removal of all subsidies to force farmers to grow more water-efficient crops and adopt less wasteful irrigation techniques.\nNew technology poses a few new options for consumers, features such and full flush and half flush when using a toilet are trying to make a difference in water consumption and waste. Also available are modern shower heads that help reduce wasting water: Old shower heads are said to use 5-10 gallons per minute, while new fixtures available are said to use 2.5 gallons per minute and offer equal water coverage.\nThe Home Water Works website contains useful information on household water conservation. Contrary to popular view, experts suggest the most efficient way is replacing toilets and retrofitting washers.\nWater-saving technology for the home includes:\n- Low-flow shower heads sometimes called energy-efficient shower heads as they also use less energy\n- Low-flush toilets and composting toilets. These have a dramatic impact in the developed world, as conventional Western toilets use large volumes of water\n- Dual flush toilets created by Caroma includes two buttons or handles to flush different levels of water. Dual flush toilets use up to 67% less water than conventional toilets\n- Faucet aerators, which break water flow into fine droplets to maintain ""wetting effectiveness"" while using less water. An additional benefit is that they reduce splashing while washing hands and dishes\n- Raw water flushing where toilets use sea water or non-purified water\n- Waste water reuse or recycling systems, allowing:\n- Rainwater harvesting\n- High-efficiency clothes washers\n- Weather-based irrigation controllers\n- Garden hose nozzles that shut off water when it is not being used, instead of letting a hose run.\n- Low flow taps in wash basins\n- Swimming pool covers that reduce evaporation and can warm pool water to reduce water, energy and chemical costs.\n- Automatic faucet is a water conservation faucet that eliminates water waste at the faucet. It automates the use of faucets without the use of hands.\nMany water-saving devices (such as low-flush toilets) that are useful in homes can also be useful for business water saving. Other water-saving technology for businesses includes:\n- Waterless urinals\n- Waterless car washes\n- Infrared or foot-operated taps, which can save water by using short bursts of water for rinsing in a kitchen or bathroom\n- Pressurized waterbrooms, which can be used instead of a hose to clean sidewalks\n- X-ray film processor re-circulation systems\n- Cooling tower conductivity controllers\n- Water-saving steam sterilizers, for use in hospitals and health care facilities\n- Rain water harvesting\n- Water to Water heat exchangers.\nFor crop irrigation, optimal water efficiency means minimizing losses due to evaporation, runoff or subsurface drainage while maximizing production. An evaporation pan in combination with specific crop correction factors can be used to determine how much water is needed to satisfy plant requirements. Flood irrigation, the oldest and most common type, is often very uneven in distribution, as parts of a field may receive excess water in order to deliver sufficient quantities to other parts. Overhead irrigation, using center-pivot or lateral-moving sprinklers, has the potential for a much more equal and controlled distribution pattern. Drip irrigation is the most expensive and least-used type, but offers the ability to deliver water to plant roots with minimal losses. However, drip irrigation is increasingly affordable, especially for the home gardener and in light of rising water rates. Using drip irrigation methods can save up to 30,000 gallons of water per year when replacing irrigation systems that spray in all directions. There are also cheap effective methods similar to drip irrigation such as the use of soaking hoses that can even be submerged in the growing medium to eliminate evaporation.\nAs changing irrigation systems can be a costly undertaking, conservation efforts often concentrate on maximizing the efficiency of the existing system. This may include chiseling compacted soils, creating furrow dikes to prevent runoff, and using soil moisture and rainfall sensors to optimize irrigation schedules. Usually large gains in efficiency are possible through measurement and more effective management of the existing irrigation system. The 2011 UNEP Green Economy Report notes that ""[i]mproved soil organic matter from the use of green manures, mulching, and recycling of crop residues and animal manure increases the water holding capacity of soils and their ability to absorb water during torrential rains"", which is a way to optimize the use of rainfall and irrigation during dry periods in the season.\nWater shortage has become an increasingly difficult problem to manage. More than 40% of the world\'s population live in a region where the demand for water exceeds its supply. The imbalance between supply and demand, along with persisting issues such as climate change and exponential population growth, has made water reuse a necessary method for conserving water. There are a variety of methods used in the treatment of waste water to ensure that it safe to use for irrigation of food crops and/or drinking water.\nSeawater desalination requires more energy than the desalination of fresh water. Despite this, many seawater desalination plants have been built in response to water shortages around the world. This makes it necessary to evaluate the impacts of seawater desalination and to find ways to improve desalination technology. Current research involves the use of experiments to determine the most effective and least energy intensive methods of desalination.\nSand filtration is another method used to treat water. Recent studies show that sand filtration needs further improvements, but it is approaching optimization with its effectiveness at removing pathogens from water. Sand filtration is very effective at removing protozoa and bacteria, but struggles with removing viruses. Large-scale sand filtration facilities also require large surface areas to accommodate them.\nThe removal of pathogens from recycled water is of high priority because wastewater always contains pathogens capable of infecting humans. The levels of pathogenic viruses have to be reduced to a certain level in order for recycled water to not pose a threat to human populations. Further research is necessary to determine more accurate methods of assessing the level of pathogenic viruses in treated wastewater.\n- Al Baydha Project\n- Berlin Rules on Water Resources\n- Conservation biology\n- Conservation ethic\n- Conservation movement\n- Deficit irrigation\n- Ecology movement\n- Environmental protection\n- Pan evaporation\n- Peak water\n- Sustainable agriculture\n- Utility submeter\n- Water cascade analysis\n- Water metering\n- Water pinch\n- WaterSense - EPA conservation program\n- ""Water conservation « Defra"". defra.gov.uk. 2013. Retrieved January 24, 2013.\n- ""Cases in Water Conservation: How Efficiency Programs Help Water Utilities Save Water and Avoid Costs"" (PDF). EPA.gov. US Environmental Protection Agency.\n- Hermoso, Virgilio; Abell, Robin; Linke, Simon; Boon, Philip (2016). ""The role of protected areas for freshwater biodiversity conservation: challenges and opportunities in a rapidly changing world"". Aquatic Conservation: Marine and Freshwater Ecosystems. 26 (S1): 3–11. doi:10.1002/aqc.2681.\n- Vickers, Amy (2002). Water Use and Conservation. Amherst, MA: water plow Press. p. 434. ISBN 1-931579-07-5.\n- Geerts, S.; Raes, D. (2009). ""Deficit irrigation as an on-farm strategy to maximize crop water productivity in dry areas"". Agric. Water Manage. 96 (9): 1275–1284. doi:10.1016/j.agwat.2009.04.009.\n- Kumar Kurunthachalam, Senthil (2014). ""Water Conservation and Sustainability: An Utmost Importance."". Hydrol Current Res.\n- ""Description of the Hydrologic Cycle"". http://www.nwrfc.noaa.gov/rfc/. NOAA River Forecast Center. External link in\n- ""Potential threats to Groundwater"". http://www.groundwater.org/. The Groundwater Foundation. External link in\n- Jorge A. Delgado, Peter M. Groffman, Mark A. Nearing, Tom Goddard, Don Reicosky, Rattan Lal, Newell R. Kitchen, Charles W. Rice, Dan Towery, and Paul Salon (2011). ""Conservation Practices to Mitigate and Adapt to Climate Change"". Journal of Soil and Water Conservation.\n- ""Persuading the public to reduce bottled water consumption"" (pdf). European Commission. 3 September 2015.\n- ""Water - Use It Wisely."" U.S. multi-city public outreach program. Park & Co., Phoenix, AZ. Accessed 2010-02-02.\n- Santos, Jessica; van der Linden, Sander (2016). ""Changing Norms by Changing Behavior: The Princeton Drink Local Program"". Environmental Practice. 18 (2): 1–7. doi:10.1017/S1466046616000144.\n- U.S. Environmental Protection Agency (EPA) (2002). Cases in Water Conservation (PDF) (Report). Retrieved 2010-02-02. Document No. EPA-832-B-02-003.\n- Albuquerque Bernalillo County Water Utility Authority (2009-02-06). ""Xeriscape Rebates"". Albuquerque, NM. Retrieved 2010-02-02.\n- Heberger, Matthew (2014). ""Issue Brief"" (PDF). urban Water Conservation and efficiency Potential in California: 12.\n- ""Time for universal water metering?"" Innovations Report. May 2006.\n- Environment Canada (2005). Municipal Water Use, 2001 Statistics (PDF) (Report). Retrieved 2010-02-02. Cat. No. En11-2/2001E-PDF. ISBN 0-662-39504-2. p. 3.\n- EPA (2010-01-13). ""How to Conserve Water and Use It Effectively"". Washington, DC. Retrieved 2010-02-03.\n- Pimentel, Berger; et al. (October 2004). ""Water resources: agricultural and environmental issues"". BioScience. 54 (10): 909. doi:10.1641/0006-3568(2004)054[0909:WRAAEI]2.0.CO;2.\n- ""Water-Saving Technologies"". WaterSense: An EPA Partnership Program. US Environmental Protection Agency.\n- UNEP, 2011, Towards a Green Economy: Pathways to Sustainable Development and Poverty Eradication, www.unep.org/greeneconomy\n- Wastewater Reuse and Current Challenges - Springer. doi:10.1007/978-3-319-23892-0.\n- Elimelech, Menachem; Phillip, William A. (2011-08-05). ""The Future of Seawater Desalination: Energy, Technology, and the Environment"". Science. 333 (6043): 712–717. doi:10.1126/science.1200488. ISSN 0036-8075. PMID 21817042.\n- Han, Songlee; Rhee, Young-Woo; Kang, Seong-Pil (2017-02-17). ""Investigation of salt removal using cyclopentane hydrate formation and washing treatment for seawater desalination"". Desalination. 404: 132–137. doi:10.1016/j.desal.2016.11.016.\n- Seeger, Eva M.; Braeckevelt, Mareike; Reiche, Nils; Müller, Jochen A.; Kästner, Matthias (2016-10-01). ""Removal of pathogen indicators from secondary effluent using slow sand filtration: Optimization approaches"". Ecological Engineering. 95: 635–644. doi:10.1016/j.ecoleng.2016.06.068.\n- Vries, D.; Bertelkamp, C.; Kegel, F. Schoonenberg; Hofs, B.; Dusseldorp, J.; Bruins, J. H.; de Vet, W.; van den Akker, B. ""Iron and manganese removal: Recent advances in modelling treatment efficiency by rapid sand filtration"". Water Research. doi:10.1016/j.watres.2016.11.032.\n- ""Slow Sand Filtration"". CDC.gov. May 2, 2014.\n- Gerba, Charles P.; Betancourt, Walter Q.; Kitajima, Masaaki. ""How much reduction of virus is needed for recycled water: A continuous changing need for assessment?"". Water Research. doi:10.1016/j.watres.2016.11.020.\n- Water Efficiency Magazine — Journal for Water Conservation Professionals\n- Water Conservation Community of Interest — American Water Works Association\n- Water Conservation — Water Quality Information Center, National Agricultural Library, U.S. Department of Agriculture\n- Alliance for Water Efficiency (AWE)\n- Smart WaterMark — Australian Water Conservation Label']"	['<urn:uuid:950aba5e-8f07-477f-b6e4-57d20e3fbdf9>', '<urn:uuid:ca9cc72d-be42-41ac-aa5a-377a7c30c215>']	open-ended	with-premise	long-search-query	distant-from-document	multi-aspect	expert	2025-05-01T23:46:40.222380	11	96	3140
380	What kinds of hearing problems can affect the inner ear, and how much more likely are people to develop memory issues because of them?	Several conditions can affect the inner ear, including Meniere's disease (which causes severe hearing loss and dizziness), labyrinthitis (inflammation of the balance organ), acoustic neuroma (a benign tumor causing hearing loss and balance problems), and trauma to the inner ear. Regarding memory issues, research shows that hearing loss increases the risk of dementia, with every 10 decibels of hearing loss increasing the dementia risk by 20%. For people aged 60 and up, hearing loss was linked to 36% of the dementia risk.	"['Hearing, Dizziness and Balance\nWe are proud to offer the following audiologic services:\n- Newborn hearing evaluations\n- Pediatric and adult comprehensive hearing evaluations\n- Balance and dizziness testing*\n- Dispensing and fitting of hearing aids for all ages\n- Bone anchored hearing aid services (including trial, surgery & programming)\n- Central Auditory Processing Disorder (CAPD) evaluations*\n- Cochlear implant programming\n- Tinnitus (ringing or buzzing in the ear) evaluations and management\n- Concussion evaluations and management*\n- Dispensing and fitting of assistive listening devices and hearing aid accessories\n- Custom hearing protection for noise management, including hunter’s earplugs\n- Custom swimmer’s earplugs for water precaution\nPlease see below for information on hearing loss and balance disorders.\nHearing loss is the partial or total loss of hearing in one or both ears. Loss of hearing can be temporary or permanent. Several disorders can affect the hearing in adults as well as children. If left untreated, hearing loss can have a significant impact on your employment, education, relationships and general well-being. Please click here for a hearing loss check list to help determine if you may need a hearing evaluation by an audiologist.\nThe 3 common types of hearing loss include:\n- Conductive hearing loss: This is the condition where the sound is not conducted efficiently through the outer ear canal to the eardrum and the tiny bones of the middle ear (ossicles).\n- Sensorineural hearing loss: This is the most common type of permanent hearing loss, resulting from damage to the tiny hair cells or to the nerve endings from the inner ear to the brain.\n- Mixed hearing loss: This type of hearing loss occurs in people who have both conductive and sensorineural types of hearing loss.\nHearing loss can be congenital (present at birth) or acquired (may appear later). Common causes of conductive hearing loss include, ear infections, middle ear fluid, allergies, perforated eardrum, ear canal infection, benign tumors, impacted earwax, and anatomic abnormalities.\nSome of the possible causes of sensorineural hearing loss include, illness, aging, head trauma, prolonged exposure to loud noises, certain drugs, and inner ear malformation.\nHearing loss may be gradual or sudden, can range from mild to profound, and may involve one or both ears. Symptoms may include, dull hearing, difficulty understanding speech, ear pain, ringing or buzzing in the ear, itching, drainage, and vertigo (dizziness). Other symptoms include need for high volume when listening to the radio or television, avoiding social situations, and depression. Tinnitus (ringing or buzzing in the ear) maybe present with or without significant hearing loss and occur in one or both ears. Please click here for more information on tinnitus.\nYour doctor will diagnose hearing loss by asking about your symptoms and with a detailed physical examination of the ears using an instrument called otoscope. Your doctor may also recommend hearing evaluation that may comprises of:\n- Pure tone audiometry: This test determines how well a person can hear sound travelling through the ear canal and through the skull.\n- Speech reception and word recognition tests: To check your ability to hear and understand speech.\n- Acoustic immittance tests (tympanometry): This test evaluates the eardrum’s and middle ear’s ability to receive sound energy.\n- Otoacoustic emissions (OAE) testing: This test measures the sounds given off by the inner ear.\n- Auditory brain stem response (ABR) testing: This objective test may be administered to test the auditory nerve pathways in the brain.\n- Tuning fork test: This test helps to differentiate conductive hearing loss from sensorineural hearing loss with the help of tuning fork.\nWhen an injury or tumor is suspected other imaging techniques such as CT or MRI scan of the head may be done.\nTreatment for temporary or conductive hearing loss depends on its cause and is often treated successfully. An ear infection is treated with the antibiotics, and blocked ear with earwax is treated by removing the wax using special instruments. Corticosteroids may be used in the case of sudden sensorineural hearing loss. If medical and/or surgical treatment is unsuccessful in correcting a temporary or conductive type hearing loss, then hearing devices (such as traditional or bone anchored hearing aids) may be a treatment option.\nIn the case of permanent hearing loss, hearing devices (such as traditional hearing aids) or hearing implants (such as bone anchored hearing aids or cochlear implants) may be used to restore your hearing and to help you communicate more easily. If a hearing loss presents as severe-to-profound or worsens to a severe-to-profound hearing loss, then a cochlear implant may be an option; however, further testing is needed prior to pursuing such options.\nA cochlear implant is a small complex electronic device that is surgically placed within the inner ear to help transmit sound via an electrical signal. It consists of external components (a microphone, a speech processor, and a transmitter) and an implanted component (a receiver/stimulator, and an electrode array). The microphone picks up sound from the environment and sends the signal to a speech processor which selects analyses and digitizes the sound signals before they are sent to a transmitter. This in turn transmits these digitized sound signals via radio waves to the internal implant where the fibers of the auditory nerve are electrically stimulated and sound sensations are perceived. Please click here for more information on cochlear implants.\nDizziness & balance problems\nDizziness means feeling light-headed or the feeling of imbalance or unsteadiness, and is a nonspecific term. Lightheadedness is a feeling of fainting and may be due to low blood pressure, illness, or other factors. Vertigo is a feeling of spinning sensation with loss of balance and may be due to a balance disorder within the inner ear.\nDizziness is often caused by decreased blood supply to the brain and the impaired blood supply may be because of low blood pressure or dehydration which may be caused by diarrhea, fever, and vomiting. Elderly people may experience lightheadedness when they get up quickly from a lying or seated position. Lightheadedness may also be associated with flu, low blood sugar, sweating, and common cold. Vertigo is often associated with inner ear problems or disorders. Other conditions that lead to dizziness include heart problems and stroke and in these cases patients may also develop symptoms like chest pain, loss of speech, and change in vision.\nThe most common causes of vertigo may include:\n- Benign paroxysmal positional vertigo (BPPV) – The crystals in the inner ear become dislodged and move to one of the semicircular canals and cause irritation. It is caused because of sudden positioning of the head and most commonly occurs in older people.\n- Labyrinthitis – Is an ear disorder that involves inflammation of the balance organ in the inner ear which commonly occurs after a viral infection.\n- Meniere’s disease – Is an inner ear disorder that causes severe hearing loss, ringing in the ears and dizziness. The disease can affect one or both ears.\n- Acoustic neuroma – Is a benign tumor of the ear causing ringing in the ears, hearing loss and dizziness and balance problems.\n- Trauma to the inner ear\n- Barotrauma causes damage to the inner ear and vertigo due to pressure changes between the middle and inner ear.\nYou may feel spinning sensation associated with loss of balance and unsteadiness. Other symptoms include decreased hearing and ringing in the ear (tinnitus). Nausea and vomiting may be also associated with vertigo causing dehydration and weakness.\nYour doctor will perform a thorough physical examination and may ask you about the associated symptoms and past medical history. Hearing tests may be recommended to make sure that that the middle ear, the cochlea, and the auditory nerve are functioning accurately. Additional specialized diagnostic testing may be ordered to help determine the source or cause of the vertigo.\nDizziness is a symptom and not a disease and if it is not treated at the right time, it may lead to serious health problems.\nTreatment includes treating underlying disease conditions, for example:\n- Dehydration – Drink more amounts of liquids or fluids and in cases where you are unable to drink water then intravenous administration may be preferred\n- Fever or infection – Medications for fever or antibiotics to treat infections may be prescribed\n- If dizziness is due to heart conditions or anxiety related disorders necessary treatment may be initiated\n- Vertigo from BPPV or labyrinthitis is often treated with vestibular rehabilitation exercises, also referred to as Epley manoeuvres. It involves positioning and manipulating the patients head to remove the crystals from the semicircular canals and thus reducing the inflammation.\n- Medications such as stemetil may be prescribed to reduce the vertigo symptoms inflammation within the vestibular system\n- Corticosteroids and antiviral medications such as acyclovir or valacyclovir may be prescribed for viral infections causing the labyrinthitis\n- Surgery may be needed in patients with acoustic neuroma or other anatomical disorders of the ear.', 'Living with untreated hearing loss is complicated and can lead to several communication difficulties. You might find it hard to talk on the phone or struggle to order a coffee at your favorite cafe. However, as we\'ll see later in this post, untreated hearing loss causes far more than these communication issues.\nMany hearing aid users wait years after their initial hearing test results before seeking treatment. What are the reasons why people put off seeking help for so long? There are two key reasons for this:\nHearing loss is a gradual process. The hairs or nerve cells in the cochlea transmit sound signals to the brain that can wear out with age and loud noise exposure. This process can last years or even decades. Because it is so slow, many people decide to neglect their hearing loss for long periods.\nHearing loss is commonly regarded as a sign of aging. Many people perceive hearing loss as a danger to their physical independence. They see it as one of the physical signals that they are aging. Those who take pride in their independence will find this line of thinking especially appealing.\nBut treatment needs to be done early for the best results. And the longer they wait, the more complex treatment becomes.\nThe potential consequences of untreated hearing loss\nHearing loss is often undiagnosed and untreated by American adults for the reasons mentioned above. Because of this, we often learn to change our behaviors to adapt. Although these temporary fixes can work in the short term, untreated hearing loss can have several adverse health and overall wellbeing implications. Here are some examples:\n**It is important to remember that while some of these studies show a correlation between these conditions and hearing loss, but we do not yet know if there is a causal relationship.\nAn increase in the number of injuries\nAccording to a study published by the Brigham and Women\'s Hospital in Boston, adults with hearing loss are more likely to be involved in incidents or injuries. The study used data from the National Health Interview Survey, a nationwide survey in which 232.2 million Americans answered questions about their health and wellbeing from 2007 to 2015. The survey contained questions about people\'s hearing health as well as reports on any recent injuries.\nAfter reviewing the results, researchers discovered that those who had ""a lot of trouble hearing"" were 50 percent more likely to be injured. 6.6 million people confirmed having been injured in an accident, with many of them rating their hearing as ""poor."" The research concluded that the worse the hearing loss, the more likely adults were involved in incidents.\nAn increase in hospital costs\nAccording to a report by the Johns Hopkins University Bloomberg School of Public Health, people with untreated hearing loss have a much higher total healthcare cost than those with good hearing. Over a decade, the study found that older adults with untreated hearing loss had 46 percent higher healthcare costs, averaging $22,434 per person. The impact was noticeable within two years.\nWhat explains this rise in healthcare costs? According to the report, over ten years, those with untreated hearing loss had a 50% higher risk of dementia, a 40% higher risk of depression, and a nearly 30% higher risk of falling than those without hearing loss.\nAn increase in the risk of dementia\nHearing loss has been linked to an increased risk of dementia, according to a 2011 report. Professor Frank Lin, Professor of Otolaryngology at the John Hopkins School of Medicine in Baltimore, led the research, which attracted a team of scientists from around the country.\nA total of 600 adults were included in the report. These individuals were followed until 2008 after completing a series of assessments to determine their cognitive and hearing abilities between 1990 and 1994. Scientists were also looking for Alzheimer\'s disease or dementia symptoms. A third of the participants had hearing loss, while the rest had no issues hearing. At the start of the research, none of the participants had dementia.\nThe researchers concluded that those who had hearing loss at the start of the study were much more likely to develop dementia, with the severity of the hearing loss suggesting a higher risk of dementia. Dr. Frank Lin of Baltimore determined that every 10 decibels of hearing loss increased the risk of dementia by 20%. Hearing loss was linked to 36% of the dementia risk in participants aged 60 and up.\nIf you have untreated hearing loss, the best time to seek hearing treatment was yesterday. The second best time is now. Contact us today to set up an appointment!']"	['<urn:uuid:13f018d8-08e5-4df0-83d3-f0d145734146>', '<urn:uuid:2c2a9669-0188-4a42-b418-5122f34eaa76>']	factoid	direct	verbose-and-natural	distant-from-document	multi-aspect	novice	2025-05-01T23:46:40.222380	24	82	2261
381	I'm studying plant evolution and I'm curious about what makes mosses unique in their life cycle - what's the critical developmental change they need to complete their life cycle?	In mosses, there is a hormone-induced switch from two dimensional filamentous growth to the easily visible leafy plant, and this change is critical to completion of the moss life cycle.	"[""Cellular & Molecular Biology, Plant Biology\nMy research interests are focused in the areas of plant physiology and development. I am particularly interested in plant signal transduction, that is, how a plant (or cell) perceives its environment, whether physical or physiological (e.g., hormones), and how such perception leads to an appropriate response in terms of growth and development of the plant. I am investigating such signaling within two different contexts. In one case, I am working with two different mosses in an effort to understand a hormone-induced switch from two dimensional filamentous growth to the easily visible leafy plant; this change is critical to completion of the moss life cycle. In the second case, I am working with a flowering plant, Arabidopsis thaliana, to understand the role of calcium ions, in particular, a specific calcium ion-binding protein, in the development of the floral organs. A mutant plant that cannot produce this protein is sterile as both the stamens and the pistil are defective. Both projects involve the use of multiple approaches: genetic, cellular, molecular, and biochemical.\nPlant Ecology & Morphology\nResearch in my lab concerns the ecology and morphology of ferns and invasive plants. Ferns are particularly interesting in that they are, in terms of species numbers, the most successful group of plants aside from flowering plants, and can dominate the understory of some forests (e.g., up to 70% of the flora on tropical islands). They also possess a number of intriguing biological traits, such as a free-living, minute, and morphologically simple gametophyte that is responsible for colonization and sexual reproduction; a gender-bending pheromone system called antheridiogen that is also a window into the hormonal controls of development and, hence, early plant evolution; a propensity for allopolyploid evolution resulting in the largest genomes of all life on Earth; and unusual growth forms such as the woodless tree ferns. All of the research in my lab regarding invasive plants has focused, thus far, on the Chinese “tree-of-heaven”, Ailanthus altissima. Ailanthus possesses all of the traits associated with invasiveness, including a rapid growth and life cycle, asexual reproduction, prolific sexual reproduction, production of an allelochemical (a toxin that reduces germination, growth, and reproduction in neighboring plants), tolerance to a wide range of soil and climatic conditions, and has escaped many of its predators and diseases in China. Ailanthus is now found in 46 of the lower 48 states and can be found in North, Central, and South America, and although common in urban centers is increasingly widespread in North American forests. Very little is known about Ailanthus, however, it is likely to have impacts on North American forest biodiversity, succession, nutrient dynamics, and foodweb structure, and in turn to have adapted to North American competitors, predators, diseases, and symbionts. I have lines of inquiry regarding all of these topics here in Michigan and, when it comes to ferns, also at the Luquillo Long Term Ecological Station in Puerto Rico.\nResearch in our lab focuses on various aspects of mammalian ecology including habitat selection and use, behavior, and reproduction. The majority of our projects are applied in nature and aim to provide information aiding resource management professionals in more effectively manage the species of interest. Nearly all of our research is field based (often in bad weather at odd times of the day) and most projects involve radio telemetry tracking. Recent/ongoing projects examine: Impacts of a Savannah Restoration on Small Mammal Communities, Winter and Summer Southern Flying Squirrel Den Tree Characteristics and Social Behavior, American Marten Resting Site Selection, Population Genetic Assessment, and Den Site Selection, Raccoon Round Worm Infection Rates.\nplant ecology, ecological restoration\nEcological Restoration Work, Bass River Recreation Area, Ottawa County Michigan\nBetween 1999 and 2005, we conducted a study to determine the feasibility of establishing native warm-season grasses on a spotted knapweed-infested site within the Bass River Recreation Area (Section 12, T7N R15W, Ottawa County, Michigan). Native grasses were successfully established using a variety of site preparation treatments, but spotted knapweed persisted at low levels (MacDonald et al., 2003). Superimposition of annual mid-spring burning beginning in 2003 further suppressed spotted knapweed and increased the dominance of native warm-season grasses (MacDonald et al., 2007). The persistence of spotted knapweed in communities with more forbs and fewer grasses remains uncertain, as does the interaction of fire with additional knapweed control measures such as hand pulling or initial herbicide treatments. In 2009, we began a study to examine the interactive effects of site preparation treatments, hand pulling of knapweed, and burning on the establishment of a mixture of native grass and forb species on this knapweed-infested site. As of 2011, native grass and forb species have become established on all plots, hand pulling has reduced knapweed densities to very low levels, and burning is planned to commence in April, 2012. TI students would participate in annual treatment application and plot measurement activities as part of an ongoing long-term ecological restoration research project.\nEcology, Global Change\nMy research interests are broadly in the areas of conservation biology, biodiversity informatics, and effects of global change – land, sea level, and climate change. Recent projects have included the following lines of inquiry: 1) the study of deforestation, forest fragmentation, and land-use change for biodiversity conservation and conservation priority-setting, and 2) applications of spatial databases and analytic tools together with biodiversity databases and informatics to explore theoretical considerations in ecology and conservation biology (niche vs. neutral theory), aid the discovery of endangered or rare species, model the spread of invasive species, and predict the effects of climate change and sea level rise on species' distributions and ecosystems. More information about my work and papers for download are available at http://works.bepress.com/shaily_menon/\nMicrobiology; Molecular Biology\nMy lab is currently investigating potentially new antibiotics. We have been testing chemically synthesized compounds against Gram + bacteria. We have found a class of compounds that inhibit only Gram + organisms, including MRSA (methicillin resistant Staph. aureus), VRE (vancomycin resistant enterococci) and C.diff (Clostridium difficile). We are working in a collaborative effort with Dr. Robert Smart and Dr. William Schroeder in the GVSU Chemistry Department. Additionally, we are exploring potential antibiotics that are produced by various plants.\nI conduct research in aquatic habitat restoration and biomonitoring, with a particular emphasis on stream ecosystems. My background is in the use of functional metrics, such as nutrient cycling, rates of primary production and respiration, and decomposition to assess stream integrity.\nOngoing projects include monitoring of the consequences and recovery of dam removal, the effectiveness of stormwater management through constructed wetlands on the GVSU campus, assessing food web structure through use of stable isotope analyses, as well as longer term projects to assess the role of floodplain connectivity on the lower Grand River. Projects involve the functional metrics described above as well as surveys linking biotic (including algae, plankton, aquatic plant, macroinvertebrates, and fish), physical, and chemical characteristics.\nPlant Evolution and Development, Mycorrhizal Symbiosis\nMy research interests are wide-ranging but mainly focused on characterizing the evolution and development of the key characteristics of lands plants that have contributed to their success. I choose to study the overlooked, yet phylogenetically important, ferns, lycopods (e.g. clubmosses), and gymnosperms (e.g. pines) in order to fill in major gaps in our knowledge of the almost 500 million year history of land plants. I employ a diverse set of techniques including molecular systematics, microscopy, and developmental genetics to answer these questions. I have 2 broad areas of research: 1) the study of the evolution, development and ecology of a type of mycorrhizal symbiosis (plant-fungal association) considered crucial to the establishment and diversification of land plants, and 2) understanding the evolution of male and female cones in gymnosperms.\nPage last modified August 31, 2012""]"	['<urn:uuid:c276c9a0-c11d-45d0-9a52-69dc3157adbc>']	factoid	with-premise	verbose-and-natural	similar-to-document	single-doc	expert	2025-05-01T23:46:40.222380	29	30	1283
383	How long did Yacov Sharir and Keith Saunders work in dance?	Yacov Sharir worked in dance from at least 1977 (his earliest video recording) to 2015, spanning about 38 years. Keith Saunders worked with Dance Theatre of Harlem for 40 years, from 1975 to at least 2018.	['Choreographer, dancer, artist and teacher Yacov Sharir recently donated his archive to the Fine Arts Library. Sharir moved to Austin in 1978 where he founded the American Deaf Dance Company and was hired on as faculty at UT shortly thereafter. He developed a dance program that has become a model for universities across the country, founding the university’s professional company-in-residence, the Sharir Dance Company, in 1982, which became Sharir+Bustamante Danceworks (SBDW) in 1998.\nThe lengthy project of processing the collection of materials from Sharir’s professional career required the persistence of graduate researcher Katie Van Winkle, an advanced degree candidate in the College of Fine Arts.\nVan Winkle took time to answer some questions about the project and her impressions of the experience.\nTex Libris: How did you get involved in processing the Sharir archive?\nKatie Van Winkle: I’m a Ph.D. candidate in Performance as Public Practice (PPP), a program in the Department of Theatre & Dance. When I began my studies in the fall 2013, a fellow PPP student named Cassidy Browning was working with Dr. Sharir as a research assistant. Cassidy moved on to dissertation work, and recommended me as a replacement, just as Beth Kerr (Theatre & Dance Librarian in the Fine Arts Library) and Dr. Sharir established the archive project.\nI have found always physical and digital archives invaluable in my work both as a scholar and as an artist–but I have almost zero training in archival work. At UT, I participated in a one-day workshop with the American Theatre Archive Project (ATAP), and a theory-based course on “Archive and Ephemera.” Instead, I have some experience in inventing and implementing technological solutions for arts management: for example, as a Dramaturgy Fellow at Center Stage in Baltimore I developed an early prototype of the National New Play Network’s New Play Exchange (http://nnpn.org/programs/new-play-exchange) through a Dramaturgy-Driven Grant from the Literary Managers and Dramaturgs of the Americas.\nWhat did the process consist of? What was the scope, and how much in terms of materials and types of materials were there?\nKVW:The Sharir/Sharir+Bustamante Dance Collection is a gift archive from Dr. Sharir to UT’s Fine Arts Library. It consists of video documentation of many hundreds of dances between 1977 and 2015, as well as paper documentation (programs, photographs, press clippings, etc.) of the work of the American Deaf Dance Company, the Sharir Dance Company, and Sharir+Bustamante Danceworks. A large selection of this archive has been digitized by Anna Lamphear and Katie Thornton and other staff members of UT Libraries’ Preservation and Digitization Services. The digitized collection is hosted on Texas ScholarWorks.\nThis symposium celebrates the public launch of the first phase of the digitization process: the videos! The paper archive will be digitized in 2017 as phase two of the project.\nDr. Sharir’s office contained 671 individual video objects. Since the earliest was dated 1977, and the latest 2015, these objects embody four decades of video technology: U-matic (3/4″), VHS, Hi8, Betacam, Digital Video Cassette and Mini DV, DVD, and born-digital files stored only on hard drives: .mov and .mp4.\nSome of these 671 objects were labeled with titles and dates and choreographers and other pertinent information; some were not labeled at all. Some of the objects documented multiple dances, some from multiple events with multiple choreographers or dance companies participating; others documented a single dance.\nThe major challenge we faced was how to balance efficiency and depth of coverage. We wanted to ensure that the digital collection represented as many unique dance works as possible, without wasting time digitizing duplicate tapes, but the inconsistency of visible information made this difficult. Also challenging: there was no way to tell if the physical object had degraded beyond use without playing/digitizing it at the PCL.\nHere’s the sequence of my work:\n- In the fall of 2013, I created an inventory of most of the video items (we discovered more later on). I ordered the items chronologically (as far as possible), gave each a unique number (0001-0671), and made a spreadsheet detailing all “metadata” available at that point. Depending on the item, this could include: unique number, date, item format and brand, event title, individual dance titles, event type (rehearsal or performance), run time, dance companies, choreographers, venues and sites, videographers and their notes, performers, designers, musicians, composers, other collaborators, and notes.\n- Sharir and I then began selecting “batches” of video items to send to the PCL, 20 at a time. We prioritized based on questions like “how old is this tape?” (older objects got priority); “how significant is this event/dance?” (Dr. Sharir, of course, was the expert of this); and “have we digitized any version of this event/dance before?” (new/unique pieces got priority).\n- In January 2014, I delivered the first batch of 20 tapes to Anna and Katie in the PCL, where they worked their magic using lots of devices that I do not recognize or understand! I continued to deliver and pick up batches of tapes through the summer of 2016.\n- Anna and Katie digitized 398 video objects between January 2014 and September 2016. WOW.\n- After they uploaded each batch to the libraries server as .mp4 files, Dr. Sharir and I watched each digitized video. While he watched the dances closely, reminiscing about his fellow artists and considering the quality of the videography and lighting, I filled in the blanks of my spreadsheet, based sometimes on in-video credits and sometimes on Dr. Sharir’s recollections.\n- Once he watched the video through, Dr. Sharir decided whether or not to accession it into the digital collection. He based this decision on the significance of the dances represented, the quality of the video (for instance, some videos lacked audio, and some had degraded over time), and whether we had coverage of the event in the collection already. We generally chose to accession subsequent nights of the same dance program, a collection-level acknowledgement that live performance changes in every reiteration.\n- About halfway through the watching process, Dr. Sharir’s co-artistic director José Luis Bustamante delivered three crates filled with beautifully organized files of programs, press clippings, and season announcements. I am so grateful for this gift! Matched with Dr. Sharir’s files, it has allowed me to create a four-decade production history, and provide extensive credits and notes for almost every item in the digital collection.\n- Once an item is chosen for the digital collection, I upload its .mp4 file to TexasScholarWorks, and add in all its metadata. On TexasScholarWorks, UT folk and the general public alike can search and browse the collection, view streaming video, and download the videos to their own drives. Each video is protected by a Creative Commons license (Attribution-NonCommercial-NoDerivs 3.0 United States).\n- I take the digitized tapes to Beth Kerr at FAL, and she adds them to the physical Sharir collection located in off-site storage. This physical collection contains all digitized video objects, whether accessioned or not into the digital collection. It also contains all the video objects we decided not to digitize (usually because they were clearly duplicates of something we already had accepted).\nYou worked closely with Dr. Sharir on this project; did he provide any impressions about the digitization/digital preservation of his work?\nKVW: I don’t want to speak for Yacov, but I know he is tremendously grateful for the opportunity to share his work with the global public and with future generations. (He is also grateful to regain all that shelf space in his office!)\nHe has found great joy in “re-view”ing his choreography and dancing over the decades, and in responding again to the work of the many extraordinary artists he worked with and presented/produced here in Austin and elsewhere.\nHe shared many jokes and memories with me. Certainly the most poignant and somber touched on the lives of his artist colleagues who had died between the filming of the dance in the 1980s or 1990s, and the day we watched it again in 2015 or 2016. The Sharir Dance Company, like so many arts organizations, lost beloved members to the AIDS epidemic. We felt sometimes that we were watching ghosts dance.\nHow long did the project take?\nKVW: 3 years and 2 months since I began my work as (part-time) archivist. (But the project isn’t done yet—we have phase 2 still to complete). Add in more time before that (I don’t know how much) for Beth and Yacov’s work getting the project up and running and funded.\nDid you discover anything in the process that was either unexpected (either in the materials or cataloging), and can you reflect on the accomplishment and its value to the broader world?\nKVW: My favorite moment in the inventory process was discovering a VHS tape with no labels except two sticky notes reading: “This is the one you’ve been waiting for. UNCUT UNRULY UNHOLY.”\nHaving never participated in a archival process of this scope, I had no idea just how much time this work takes. It’s a major undertaking.\nYacov is a treasure: of the dance world, of Austin and the UT faculty, of the Department of Theatre & Dance. His career has been hugely significant and influential, from his pioneering, inclusive work with Deaf and hearing dancers; to his artistic and production collaborations with artists like Merce Cunningham, Bill T. Jones, Deborah Hay, David Dorfman, Doug Varone, Margaret Jenkins, Tina Marsh, Allison Orr…the list goes on.\nDocumenting and preserving dance has always been difficult. Yacov’s work is perhaps particularly suited to a digital life because he was a pioneer of the integration of digital media and live performance, beginning in the early 1990s and continuing in his collaborations with dancers, musicians, computer programmers, and biomedical and wearable-tech engineers today. (Check out [3D Embodied] and AdMortuos for the most recent examples in the collection):\nIt has been a privilege—and a real pleasure—to help make this important piece of dance history available to the public. I grew up and discovered theatre and dance here in Austin, and I’m proud to contribute to the preservation of the city’s cultural history.', 'Dance Theatre of Harlem dancers reflect as company turns 50\nZita Allen | 8/2/2018, 10:22 a.m.\nDance Theatre of Harlem, the ballet company founded by Arthur Mitchell and Karel Shook in 1969 and led today by former DTH ballerina Virginia Johnson, kicks off a months long 50th anniversary celebration at Lincoln Center Saturday, Aug. 4. “50 Years of Dance Theatre of Harlem: Experiencing History on Pointe and in Color” is a panel discussion featuring past and present DTH dancers that gets the ball rolling at 4 p.m. in the Performing Arts Library’s Bruno Walter Auditorium. It is then followed by a company performance as part of the Lincoln Center Outdoors program, featuring a dynamic mix of neoclassical and contemporary works.\nDTH’s 50th anniversary is a momentous occasion. In its early days, when Mitchell called DTH “the first permanent Black ballet company,” some quibbled, thinking the label premature, even as critics praised DTH’s meteoric rise. When, as Dance Magazine’s first Black critic, I witnessed DTH’s Guggenheim Museum debut with pride, I also took issue with those who saddled the company with the burden of proving Blacks and ballet were not dance’s equivalent of oil and water. At the time, many seemed unaware that before DTH there had been other Black ballet companies and dancers. (Thanks to the late historian Joe Nash, my 1976 Dance Magazine article, “Blacks and Ballet,” discussed such as Delores Brown and Raven Wilkinson and a handful of companies that, despite talent and favorable reviews, were short-lived.)\nToday, 50 years later, thanks in no small measure to the DTH effect, ballet’s landscape is changing, slowly but changing. Recently, the Amsterdam News spoke with a few former and current DTH dancers about their careers and the ballet change agent DTH.\nBallet master and DTH former principal Keith Saunders reflected on his career with the company, beginning as an apprentice, rising to principal, and then ballet master. And now, after recently receiving an MFA, moving to yet another level as he accepts a teaching position at Texas Christian University in Fort Worth, Texas. “Fifty years is quite an achievement,” Saunders said. “I’ve been with DTH for 40 of those 50. My wife Kellye and I are treating this as a big new adventure.”\nHis wife, Kelly, is also a former DTH dancer and current company ballet master. The couple plans to complete their Texas relocation after DTH’s 2018-2019 season.\nSaunders reflected on how it all began.\n“I started dancing as an 18-year-old freshman at Harvard in Cambridge, Mass.,” he said. “My plan was to major in political science and my dream was to become a lawyer.” During freshman orientation, he learned about a dance class. “They called it Afro-American dance,” he said. One class and everything changed.\nDance classes at Elma Lewis’ Boston-based school followed, and soon he had joined her company. Then came auditions with several New York companies, including Dance Theatre of Harlem. “Mr. Mitchell and Mr. Shook offered me a job and, in August 1975, I started as an apprentice,” he said. Before long, he became a principal dancer, performing with DTH for 17 years, from 1975 to 1996. “Sometime around the early 1990s, while I was still dancing, I started doing some ballet mastering,” he said. “In 2004, though we lost the company, we still had the school. I became director of the Dancing Through Barriers and director of the Professional Training. We developed the DTH Ensemble, a kind of second company and, from 2009 to 2012, in the absence of the first company, the Ensemble toured, nationally and internationally, under my direction in those years. When the company came back in 2012, I went back to being ballet master.”']	['<urn:uuid:ff864233-7a50-4d99-878a-a0be8092c770>', '<urn:uuid:c43882bf-9228-4f0d-b16b-a8816a1c410a>']	factoid	with-premise	concise-and-natural	distant-from-document	comparison	novice	2025-05-01T23:46:40.222380	11	36	2289
384	environmental research methods zhou jenkins achievements	Both researchers have made significant contributions to environmental research using different methodologies. Zhou Weijian has achieved recognition through work with cosmogenic nuclides and radiocarbon dating, winning China's first hundred outstanding doctoral degree paper and multiple provincial-level prizes. She has published nearly a hundred papers and led major research projects. Emma Jenkins has developed innovative environmental archaeology methods, particularly in phytolith and microfaunal analysis, and has been awarded an AHRC Early Career grant. She has published extensively on environmental reconstruction techniques and leads various research projects examining early Neolithic communities and their environments.	"['She is mainlyengaged in cosmogenic nuclides (14C, 10Be, etc.) applications in earth environmental sciences research. She is the quaternary geologist. Zhou hasworked on the research of the quaternary geology and global change andcosmogenic nuclide chronology C for a long time and in recent years she hasextended it to Be environmental tracer study.\nUpon graduationfrom the Department of Foreign Languages of Guizhou University in 1976, shepursued further studies in the Geology Department of Northwest University andobtained her doctoral degree. She won the prize of China’s first hundredoutstanding doctoral degree paper. In December 2009, she was elected Academicianof Chinese Academy of Sciences(CAS), Academician of the third world Academy ofSciences, the current Deputy Head of the Institute of Earth Environment of CAS.She also serves as Director of Loess and quaternary geology for State Key Laboratoryof Chinese Academy of Sciences and “Xi’an Accelerator Mass Spectrum Center”co-built by Ministry of Science and Technology (MOST), Chinese Academy ofSciences(CAS) and The Ministry of Education(MOE), as well as substantive doublehired professor of XJTU. She was once appointed as Executive Director ofInternational Society for Radioactive carbon and committee member ofInternational PAGES/CLIVAR Working Committee. At present, she holds the post ofeditorial board member of International SCI Journal, judge of discipline reviewgroup of National Natural Science Fund Committee, Deputy Director of theChinese Quaternary Research Committee as well as editorial board member of Radiocarbon.\nAcademic and Scientific Achievements\nShehas successively presided over key subjects such as “Outstanding Youth ScienceFoundation” of National Foundation, “Outstanding Youth Scientists Community”, “MajorProjects”, 973 Program(second level), special project in earlier stage of basicresearch of Ministry of Science and Technology (MOST) and project of importantdirections of Chinese Academy of Sciences(CAS). She has published nearly a hundredpapers and won the prize of “China’s first hundred outstanding doctoral degreepaper”. She also obtained five provincial-level first prizes, a national-levelsecond prize and third prize as well as a patent. Besides, she won a number ofhonorary titles.\nThefirst prize for Science and Technology Progress of Shaanxi Province in 2002 2007-11-13\nThe secondprize for State Natural Science Award in 2008 2008-12-24\n1.Zhou Weijian, Zhou Mingfu, and M.J. Head, 14C Chronology of Beizhuangcun sedimentation sequence since 30,000 years B.P. Chinese Science Bulletin, 35(7) (1990), 567-572.\n2.Zhou Weijian, M.J.Head, and L. Kaiholas, Smallsample dating in China. Radiocarbon 34(3) (1994), 47-49.\n3.Zhou Weijian, D.J.Donahue, S.C.Porter, T.A.Jull, LiXiaoqiang, M.Stuiver, An Zhisheng, Eiji Matsumoto and Dong Guangrong,Variability of monsoon climate in East Asia at the end of the last glaciation.Quaternary Research 46(3) (1996), 219-229.\n4.Zhou Weijian, D.J. Donahue and J.T. Jull,Radiocarbon AMS dating of pollen concentrated from eolian sand and paleosol:Implications for the monsoon climate change since the late Quaternary.Radiocarbon, 39(1) (1997), 19-26.\n5.Zhou Weijian, Head, M.J., Lu Xuefeng, A.J.T.Jull and D.J.Donahue, Teleconnection of climatic events between east Asia andploar high latitude areas during the last deglaciation. Palaeo. Palaeo. Palaeo.152 (1999), 163-172.\n6.Weijian Zhou, M. John Head Zhisheng An Patrick DeDeckker Zhengyu Liu, Xiaodong Liu, Xuefeng Lu Douglas Donahue, A. J. TimothyJull, & J. Warren Beck, Terrestrial Evidence for a Spatial Structure ofTropical-Polar Interconnections During the Younger Dryas Episode. Earth andPlanetary Science Letter, (2001), 191: 231-239.\n7.Zhou Weijian J.Dodson, M. John Head, B.S Li,Y.J.Hou, X.F. Lu, D. D. Donahue,, A. J. T. Jull, Environmental variabilitywithin the Chinese desert-loess transition zone over the last 20,000 yrs.Holocene 12 (1) ( 2002), 107-112.\n8.Weijian Zhou, Xuefeng Yu, A. J. Timothy Jull, G.Burr, J. Y. Xiao, Xuefeng Lu, & Feng Xian, High-resolution evidence of anearly Holocene optimum and a mid-Holocene dry event from southern China duringthe last 18,000 years. Quaternary Research 62 (2004), 39-48.\n9.Weijian Zhou, Shucheng Xie, Philip A. Meyers, andYanhong Zheng, Reconstruction of Late-Glacial and Holocene Climate Evolution inSouthern China from Geolipids and Pollen in the Dingnan Peat Sequence. OrganicGeochemistry, 36 (2005), 1272－1284.\n10.Zhou Weijian, Zhao Xiaolei, Lu Xuefeng, Liu Lin, WuZhengkun, Cheng Peng Zhao Wengnian and Huang Chunhai, 2006 , 3MV multi-elementAMS in Xian China: Peculiar features and preliminary tests. Radiocarbon 48 (2)(2006), 285-293\n11.Zhou, W., P. Alfred, et al. Disentanglinggeomagnetic and precipitation signals in an 80-kyr Chinese loess record of10Be. Radiocarbon 49(1) (2007), 139–160.', 'Dr Emma Jenkins\n- 01202 968184\n- ejenkins at bournemouth dot ac dot uk\n- Associate Professor\n- Christchurch House C119, Talbot Campus, Fern Barrow, Poole, BH12 5BB\nUse a QR Code reader on a mobile device to add this person as a contact:\nI am an Environmental Archaeologist whose research interests are focused on the Neolithic of southwest Asia. I am particularly interested in why and how people made the switch from being mobile hunter-gatherers to settled farmers. I have two archaeological specialisms which I use to address these questions phytolith and microfaunal analysis.\nI have an undergraduate degree in Archaeology from the University of Bristol and an M. Phil and Ph.D. from the University of Cambridge. I am a committee member for the Association for Environmental Archaeology and in my spare time I enjoy cycling, walking and reading.\nI am currently involved in a number of research projects involving the Neolithic of southwest Asia.\nI have recently been awarded an AHRC, Early Career grant in collaboration with Dr Carol Palmer (CBRL), Prof John Grattan (University of Aberystwyth) and Dr Helen Smith (Bournemouth University). The aim of this project is to develop a combined phytolith and geochemical method to help us understand how space was used in early Neolithic sites through the ethnographic analysis of Bedouin camp sites and traditionally built villages in Jordan (http://research.bournemouth.ac.uk/2014/07/inea-project-2/).\nI work on the WF16 project (a PPNA site in southern Jordan), the Eastern Fertile Crescent Prehistory Project (EFEC) which explores the transition from foraging to farming in the Kurdistan Region of northern Iraq, the Boncuklu Project and the Çatalhöyük Project.\n- Cucchi, T., Jenkins, E. et al., 2020. Tracking the Near Eastern origins and European dispersal of the western house mouse. Scientific Reports, 10 (1).\n- Asouti, E., Baird, D., Kabukcu, C., Swinson, K., Martin, L., Garcia-Suarez, A., Jenkins, E. and Rasheed, K., 2020. The Zagros Epipalaeolithic revisited: New excavations and 14C dates from Palegawra cave in Iraqi Kurdistan. PLoS ONE, 15 (9 September).\n- Jenkins, E., Al Nuimat, S.A.M.Y., Jamjoum, K.I. and Stafford, R., 2020. Assessing past water availability using phytoliths from the C4 plant Sorghum bicolor: an experimental approach. Journal of Archaeological Science: Reports.\n- Birch-Chapman, S. and Jenkins, E., 2019. A Bayesian approach to calculating Pre-Pottery Neolithic structural contemporaneity for reconstructing population size. Journal of Archaeological Science, 112.\n- Jenkins, E., Jamjoum, K., Nuimat, S., Stafford, R., Nortcliff, S. and Mithen, S., 2019. Corrigendum to “Identifying ancient water availability through phytolith analysis: An experimental approach” (Identifying ancient water availability through phytolith analysis: An experimental approach (2016) 73 (82–93), (S0305440316300930), (10.1016/j.jas.2016.07.006)). Journal of Archaeological Science, 110.\n- Flohr, P., Jenkins, E., Williams, H.R.S., Jamjoum, K., Nuimat, S. and Müldner, G., 2019. What can crop stable isotopes ever do for us? An experimental perspective on using cereal carbon stable isotope values for reconstructing water availability in semi-arid and arid environments. Vegetation History and Archaeobotany, 28 (5), 497-512.\n- Elliott, S., Palmer, C., Samantha Lee, A. and Jenkins, E., 2019. Examining Neolithic Building and Activity Areas through Historic Cultural Heritage in Jordan: A Combined Ethnographic, Phytolith and Geochemical Investigation. Bulletin of the Council for British Research in the Levant : CBRL.\n- Vos, D., Jenkins, E. and Palmer, C., 2018. A dual geochemical-phytolith methodology for studying activity areas in ephemeral sites: Insights from an ethnographic case study from Jordan. Geoarchaeology, 33 (6), 680-694.\n- Baird, D., Jenkins, E. et al., 2018. Agricultural origins on the Anatolian plateau. Proceedings of the National Academy of Sciences of the United States of America (PNAS).\n- Jenkins, E., Allcock, S.L., Elliott, S., Palmer, C. and Grattan, J., 2017. Ethno-geochemical and Phytolith Studies of Activity Related Patterns: A Case Study from Al Ma’tan, Jordan. Environmental archaeology : the journal of human palaeoecology, 22 (4), 412-433.\n- Birch, S., Jenkins, E.L., Coward, F. and Maltby, M., 2017. Estimating population size, density and dynamics of Pre-Pottery Neolithic villages in the central and southern Levant: an analysis of Beidha, southern Jordan. Levant, 49 (1).\n- Wicks, K., Finlayson, B., Maričević, D., Smith, S., Jenkins, E. and Mithen, S., 2016. Dating WF16: Exploring the Chronology of a Pre-Pottery Neolithic A Settlement in the Southern Levant. Proceedings of the Prehistoric Society, 82, 73-123.\n- Jenkins, E., Jamjoum, K., Nuimat, S., Stafford, R., Nortcliff, S. and Mithen, S., 2016. Identifying ancient water availability through phytolith analysis: An experimental approach. Journal of Archaeological Science, 73, 82-93.\n- Fairbairn, A., Jenkins, E., Baird, D. and Jacobsen, G., 2014. 9th millennium plant subsistence in the central Anatolian highlands: new evidence from Pınarbaşı, Karaman Province, central Anatolia. Journal of Archaeological Science, 41, 801-812.\n- Baird, D., Jenkins, E. et al., 2013. Juniper smoke, skulls and wolves\' tails. The Epipalaeolithic of the Anatolian plateau in its South-west Asian context; insights from Pinarbaşi. Levant, 45 (2), 175-209.\n- Jenkins, E., 2012. Mice, scats and burials: unusual concentrations of microfauna found in human burials at the Neolithic site of Catalhoyuk, Central Anatolia. Journal of Social Archaeology, 12 (3), 380-403.\n- Mithen, S.J., Finlayson, B., Smith, S., Jenkins, E.L., Najjar, M. and Maricevic, D., 2011. An 11 600 year-old communal structure from the Neolithic of southern Jordan. Antiquity, 85, 350-364.\n- Flohr, P., Muldner, G. and Jenkins, E.L., 2011. Carbon stable isotope analysis of cereal remains as a way to reconstruct water availability: preliminary results. Water History.\n- Turner, R., Roberts, N., Eastwood, W.J., Jenkins, E.L. and Rosen, A.M., 2010. Fire, climate and the origins of agriculture: micro-charcoal records of biomass burning during the Last Glacial Interglacial Transition in Southwest Asia. Journal of Quaternary Science, 25, 371-386.\n- Deckers, K., Riehl, S., Jenkins, E.L., Rosen, A.M., Dodonov, A., Simokava, A.N. and Conard, N.J., 2009. Vegetation Development and Human Occupation in the Damascus Region of Southwestern Syria from Pleistocene to Holocene. Vegetation History and Archaeobotany, 18, 329-340.\n- Jenkins, E.L., 2009. Phytolith taphonomy: a comparison of dry ashing and acid extraction on the breakdown of conjoined phytoliths formed in Triticum durum. Journal of Archaeological Science, 36, 2402-2407.\n- Finlayson, B., Mithen, S.J., Jenkins, E.L., Smith, S.J., Helmsley, S., Maricevic, D., Pankhurst, N., Yeomans, L. and al-Amarat, H., 2009. Excavations at the PPNA site WF16: A Preliminary Report on the 2008 season. Annual of the Department of Antiquities of Jordan, 53, 115-126.\n- Finlayson, B., Mithen, S.J., Najjar, M., Jenkins, E.L. and Smith, S., 2009. Excavations at Pre-Pottery Neolithic A WF16, Southern Jordan. Antiquity (Project gallery), 83.\n- Mithen, S.J., Jenkins, E.L., Jamjoum, K., Nuimat, S. and Finlayson, B., 2008. Experimental Crop Growing in Jordan to Develop A Methodology for the Identification of Ancient Crop Irrigation. World Archaeology, 40, 7-25.\n- Finlayson, B., Mithen, S.J., Najjar, M., Smith, S.J. and Jenkins, E.L., 2008. New Excavations at the Pre-Pottery Neolithic Site of Wadi Faynan 16. Bulletin of the Council for British Research in the Levant, 3, 60-61.\n- Mithen, S., Finlayson, B., Maricevic, D., Smith, S., Jenkins, E. and Najjar, M., 2018. WF16 Excavations at an Early Neolithic Settlement in Southern Jordan: stratigraphy, chronology, architecture and burials. Oxford: Council for British Research in the Levant.\n- Jenkins, E.L., 2009. Unwanted Inhabitants? The Microfauna from Çatalhöyük and Pınarbası. Saarbrücken, Germany: VDM-Verlag.\n- Mithen, S., Finlayson, B., Maricevic, D., Smith, S., Jenkins, E. and Najjar, M., 2015. Death and Architecture: The Pre-Pottery Neolithic A Burials at WF16, Wadi Faynan, Southern Jordan. In: Renfrew, C., Boyd, M.J. and Morley, I., eds. Death Rituals, Social Order and the Archaeology of Immortality in the Ancient World ""Death Shall Have No Dominion"". Cambridge University Press, 82-110.\n- Jenkins, E. and Yeomans, L., 2013. The Çatalhöyük microfauna. Humans and Landscapes of Çatalhöyük: reports from the 2000-2008 seasons. Cotsen Institute of Archaeology Press, 253-264.\n- Jenkins, E., Rosen, A.M. and Otsaku, M., 2012. The Phytoliths of the BACH Area. In: Tringham, R. and Stevanović, M., eds. Last House on the Hill: BACH Area Reports from Çatalhöyük, Turkey. Los Angeles, CA, USA: Cotsen Institute of Archaeology Press, 261-267.\n- Jenkins, E., 2012. The Microfauna of the BACH Area. In: Tringhham, R. and Stevanović, M., eds. Last House on the Hill: BACH Area Reports from Çatalhöyük, Turkey. Los Angeles, CA, USA: Cotsen Institute of Archaeology Press, 253-260.\n- Jenkins, E.L., Jamjoum, K. and Nuimat, S., 2011. Irrigation and phytolith formation:an experimental study. In: Mithen, S.J. and Black, E., eds. Water, life and civilisation: climate, environment and society in the Jordan Valley. Cambridge/New York: Cambridge University Press/UNESCO, 347-372.\n- Jenkins, E.L., Baker, A. and Elliott, S., 2011. Past plant use in Jordan as revealed by archaeological and ethnoarchaeological phytolith signatures. In: Mithen, S.J. and Black, E., eds. Water, life and civilisation: climate, environment and society in the Jordan Valley. Cambridge/New York: Cambridge University Press/UNESCO, 381-399.\n- Stokes, H., Muldner, G. and Jenkins, E.L., 2011. An investigation into the archaeological application of carbon stable isotope analysis used to establish crop water availability: solutions and ways forward. In: Mithen, S. and Black, E., eds. Water, life and civilisation: climate, environment and society in the Jordan Valley. Cambridge, England/ New York: Cambridge University Press/UNESCO, 373-380.\n- Jenkins, E.L. and Rosen, A.M., 2007. The Phytoliths. In: Finlayson, B. and Mithen, S., eds. The Early Prehistory of Wadi Faynan, Southern Jordan: Archaeological survey of Wadis Faynan, Ghuwayr and al-Bustan and Evaluation of the Pre-Pottery Neolithic A Settlement of WF16. Oxford, England: Oxbow Books, 429-436.\n- Jenkins, E.L., 2005. The Çatalhöyük microfauna: preliminary results and interpretations. In: Hodder, I., ed. Inhabiting Çatalhöyük: reports from the 1995-1999 seasons. Cambridge/London: McDonald Institute for Archaeological Research and British Institute at Ankara, 111-116.\n- Andrews, P. and Jenkins, E.L., 2000. The Taphonomy of the Small Mammal Faunas. In: Barham, L., ed. The Middle Stone Age of Zambia, South Central Africa. Bristol, England: Western Academic & Specialist Press, 57-62.\n- Michelle Feider. Understanding early Neolithic communities in Anatolia: using small vertebrates to inform on the palaeoenvironmental and social conditions during the transition from mobile hunter-gatherers to settled farmers\n- Paul Clarkson\nProfile of Teaching PG\n- Unit Leader Level M Advanced Zooarchaeology\nProfile of Teaching UG\n- Unit Leader for Environmental Archaeology\n- Option Leader for Post Excavation-Environmental Remains\n- Unit Leader Level C Gathering Time\nBritish Academy, London, 15 Mar 2017 more\nTraces of Life: using geochemistry, phytoliths and ethnographic analogy to interpret Neolithic settlements, Council for British Research in the Levant, British Academy, London\n- Magdalene College, University of Cambridge: Life on the Wadi Edge: Excavations at the PPNA site of WF16, southern Jordan\n- Identifying activity areas in Neolithic sites through ethnographic analysis of phytoliths and geochemical residues (AHRC, 01 Jan 2014). Awarded\n- Outreach and Recruitment Lead, Archaelogy, Anthropology and Forensic Sciences Departmental Leadership Team\n- REF Outputs Champion, Archaeology, Anthropology and Forensic Sciences REF Team\n- Member, PGR External Examiner Approval Committee\nPublic Engagement & Outreach Activities\n- 2016 Mini BU Archaeologists: Skull Workshop, Talbot Woods Pre-School, BU, Poole\n- 2016: Human Evolution workshop, Hamworthy Park Junior School, Poole\n- 2016 BU Mini Archaeologists:sand-pit digging activity. Talbot Woods Pre-School, BU, Poole\n- 2016 St Lukes primary School Visit-Farmyard animals from the inside out.\n- 2016 Talk on Wadi Faynan 16 a Neolithic village in Jordan-South Wessex Archaeological Association\n- 2016 Archaeology/Anthropology Talk and Osteoarchaeology Practical-Brockenhurst College\n- 2015 Archaeology talk and Osteoarchaeology practical-Luton Sixth Form College\n- 2015 Osteoarchaeology Talk and Practical-Ringwood Waldorf Steiner School\n- 2015 Stand at Glenmoor and Winton Academies Career Convention\n- 2015 Bournemouth University Webinar for International Applicants\n- 2014 Archaeology talk on the Neolithic-Luton Sixth Form College\n- 2014 Archaeology talk on the Neolithic-Strode College, Somerset\n- 2014 Archaeology Talk and Practical-Osteoarchaeology-Richard Huish College, Somerset\n- 2014 Stonehenge talk and Practical Activity-Hillside First School, Verwood\n- 2014 Stand at Bournemouth School Career Fair\n- 2014 Particpant in Meet the Scientist Day-Thomas Hardye School, Dorchester\n- 2014 Designed and participated in an A Level teacher CPD course\n- 2014 Neolithic Archaeology Talk-Ringwood Waldorf Steiner School\n- 2013 An in house Archaeology day for AS/A Level students from Brockenhurst College\n- 2013 Designed and participated in an A Level Teacher CPD course\n- 2013 Talk and stand at Careers Convention-Bournemouth and Talbot Heath Schools\n- 2013 Archaeology talk for the Bishop of Wordsworth School\'s History Society\n- 2013 Zooarchaeology talk and practical for AS/A Level Students-Brockenhurst College\n- 2013 Archaeology talk-Bournemouth School for Boys\n- 2013 Archaeology Talk-St Brendan\'s Sixth form College, Bristol\n- Ongoing-STEM Ambassador and Outreach Coordinator for Archaeology and Anthropology\n- 2013 Archaeology Talk and Workshop-Broadstone First School\n- Association of Environmental Archaeology, Combining phytolith analysis and geochemistry to study ephemeral sites in dynamic environments, 29 Sep 2016, Rome\n- International Congress on the Archaeology of the Ancient Near East, Exploring methods for site characterisation in ephemeral Neolithic and ethnographic sites in Jordan, 25 Apr 2016, Vienna\n- International Congress on the Archaeology of the Ancient Near East, . Estimating Population Parameters of Early Village Societies in the Pre-Pottery Neolithic Central and Southern Levant, 25 Apr 2016, Vienna\n- 13th Synchroton-Light For Experimental Science and Applications in the Middle East (SESAME) User Meeting User Meeting, Synthesis of a range of analytical techniques used in archaeological projects in Jordan, Iraq, Iran and Turkey: X-ray diffraction, X-ray fluorescence, portable X-ray fluorescence, environmental scanni, 25 Nov 2015, Amman\n- European Association of Archaeologists, A Tale of Two methods: Applying Phytolith and Geochemical Analysis to Study the Use of Space at Ethnographic and Neolithic Ephemeral Sites in Jordan, 02 Sep 2015, Glasgow\n- 1st Petra International Conference on Cultural Tourism, New Research on the Old Village of Al-Ma’tan: Futures for the recent past, 17 May 2015, Ma\'an, Jordan\n- Society for American Archaeology, An Integrated phytolith and geochemical approach to understanding activity areas and the choice of building materials in Neolithic sites using ethnographic analysis, 15 Apr 2015, San Francisco\n- British Association for Near Eastern Archaeology, A new integrated approach to understanding household activity areas using phytolith and geochemical signatures from ethnographic and archaeological sites in Jordan, 07 Jan 2015, London\n- British Association for Near Eastern Archaeology, Rural Settlement, House Forms and Oral Histories in Southern Jordan, 07 Jan 2015, London\n- British Association for Near Eastern Archaeology, Studying Phytolith and Geochemical Soil Signatures in Bedouin Campsites at Wadi Faynan, Jordan, 07 Jan 2015, London\n- Association for Environmental Archaeology, An integrated approach to understanding activity areas using phytolith and geochemical signatures from ethnographic and archaeological sites in Jordan, 07 Nov 2014, Plymouth\n- -British Association for Near eastern Archaeology, Reconstructing past water management with plant stable isotopes: possibilities and applications of a novel technique, 09 Jan 2014, Reading\n- World Archaeological Congress, Plant carbon and nitrogen stable isotope ratios for the reconstruction of past water availability: new insights, 13 Jan 2013, Dead Sea Region, Jordan\n- Experimental Archaeology Conference, Reconstructing past water availability with plant stable isotope ratios: re-assessing a method by using experimental archaeology, 06 Jan 2012, York\n- Experimental Archaeology Conference, Phytoliths as indicators of past water availability and palaeoeconomic practices, 08 Jan 2011, Reading\n- Experimental Archaeology Conference, Stable isotope analyses of ancient cereal grains for environmental reconstruction: using experimental archaeology to improve existing methodology, 08 Jan 2011, Reading\n- British Association for Near Eastern Archaeology, Changes in Plant Exploitation from the PPNA to the PPNB in Wadi Faynan: Analysis of Phytoliths from WF16 to Ghuwayr 1, 07 Jan 2009, Durham\n- Society for American Archaeology, The Ecological Footprint of Early Levantine Cereal Exploitation, 24 Apr 2007, Austin, Texas\n- British Association of Near Eastern Archaeology, Water, Life and Civilisation: Experimental Crop Growing for Phytolith Analysis, 01 Apr 2007, Birmingham\n- International Meeting on Phytolith Research, Phytoliths as Indicators of Irrigation: An Outline of On-going Crop Growing Experiments and their Implications for Phytolith Research, 05 Sep 2006, Barcelona\n- Society for American Archaeology, Serial Collectors of the 12th to 11th Millennium BP: A Possible Case Against Cultivation in the Pre-Pottery Neolithic A in the Jordan Valley, 24 Apr 2006, Puerto Rico\n- Society for American Archaeology, Phytoliths as Indicators of Plant Use at Çatalhöyük, 24 Apr 2006, Puerto Rico\n- PhD in Archaeology (University of Cambridge, 2004)\n- MPhil in Archaeology (University of Cambridge, 1999)\n- BA (Hons) in Archaeology (University of Bristol, 1997)\n- British Association for Near Eastern Archaeology, Steering Commitee (2016-), http://banealcane.org/banea/\n- WISE (Women in SCience technology and Engineering), Member (2016-), https://www.wisecampaign.org.uk/\n- Council for British Research in the Levant, Member (2014-),\n- Higher Education Academy, Fellow (2014-),\n- STEMNET (Science, Technology, Engineeering and Mathematcis Network), Member (2013-), http://www.stemnet.org.uk/\n- Association for Environmental Archaeology, Ordinary Committee Member, http://envarch.net/\n- Society for Phytolith Research, Member,']"	['<urn:uuid:07ed0cc0-38f8-4838-9a80-0885a6136409>', '<urn:uuid:2648b755-dbd0-42f3-b99c-cd0d5e1222e8>']	open-ended	direct	short-search-query	similar-to-document	comparison	expert	2025-05-01T23:46:40.222380	6	92	3409
385	classical music black composers outreach programs impact	Black composers have historically faced significant challenges in classical music, from early pioneers like Chevalier de Saint-Georges to Pulitzer prize winner George Walker. While numerous talented black composers created important works, their representation remains limited. Today, only 5% of classical music professionals in the UK identify as black and minority ethnic, despite comprising 12% of the population. To address this disparity, various outreach initiatives have emerged, including the London Symphony Orchestra Discovery Program reaching 60,000 children, and the El Sistema project in Liverpool and London, which provides orchestral education to underprivileged children. However, without sustained exposure and support for instruments and lessons, especially in BME communities where Western classical music can feel alien, these programs alone cannot fully address the representation gap.	['In the past 200 years, dozens of prominent black composers from America and other parts of the African diaspora have fought to be recognised by the western classical tradition. The earliest example is Chevalier de Saint-Georges (1745-99). Born in Guadeloupe, the son of a wealthy plantation owner and a female slave, Saint-George was brought to France at a young age. As well as being a champion fencer, a violin teacher to Marie Antoinette and a colonel in the republican army, his prodigious musical talents led to him being dubbed “le Mozart noir”. He was a prolific composer (with several operas, 15 violin concertos, symphonies and numerous chamber works to his name) and a rare French exponent of early classical violin composition. (Listen to Chi-chi Nwanoku’s radio documentary about him here, available until 3 July.)\nSaint-Georges would have perhaps come into contact with George Bridgewater (1778-1860), a violinist of African origin born in present-day Poland. By the age of nine, his father (who was probably born in Barbados) had taken him to London, where he was shown off as a child prodigy, performing in front of the likes of Thomas Jefferson and George IV. Several of Bridgewater’s compositions survive, although few have been recorded. His story was also the basis for a 2007 opera, written by Julian Joseph.\nSamuel Coleridge-Taylor (1875-1912) was born in Croydon, the son of a white English mother and a Creole man from Sierra Leone. As a violin scholar at the Royal College of Music, he was taught composition under Charles Villiers Stanford and soon developed a reputation as a composer, with Edward Elgar recommending him to the Three Choirs festival in 1896. By the time he died of pneumonia – aged only 37 – he had already toured America three times and performed for Theodore Roosevelt at the White House.\nCompositions such as Coleridge-Taylor’s African Suite attempted to incorporate African influences in the same way that, say, Dvorák used Hungarian folk themes, but much more successful is Hiawatha’s Wedding, which is occasionally performed today. Even better are Coleridge-Taylor’s works for violin and orchestra, which are elegant pieces of fin de siècle romanticism.\nAs Alex Ross observes in his study of modern classical music, The Rest Is Noise, the history of African American composition around the turn of the 20th century is full of sorrowful tales. Harry Lawrence Freeman (1869-1954) founded Harlem’s Negro Grand Opera Company, but his two all-black Wagnerian operas are barely staged.\nMaurice Arnold Strothotte (1865-1937) studied in Berlin and wrote an opera and a symphony that were highly praised by Dvorák, but his work was rarely performed and has all but dropped off the musical map – he ended up making his living teaching violin and conducting provincial operettas.\nLike Strothotte, Will Marion Cook (1869-1944) also studied in Berlin and was praised by Dvorák. He was acclaimed for his Broadway shows and ragtime-influenced songs, but found it almost impossible to break into “straight” composition.\nMost sorrowful of all was Scott Joplin (1867-1917). The son of an ex-slave from Texas, he started as a travelling musician around the southern states, playing piano in “gentleman’s clubs”. By the turn of the century his piano rags, such as Maple Leaf Rag, had become a national sensation, but he was desperate to be taken seriously as an orchestral composer. His opera Treemonisha was all but ignored, and he died insane in 1917 after his brain was destroyed by syphilis.\nOther black American composers had happier endings. William Grant Still (1895-1978) wrote 150 works, studied with Edgard Varèse, was the first African American to conduct a major US symphony orchestra (the New Orleans Philharmonic), composed for Hollywood and found his works performed by leading orchestras around the world, including his 1930 Afro-American Symphony.\nFlorence B Price (1887-1953) was the first African American woman to have a work played by a major orchestra – the Chicago Symphony premiered her Symphony in E minor in 1933, but despite success during her lifetime, her many compositions are rarely played today.\nAnd George Walker, born in 1922 and still working today, was the first black American composer to win the Pulitzer prize for music (for Lilacs, a piece for voice and orchestra, in 1996). However, for all his acclaim, he still remains a cult figure in the world of contemporary composition.\nWho have we missed out? Tell us in the comments section below.', 'Racial diversity in classical music: A daunting experience for non-white professionals working in the industry today\n“Going into a concert hall, you see an entirely white orchestra, a white audience and a white soloist”. I am talking to Julian Lloyd-Webber about the lack of black and ethnic minority people in the cut-throat world of classical music. He describes a common scene; by his own admission a “daunting” one for the handful of non-white professionals working in classical music today.\nCurrently, just five per cent of classical music professionals working in the UK identify as black and minority ethnic – and this figure shows no sign of rising, according to the Arts Council Staff Survey. Compare this to the 12 per cent slice of the UK population made up by the same group, and the under representation in British classical music speaks for itself and it speaks volumes.\nThe problem of racial diversity in classical music has long been the elephant in the room. Anecdotally, the stories are prolific. Only last year Hollywood screenwriter Candace Allen (the ex-wife of conductor Sir Simon Rattle) branded the British classical world “racist”.\nAllen claimed that a combination of discrimination and lack of exposure to classical at an early age meant that black people were unlikely to make it to the concert hall (be that in the audience or in the pit) so when they did, their sense of alienation made the experience not one to be repeated. On this second point, Allen can’t be faulted.\n“People need role models,” Lloyd-Webber tells me. “They need to see someone like themselves out there”. It’s long been accepted that one’s relationship with music starts at a young age. That counts for any genre of music, so any suggestion that classical isn’t ‘relevant’ is absurd. Listening to Mozart might seem odd for a young black kid living in an estate, but no more so than listening to a K-Pop star speaking in Korean while he dances like a horse; it’s all about exposure.\nHearing it at home, in school, visits to concerts, a few friends with the same interest, all these factors contribute to one’s sense of community in music, and without this sense of community, forming a meaningful bond to any kind of sound is nigh impossible.\nTo this end, a number of outstanding outreach programs have developed. There’s over 20 years of the London Symphony Orchestra Discovery Program, a music education scheme that touches 60,000 children with a particular focus on East London. At the Barbican, the famous avant-garde programming has actively (and successfully) sought new audiences by breaking boundaries in concert hall convention, be that by fusing classical musicians from India with a jazz band or by giving Aphex Twin a remote control orchestra. Orchestras Live are creating pop-up performances in shopping malls to recontextualise how we see classical, and perhaps most moving of all, is Julian Lloyd-Webber’s In Harmony El Sistema project in Liverpool and London, modelled on its Venezuelan namesake.\nEl Sistema was a social project initiated under Hugo Chavez that encouraged community activity and adolescent discipline by providing poor children with lessons in an orchestra. Venezuela now boasts over 300,000 children in the program and one of the best orchestras in the world. “The conductor [Gustavo Dudamel] is as famous as any footballer”, Gabriel Prokofiev (grandson of Sergei and composer) tells me.\n“The audiences are young, the players are young, the performances feel like a party”. Here in the UK, Lloyd-Webber’s program has reported equally outstanding results. “I am positive that for most of the kids in our program, they have had little to no exposure to classical,” Lloyd-Webber tells me. “And now it is their life”.\nSo why, after all this, is classical music as white as it has ever been?\n“Traditionally, most people in the classical world have grown up in a family where classical music was played,” Prokofiev tells me “and as far as I can see, that hasn’t changed”. The outreach work of any number of organisations may have helped to engage audiences – but without sustained exposure, and, if the child wants, the costs of lessons and instruments, the status quo cannot and will not change. This is particularly true of BME communities where classical music – a largely Western movement – can be perceived as alien.\nThese changes cannot, and should not come from non-elected bodies such as orchestras and community projects. They should, and can only, come from the government. Music education funding was shredded to ribbons under Thatcher; Michael Gove’s National Plan for music education has been in full swing for just under a year, and it is perhaps too early to say whether it has succeeded or not. But the instances of ‘theory-only’ music classes to meet curriculum requirements, or no music programme at all, compounded with the challenge of giving a child continued access to an instrument, remain widespread.\nIf you happen to live in an area where people like In Harmony, LSO and others are working, then your child might just fulfil their musical potential regardless of their colour or class. If not, the postcode lottery of music education might get the better of you. But what does it all matter if classical music still looks set to stay white? According to Kathryn McDowell, director of the LSO, “If we’re in receipt of public subsidy we have a responsibility”. Responsibility, if only that was a classic.Tagged in: Candace Allen, Classical music, El Sistema, Gabriel Prokofiev, Julian Lloyd-Webber, London Symphony Orchestra Discovery Program, Racial diversity\nRecent Posts on Arts\n- Indian rickshaw fetches £100,000 for wild elephants at Prince Charles hosted auction\n- Vennart Interview and album stream: ‘This album is more focused on vocals and guitar rather than pounding your head and complex riffs’\n- India’s old moderns keep the art auctions buoyant\n- Scottish Book Trust: Ask the Illustrator with Debi Gliori\n- Dialects: LTKLTL - EP Stream\nLatest from Independent journalists on Twitter']	['<urn:uuid:a9785ccf-fa95-448d-a81f-79486a8c3841>', '<urn:uuid:4ea45122-2e19-4112-8a39-cebc48e7c5d6>']	open-ended	with-premise	short-search-query	similar-to-document	multi-aspect	expert	2025-05-01T23:46:40.222380	7	122	1725
387	what was average speed record breaking million franc delahaye compared to circuit du sud ouest speed record	The Million Franc Delahaye achieved an average speed of 91 miles per hour around Autodrome de Montlhery, which was significantly faster than the Circuit du Sud Ouest speed record of 43.8 miles per hour set in 1900.	['The “Million Franc Delahaye” and the Panhard et Levassor B1 honored with awards at The Quail and the Pebble Beach Concours d’Elegance.\nOxnard, Calif. (August 2015) – For any organization, to have a single vehicle from its collection receive an award at any of the events held during Monterey’s famed Car Week is a great honor. Having two vehicles receive awards is almost unheard of, but such was the case with the 1902 Panhard et Levassor B1 Rear-Entrance Tonneau and the famous “Million Franc” Delahaye 145, with the former taking home the prestigious Charles A. Chayne Trophy at the Pebble Beach Concours d’Elegance and the latter receiving the Best In Class award for Pre and Post-War Sports and Racing Cars at The Quail.\nThe “Million Franc” 1937 Delahaye Type 145 V12 Grand Prix (Chassis #48771) earned its nickname by answering a challenge set by the Automobile Club of France to beat an existing speed record around Autodrome de Montlhery. Famous French racecar driver René Dreyfus drove the Type 145, with its new naturally aspirated 4.5 liter V12, around the track sixteen times, at an average speed of 91 miles per hour. The car was then hidden in a hillside during World War II to protect it from the invading Germans. After the war, the engine was sold as a mechanical demonstrator to a school and the car disappeared from public view until Mr. Mullin purchased it in 1987. He undertook a full restoration and managed to locate the original magnesium V12 and reunited it with the car for the first time since the war. Now, far from being just a static museum piece, the “Million Franc” Delahaye is semi-regularly driven on track, with aplomb.\nThe Charles A. Chayne Trophy-winning Panhard represents a distinctly different approach to the automobile than the Delahaye. The 1902 Panhard et Levassor B1 Rear-Entrance Tonneau was never destined to win any races but it did manage to completely change the way automobiles were designed. The B1 represents one of the first uses of the “Systeme Panhard”. This “Systeme” was typified by use of a front-mounted engine, rear wheel drive, and use of a clutch pedal which interacted with an innovative sliding gear three speed transmission. This transmission became the industry standard until Cadillac introduced the synchromesh in the late 1920s. The front engine, rear wheel drive architecture remains prevalent to this day. Another Panhard innovation that remains in use today is the so-called “Panhard Rod” which is used to prevent side-to-side movement in a live axle-equipped vehicle.\n“We feel that it’s important for us to continue to race and display these wonderful old cars so that people can see how technologically important they were and how capable cars like the ‘Million Franc Delahaye’ are today,” said Mullin Museum founder, Peter Mullin. “It’s truly an honor to have the cars recognized during Car Week, especially at events such as Pebble Beach and The Quail. We love the cars so much, it’s great to have others appreciate them as well.”\nMonterey Car Week is like no other automotive gathering in the world, and the Mullin Museum is absolutely thrilled to bring pieces from the collection out just to participate and educate. To have won two awards truly speaks to the interest that the public has for cars from this era and reinforces the truth of the Mullin Museum’s mission to showcase the beauty and splendor of French automotive styling and the innovative technical achievements of French automotive designers throughout history.\nFor more information on the Mullin Automobile Museum, please visit www.MullinAutomotiveMuseum.com or call 805.385.5400.\nAbout The Mullin Automotive Museum\nThe Mullin Automotive Museum is located at 1421 Emerson Ave., Oxnard, CA 93033, in the building formerly occupied by the Otis Chandler Vintage Museum of Transportation and Wildlife. The museum is open to the public every other Saturday from 10:00 a.m. to 3:00 p.m. Tickets must be purchased in advance at www.MullinAutomotiveMuseum.com. For information on semi-private tours or on Mullin 1000 Club membership benefits, please call 805.385.5400.', 'Traditionally, the Riviera Speed Week in the south of France had been the opening of the motorsport season in early years. However, a few minor–but still notable–races took place before the Speed Week in 1900. These included the Course du Catalogue, the Circuit du Sud Ouest, and a voiturette only race from Paris to Rouen and back to Paris. The Circuit du Sud Ouest race was the most important of these comparatively minor races.\nThe Course du Catalogue\nThe 1900 motorsport season opener took place on February 18, 1900. It was a short race, just under 45 miles (72 km). The race was organized by the publication, La France Automobile.\nAs noted in the last post, classes were seemingly arbitrarily created by the organizing committee to suit their disparate purposes. This race had six classes, which were divided according to chassis cost. In the so-called (or at least what I am calling) “big car” category, there were only two competitors. A Mr. Degrais driving a Mors, and recent strong competitor Léonce Girardot. Girardot was rocking his usual Panhard et Levassor.\nGirardot, pictured above above in his Panhard, carried the day against Degrais. Baron de Rothschild, philanthropist, racer, and ancestor of the wine maker, wagered he could complete the 72 kilometer (44.7 mile) circuit in 72 minutes. He failed. He broke a powertrain chain just before the halfway point.\nThe Circuit du Sud Ouest\nThe race on the newly devised Circuit du Sud Ouest was the main event of a series of races being held the week of February 22, 1900. This main event took place on the 25th of February. For races of the day, it was on the short side at 209.5 miles.\nAccording the authoritative Gerald Rose, “In most cases, the cars were those of the Tour de France, though with additions and improvements.” For example, René de Knyff had managed to lighten his Panhard by 200 kilograms (approx. 440 pounds). The car was 440 pounds lighter in spite of a bigger, heavier engine as compared to the Tour de France setup. This new engine was more powerful and also utilized “dual ignition” (dual ignition involves the use of both incandescent Platinum tubes and electric ignition).\nFerand Charron and Léonce Girardot also had lighter cars, utilizing changed axels, new ball bearing setup, and several other secret developments to be used in later models. These secret modifications have been lost to history.\nThe race was preceded by heavy rain. However, the rain not only cleared before the race, but also served to harden the dirt roads. This reduced the usual cloud of dust following each car. In general, conditions were great for high-speed rollicking.\nIt was an interval start. Giraud left first; however, he was to have a rough day. Conversely, de Knyff had an epic day. At the 75 mile mark, he already led the field by a shocking 30 minutes.\nGiraud, who had started first, had serious problems with his rear tires, which slowed him down throughout the race.\nFernand Charron wrecked before Saint Sever. He hit a large hump in the road, which destroyed all four of his tires. Upon simultaneously bursting all four tires, he (and his passenger) were thrown out of their Panhard.\nIn short, de Knyff crushed it. In the end, he won by over 40 minutes. In fact, he flogged his Panhard until it had nothing left to give. According to Rose, “Just before the end of the race, the winner’s pump gave out, and although he managed to reach the finish, his car arrived enveloped in a blue haze of smoke and refused to move an inch beyond the finishing line.”\nWith nearly every race, average speeds were rising, which is a testament to the furious rate of technological advancement occurring. This race set a new record pace for an automobile race of 43.8 miles per hour, which is not too shabby for a car rated at only 16 horsepower.\nParis to Rouen and Back: A Voiturette Race\nA voiturette, by the way, is a smaller car relative to the “big cars.” However, for many years, the division between the two would remain vague at best. Théry won in a Decauville weighing roughly 1,030 pounds. However, the Renault voiturettes were also particularly strong.\nOne criticism of motorsport then, which oddly still rages today even in Formula 1, is the disconnect between racing cars and road cars. However, the Paris to Rouen to Paris race in early March 1900, raised an oddly practical point. Several people ordered voiturettes based on their observation of the cars in the race. They were infuriated to realize that the company merely delivered a touring model. It was the racers, themselves, that were converting these to race cars. The purchasers were not happy to realize that they had ordered and paid for a car rather incapable of racing, without serious modification.\nStay tuned for the next post, which will detail the story of how the “Mercedes” came to be!\n/ Travis Turner of GPevolved.com\nA Record of Motor Racing, 1894 – 1908, Gerald Rose (2nd. ed. 1949).']	['<urn:uuid:a1304aa4-bb28-4ed2-aecc-2c3fdc2e1f9c>', '<urn:uuid:9b7c1540-c436-4333-8b02-56b4521fc4c8>']	factoid	direct	long-search-query	similar-to-document	comparison	expert	2025-05-01T23:46:40.222380	17	37	1518
390	I've been reading about ancient religious clothing and was wondering what kind of precious stones were used in the first row of the breastplate that they made?	The first row of the breastplate contained ruby, topaz, and beryl.	"[""Of the blue, purple, and scarlet, they made finely worked garments, for ministering in the holy place, and made the holy garments for Aaron; as Yahweh commanded Moses.\nHe made the ephod of gold, blue, purple, scarlet, and fine twined linen.\nThey beat the gold into thin plates, and cut it into wires, to work it in the blue, in the purple, in the scarlet, and in the fine linen, the work of the skillful workman.\nThey made shoulder-pieces for it, joined together. At the two ends it was joined together.\nThe skillfully woven band that was on it, with which to fasten it on, was of the same piece, like its work; of gold, of blue, purple, scarlet, and fine twined linen; as Yahweh commanded Moses.\nThey worked the onyx stones, enclosed in settings of gold, engraved with the engravings of a signet, according to the names of the children of Israel.\nHe put them on the shoulder-pieces of the ephod, to be stones of memorial for the children of Israel, as Yahweh commanded Moses.\nHe made the breastplate, the work of a skillful workman, like the work of the ephod; of gold, of blue, purple, scarlet, and fine twined linen.\nIt was square. They made the breastplate double. Its length was a span, and its breadth a span, being double.\nThey set in it four rows of stones. A row of ruby, topaz, and beryl was the first row;\nand the second row, a turquoise, a sapphire, and an emerald;\nand the third row, a jacinth, an agate, and an amethyst;\nand the fourth row, a chrysolite, an onyx, and a jasper. They were enclosed in gold settings.\nThe stones were according to the names of the children of Israel, twelve, according to their names; like the engravings of a signet, everyone according to his name, for the twelve tribes.\nThey made on the breastplate chains like cords, of braided work of pure gold.\nThey made two settings of gold, and two gold rings, and put the two rings on the two ends of the breastplate.\nThey put the two braided chains of gold in the two rings at the ends of the breastplate.\nThe other two ends of the two braided chains they put on the two settings, and put them on the shoulder-pieces of the ephod, in the front of it.\nThey made two rings of gold, and put them on the two ends of the breastplate, on the edge of it, which was toward the side of the ephod inward.\nThey made two rings of gold, and put them on the two shoulder-pieces of the ephod underneath, in the front of it, close by its coupling, above the skillfully woven band of the ephod.\nThey bound the breastplate by its rings to the rings of the ephod with a lace of blue, that it might be on the skillfully woven band of the ephod, and that the breastplate might not come loose from the ephod, as Yahweh commanded Moses.\nHe made the robe of the ephod of woven work, all of blue.\nThe opening of the robe in the midst of it was like the opening of a coat of mail, with a binding around its opening, that it should not be torn.\nThey made on the skirts of the robe pomegranates of blue, purple, scarlet, and twined linen.\nThey made bells of pure gold, and put the bells between the pomegranates around the skirts of the robe, between the pomegranates;\na bell and a pomegranate, a bell and a pomegranate, around the skirts of the robe, to minister in, as Yahweh commanded Moses.\nThey made the coats of fine linen of woven work for Aaron, and for his sons,\nand the turban of fine linen, and the linen headbands of fine linen, and the linen breeches of fine twined linen,\nand the sash of fine twined linen, and blue, and purple, and scarlet, the work of the embroiderer, as Yahweh commanded Moses.\nThey made the plate of the holy crown of pure gold, and wrote on it a writing, like the engravings of a signet: 'HOLY TO YAHWEH.'\nThey tied to it a lace of blue, to fasten it on the turban above, as Yahweh commanded Moses.\nThus all the work of the tent of the tent of meeting was finished. The children of Israel did according to all that Yahweh commanded Moses; so they did.\nThey brought the tent to Moses, the tent, with all its furniture, its clasps, its boards, it bars, its pillars, its sockets,\nthe covering of rams' skins dyed red, the covering of sea cow hides, the veil of the screen,\nthe ark of the testimony with its poles, the mercy seat,\nthe table, all its vessels, the show bread,\nthe pure lampstand, its lamps, even the lamps to be set in order, all its vessels, the oil for the light,\nthe golden altar, the anointing oil, the sweet incense, the screen for the door of the Tent,\nthe brazen altar, its grating of brass, its poles, all of its vessels, the basin and its base,\nthe hangings of the court, its pillars, its sockets, the screen for the gate of the court, its cords, its pins, all the instruments of the service of the tent, for the tent of meeting,\nthe finely worked garments for ministering in the holy place, the holy garments for Aaron the priest, and the garments of his sons, to minister in the priest's office.\nAccording to all that Yahweh commanded Moses, so the children of Israel did all the work.\nMoses saw all the work, and, behold, they had done it as Yahweh had commanded, even so had they done it: and Moses blessed them.""]"	['<urn:uuid:cd213923-d87d-4273-b0b8-cab4a5c3f462>']	factoid	with-premise	verbose-and-natural	similar-to-document	single-doc	novice	2025-05-01T23:46:40.222380	27	11	962
391	essential components portable mouth injury management kit detailed list	A dental first aid kit should include: pain medication (like Motrin or Aleve, but not aspirin), cotton or gauze pads, wax, floss, a Save A Tooth System, tea bags, denture adhesive paste, temporary filling material, dental mirror and spatula, instant ice packs, topical anesthetic, salt packets, Colgate Wisps, Orabase, and dentist contact information. These items are readily available in most homes and drug stores and can be kept both at home and in the car.	['A dental emergency can arise at any time and place. These emergencies can be a loose crown, fractured tooth, or even a toothache. Many homes and even cars have\nemergency first aid kits in case of a medical emergency. Most do not even think twice about dental emergencies until they happen. Are you prepared for a dental emergency?\nItems To Include in a Dental First Aid Kit\n-Pain Medication. This can include Motrin or Aleve. Just something to relieve the pain until you can see your dentist for better pain relief. Do not use aspirin as this will inhibit clotting.\n-Cotton or Gauze pads. These come in handy if there is any bleeding from an injury or even to have the patient bite down on to relieve some of the pressure. It also comes in handy if you have irritation from your braces or a denture. You can place the cotton or gauze in between the appliance and the sore to relive some of the discomfort.\n-Wax. Another handy item to cover up areas of irritation like orthodontic brackets or wires.\n-Floss. This can come in handy to remove food debris that gets lodged between teeth and beneath the gums that cause pain and discomfort.\n-“Save A Tooth” System. This is for transporting teeth that have fallen out so that you have a better chance for long term survival once re implanted.\n-Teabags. These are great for stopping bleeding following oral surgery or even a trauma in the mouth. Research suggests that bags containing tea from the plant camellia sinensis is better than herbal tea for this purpose. Tea bags may also be soothing if you bite your lip, cheek, or tongue.\n-Denture Adhesive Paste. This can be used even if you do not have dentures. In addition to using it to secure dentures, it can also be used to temporarily secure a crown or bridge that has fallen out. A good example of this is Fixodent.\n-Temporary filling material. This material tends to work better than wax for temporary replacement of a missing filling.\n-Dental Mirror and Spatula. The mirror can come in handy if the emergency is back in the mouth and the spatula is necessary for using any temporary filling material in the mouth.\n-Instant Ice Packs. These packs can come in handy if there is any trauma to the mouth or face.\n-Topical Anesthetic. This can give temporary relief for denture sores, gum irritation, cold sores, canker sores, or sores from simply biting your lip, tongue, or cheek.\n-Packets of Salt. These can be helpful if rinsing is necessary, as salt water helps clean and irrigate out wounds.\n-Package of Colgate Wisps. This handy dental hygiene tool acts as toothbrush as well as a toothpick. These can help remove foreign objects lodged between your teeth.\n-Orabase. A paste used for healing canker sores or sore mouths.\n-Dentist Contact Information. Most dentists can be reached after hours via an emergency telephone line.\nDental First Aid Conclusion\nAll of the items listed above are readily available in most homes as well as drug stores. You can make a kit for at home and in your car for on the road. You never know when a dental emergency might arise and this kit can be a life saver or should I say tooth saver! As always visit your dentist regularly for dental examinations and professional cleanings as well as for follow up to any at home dental emergency.\n© 2013, Marielaina Perrone DDS. All rights reserved. Las Vegas Cosmetic Dentist\nAll user-generated information on this site is the opinion of its author only and is not a substitute for medical advice or treatment for any medical conditions. Members and guests are responsible for their own posts and the potential consequences of those posts detailed in our Terms of Service.']	['<urn:uuid:27d2074c-3b9f-4396-922e-45d37cd1bbe8>']	open-ended	direct	long-search-query	distant-from-document	single-doc	expert	2025-05-01T23:46:40.222380	9	75	640
392	What should business managers look at when deciding between different security investments, and how can they handle the uncertainty about how often cyber attacks might happen?	Business managers should focus on Return on Security Investment (ROSI) calculations to evaluate whether the amount of potential money saved is higher or lower than the recommended security control investment. Instead of trying to determine a single estimate for how often attacks occur (Annualized Rate of Occurrence - ARO), managers can use simulation models that test different frequencies of attacks. This approach helps find a 'tipping point' - the frequency at which security investment becomes worthwhile. For example, if a security investment becomes cost-effective when attacks happen more than once every seven years, managers only need to determine if they believe attacks will occur more or less frequently than that, rather than determining an exact frequency.	['Question 1. Information systems have become essential components in most organizations since they enhance efficiency in completing business and organizational operations. The security of this information systems is equally important to ensure their optimum functionality. Most organizations have heavily invested in information systems ranging from enterprise resource planning systems (ERP) to customer relationship management systems among others. These investments will be futile if their security is not guaranteed. Consequently, it is the role of the Computer Emergency Response Teams (CERT) together with the CISO to identify the security measures to be implemented in the organization. Information security efforts and implementation must be factored in the budget to meet various activities and procedures that go into the implementation. It is therefore important to consider the returns on investment that will be realized from information security.\nCERTs need to determine their cost-effectiveness in order to justify their budget usage as well as provide supportive claims for the next budgetary allocations. According to ENISA (2012), organizations mainly face challenges while accurately determining the cost and effectiveness of the respective information security activities. This is attributed to the fact that information security investment does not yield profits but it is a loss prevention investment. Despite this challenge, it is important that the organizations have a clear understanding of the benefits and the importance of investing in the security of information systems. Hence the need for Returns on security on investment calculation (Cavusoglu, Mishra & Raghunathan, 2004).\nReturn on Investment (ROI) calculation is essential for justification of every budgetary allocation in any organization (Cavusoglu, Mishra & Raghunathan, 2004). Security is an investment in both public and private entities. Thus, the return on security investment (ROSI) must be done to determine and justify budgetary allocation for information system security. The ENISA work program states that the executive decision makers should know the impact of security. This will assist them to understand how much they should spend on security and how much the lack of security is going to cost. Additionally, they should identify the most cost-effective solutions that can be adopted (ENISA, 2012). This is only possible with a ROSI calculation.\nAccording to Sonnenreich, Albanese & Stout (2006), ROSI calculation will provide substantial quantitative answers to fundamental questions such as the amount an organization is paying for cyber security, the impact of the lack of cyber security in the organization and whether the security investment is enough. The method uses estimated potential loss (ALE), estimated risk mitigation and cost of the solution variables. This metric can also be applied to the Big Data Analytic (BDA) technology to determine its cost and the potential returns on investment (ENISA, 2012). ROSI calculations can be used to determine whether and organization particularly security companies can implement the technology and be able to realize returns on investment. Most notably, it enables decision makers in this respect to identifying the improvements to be gained from the technology and the losses from lack of implementation.\nROSI calculation has some limitations that are mainly centered on the drawbacks of estimation and the Gordon and Loeb model of calculation. ROSI calculation is based on estimations which make it difficult to estimate the cost of cyber security incidents which vary depending on the environment. Additionally, the ROSI calculation can be manipulated very easily to serve the interest of the user. Secondly, the Gordon and Loeb model popularly used in the metric is an approximate model hence the resulting numbers must be treated with caution (ENISA, 2012).\nCavusoglu, H., Mishra, B., & Raghunathan, S. (2004). A model for evaluating IT security investments.Communications of the ACM,47(7), 87-92.\nEuropean Network and Information Security Agency. (2012). Introduction to Return on Security Investment: Helping CERTs assessing the cost of (lack of) security. Heraklion, Crete, Greece: Author. Retrieved from https://www.enisa.europa.eu/activities/cert/other-work/introduction-to-return-on-security-investment/at_download/fullReport\nQuestion 2. Return on security investment (ROSI)-a practical quantitative model.Journal of Research and Practice in Information Technology,38(1), 45-56.Since network security products do not generate revenue, it is necessary to evaluate their worth by considering money saved from potential loss.The concept of Return on Security Investment (ROSI) provides a quantitative value in reference to the benefits attained through an investment in network security technology.“ROSI is calculated by the amount of risk reduced, less the amount spent, divided by the amount spent on controls, resulting in the net amount of risk per amount of control,” (Lindstrom, 2017).This value provides an indicator if the cost for security controls will outweigh the potential liability for penalties incurred due to network security breaches throughout the year.\nCybersecurity technologies are the primary line of defense for network intrusions.It is essential that an organization remain abreast with the latest security software and strategies to defend against emerging security threats.Acquiring the most effective technology requires a cost benefit analysis to ensure a reasonable correlation of mitigated risk is met.ROSI is used to evaluate whether the amount of potential money saved is higher or lower than the recommended security control investment, (Schneier, 2008).This resulting loss or gain will provide guidance as to whether it is cost effective to purchase the recommended security measure or not.\nNetwork security threats are imminent to organizations and network resources everywhere.Increased accessibility of a network resource is generally parallel to an increase in security vulnerabilities.It is essential that all input values be as accurate as possible to assume an effective value of investment.“Unfortunately, the cost of cyber security incidents and annual rate of occurrence are hard to estimate and the resulting numbers can vary highly from one environment to another.These approximations are often biased by our perception of the risk and the ROSI calculation can be easily manipulated,” (ENISA, 2012).The routine probability for error limits the potential effectiveness of the ROSI metric and should be analyzed on a case by case bases.\nThe ROSI calculation may even be utilized to evaluate the benefits of acquiring appropriate security measures for wearable technology.Take the smartwatch for example, as this product endures similar security vulnerabilities to a standard wireless network resource. There are third party antimalware security applications that may be purchased in addition to the use of advanced security and password features on the device, (Thomas, 2015).It is still necessary to confirm whether this investment in security control technology will yield savings or excess expenditures compared to the predicted losses without it.In this case, the resulting ROSI value may indicate that these low costing security applications may prove to be very cost effective, providing substantial savings against any potential futures losses incurred by a device security breach.\nENISA. (2012). Introduction to return on security investment. Retrieved from\nLindstrom, P. (2017). Return on security investment: the risky business of probability. Retrieved\nSchneier, B. (2008, September 2). Schneier on security: security ROI. Retrieved from\nThomas, K. (2015, April 15). How secure is your smartwatch? Retrieved from', 'In a previous post, I proposed a Monte Carlo simulation model that attempts to determine the probability that a security investment will result in a positive Return on Security Investment (ROSI). The model views security countermeasures and breaches as streams of cash flows and evaluates the Net Present Value (NPV) of each. To account for the inherent uncertainty in predicting the timing and cost of a breach, the model accepts ranges of possible outcomes and runs repeated simulations. By calculating the ROSI of many thousands of possible scenarios, the model allows the information security manager to estimate the likelihood that a specific countermeasure will pay for itself by mitigating the impact of a breach. Please see the earlier post for more detail on this model.\nIn this follow-up to that post, I propose a slightly different approach to the problem and present a revised version of the simulation tool. The revised version of the tool includes Annualized Rate of Occurrence (ARO) as one of the variables tested by repeated simulation.\nThe ARO Challenge\nOne drawback to my first model is that it requires you to enter a single estimate for the Annualized Rate of Occurrence (ARO). The model then uses this ARO for every subsequent simulation. If you think that a specific breach happens about once every 3 years, you enter 33% for the ARO, and the tool runs every simulation with a 33% chance of the breach happening each year.\nHowever, determining the ARO of a specific type of breach can be very difficult. For example, you may be hard pressed to estimate the number of times per year that someone will attempt a war driving attack on your organization’s WLAN. The ARO will be influenced by a number of factors, including the population density of the area, the accessibility of the campus, and so on. In spite of your best research, you might still not feel very confident about the ARO that you assign to this event.\nAccounting for Uncertainty in the ARO; Restating the Problem\nWith that challenge in mind, I realized that the ARO itself could be one of the variables in the model. Instead of asking you for one ARO, I realized I could just have the tool grind out more simulations. By running the simulation for multiple AROs, you can find a sort of tipping point. That is, you could find the ARO at which the model begins to produce a positive ROSI in a majority of the simulations. Put another way, you can determine how frequently the breach has to happen before the security investment makes sense.\nThis way, the task is not to determine a single ARO but rather to gauge whether the true ARO is probably higher or lower than the tipping point. Instead of trying to fix a number to some event, you just have to answer the question, “Do I think it will happen more or less frequently than X times per year.” In many cases, this will be an easier question to answer.\nTo use the war driving example from above, you might not be comfortable assigning a specific ARO, but what if any ARO of 33% or higher returns a positive ROSI in a majority of the simulations? Now your question is “Do I think war driving happens more or less than once every three years?” This might well be an easier question to answer.\nOnce you have the tipping point ARO, it may well be unnecessary to spend any more time determining a specific ARO. In the example above, do you really care much if the ARO is 75% or 90% if an ARO of 33% is sufficient to trigger the decision to buy?\nA Revised Simulation Model\nThe revised model takes this approach (download it from SkyDrive here). Like the original model, it accepts a range of values for the cost of a breach and the cost of the countermeasure. However, the revised model now tests AROs from 1% to a maximum set by the user. The model increments the ARO by 1% for each run of simulations, and records the percent of simulations at each ARO that return a positive ROSI.\nAfter you complete the worksheets for the cost of the breach and the countermeasure, you enter the maximum ARO you want to test. For example, you might enter a maximum ARO of 300% (you think the event is expected to occur no more than about three times a year). The model runs thousands of simulations with an ARO of 1%, then repeats the simulations with an ARO of 2%, then 3%, and so on up to 300%. The results of each run of simulations are displayed. You might learn than an ARO well below 300% makes the investment a good buy. On the other hand, you might learn that the investment is only worthwhile if the ARO is implausibly high.\nI took the example scenario described in my earlier post and fed the same streams of cash flows into the revised model. I then ran the simulation 2000 times at every ARO between 1% and 200%. The model ran all the simulations in a minute or two. The results can be seen in ROSI_Tool_2.xls (download here).\nAs you can see, in this example, an ARO of 14% gives about a 50-50 chance that the investment will turn out to be worthwhile. As the ARO goes higher, the likelihood of the investment paying off naturally increases. Thus, my question is, “Do I think this event will happen more than about once every seven years (an ARO of 14%)?” If I answer yes, then I can state that there is a better-than-even chance that the investment will turn out to pay for itself by mitigating a breach at some point in the life of the countermeasure.\nOf course, I might want to set the bar higher than a “better-than-even chance” if I’m making a business case for the investment. In that case, I can simply look to the ARO that produces the appropriate percentage of positive outcomes and ask whether I think the true ARO is above or below that number.\nAsking whether the ARO is above or below a certain number is not necessarily an easy question. It may still be impossible to answer in some cases. However, it should be easier than attempting to determine and stick to a single ARO.\nI think this approach complements my earlier version of the model. Once you complete the run of simulations with this version of the tool, you can input specific AROs into the earlier version for more detail on the outcomes, including the graphed results. The revised model presented here offers a slightly different way of looking at the problem and presents an additional tool the information security manager can use to analyze the business case for a security investment.']	['<urn:uuid:a6dac902-24ff-4053-b29f-22183510940a>', '<urn:uuid:b9670d26-9138-4a8c-880b-a16a51174fae>']	open-ended	direct	verbose-and-natural	distant-from-document	multi-aspect	novice	2025-05-01T23:46:40.222380	26	116	2273
394	manufacturing safety asrs storage benefits	Manufacturing safety and ASRS benefits combine in significant ways. In Li-ION cell manufacturing, safety is crucial during the cell finishing process due to risks of electrolyte fires and gas explosions, which is addressed through prevention techniques and passive safety enclosures. The ASRS system enhances safety by automating material handling, while also providing operational benefits across industries - it reduces worker injuries by delivering items at ergonomic heights, eliminates climbing ladders, and increases accuracy through inventory management software with features like barcode scanners and pick-to-light systems.	['PEC offers a turn-key integrated solution for all process steps after the electrolyte filling. In a single automated Cell Finishing Line the cells are routed through Soaking, Formation, Degassing, Roll-Pressing, Ageing, Grading and Sorting using an Automated Storage and Retrieval System (ASRS).\nThe heart of the Automated Cell Finishing lines are the cell formation towers. The formation towers are used for accurate formation, grading, DCIR and OCV measurements of the cells during the cell finishing process. PEC offers systems for cylindrical, pouch and prismatic cells, ranging from small to large format cell types.\nThe PEC inline tester is designed for running a fast qualification of alkaline and primary lithium cells during cell assembly or cell finishing. The inline test station is integrated in the line and works as a stand-alone module. The system is typically used for AA, AAA, C or D type cells and runs at a maximum speed of 1200 cells per minute.\n100% Manufacturing Safety\nThe complete cell finishing process forms the biggest risk factor in Li-ION factories. During this production stage the cells will be activated and will reach their rated capacity after several charge and discharge cycles. Individual performance will be checked against specifications using high C-rate pulses on the cells.\nDuring this process any cell or equipment related imperfection may lead to electrolyte fires, gas explosions and even worse a thermal runaway of a cell. Examples of these events are well known in the industry. Therefore, safety is PEC’s main concern in the design and continuous improvement of the automated cell finishing lines.\nThe key point of PEC’s safety design is prevention. The lines are equipped with a very long list of safety related techniques and features in order to prevent the thermal runaway from happening.\nOn top PEC’s unique formation station design offers a completely passive safety enclosure for any electrical process on the cells. In case of a thermal runaway of a cell the formation station protects the other cells and stations from propagation due to the fire and gas explosions.\nIntegrated MES System\nThe PEC cell finishing software is part of a complete manufacturing software solution, called MWare, covering all the functionalities required in cell and battery manufacturing plants.\nMWare is an in-house developed application that reflects our long history and experience in battery production.\nMWare supports the sequence of production steps from receiving raw materials over slurry mixing, coating, to the cell assembly. After the cell assembly, cells need to be formed,\naged and graded before they are assembled into modules and packs. PEC provides turn-key automated systems for these process steps, automating the complete cell handling from the electrolyte filling to the formed and sorted cells.\nSpecifically for these automated lines, the PEC formation software, part of the overall MWare solution, gives a complete answer to the following functional domains:\n- Manufacturing and Logistics Execution System\n- Process Control (creating and starting the correct formation and grading programs)\n- Order management and planning (managing the flow through the line)\n- Cell level traceability and quality assurance\n- Validation and rejecting the cells based on the measurement results\n- Management of the material handling systems\n- Operator Control System\n- Monitoring the processes, the equipment and the material handling systems\n- Alarm management and operator notification\n- Check Measurement results\n- Calibration Procedures\n- Reporting System\n- Monitoring order progress and work in progress\n- Analyzing and inspecting the results\n- Statistical analysis and trends (Yield report, Pareto Analysis of error codes, Production Progres reports…)\nTurnkey Automated Solution\nPEC integrates all process steps after the electrolyte filling in a single automated Cell Finishing Line. This single line includes equipment for Soaking, Roll-Pressing, Formation, Degassing, Ageing, Grading, End of Line Testing and finally Sorting.\nThe cells that enter the automated Cell Finishing Line are first loaded on a customized pallet, if required equipped with a clamping unit for prismatic cell types. Product and carrier are all uniquely identified with barcodes and RFID tags. This pallet is then transported through the different process steps by an Automated Store and Retrieval System (ASRS crane).\nThe modular line is configured with different building blocks to supply the required line capacity. A typical line includes the following building blocks:\n- Input and Output units\n- Soaking towers\n- Roll-press stations\n- Formation & Grading towers\n- OCV measurement\n- Room and High Temperature Ageing area\n- Degassing Stations\n- Sorting Stations\nManufacturing Cost Reduction\nThe target price per kWh for xEV applications is dropping fast in order to reach mass adoption of the electrified car. While many scientists and researchers are looking for the advancements in materials, PEC has achieved spectacular results in reducing the cost of cell finishing in both Capital Expenditures and Operational Costs.\n- Standard all-inclusive automated turn-key cell finishing line\n- Low cost design\n- Maximum investment protection\n- Low maintenance cost\n- 100% flexibility\nAfter the electrolyte filling of the cell the SEI layer (solid electrolyte interphase) is formed during the cell finishing process. The SEI is very critical for cell performance and cycle life as the SEI protects the active material in the cell.\nConsistency of the SEI is THE determining factor in cell cycle life, the most important characteristic in high cycle life applications (xEV, aerospace, defense, wearables…).\nAt PEC we have the technology and the experience for achieving this homogeneous SEI in prismatic, pouch and cylindrical type cells.\nPEC has worked on mass production projects where a 40% increase of cycle life has been achieved.', 'Automated storage and retrieval systems (ASRS) are found in nearly every industry in countries throughout the world. From manufacturing and wholesale distribution to warehousing, military, aerospace, vehicle dealerships, retail sales, mining, forestry, and more. Organizations interested in reducing cost and increasing productivity rely on AS/RS material handling equipment. There are three main types of AS/RS machines: automated vertical lifts, automated vertical carousels, and automated horizontal picking systems. Each of these automated storage solutions uses the goods-to-person principle to make inventory and parts storage and retrieval more effective.\nHow Automatic Parts Retrieval Works Using the Goods-to-Person Principle\nInstead of multiple persons walking to multiple locations in a warehouse to pick multiple parts, inventory and parts (up to thousands) are stored in one location, delivered to one operator, and picked by the same operator. Picking operations can also be performed by crane assist or other mechanical manipulators to lift heavy items. Inventory management software directs the AS/RS systems to deliver the item to an operator at an ergonomic height. Picking aids, such as bar code scanners, LED light, pick-to-light, and laser pointers, confirm or visually assist the operator to accurately pick items.\nThe inventory management software, combined with the AS/RS equipment, significantly increases productivity, improves accuracy, and reduces work related injuries. Employees no longer waste company time looking for inventory, and since items are delivered at an ergonomic level by the AS/RS system, injury occurring while bending, twisting or climbing ladders to retrieve inventory is significantly reduced or eliminated.\nBrief Explanation of the Three Different Types of AS/RS Systems\nThe type of AS/RS system that will best suit you depends on the type of material handling and processes of your facility. It may be that only one, or a combination of all 3 will work best for you.\nAutomated Vertical Lifts utilize a high speed “elevator” (lift) that goes up and down between two walls of storage shelves that face each other. The system is fully enclosed for safety and security. When directed by software, the lift will retrieve a tray from a shelf containing the desired item and deliver the tray to the operator bay, where the operator then picks the item from the tray. The software instructs the AS/RS system to store shelves/trays dynamically. In other words, sensors will measure the tallest item height on any given tray. The measurements are calculated and the software then instructs the shelves to store as close as 1” above the tallest item. Dynamic storage eliminates unused airspace and optimizes high density storage. Vertical lifts come in varying heights (8’ to 100’ approx.), are deeper than vertical carousels and store about twice as much.\nAutomated vertical carousels, on the other hand, store shelves in fixed positions on an elliptical track (similar to a ferris wheel). You can choose the amount of space between shelves, but once in place, it is very cumbersome to reposition. The shelves can be rotated forward or backward to bring them at ergonomic level to the operator to retrieve items on shelves. The shelves can further be divided with partitions, bins and boxes. As with vertical lifts, vertical carousels use the air space above traditional storage, and significantly reduce your storage footprint. You can recover up to 75% of your floor space by going vertical with a carousel. Carousels are ideal for small parts and inventory and uniformly sized inventory (such as tires, bankers boxes, etc.)\nHorizontal automated picking systems rotate shelves on a horizontal elliptical track to a pick up / delivery workstation. These picking systems provide exceptional throughput capabilities in high volume pick applications such as distribution centers. When the horizontal systems are grouped into pods, batch picking is easy and efficient.']	['<urn:uuid:ee51e566-a881-4b11-8f8c-35629852853a>', '<urn:uuid:578ec609-8fa7-4f05-a056-0b3a8ef57e9e>']	open-ended	direct	short-search-query	similar-to-document	multi-aspect	novice	2025-05-01T23:46:40.222380	5	85	1532
395	What's the role of context in space design and DC's guidelines?	Context is crucial as design functionality results from how elements are configured within a site's location and orientation, with guidelines needing to emphasize planning for anticipated activities rather than standard checklists. Washington DC applies this principle by having additional specific streetscape requirements for areas like Downtown, NoMa, Mount Vernon Triangle, and Buzzard Point that reflect their unique characteristics and take advantage of context-specific opportunities.	['By Ensiyeh Ghavampour, AECOM Auckland, Mark Del Aguila, TAFE, SA and Brenda Vale, Victoria University of Wellington\nIn inner urban areas, where land values are high and city governments have limited budgets, designing successful public spaces and using resources wisely is essential. With the increasing need for more quality public spaces in cities, planning authorities usually prepare design guidelines based on international research to help ensure quality will be achieved. However, with design guidelines failing to create quality spaces with enduring success, placeless spaces continually need to be redeveloped. There are many successful public spaces around the world, however, the application of guidelines developed from observations and surveys of these spaces creates visionary spaces without connections to their context. With spaces lacking character and failing to fit with local use, there is an increasing demand for a rethinking of design methodology in public open space.\nOur paper, ‘A GIS Mapping & Analysis of Behaviour in Small Urban Public Spaces’, recently published in Area, investigates links between behaviour and design in context. Using time interval still photography, activity in four small public spaces in Wellington CBD (New Zealand) was recorded and mapped with GIS. Comprehensive and detailed analyses of activity, age, gender, group size, and length of stay indicated that:\n- Design elements can be successful in one space, yet under-utilised in a different context.\n- Functionality of a design is a result of the configuration of elements within the site with respect to the site’s location and orientation.\n- Guidelines should direct designers toward creation of spaces that afford opportunities for users rather than focusing on checklists of specific design elements\n- The process of defining and setting design guidelines for the physical environment should be re-conceptualised with an emphasis on planning for anticipated activities.\nAbout the authors: Ensiyeh Ghavampour is an Urban Designer at AECOM, she has a PhD in Urban Design and Landscape Architecture from Victoria University of Wellington. Mark Del Aguila, Advanced Building Studies, TAFE SA, and Brenda Vale is a Professorial Research Fellow in the School of Architecture at Victoria University of Wellington.\nBliss, L. 2017 The High Line’s Next Balancing Act Citylab Online 7 Feb 7 2017\nCathcart-Keays, A. 2015 Guardian ‘mayors for a day’ demand more public spaces in their cities The Guardian Online 29 January 2015\nCarrington, D. 2013 England’s parks and open spaces have lost £75m in cuts since 2010 The Guardian Online 19 November 2016\nGhavampour, E., Del Aguila, M. and Vale, B. (2017), GIS mapping and analysis of behaviour in small urban public spaces. Area. doi: 10.1111/area.12323\nHemmelgarn, S. 2017 Milk Plaza Redesign gets $500 K Bay Area Reporter Online Volume 7/ No. 7/ 16 February 2017\nJohnson C, 2016 Can Design Quality Be Regulated? Sourceable Online 18 October 2016\nMccrary, L. 2016 Modernism, Food, and Public Space New Urbs Online 15 September 2016\nPersico, A. 2016 Rethinking Park Space Yorkregion Online 16 June 2016\nWaxmann, L. 2016 Troubled Public Plaza Will Be Fenced Off To Divert Homeless Mission Local Online 27 July 2016', 'Streetscape Design Guidelines\nThe design of Washington, DC’s public space is one of several qualities that sets the city apart from other American cities. Washington, DC has a long history of using public space to shape the city’s image and improve living conditions in a dense urban environment. Starting with the Parking Act of 1870, legislation passed by Congress gave the city the authority to set aside part of the right-of-way as park land. Regulations are still in place today that protect the area between the sidewalk and property line (or building restriction line) as part of the city’s park and open space system. This enduring feature of the city contributes to the park-like character of streets and reputation as a walkable city. Washington, DC has continued this tradition to the present day, promoting the protection of green space in residential areas and creating guidelines for commercial areas and developing neighborhoods to encourage public space that is an attractive part of community life and a transportation system with characteristics distinct to specific neighborhoods.\nA streetscape is the result of two things: the physical environment and the uses that take place within public space. To help shape the character of new areas that are in the development phase and protect the quality of existing neighborhoods, the District’s streetscape standards, guidelines, and policies guide changes to public space. Physical features that are reviewed for design include sidewalks, landscape, fences, retaining walls, street trees, and other infrastructure like street lights or curb and gutters. Uses that impact the character of public space include sidewalk cafes, vending, street festivals, and other temporary activities.\nIn partnership with the District Department of Transportation, the Office of Planning works with District agencies, residents, and the private sector to ensure the design of public space is of high quality and meets minimum requirements. Every property owner plays a role in maintaining the city’s public spaces. Homeowners are responsible for maintaining the green space in front of their property that looks like a front yard but is often public space and part of the city’s park and open space system. In commercial areas, wide sidewalks provide spaces for businesses to display merchandise or operate sidewalk cafes. The city’s standards and regulations for public space apply to all parts of the city. There are some areas - such as the Downtown, NoMa, Mount Vernon Triangle, Florida Avenue Market, and Buzzard Point – that have additional streetscape requirements that reflect their location and unique characteristics that take advantage of context-specific opportunities.\nThe Government of the District of Columbia encourages everyone to understand the importance of our shared public space. It is important to understand how your efforts fit into larger goals for the city to use public space in a way that enhances communities across the District. For more information, contact Chris Shaheen, Public Space Program Manager of the DC Office of Planning at (202) 442-7616 or by email at [email protected] Design Guidelines\n- Buzzard Point Streetscape Guidelines\n- Columbia Heights Public Realm Framework Plan\n- Downtown Streetscape Regulations\n- Union Market Streetscape Design Guidelines\n- Mount Vernon Triangle Transportation and Public Realm Design Project\n- NoMa Streetscape Guidelines\n- Public Realm Design Manual\n- Public Realm Handbook']	['<urn:uuid:f83d4c6c-da16-4d66-b2d0-a276beb5c5cf>', '<urn:uuid:a466b2dc-c4da-49a0-b766-393f0b1efb43>']	factoid	with-premise	concise-and-natural	distant-from-document	multi-aspect	expert	2025-05-01T23:46:40.222380	11	64	1042
398	erosion process effects winooski river pictured rocks compare geological formations	Both water bodies demonstrate significant erosional processes but in different ways. The Winooski River forms gorges and cascades through erosion, where fast-flowing water erodes sediment from the bottom and carries it downstream, creating features like potholes in turbulent water areas. At Pictured Rocks, erosion by waves, wind, and ice creates sea caves, particularly in the softer Chapel Member of the Munising Formation of Sandstone, resulting in features like Rainbow Cave.	"[""The Winooski River begins east of the Green Mountains, cuts through them, and then empties into Lake Champlain. Most of Vermont' s rivers are referred to as subsequent which means they flow parallel to a mountain range. The Winooski River, however, is what geologists call a superimposed river, which means that it flows perpendicular to the mountain range. This means that the Winooski River predates the mountain range and was able to cut through the Green Mountains at the same rate at which the mountains rose 450 million years ago.\nGeologic features form as a result of continuous hydrologic processes over very long periods of time. As water flows over bedrock, it erodes and deposits material that, in turn, forms a variety of structures within the channel. The different flow rates form different structures. Where the river flows fast, it erodes sediment from the bottom and carries it downstream. Where it slows down, it deposits the sediment back on the bottom. For example, in a river meander (s-curve) the outer bank is being eroded while the inner bank receives sediment. This dynamic process allows the river to migrate over the entire floodplain. When the natural character of a river is altered, for example by damming, building bridges, road beds and railroad beds, the hydrologic processes governing the river are no longer the same.\nWaterfalls, cascades, and gorges are among the many geologic features which give the Winooski River its unique natural character. On your Winooski River journey you may observe these three gorges, one fall, and a cascade.\nBefore Middlesex Gorge, the Winooski River alluvial plain averages over 100 feet in width. Upon entering the gorge, which is about 1,000 feet long with high angled rock walls (20 to 60 feet high), it narrows to a width of 15 to 30 feet. The rocks are vertically bedded schist and contain potholes which form in rocks beneath turbulent water.\nThere is a power dam at the bottom of the Bolton Falls Gorge. It is not a natural fall, and the site has been redeveloped to once again produce hydroelectric power.\nAllen Brook Cascade\nA cascade differs from a waterfall in that the water never falls free from the bedrock. Allen Brook (near Muddy Brook) is a small stream, three to five feet wide, which cascades about 200 feet downstream, dropping a total of 20 feet. Small potholes are common in this area of dolomitic bedrock.\nLime Kiln Gorge\nIn Lime Kiln Gorge, which extends about 250 feet, the Winooski River flows about 70 feet wide. The walls are nearly vertical and rise 15 to 70 feet. The limestone bedrock forms steep, fractured and jagged walls. There are rippled rocks at the upstream end of the gorge and several caves on the north shore.\nThe Winooski Gorge is a uniquely formed gorge which is dammed, and relatively inaccessible. The gorge is more than 150 feet across at its narrowest point. The walls range from 50 to 80 feet high, and are composed of dolomitic limestone. Small caves exist along the walls of the river and flooded portions of the gorge may also contain large potholes and sculpted ledges."", 'PIRO: The “Painted” Pictured Rocks\nFigure 1. Pictured Rocks Cliffs Photograph by: Beth Dondit\nWhy are the Pictured Rocks the “Pictured Rocks?” What caused the colors to form on the cliffs? How did it happen?\nThe Pictured Rocks cliffs span approximately 15 miles from the Beaver Basin west to Munising, MI. The cliffs are constantly being weathered and eroded by the powerful forces of the water, waves, wind and ice. A sea cave can form when a softer rock is affected by erosion. The Chapel Member of the Munising Formation of Sandstone is this softer layer. Waves, wind, etc. have slowly eroded “Rainbow Cave” over a long period of time. Inside this sea cave, you will see many colors along the rock walls/ceiling. The staining or nature’s painting, has left quite a canvas inside this cave. When groundwater seeps through porous rocks, the minerals in the groundwater also seep through, and leave behind colors to mark their presence. Green and blue colors come from copper; black from manganese, or tannins originating in the streams; orange and red come from iron; and white from limonite. Water follows the path of least resistance, and travels downwards (gravity). The water table here is higher than Lake Superior, thus water is moving to the lowest point possible. This is very evident inside the “Rainbow Cave.”\nFigure 2. Natural Paintings on the Pictured Rocks Cliffs Photograph by: Beth Dondit\nLogging Your Visit:\nL1: At this location, what is the most prominent color in the cave? What mineral caused that coloration?\nL2: What is the most unique color here? What mineral “painted” this color?\nL3: What force caused this landform to form?\nL4: What is causing the “rain” inside the cave? Where is it coming from?\nFigure 3. “Rainbow Cave” in the distance Photograph by: Beth Dondit\nEarth Science Literacy Principles Big Ideas:\nEarth Science Literacy Big Idea 4- Earth is continually changing.\nEarth materials take many different forms as they cycle through the geosphere.\nAs water and minerals travel through both the hydrological cycle/geosphere, they continually shape our Earth’s landscape. Evidence of this is easily viewed along the Pictured Rocks coast. Even more impressive from a kayak, viewing the features firsthand (beware of changing weather conditions, clapotis, and cracks/fractures, which could amount to falling rocks).\nThe mineral deposits/stains that paint the Pictured Rocks are very colorful and impressive. The minerals seep through the porous sandstone layers, with the groundwater, and leave their mark.\nCommon Earth Science Misconceptions:\nMinerals are only found in rocks, as solids, and they don’t change forms.\nRocks are solid, hard surfaces that don’t change shape/form.\nRocks are hard, nonporous substances.\nMichigan State Content Expectations:\nGrade 3- E.SE.E.2- Surface Changes- The surface of the Earth changes. Some changes are due to slow\nprocesses, such as erosion and weathering; and some are due to rapid processes, such as landslides, volcanic eruptions, and earthquakes.\nGrade 6- E.SE.06.12- Earth’s Changing Surface- Explain how waves, wind, water, and glacier movement,\nshape and reshape the land surface of the Earth by eroding rock in some areas and depositing sediments in other areas.\nClapotis- “confused seas.” This occurs when waves hit large cliffs, and bounce off, connecting with other waves, creating large, multi-directional wave patterns.\nBlewett, William L. Geology and Landscape of Michigan’s Pictured Rocks National Lakeshore and Vicinity. Detroit, MI: Wayne State University Press,\nNational Park Service. “Pictured Rocks: Frequenly Asked Questions.” 11 June 2012. <http://www.nps.gov/piro/faqs.htm.>']"	['<urn:uuid:1bf52ae7-a2d3-4085-a1a4-928462380373>', '<urn:uuid:19a45410-c030-465f-97e0-8555075f9967>']	factoid	direct	long-search-query	distant-from-document	comparison	expert	2025-05-01T23:46:40.222380	10	70	1095
399	future urban planning downtown developments disability needs smart technology integration	Urban planning is evolving to address both downtown development and accessibility needs. In Clawson, the downtown is being transformed from a drive-through to a drive-to destination, with experts helping develop economic plans that preserve historical features while enhancing community spaces. Looking to the future, smart city development must consider that the population is becoming older and less mobile, with sight loss expected to affect four million people by 2050. The integration of smart technology in urban spaces needs to support both historical character and accessibility, including features like autonomous vehicles, smart street furniture, and technology that enables independent mobility. Cities must balance traditional downtown character with modern inclusive design principles to ensure all citizens can fully participate in community life.	['Clawson is on the road to further improving its downtown and getting help from experts from around the country through the Main Street Oakland County program.\n“The goal is to capture what we have that is unique and enhance it,” said Joan Horton, executive director of Clawson’s Downtown Development Authority. ”We have gone from having a drive-through downtown to having a drive-to downtown with destination businesses.”\nThe county initiative is affiliated with the National Main Street Center, a program of the National Trust for Historic Preservation in Washington, D.C.\nSince 2000, 13 communities have joined Main Street Oakland and seen hundreds of millions of dollars of investment and upgrades in their downtowns.\nClawson is the most recent downtown to become accredited to the program, joining cities such as Ferndale, Rochester, Royal Oak, Pontiac and others.\nThe communities benefit by getting free advice and resources from top consultants.\nA resource team of experts in organization, promotion, design and economic restructuring spent two days in Clawson this week, Horton said.\nThe team is working to help Clawson officials develop a plan for economic development that preserves key historical and community features in the downtown.\n“The experts met with 71 people and 19 focus groups while they were here,” Horton said.\nLocal people interviewed included everyone from business owners and residents, to school and city officials and realtors, she added.\nOne common thing the Main Street consultants heard from those they talked to in Clawson was a sense of community pride.\nKathy La Plante, senior program officer with the National Trust Main Street Center, lives in New Hampshire and was one of the four consultants who visited Clawson.\nThe team was impressed with the city and the DDA’s commitment to improving the downtown district, she said. The city two years ago undertook a major $1.2 million streetscape improvement project, adding new streetlights, on-street parking, trees and other features in the downtown.\n“Reinvestment has been significant from both the public and private sectors,” La Plante said, “which has spurred more reinvestments and excitement in the downtown.”\nThe downtown covers almost 40 acres along four long city blocks centered around 14 Mile Road and Main Street.\nLa Plante said the resource team also noted the number of unique destination businesses in the downtown such as Leon & Lulu, Wunderground Magic and the Michigan Harp Store.\n“With continued marketing and business recruitment, the downtown will continue to improve,” La Plante said.\nClawson’s commercial buildings date chiefly from the suburban boom years following World War II.\n“We have post-war details in our architecture that stand out,” Horton said after consulting with the team’s architectural expert. “There is beauty in that which some don’t see because they think buildings have to be 100 years old to be historic.”\nThose interviewed by the Main Street team also indicated they wanted to see the city’s downtown maintain its community roots.\n“They want the downtown to stay true to its character,” Horton said. “They don’t want it to be like Royal Oak’s downtown, or the downtown’s in other cities.”\nThe Main Street team’s final report will be unveiled in August with a public event and power point presentation.', 'The future doesn’t belong to the young and able-bodied. It is older, more urban and less mobile than you think. It is also, to put it bluntly, blinder.\nThe numbers of those living with sight loss in the UK are set to double to four million by 2050. This will create enormous challenges for those involved in creating the built environment. But it’s not a challenge we can or should avoid. Instead it is an enormous opportunity to future-proof your projects by putting inclusivity at the top of the agenda for the benefit of all. And profiting from a vastly under-serviced disabled community controlling £249 billion in spending power.\nGuide Dogs is recognised globally as an expert in mobility and inclusivity. After all, for more than 80 years we’ve been working to ensure that people living with sight loss are not excluded from life. Though best known for our guide dogs, they are only a part of what we do. We bring the same expertise to our children and young people’s services and our My Guide sighted guiding service. Increasingly, we are also pioneering the design and deployment of smart tech to get people out and about.\nAs the UK’s leading sight loss charity specialising in mobility, particularly in relation to the built environment, we believe that everyone, regardless of their ability should be able to get out and about safely and confidently; be that to study, to work, to shop, to look after grandchildren, to maintain their health and fitness and so on. In short, we feel that no one should be left out of life.\nThis article aims to educate and challenge current thought leadership and emerging policies concerning the development of our Smart Cities, and the design and deployment of digital technologies and their impact on citizen wellbeing. We want to ensure that future Infrastructure and Smart City solutions serve the needs of all sectors of society; including people living with sensory loss, older people, people with physical disability, and people with learning disabilities. These sectors of society are so often forgotten and have struggled for years in a world defined by a legacy of Victorian infrastructure; as we move to the next great era of technology innovation, our policies and standards for city design and infrastructure investment need to proactively champion inclusivity for everyone.\nInclusion for all sectors of society surely has to be an important metric to attain ‘Smart City’ status.\nThe UK is leading the way on the development of Smart Cities; where advances in digital technologies and open-data are finding new ways to augment and improve the world we live in. But our Smart Cities should not just be about the deployment of innovative technologies to increase efficiency or economic growth; the degree to which our cities are smart also affects citizen wellbeing and the way we interact with our environments and communities in everyday life. Indeed, in 2013 the Department for Business Innovation and Skills noted that “A Smart City should enable every citizen to engage with all the services on offer, public as well as private, in a way best suited to his or her needs.1\nThe UK is a signatory to the United Nations Convention on the Rights of Persons with Disabilities. This places obligations on the government, including article nine which requires State Parties to (amongst other things): “take steps to ensure that disabled people are able to access the physical environment which embraces buildings, roads, transportation and other indoor and outdoor facilities.2\nUndoubtedly, we are currently witnessing a convergence between technology innovation and policy thinking; in 2017 the UK government published its long awaited UK Digital Strategy3 and a green paper setting out its plans for the UK Industrial Strategy4, and the City Standards Institute has recently published new standards for smart city development5. Whilst these documents are addressing some of the big issues and mega-trends facing society, they have not yet adequately covered the need to accommodate the needs of nearly 12 million people living with disabilities in the UK.\nIn 2014 The Office for Disability Issues noted “There are over 11 million people with a limiting long term illness, impairment or disability. The prevalence of disability rises with age. Around 6% of children are disabled, 16% of working age adults and 45% of adults over State Pension age.” With so many people affected, inclusion for all sectors of society surely has to be an important metric to attain ‘Smart City’ status, and hence surely has to be better embedded within the thought leadership behind our infrastructure policies and investment decisions.\nIt affects both the quality of life of individuals and the equity and cohesion of society as a whole.\nDespite the current national focus on defining strategies and guidance for the next era of city and infrastructure investment, sadly, many people with sight loss, people with other disabilities and older people are still unable to participate fully in community life due to public ignorance, poor design and bad service delivery. Guide Dogs is seeking support for a more collaborative approach to the co-creation of inclusive environments; where the interaction between people and their physical or virtual environments allows them to get around safely and confidently, with minimum fuss and maximum independence.\nToday, many everyday services and environments tend to operate in a default mode and an accessibility mode. Unless there is significant pressure during the design phase of a new system or environment, far more attention is given to the default mode, and the accessibility mode is often not a primary concern. This tends to result in sub-optimal experiences for older people and people living with a disability, and sometimes it can mean total exclusion.\n“Social exclusion is a complex and multi-dimensional process. It involves the lack or denial of resources, rights, goods and services, and the inability to participate in the normal relationships and activities available to the majority of people in a society, whether in economic, social, cultural or political arenas. It affects both the quality of life of individuals and the equity and cohesion of society as a whole.”6\nInclusive environments combine the design of the built environment and transport, retail and entertainment services with new digital technologies to deliver consistent and joined-up customer experiences that often transcend any single service provider’s remit. Collaboration and interoperability of this nature will require central support and facilitation to seed a new approach to designing and delivering positive joined-up services and customer experiences, powered and enabled by appropriate infrastructures and technologies.\nIn a climate of increasing devolution, city administrations require clear guidance and support to ensure that their Smart Cities are actively focussed on delivering inclusive environments and communities for disabled people. In short, ‘Inclusion’ must be given equal prominence and investment amongst other smart city themes (e.g. energy, transport, environment, etc.).\nOfficial disability facts and figures published on the government website in 2014 noted “A substantially higher proportion of individuals who live in families with disabled members live in poverty, compared to individuals who live in families where no one is disabled.” This impacts millions of people, and whilst many people with disabilities are living on the poverty line, the combined spending power of disabled households is still significant: “In 2014/15 disabled people and their families in the UK had an aggregate annual household income of £249 billion, up from £212 billion in 2012/13.7 So, there is both a social obligation and an economic incentive to encourage innovators and service providers to embrace social inclusion.\nWhen considering the UK’s future infrastructure investments consideration should also be given to achieving the right balance in the solutions-mix (hi-tech, lo-tech and person to person services) and demonstrate how ‘digitally excluded’ members of society can easily, confidently and safely participate in society. Similarly, initiatives need to demonstrate how solutions are equally applicable to residents in rural communities as they are to those living in cities.\nThe aforementioned UK Digital Strategy clearly notes the growth of digital solutions in all aspects of life and the economy, and it references the need to close the digital divide – this is a problem that has been known for many years, yet still significant numbers of disabled and older people are unable to use digital solutions because the technology and operating policies are often poorly designed, inaccessible, expensive and there is a lack of awareness and training support. This is particularly the case for people with sight loss.\nDigital solutions have great potential to assist many disabled and elderly people in everyday life, but our future infrastructure assessments also need to address the many issues associated with poor town planning, street design, building architecture and public services.\nThe decisions and policies that we make today will affect the world that we all grow old in tomorrow, so our infrastructure policies, smart city standards, public contracting processes and economic models should proactively champion inclusivity for everyone, so that city administrations and solutions providers are actively challenging themselves at every step to ask and answer questions such as “can this solution be used by, and be of benefit to, older people and people who are disabled?”\nIn particular, designers and policy makers often tend to think of disability purely in terms of step-free access for wheelchair users – they rarely test their project solutions from the perspective of people living with sight loss, hearing loss, or cognitive difficulties. In the modern age this is no longer acceptable.\nOver 70% of registered blind and partially sighted people of working age are unemployed.\nLooking forward, autonomous vehicles, smart street furniture and more considerate architecture and street designs all have great potential to help people who are disabled to lead integrated and independent lives. Infrastructure that improves connectivity and supports the use of artificial intelligence and machine learning can also be used to support mobility in both outdoor and indoor environments. However, if we do not actively focus attention now on ‘inclusivity’ at all stages of the strategy, design and implementation processes, then the UK will fail in its drive to create smart cities – as cities that continue to exclude millions of citizens cannot be considered smart!\nInfrastructure that supports virtual and physical connectivity will promote independence and greatly enable disabled people to fully participate in higher education, employment and to become positive contributors to the economy. For example, research conducted in 2015 with 1,200 respondents identified that over 70% of registered blind and partially sighted people of working age are unemployed8. A shocking statistic compared to the 5% unemployment figure for the general population.\nInclusive transport infrastructure can promote smooth, safe and independent travel, giving disabled people the same ability to simply ‘turn up and go’ without the need to book assistance in advance. This will save time and stress for the traveller and the service provider. It is well documented in design literature that adopting a ‘universal design’ approach benefits everyone – designing for the UK’s most challenged users delivers results that benefit and delight all users, regardless of their abilities or disabilities.\nStrong proactive steps are needed now to design-in inclusivity on all new infrastructure projects.\nWe are on the cusp of multiple technologies converging at a time when government support and guidance is most needed to ensure that marginalised communities are finally brought into the mainstream in terms of education, employment, health, social wellbeing and net contribution to the economy. There are many research projects underway in the UK and abroad investigating how advances in technology can assist disabled people, but these projects require access to real-world infrastructure to break out of the research environment to become scalable solutions.\nStrong proactive steps are needed now to design-in inclusivity on all new infrastructure projects – be they schemes to replace old street lights with intelligent lampposts, or the roll-out of autonomous vehicles from 2020 onwards. In particular, thought leadership is required to ensure that there are no negative impacts of changes made to our infrastructure – for example will the introduction of autonomous vehicles lead to changes in street design that will have negative consequences for disabled pedestrians? We have already seen controlled level crossings being removed from ‘shared surface’ street schemes which has created no-go zones for some disabled users – a problem that could have been avoided if these schemes adopted the following 6 design principles for inclusive design:\nPrinciple 1: Co-production and assessing the impact of change – working together for the benefit of everyone\nPrinciple 2: Complying with standards but striving for excellence – the importance of continuous improvement\nPrinciple 3: Joined-up travel, retail and entertainment experiences – facilitating smooth and stress-free participation in community life\nPrinciple 4: Seamless processes and operating Systems – interoperability and making the most of technology\nPrinciple 5: Using clear language and information – creating an environment that everyone understands\nPrinciple 6: Design that influences public and staff behaviour – using our intuition\nWe are not alone in recognising the importance of taking an inclusive approach to design. The architecture and design community also appreciates the need to get things right. Yes, so that high streets can look nice and welcoming in order to increase footfall for retail outlets and boost local economies, but inclusive design also impacts on health and wellbeing and community cohesion.\nThe possibilities are endless, if we all work together!\nThe Commission for the Architecture in the Built Environment (CABE) summed it up nicely: “Inclusive design is about making places that everyone can use. The quality of buildings and spaces has a strong influence on the quality of people’s lives. Decisions about the design, planning and management of places can enhance or restrict a sense of belonging. They can increase or reduce feelings of security, mobility, and improve or damage health. They can remove real and imagined barriers between communities and foster understanding and generosity of spirit.”\nSo, what does a future smart city experience look like for a blind or partially sighted person? We have prepared the following simple use cases to get you thinking – the possibilities are endless, if we all work together!\nSmart Home: You’re running late for a friend. Pulling on your coat, you tell the house to have the chops in the oven cooked by 7pm, to switch the heating on at 6pm and play some burglar-deterring radio all day.\nSmart Streets: You walk into town passing smart lampposts. Their free Wi-Fi and Bluetooth complements your satnav telling you exactly where you are and warning you that you’re approaching a shared surface.\nAutonomous Taxi: Rain is imminent, so you ask your phone to call an autonomous taxi. They know your needs, billing is fully automated, and the accessible vehicle is easy to locate and use.\nSmart Retail: It’s your friend’s birthday and you need to pick up a gift. Quickly matching your budget with her tastes, your smart aisle finder easily guides you to suitable products in the store.\nEntertainment: Your tech helps find your friend in a crowded gallery. The customer experience doesn’t just navigate you through the accessible building – the highly amusing commentary empowers you to discover and select exhibits, too.\nPublic Transport: Heading home, your tech locates a bus stop over the road and says your bus is just 90 seconds away. You board, aided by a driver who’s received compulsory disability training – and arrive to a warm home in time to enjoy your chops.\n1 Department for Business Innovation and Skills. Smart Cities Background Paper. (2013)\n2 United Nations Convention on the Rights of Persons with Disabilities. (2006)\n3 Department for Culture, Media and Sport. Policy Paper, UK Digital Strategy. (2017)\n4 Department for Business, Energy and Industrial Strategy. Green Paper, Building our Industrial Strategy. (2017)\n5 British Standards Institute. PAS 183 Smart cities – Guide to establishing a decision-making framework for sharing data and information services. PAS 184 Smart Cities – Guide to developing project proposals for delivering smart city solutions. (2017)\n6 Levitas et al. The Multi-Dimensional Analysis of Social Exclusion. (2007)\n7 Department for Work and Pensions. The spending power of disabled people and their families. (2016)\n8 John Slade and Rose Edwards. My Voice 2015: The views and experiences of blind and partially sighted people in the UK. RNIB. (2015)\nThumbnail image: chuttersnap']	['<urn:uuid:90b93823-8972-44ba-b372-d4d472671207>', '<urn:uuid:3bb232b8-9678-41ea-af46-d1bd891a6236>']	open-ended	with-premise	long-search-query	similar-to-document	multi-aspect	expert	2025-05-01T23:46:40.222380	10	120	3235
400	What specific measures has Beneteau implemented to reduce their environmental impact in their industrial operations?	Beneteau has implemented several measures including using geothermal heating and a glazed façade with photovoltaic shading-glazed canopy in their headquarters, establishing non-emissive transformation processes in their composite workshop to reduce VOC emissions, and implementing a waste control process to reduce waste creation and increase recycling.	['- YELKENLİ TEKNELER\n- Oceanis Yacht\n- Figaro BENETEAU 3\n- TÜM YELKENLİ MODELLERİ GÖR\n- Gran Turismo\n- Swift Trawler\n- TÜM MOTORLU MODELLERİ GÖR\n- MONTE CARLO\n- BENETEAU CAZİBESİ\n- BENETEAU SERVİSLERİ\n- MİMAR VE TASARIMCILAR\n- YELKENLİ TEKNELER\n- Beneteau İletişim Ağı\nWhen you choose a Beneteau, you benefit from expertise second to none. From R&D to industrialisation, the brand and the group have been working for over 130 years to build innovative, reliable and competitive boats.\nExcelling in material expertise\nFor over 130 years, BENETEAU has been searching for increasingly innovative solutions to develop high performing, robust and environmentally friendly boats for a wide public. Pioneers in the use and implementation of new materials, the R&D engineers and technicians work towards continuous progress and improvement. They develop technology that meets the increasing demands of design, practicality and quality.\nSince the structure of boats is constantly subjected to external stresses, it is of huge strategical importance to have expertise in composites as well as their implementation. In often complicated assemblies, materials must have a number of intrinsic qualities and maintain them, to stand the test of time in very varied environments. The group has a laboratory that carries out in-depth tests to achieve irreproachable quality. Beneteau has unique experience combined with own-developed structural engineering tools and this has made it a leader in this field. Excelling in the distribution of material, they can build boats that are both light and strong.\nEfficiency and sharing\nFrom the launch of a new project at the design office into the delivery of its boats, Beneteau depends on an intelligent life-cycle management solution (Product Lifecycle Management), which enables them to manage complicated processes. A unique and secure source of information shared by all the players considerably increases the company’s performance enabling it to develop and build its ever more reliable and competitive boats within a short timeframe.\nBy coordinating the work of all the teams involved in the design and manufacturing line, the simultaneous modelling of complex surfaces, the optimisation of composite parts, the management of space, and the definition of equipment and fittings on board the boat can be achieved with PLM combined with CAD (Computer-Aided Design) and CAM (Computer-Aided Manufacturing) tools.\nOf wood and men\nGenerations of men and women, with a love of wood and work well done, have succeeded each other at Beneteau’s cabinetmaking workshop, for nearly 40 years. With modernity and rigour they have turned a craft-based organisation into an industrial organisation, while preserving the trade’s nobility and their broad expertise.\nTables and doors, companionway steps and furniture, fiddles and other decorative pieces are formed, stained and polished in the 27,000 m² cabinetmaking workshop, bestowing the interior of each boat with nobility and elegance.\nFocussed on offering a wide choice to customers of the brand, Beneteau’s cabinetmaking workshop has been reorganised in recent years to offer several different wood types by boat model and to develop new finishes (closed pore, open pore, high-gloss, lacquers, brushed words, soft touch, etc.) The workshop located in Vendée is well-known for its age-old know-how in the manufacture of plywood and solid woods, as well as in the making of moulded wood, and it supplies the Beneteau production sites, including the United States. Today it is the biggest cabinetmaking centre in Europe.\nBeneteau has a continuous quality improvement dynamic for its products and processes, with the goal of doing everything possible to guarantee their owners confidence and peace of mind.\nWith the aim of keeping control of its capacity to deliver boats complying with very strict quality standards, Beneteau obtained ISO 9001 certification, in 2003, and this is reassessed successfully every year by an independent organisation. This has meant that the development of new models, purchases, industrial manufacture and respecting deadlines have all been the subject of procedures and methodical inspection. Based on the principles of lean manufacturing, the continuous improvement approach is very pragmatic and involves all the company’s staff.\nThe environmental policy implemented by Beneteau is based on two major challenges: the reduction of the impact of boatbuilding and reducing the ecological footprint of their boats.\nAmong the pioneers in this field, Beneteau was awarded ISO 50001 certification in 2015, demonstrating that it has taken all possible measures to manage energy and even reduce greenhouse gas emissions and decrease costs. With geothermal heating and a glazed façade as well as a photovoltaic shading-glazed canopy, the new brand headquarters, inaugurated in 2014, is a remarkable building in this regard.\nBeneteau has also invested heavily in its industrial tool with the goal of reducing the emission of pollutants in the atmosphere (VOCs). The recent composite transformation workshop chiefly houses non-emissive transformation processes. Beneteau is also working to reduce the creation of waste (packaging, cut optimisation, scrap) and to increase the amount of recycling through the implementation of a waste control process.\nStakeholder in standardisation in the nautical industry\nBeyond providing CE certification on all of its boats, which is an internationally recognised guarantee of quality and safety, Beneteau shares its experience as a boat builder to assist with the development of standardisation and regulations in the nautical industry. With its expertise, the brand is also committed to working alongside a variety of institutions such as the Fédération des Industries Nautique and European boating industry to promote the safety of users and']	['<urn:uuid:45a54adb-ab28-4385-af69-a9e80104defb>']	factoid	direct	verbose-and-natural	similar-to-document	single-doc	expert	2025-05-01T23:46:40.222380	15	45	891
401	How do blazar plasma jets accelerate particles, and what technology detects them at the South Pole?	Blazar plasma jets accelerate particles through magnetic reconnection, which involves rapid breaking and reconnection of magnetic field lines in ionized gas. This process converts magnetic energy into thermal and kinetic energy, accelerating plasma particles to produce ultra-high-energy cosmic rays with energies of 1018 to 1020 electronvolts. These particles are detected at the South Pole by the IceCube telescope, which consists of at least 70 strings of optical detectors deployed in 2.4-kilometer-deep holes drilled into Antarctic ice. Each string contains 60 optical detectors housed in volleyball-sized glass spheres with highly sensitive light detectors and sophisticated electronics.	"['Computer models designed and run by astrophysicists from Brazil and abroad reproduced the generation of ultra-high-energy cosmic rays by a mechanism of magnetic acceleration associated with the activity of blazars—galaxies with an active nucleus that emit an intense jet of plasma (ionized gas) towards Earth. At the center of every blazar is a black hole whose mass is millions or even billions of times greater than the Sun. After consuming the matter it attracts, the black hole blasts a stream of electrically charged subatomic particles perpendicular to its axis of rotation—known as a plasma jet. This stream of ionized matter can travel through space at about 300,000 kilometers per second, close to the speed of light.\nCosmic rays that are accelerated in these environments are the most energetic particles in the Universe. Many particle physicists are interested in determining what types of celestial bodies and processes produce them. “In our simulations, we were able to accelerate low-energy protons inside a turbulent jet using a mechanism known as magnetic reconnection, producing cosmic rays with energies in the order of 1018 to 1020 electronvolts [eV],” says Elisabete de Gouveia Dal Pino of the Institute of Astronomy, Geophysics, and Atmospheric Sciences at the University of São Paulo (IAG-USP), coordinator of the group that created the computer model as part of a project funded by FAPESP. “These results support the hypothesis that blazars may be one of the sources of the most extreme cosmic rays.” Data from the studies were presented in two articles published in the Astrophysical Journal in 2021 and are set to be described in new papers later this year.\nThe expression “cosmic rays” refers to electrically charged particles (protons, electrons, and nuclei of atoms) and neutral particles (neutrinos, neutrons, and photons) that are produced in extreme celestial objects and travel through the Universe before eventually reaching Earth. Less energetic examples, such as solar wind, are more abundant and probably arise through phenomena that occur within the Milky Way. Those with more energy are seen less frequently and tend to come from farther away. Particles of the highest energy are generated outside the Milky Way, as has already been verified by the Pierre Auger Observatory in Argentina, funded by several international agencies, including FAPESP and the CNPq (see Pesquisa FAPESP issue nº 260).\nIn 2005, Dal Pino and American astrophysicist Alexandre Lazarian of the University of Wisconsin, USA, proposed the mechanism of magnetic reconnection as one of the possible ways ultra-high-energy cosmic rays are produced. Magnetic reconnection is characterized by the rapid breaking and reconnection (hence the term) of the magnetic field lines of an ionized gas, as occurs in jets of particles produced by the black holes at the centers of galaxies, including blazars. The process converts magnetic energy into thermal energy (heat) and kinetic energy (accelerating the plasma particles), often resulting in explosions. Phenomena like solar flares (sudden eruptions on the surface of the Sun) and auroras in Earth’s polar regions occur due to rapid reconnection of magnetic field lines. In the case of cosmic rays, it was previously unknown whether the mechanism is strong enough to explain the generation of the most energetic particles in the Universe.\nStudies by Dal Pino’s group suggest that at least in plasma jets produced by blazars, magnetic reconnection appears to be capable of producing extremely energetic cosmic rays. Dal Pino’s team used numerical computer models to generate a system that emulates the behavior of these plasma jets, and then introduced instabilities that led to rapid and turbulent magnetic reconnection. In the simulations, some of which lasted hundreds of hours, the researchers wanted to see whether any particles were able to gain enough speed to be considered ultra-high-energy cosmic rays. According to the group’s work, the answer is yes. “In the simulations, we injected hundreds to thousands of low-energy protons that are accelerated by magnetic reconnection in the turbulent fluid of the jet,” explains Tania Elizabeth Medina Torrejón, a Peruvian physicist currently on a postdoctoral fellowship at the IAG and one of the authors of the articles. “Over time, we saw an exponential growth in the energy of these particles.”\nIn 2018, the IceCube Neutrino Observatory, located near the South Pole in Antarctica, recorded the first documented source of high-energy neutrinos associated with blazars, a type of particle that can only be produced by protons with extremely high energy. The superaccelerated particles came from a blazar named TXS 0506+056, about 5.7 billion light-years from Earth, where a black hole emits a jet of plasma toward Earth (see Pesquisa FAPESP issue nº 270). “This blazar also generates strong gamma-ray and neutrino emissions. We recently reconstructed these emissions using the magnetic reconnection acceleration model,” says Mexican astrophysicist Juan Carlos Rodríguez-Ramirez, another postdoctoral fellow in the IAG group. The production of gamma rays is set to be studied in detail by the Cherenkov Telescope Array (CTA), designed to be the largest ground-based astronomical instrument for observing of this type of radiation. The CTA is a €350-million project, led by Europeans with the participation of astrophysicists from Brazil (see Pesquisa FAPESP issue nº 312).\nInvestigation of high energy phenomena and astrophysical plasma: Theories, numerical simulations, observations, and development of instrumentation for the Cherenkov Telescope Array (CTA) (nº 13/10559-5); Grant Mechanism Thematic Project; Principal Investigator Elisabete de Gouveia Dal Pino (USP); Investment R$14,836,626.42. 17/12188-5.\nMEDINA-TORREJÓN, T. E. et al. Particle acceleration by relativistic magnetic reconnection driven by Kink instability turbulence in poynting flux-dominated jets. Astrophysical Journal. vol. 908, no. 2. Feb. 2021.\nKADOWAKI, L. H. S. et al. Fast magnetic reconnection structures in poynting flux-dominated jets. Astrophysical Journal. vol. 912, n. 2. may 2021', 'A key first step has been taken in the construction of IceCube, a giant neutrino telescope spanning a volume of one cubic kilometer of ice at the South Pole: Working under harsh Antarctic conditions, an international team of scientists, engineers and technicians – among them scientists from the DESY research center – has successfully deployed a first critical part of the telescope, a string of 60 optical detectors, in a 2.4-kilometer-deep hole drilled into the Antarctic ice. Comprising a total of at least 70 such strings, the $272 million telescope will be the largest scientific instrument ever built. Designed to detect cosmic neutrinos – ghost-like high-energy particles from deep space – it will open up a new window to the sky and allow scientists to investigate the still-mysterious sources of cosmic rays.\nIceCube is a joint international effort involving more than 20 institutions from the USA, Germany, Sweden, Belgium, the Netherlands, Great Britain, Japan and New Zealand. German contributors are the research center DESY with its location in Zeuthen close to Berlin, and universities in Berlin, Dortmund, Mainz and Wuppertal. The major part of the telescope and its construction is being financed by the National Science Foundation (NSF), with $30 million in support coming from European partners.\nIn a common effort, DESY and the German universities will deliver more than a quarter of the around 4200 optical modules that are to be deployed over the next six years. 1300 volleyball-sized glass spheres, each of them housing a highly sensitive light detector and sophisticated electronics, will be assembled and tested at DESY in Zeuthen. “The first IceCube string, which was successfully lowered into the ice in late January, already comprises eight optical modules produced in Zeuthen,” says physicists Rolf Nahnhauer, who is responsible for the production of the modules at DESY. Setting the string into the Antarctic ice required drilling a 2.4-kilometer-deep hole using a novel hot-water drill. “The detectors are then frozen in place in the ice,” explains Nahnhauer. “The first string is working perfectly, and data from the string and the surface tanks is now being transmitted to the Northern Hemisphere.”\nPetra Folkerts | alfa\nDiving robots find Antarctic seas exhale surprising amounts of carbon dioxide in winter\n16.08.2018 | National Science Foundation\nDiving robots find Antarctic winter seas exhale surprising amounts of carbon dioxide\n15.08.2018 | University of Washington\nNew design tool automatically creates nanostructure 3D-print templates for user-given colors\nScientists present work at prestigious SIGGRAPH conference\nMost of the objects we see are colored by pigments, but using pigments has disadvantages: such colors can fade, industrial pigments are often toxic, and...\nScientists at the University of California, Los Angeles present new research on a curious cosmic phenomenon known as ""whistlers"" -- very low frequency packets...\nScientists develop first tool to use machine learning methods to compute flow around interactively designable 3D objects. Tool will be presented at this year’s prestigious SIGGRAPH conference.\nWhen engineers or designers want to test the aerodynamic properties of the newly designed shape of a car, airplane, or other object, they would normally model...\nResearchers from TU Graz and their industry partners have unveiled a world first: the prototype of a robot-controlled, high-speed combined charging system (CCS) for electric vehicles that enables series charging of cars in various parking positions.\nGlobal demand for electric vehicles is forecast to rise sharply: by 2025, the number of new vehicle registrations is expected to reach 25 million per year....\nProteins must be folded correctly to fulfill their molecular functions in cells. Molecular assistants called chaperones help proteins exploit their inbuilt folding potential and reach the correct three-dimensional structure. Researchers at the Max Planck Institute of Biochemistry (MPIB) have demonstrated that actin, the most abundant protein in higher developed cells, does not have the inbuilt potential to fold and instead requires special assistance to fold into its active state. The chaperone TRiC uses a previously undescribed mechanism to perform actin folding. The study was recently published in the journal Cell.\nActin is the most abundant protein in highly developed cells and has diverse functions in processes like cell stabilization, cell division and muscle...\n17.08.2018 | Event News\n08.08.2018 | Event News\n27.07.2018 | Event News\n17.08.2018 | Physics and Astronomy\n17.08.2018 | Information Technology\n17.08.2018 | Life Sciences']"	['<urn:uuid:acc080fa-c159-476f-88d5-e49f5c84e3d7>', '<urn:uuid:4139e27f-05f5-4597-909f-408a88102705>']	open-ended	with-premise	concise-and-natural	distant-from-document	multi-aspect	expert	2025-05-01T23:46:40.222380	16	95	1647
405	I've heard about the Progressive Automotive X Prize competition - what was the winning innovation and has it made it to the market?	The $5 million grand prize went to a startup called Edison2 for their Very Light Car, which weighs just 830 pounds and achieves 100.3 miles per gallon. Despite setting records for aerodynamic efficiency at a General Motors wind tunnel and achieving an EPA-accredited 350 miles per gallon-equivalent rating in an electric version, the car hasn't made it to market yet. Although Edison2's team has had numerous discussions with U.S. and foreign automakers, no manufacturer has licensed their design or invested in the company. The auto industry and car buyers appear hesitant to embrace such radical change, despite the vehicle's breakthrough efficiency.	['The Best Ideas Money Can Buy\nThe prize pool for environmental innovation challenges increased twelvefold in the past ten years—and shows no sign of easing up. But does crowd-sourcing solutions pay off for the world as well as for the winners?\nBy Marc Gunther\nThe ceremony had all the pomp of the Oscars, minus the gowns. Musical fanfares greeted each presenter. Politicians delivered windy speeches. A global audience watched live (and a prime-time special followed on The Discovery Channel) as the winners of the Progressive Automotive X Prize were announced on September 16, 2010, in Washington, D.C.\nThe $5 million grand prize went to a startup company called Edison2, whose founder, Oliver Kuttner, had assembled a team of professional motor-racing engineers to rethink the fundamentals of the automobile. Their winning entry, aptly named The Very Light Car, weighs just 830 pounds, travels 100.3 miles on a gallon of gas, and represents a radical departure from any other car on the road today. “That’s what this competition is all about: advancing the science behind automotive technology to create revolutionary change,” declared Glenn Renwick, chief executive of Progressive Insurance, which put up $10 million in total prize money. Peter Diamandis, founder and chief executive of the X Prize Foundation, was characteristically effusive. “We’re living in a day and time where literally anything is possible,” he declared, “where a man or woman who is passionate and driven can go out and build a spaceship or a 100-mile-per-gallon car. This is only the beginning.”\nBut the beginning of what? Don’t expect to see the Edison2 on the roads anytime soon, if ever; so far, no auto-maker has stepped forward to license the design. When it comes to prizes, though, we’re well past the beginning. Thanks in part to the influence of Diamandis and the X Prize, nonprofits, governments, and corporations are turning to prizes to spur innovation—particularly environmental innovation.\nIt’s not hard to see why. Unlike conventional research and development, prizes pay for performance, not just the effort. They call attention to important issues. And they open up problems to anyone with a good idea (or a bad one), getting beyond insiders or accredited professionals. “There are so many more ideas and possible solutions out there in the world than any given company or organization can tap into,” says Beth Trask, who oversees prizes for the nonprofit Environmental Defense Fund. Some people call this Joy’s Law—after Bill Joy, a founder of Sun Microsystems and a venture capitalist who once said: “No matter who you are, most of the smartest people work for someone else.”\nOften, though, it takes insiders as well as outsiders to solve big problems, as Edison2’s travails suggest. Prizes can clearly drive technological innovation, but big environmental problems such as climate change and biodiversity loss are shaped by politics, economics, and culture as well as by science and engineering. And that raises a question: Once the buzz dies down, can prizes generate solutions that scale up to deliver lasting environmental change? Put another way, do they pay off for the world as well as for the winners?\nHistory tells us that prizes can deliver big social benefits. Before the growth of research universities and global corporations with R&D labs, prizes were the pathway to solving many scientific problems, according to Karim Lakhani, a faculty member at Harvard Business School who studies open innovation. The Longitude Prize, established in 1714 by the British government, inspired clockmaker John Harrison to develop the marine chronometer, enabling ships to know their locations at sea. In 1795, Napoleon offered a 12,000-franc prize for a method of food preservation to feed his army when “an invaded country was not able or inclined to sell or provide food,” according to Knowledge Ecology International. The 1809 winner, French confectioner Nicolas Appert, invented the basic method of canning food still in use today. Nearly a century later, America’s biggest manufacturer of billiard balls, Phelan & Collander, offered $10,000 in gold to anyone who could come up with a substitute for the elephant ivory used in billiard balls. That may have been the first prize designed to promote environmental protection—although the solution turned out to be celluloid, one of the first industrial plastics.\nMost famously, Charles Lindbergh flew the Spirit of St. Louis from New York to Paris in 1927 to win a $25,000 prize offered by New York hotelier Raymond Orteig. It was Lindbergh’s story that inspired Peter Diamandis, who has had a lifelong fascination with space travel, to announce the first X Prize in St. Louis in 1996. Eight years later, aerospace designer Burt Rutan, financed by Microsoft billionaire Paul Allen, won what had become the $10 million Ansari X Prize for developing a private spacecraft—after 26 teams from seven nations spent more than $100 million on the competition. Since then, another $1.5 billion in private and public funds has been invested to build a private spaceflight industry. Says Diamandis: “We’re on the verge of the greatest exploration that the human race has ever known.”\nA 50-year-old philanthropist and entrepreneur who earned an MD degree from Harvard but never practiced medicine, Diamandis has become the world’s leading evangelist for the power of prizes. The success of the space-travel prize led him to organize prizes in environment, genomics, and health care; his team is currently working on prizes in education and global development, too—on the theory that no problem is too big to be solved by the collective intelligence of mankind. “Out there in the world today, there are billions of innovative people,” Diamandis says. “How do you get them to spend their time working on your problem? When you’re looking for a needle in a haystack, an X Prize allows the needle to come to you.”\nThe X Prize phenomenon has set off a boom in the prize business. A 2009 McKinsey and Company report identified 219 prizes worth at least $100,000, more than 60 of which had debuted since 2000. (1) Total prize money: $315 million. (Some prizes reward past achievement, but most are competitions focused on a future goal, the report says.) Last year, the Obama administration created challenge.gov, a portal that lists government prizes ranging from a NASA green-flight challenge to build a super-efficient aircraft, to an EPA essay contest inviting contestants to write Six Words for the Planet. McKinsey said 80 major prizes are devoted to energy and the environment.\nSome have already delivered results. When Congress enacted legislation in 2007 to create a $10 million prize for an efficient light bulb to be manufactured in the U.S., Philips, the world’s largest lighting company, accelerated its work on LED technology. Last year, a Philips 60 watt–equivalent LED bulb was awarded the L Prize. The new bulb went on sale on Earth Day 2012. “Would it have happened anyway?” asks Ed Crawford, president of Philips North America. “Absolutely. But we’re at least two years ahead of where we would have been.” The Philips LED bulb, which had to meet rigorous Department of Energy standards to win, is 83 percent more efficient than a traditional incandescent bulb and lasts 20 to 30 years, depending on usage. It should save customers money, despite a steep $50 price tag. “It really is a breakthrough product,” Crawford says.\nLast fall, with the support of environmental philanthropist Wendy Schmidt, the X Prize Foundation awarded $1.4 million in prizes to improve the ways oil is cleaned up after spills. Elastec Marine, a private company, won the $1 million first prize in the competition by developing technology that sucked up oil at a rate of 4,670 gallons per minute—more than three times the industry norm. In the meantime, the World Wildlife Fund has been running its International Smart Gear competition since 2004, awarding prizes for fishing gear that reduces the capture of unwanted marine life—commonly known as bycatch. Several winning entries have been commercialized, and a couple of inventions have become mandatory in selected fisheries.\nNone of those competitions cast a wide net (if you’ll pardon the pun) in the search for solutions. It was almost a given that a lighting company would win the L Prize, and no landlubber is going to invent “greener” fishing gear. But other prizes are now using the power of the Internet to crowd-source solutions. InnoCentive, a company spun off from pharmaceutical giant Eli Lilly, acts as a clearinghouse for companies and nonprofits, including Environmental Defense Fund, to tap into its community of more than 250,000 problem solvers from all over the world who compete for cash prizes. “Challenge-driven innovation,” it’s called, and it seems to work. When Harvard’s Lakhani studied InnoCentive, he found that its diverse community of Internet-connected scientists and engineers found solutions to about “one-third of a sample of problems that large and well-known R&D-intensive firms had been unsuccessful in solving internally.” So-called outsiders, he found, did best because they looked at problems with fresh eyes.\nLast year, for example, in a challenge put forth by Environmental Defense Fund, Patrick Fuller, a graduate student in chemical and biological engineering at Northwestern University, won $5,000 for an idea about capturing agricultural runoff and using the nitrate-rich water to feed algae. Iowa soybean and corn farmers will now try it out. Environmental Defense Fund is also using the InnoCentive platform to address two problems associated with electronics recycling. Together with the Consumer Electronics Association, they sponsored a competition to find creative ways to repurpose old cathode-ray picture tubes. And with EMC Technologies, a major Massachusetts-based firm, they are offering a prize for technologies that keep track of discarded electronics to ensure they are handled responsibly. “Within those big, gnarly, system-wide problems,” EDF’s Beth Trask says, “we can carve out discrete questions that need to be solved, often of a technical or scientific nature.” Focus is the key to managing challenge-driven innovation, explains Dwight Spradlin, CEO of InnoCentive. “If I had 60 minutes to save the world,” he says, “I’d spend 55 minutes asking the right question.”\nFor General Electric, which invited entrepreneurs to propose new business ideas and technologies through a competition called the Ecomagination Challenge, the key to making profitable use of the ideas is what happens after prizes are awarded. Initially, GE and four venture-capital firms put up $200 million to find and fund promising technologies for the smart grid and to promote energy efficiency; they attracted more than 1,500 business plans and invested $85 million in startups.\nThen, according to Mark Vachon, vice president of GE Ecomagination, GE set out to test the new technologies with customers and, if needed, bring its own know-how to bear. “We have an amazing infrastructure,” he says. “Five global research centers, 1,500 PhDs, as well as access to thousands of customers.” So, for example, GE invested in a company called Oblong Industries, which surfaced during the Ecomagination Challenge and makes “gesture-based operating systems” such as those seen in the movie Minority Report. GE also licensed Oblong’s technology for its Smart Grid software, which it is testing with utility companies. “The prize can get ideas into a funnel, but it can’t get them to scale,” says Vachon. Only big companies, governments or consumers can do that.\nGetting new technologies to scale, as Vachon notes, takes more than a contest. That’s the challenge facing the X Prize Foundation, which has proven that it can uncover and showcase breakthrough innovation, such as private space travel or The Very Light Car. But Diamandis and his team have no desire to run the equivalent of a high-school science fair for well-to-do entrepreneurs; they want to change the world. Diamandis likes big, attention-getting ideas not for their own sake, but because he wants X Prizes to have an impact on “hundreds of millions, if not billions, of people,” he told me. The trouble is, well-entrenched industries such as the auto industry may resist breakthrough ideas because they’re tied to old ways of doing things. The automakers, after all, know how to build small, fuel-efficient cars; they haven’t done so to this point except when forced to by the government, because they don’t think consumers will buy them.\nEdison2 and its Very Light Car have yet to overcome those institutional obstacles. Eighteen months after winning the X Prize, Edison2’s engineers are still hard at work, trying to design a car that will be efficient and affordable, with all the comfort and safety buyers have come to expect. The Very Light Car set a record for aerodynamic efficiency at a General Motors wind tunnel, and an all-electric version achieved an EPA-accredited 350 miles per gallon–equivalent rating. But, although Oliver Kuttner and his crew have had numerous conversations with U.S. and foreign automakers, none has yet stepped up to license their car design for manufacturing. Nor has any manufacturer invested in Edison2. It’s not clear that the auto industry—or car buyers—is prepared to embrace the kind of radical change embodied by The Very Light Car and encouraged by the X Prize.\nA new environmental X Prize under development could run into similar obstacles. A $10 million prize for carbon capture and recycling aims to do nothing less than transform the energy and climate landscape by turning carbon dioxide emissions from a waste stream into an asset. It’s being designed to uncover ways that carbon can be beneficially and efficiently re-used—as a feedstock for fuels, plastics, chemicals, fertilizers, building products, or other valuable materials. If all goes according to plan, the prize would solve a problem that has stumped the federal government: although Congress has appropriated $6 billion to develop ways to capture CO2 and store it underground, its efforts have stalled because there’s no way to pay for carbon capture and sequestration. Recycling carbon, by contrast, would generate revenues—at least in theory.\nTri-State Generation and Transmission, a wholesale electric-power supplier owned by 44 electric cooperatives in the West, has agreed to put up $10 million for the carbon prize. The company generates most of its electricity by burning coal and natural gas. “We’ve been looking at what do we do with carbon,” says Jim Spiers, a senior vice president at Tri-State. “We’re looking for a totally different capture solution that will create a monetizable by-product.” The X Prize Foundation is now trying to raise the money needed to run the competition. Success in carbon capture and recycling will require shaking up the heavily regulated, slow-moving utility industry, which will be no easy feat.\nLong odds don’t deter Diamandis. He is an inveterate optimist. (His new book Abundance: The Future Is Better Than You Think is not for the cynical among us.) Along with its environmental work, the foundation is developing challenges in agriculture, education, and health care in the global South, aiming at discovering scalable ways to “create wealth and uplift entire populations from poverty.”\nIsn’t that a lot to ask of a prize? I ask Diamandis. Maybe, he replies, but we don’t know yet what prizes can or cannot do. “Can they change rules and regulations? Can they change a marketplace? Can they change human behavior? We’re going to experiment. We’re going to find out.” ❧\n1. McKinsey & Company. 2009. “And the winner is …” Capturing the promise of philanthropic prizes. http://mckinseyonsociety.com/capturing-the-promise-of-philanthropic-prizes/.\nMarc Gunther is a contributing editor at Fortune magazine, a senior writer at Greenbiz.com, and a blogger at www.marcgunther.com. His ebook Suck It Up: How Capturing Carbon from the Air Can Help Solve the Climate Crisis was recently published as an Amazon Kindle Single.\nImage: ©Fanatic Studio\nThe Ecological Creed of Craft BeerMarch 14th, 2014\nHow Beer Money Can Help Save a Nation’s Water SupplyDecember 11th, 2013\nSolar Power to the PeopleSeptember 9th, 2013\nVino EcologyJune 10th, 2013\nPurple PipesMarch 8th, 2013']	['<urn:uuid:2ff2d870-4f3c-42a2-808f-bf82d9062536>']	open-ended	with-premise	verbose-and-natural	distant-from-document	single-doc	expert	2025-05-01T23:46:40.222380	23	101	2610
409	Do both business analysts and internal communications managers deal with crisis situations?	While internal communications managers explicitly handle crisis situations affecting organizational perception and reputation, there is no mention of crisis management in the business analyst role description.	"['Internal communications managers work to ensure employees of organisations are kept informed and motivated. They do this by communicating through several channels, such as a staff intranet, email bulletins, social media and regular newsletters.\nWorking closely with senior executives, internal communications managers establish organisational messages and keep staff informed of developments. They also formulate their organisation’s internal response to crisis PR situations. Internal communications managers tend to work in large organisations, such as private sector companies, public sector bodies, local authorities and charities.\nAs an internal communications manager, you can expect your role to typically involve some or all of the following:\n- Establish an internal communications strategy in conjunction with senior managers\n- Ensure organisational initiatives and projects are successfully communicated to employees and stakeholders\n- Plan, edit and write content for a variety of internal communications mediums, such as a staff intranet, monthly magazine or regular email bulletin. You may also be required to work on the layout of content\n- Keep clients abreast of progress and answer their questions\n- Storyboard or translate ideas to the creative team of art directors and designers\n- Use social media to communicate with staff internally\n- Manage an internal communications officer or whole team\n- Deliver presentations at organisational events, such as your company’s AGM\n- Draft messages or scripts from senior executives for presentation to employees in written or spoken form\n- Ensure internal communications messages are consistent across all mediums and for different departments of the organisation\n- Ensure internal communication messages are consistent with external communication messages\n- Respond to feedback from staff and adjust communications content accordingly\n- Handle the internal communication response to crisis situations which affect organisational perception and reputation\n- Advise senior executives of developments throughout the organisation, either face to face or through regular written communication\n- Writing skills: You need excellent writing, editing and proofreading skills as well as the journalistic ability to source stories from employees\n- Speaking skills: You also need strong speaking skills as you are likely to be called on to give presentations to staff. Internal communications managers need sensitivity to an organisation’s goals and values and the ability to relay them to employees\n- Interpersonal skills: You need good interpersonal and relationship-building skills in order to work with communications and HR departments. You also need to possess the confidence to deal with senior executives and explain communication techniques to them.\n- Creative skills: You need the creative ability to devise communication strategies Digital skills: Familiarity with information technology, especially digital and video means of communication, is essential. Understanding the sector you wish to work in (private, public or voluntary) can be crucial.\nA BA in journalism, communications, public relations or marketing is an advantage, though other degrees are often acceptable. A professional qualification from the Chartered Institute of Public Relations or the Chartered Institute of Marketing can be helpful. An MA qualification is also possible.\nExperience in a communications team, especially internal communication, for a large organisation, is most sought after. But experience of writing for a variety of different audiences is also desired. General journalistic or marketing experience is beneficial. Prior management of complex projects and advising senior managers is also looked upon favourably.\nThe average salary for an internal communications manager can range from £30,000-£50,000 per annum.\nRegular office hours of 9:00am-5.30pm but availability outside of office hours and the willingness to travel are expected.\nYour next steps may include:\n- Digital internal communications manager\n- Global internal communications manager\n- Head of internal communications\n- Head of communications\nAn internal communications manager’s perspective\n""Working in internal communication and engagement gives me a really privileged view into the ‘behind the scenes’ of Alzheimer’s Society. The role allows me to learn about the vast range of activities we do to support people affected by dementia, from the launch of an innovative new service to our latest successful public affairs campaign.\n""The challenge is to make sure that our employees and volunteers across England, Wales and Northern Ireland are engaged with and proud of what the Society is doing to move us closer to our vision of a world without dementia.""\n- Louise Shevlane, internal communication and engagement manager at Alzheimer’s Society', 'Business Analyst vs. Data Analyst: Analyzing These Commonly Confused Careers\nIf you take the job titles by their face value, you could guess that “business analyst” means someone who analyzes businesses and “data analyst” means someone who analyzes data. But wouldn’t a data analyst still be part of a business? Wouldn’t a business analyst still use data?\nSo what differentiates these careers? What do these professionals do? If you’re wondering about the role of a business analyst versus a data analyst for how it might work into your own future—you’re looking in an optimistic direction.\n“It’s no secret that the amount of data in the world is growing exponentially, and this greatly applies to the data that companies work with,” says Artem Melnikov, senior business analyst at MightyCall. Melnikov says companies today understand that decisions should be made on various kinds of data to supplement a manager’s subjective point of view and experience.\n“This leads to decision-making known as data-driven and data-informed,” Melnikov explains. And in the hope that data-based decisions will lead to smarter, more efficient and more lucrative choices, companies across all industries are taking note.\nIt’s safe to say that both business analysts and data analysts will have a relationship with data into the foreseeable future. But learning a bit more about what these two job titles represent and how they compare can help you understand the way companies navigate the new data capabilities of today.\nIf you are interested in finding your career somewhere in this arena, more details can help you choose a path forward. We combined research with expert advice to flesh out these commonly confused careers.\nBusiness analyst vs. data analyst: Differentiating the job descriptions\nBusiness analysts conduct studies and evaluations, design systems and procedures, conduct work simplification and measurement studies to assist a business in operating more efficiently and effectively, according to the Department of Labor.1 Their goal is to analyze aspects of a company, often using data sets, to find vital information and suggest improvements, fix problems and move the company’s operations forward.\nAs you can probably imagine—that general goal can take on a myriad of tasks depending on the company. “I work for a creative agency so my role as a business analyst is extremely unique,” says Holland Martini, director of data strategy at Grey Group. “My data sets include typical metrics such as sales, spend and media activity, but get partnered with more eccentric data points such as fashion trends, cultural biases, food habits, etc. …”\nJeff Neal, business analyst for The Critter Depot, has unique tasks and challenges based on his company as well. “We ship live insects across the country, so I’m always churning through data, to determine the probability of ‘transit survival’.” Neal’s business analysis often involves finding patterns in what might cause insects to perish during transit, to come up with options on how to avoid or mitigate those scenarios.\nWhile your employer or client’s specific needs could be all across the charts, business analysts usually need to rely on lots of critical thinking to draw meaningful conclusions from the data they have and help the business make choices.\nMartini explains that the importance of business analytics is rising. “Even architects and fashion designers are no longer willing to make decisions based solely on gut reaction to trends,” Martini says. “Everyone wants a smart proof point that substantiates their idea, and this has drastically expanded the market.”\nData analysts tend to lean a little closer to tech and mathematics. “In the purest sense, data analysis is a quantitative discipline—hard numbers and statistics flow into conclusions,” says Micah Melling, director of data science at Spring Venture Group.\nMelling explains that data analysts must first define the purpose of the analysis they are performing, being mindful of the bigger picture. Then, they gather the data they believe relevant, which requires technical skill sets. “We are often tasked with cleaning the data and placing it into a usable format as well,” Melling says. “After this point, we can dive into applying statistical models and developing visualizations.”\n“At the end of the day, my role is clarity—a concise summary of key learnings backed by data,” Melling says. In this phase of the role, business analysis and data analysis basically cross over. Both career avenues are culling information to help their businesses thrive.\nWhat skills are needed to be a business analyst vs. data analyst?\nWe combed through job postings from the last year to show you the most in-demand skills for each of these job titles to help you compare and contrast their attributes.\nBusiness analyst skills:2\n- Business analysis\n- Business process\n- Project management\n- SQL (structured query language)\n- Communication skills\nData analyst skills:2\n- Data analysis\n- Data quality\n- Data management\nYou can see that top skills for data analysts in the last year included more systems and software familiarity, while top skills for business analysts lean toward business awareness. But our experts say these roles really do cross over frequently—even to the point of becoming indistinguishable for many professionals.\nAfter all, many business analysts will need to learn more than one or two technical skills to make their work happen. And data analysts often need to understand the businesses they serve and the purpose of the data they are finding. “Both the business analyst and data analyst roles are pretty similar—to crunch numbers and discover patterns and relationships,” Neal says. “The titles are often used interchangeably.”\nHow do you choose between becoming a business analyst versus a data analyst?\nIf you are looking at the possibility of a career as a business analyst or data analyst—you might be making decisions early on in your education that would better complement one or the other. The vast majority of both business analyst and data analyst job postings asked for applicants with a bachelor’s degree.2\nSo how can you choose which career to pursue? “While the roles often overlap, the advice I would give is to decide how creative you want to be with your insights,” Martini says. “A business analyst is responsible for taking data and making insightful and creative actions to drive business, which often mixes the arts and sciences.”\n“A strictly data analyst is responsible for finding unique ways to solve a problem,” Martini says. “Both are fun!”\nJason Morphett, technical director of Purple Toolz, points out that many business analysts will have roles centered on finance, and many data analysts will have programming-heavy jobs. “I would advise anyone trying to decide between business and data analytics to consider where their interests lie,” Morphett says. “In all cases, be one step ahead of the game and get familiar with data science.”\nIf you see yourself craving creative opportunity and out-of-the-box thinking, maybe business analysis will offer more flexibility with that. And if you crave the hard-and-fast parameters of finding information in the most unbiased way possible, Melling says data analysis can offer that.\n“At times, data analysts need to focus solely on the technical side and temporarily throw out interpretability. Intellectual honesty is paramount. This mindset allows you to dig into a challenging problem and find a solution free of constraints.”\nChoosing a side—for now\n“The appetite for data analysis know-how will only increase,” Melling says. “In particular, versatility of skills will be in demand. Being able to move from technical practitioner to storyteller represents a comparatively rare skills set.”\nAs data analysts supplement their skills with business acumen, and business analysts branch into deeper technical ability—these two titles might very well merge into one career. While the blurred lines between these job titles might be a little frustrating for those who like black-and-white answers, the good news is that there are multiple viable paths into these roles.\nFor instance, a Business Management program that incorporates data analysis fundamentals can give you a broader understanding of business operations. On the flip side, a Data Analytics program that dives deep into the technical skills used for advanced data analysis paired with business experience could be an effective combo as well.\nNo matter your initial leanings for how to get there, you’ll want to learn more about the role of a data analyst before making a decision. Our article “What Does a Data Analyst Do? Exploring the Day-to-Day of This Tech Career” can help shed some light.\n1Bureau of Labor Statistics, U.S. Department of Labor, Occupational Employment Statistics, [accessed July, 2019] www.bls.gov/oes/. Information represents national, averaged data for the occupations listed and includes workers at all levels of education and experience. Employment conditions in your area may vary.\n2Burning-Glass.com (analysis of 85,690 data analyst job postings and 192,308 business analyst job postings, Jul. 01, 2018 - Jun. 30, 2019).\nPython is a registered trademark of The Python Software Foundation.\nTableau is a registered trademark of Tableau Software.']"	['<urn:uuid:867f2750-548f-4cb4-a0f8-f4d3702cb794>', '<urn:uuid:a44520f6-2a1e-437b-93db-ba71bfa98823>']	factoid	with-premise	concise-and-natural	similar-to-document	comparison	expert	2025-05-01T23:46:40.222380	12	26	2178
412	What are proper hay sampling methods and nutrient components?	Proper hay sampling requires defining feed lots by field and harvest time, using a hay probe for representative samples, taking minimum 20 probes per lot, and splitting samples using cone and quarter method. Regarding nutrients, hay contains protein for tissue growth, carbohydrates for energy, fats for energy storage, vitamins A/B/C/E for metabolism, minerals like calcium/phosphorus for skeletal maintenance, and fiber for digestive function.	['With the first cutting of hay coming off fields in southern states, I am reminded that proper hay sampling procedures are a must. Today I was brought a sample from a single bale of mixed hay and asked to sort the alfalfa from the grass hay and use those as individual, separate samples. I was not the only one whose first reaction was, are they planning on sorting it out every time they feed? (Of course not!) For someone who is very passionate about providing producers with accurate, precise and above all else useful results, this request was difficult to stomach. No matter what species of animal is being fed, lab results are a useless waste of producer time and lab time if they are not representative of the entire pile of feed or stack of hay. So, when sampling hay and other forages the goal is to provide WARD Laboratories Inc. with a representative sample. Here are 5 steps to obtain a representative hay sample:\n- Define ‘lots’ of feed.\nA lot can be one field of the same or a mixed species which has been harvested and bales in one consecutive time frame. For example, if I had three fields two alfalfa and one mixed alfalfa and grass. I harvested and baled one alfalfa field, then the mixed field and then a few weeks later finally harvested and baled the second alfalfa field. I would define 3 separate lots based on species and time of harvesting and baling.\n- Use a hay probe.\nUsing a hay probe will ensure samples representative of each bale. The probe can cut through the side of the bale and take sample from deeper within the bale than a hand grab can. Additionally, a hay probe does not discriminate against delicate leafy material the way fingers do. A sample taken with a hand grab will test falsely low in protein and energy as the leafy material, which is high in protein and energy, slips through fingers.\n- Take a minimum of 20 probes per lot.\nIf the lot has less than 20 bales, then take one probe per bale. If more than 20 bales are in a lot take a minimum of 20 samples to represent that lot properly. The National Forage Testing Association has done research to prove this number of probe samples decreases likelihood of a non-representative sample. When choosing bales to probe it is also important to not leave out ‘bad looking bales’ or intentionally include ‘good looking bales’. Sample as randomly as possible. The best possible thing to do is come up with a system to determine which bales to sample and follow it each time you sample a new or different lot.\n- Split the sample using the cone and quarter method.\nOnce 20 cored samples are obtained, they will not all fit in a quart sized Ziploc bag. Therefore, the sample must be mixed and split until the sample is small enough to fit in the bag. On a tarp, large newspaper or other clean surface, mix the cores then pile them up into a cone like shape. Divide the cone into 4 quarters discarding two quarters diagonal to each other and repeating the process with the remaining two quarters. Continue the process until each quarter can fill a quart sized Ziploc bag. Then send one of those quarters to Ward Laboratories Inc. and save another quarter in a cool dry place. The saved sample may come in handy if the original gets lost in the mail, or a resample is needed for some reason.\n- Send the sample to Ward Laboratories Inc.\nWhen placing the sample in an envelope or mailer, be sure to include your name, address, phone number. Write the test on the sample bag or call into be sure you receive the information you want on your report. Remember, if a result looks suspicious, Ward Laboratories Inc. will rerun tests to ensure accuracy upon request.\nFor further information on representative hay testing or to become a certified sampler check out foragetesting.org. Here is a infomative video by Dr. Mary Drewnoski, currently a Beef Systems Specialist at the University of Nebraska-Lincoln:', 'The Different Types of Hay for Horses\nComponents of Hay\nGood quality, fresh hay, then, contains all the different nutrients your horse requires:\n- Protein – used for growth and repair of tissues\n- Carbohydrates – used for energy\n- Fats – used to store energy and as insulation against cold\n- Vitamins A, B complex, C, and E – used for a variety of metabolic processes\n- Minerals, most importantly calcium and phosphorus, which are used predominantly for skeletal growth and maintenance\n- Fibre – essential for function of the digestive system\nThe way in which types of hay differs is generally not in which nutrients they contain, but the proportions in which those nutrients are present. Nutrient density also varies from one cutting to another, so to really balance your horse’s diet, it’s best to have a hay sample tested to ensure you know exactly what’s in it. Many farmers will have this done as a matter of routine to check for quality.\nA general baseline to check for hay quality is in the percentage of crude protein. An adult horse in moderate work only needs about 10% protein in his diet, while growing, performance and breeding horses will need more.\nTypes of Hay\nClover hay is very similar to alfalfa, with a very high protein content and excellent palatability. Its\nCa:P ratio is also generally unbalanced, but the advantage of clover hay is that clover is usually planted alongside grass and then cut and baled with the grass hay, so the two hays are already mixed. This boosts the quality of a grass hay crop and eliminates the fuss of having to feed two different hays to your horse. However, some sneaky horses will pick out all the clover and leave the grass, so you have to keep a close eye on your horse’s intake.\nTypes of grass hay vary across the world, but in the US, timothy hay is by far the most popular. Good quality timothy is up to 10% protein, which is sufficient for most horses. It is high in fibre and thus optimises the horse’s digestive system while supplying a moderate amount of carbohydrates. Good quality, green timothy hay is also rich in well-balanced vitamins and minerals. Bermuda grass and orchard hays are very similar to timothy hay and can be fed almost interchangeably according to what’s available – and cheaper – in your area. Timothy hay is a safe bet, but almost always more expensive than bermuda grass or orchard hay. The only real disadvantage of these grass hays is that they do not contain enough carbohydrates and protein for performance or breeding horses, so must be supplemented with alfalfa or concentrate feed. Later in the season when the hay has lost its greenness, it may also be low in vitamins and minerals, so a balancer may need to be fed.\nAnother type of grass hay is oat hay. This hay has a similar protein content to other grass hays, but is significantly higher in carbohydrates. For a skinny horse who needs to pack on some pounds or a performance horse who needs some extra energy, oat hay can be great, but it is disastrous to feed to insulin resistant, overweight, or laminitic horses. It may also cause some horses to become hot and unmanageable to ride.']	['<urn:uuid:7dadf913-17cb-433c-875e-1246bf58fdf9>', '<urn:uuid:a816f16a-24dc-4a8f-b207-58b61f6dd7ae>']	factoid	direct	concise-and-natural	similar-to-document	multi-aspect	expert	2025-05-01T23:46:40.222380	9	63	1252
416	I want to learn about hawksbill turtles in Thailand and India - what threats do they face and how are people trying to protect them?	In Thailand, hawksbill turtles are being protected through nurseries where they are raised until they're large enough to survive in the ocean, and through beach cleaning activities to prepare proper spawning grounds. In India, these turtles face threats from tourism development, oil and gas drilling, fishing, and industrial pollution in their habitats. India has responded by creating protected areas and running education and awareness programs to help save the species.	"['Ko Tha Lu\nNowadays, travelling doesn’t have to harm the environment and a good trip doesn’t have to come at the expense of nature. Having realized that human beings are just one small component of nature and that we share this planet with thousands of other species, forward-thinking travellers have begun striving to find new travel experiences that enable them to stay surrounded by natural beauty and yet do so in a sustainable way. Ko Tha Lu is not only a fantastic destination for people wishing to explore the most abundant spot in the Gulf of Thailand’s vast underwater world but also the perfect choice for travelers seeking to do something for a worthy cause, like planting and cultivating coral reefs or nursing hawksbill sea turtles.\nSituated on Ko Tha Lu, the Plant Genetic Conservation Project under the Royal Initiative of Her Royal Highness Princess Maha Chakri Sirindhorn was established and has been operating under the name “Siam Marine Rehabilitation Foundation” for many years now. Moreover, Ko Tha Lu is a tourist attraction that promotes responsible tourism by inviting interested travelers to participate in the construction of coral reefs with artificial root techniques and install them in the ocean. By positioning these reefs where the tides and the wind are not particularly strong and where there is sufficient sunlight, they create a suitable environment for the recovery and growth of the coral reefs that will become a sanctuary for various marine life. Before the arrival of the hawksbill turtle’s spawning season, the island arranges several activities including collecting litter and branch scraps from the beach to prepare the area as a spawning ground for the turtles, one of only five species of sea turtles found in Thailand and cleaning the nursery, where hawksbill turtles are raised and nurtured until they reach a size where they can survive out in the vast ocean.\nAnother activity not to miss when visiting Ko Tha Lu is snorkeling. Experience the crystal clear waters, admire coral reefs teeming with life, and be greeted by schools of small colorful fish as you explore the underwater world. Remember to always be careful not to step on or break the coral reefs and never drop an anchor near them. When it’s nearing sundown, take a stroll and explore the local community to witness the simple lifestyle of fishermen, learn the different cultures, and visit projects on local fishery conservation and the crab bank. By supporting these activities, you can show your commitment to responsible tourism and give back to the environment.\n- Join a coral-reef planting activity to help marine life thrive.\n- Help prepare the beach areas and create proper spawning grounds for female hawksbill turtles or prepare the nursery to nurture endangered sea turtles allowing them to grow and continue to breed.\n- Try snorkeling and admire one of the country’s most abundant coral reefs.\nBest Time to Visit\n- During February to May is recommended.\n- Turtle hatching season in Thailand is from November to February. Hatchlings need to be well nursed before being released into the sea.', ""List of Critically Endangered Animals in India\nBengal Florican (Houbaropsis bengalensis)\nThis is native to the Indian sub-continent and can be found mostly in the eastern part of India. This was categorized as critically endangered. Loss of habitat, cutting down trees for timber, livestock farming, transportation in their habitats, hunting these species and humans intrusion into their living spaces extensively resulting in their number coming down. Monitoring of their number, identifying their conservation sites, creating protection sites for this species, creating awareness about them are few measures being taken by the authorities for their conservation.\nPangolin (Manis pentadactyla)\nThis is not really native to the Indian sub-continent and extends in most parts of Asia. In India, this is seen in north-west regions. Human constructions, cutting down trees, mining, quarrying, laying roads for transport, hunting, habitat intrusion and not very often natural calamities are the threats for this species to survive. A recovery plan was formulated for their conservation however, systematic monitoring measures not yet widely taken. Their habitats were identified and conservation measures were going on by declaring protected areas. Awareness programs, legislations, and management to contain their number coming down were declared.\nGharial (Gavialis gangeticus)\nThis is native to the Indian sub-continent. This is mostly seen in the deltas of the Chambal and Ganga rivers. Mining, quarrying, agricultural activities, fishing and harvesting, other activities in their habitats and mainly dams and water management are threats to this species. A recovery plan has been formulated to save this species from extinction. their conservation sites were identified and notified. Ex-situ conservation and reintroduce plans were successfully taken up for their conservation.\nGreat Indian Bustard (Ardeotis nigriceps)\nThis species is native to India and found all over the country. Northern plains and the Deccan plateau are the main sites they can be seen. Loss of habitats due to trees being cut down, live-stock farming, mining, quarrying, sites being used for renewable energy sources, laying road and rail lines, hunting the species are the major threats for this species. A recovery plan with a Systematic monitoring scheme to save this species was formulated. Conservation sites were identified, protected sites were declared and invasive species control measures too were on heels to maintain their number from coming down.\nHawksbill Turtle (Eretmochelys imbricata)\nThis is found in the seas between 30 degrees north to 30 degrees south latitudes. In India, their habitats were occupied by humans for tourism and recreation which is why they happen to have lost their habitat. Oil and gas drilling, fishing, industrial effluent release and other recreational activities are serious threats to this species. A protected area was created for its conservation in India. Education and awareness programs were being taken to save them.\nIndian Vulture (Gyps indicus)\nAll over India, we see them but now no more and that is why this was declared as critically endangered species. Serious ecosystem modification and other agriculture activities were threats to this species. An action plan was formulated and their number is being monitored. Their habitats were identified and their conservation sites too and protected areas were declared. Ex-situ conservation plans were taken up to save this species.\nIndian Wild Ass (Equus hemionus)\nGhudkhur, Khur or Indian onager were the other names for this species and can be found mostly in the state of Gujarat, India. Loss of trees due to their cut down, developing roads and railways, hunting this animal and invasion of other species into their habitats are major threats to this species to survive. They are being monitored by the authorities and protected areas are being created to save this species from extinction.\nJerdon's Courser (Rhinoptilus bitorquatus)\nNative to India this is a nocturnal bird found in down south. The Eastern Ghats of Andhra Pradesh is the area where this can be spotted. Agriculture activities, mining and quarrying, hunting them down, logging and woodcutting are serious threats to this species to go extinct. An action plan was formulated for their recovery and protected areas too were created to protect them.\nPink-headed Duck (Rhodonessa caryophyllacea)\nMostly found in India, this is a large diving duck. Gangetic plains of India are the areas where this can be seen. However, their existence now is becoming hard to prove. Agriculture activities and hunting them down lead to their extinction, if not presumed extinct.\nPygmy Hog (Porcula salvania)\nThe foothills of the Himalayas and the alluvial grasslands, the area for their presence. Housing and development of urban areas, wood and pulp plantations, livestock farming, hunting, wood harvesting and ecosystem modifications were serious threats for this species. they are being monitored and an action plan was formulated to protect them.\n© 2020 Dilip Chandra""]"	['<urn:uuid:e248060a-ca99-4569-990e-b95073792b8f>', '<urn:uuid:c622cb2a-e0ca-447e-9621-c9042fd0c37c>']	factoid	with-premise	verbose-and-natural	similar-to-document	multi-aspect	novice	2025-05-01T23:46:40.222380	25	70	1291
420	What role does education play in soil conservation efforts?	Education plays a crucial role in soil conservation efforts through various channels. Agricultural extension services provide essential training and expertise, as demonstrated by Michigan State University Agriculture Extension's involvement in teaching proper windbreak implementation and erosion control. They conduct specialized classes for Agriculture Watershed Extension Teachers who are maintenance and erosion specialists. The education includes practical aspects like determining optimal placement of windbreaks and selecting appropriate tree species. Furthermore, educational initiatives help disseminate information about successful conservation projects through media, newspapers, and environmental publications, helping spread knowledge about effective soil protection methods like maintaining vegetation cover, proper tillage techniques, and erosion control strategies.	['- Additional Plants: herbs\n- Crop Production: windbreaks\n- Education and Training: extension\n- Natural Resources/Environment: habitat enhancement, soil stabilization, wildlife\nCrosby Mint Farms has been a family-owned independent producer of mint and mint products since 1912. We currently farm 300 acres. About 95% of this mint grows on low land organic muck. Our major focus has been to grow, harvest and distill mint to produce high grade peppermint and spearmint oils. These oils have no chemical additives or re-processing to compromise the healing properties of the oil.\nCrosby Mint Farms has developed a process over the past six years whereby our mint waste products are changed into high-nutrient mint compost. The compost is all natural, biodegradable and usable for organic farmers and gardeners. In 2003, James Crosby received the Tri- Country Waste Recycling Award and was honored as the State of Michigan Recycler of the Year.\nIn the past five years, we have suffered crop loss due to high winds and erosion. There was a natural wind break that has been damaged either by loss of trees or by nearby home development. A change in weather patterns has impacted the area. Heavy winds blow from the southwest into our valley and create a massive dust cloud traveling east and then northeast over 80 to 100 acres of our mint, taking much of our crop with it.\nIDENTIFYING THE PROBLEM\nOur low land muck soil is located in a small valley. In the spring, high winds have increased from the southwest. There has been a negative impact on our mint crops due to wind erosion. Two new crops of mint were lost to high wind and lack of moisture in the ground. The wind breaks in place were inefficient. The trees still standing were over seventy years old. There had been a loss of trees due to storms and nearby home development. There was also a considerable amount of field maintenance due to fallen limbs and branches in our mint crops.\n1. Re-establish the wind break system\n2. Plant new mint crop and be able to keep it\n3. Reduce wind erosion\n4. Add to the environment/wildlife habitat\n5. Reduce labor and fuel costs by reducing wind break maintenance\n6. Increase and promote good land stewardship\nMichigan State University Agriculture Extension conducted a class for Agriculture Watershed Extension Teachers (maintenance and erosion specialists for the Department of Agriculture). This was a two-hour field class. The area of greatest need for the wind break was determined and we then worked our way into the valley to assess impact. We determined that Blue Spruce would be a good choice because of their growth pattern. They would be fast growing, adding one foot to their height and one foot to their width per year. They are sturdy enough to withstand the storms and high winds that had caused previous damage so that our maintenance of the trees and our fields would be reduced.\nWe cleared the necessary area with a 5-yard dump truck, skid header, and 5-yard loader. The large logs were stacked and additional limbs and brush were bundled and hauled to a processing location. The entire area was cleaned and leveled in preparation for new tree plantings. This phase took 4 days.\nWe began orange flagging the placement for the new trees 15 feet apart and staggered every 7 feet to ensure a thick line of trees. We were able to plant 10 trees per day. Each tree was watered as we planted by filling the plug hose with water and placing the tree and the plug in the hole dug for it. We went around each tree to close any gaps that might expose the root systems to air. We planted the trees in the fall while they were in a dormant state. The flagging and measuring took one day. The planting took four and a half days. The watering and packing took two days. Therefore, the total project took eleven and a half days to form a 600 foot wind break.\nInformation concerning the project was disseminated via a press release in cooperation with the Michigan State University Agriculture Extension to statewide media, newspapers, and environmental publications.\nThis project was larger than anticipated due to the size of trees and many years of accumulated brush.\nWe have determined that this project will continue for 3 to 4 years to increase the wind break, provide wildlife habitat and year-round green esthetics as well as protect our fields from wind erosion.', 'Question: What are some things that farmers do to keep soils from eroding?\nAnswer: What a great question, but let’s not limit it to farmers!\nErosion is a natural process; it is the reason we have valleys, mesas, sand dunes, and the Grand Canyon. There are three processes in erosion:\n1) Detachment of soil particles from the surface\n2) Transportation of the detached particles\n3) Deposition of the particles\nErosion control methods address one or more of these processes.\nKeeping a blanket on the soil\nThe best protection a soil has is a blanket of living vegetation on the surface. Dead plants and plant parts (a.k.a., residues) on the surface and mulches also help.\nFarming and construction often remove or decrease the amount of vegetation (both living and dead) on the soil surface, and so increase the potential for erosion. But work activities are not the only danger to soil. Recreational vehicles, hiking off-trail, military drills, and other activities also can destroy vegetation and decrease the plant cover on the soil surface. After the vegetation is gone, the soil is susceptible to blowing in the wind, being pounded by raindrops, and washing away in runoff.\nHow do farmers keep the surface covered? When possible, they have a growing crop on the field, though not all crops are equally effective at decreasing erosion. Wheat and hay crops cover most of the soil surface, and so limit erosion better than crops like soybeans or cotton. These latter crops are often planted in wide rows, leaving bare soil exposed for a longer time.\nAfter a crop is harvested, farmers in wet and humid regions may plant a cover crop to protect the soil surface until the next growing season when they plant another crop they will harvest. Some farmers use irrigation to plant a cover crop, but in many areas the water available for irrigation is becoming more limited.\nTilling the soil less\nTraditional tillage systems turn and mix the soil, much like a rototiller that gardeners often use. When I was a child, my dad and I would turn our garden soil to about 30 centimeters (1 foot) deep with a spade. Then we’d run a rototiller to make the soil nice and fluffy. Intensive tillage systems like these break soil aggregates (natural clumps of soil particles) into smaller chunks.\nIn semiarid and arid regions, the soil can dry as deep as it was tilled. The powdery soils on the surface are also easily washed away by rain or blown away by wind.\nIn contrast, more modern tillage systems involve plowing less often, mixing the soil less, creating and leaving large aggregates at the soil surface, and/or leaving plant residues on the soil surface.\nSlowing the downhill flow of water\nWhen water erosion is a problem on sloping lands, farmers may plant on contours so that the plant rows follow lines of equal elevation. This limits water from running downhill, and increases infiltration of water into the soil surface. Terraces, grassed waterways, and diversions are other tools used on sloping lands to limit the amount of water running downhill across bare soils.\nSimilar techniques are used on hiking and biking trails, and on ditches in the roadside right-of-way to slow water movement or divert it away from the trail or road.\nWhat about off the farm?\nConstruction projects often strip away all the vegetation and much of the surface layer of soil. Heavy equipment compacts and disturbs the soil surface even more. When it rains, water cannot permeate the ground, so there is more runoff. Moving water then carries soil particles with it: The soil goes where the water goes. In some areas, construction projects are also subject to wind erosion.\nDuring a project, special fences, compost, detention ponds, and other techniques are used to protect the soil surface, slow runoff, and limit the amount of water that leaves the construction site. After the project, vegetation is planted, often in two phases. The first phase provides quick ground cover (if there is rain to get the seeds to germinate and grow). The second phase establishes perennial plants that will protect the surface in the future.\nIn short, the basic principles for controlling erosion are similar regardless of who uses the soil. These include:\n1) Keeping the soil surface covered with vegetation or residues to protect it from wind or raindrops. This limits detachment.\n2) Slowing down flowing water or wind speeds at the soil surface. This limits detachment and transportation, while encouraging deposition of soil.\n3) Improving soil physical conditions at the surface so that it holds together better. This also limits detachment.\n–Answered by Clay Robinson, a.k.a., Dr. Dirt\nHave a question for Soils Matter? Post it in the comments section below or email us at email@example.com']	['<urn:uuid:45607e0a-f97e-40ae-a5ed-4aa02031b620>', '<urn:uuid:bd335650-517a-48da-98f3-8828e2687e55>']	open-ended	with-premise	concise-and-natural	similar-to-document	three-doc	expert	2025-05-01T23:46:40.222380	9	103	1546
422	test validity experimental studies mental powers	Studies examining alleged psychic phenomena through the ganzfeld experiment have been found to contain serious methodological flaws. According to psychologist Ray Hyman's 1985 review of 42 studies, these included inadequate randomization of targets, potential sensory leakage, breaches in security, insufficient experimental details, and statistical problems. The studies showed that the greater the number of flaws, the more likely they were to find a significant effect, and evidence for ESP disappeared as experimental controls became tighter.	"['|Style over substance|\n Experimental conditions\nIn this ""experiment"", a person wearing headphones is placed in a room in relaxed mood half-lying in a comfortable chair. Halved ping-pong balls are placed over his/her eyes with red light shone on them. This makes quite striking imagery for pseudoscience documentaries and is presumably only for this purpose. In the course of the ""experiment"", a ""sender"" sends information about an object (""target"") to the ""receiver"" (the person) and the ""receiver"" tell what he/she is seeing. At the end of this process, the ""experimenter"" shows the ""receiver"" some possible ""targets"" from which he/she decides which resembled the image he/she saw during the ""experiment"".\nThe psychologist Ray Hyman (1985) reviewed forty-two studies from the ganzfeld experiment and concluded ""I believe that the ganzfeld psi data base, despite initial impressions, is inadequate either to support the contention of a repeatable study or to demonstrate the reality of psi. Whatever other value these studies may have for the parapsychological community, they have too many weaknesses to serve as the basis for confronting the rest of the scientific community"". According to Terence Hines in his book Pseudoscience and the Paranormal (2003):\n“”Hyman (1985) found several different flaws in the ganzfeld studies. There was inadequate randomization of the targets in a large percentage of the studies. Opportunities for information on the target to inadvertently reach the subject and breaches in security that might have permitted cheating were also present in many of the studies. Many studies were not described in sufficient detail to allow evaluation of what actually happened in the study. Statistical problems were also common. These included the use of incorrect statistical tests and procedures and “multiple testing” errors in which the subjects’ responses were tested several times against chance, using different criteria for scoring the responses for different tests. This, like testing numerous astrological predictions or numerous predictions of any theory, increases the chance of spuriously obtaining a significant result. Further, the greater the number of flaws in a study, the more likely it was to find a significant effect. This is another example of the phenomenon noted earlier, that evidence for ESP and related phenomena disappears as the tightness of experimental controls is increased. On the basis of Hyman’s review, the ganzfeld studies cannot be said to provide evidence for ESP, as claimed by proponents.\nThe ganzfeld studies contained serious flaws such as inadequate randomization; sensory leakage (in some cases, the receivers could hear what was going on in the sender\'s room next door and, it was possible for the sender\'s fingerprints to be visible on the target object for the receiver to see); and inappropriate statistical analysis. Parapsychologists were embarrassed over this issue.\nIn response, the parapsychologist Charles Honorton co-wrote a paper in 1986 with Hyman that called for additional studies with better, more precise methodologies that would help rule out nonparanormal sources of above-chance results. Daryl Bem and Honorton (1994) published a review of ganzfield studies and concluded they were evidence for ESP. But it turned out that there was a serious problem with their review.\nThe psychologists Julie Milton and Richard Wiseman (1999) published a critique of that review and an analysis of additional new ganzfeld studies. They discovered that Bem and Honorton had counted the results of some studies as being statistically significant when they actually were not significant. This error led Bem and Honorton to conclude that the studies they reviewed had shown, overall, that ESP was operating in the ganzfeld. Milton and Wiseman reviewed thirty ganzfeld studies and they showed no effect greater than chance. Milton and Wiseman concluded:\n“”The new ganzfeld studies show a near-zero effect size and a statistically nonsignificant overall cumulation... The autoganzfeld results have not been replicated by a ""broader range of researchers."" The ganzfeld paradigm cannot at present be seen as constituting strong evidence for psychic functioning.\nPseudoscientific experiments in parapsychology such as the ganzfeld studies are not evidence for psi. Consistent, independent replication has not been achieved.\n Usual outcome\nIn reality, the entire ""experiment"" is a trick. The ""experiment"" is not always done in a soundproof room. The ""receiver"" and the ""experimenter"" can easily hear when videos were playing during the ""experiment"". Involuntary cues are given to the ""receiver"" during the selection procedure.\n- New Analyses Raise Doubts About Replicability of ESP Findings - Skeptical Inquirer\n- Ganzfeld - Skeptic\'s Dictionary\n- ↑ Hyman, R. (1985). The Ganzfeld Psi Experiment: A Critical Appraisal. Journal of Parapsychology 49: 3–49.\n- ↑ Hines, T. (2003). Pseudoscience and the Paranormal. Prometheus Books. p. 137\n- ↑ Dunning, B. (2013). Ganzfeld Experiments. Skeptoid Podcast. Skeptoid Media, Inc.\n- ↑ Hyman, R., and C. Honorton. (1986). A Joint Communique: The Psi Ganzfeld Controversy. Journal of Parapsychology 50: 350–64.\n- ↑ Bem, D., and C. Honorton. (1994). Does Psi Exist? Replicable Evidence for an Anomalous Process of Information Transfer. Psychological Bulletin 115: 4–18.\n- ↑ Milton, J., and R. Wiseman. (1999). Does Psi Exist? Lack of Replication of an Anomalous Process of Information Transfer. Psychological Bulletin 125:387–91.']"	['<urn:uuid:7b74d666-9dfc-4305-b5e0-a339dd7a80c8>']	open-ended	direct	short-search-query	distant-from-document	single-doc	expert	2025-05-01T23:46:40.222380	6	75	837
437	I heard they're doing some work to protect the environment at Dantzler Nature Preserve. What are the main things they're trying to achieve there?	The primary management goals for the Dantzler Nature Preserve are to protect and enhance the estuarine marsh flora and fauna, restore the longleaf pine ecosystems of the uplands, install nature trails for public access, and reduce the wildfire hazard to adjacent subdivisions.	"[""Dantzler Nature Preserve Longleaf Pine Restoration Project: MX974390\nThe vision for managing Mississippi's Coastal Preserves is to provide long-term benefits to the natural resources and economic value of the region. Management goals are designed to enhance and perpetuate important coastal wetland resources, provide compatible human recreational use, provide research and data applicable to coastal resource management both on-site and off-site, and protect specific habitat necessary for native, threatened, or endangered species. State trust lands within the Coastal Preserve sites are effectively managed to perpetuate their natural characteristics, features, ecological integrity, social, economic and aesthetic values so that future generations may enjoy the benefits of viable wetland ecosystems.\nThe Dantzler Nature Preserve (DNP) was donated to the State of Mississippi in 1996 as part of the wetland mitigation requirements for the Beau Rivage Casino development. This site was incorporated into the Pascagoula River Coastal Preserve to be managed, in perpetuity, as a natural area. This preserve is part of the Mississippi Coastal Preserves System comprising nearly 35,000 acres of coastal wetland and maritime forest habitat. This preserve has been designated as a Gulf Ecological Management Site (GEMS) and as a Nationally Important Bird Area by the National Audubon Society and as a Globally Important Bird Area by the American Bird Conservancy.\nThe DNP tract is a mixture of 403 acres of uplands and 470 acres of saltwater marsh. The upland soils (~ 265 acres) are dominated by the Lenoir Silt Loam with Myatt inclusions of hydric soil. The balance of the area is in hydric soils such as Daleville and Hyde Silt Loams. Approximately 60% of the upland contains a stand of longleaf pine (Pinus palustris) of varying densities mixed with slash (Pinus elliottii) and loblolly pines (Pinus taeda) and mixed hardwoods. The remainder is in slash pine and hardwoods. Except for the wettest sites, a heavy understory of brush dominated by yaupon (Ilex vomitoria) and gallberry (Ilex glabra) characterizes the entire upland. The marsh portion of the tract contains four islands of uplands totaling 11 acres, predominantly slash pine, ranging in size from less than an acre to about nine acres.The primary goals for managing the DNP are:\n1. Protect and enhance the flora and fauna of the estuarine marsh.The strategies for achieving these goals are:\n2. Restore the longleaf pine ecosystems of the uplands.\n3. Install nature trails to provide public access.\n4. Reduce the wildfire hazard to adjacent subdivisions.\n1. Using prescribed fire on a 3-5 year cycle to reduce fuel loads and maintain the fire-dependent longleaf pine ecosystems.\n2. Using herbicides to control invasive species that do not respond to fire.\n3. Using timber thinning to remove the loblolly and slash pines and to reduce the basal area for the dense longleaf pine areas.\n4. Developing a parking area and using signage and existing firelines as nature trails.\nIn summary, prescribed burning is the primary tool used in restoring longleaf pine ecosystems. However, due to weather conditions and resource issues, MDMR was unable to conduct burns on the planned schedule. Nevertheless, MDMR has managed to burn seven of eight burn units over the past 5 years and has burned one unit twice during that period. The twice-burned unit shows significant movement toward a longleaf pine / wiregrass savanna ecological community, with a major reduction in heavy brush and an increase in the herbaceous community. In addition, MDMR has shown good success in reducing invasive cogongrass populations and is making some progress in reducing tallowtree populations. Through thinning and planting MDMR has reduced the number of loblolly and slash pines and increased the number of longleaf pines. MDMR has also made progress in restoring the natural hydrology by grading down roads and filling ditches. Although this restoration project will take several more years to complete and will require continuous maintenance after completion, the funds from this grant has helped MDMR make""]"	['<urn:uuid:2c1e8e91-230a-4bd8-98fe-924fcff115e3>']	factoid	with-premise	verbose-and-natural	distant-from-document	single-doc	novice	2025-05-01T23:46:40.222380	24	42	643
441	As someone interested in ocean conservation, I'd like to know what's the difference between how marine protected areas help with scientific research in the Philippines versus Australia?	Marine protected areas serve distinct research functions in both countries. In the Philippines, scientists use protected areas to conduct comprehensive biodiversity surveys, like the California Academy of Sciences expedition that discovered over 300 new species. These areas allow researchers to document and study unique marine life in the world's most diverse marine environment, including discovering new species of sea slugs, barnacles, and deep-sea creatures. In Australia, marine protected areas serve as controlled research environments through strict no-entry zones that prevent any human interference. These areas provide researchers with undisturbed conditions to study how marine plants and animals function and what adaptations they've developed to cope with climate change. The complete exclusion of human activity in these zones allows scientists to collect data without external influences affecting the natural ecosystem.	"['After six weeks in the Philippines trawling the ocean floor, canvassing the jungly flanks of volcanoes and diving in coral reefs, scientists believe they have discovered more than 300 species that are new to science. Their research constituted the largest, most comprehensive scientific survey ever conducted in the Philippines, one of the most species-rich places on earth.\nThe survey, led by the California Academy of Sciences, brought scores of bizarre and unexpected creatures into the annals of life as we know it. It revealed more than 50 kinds of colorful new sea slugs, dozens of spiders and three new lobster relatives that squeeze into crevices rather than carry shells on their backs. The scientists found a shrimp-eating swell shark that lives 2,000 feet under the sea, a starfish that feeds exclusively on sunken driftwood and a cicada whose call sounds like laughter.\nFor two weeks I shadowed teams of scientists—from seahorse specialists to spider experts—as they surveyed reefs, rain forests and the South China Sea. On a deep-sea vessel, scientists dropped traps and nets to obtain a glimmer of the life that exists in the shadowy depths. They surrounded each haul excitedly as it was deposited on deck, picking through the curious sea life and discarding the garbage that inevitably accompanied it. “To see live stalk crinoids”—feather stars—“come up that I’ve only seen as preserved specimens is like a scientist’s dream world!” said invertebrate zoologist Terrence Gosliner, who led the expedition, one afternoon as he sorted spindly starfish and coral from candy wrappers.\nThree new species of deep-sea “bubble snails” that possess fragile, translucent, internal shells arrived in one trawl, along with a snake eel and two new “armored corals” called primnoids, which protect themselves against predatory nibbles from fish by growing large, spiky plates around each soft polyp. Ten-inch-long giant isopods as imagined by science fiction turned up in a trap. “If you saw District 9 I’m sure they modeled the faces of the aliens off these,” said marine biologist Rich Mooi, who studies sea urchins and sand dollars. Later that evening, the catch yielded several two-foot-long, mottled swell sharks that inflate their stomach with water to bulk up and scare off other predators.\n“When I watch the trawl come up it’s like a window onto the frontier,” said Mooi. “You start going through this material wondering, ‘What are they doing down there? Are they interacting with each other?’ We’ve seen a very tiny percentage of that sea bottom—three-quarters of the planet is obscured by this endlessly restless mass of water you can’t see through.”\nMany of the new species found in the survey had evaded science because of their small size—the 30 new species of barnacles discovered measure just fractions of an inch in length—while others lived in areas rarely visited by humans. A primitive, fernlike plant called a spikemoss was found growing on the precipitous upper slopes of a 6,000-foot volcano. “Our scientific understanding of this part of the world is still in its infancy,” said Gosliner. “For people interested in biodiversity and the distribution of organisms and evolution, the Philippines is a treasure trove.”\nYet it is a gravely imperiled treasure trove. The rate of species extinction in the Philippines is “1,000 times the natural rate,” according to the country’s Department of Environment and Natural Resources, because of deforestation, coastal degradation, unsustainable use of resources, climate change, invasive species and pollution. A recent study by Conservation International found that just 4 percent of the Philippines\' forests remained as natural habitat for endemic species, and according to the World Wildlife Fund, destructive commercial fishing has left only 5 percent of coral reefs in the Philippines in excellent condition.\nScientists described the expedition this spring as a kind of emergency response. “We’re living in a burning house,” said Mooi. “In order for firemen to come in and make an effective rescue they need to know who’s in those rooms and what rooms they’re in. When we do biodiversity surveys like this we’re doing nothing less than making a tally of who’s out there, who needs to be paid attention to, and how can we best employ the resources we have to conserve those organisms.”\nFor years scientists have recognized a 2.2-million-square-mile area around Malaysia, Papua New Guinea and the Philippines as being home to the world’s highest diversity of marine plants and animals. It’s known as the Coral Triangle and considered the Amazon basin for marine life. The waters harbor 75 percent of the planet\'s known coral species and 40 percent of its coral reef fish.\nIn 2005 Kent Carpenter, an ichthyologist at Old Dominion University, identified the core of that diversity. Overlaying global distribution maps for nearly 3,000 marine species, including fishes and corals, sea turtles and invertebrates, Carpenter found that the highest concentration of marine species on the planet existed in the central Philippines. “I fell off my chair—literally—when I saw that,” Carpenter recalled recently. He dubbed the region “the Center of the Center.”\nThe reasons for this are not entirely understood. The 7,107 islands that make up the Philippine Archipelago constitute the second-largest island chain in the world after Indonesia. The islands converged over millions of years from latitudes as disparate as those of present-day Hong Kong and Borneo, and they may have brought together temperate and tropical fauna that managed to get along in a crowded environment.\nAnother possible explanation is that the Philippines has a higher concentration of coastline than any country except Norway, providing a lot of habitat. It is also a place where species are evolving more rapidly than elsewhere. Populations become isolated from other populations due to oceanographic features such as swirling currents known as gyres. The populations then diverge genetically and become new species. “The only place on the planet where you have all of the above is in the Central Philippines,” said Carpenter.\nA prime location for this diversity is the Verde Island Passage, a busy commercial sea route off Luzon Island, the largest island in the archipelago. During two decades of diving in the Verde Island Passage, Gosliner, the world’s foremost expert in nudibranchs, or sea slugs, has documented more than 800 species, half of them new to science. There are more species of soft corals at just one dive site than in all of the Caribbean. “Every time I go into the water here I see something I’ve never seen before,” he said.\nOne afternoon, Gosliner emerged from a dive into the shallow water reefs clutching a plastic collection bag that contained two nudibranchs, one colored a bright purple with orange tentacles. “Two new nudis!” he called out. “And the black and electric blue nudibranchs were mating like crazy down there. There were egg masses everywhere. They were having a good ole time.”\nUnlike land slugs, nudibranchs have bright colors that advertise toxic chemicals in their skin. These chemicals may have pharmaceutical value, and several are in clinical trials for HIV and cancer drugs. Gosliner explained that the presence of nudibranchs, which feed on a wide variety of sponges and corals, “are a good indication of the health and diversity of the ecosystem.”\nThe Verde Island Passage ecosystem has faced immense pressures over the past few decades. In the 1970s, Carpenter worked as a Peace Corps volunteer with the Philippines Bureau of Fisheries. “Every 50 feet you’d see a grouper the size of a Volkswagen Bug, big enough to swallow a human being,” he recalls. Today, large predatory fish like sharks are virtually absent. Fishermen now harvest juveniles that haven’t had a chance to reproduce; “it’s at the very level where you can’t get any more fish out of oceans here,” says Carpenter. Destructive fishing methods have devastated the area’s coral. Illegal trade has exacted a further toll; this spring, Filipino officials intercepted a shipment of endangered sea turtles and more than 21,000 pieces of rare black corals bound for mainland Asia, for the jewelry trade.\n“There’s a lot of good policies and regulations in place in the country, but the main weakness right now is enforcement,” says Romeo Trono, country director for Conservation International.\nThe Philippines has more than 1,000 marine protected areas, more than any country in the world, but only a few, Carpenter and other scientists say, are well managed. For 30 years, Apo Island, in the southern Philippines, has been held as a model for community-managed marine reserves. In 1982 a local university suggested the community declare 10 percent of the waters around the island a “no take” zone for fishermen. Initially resistant, the community eventually rallied behind the reserve after seeing how an increase in fish numbers and sizes inside the sanctuary spilled over into the surrounding waters. They established regulations against destructive fishing and a volunteer ""marine guard"" (called bantay dagat) to patrol the fishing grounds and prevent encroaching from outsiders. User fees from the marine sanctuary generate nearly $120,000 per year, and the tourist industry surged after the marine ecosystem recovered.\n“Where marine protected areas have been established and populations of animals and fishes have been allowed to recover, they recover very well and very quickly,” says Gosliner. “The difference between diving in a marine protected area versus an area right next to it is like night and day.”\nOver the next several months, California Academy scientists will use microscopes and DNA sequencing to confirm and describe these new species. The species lists and distribution maps created during the expedition, they hope, will help to identify the most important locations for establishing or expanding marine protected areas, as well as areas for reforestation that will reduce erosion and subsequent sedimentation damage to the reefs.\nBut for the scientists, the survey is just the beginning. “Being able to document the richest and most diverse marine environment on the planet” will help them “get an understanding of what the dimensions of diversity are,” said Gosliner. “We really don’t know the answer to that fundamental question.”\nAndy Isaacson is a writer and photographer who lives in Berkeley, California. His reporting was made possible by a grant from Margaret and Will Hearst that funded the expedition.', 'CONSERVING NATURAL BEAUTY: MARINE PROTECTED AREAS\nDid you know that many of Australia’s most picturesque vacation destinations are actually also marine protected areas? Some of the most famous marine protected areas are Lord Howe Island and the Great Barrier Reef. There are quite a few more marine protected areas in Australia that you might have not heard about, these include Pati Point Reserve, Red Sea Marine Peace Park and Bonaire Marine Park. But what exactly is the purpose of a marine protected area?\nA marine protected area (MPA) is an area of the ocean in which a country’s government has placed limits on human activity for the protection and maintenance of biological diversity. Marine protected areas can have different names including marine parks, marine conservation zones, marine reserves, marine sanctuaries, and no-take zones.\nThe extent to which human activity is limited in an MPA varies between different MPAs. The strictest type of MPA doesn’t allow any human entry at all, this not only prevents people from fishing but also prevents people from disturbing the natural flow of particular ecosystems and their fragile habitats. No-entry MPAs are normally quite small and used for research as they are controlled environments with no outside influence impacting the environment. Another type of MPA is a no-take MPA which doesn’t allow fishing but allows people to travel through the area whether on land or snorkelling. In multiple-use MPAs, the areas are still quite protected but some fishing is still allowed.\nMarine protected areas have been established due to the threats that face our oceans including overfishing, litter, water pollution, and global climate change. These threats have caused a decline in the population of many fish and marine mammals, leading even some to extinction.\nThe aim of MPAs is to assist in maintaining the long-term ecological viability of marine and estuarine systems and to minimise the impact of the threats that face our oceans. It is commonly known that the marine benefit of MPAs is their impact on fisheries. It supports fisheries by restricting people’s ability to fish endangered species in certain marine ecosystems. However, it often goes unrecognised that MPAs benefit marine ecosystems through waste assimilation, coastal protection, flood management, and critical environmental requirements for fished species. Additionally, by limiting human access to certain marine systems we are able to provide researchers with the data they need to understand how certain marine plants and animals function and what adaptations they have undergone to limit the impact of climate change on their population.\nNot all MPAs have the same goals but overall the main focus of many is to protect marine habitats and the variety of life they support. The preservation of shipwrecks can also be the focus of MPAs as these areas can be closed off to fishing, diving and ocean exploration in order to maintain the environment that is living around the shipwreck to conserve the shipwrecks and their historical and cultural meaning. By restricting access to certain areas of the ocean and preventing overfishing, MPAs also ensure that certain resources remain sustainable. It can be seen in the US and Canada that after several MPAs were established, fish populations began to increase, and fishing improved.\nWhilst more than 5,000 marine protected areas have been established worldwide, there is still a lot more progress that needs to be made to conserve the natural marine ecosystems across the globe. Whilst they vary in restrictions, any type of MPA being established will further the preservation of our oceans and their marine life. Marine protected areas hold the key to ensuring we can preserve our oceans’ beauty and its resources for many years (and hopefully centuries) to come.']"	['<urn:uuid:bf5ce8a6-06ef-4c05-9f70-4d71b0d956b7>', '<urn:uuid:14354bb8-a006-486c-9a17-56ae8cc2ab72>']	open-ended	with-premise	verbose-and-natural	distant-from-document	comparison	novice	2025-05-01T23:46:40.222380	27	129	2294
446	fungal sinusitis diagnosis immune deficiency causes	Fungal sinusitis occurs commonly in immune deficient patients, including those with AIDS, poorly controlled diabetes, or transplant recipients on immunosuppressants. Diagnosis requires CT scans to show the extent of sinusitis and identify underlying causes. Key fungal infections include mucormycosis, which produces black dead tissue, aspergillosis in cancer patients on chemotherapy, and candidiasis in immunocompromised patients. COVID-19 can also predispose patients to fungal infections due to its impact on T-cell populations and cell-mediated immunity, particularly affecting CD4+ and CD8+ T-cells.	['A middle-aged woman with diabetes presented with left-sided facial pain, complete ptosis and fever of short duration. On presentation, she had hyperglycaemia without ketosis. There was total ophthalmoplegia of the left eye with a visual acuity of 6/36. She incidentally tested positive for COVID-19. CT paranasal sinus and MRI brain revealed left-sided pansinusitis with acute infarct in the left parieto-occipital region without angioinvasion. An emergency functional endoscopic sinus procedure was done, which confirmed mucormycosis on histopathological examination. After 1 week of conventional amphotericin B and antibiotics, repeat CT brain showed improvement in mucosal thickening and sinusitis. This case is a rare presentation of mucormycosis associated with rapid progression to orbital apex syndrome with brain infarction in a patient with non-ketotic diabetes and COVID-19. Early diagnosis and treatment are essential to prevent further end-organ damage. It is also interesting that there was no angioinvasion and transient periarterial inflammation was attributed to brain infarction.\n- tropical medicine (infectious disease)\nThis article is made freely available for use in accordance with BMJ’s website terms and conditions for the duration of the covid-19 pandemic or until otherwise determined by BMJ. You may use, download and print the article for any lawful, non-commercial purpose (including text and data mining) provided that all copyright notices and trade marks are retained.https://bmj.com/coronavirus/usage\nStatistics from Altmetric.com\nMucormycosis is an angioinvasive disease caused by fungi of the order Mucorales like Rhizopus, Mucor, Rhizomucor, Cunninghamella and Absidia. The prevalence of mucormycosis in India is approximately 0.14 cases per 1000 population, about 80 times the prevalence in developed countries.1 COVID-19 infection has been associated with fungal infections. Mucormycosis is more often seen in immunocompromised individuals, and complications of orbital and cerebral involvement are likely in diabetic ketoacidosis and with concomitant use of steroids. The most common risk factor associated with mucormycosis is diabetes mellitus in India.2 In the background of the COVID-19 pandemic, only a limited number of cases of mucormycosis have been reported, but there are no known documented cases of sudden-onset visual loss with incidental COVID-19 infection in a newly detected young non-ketotic diabetic.3\nA middle-aged woman, with newly detected diabetes mellitus (haemoglobin A1c: 12.39%), presented with left eye complete ptosis, facial pain for 5 days and preceding fever for 3 days with no symptoms of rhinitis or sinusitis. Clinical examination revealed tenderness of all sinuses on the left side. There was a complete internal and external ophthalmoplegia of the left eye, with absent left eye direct light reflex and left eye visual acuity of 6/36 (figure 1). The right eye movements and vision were normal. The rest of the neurological examination was within normal limits. The patient was afebrile on presentation. Pulse was 78 bpm, blood pressure was 124/80 mm Hg and oxygen saturation was 98% on room air. Systemic examination was unremarkable, and there was no clinical evidence of ketoacidosis.\nAdmission glucose was 378 mg/dL without ketosis. Serum glycated haemoglobin was 12.39%. A CT paranasal sinus showed total opacification of the left ethmoid, maxillary and frontal sinuses (figure 2). An MRI brain showed acute infarct in the left parieto-occipital lobe with a subperiosteal abscess in the superomedial extraconal aspect of the left orbit (figure 3) with thickening and perineural enhancement of the left optic nerve. There was no thrombus in the left internal carotid artery (ICA); however, there was some periarterial inflammation of the left ICA (figure 4). The total leucocyte count was 10.6 × 109/L with a lymphocyte count of 1696 cells/uL. Serial monitoring showed a falling trend of lymphocyte count from 1696 (day 1), to 1246 (day 5), to 924 (day 10), to 666 (day 14) cells/uL. However, CD4 or CD8 testing could not be done. Serum liver biochemistry was within normal limits. Blood urea was 12.3 mg/dL, and serum creatinine was 0.44 mg/dL. The serum electrolytes were within normal limits. She had a B-positive blood type. Inflammatory markers were C reactive protein, 68.35 mg/L (reference range: ≤6 mg/L); procalcitonin, 0.069 ng/mL (reference range: <0.5 ng/mL); D-dimer, 0.80 μg FEU/mL (reference range: <0.5 μg FEU/mL); and serum ferritin, 180.2 mg/dL (reference range for men, 30–400 ng/mL; women, 13–150 ng/mL). She tested positive incidentally for COVID-19 by real-time PCR (nasal and oropharyngeal swab) on day 2 of hospitalisation using TRUPCR SARS-CoV-2 RT qPCR KIT (version 3.2). Chest X-ray (figure 5) was unremarkable, and the patient never required oxygen therapy. She was classified as having a mild COVID-19 infection. Functional endoscopic sinus surgery (FESS) was performed on an emergency basis due to orbital apex syndrome as she fell into group ‘A’ of endonasal surgery indications4 and showed unhealthy, polypoidal mass and slough in the maxillary, anterior and posterior ethmoid sinuses with pus in the frontal sinus and polypoidal mucosa in the sphenoid sinus. Histopathological analysis of the biopsy sample from ethmoid sinus showed fungal colonies of broad aseptate hyphae at an obtuse angle with periodic acid–Schiff stain, which was consistent with mucormycosis. Fungal culture of the sample obtained after sinus debridement in FESS confirmed mucormycosis (Rhizopus species). However, serological fungal markers and fungal culture sensitivity were not tested. The patient was hospitalised for 17 days. Her sugars were well controlled after the initiation of insulin therapy. However, there was no resolution of ophthalmoplegia or ptosis until she was discharged.\nShe was initiated on conventional amphotericin B (given for 11 days) and aspirin for acute cerebral infarct. Post FESS, CT paranasal sinus imaging was done after 1 week of treatment with antifungal therapy and showed a reduction in the diffuse opacification of the left ethmoid, frontal and maxillary sinuses (figure 6).\nAn active search of literature reviewed few reported rhino-orbitary cases associated with COVID-19.3 5 6 Diabetes mellitus is an independent risk factor for rhino-orbital–cerebral mucormycosis in a meta-analysis of 600 series with 851 cases. The most common species isolated was Rhizopus species, with an overall mortality of 46%.7\nA case of COVID-19 with rhino-orbital mucormycosis coinfection associated with ketoacidosis was reported in a patient with recent-onset diabetes mellitus.8 Pathogenic mechanisms involved in fungal aggressiveness include decreased phagocytic activity, accessible amounts of iron due to the displacement of protons by transferrin in diabetic ketoacidosis and fungal heme oxygenase, which promotes iron absorption for its metabolism.\nIn a case described of severe COVID-19 associated with fungal coinfection, cell counts revealed that there was a progressive increase in white blood cell count and neutrophils while lymphocytes progressively decreased.9 It is hypothesised that SARS-CoV-2 infection may affect CD4+ and CD8+ T-cells, which are highly involved in the pathological process of COVID-19 infection. It has been shown that in severe COVID-19 cases, there is a reduction in the absolute number of lymphocytes and T-cells, which is associated with the worst outcomes. Mucorales-specific T-cells (CD4+ and CD8+) produce cytokines such as interleukin (IL) 4, IL-10, IL-17 and interferon-gamma (IFN-γ) that damage the fungal hyphae. Such specific T-cells were seen only in patients affected by invasive mucormycosis, and they concluded that they could be a useful surrogate diagnostic marker of an invasive fungal disease. It might be speculated that lymphopenia could increase the risk of developing invasive mucormycosis, while the recovery of lymphocyte count could improve the adaptive immune system and induce the production of Mucorales-specific T-cells, which might have a role in controlling the invasive infection.\nThere are a significant number of reports showing alterations in cell-mediated immunity, such as chemotaxis, phagocytosis and cytokine secretion in both type 1 and type 2 diabetics. Individuals with diabetes have been described to have alterations in innate immune system components. Natural killer cell activity is reduced in individuals with diabetes, and more pro-inflammatory M1 macrophages are present. Furthermore, T-cell activity is skewed. Disease severity in patients is due to not only the viral infection but also the host response. Elevated glucose levels may also suppress the antiviral response. In the context of COVID-19, severe disease progression is described by a delay in IFN-γ response with a prolonged hyperinflammatory state and lower CD4 and CD8 cell numbers. Regardless of the involvement of the endothelial cells, the initial delay in IFN-γ response together with the hyperinflammatory response in individuals with diabetes may exacerbate the ‘cytokine storm’ and increase COVID-19 severity. Increased vascular lesions, endothelial inflammation and vasoconstriction associated with endothelial dysfunction put individuals with diabetes at a greater risk for endotheliitis in several organs. Change of vascular tone towards more vasoconstriction can lead to subsequent organ ischaemia, tissue oedema and a procoagulant state. Finally, dysregulated immune cell populations and activity observed in individuals with diabetes play a critical role in aggravating the severity.10\nA case series in the Indian subcontinent reported six cases of rhino-orbital–cerebral mucormycosis following COVID-19 infections.11 The mean duration between the diagnosis of COVID-19 and the development of symptoms of mucormycosis was 15.6±9.6 days. Control of hyperglycaemia, early treatment with liposomal amphotericin B and surgery are essential for the successful management of mucormycosis. Thus, the use of glucocorticoids in mild COVID-19 cases (without hypoxaemia) or the utilisation of higher doses of glucocorticoids should be avoided. Further, in the absence of a clear benefit, drugs targeting immune pathways such as tocilizumab should be discouraged. For successful management of mucormycosis, a high index of clinical suspicion, low threshold for diagnosis in patients with risk factors, neuroimaging and specific diagnostic tests with a coordinated effort from a multidisciplinary team including ophthalmology, otorhinolaryngology, infectious diseases, neurosurgery, critical care, microbiology and pathology department are crucial. A delay of even 6 days in initiating treatment doubles the 30-day mortality from 35% to 66%.11\nSimple tests like vision, pupil, ocular motility and sinus tenderness can be part of routine physical evaluation of a patient with COVID-19 hospitalised with moderate to severe infection or diabetics with COVID-19 or those receiving systemic corticosteroids. Visual prognosis, however, continues to remain poor.\nThus, it is important to have a high index of suspicion for fungal coinfection in patients with COVID-19 presenting with comorbidities. Further, they should undergo immediate imaging studies with an emphasis on the requirement of surgical intervention. There is a need to stress on the judicious use of steroids to avoid flaring up of the fungal infection.\nThis case is an unusual presentation of rapidly developing fungal infection in a patient with non-ketotic diabetes in the background of COVID-19. Severe disease progression in the absence of use of immunosuppressants makes it a rare case.\nAn alteration in the T-cell population in COVID-19 infection is linked to the pathogenesis of fungal infection.\nEarly diagnosis and treatment of mucormycosis that involve antifungal therapy and surgical debridement are necessary to reduce mortality and prevent end-organ damage.\nJudicial use of immunosuppressive therapy in COVID-19 infection should be considered particularly in regard to treatment of fungal coinfections.\nContributors All four authors were involved in patient care directly. Writing the initial manuscript was done by SMR. Selecting appropriate image templates was done by VVK. The necessary corrections and final outcome of the article were done under the guidance of SPS and LS.\nFunding The authors have not declared a specific grant for this research from any funding agency in the public, commercial or not-for-profit sectors.\nCompeting interests None declared.\nProvenance and peer review Not commissioned; externally peer reviewed.\nIf you wish to reuse any or all of this article please use the link below which will take you to the Copyright Clearance Center’s RightsLink service. You will be able to get a quick price and instant permission to reuse the content in many different ways.', 'Sinusitis exists when one or more of the sinus cavities is infected. There are 3 pairs of common sinus cavities, the frontal sinuses above the eye sockets, the ethmoid sinuses between the nasal cavity and the eye sockets, and the maxillary sinuses underneath the eye sockets, but above the upper row of teeth.\nThere is a fourth location of a sinus cavity, located in the midline right underneath the pituitary gland, which is called the sphenoid sinus. These hidden cavities in the facial bone are lined with a mucous membrane and are connected to the inside of the nose through very tiny ducts.\nThese can get plugged with a cold, which can lead to sinusitis with a “sinus headache”. Subsequent bacterial superinfection can lead to an acute bacterial sinusitis. Often the pathogen is a bacterium such as Haemophilus influenzae or Staphylococcus aureus, but viruses can also cause an identical clinical picture. As the sinus ducts are plugged and a vacuum develops inside the sinus cavities, there is an accumulation of inflammatory serum, which is the ideal breeding ground for bacteria to multiply in.\nWith regard to sinus symptoms, there may be a dull pain around the eyes, there may be a pussy discharge from the nose and a fever. Depending on which sinuses are affected, there can be swelling over the area.\nFor instance, with maxillary sinusitis (thanks to www.pharmacy-and-drugs.com for this link) there might be swelling and tenderness in the area below the side of the nose underneath the eye socket. At the same time there might be a tooth ache in the upper teeth as the nerve roots can be directly irritated from inflammation in the bottom part of the sinus cavity where the nerves run by. With a frontal sinusitis there is often a frontal headache. With ethmoid sinusitis there is a splitting headache in he front and pain between and behind the eyes. A sphenoid sinusitis gives the patient a more dull headache either in the back or in the front.\nIn an acute sinusitis the doctor may make the diagnosis clinically and treat with a course of antibiotics. In chronic sinusitis, which has the identical symptoms as acute sinusitis, diagnostic tests may be necessary to locate the sinusitis and look for other underlying causes. A CT scan can give a lot of detail, shows the extend of the sinusitis, possible underlying polypoid or cancerous lesions etc. that may have predisposed the patient to get sinusitis.\nSinus treatment consists of doing steam inhalation frequently and for 10 minutes at a time. This will bring the swelling of the nasal lining down facilitating the opening up of the sinus ducts and promoting drainage.\nTopical vasoconstrictive nasal sprays such as phenylephrine (brand names: Dionephrine, Mydfrin, Neo-Synephrine) or xylometazoline nasal spray (brand names: Otrivin, Decongest) will also assist in drainage of sinus cavity secretions. However, these nasal solutions should not be taken more than 7 days in a row as they lose effectiveness. In acute sinusitis penicillin V or erythromycin is given for 10 to 12 days. In chronic sinusitis amoxicillin or tetracycline is given a prolonged course of 4 to 6 weeks. Nasal discharge is cultured to detect the pathogen, which guides the choice of antibiotic. If a chronic sinusitis does not respond to the above mentioned measures, then a referral to an ENT specialist is needed, as a surgical drainage procedure using endoscopic intranasal surgery may be required to ventilate the sinuses again. In immune deficient patients, such as AIDS patients or patients with poor control of diabetes or recipients of transplanted organs on immune suppressants, chronic sinusitis may develop with more rare fungal infections.\nMucormycosis is one such fungal infection, which leads to black dead tissue from which the fungus can be isolated. It would need treatment with intravenous amphotericin B, an antifungal agent, and improvement of the diabetic control, if this is the underlying metabolic condition. Aspergillosis is to be suspected in a person with cancer who is on chemotherapy or otherwise immunocompromised when there is polypoid tissue in the nose and the sinuses. There are several species such ass Aspergillus flavus, A. fumigatus and A.niger. The specialist needs to do a biopsy and culture of this material and once confirmed as aspergillosis, wide surgical drainage and cleaning out of the papillomatous material has to be done in combination with intravenous amphotericin B (brand name: Fungizone), which eradicates this fungus. If the seriousness of this condition is not appreciated, this disease can be fatal as it will spread systemically (Ref. 4, p.689). Candidiasis is common in AIDS patients and patients with immune suppressing therapy or diseases. It is very versatile and causes white thrush on the mucous membranes of the mouth or genitals (glans of penis, inside vagina), or moist skin areas between the fingers, or in moist skin folds particularly in obese people. With regard to the sinuses the accumulation of mycel in the sinus ducts can lead to blockage of the natural drainage of the sinuses, which leads to the candidiasis infection. Treatment: Similar to aspergillosis the specialist needs to biopsy and culture the mycel material. When diagnosed, drainage procedures have to be done to reopen the sinuses wide. This is combined with anti Candida albicans therapy such as fluconazole (brand name: Diflucan) orally. For serious systemic infection Amphotericin B (brand name: Fungizone) is given intravenously (Ref. 1, p. 83).\n1. The Merck Manual, 7th edition, by M. H. Beers et al., Whitehouse Station, N.J., 1999. Chapter 161.\n2. TC Dixon et al. N Engl J Med 1999 Sep 9;341(11):815-826.\n3. F Charatan BMJ 2000 Oct 21;321(7267):980.\n4. The Merck Manual, 7th edition, by M. H. Beers et al., Whitehouse Station, N.J., 1999. Chapter 43.\n5. JR Zunt and CM Marra Neurol Clinics Vol.17, No.4,1999: 675-689.\n6. The Merck Manual, 7th edition, by M. H. Beers et al., Whitehouse Station, N.J., 1999. Chapter 162.\n7. LE Chapman : Antivir Ther 1999; 4(4): 211-19.\n8. HW Cho: Vaccine 1999 Jun 4; 17(20-21): 2569-2575.\n9. DO Freedman et al. Med Clinics N. Amer. Vol.83, No 4 (July 1999): 865-883.\n10. SP Fisher-Hoch et al. J Virol 2000 Aug; 74(15): 6777-6783.\n11. Mandell: Principles and Practice of Infectious Diseases, 5th ed., copyright 2000, Churchill Livingstone, Inc.\n12. Goldman: Cecil Textbook of Medicine, 21st ed., Copyright 2000, W. B. Saunders Company\n13. PE Sax: Infect DisClinics of N America Vol.15, No 2 (June 2001): 433-455.\n14. Suzanne Somers: “Breakthrough” Eight Steps to Wellness– Life-altering Secrets from Today’s Cutting-edge Doctors”, Crown Publishers, 2008']	['<urn:uuid:0419cc06-8800-41cd-8467-90adc4377911>', '<urn:uuid:9581eab1-68b4-41d7-9794-4b3a91a24e6c>']	open-ended	direct	short-search-query	similar-to-document	multi-aspect	expert	2025-05-01T23:46:40.222380	6	79	2979
451	best temperature and conditions to store feijoa fruit long time	Feijoa fruit can be stored at 4°C in unlined trays. Under these conditions, weight loss reaches about 6% after six weeks at 4°C plus an additional 5% during 7 days at ambient temperature (20°C). Controlled atmosphere storage with 2-5% oxygen and 0-3% carbon dioxide at 4°C can be more effective, reducing weight loss to only 1.5-2% of initial weight and helping maintain fruit firmness.	['Postharvest treatments to extend the storage life of feijoa (Acca sellowiana) : a thesis presented in partial fulfilment of the requirements for the degree of Doctor of Philosophy in Food Technology at Massey University, Palmerston North, New Zealand\nFeijoas (Acca sellowiana) have a short harvest season and a limited postharvest life. In feijoa, usually there is a large variation between individual fruit in terms of size, colour, chemical composition and physiological stage. This variation could be attributed to the time of fruit set which is relatively long, which leads to great variation in fruit maturity. In order for the New Zealand feijoa industry to export to distant markets a postharvest life of at least 6 weeks is required. Determining the maturity index of a crop is vital especially for trade regulations and marketing strategy. Feijoa do not change colour significantly during ripening, so the only unequivocal way of assessing fruit maturity is to cut the fruit open. An internal maturity rating scale has been developed by Plant and Food Research primarily based on locular development. The use of ‘touch picking’ depending on fruit retention force is considered the most practical and reliable method for the time being for determining minimum harvest maturity of feijoa. The aims of this work were to investigate options for a non-destructive method in determining maturity index of feijoa fruit compared to the internal maturity rating scale; extending storage life of feijoa fruit by cool storage and controlled atmosphere conditions to allow long distance sea freight to increase export opportunities; and to develop an understanding of feijoa ripening physiology in relation to ethylene and propylene treatments.\nIn this study, differences between the commercial pack houses in identifying the optimum fruit maturity of feijoa at harvest were large. Compression firmness was more reliable than acoustic firmness in determining maturity stages of different feijoa cultivars, but acoustic firmness was quite reliable for some cultivars. The Sinclair unit device was not suitable for measuring maturity index of feijoa fruit tested. Spin-spin relaxation time (T2) and half height peak (ΔH2) determined by NMR showed promise for identifying fruit maturity. In general, these non-destructive techniques used in this experiment showed some promise but further work is required to understand why the differences between cultivars and regions happen. Chemical changes such as total soluble solids, dry matter and titratable acidity were found unhelpful in determining maturity stages of feijoa fruits. There was no significant reduction in TSS or dry matter with maturity, but there was a clear reduction in titratable acidity. Even with this clear trend with titratable acidity, it is not helpful as it is still a destructive measurement, nevertheless the internal chemical changes may be able to be estimated with a non-destructive technique such as Near Infrared Spectroscopy (NIRS). A combination of non-destructive methods such as firmness with NIR may be better than depending on a single index in identifying fruit maturity. In addition, the data clearly demonstrated that fruit at any particular internal maturity rating were clearly shown to have a wide range of firmness values, total soluble solids (TSS), titratable acidity (TA), skin colour, and aroma. This makes it likely that this maturity as measured by locular development is a poor descriptor for overall process of fruit ripening in feijoa.\nAs feijoa fruit mature, aroma volatile concentrations increase. The three characteristic compounds (ethyl butyrate, ethyl benzoate and methyl benzoate) of feijoa aroma were found more consistently in headspace analysis than solvent extracted flesh. Controlled atmosphere (CA) storage was found to suppress volatile production. Aroma could be used as a fruit quality measure. The e-nose has been shown to be sensitive to volatiles in other fruit, so it might have potential for measuring the changes in maturity of feijoa fruit. This technique is practical, non-destructive and cost effective. This technique should be tried in the future with feijoa cultivars.\nTo extend the postharvest life of feijoa fruit, cool storage in unlined trays at 4°C was tested. During cool storage, weight loss increased to about 6% after six weeks at 4°C and additional 5% during 7 days of storage at ambient temperature (20°C). Firmness (acoustic and compression) and other aspects of fruit quality decreased with time. Rate of ripening as measured by the change of internal maturity rating at 20°C increased with time. No significant changes were found in terms of total soluble solids during subsequent shelf life at 20°C for the entire period of storage. ‘Unique’, an early cultivar, generally had a shorter storage life than ‘Opal Star’.\nThe effects of five controlled atmospheres were also studied. Fruit were stored in a matrix of two levels of oxygen (2% and 5%) and two levels of carbon dioxide (0% and 3%), or air control, at 4°C for 10 weeks. Fruit were transferred to ambient temperature (20°C) after storage for 4, 6, 8 and 10 weeks for shelf life assessment for 7 days. For the entire period of storage, fruit weight loss was approximately 1.5-2% of the initial weight. The firmness of the fruit stored under CA conditions decreased regardless of atmospheric conditions. In ‘Opal Star’, fruit underwent a significant colour change from dark to light green after the 10 weeks of storage. However, for ‘Unique’ there was no significant change in colour observed in the period tested. In both cultivars, there was a slight decrease in TSS over time. ‘Opal Star’ showed a good storage life with better fruit acceptability as compared to ‘Unique’. In both cultivars, all the treatments caused some signs of injury after week 6. Generally, CA conditions were effective in reducing weight loss and external injury, and maintaining fruit firmness compared with air. ‘Opal Star’ had a good storage life with over 60% of fruit rated acceptable after 73 days of storage in CA treatments without CO2. Hence ‘Opal Star’ may be suitable for export by sea.\nThe effect of three concentrations of ethylene (10, 100 and 1000 ppm) and one concentration of propylene (1300 ppm) applied for 24 hours on three different stages of maturity of ‘Opal Star’ and ‘Unique’ of feijoa suggests that ‘Unique’ and ‘Opal Star’ do not present typical climacteric activity. Feijoa fruit harvested at different stages of maturity were able to continue the ripening process without any acceleration by ethylene or propylene treatments. Different concentrations of exogenous ethylene or propylene had no effect on fruit firmness and colour changes. This could mean both cultivars are non-climacteric fruit according to the McMurchie et al., (1972) classification. However, this may also indicate that the fruit are already saturated with ethylene at early harvest stage. In ‘Unique’ highest ethylene production rates occur with early season fruit as they soften. Fruit at late harvest seems to be past the climacteric peak. In ‘Opal Star’ highest ethylene production occurred in late season, which may imply that climacteric peak happens at the ripe stage. There was no clear relationship between ethylene production and colour. This study supports the idea that the climacteric and non-climacteric classification is relatively general and unable to take into account the peculiarities of each species.\nIn conclusion, this thesis offers important insights into the regulation of postharvest loss of quality in feijoa. These insights should allow the future development of non-destructive at harvest maturity tests for feijoa. In addition, CA storage conditions are defined that could be used to support sea freight of feijoa to distant markets, although it remains to be seen whether aroma fully recovers after CA.']	['<urn:uuid:06440491-d876-40c2-8a4a-df140cf69587>']	factoid	direct	long-search-query	similar-to-document	single-doc	novice	2025-05-01T23:55:16.606337	10	64	1236
454	sharp flat key signature music theory difference position major keys	A sharp sign placed in front of a note indicates to play the next key to the right, while a flat sign indicates to play the next key to the left. Regarding key signatures, F sharp at the beginning of a piece is the key signature of G Major, while B flat at the beginning is the key signature of F Major. The sharp and flat signs must enclose the individual line or space on the staff.	['The role of rests in Music Theory\nAs we have discussed the note value in time signatures. It is also important for each student to know what does the word rest mean in music theory.\nRests are symbols of silence. You must be aware of the fact that when a song is composed, rests are also mentioned on the grand staff for the musician to read so that he can play in harmony with other musical instruments. Look at the picture below to understand the value of rest.\nNow as a drill, it is recommended that students should draw 4 of each rest. Remember that this drill is very important too.\nCounting and Clapping\n1. Check Time Signature\n2. Set up a steady pulse by counting and tapping the four beats for a full measure before you begin to clap.\n3. The first time you clap, say the name of the note value in the rhythm. The second time count the beats. Remember quarter note gets a clap, the half note gets a clap and a squeeze, the half dotted note gets a clap and two squeezes whereas the full note gets one clap and 3 squeezes. On rests throw your hands open for the correct number of beats.\nThe stems on notes go up on the right or down on the left. Notes that are on the middle line of the staff or above the middle line are stemmed down on the left. Notes that are below the middle line of the staff are stemmed up on the right.\nThe students must draw notes on the staff sheet and stem them according to the instructions given above. First write quarter notes on or above the middle line and stem them, then write half notes and repeat the exercise, also continue this exercise with half dotted notes and whole notes. This exercise will refresh the memories of the students and they will be able to remember the names of the notes in a better way.\nStem whole note. They will become half notes. now change these notes to quarter notes by adding stems and blackening the heads. So it means when note is stemmed its value becomes half.\nSharps and Flats\nSign of Sharp\nSign of Flat\nA sharp sign placed in front of a note tells us to play the very next key to the right. Now draw 8 sharp signs by looking at the pic. The vertical lines for sharps are drawn straight. The cross lines are at an angle. Now write sharp signs on the staff sheet on different lines and spaces to grasp better knowledge. The box of the sharp must enclose the individual line or space. when we see F sharp sign at the beginning of a piece, we call it a Key Signature. F sharp is the Key Signature of G Major.\npic of signature of G Major\nA flat sign placed in front of a note tells us to play the very next key to the left. Now see the pic of Flat and try to draw is yourself. First draw a downward line and then add the head on each Flat. The head of the flat must enclose the individual line or space. When we see a B flat at the beginning of a piece we call it a key signature. B flat is the key signature of F Major.\npic of key signature of F Major']	['<urn:uuid:2ef3bbee-0b9a-47c8-b333-437296fc487a>']	open-ended	with-premise	long-search-query	similar-to-document	single-doc	expert	2025-05-01T23:55:16.606337	10	77	575
455	What's special about a ramen burger?	A ramen burger is a dish created in 2013 in New York that features beef burger patties sandwiched between two ramen 'buns'. The buns are made from fresh noodles that are boiled and pressed into shape. They are then lightly seared with sesame oil, making them crispy on the outside but chewy on the inside.	['Whether you are cooking for yourself at home, or dining out at a Michelin-starred restaurant, it is always exciting to see some innovation in the food that you eat. From beetroot-pickled devilled eggs to French toast waffles, here are 15 deliciously creative dishes to inspire your next meal.\n1. French Toast Waffles\nIt is common knowledge that breakfast is the most important meal of the day, but coming up with new breakfast ideas can be tricky.\nFor those who love French toast, as well as waffles, French toast waffles will be a dream come true.\nA dish that looks like waffles, but tastes like French toast, this is the perfect base onto which you can then get even more creative with toppings.\nReady to get cooking?\nFollow these steps:\n- Preheat your waffle iron\n- Mix together a cup of waffle mix, two teaspoons of sugar, and a pinch of cinnamon\n- Stir in half a cup of milk, two eggs and a splash of vanilla\n- Pour this mix onto your hot waffle iron, and then cook until it is golden brown\n2. The Ramen Burger\nThe ramen burger is a dish that was first conceived in 2013 in New York, so you have likely seen it plastered all over Instagram countless times since then, as it did not take long for the dish to shoot up in popularity.\nThe dish itself is fairly self-explanatory – beef burger patties sandwiched between two ramen “buns”.\nHow does it work?\nFresh noodles are used, and these are boiled before being pressed into buns. They are then lightly seared with sesame oil, so that they are crispy on the outside, but chewy on the inside.\nWant to make this yourself at home?\nDo not be afraid to experiment with this dish, in the same way you would a standard burger dish. Whether you get creative with the fillings or go all out with condiments, the ramen burger is one that is definitely worth trying.\n3. Savory Beignets\nBeignets are a classic sweet treat from New Orleans, but chefs around the world have been turning this sugary pastry into delicious savory dishes.\nFor those of you who would like to try these in New Orleans itself, head to Basin for their crab and crawfish beignets, or to SoBou for their sweet potato beignets.\nAlternatively, you could try making some yourself at home. Here are a few ideas to get you going:\n- Black pepper and Gruyère\n- Rock shrimp and sweetcorn\n- Cheddar and chive\n4. Rolled Ice Cream\nA traditional Thai dessert, rolled ice cream has exploded in popularity recently, and can now be found in ice cream parlours all around the world.\nHere is how it is made:\n- A milk-based ice cream is poured onto a metal plate, which has been frozen\n- Using small paddles, it is kneaded and then spread over the plate, so that it will freeze in an even layer\n- The ice cream is then scraped off the plate in rolls, before being placed into a cup\nWhat about toppings?\nYou could use anything that you desire, from marshmallows to shaved coconut to hot fudge.\n5. Grilled Lamb-Stuffed Pitas\nThis dish featured grilled pita breads that have been stuffed with lamb, and is actually a traditional Lebanese dish. A popular street food that can be found all over the Middle East, the innovation comes from the way in which the meat is cooked from within the pita bread.\nWondering exactly how to make it?\nIt is really quite simple…\nAll you need to do is season some ground lamb and then spread it inside a pita bread. Place this onto a hot grill, and, as the meat cooks, its juices will soak into the bread, turning it crispy.\nIf you decide to give it a go, here are a few tips to keep in mind:\n- Use bread that is as fresh as possible, as older pitas tend to become brittle, making them harder to stuff\n- The traditional seasonings for this dish are cumin, coriander and onion, but you could experiment with other spices, such as cayenne and paprika, and even add in some lemon zest and cilantro to balance everything out\n- Your fire should be medium-hot. If it is too cold, the dish will not cook properly, and if it is too hot, the bread will burn\n- Whip up a yoghurt-tahini sauce to serve alongside this, as the cooling flavors complement the lamb perfectly\n6. The Rainbow Bagel\nWhile the rainbow bagel was first introduced to New York a few years ago, it has only recently begun to make its way around the world, and is now a huge hit in London.\nWondering how the bagels are made?\nThey contain seven different dough mixtures, each of a different color.\nBut what about the taste?\nThey are slightly sweeter than other bagel varieties, but not too much so. There are also different hints of flavor within each color, such as banana in the yellow, strawberry in the red and mango in the orange.\nIn New York, these bagels are commonly eaten with cheese, but, in London, salt beef rainbow bagels are quite a big hit.\n7. Amaranth Patties\nAlso known as Chinese spinach, or as callaloo in Caribbean cuisine, amaranth is a plant that produces thousands of tiny little seeds. These small grains are actually a fantastic source of protein, and can be used in a way similar to quinoa.\nWhile there are so many ways in which you can cook amaranth, turning them into patties is always a good idea, as this is such a versatile dish that can be served in so many different ways.\nSimply boil the amaranth and then mix it with some egg, bread crumbs, parmesan cheese, parsley, garlic and onion, before forming them into patties and then frying on each side.\nYou could serve these up in a salad, or as a burger, for vegetarians, or use them as a side dish to accompany meat in a larger meal.\n8. Spicy Moroccan Carrot Salad\nThe carrot is quite a humble ingredient, and can often be difficult to really elevate.\nHowever, turning them into a spicy Moroccan carrot salad really takes the ingredient to new heights, bringing out bold and exciting flavors.\nCooking the carrots is simple, as all you need to do is blanch them for a few minutes, until they are tender.\nThe innovation comes with the marinade…\nWhile you can use whichever spices you enjoy the most, here are some suggestions:\n- Chilli powder\n- Red pepper flakes\n- Salt and pepper\nMix these together with some vinegar, and then toss the carrots in this, before marinating for a couple of hours. Once it is time to serve them up, top them with some micro greens, and give them an extra season with some sea salt.\n9. Crispy Chicken Skin\nCrispy chicken skin is often used as a bacon substitute by many Jewish communities, and, just like with bacon, the possibilities are endless when it comes to this crunchy snack.\nThere are a number of ways to make this dish, from deep frying to baking, but if you want to taste the very best of the best, here are the restaurants to head to:\n- Cockscomb, San Francisco, California – The crispy chicken skin at Cockscomb is used in their much talked about appetizer, Oeufs Mayonnaise. Consisting of hard boiled eggs with mayo that has been made in-house, the chicken skin accompanies seared foie gras as a decadent topping.\n- Tori Shin, New York City – Tori Shin is known for being one of the best yakitori joints in New York, with one of their dishes being organic chicken skin that has been skewered and then cooked over charcoal.\n- Husk, Charleston, South Carolina – In Charleston, the restaurant Husk puts a special twist on crispy chicken skin, by braising it in buttermilk before frying it. Topped with hot sauce and honey, these skins are still deliciously crunchy, but have a sticky, tangy coating too. 7\n- Slab Sandwiches + Pie, Seattle, Washington – Avocado toast is quite a common dish these days, but Slab Sandwiches + Pie takes theirs to a whole new level, thanks to the addition of crispy chicken skin. Alongside some tomato ginger jam, the chicken skin gives the toast some extra texture, while still managing to allow the meal to be quite healthy.\n10. Plancha-Grilled Seafood\nYou are likely already familiar with grilled seafood dishes, but when they are cooked on a plancha, this gives the ingredients a whole new depth of flavor.\nWondering what a plancha is?\nIt is basically a flat slab of cast iron that works like a griddle, in that you place it onto a grill, and then cook your ingredients on top of this. This makes it perfect for creating more delicate dishes, such as with fish or shrimp, but with an intense taste.\nDoes cooking on a plancha actually make the food taste different?\nMost definitely, yes. Thanks to the plancha, your food will take on quite a different sear and crust, and will still have a smoky flavor from the grill.\nHere’s another advantage…\nSince the plancha does not have slats like a traditional grill, this means that you can smother your ingredients in glazes and sauces, allowing them to soak up these extra flavors and textures while they cook.\n11. Zucchini Carpaccio\nCarpaccio is an Italian dish that usually features thinly sliced raw meat or seafood, from beef and venison to salmon and tuna.\nHowever, this version features thinly sliced fresh zucchini, and is just as satisfying as the meaty versions.\nNever tried raw zucchini before?\nIt has such a fresh, green flavor, which is often lost during the cooking process.\nThis is an easy dish to make, and the dressing can be customized to your own tastes.\nIf you are making this dish for the first time, give this feta, walnut and dill version a try:\n- Slice zucchini thinly, so that they are almost transparent\n- Drizzle with extra virgin olive oil and lemon juice, before seasoning\n- Arrange the slices on a plate so that they are overlapping in a circular shape\n- Top with chunks of feta cheese, walnuts and dill\n12. Crab Fluff\nWhen you are a chef in the city of Baltimore, which is surrounded by the blue crab-filled Chesapeake Bay, it only makes sense to make the most of this versatile ingredient.\nUnlike many other seafood varieties, the blue crab population in the bay is actually increasing, with around 550 million of them in the water last year.\nWhile you will find blue crab featured on many menus around Baltimore, head over to Locust Point Steamers if you want to try one of the most innovative of blue crab dishes.\nNamed crab fluff, this dish consists of a fried crab cake that has been dipped in a batter, which is similar to a funnel cake mixture, before being fried again. This twice-fried, golden brown, beauty is served with crackers and mustard, which really helps to enhance the “fluffiness” of the dish.\n13. Blistered Shishito Peppers\nBlistered shishito peppers is a staple dish at many Japanese joints, but are now starting to make their way onto menus all over the world.\nHow is this done?\nThe peppers are simply cooked over a high heat, until their sides start to blister.\nIf you want to give this a try but cannot find shishito peppers near you, there is no reason as to why you cannot make this dish with other peppers, as each variety will impart its own unique flavor.\nShishito peppers are sweet and spicy, while padron peppers are similar, but spicier. Of course, you could always just use standard sweet peppers, adding in some chilli for some extra heat.\n14. Barbecued Spaghetti\nIf you regularly dine out in Memphis, then you are likely aware of all of the barbecue options available to you.\nHowever, the Bar-B-Q Shop has added their own bit of innovation to the technique, and have come up with a rich, smoky barbecued spaghetti dish.\nHow is this made?\nThe noodles are mixed with a thick base, of which the recipe is closely guarded, before being smoked in a pit for 12 hours, ensuring that the shreds of pork are amongst some of the most tender you will have ever tried.\n15. Cauliflower Steaks with a Cauliflower Purée\nCauliflower steaks really made a name for themselves a couple of years ago, and while you may not think that they are that innovative, this dish, which makes use of the entire cauliflower, really is.\nThe idea arose in New York, thanks to chef Dan Barber, from the nose-to-tail concept, where produce is used in its entirety, with no part going to waste.\nIn this case, the center of the cauliflower is used to make the steaks, which are cooked in a skillet over high heat, until they are golden brown.\nWhen it comes to the individual florets, these are blitzed into a cauliflower purée to accompany the steaks, and seasoned with fresh herbs.']	['<urn:uuid:1e3661f4-cb01-4dc3-ab76-af1810220af4>']	open-ended	with-premise	concise-and-natural	similar-to-document	single-doc	novice	2025-05-01T23:55:16.606337	6	55	2201
459	Do nest associate fish and arctic grayling both migrate for spawning?	Yes, both species migrate for spawning but in different ways. Nest associate fish like Chrosomus oreas migrate to spawn in nests constructed by host species, particularly in rocky streams with unsilted gravel substrate. Arctic grayling migrate in early spring from overwintering habitats to rocky streams with moderate current and gravel substrate for spawning. They gather in large groups to 'run' upstream to these spawning areas.	"['Applying ecological models to positive interactions among lotic fishes: implications for population and community regulation at multiple spatial scales\nPeoples, Brandon Kevin\nMetadataShow full item record\nPositive biotic interactions such as mutualism, commensalism and facilitation are ubiquitous in nature, but historically have received considerably less research attention than negative interactions such as competition, predation and parasitism. The paucity of research on positive interactions is particularly evident in stream ecosystems and in vertebrate communities. Stream fishes clearly provide an ideal system for advancing research on positive interactions. Many minnows (Cyprinidae) of eastern North America engage in a potentially mutualistic reproductive interaction known as nest association, in which individuals of one species (nest associates) spawn in nests constructed by host species. In nest association, hosts provide unsilted gravel substrate for spawning nest associates, and increased parental care to associate broods. High associate: host egg ratios can create a dilution effect, reducing the probability that host eggs will be preyed upon by egg predators. Nest associative interactions are common, but are relatively understudied compared to other interactions among stream fishes. The goals of this study were to apply general ecological models to this novel system to (a) gain new insight into the mechanisms structuring nest associative stream fish communities, and (b) to use inference from stream fish communities to potentially expand and improve the general ecological models. These goals required completion of three objectives, including (1) examining the influence of abiotic and biotic contexts on reproductive behavior and fitness outcomes between a cyprinid host and associate, using the biological markets model to generate predictions; (2) examining the utility of the nest web framework (previously only used for cavity nesting vertebrate communities) and the stress gradient hypothesis (previously applied almost exclusively to plant communities) for predicting which associate species spawn on nests built by various nest building species, and the consequences of these choices, respectively; and (3) using two-species occupancy modeling to determine the relative influence of biotic interactions and habitat covariates on the co-occurrence of a host and two nest associates. To accomplish these goals, I conducted a large-scale experiment to manipulate presence of mutualists (Nocomis leptocephalus, host; Chrosomus oreas, associate), egg predators (biotic context) and habitat quality (abiotic context). I conducted behavioral nest observations and conducted repeated stream fish stream fish community surveys to collect demographic data. I constructed a nest web from observational data, and implemented structural equation modeling through an information-theoretic framework to identify nest web plausibility across a large spatial extent. I tested some predictions of the stress gradient hypothesis by regressing juveniles-per-nest and a metric of cyprinid community structure on a composite measure of physical stress (scaled gradients of catchment-scale agricultural land use and catchment area). I used two-species occupancy modeling to model co-occurrence of N. leptocephalus hosts and two associates, C. oreas and Clinostomus funduloides, and used an information-theoretic framework to compare hypotheses representing the importance of biotic interactions, habitat covariates or both at determining species co-occurrence. Results corroborated some (but not all) model predictions, and identified room for improvement in each of the general models. Nest associative spawning by C. oreas was not context dependent; C. oreas did not spawn in the absence of a reproductively active male N. leptocephalus at any treatment level. However, the net fitness outcome of host and associate species was mutualistic, and the interaction outcome switched from commensalistic to mutualistic with abiotic context. N. leptocephalus reproductive success was improved by C. oreas presence in less-silted habitats, but not in heavily-silted habitats. This is most likely because broods were subject to predation in both habitat types, but were also negatively affected by siltation in silted habitats. Accordingly, egg dilution by associates was not sufficient to support a mutualistic relationship in less favorable habitats. Results suggest that the biological markets model may be a useful tool for predicting fitness outcomes of nest associative mutualism, but may not be as useful for predicting the behavioral outcomes of obligate mutualisms. Future applications of the biological markets model should carefully consider species traits, specifically the degree to which trading behavior is obligate for participants. Future work with this model will yield more insight by considering highly facultative associates. Nest webs constructed from nest observational data suggested an interaction topology in which strong (nearly-obligate) associates relied most frequently on N. leptocephalus nests, and less frequently on nests constructed by Campostoma anomalum. Weak (facultative) associates were seldom associated with nests constructed by either species, and probably spawned before hosts began nesting activity. Structural equation models corroborated this topology throughout the New River basin, although some less-supported model evidence specified some nest association by weak associates. Juveniles-per-nest of strong associates responded positively to physical stress, while this metric for other cyprinid reproductive groups showed no relationship. Proportional representation of Nocomis and strong associates also increased predictably with physical stress. This study suggests that the nest web framework can be informative to systems outside the ones for which it was developed; future studies may be able to use this framework to better understand the role of habitat-modifying species in communities other than cavity nesting terrestrial vertebrates and nest associative stream fishes. This work extended the nest web framework by (a) modeling the outcomes of interactions instead of the interactions themselves, and (b) by using structural equation modeling to test nest web predictions with an information-theoretic framework. This study also suggests that the stress gradient hypothesis can be useful for understanding interaction dynamics in vertebrate communities; this represents the first direct evidence that this model can be used in vertebrate communities. Further, I demonstrate that the stress gradient hypothesis may be extended to predict community structure. However, more research in a diversity of systems will be needed to determine the extent to which this can be applied. This study provides some of the first evidence of large-scale positive co-occurrence patterns in vertebrates. However, the precise roles of habitat covariates and biotic interactions were species-specific. Occupancy results suggest that co-occurrence between N. leptocephalus and nest associate C. funduloides is driven only by reproductive behavioral interactions. Alternatively, evidence suggests that co-occurrence between N. leptocephalus and C. oreas is driven by both nest association and habitat covariates. That two-species occupancy modeling can be a useful tool for comparing difficult-to-test hypotheses involving biotic interactions at large spatial scales. This study represents the first quantitative, multi-scale treatment of positive interactions in stream ecosystems. This study demonstrates that applying general ecological models to stream fish communities can yield new insights about both the study system and the models themselves. While models of negative interactions, food webs and dispersal have been applied to stream fishes, we stand to gain much ground by also considering positive biotic interactions. In doing so, stream fish ecologists will also be able to contribute to the advancement of general ecology, and thus raise awareness for these understudied ecosystems and taxa.\n- Doctoral Dissertations', 'Arctic grayling inhabit a wide geographic area that includes the Arctic and Pacific drainages in Canada, Alaska, and Siberia. Historically, they were found throughout the Arctic as far west as the Kara River in Russia, as far east as the western shores of the Hudson Bay in Canada, and as far south as Michigan. Though they no longer occur naturally in North America apart from Canada and Alaska, the species has been introduced into some lakes of western mountain states such as Arizona and California and the upper Missouri River drainage in Montana. (Sepulveda, et al., 2013; Stamford and Taylor, 2004)\nArctic grayling live in high-elevation, mid to large, cold (8 to 11°C), and clear freshwater lakes and rivers. They are obligate cool or cold water dwelling species. They migrate several times per year. In the early spring, individuals migrate from overwintering habitats to rocky streams for spawning. Individuals then move to summer feeding areas before finding a suitable wintering spot, where they spend 8 to 9 months under ice. Arctic grayling typically overwinter in a lake or sections of a stream that are downstream of feeding areas. Larger fish are usually found in cooler upstream reaches of the river, while juveniles typically live in downstream and lower reaches of rivers. A possible explanation for this pattern is that water downstream is typically warmer than water upstream, helping to speed growth. Another hypothesis is that larger fish that are upstream have a feeding advantage because they have first access to drifting prey. (Baccante, 2011; Hughes and Reynolds, 1994)\nArctic grayling have an elongated, laterally-compressed, and trout-like body. Like many fish in the family Salmonidae, they have short heads, large eyes, small, toothed mouths, and forked tails. Arctic grayling are approximately 15 to 36 cm long, with an average weight of 1 to 2 kg. The largest individual on record was around 76 cm long and 3.8 kg. The dorsal surface of the body is often the darkest, with dark-purple or blue-black to blue-grey coloring. The sides have tiny scales exhibiting a variety of colors, from iridescent gray to light greenish blue. Patterns of numerous V-shaped or diamond-shaped spots are also common. The dorsal fin is sail-like, with as many as 17 to 25 rays, and is sometimes taller than the width of the fish’s body. They are usually marked with black and a narrow, vividly colored band on the top edge with orange to bright green spots on the bottom. The pelvic fins can have bright colors, such as pink or orange stripes. Grayling that live in the clearest waters tend to exhibit brighter colors. There is sexual dimorphism in coloration, with males having more orange, light green, and blue colored scales than females, which have more dull and dark colored scales. (""Arctic Grayling (Thymallus arcticus)"", 2013; ""Arctic Grayling Recovery"", 2012)\nArctic grayling fry hatch 2 to 3 weeks after spawning, and they are approximately 1.3 cm long at hatching. The fry immediately move toward the calm and warm shoreline waters where they will become juveniles at 5 to 10 cm by the end of summer. Fry are miniature versions of adults. They continue to grow quickly and reach maturity in 3 to 4 years. At this point, they begin to grow much more slowly as they dedicate more of their annual energy intake to spawning efforts. The growth rate of arctic grayling is among the fastest for arctic fish in many streams and lakes. Researchers note that grayling embryos and hatchlings are exposed to increasingly colder temperatures as they develop. At these life stages, arctic grayling are exposed to microbial bacteria pathogens that are often temperature and sex-specific and result in behavioral and immunological responses. While this does not directly affect the sex-determination of individuals, studies show that male grayling appear to have a sex-specific behavior or tolerance to warm temperatures that female grayling do not have. (""Arctic Grayling (Thymallus arcticus)"", 2013; Wedekind, et al., 2013)\nArctic grayling spawn in spring in shallow areas of rivers with moderate current as well as a gravel or rocky areas with a substrate composed of fine sand sediments. Spawning in lakes is rare. Arctic grayling alter their behavior to give them better abilities to spawn and reproduce. During mating season, males defend their spawning area for up to 7 days against other males. Females do not exhibit agonistic behavior during this season. During the act of mating, other males will try to beat other males off prospective mates. Females can also just swim off. Males court females by flashing their colorful dorsal fins. These fins are also used to brace receptive females to aid in the mating process. Although they do not excavate a redd (nest) in the substrate, the act of mating kicks up a large amount of substrate that serves as a sort of nest for the eggs. The roe (eggs) are left on the bottom of the streambed to mix with the milt (sperm) released from the males. The female leave and find another prospective male to mate with and leave the zygotes to be covered by the substrate and to survive on their own. However, less than 50% of all spawning attempts are actually completed due to interference by other fish or the female moving away from the male. Arctic grayling are promiscuous, with males mating several times with several females and females mating more than once with several males. (Kratt and Smith, 1980)\nArctic grayling, like most other fish, are oviparous and they lay eggs in the spring, when ice begins to break up. Depending on the size of the female, she may lay between 1,500 and 30,000 eggs, each around 2.5 mm in diameter. The eggs sink to the bottom and become lodged between pebbles and gravel. Only about 10% of the fry that hatch from the eggs will reach adulthood and be able to spawn. When spring approaches, arctic grayling gather in large groups to ""run"" upstream to spawning areas. (""Arctic Grayling (Thymallus arcticus)"", 2013; Kratt and Smith, 1980)\nThe lifespan of arctic grayling is usually around 18 years for both males and females. However, individuals in Alaska have been known to live up to 32 years. Most mortality occurs in eggs, larvae, and fingerlings or in areas where these fish are heavily fished. (""Arctic Grayling (Thymallus arcticus)"", 2013; ""Arctic Grayling Recovery"", 2012)\nMuch of arctic grayling behavior revolves around strategies that aid survival in the harsh, uncertain environment of the Arctic. One strategy is migration for food and spawning. Individuals can use different streams for spawning, development, overwintering, and summer feeding, although some individuals spend their entire life within a single section of a stream or lake. They are active during the day. (Davis, et al., 2010; Gingerich, et al., 2010)\nArctic grayling may move tens of miles on a seasonal or annual basis between spawning, feeding, and sheltering habitats. Some arctic grayling have been known to travel more than 160 km (100 miles) in one year. (Davis, et al., 2010; Gingerich, et al., 2010)\nThere is no research on communication and perception in arctic grayling, but it is assumed they have sensory perception similar to other freshwater fish, including chemoreception and the lateral line system. One form of perception is through chemoreceptors that can respond to chemical stimuli in the water and act a sense of taste and smell. Another form of perception is the lateral line system. This system is common in fish and detects the motion of other fish and prey through changes in current and vibration that are caused by the other organisms. They are visual predators, reacting to visual cues to detect and attack prey. (Bleckmann and Zelick, 2009)\nDuring the brief northern summers, arctic grayling eat drifting aquatic insects, such as black flies (Simuliidae), mayflies (Ephemeroptera), stoneflies (Plecoptera), and caddisflies (Trichoptera). At times, grayling gorge upon the eggs of spawning salmon, smaller fish, or terrestrial insects that have fallen into the water. They may even eat an occasional vole, lemming, or shrew. Young arctic grayling feed on zooplankton and eventually transition to feeding on insect larvae. (""Arctic Grayling Recovery"", 2012; Davis, et al., 2010)\nPredators of arctic grayling include other fish (pike and trout), predatory birds (eagles and osprey), and mammals (otters and mink). (""Arctic Grayling (Thymallus arcticus)"", 2013; Sepulveda, et al., 2013)\nArctic grayling are one of the top predators in their aquatic habitats. They prey on a wide variety of insects, fish and other small animals. They are also hosts to protozoan and metazoan parasites such as Cystidicoloides tenuissima and Pomphorhynchus bulbocoli. (Arai and Mudry, 1983; Davis, et al., 2010; Muzzall, 1990)\nArctic grayling are raised commercially for food and fished for sport. (""Arctic Grayling (Thymallus arcticus)"", 2013)\nThere are no known adverse effects of arctic grayling on humans.\nWhile arctic grayling are not currently considered endangered, they are sensitive to pollution in the areas they live and pollution can cause local extirpations. They are most vulnerable to overfishing, competition, road culverts, mining, agriculture, and destructive forestry practices. Recent findings indicate that populations of arctic grayling in North America have been steadily declining and the species is listed as a candidate for “species of concern” status and may warrant protection under the Endangered Species Act. (""Arctic Grayling (Thymallus arcticus)"", 2013)\nMichael Hsieh (author), The College of New Jersey, Keith Pecor (editor), The College of New Jersey.\nliving in the Nearctic biogeographic province, the northern part of the New World. This includes Greenland, the Canadian Arctic islands, and all of the North American as far south as the highlands of central Mexico.\nliving in the northern part of the Old World. In otherwords, Europe and Asia and northern Africa.\nhaving body symmetry such that the animal can be divided in one plane into two mirror-image halves. Animals with bilateral symmetry have dorsal and ventral sides, as well as anterior and posterior ends. Synapomorphy of the Bilateria.\nan animal that mainly eats meat\nuses smells or other chemicals to communicate\nhaving markings, coloration, shapes, or other features that cause an animal to be camouflaged in its natural environment; being difficult to see or otherwise detect.\nanimals which must use heat acquired from the environment and behavioral adaptations to regulate body temperature\nfertilization takes place outside the female\'s body\nunion of egg and spermatozoan\nA substance that provides both nutrients and energy to a living thing.\nmainly lives in water that is not salty.\nhaving a body temperature that fluctuates with that of the immediate environment; having no mechanism or a poorly developed mechanism for regulating internal body temperature.\na distribution that more or less circles the Arctic, so occurring in both the Nearctic and Palearctic biogeographic regions.\nFound in northern North America and northern Europe or Asia.\nAn animal that eats mainly insects or spiders.\nreferring to animal species that have been transported to and established populations in regions outside of their natural range, usually through human action.\noffspring are produced in more than one group (litters, clutches, etc.) and across multiple seasons (or other periods hospitable to reproduction). Iteroparous animals must, by definition, survive over multiple seasons (or periodic condition changes).\nmakes seasonal movements between breeding and wintering grounds\nhaving the capacity to move from one place to another.\nspecialized for swimming\nthe area in which the animal is naturally found, the region in which it is endemic.\nreproduction in which eggs are released by the female; development of offspring occurs outside the mother\'s body.\nthe regions of the earth that surround the north and south poles, from the north pole to 60 degrees north and from the south pole to 60 degrees south.\nthe kind of polygamy in which a female pairs with several males, each of which also pairs with several different females.\nbreeding is confined to a particular season\nremains in the same area\nreproduction that includes combining the genetic contribution of two individuals, a male and a female\nuses touch to communicate\nuses sight to communicate\nanimal constituent of plankton; mainly small crustaceans and fish larvae. (Compare to phytoplankton.)\nAlaska Department of Fish and Game. Arctic Grayling (Thymallus arcticus). Anchorage, Alaska: Alaska Department of Fish and Game. 2013. Accessed October 15, 2013 at http://www.adfg.alaska.gov/index.cfm?adfg=arcticgrayling.main.\nUS Fish & Wildlife Service. Arctic Grayling Recovery. Washington, DC: US Fish & Wildlife Service. 2012. Accessed October 15, 2013 at http://www.fws.gov/redrocks/arcticgrayling/.\nArai, H., D. Mudry. 1983. Protozoan and metzoan parasites of fishes from the headwaters of the Parsnip and McGregor Rivers, British Columbia: a study of possible parasite transfaunations. Canadian Journal of Fisheries and Aquatic Sciences, 40: 1676-1684.\nBaccante, D. 2011. Further evidence of size gradients of arctic grayling (Thymallus arcticus) along stream length. Journal of Ecosystems and Management, 11: 13-17.\nBleckmann, H., R. Zelick. 2009. Lateral line system of fish. Integrative Zoology, 4: 13-25.\nDavis, J., A. Rosemond, S. Eggert, W. Cross, J. Wallace. 2010. Long-term nutrient enrichment decouples predator and prey production. Proceedings of the National Academy of Sciences, 107: 1210126.\nGingerich, A., D. Philipp, C. Suski. 2010. Effects of nutritional status on metabolic rate, exercise and recovery in a freshwater fish. Journal of Comparative Physiology B, 180: 371-384.\nHughes, N., J. Reynolds. 1994. Why do arctic grayling (Thymallus arcticus) get bigger as you go upstream?. Canadian Journal of Fisheries and Aquatic Systems, 51: 2154-2163.\nKratt, L., R. Smith. 1980. The analysis of the spawning behaviour of the arctic grayling Thymallus arcticus (Pallas) with observations on mating success. Journal of Fish Biology, 17: 661-666.\nMiano, A. 2013. Lake Trout (Salvelinus namaycush) and Arctic Grayling (Thymallus arcticus) Diet, Population and Migration Dynamics in Arctic Ecosystems. Biology Honors Paper at Connecticut College.\nMuzzall, P. 1990. Parasites of arctic grayling, Thymallus arcticus (Pallas), stocked into Michigan lakes. Canadian Journal of Zoology, 68: 596-599.\nSepulveda, A., D. Rutz, S. Ivey, K. Dunker, J. Gross. 2013. Introduced northern pike predation on salmonids in southcentral Alaska. Ecology of Freshwater Fish, 22: 268-279.\nStamford, M., E. Taylor. 2004. Phylogeographical lineages of arctic grayling (Thymallus arcticus) in North America: divergence, origins and affinities with Eurasian Thymallus. Molecular Ecology, 13: 1533-1549.\nWedekind, C., G. Evanno, T. Szekely, M. Pompini, O. Darbellat, J. Guthruf. 2013. Persistent unequal sex ratio in a population of grayling (Salmonidae) and possible role of temperature increase. Conservation Biology, 27: 229-234.']"	['<urn:uuid:1a20acaa-2f58-4921-912c-9e58e24d8c2d>', '<urn:uuid:b595a842-3459-4390-8fe0-a6d56410cd99>']	open-ended	direct	concise-and-natural	similar-to-document	comparison	novice	2025-05-01T23:55:16.606337	11	65	3509
464	how did gunpowder spread from china west	Gunpowder technology spread from China when the Mongols acquired fire-lance technology by 1233 CE during their invasion of the Jin Dynasty. It later reached Europe during the Mongol invasion of 1200-1300 AD, and was first described in Europe by Friar Roger Bacon in the 13th Century. As late as 1500 CE, European travelers were still amazed by Chinese fireworks displays.	"['Oh, why do the myriad stars fall like rain when there is no wind to blow?\nThey are the fireworks that have burst in the sky.\nOh, what thunders are those we hear on the earth when the sky is clear?\nThey are shouts of joy and revelry of the people gathered here.\nThe Story of Yone Noguchi (Yone Noguchi, Japan, 1914)\nGunpowder evolves in China\nGunpowder would take hundreds of years to evolve into its final form. However, Chinese alchemists would use proto-gunpowder, the precursor to actual Chinese gunpowder, in many ways. The most recognizable use to which early gunpowder was put was in fireworks. The earliest accounts of fireworks dates 250 BCE when it is recorded that the alchemist Ma Jun filled bamboo tubes with an explosive substance. When the stalks were lighted, they would produce a violent and exciting explosion. By 1232 CE, Chinese were using explosive missiles, or war rockets, for military purposes. These devices were either launched from mechanical devices or dropped from fortress walls on attackers. By the end of the thirteenth century, the Chinese had begun to develop early rifle-like devices. These were often fashioned out of bamboo stalks. All of these weapons were in early stages of development, but one weapon had been used for hundreds of years before this: the fire-lance.\nChinese create the fire-lance\nThe fire-lance weapon was constructed around a common pike. Attached to the end, however, was a cylinder that would shoot flame towards the attacking enemy. This was a very effective weapon that could keep an enemy at arm\'s length. The fire-lance itself would also evolve. It was eventually used not just as a hand held flame thrower but as an early rifle that could fire projectiles from the cylinder. In reality, it was not really a rifle because the projectiles did not fit the chamber. Yet this weapon could be used to spray shrapnel at the enemy, causing damage to a larger number of attackers.\nAs you can see from the tenth century Buddhist painting at left, there is clear evidence that fire lances and even early grenades were being employed fairly early. In the painting, the Buddha is being attacked by demons of the evil goddess Mara the Temptress, who is trying to distract the Buddha from attaining enlightenment. This image indicates that Chinese alchemists had created a proto-gunpowder that was powerful enough to be used in such weapons by the time of this print. The Chinese, as masters of invention, found many uses for gunpowder, such as cannons, mortars, and multi-stage rockets.\nThe secret of gunpowder begins to spread\nNo matter how hard Chinese military leaders may have tried to keep the secret of gunpowder to themselves, they could not prevent this technology from being transmitted beyond China. For example, in India, where early alchemy was quite limited, fireworks began to be used in religious ceremonies.\nClear evidence of the movement of this technology is seen in the history of the Jin Dynasty (1115 1234 CE). This dynasty was destroyed in 1234 CE by Mongol invaders. During a night raid in the year 1233, Mongols invaders used fire-lances to make their way into the city. Eventually they were defeated by Chinese warriors also using fire-lances. What is important here is that the Mongols had received this technology by 1233. Fire-lance technology had therefore migrated out of China into the hands of non-Chinese peoples. Still it would take many more years for this technology to spread to the other side of the Eurasian continent. As late as 1500 CE, European travelers would write amazed reports of displays of Chinese fireworks and pyrotechnics that dwarfed displays they had seen in Asia.\nGunpowder Index Page The Islamic ""Discovery"" of Gunpowder', ""1. Paper would change the world forever\nPaper is possibly one of the most important inventions of all time. Records show that paper existed in China as early as 105 AD.\nHowever, it wasn't widely adopted until one eunuch, Cai Lun, made significant improvements to the papermaking process. He also drove its widespread adoption throughout China.\nThe technology would later spread to Europe via the famous Silk Road. Its development would have enormous ramifications for the recording and spread of information.\nThis, in no small part, would have a consequential effect on later technological innovations.\n2. Gunpowder had an explosive effect on humanity\nAnother incredibly crucial Chinese invention was the development of gunpowder. Interestingly, it was discovered completely by mistake in, or around, 1000 AD.\nChinese inventors were attempting to develop an elixir for eternal life. The result, as it turned out, would be a substance that would prematurely end countless lives throughout history.\nLike other Chinese inventions, it was eventually introduced to Europe sometime later. It is widely believed this occurred with the Mongol invasion of 1200-1300 AD.\nWhatever the case, it was first described in Europe in the works of Friar Roger Bacon in the 13th Century.\nWhilst the Chinese tended to use it for more benign applications like fireworks; the Europeans soon realized its deadly battlefield potential. But that's not to say they didn't also recognize its potential for war.\n3. The crossbow was another revolutionary Chinese invention\nThe crossbow is symbolic of battlefields of the middle ages. But they were actually a Chinese invention from almost 2.5 millennia ago.\nAccording to historical records, the crossbow was in widespread use in China by 500 BC. Other records seem to indicate the technology could actually date to around 700 BC.\nSome other archaeological finds could push the crossbow's invention to as early as 2000 BC. Whatever the case, its invention would have an enormous impact on warfare forever.\nMost early evidence for them consists of the metal triggers and bolts - usually made of bronze. Repeating crossbows also became common in China are the 4th Century BC.\n4. Sericulture was closely guarded secret for millennia\nThe production of silk, called sericulture, was a very early Chinese invention. Evidence points to the fact that the Chinese were harvesting silk as early as 6,000 years ago.\nSilk cocoons have been found cut in half that date to between 4,000 and 3,000 BC. Yet other finds from ancient tombs show silk production may even stretch back as far as 8,500 BC.\nWhenever it was first developed, the Chinese would master the technique very early on and kept the secrets of weaving silk a closely guarded secret for many centuries.\nIt became something of a hotly desired commodity, and European merchants would often pay its weight in gold to get their hands on this material.\nIt would become one of China's most important exports that would lead to the formation of the now famous Silk Road.\n5. The Abacus was groundbreaking\nThe Abacus is thought to have been developed by the Chinese in around 500 BC. It should also be noted that other historical records seem to show that another form of Abacus might have been developed by the Sumerians a lot earlier in 2,700 BC.\nAbaci are also mentioned in later Roman texts, Egyptian hieroglyphics and as Greek artifacts from around 300 BC. Whatever the case, the technology would become perfected by around the 1300s and is largely unchanged today.\nThe device's simplicity and utility would allow it to stand the test of time. They are still commonly used today in many cultures around the world.\nIn fact, many attest to their superiority over modern digital calculators - at least for simple calculations.\n6. You might have to thank the Chinese for booze too\nFairly recent uncovered archaeological evidence seems to indicate we have the Chinese to thank for alcohol too. 9000-year-old pottery shards were found in the Henan province of China, that show evidence of alcoholic contents.\nIf true, this would push its development almost 1,000 years before the inhabitants of the Arabian peninsula who were thought to be the first brewers for many years.\nOutside of China, alcoholic beverages and fermentation, have been discovered in Georgia (dating to around 6,000 BC), ancient Egypt (3150 BC) and Babylon (3000 BC). Whether these were independent discoveries is unknown, but it wouldn't be out of the realm of possibility that the secret was passed from East to West.\nAnother discovery, in 1970, in the Pingshan County of Hebei Province, unearthed large amounts of wine-storing and drinking vessels. Two of these appeared to have also contained a drink made from wheat dating to around 2,280 BC.\nThis might well be the oldest liquor yet discovered in history.\n7. China and tea are intimately entwined\nTea is practically synonymous with China. According to ancient Chinese legend, tea was first discovered by Shennong in 2,737 BC.\nTea would become incredibly popular during the Tang Dynasty between 618 and 907 AD. It was enjoyed by all members of society.\nThe tea plant is actually indigenous to the Chinese region of Yunnan. The world's oldest living tea plant can be found in the Lin Cang in China. This plant is truly ancient and has been dated to be around 3,200 years old.\nTea would be a closely guarded commodity for the Chinese for many centuries. It would later become popular around the world and would even inspire the British Empire to go to war over tea-trade deficits.\n8. You can thank the Chinese for the compass\nThe very first compasses ever discovered date to the Han dynasty of China, around 206 BC–220 AD. These early compasses were made from lodestone which is a naturally magnetized iron ore.\nThese devices were later used for navigation during the 11th Century Song Dynasty. Lodestone was replaced with iron needles that were magnetized by striking with some lodestone.\nAs with other Chinese inventions, the compass would later be adopted by other cultures as they made contact via trade. Compasses began to appear in Europe and the Middle East around 1300 AD.\nThe compass would drastically improve sea trade and was a prerequisite to the later Age of Discovery.\n9. Moveable type and printing was a Chinese thing\nOne of the most important inventions of all time was the development of print. The earliest example comes from a Tang tomb near Xi'an in China.\nThis delicate manuscript consisted of a woodblock printing on a piece of hemp paper that dates to around 650 to 670 AD.\nThe movable type would also appear in China sometime around 1088 AD. Shen Kuo, a Chinese polymath, would describe the process in his Dream Pool Essays in which he attributed the technique to little-known artisan called Bi Sheng.\nIt would be another four centuries before the technology would be introduced to Europe thanks to one Johannes Gutenberg. It would literally transform the balance of power and control of information forever.\n10. Porcelain was mastered by the Chinese\nPorcelain, or vitrified, translucent ceramics, first appeared in China during the Tang Dynasty. Early examples date to around the start of this period of Chinese history in the 7th Century.\nWhilst glazed ceramics had existed before this time; the technique reached maturity during this period. During the later Song Dynasty (960 to 1279 AD) the technique of creating porcelain reached its peak.\nPieces from this time are exquisite in their fine detail and delicate shapes. Chinese porcelain was highly prized in the world and many artworks had been introduced to the West through the Silk Road.\n11. China might have been using umbrellas for almost two millennia\nAccording to existing historical records, the first reference to a collapsible umbrella dates to around 21 AD. This particular umbrella was apparently developed for a ceremonial four-wheeled carriage of the period.\nAn actual example of one has also been uncovered from the 1st Century in the tomb of Wang Guang.\nThere might even be earlier evidence of them from 2,400-years-ago. Legend has it one Lu Ban, a Chinese carpenter, and inventor developed the umbrella after watching children using lotus leaves as a rain shelter.\nMore reliable evidence does seem to indicate that umbrellas could have been developed during the 6th Century Zhou Dynasty. Bronze castings have complex bronze socketing hinges with locking sides and bolts.\nIt is believed that these mechanisms were used to hold parasols and umbrellas.""]"	['<urn:uuid:04a86620-db90-4165-bb4f-68fbf60ca490>', '<urn:uuid:7a6e6a52-6aeb-47eb-88e7-6cd9249d3ed9>']	factoid	direct	short-search-query	similar-to-document	three-doc	expert	2025-05-01T23:55:16.606337	7	60	2029
466	da vinci studies anatomy science inventions	Da Vinci conducted extensive anatomical studies in the 1480s, creating detailed drawings of human and animal bodies, including fetus development, heart and vascular systems. He also studied various scientific fields including botany, geology, zoology, hydraulics, aeronautics, and physics. His innovative designs included concepts for flying machines inspired by bat physiology, helicopters with aerial screw mechanisms, and various other inventions that can now be seen as life-size models at Château du Clos Lucé, such as the ornithopter with its 12-meter wingspan and the portable revolving bridge.	['Leonardo Da Vinci is arguably history’s greatest multi-tasker. Possessor of a curious mind and keen intellect, Da Vinci studied the laws of science and nature, which greatly informed his work as a painter, sculptor, architect, inventor, military engineer and draftsman.\nYoung Leonardo received little formal education beyond basic reading, writing and mathematics instruction, but his artistic talents were evident from an early age. Around the age of 14, da Vinci began a lengthy apprenticeship with the noted artist Andrea del Verrocchio in Florence. He learned a wide breadth of technical skills including metalworking, leather arts, carpentry, drawing, painting and sculpting. It is thought that Verrocchio was so humbled by the superior talent of his pupil that he never picked up a paintbrush again.\nIn 1482, Florentine ruler Lorenzo de’ Medici commissioned Da Vinci to create a silver lyre and bring it as a peace gesture to Ludovico Sforza, who ruled Milan as its regent. After doing so, Da Vinci lobbied Ludovico for a job and sent the future Duke of Milan a letter that barely mentioned his considerable talents as an artist and instead touted his more marketable skills as a military engineer. Using his inventive mind, Da Vinci sketched war machines such as a war chariot with scythe blades mounted on the sides, an armored tank propelled by two men cranking a shaft and even an enormous crossbow that required a small army of men to operate. The letter worked, and Ludovico brought Da Vinci to Milan for a tenure that would last 17 years.\nDa Vinci began to seriously study anatomy and dissect human and animal bodies during the 1480s. His drawings of a fetus in utero, the heart and vascular system, sex organs and other bone and muscular structures are some of the first on human record. In addition to his anatomical investigations, Da Vinci studied botany, geology, zoology, hydraulics, aeronautics and physics. He filled dozens of notebooks with finely drawn illustrations and scientific observations. A man ahead of his time, da Vinci appeared to prophesize the future with his sketches of machines resembling a bicycle, helicopter and a flying machine based on the physiology of a bat.\nAround 1495, Ludovico commissioned Da Vinci to paint “The Last Supper” on the back wall of the dining hall inside the monastery of Milan’s Santa Maria delle Grazie. The masterpiece, which took approximately three years to complete, captures the drama of the moment when Jesus informs the Twelve Apostles gathered for Passover dinner that one of them would soon betray him.\nAfter brief stays in Mantua and Venice, Da Vinci returned to Florence. In 1502 and 1503, he briefly worked as a military engineer for Cesare Borgia, the illegitimate son of Pope Alexander VI and commander of the papal army. He traveled outside of Florence to survey military construction projects and sketch city plans and topographical maps. He designed plans to divert the Arno River away from rival Pisa in order to deny its wartime enemy access to the sea.\nDa Vinci started working in 1503 on what would become his most well known painting—and arguably the most famous painting in the world—the “Mona Lisa.” The privately commissioned work is characterized by the enigmatic smile of the woman in the half-portrait.\nDa Vinci moved to Rome in 1513. Giuliano de’ Medici, brother of newly installed Pope Leo X and son of his former patron, gave Da Vinci a monthly stipend along with a suite of rooms at his residence inside the Vatican. His new patron, however, also gave Da Vinci little work. Lacking large commissions, he devoted most of his time in Rome to mathematical studies and scientific exploration.\nAfter being present at a 1515 meeting between France’s King Francis I and Pope Leo X in Bologna, the new French monarch offered Da Vinci the title “Premier Painter and Engineer and Architect to the King.” Da Vinci did little painting during his time in France. One of his last commissioned works was a mechanical lion that could walk and open its chest to reveal a bouquet of lilies. He continued work on his scientific studies until his death at the age of 67 on May 2, 1519.', '[This post was originally published in 2016.]\nA visit to the Loire Valley is not complete without seeing Leonardo da Vinci’s inventions at Château du Clos Lucé, especially in 2019. May 2, 2019, is the 500th anniversary of da Vinci’s death in Amboise.\nLeonardo da Vinci (1452-1519)\nLeonardo da Vinci was quite simply a genius. While the Mona Lisa and the Last Supper are perhaps da Vinci’s most famous works, he was more than just a painter. He was also a sculptor, inventor, engineer, and visionary.\nLeonardo da Vinci was born in Italy in 1452 and was exposed to the arts early in his life, as an apprentice to artist Andrea di Cione.\nAs a young man, he was commissioned to do paintings in Italy and eventually expanded his work into the areas of engineering and architecture. His interest in and study of the sciences covered geology, anatomy, astronomy, mathematics, and cartography.\nLeonardo da Vinci’s Home In France\nWhile most people think of Italy as the home of Leonardo da Vinci, many do not realize that he lived in the Loire Valley at Château de Cloux, now known as Château du Clos Lucé. He lived there beginning in 1516 after being invited by the King of France and worked there until his death on May 2, 1519.\nHe was initially buried in Amboise at the Chapel of St. Florentin; however, the chapel was demolished during the French Revolution. In the 1800s, bones supposedly belonging to Leonardo da Vinci were discovered and they were buried at Chapelle Saint-Hubert. This is a tiny chapel located on the grounds of Château d’Amboise and a beautiful tribute to da Vinci. The interior is particularly striking when the stained glass is reflected on the tomb’s plaque.\nChâteau du Clos Lucé in Amboise\nIt is at Clos Lucé, also known as the Leonardo da Vinci Museum, where you will really discover the genius. I visited Château du Clos Lucé on a beautiful spring day and did not spend a lot of time in the Château (built in 1471).\nI found being outside, walking amongst the recreated inventions, most enjoyable. Leonardo da Vinci is seen as the inventor who conceptualized the flying machine, the parachute, and various weapons, like the tank and the catapult.\nLeonardo da Vinci’s Inventions at Château du Clos Lucé\nAt the Château you can see 20 life-size models which have been scattered throughout the gardens and park. His work and inventions are certainly brought to life in an open-air museum. Children will find the park interesting as many of the inventions are interactive. Here are some highlights:\nYes, this is a tank, like the kind used in modern-day wars, just not quite the tank as we know it today. There were openings on all sides and it was mobile. Leonardo da Vinci was known as a military engineer and he also had some of the first designs for machine guns and catapults.\nLeonardo’s study of birds inspired him to create many flying-related machine designs including human-powered ones like the ornithopter. This machine theoretically achieves flight by the flapping of wings. Sadly the machine did not work but certainly was the precursor to our modern day airplane.\nThis model’s wingspan is 12 meters wide.\nThe military loved da Vinci’s invention of the portable or revolving bridge. Think of it as a temporary bridge that can be easily moved on wheels to different parts of a body of water like a stream. It would allow soldiers to easily cross over to the other side.\nda Vinci’s designs from 1480 proposed an ariel screw-shaped device with blades that would rotate fast enough to lift the device off the ground. A technically sound version and modern-day design was the helicopter and it wasn’t developed until the early 1900s.\nLeonardo invented the paddle wheel and it was used on boats for centuries until propellers took over. Fortunately, large paddle steamers or riverboats still exist around the world, especially in Switzerland. Smaller versions, called pedalos or paddle boats are used for recreational purposes where two people use their feet to turn the paddle wheels.\nReproductions of da Vinci’s Paintings On Canvas\nThroughout the grounds are large reproductions of Leonardo da Vinci’s paintings and they have added a sense of design to the park.\nInside The Chateau\nDon’t forget to visit inside the chateau where you will see his bedchamber (with a reproduction of the Mona Lisa), the large salons and the kitchen, located in the basement. The basement also houses many of his drawings and models of his inventions that you saw outside.\nApp: Château du Clos Lucé has a free, informative app in English and French that gives information about the artist and château and animated examples of some of Vinci’s inventions.\nLocation: Chateau du Clos Lucé is located just 500 meters from Château d’Amboise in the town of Amboise. So if you are visiting the town’s chateau, be sure to visit Clos Lucé.\nIf you want to learn more about traveling in the Loire Valley, check out these posts:\n- Some Truly Unique Chateaux In The Loire Valley\n- So Many Loire Valley Chateaux To See In A Week\n- Fly In A Hot Air Balloon In The Loire Valley\nPin to your favorite board on Pinterest']	['<urn:uuid:bed75671-9195-4387-9605-1c3b44c33308>', '<urn:uuid:27d6a09e-7028-4d34-bd6a-248f4a6705b6>']	open-ended	direct	short-search-query	similar-to-document	multi-aspect	expert	2025-05-01T23:55:16.606337	6	85	1578
469	What type of equations model the flow of funds?	The flow of funds is modeled using a system of differential balance equations with unit impulse function in the right-hand side.	"[""Development of an analytical method for economic characteristics variation in an innovation process is a challenging task, starting from invention or entrepreneur idea and finishing with market implementation. The practical purpose here is both to minimize the risks and shorten design and implementation time. Theoretical and experimental results presented in the paper show the possibility to solve the mentioned task via applying a non-autonomous differential equation system along with the Lyapunov's First Method for stability analysis. A mathematical model of flow of funds related to the manufacturing and market implementation of the engineering innovation has been studied. It is presented in the form of the system of differential balance equations with unit impulse function in the right-hand side. An algorithm has been developed to analyze the stability of the equilibrium states of the manufacturing process, considering the influence of the external environment “from the right” (preparation of manufacturing) as well as “from the left” (market state). The requirements are determined regarding both the discrete model of manufacturing preparation to formulate initial conditions for the non-autonomous system and the discrete model of the market to calculate the market state dependent coefficients for the system of differential equations. The results of analysis of the economic characteristics variation in the stage of product manufacturing have been presented as 3D phase images.\nOslo Manual 2018: Guidelines for Collecting, Reporting and Using Data on Innovation, 4th Edition. Paris/Eurostat, Luxembourg, OECD Publ., 2018, 258 p.\nSilkina G.Yu. Natural science categories in modelling the diffusion of innovations. Bulletin of South Ural State University. Series. Economics and Management, 2013, vol.7, no.2, pp.95–103.\nMakarov V.L. Overview of mathematical models of economy with innovation. Economics and Mathematical Methods, 2009, vol.45, no.1, pp.3–14.\nBilal Nawaf Elian Suleiman. Matematicheskoe modelirovanie innovacionnyh processov na osnove avtonomnyh dinamicheskih sistem: dissertaciya na soiskanie uchenoj stepeni kandidata fiziko-matematicheskih nauk [Mathematical modeling of innovative processes based on autonomous dynamic systems: dissertation for the degree of Candidate of Physical and Mathematical Sciences]. Belgorod State University. Belgorod, 2012, 181 p.\nBelov V.F., Gavryushin S.S., Markova Y.N. A mathematical model of distributed prototype design in mechanical engineering. BMSTU Journal of Mechanical Engineering, 2019, no.9, pp.7–19.\nKalitin B.S. Ustojchivost' neavtonomnyh differencial'nyh uravnenij [Stability of non-autonomous differential equations]. Minsk, BSU Publ., 2013, 227 p.\nKalitin B. S., Chabour R. Ob ustojchivosti diskretnyh neavtonomnyh sistem [On the stability of discrete non-autonomous systems]. XII vserossijskoe soveshchanie po problemam upravleniya VSPU–2014. Institut problem upravleniya im. V.A. Trapeznikova RAN [The XII All-Russian meeting on the problems of VSPU management–2014. V.A. Trapeznikov Institute of Management Problems of the Russian Academy of Sciences], Moscow, 2014, pp.868–881.\nDemidovich B.P., Modenov V.P. Differencial'nye uravneniya [Differential equations]. St. Petersburg, Lan' Publ., 2008, 288 p.\nIl'ichev V.G. Local and global properties of nonautonomous dynamical systems and their application to competition models. Siberian Mathematical Journal, vol.44, no.3, pp.490–499.\nLasunsky A.V. Methods of investigating the stability of equilibrium positions in the nonautonomous systems, and some applications theirof. Transactions of Karelian Research Centre of Russian Academy of Science. Mathematical Modeling and Information Technologies, 2011, no.5, pp.38–44.\nAleksandrov A.Yu., Kosov A.A. Stability analysis of equilibrium positions of nonlinear mechanical systems by means of decomposition. Vestnik of Saint Petersburg University. Applied mathematics. Computer science. Control processes, 2009, no.1, pp.143–154.\nAleksandrov A.Y., Kosov A.A. Stability and stabilization of equilibrium positions of nonlinear nonautonomous mechanical systems. Journal of Computer and Systems Sciences International, 2009, vol.48, no.4, pp.511–520.\nRatnadip Adhikari. A Treatise on stability of autonomous and non-autonomous systems: theory and illustrative practical applications paperback. Saarbruecken, LAP LAMBERT Academic Publ., 2013, 84 p.\nZhabko A.P., Kotina E.D., Chizhova O.N. Differencial'nye uravneniya i ustojchivost' [Differential equations and stability]. St. Petersburg, Lan' Publ., 2015, 320 p.\nKurakin L.G., Ostrovskaya I.V. Elementy teorii ustojchivosti [Elements of the stability theory]. Rostov-on-Don, Southern Federal University Publ., 2016, 60 p.\nБелов В.Ф., Гаврюшин С.С., Маркова Ю.Н. Неавтономная система как модель процесса производства технической инновации. Математическое моделирование и численные методы, 2021, № 1, с. 110–131.\nКоличество скачиваний: 123""]"	['<urn:uuid:3c4317b6-448b-40fd-a956-557d0b700990>']	factoid	direct	concise-and-natural	similar-to-document	single-doc	expert	2025-05-01T23:55:16.606337	9	21	651
474	I'm interested in watches with art pieces inside them. Can you tell me what the Art Piece 1 watch looks like and what rights would the building owner have if this art was painted on their wall instead?	The Art Piece 1 watch features a 30-degree double tourbillon and a microsculpture viewable through a 23x magnifier at 9 o'clock. It has a blue dial, a 72-hour power reserve indicator at 4 o'clock, and time display that only appears when needed. For the microsculpture example, it contains a three-mast galleon sailing across a blue support. If this art was on a building wall, the building owner would own the physical artwork but not the copyright - they could sell the wall containing the art or even cut it out, but they couldn't make t-shirts, mugs, or use the design in advertising without the artist's permission, as these would constitute unlawful derivative works.	"['As if the superlative multi-tourbillon watches that Robert Greubel and Stephen Forsey typically produce weren\'t enough, the pair have teamed up with artist Willard Wigan to create Art Piece 1. The watch houses both a Greubel Forsey 30 degree double-tourbillon and a Wigan microsculpture that you can admire through a magnifier in the crown at 9 o\'clock. Sometimes we talk about timepieces being works of art, but the Art Piece 1 pushes this to a whole new level. Click through for a full explanation and tons of hands-on photos.\nBritish artist Willard Wigan might not be a household name, but in the art world he is something of a legend and he was presented a knighthood by Prince Charles in 2007. For decades Wigan has been making sculptures that fit on the heads of pins and inside the eyes of needles, with some being even smaller than a human red blood cell. Pretty crazy, right? Even more intense is how he has to craft these tiny objects - using tools like diamond shards and hairs from house flies, Wigan shapes them under a microscope during the time between his own heartbeats to avoid shaking. And one of these sculptures sits inside the Art Piece 1.\nAlong with Wigan\'s sculpture is one of Greubel Forsey\'s signature 30 degree double tourbillons. The interior cage, which is the one tilted at 30 degrees, rotates once per minute, while the outer cage sits parallel with the dial and completes a rotation every four minutes. A massive curved bridge holds the double tourbillon suspended between the sapphire crystal and caseback, and you can see right through it. Cliche aside, the execution here is something you really need to see to appreciate.\nThe dial itself is a beautiful blue color and the mainplate (visible through the sapphire caseback) is engraved with the names of the three artists involved here: Robert Greubel, Stephen Forsey, and Willard Wigan. A 72-hour power reserve indicator for the tourbillon sits around 4 o\'clock. Just above this is a plate that reads ""GF Art Piece 1,"" and when you push the button at 4 o\'clock on the case, the plate moves aside and that red arrow points to the time on a 12-hour disc. The time is only there when you need it, letting Wigan\'s sculpture and the tourbillons take all the attention.\nThe real treat comes from looking through magnifier at 9 o\'clock, which is styled to look like a second crown. You\'ll notice a dark blue bridge supporting what looks like a speck of gold from the dial-side, but looking through the 23x magnifier set into the crystal, you can see Wigan\'s sculpture crisply and clearly. Here we have a three mast galleon that seems to be sailing across the blue support. All the open-working allows tons of light in, letting you get a great look at the sculpture without any artificial assistance.\nAs you would expect, very few pieces of the Art Piece 1 will be made, each containing an entirely unique microsculpture from Wigan. This ""Golden Sails"" edition is for sale under $2 million, though official pricing is only available upon request. Enjoy the gallery below, and visit Greubel Forsey and Willard Wigan for more.', ""*VARA Visual Artists Rights Act part of the US Copyright Law.\nYes, real artists paint on buildings and yes those artists own the copyright in the art.\nA painting on a wall is different only in size and accessibility to the public from those on canvas or paper. Real artists paint on buildings and cars and busses. The fundamental legal issues facing mural and street artists are relatively straightforward. Most of us are aware that painting on a building or other public property can lead to civil and criminal liability. Less often considered are the interesting and nuanced legal issues concerning copyright and ownership of the work itself. How the work got on the wall does not alter the legitimacy of the expression, the work can even be vandalism and also protected by copyright. Although communities vary in artistic preferences, especially in their regulation of public art, the expressive and aesthetic value of art is separate from its status in that regulatory process. The fact remains that even “street art” is real and as advocates for arts and artists it is something we should come to terms with. In fact many cities and businesses in America (NIKE, Vans, Levi’s, and Frito Lay) have embraced this work both to advocate the legitimacy of street art, and to utilize this young urban medium for commercial purposes. Street artist Shepard Fairey helped define the brand of the last presidential election, inviting hordes of young people into the political process. Shepard Fairey is an ambassador.\nEspecially relevant to the public artists are the rights regarding the attribution and integrity of the work, which is part of the 1990 Visual Artists Rights Act that became part of copyright law. VARA applies to the work of artists who paint on building walls. Important rights also control secondary uses of the art such as the making of copies, t-shirts, postcards, posters, and other commercial goods.\nHow Copyright law applies to Murals\nCopyright law is grounded in our constitution to ensure a continuing incentive for creativity. Copyright protects “original works of authorship fixed in any tangible medium of expression.” This means the author of an original work in a tangible medium of expression owns the copyright in that work from the moment of creation: the copyright springs into existence as soon as the pen leaves the paper (starting with the cartoon), or the paint hits the wall. The law applies to the work of Shepard Fairey, Jeff Koons, KAWS, Joe Cotter, Larry Kangas, and Robin Corbo the same as it applies to any other artist.\nThe rights of muralists under Copyright law\nOnce an image is “fixed in a tangible medium of expression,” the creator of the work enjoys the exclusive right to make and distribute copies, to display the work publicly, and to make derivative works (subsequent copyrightable creations based on the original work). Through stencils, sketches, and the final image, the muralist fixes this creative expression “in a tangible medium;” thus, earning the protections afforded by copyright law.\nWhile the rights to the work itself pass to the owner of the wall by nature of the wall; ownership of the copyright stays with the author. Under copyright law, the artist is the sole holder of the copyright to his creations; however, if a piece is painted onto a building owned by another, the building owner is the rightful holder of that particular “copy” of the work. Lawyers can split this hair separating the copyright in the art from the rights in the work therefore; the building owner could cut out the wall on which the art was placed and sell or lend it.\nA building owner cannot, however, begin making t-shirts, mugs or advertising with the design because doing so would constitute the creation of unlawful derivative works or copies—the building owner is no longer using the wall but, instead, is using the art itself. Similarly, a photographer could not legally photograph the wall and then proceed to sell or license the copies. Capturing the painting in photographs is a copy or derivative. It would be a derivative work to use the patterns in the artwork to make fabric designs, packaging, or as promotions for film or video projects. Most major film and video productions obtain clearances for murals appearing in background shots. The art is a valuable tool to establish the “look and feel” of a location.\nThe ownership of the rights can change if the artist gives the rights to someone by signing a “work for hire” agreement which has the effect to transfer the ownership of the rights in the work. That agreement must clearly state that the work will be considered a “work for hire.” There are good reasons why a street artist may not want to demand credit for his work nor trouble himself with copyright and compensation. If we are talking about graffiti, making such a demand could expose the artist to civil and criminal liability for vandalism, trespassing, and a host of other potential violations. These uncredited artists miss out on some copyright protections recognitions and royalties in their copyrights and devalue their otherwise legitimate work.\nThe artists can also give up the rights in the artwork with a license, transfer or assignment of the rights in the work. The artist can give up some or all of the rights, its up to the seller and buyer.\nThe Duration of Copyrights For works created on or after January 1, 1978, when an artist creates a work under a pseudonym (for example, calling oneself “KAWS” instead of signing with one’s actual name) or creates a work anonymously, the copyrights in that work only lasts for the lesser of 95 years from first publication or 120 years from the year of its creation. However, if an artist's identity is revealed in the registration records of the Copyright Office (including in any other registrations made prior to the expiration of the copyright term), then the term will last for either (a) the life of the author plus 70 years; or (b) in the case of a work made by more than one person, for the life of the last surviving author plus 70 years. These nuances often mean that an unattributed work fades into the public domain much sooner than an attributed work. The Visual Artist's Right of Attribution and Integrity\nWe know that a building owner can sell the building or the wall itself but cannot make t-shirts of the art. Another question is whether a building owner may paint over a given work of art. The standard provisions of copyright law only prevent people from violating the copyright holder's exclusive rights which include distribution, making copies, and selling or licensing derivatives. The artist and copyright holder would typically be powerless to stop the destruction\nof the work except for VARA which might add additional rights. If the work is of “recognized stature” the artist may be able to prevent its destruction by exercising his moral rights under the Visual Artist's Right of Attribution and Integrity (“VARA”).\nVARA was enacted in 1990 as an amendment to the Copyright Act, to provide for the protection of the so-called “moral rights” of certain artists. “[M]oral rights afford protection for the author's personal, non-economic interests in receiving attribution for her work, and in preserving the work in the form in which it was created, even after its sale or licensing.” VARA provides that the author of a “work of visual art,” “shall have the right,” for life,\n(A) to prevent any intentional distortion, mutilation, or other modification of that work which would be prejudicial to his or her honor or reputation, and any intentional distortion, mutilation, or modification of that work is a violation of that right, and\n(B) to prevent any destruction of a work of recognized stature, and any intentional or grossly negligent destruction of that work is a violation of that right.\nHow VARA applies to a mural including street art.\nUpon passing VARA in 1990, Congress instructed courts to use common sense and generally accepted standards of the artistic community in determining whether a particular work falls within the scope of the definition of a “work of visual art”, and explicitly stated that “whether a particular work falls within the definition should not depend on the medium or materials used.” Protection of a work under VARA can depend upon the work's objective and evident purpose.\nVARA protects only things defined as “work[s] of visual art.” There is no clear bright line standard for where this applies. The congressional debate “revealed a consensus that the bill's scope should be limited to certain carefully defined types of works and artists, and that if claims arising in other contexts are to be considered, they must be considered separately” (Thus the “legislation covers only a very select group of artists”). VARA does not protect advertising, promotional, or utilitarian works, and does not protect “works for hire”, regardless of their artistic merit, their medium, or their value to the artist or the market.\nAs the quoted text reflects, VARA confers rights only on artists who have produced works of “recognized stature,” or whose “honor or reputation” is such that it would be prejudiced by the modification of a work. To determine whether a work is of “recognized stature,” courts typically apply a two-part test: (1) the work is viewed as meritorious and (2) this stature is recognized by art experts, other members of the artistic community, or some other cross-section of society. To satisfy this test, the artist will probably have to rely on expert witnesses; however, a long-existing work with some importance to the community should be sufficient. For the purposes of this determination, “recognized stature” can be either recognition of the work itself, or of the artist.\nThe rights of muralists under VARA\nVARA grants artists a type of “moral rights.” For example, from the Büchel (Mass MoCA) case, part of the law provides that the author of a “visual work” has the right to prevent the use of his or her name as the author of the work of visual art in the event of a distortion, mutilation, or other modification of the work which would be prejudicial to his or her honor or reputation.\nUnder VARA, authors of qualifying works have the right to prevent its destruction. Destruction of such works can lead to substantial liability. In 2008, Kent Twitchell (an American muralist) settled a case under VARA and California's Art Preservation Act (CAPA), in which he was awarded approximately $1,100,000 for the destruction (painting over) of his 70-foot-tall landmark mural of the iconic L.A. artist Ed Ruscha. However, even if all the VARA elements are met, courts may still deny relief to artists who have illegally placed their works on property. This was the case when artists illegally placed artwork in a community owned garden on city property. When the interior construction by the artists was identified as a “work for hire” so the artists did not own the copyright (Carter v. Helmsley- Spear). It was also the case with a temporary mural (Pollara case) attached to a chain link fence in Albany New York, regardless of the artists reputation and quality of the work, political appropriateness, or value of the message. But it was not the case when the artist and museum disputed whether the work was “finished” and if it could to be publically shown (Büchel).\nUnpermitted work in violation of the law\nUnder VARA, artists who illegally paint the property of another are probably without a means of stopping the destruction, removal, or transfer of that particular manifestation. As a result public pressure rather than copyright law is probably the best means of protecting such work—if the work is truly special, of recognized stature, or widely appreciated by members of the community, then coordinated action from local citizens may be the only way to save it regardless of artistic merit. While there is a growing recognition of street art, illegally placed artwork is subject to the wishes of the landowner. Whether you agree or not, the legal reality balances the value of art against the value of property rights, and the result is unsurprising. Although it makes sense from a policy perspective, it has also led to the destruction of many important works of art. Copyright law applies to all artwork, legal or otherwise. “Legal” work can have the additional protection of VARA which might prevent certain important works from being lost, or altered, or even exploited improperly. Conversely, artists of commissioned work may be entitled to VARA protections even absent their ownership of the copyright.\nConclusion Copyright grants artists the right and ability to control the copying and distribution of their work. Murals painted with the approval or the property owner will enjoy this protection under VARA if it meets the necessary subjective conditions. If it’s protected under VARA and if the artist or their agent is attentive, if there is an attempt to alter or deface the work the artists has rights that can stop the artwork from being changed or even repaired without permission. But the artist must assert that right. The artist should be able to assign that right to someone, or an agency, to protect the work like the Mural Conservancy of Los Angeles. That solution hasn’t been tested in the courts, but certainly has been suggested in the cases.\nWith regard to unpermitted works, the rubbing out, painting-over and alteration by other artists, and the constant changing urban landscape drives street art forward. While such art can be commoditized, it is inherently impermanent. Perhaps today's mural and street artists owe thanks to the public reaction and the laws that constrain the medium because they force it to evolve.\nMurals, Copyright & VARA February 11, 2012 RACC Mural Workshop, Portland OR Kohel Haver, 503-295-2787 firstname.lastname@example.org""]"	['<urn:uuid:f36daccf-e47e-4383-afcd-c117fa9ec45e>', '<urn:uuid:b5860489-752a-4e05-8c98-1b441a5fa068>']	factoid	with-premise	verbose-and-natural	distant-from-document	multi-aspect	novice	2025-05-01T23:55:16.606337	38	113	2850
477	How do American and European approaches to Varroa control differ?	Americans focus on organic treatments (formic acid, thymol) and treatment-free methods (small cell size), with successful VSH breeding programs. Europeans, particularly Germans, use a strict schedule of formic acid treatments and oxalic acid in winter, while focusing on pure race breeding of Carniolan and Buckfast bees through isolated mating stations.	['As the managed honey bee industry continues to grapple with significant annual colony losses, the Varroa destructor mite is emerging as the leading culprit. And, it turns out, the very nature of modern beekeeping may be giving the parasite the exact conditions it needs to spread nearly beyond control. In an article published yesterday in […]\nFor Varroa mite control, I sprung for a ProVap110 this year. I put it through the paces this week and thought I’d report on it here.\nView Video Here:\nDisclaimer first: Yes, Larry of OxaVap is a friend of mine. We met at a South Carolina Beekeepers Association conference several years ago and hit it off talking bees non stop for the duration of the conference. This was all before oxalic acid was approved for use in the United States. Larry told me then it would be the next big deal in Varroa mite control and apparently he was right as it was approved a couple years later. (Larry also told me where U.S. beekeepers were already ordering vaporizers from across the border in Canada.) Anyway, Larry and I always look forward to conferences and hanging out, telling bee stories when we can.\nBefore getting the ProVap110 I was using two Varrox, pan type ,vaporizers. Using two really sped up my mite treatments. Duh, twice as fast, right? No, don’t ask me how but everything moved faster and down time between hives was less so I really think I was doing the job in less than half the time than with one.\nRecently, Larry suggested I needed to try the ProVap110 but I was resistant due to the issue of needing AC current. He said that most inexpensive car/truck inverters would do the job as it only used 250 watts and 2.2 amps. I checked and Harbor Freight had an inexpensive inverter. But I really wanted to be able to treat without having to drive my truck into sometimes muddy out yards. Larry assured me that a long extension cord run would not be a problem but I resisted and bought a small WEN 1800watt generator. I do plan on buying that inverter as well but the WEN1800w is under 50 pounds and, so far, I really like it and don’t have to worry about getting my truck stuck in a muddy out yard field while vaporizing mites.\nOne morning this week I oxalic acid vaporized 32 hives in about an hour and 15 minutes. As with the old Varrox, you still have the setup time of placing IPM boards under screened bottom boards to help seal the hive as well as a damp dishcloth across the entrance. I left the WEN1800w generator in the back of my truck and used a 50 ft extension cord. The extension cord had no noticeable effect on the operation as the ProVap performed exactly as the enclosed paperwork stated it would. I will use a 100 ft extension next time to see if that has any effect. The ProVap110 took about 2 to 3 minutes to reach its operating temperature of 230C. The unit adjusts to maintain that temperature throughout its use. I’ll place a link to a video in this post for those who have not seen how it operates. Basically, after it reaches its operating temperature a measured amount of OA is placed in a cup and attached to the ProVap110 while inverted. The nozzle is inserted into a 1/4″ predrilled hole in the hive body and the unit is spun around to its upright position causing the OA to drop into the 230C pan. The temperature readout dropped to approximately 208C when the OA came in contact with the heating unit and immediately began its rise back to 230C. Within about 20 seconds the temperature had returned to 230C and I removed the unit from the hive. An additional “cup” is provided so the user can prepare the dose for the next hive during the 20 second wait. And so it goes hopscotching down the row of hives.\nSome things I learned are: 1) Hole placement is more critical than I first expected. I had used a homemade template based on the instruction sheet and some of the holes were drilled into handholds which caused me to have to hold the unit in place instead of leaving it to prep the next dose. The instructions say drill the hole 3 to 4 inches up from the bottom . I will drill future holes below the handholds in the lower box – if you use cleats drill well below. You want the vapors to circulate readily once inside the hive so make the hole in that area where the frames are narrow (lower half) to allow for the bees to move around the frame. 2) The tube that sends the vapor into the hive is copper and about 3/4″ in length. That makes sense since it is going into a hive body with a thickness of 3/4″. Longer and it could bottom out on a frame inside. Unrelated to the tube length but I’d like the tube to be made of a harder metal than copper if possible – I am uncomfortable with the possibility of bending the copper tubing. 3) You will need an acid/vapor PPE mask as you will be in close proximity of the OA vapor. There is no getting around this. I currently use a 3M 7502 mask with organic vapor/ acid gas filters – $13.99 on Ebay, and non vented safety goggles – $7.99 Ebay. The mask worked great and I never even got a whiff while standing behind the hive administering the OA vapor. (more on this later)\nSome of the nice things about the unit are: 1) Its speed. I usually just stood there behind the hive for 20 seconds and let it do its thing. 2) The plume of vapor into the hive is thick and sudden. The bees don’t have the “warning time” they did with pan type vaporizers to start fanning. Bang, it’s in there and done. Most of the hives didn’t object any more than they did with the pan vaporizer but a couple did. All hives settled down soon afterwards. 3) The almost constant 230C temperature ensures the OA is properly sublimated. I always suspected the gradual warming of the OA with the pan vaporizers may have wasted some of the OA as it was evaporated, boiled off, or was otherwise consumed instead of sublimated thus diminishing the dose. The ProVap110 ensures the OA always hits the pan at exactly 230C. 4) I often lose my biggest and strongest hives over the winter. I’ve always suspected it might be related to inadequate OA treatment reaching the upper boxes. Now I can treat the hive via a 1/4″ hole placed anywhere, in any box, instead of just underneath the hive. And don’t worry about drilling 1/4″ holes in your woodenware, the bees will propolize it soon enough or you can use a golf tee or dowel rod to plug. 5) It would be nice to have a half dozen of the “caps.” to prepare in advance. It’s not essential; that’s just my OCD speaking.\nGeneral comments: Most efficient use would necessitate a planned layout of the hives in the bee yard. If you scatter your hives around here and there you’ll waste time in transit. I have basically three different zones in my home yard. This meant driving the truck to three different positions and repositioning the drop cord each time. I think keeping your hives within a 100 foot radius and using a 100 foot drop cord might be ideal. Having plenty of IPM boards available is also a great time saver as transferring them hive to hive is a time waster. Luckily I have plenty to use in case of a severe winter but others may not. The hives with solid bottom boards were easiest to treat.\nNow, here’s an interesting thing: The visible escaping particulate using the ProVap110 was noticeably less than when using pan type vaporizers. I can’t really account for why this is other than the bees don’t have the 2 – 4 minutes to start fanning before the deed is done. I actually used the ProVap110 in the first two hives and thought, “Did it work?” So I loaded the ProVap110, held it downwind, and flipped it to see if it was sublimating the OA. Yes, it was working and it’s done in about 20 seconds. If you look at the video, at the end the guy does exactly this and you can see how thick the plume is and how fast it comes out. Anyway, my point is, there appears to be less particulate escaping the hive than with pan vaporizers – and that’s a good thing!\nCleanup is a breeze. A little water to wash out the areas where the OA comes in contact was quick and easy. The unit itself cools off quickly when unplugged which is good and bad. Good for safety once you are done but moving into different bee yard zones meant having to wait the 2 – 3 minutes for the unit to return to operating temperature. I’m convinced I can shave 30 minutes off my first effort implementing some of the changes mentioned above.\nI am satisfied with the unit over the pan type vaporizers for a few reasons: time efficiency, proper sublimation, flexibility in selecting placement of the area the OA is administered, and ease of use. I’d recommend it to anyone that starts to feel that pan-type vaporizing is taking too much of their bee management time that could be better spent more productively.\nAddendum August 31st, 2017: After having used the ProVap100 for multiple yard treatments I thought I’d comment on a couple items I hedged on in my first review (above). First, use of multiple extension cords makes no noticeable difference in either warm up time or time to sublimate the oxalic acid. I am now using two fifty foot extensions cords and I get the same excellent performance as with one. Second, After having a problem with my gas powered generator I purchased an inexpensive 400 watt inverter at my local Harbor Freight store for ~ $23.00 USD. Using this as my power source the ProVap100 performed again without any degrading of performance. At $23.00 versus what I paid for the gas powered generator I’d opt for the inverter first unless there was an issue with access to the bee yard. Third, Thus far this year I have not lost my biggest hives post nectar flow and during the Varroa buildup as I have in previous years. I am unable to say that positive outcome is a result of the ProVap100 but I suspect it is a contributing factor. I remain very happy with the unit and from emails and messages I have received from people that have also purchased one they are likewise happy with the efficiency and ease of use of this unit.', 'Varroa resistance breeding is now for us a feasible and promising way. The beekeeping system of Ed & Dee Lusby, with small cell bees, represents for us a basis which allows the bees to actively defend themselves against the Varroa mites. The additional use of selective breeding, in accordance with the experience of Harbo, gives us the opportunity to bring Varroa tolerance breeding in Europe to success what was not prosperous the last 40 years. The investigations of our small cell hives on VSH (Varroa Sensitive Hygiene) shows us the mechanisms how the bees actively defend against the Varroa. Now it is up to us in the working group to put it into reality, because we are now in the fortunate position to have all the necessary basics. We will establish a working group of resistance breeding in our group, and all who wish to cooperate are cordially invited to attend.\nThe other day I received Imkerfreund 12-2013 in my postbox. In this issue of the German bee magazine I found an interview with the scientist leading a varroa breeding project involving beekeepers. It’s a project that has made some progress.\nA German strategy\nGermany has had varroa for about 40 years. And they mostly try to breed pure Carniolan bees (carnica) and pure Buckfast with the help of isolated mating stations (and insemination). The main varroa treatment concept is the following in the south of Germany.\n- April-June Cut dronebrood and make splits\n- July After harvest in July treatment with Formic acid\n- August Four weeks later the second treatment with Formic\n- September The third treatment with Formic if mite downfall after treatment no 2 is too high\n- December Treatment with Oxalic acid, trickling of sugarsolution with oxalic\nTheir breeding program has two resistance parameters: pinkilling a square decimeter of brood (similar to freeze killed brood) and measuring the development of the varroa population during the season. Besides traits like low swarming, good temper and a honey crop. Their progress: being able to skip one of the summer treatments with Formic acid (as far as I understood the German article).\nAn American strategy\nUSA has had varroa for about 25 years. Few try to breed pure race bees like the Germans. Ineminated and naturally mated queens are used. The main varroa treatment concept for smaller operations are aimed at organic treatment (involving formic acid, thymol, drone cutting, hops) and treatment free (involving small cell size, topbar hives). Bigger operations most often trust different syntetic miticides, formic, thymol and hops.) Americans are more focused on treshold counts of mites for the time to treat.\nThe Russian bees from the very east of Russia, the Primorski area, is one quite succesful undertaking started and developed by the USDA. A number of beekeepers have formed an association to take care of the 18 lines of these bees. They are treated much less than ordinary bees against varroa. With these bees you have to watch out for swarming.\nThe VSH-bees are influencing most of the other efforts of breeding resistant bees to varroa mites. These bees are a mixture of all kind of bees. Here you find most of the traditional beekeepers that don’t use any treatment against varroa mites, for example John Harbo, http://www.harbobeeco.com/breeder-queens/ , and Adam Finkelstein, http://www.vpqueenbees.com/breeding.html\nBeekeepers in different states are forming breeding organisations funded by the governement, like this one: http://mysare.sare.org/mySARE/ProjectReport.aspx?do=viewRept&pn=FNE12-737&y=2012&t=1\nThere are those in Europe forming good projects and those already not treating against varroa either, but with this article I want to get attention to how little progress is made with the strategy mentioned above in Germany and how great achievement is made with the VSH-breeding, focused at the start on one trait: VSH. Then on the other. Something has to be learnt here.\nActually resistant bees were achieved already after very few years, by Harbo and Harris in 1995-98 in USA. They started with survivor colonies of any type of bee they were given. The only one parameter they focused on first was VSH: Varroa Sensitive Hygiene. See other articles here in the VSH category. This development of resistant bees have to be done in all kind of regions differing in climatic and other local characteristics, mites and pathogens for example.\nIt’s time for Europe to learn the lesson and form breeding projects together with beekeepers where ’central’ areas are formed fairly isolated from other bees. All bee colonies in these ’small starter’ areas are part of the program. An effective way of using funding money from European Union would be to support such projects.\na response from our colleague Rüdiger:\nAs a German I have of course to answer to Eriks contribution “Breeding for Varroa resistance: Germany versus USA”…:-).\nWhen commenting about activities in the varroa resistance breeding area I guess it’s better to compare Europe versus US. Otherwise it would be too bad for Germany…\nI think the main drawback for Europe compared to US is that a funded continuous breeding program is missing. The US seems to have at least 3 – Minnesota Hygienic Stock (MNHYG), Russian Honey Bee program (RHB) and VSH program, which all seem to have shown valuable outcomes. Moreover, the organic beekeeping community in the US, e.g. Ed and Dee Lusby, Michael Bush, Dennis Murrel and others have been innovative and could establish treatment free beekeeping since many years. And this could be achieved with local bee races or no complicated bee breeding scheme!!! Their impact with small cells, comb distance, not contaminated bee wax etc. is not only logic and inspiring, it works as stated above.\nEurope did of course some funded scientific investigation of Varroa and could contribute to the understanding of infestation mechanism in the 90-ies, e.g. grooming behaviour (Bienefeld, Aumeier, Thakur etc.) or VSH (Rosenkranz, Vandame). However, efforts seem to be sporadic and as already mentioned not continuous, to yield in resistant queens that are distributed via the beekeeping community.\nBesides, beekeeping organizations here I can only comment on Germany with the AgT (Arbeitsgemeinsschaft für Toleranzforschung) http://www.toleranzzucht.de/en/breeding-programme/, try to connect and coordinate different breeders in order to achieve bees that combine favourable and varroa resistant traits. However, improvement ratios seem to be small up to now.\nBut in my eyes Europe could contribute significantly by activities of bee breeders. The idea to use already varroa resistant bees for breeding was first established by Erik Österlund (1989) and John Keyfuss (1993), who cross African bees into A.mellifera mellifera/Buckfast. John uses a Tunisian bee (Apis mellifera intermissa) and Erik Apis mellifera monticola from Kenya. The resulting Elgon bee is since a bee that needs less or even no varroa treatment. The same is true for Keyfuss bees and he gain merits by bringing this topic into broad public interest with his “World varroa challenge”.\nThis approach was copied by Rinderer (RHB), who used Russian bees that lived since 200-250 years with varroa mites and hence, should have developed resistance traits. The same idea was practically followed by P. Jungels (Buckfast – Primorski mixes) and J. Koller (pure Primorski) (Primorski synonyme for russian bees) in Europe, who contributed significantly by providing varroatolerant queens to the European bee keepers.\nA guy that use local (carnelian) bees for his breeding program is Alois Wallner from Austria http://www.voralpenhonig.at/, who bred since 1990 for bees that groom and kill varroa mites by removing their legs. The result is now a bee that kill nearly every mite (varroa killer factor 100). Additionally his bees express VSH behaviour and hence, bees need only few or no treatment with formic acid.\nIn my opinion one brave European guy need to be mentioned as well which is Juhani Lunden in Finland http://www.saunalahti.fi/lunden/varroakertomus.htm He managed in a brute force approach to breed varroaresistant bees, which are not treated since 2009. He used a strong selective pressure to achieve his goal and hence, other traits as gentleness or honey crop might be compromised.\nSo taken together, these efforts need to put on a strong base in Europe as well and both, the spread of “resistant genes” by suitable queens and by suitable programs need to be pushed and furthermore the usage of organic beekeeping principles that result in treatment free bees should be distributed. That includes the courage of not using treatments to outselect non optimal strains. Here the community in Europe is already on the way see http://resistantbees.com/ (Germany and Spain), but Europe should definitely speed up and learn the positives from the US. This is especially true for the scientific sector and funded EC programs.']	['<urn:uuid:96902eb0-644f-411b-b8f2-163f33519dff>', '<urn:uuid:004e58ad-14c5-41f4-9670-3c967b3716b5>']	factoid	direct	concise-and-natural	similar-to-document	multi-aspect	novice	2025-05-01T23:55:16.606337	10	50	3263
481	What unique symbol marks the pilgrimage trails in Norway?	The Pilgrims' Way is marked by a square emblem the size of a cocktail napkin showing a red-on-black or red-on-gray Celtic-like cross (the St. Olav's Cross) bisected by a cloverleaf.	"[""Hiking the pilgrimage trails of Norway and Scandinavia: Ancient footsteps with a modern twist.\nThe pilgrimage trails collectively known as St. Olav's Ways cross Scandinavia on their way to Trondheim. While not as famous as some pilgrimage routes, they still attract people from all over the world.\nIn a land where hiking is second only to skiing as a national pastime, many Norwegians are unaware that the longest and oldest of Norway's recognized walking trails crosses not only mountains, streams and forests but also Oslo, barley fields, the E6, and in some cases people's backyards.\nFrom Oslo to Nidaros\nPilegrimsleden, or The Pilgrim's Way, stretches 643 km from the ruins of Mariakirken in Oslo's Gamlebyen to Nidaros Cathedral in Trondheim.\nIn addition, several historical feeder trails connect with the main route, including a segment from Tønsberg northward to Oslo, and a route from Selånger on the Bothnian Sea in Sweden westward to Trondheim via Stiklestad (known also as St. Olavsleden).\nAn experience like no other\nThe Pilgrim Way offers a hiking experience like no other because of its sheer variety and historical back-story. It is a walk through culture and time as well as nature, embracing the human-built environment as much as wilderness and highlands.\nIt all came about because a Norwegian king, Olav Haraldsson, got himself martyred at the Battle of Stiklestad in 1030, and canonised not long thereafter.\nMiracles attributed to St. Olav drew penitents and pilgrims from all parts of Europe to Nidaros, where the slain king was buried after some grave-shifting.\nThe Cathedral was later erected on the spot. At its medieval heyday, the journey to Nidaros became the northern apex of a pilgrimage matrix extending south to Rome, east to Jerusalem, and west to Santiago de Compostela.\nThis carried on until the Protestant Reformation in the 16th century. After Norway became predominantly Lutheran, the Pilgrims' Way fell largely into disuse and was all but forgotten for the next 450 years.\nIn the 1990s, some prominent proponents of friluftsliv and Norway's Deep Ecology movement, along with church leaders, persuaded the government to join in an effort to rediscover and reestablish the old pilgrim routes.\nAfter five centuries of human activity and imprint this meant that where once stood only woods, footpaths and the occasional river, now there were motorways, homes, and golf courses directly on the places history said St. Olav's devotees trod.\nBecause the project planners of the resurrected pilgrimage routes wished to hew to the original walks as much as possible, the modern-day pilgrim/hiker traverses everything from city streets and freeway underpasses to steep forests and the Dovrefjell plateau.\nThe real Norway\nAlong the way you can expect to see iconic Norwegian stave churches, farms, towns, cities, lakes, rivers, mountains, valleys, ruins, historical monuments, the settings of Peer Gynt and Kristin Lavransdatter, wildlife, and many, many sheep.\nMost importantly for navigation purposes, you will have your eyes peeled for a square emblem the size of a cocktail napkin: a red-on-black or red-on-gray Celtic-like cross (the St. Olav's Cross) bisected by a cloverleaf, the symbol that marks the Pilgrims' Way.\nThis little homing beacon appears in numerous forms, from sturdy fence-post plates to dangling sticks from tree branches to stickers on traffic poles.\nIf you look closely on a stroll around Trondheim or Oslo, you will likely come across it in the vicinity of the oldest churches, and various other seemingly random places.\nRecently I found Pilgrims' Way markers while wandering around Oslo's Ekeberg sculpture park!\nAccommodation on the route\nWhereas DNT huts provide shelter to hikers on most trail networks in Norway, travelers on the paths that make up the Pilgrims' Way can bed down for the night in a stabbur, farmhouse, youth hostel, tourist hotel, church hall, community center, or school, among other pilgrim-designated lodging options.\nThe option to camp\nCamping-oriented hikers and those wanting to save on expenses can, of course, put up a tent in campgrounds or just about anywhere that isn't close to someone's house or in a cultivated field.\nWhen I walked the Pilgrim Way from Oslo to Trondheim with a friend, we did a mix of camping with our own gear and paying to stay at indoor places.\nRead more: Camping in Norway\nI would highly recommend staying in at least some of the pilgrim-oriented lodging along the way for an opportunity to talk with the hosts and learn more about the areas you are walking through.\nThree truly memorable examples of this are the Sygard Grytting farm in Sør-Fron, welcoming pilgrims since the 13th century; Hæverstølen Gardstun in Rennebu, run by one of the founders of the revived Pilgrims' Way; and Munkeby Hostel on the way from Stiklestad to Trondheim, close to a monastery which produces what many regard as Norway's finest cheese.\nCustom-build your ideal hike\nHiking the entirety of the main Oslo-Trondheim route or the trans-Sweden Selånger-Trondheim route will take upwards of a month, but a great feature of the Pilgrim Way is that it lends itself to customization depending on one's interests and available time.\nBecause the pilgrim paths go right through several population centers, you can pick your own start and end points with easy access by train or bus.\nAn ever-increasing number of guided group tours for segments ranging from one day to five weeks is also available.\nWhether you are spiritually-minded or just enjoy walking, every day and every part of the Pilgrim Way presents different joys and challenges – just as it must have done for the first travelers nearly a thousand years ago.""]"	['<urn:uuid:65de2a4d-90e9-45ae-8414-949a79f65b9b>']	factoid	with-premise	concise-and-natural	similar-to-document	single-doc	expert	2025-05-01T23:55:16.606337	9	30	924
482	mazda rx7 first version power specs	The first Mazda RX-7 used a 12A rotary engine displacing 1.2 liters and producing around 105 horsepower. It could accelerate from zero to sixty in ten seconds.	"[""Image credits: © Mazda.\n1982 Mazda RX-7 news, pictures, specifications, and information\nIn 1969 Mazda Project engineer Akio Uchiyama began work on a two-seater sports car. Internally it was called project X020A and eventually became known as RS-X. The idea was to share a chassis from a production saloon thus saving on production costs and limiting the time-to-market. This project continued until 1973 when the oil crisis finally put an end to the car.\nAround 1975 Sinpei Hanaoka, a Mazda board member and former banker, recommended that a rotary engined sports car be developed. Soon after Project X605 began. This was different from the prior attempt, in that a new chassis was developed for the sole purpose of accommodating the rotary engine's compact dimensions. Akio was tasked with assisting Sumio Mochizuki, the Chief Project Engineer, in designing the chassis. Styling was handled by Yasuji Oda and Matasaburo Maeda. The creation of the rotary engine design was given to Kenichi Yamamoto.\nThe rotary engine was compact, small, and helped in the 50/50 weight distribution resulting in exceptional handling. Instead of focusing on maximum horsepower, a fuel-efficient 12A version was opted chosen. The engine was placed in the front and designed to power the rear wheels. To reduce production costs, the suspension was borrowed from the production vehicles. The front had McPherson struts and coil springs and the rear was a live axle with coil springs. The steering was re-circulating ball. Disc brakes were placed in the front while the rear brakes were drums. The chassis was comprised of monocoque which helped reduce weight while increasing structural rigidity. The rear window was originally a one-piece wrap around sheet but was replaced in favor of a cheaper and more reliable 3-peice design. During wind tunnel testing it was revealed that the design had an excellent aerodynamic drag, equivalent to a Porsche 924. With the headlights exposed, the drag was reduced from 0.36 to 0.38 CD, similar to the Datsun 280Z.\nThree transmission were available; a three-speed automatic, four- and five-speed manual.\nThe 12A rotary engine, with the help of modifications, was able to produce five extra horsepower and three more pounds-feet of torque. Fuel injection was attempted but did not work with the exhaust thermal reactor and would not have complied with United States safety and emission regulations. A characteristic of the engine is that it is very quiet. It is smooth and 'torqy' offering loads of performance.\nThe front seats were buckets with plaid designs and the rear was a bench seat. The instrument panel featured a 130 mph speedometer. The rev counter had dual purposes, first it reported revolutions per minute and when the ignition was on but the engine had not yet started, it served as a voltmeter. This was later changed to separate gauges.\nIn 1977 the prototype was finished and a year later in March of 1978 the RX7's were being produced at the Ujina plant. The RX-7 was introduced to the members of the press at Hiroshima and later debuted to the United States in April of 1978. The RX7, a.k.a. Project X605, was an immediate hit.\nThe Mazda RX7 was a practical sports car, highly competitive, and offered at a low price. Supply could not keep up with demand and many potential buyers were often offering more money above sticker price just to own one. There were initial quality problems but all issues were quickly resolved. By 1980 nearly 140,000 examples had been produced. Using a 12A rotary engine displacing 1.2 liters, it was capable of producing around 105 horsepower. Zero to sixty was accomplished in ten seconds.\nIn 1984 a more powerful 1.3 liter rotary engine was introduced, the 13B. The 13B produced 135 horsepower and was placed in the 'special edition' cars called the GSL-SE. The GSL-SE were given disc brakes on all four corners and a Limited Slip Differential. The zero to sixty time improved to just under nine seconds.\nThe main complaint for the car was its steering. Many believed that the recirculation ball should be replaced with a rack-and-pinion unit which could better keep up with the cars excellent performance and offer superior handling. Besides this, the car was given excellent reviews by all automotive magazines.\nThe RX7 was eligible for class C racing in the United States. Under IMSA's classification, it was eligible for 2.5 liter racing. After its domination on the racing circuit, the IMSA re-classified the RX7 at a higher minimum weight limit which allowed it to run in the more competitive GTX class.\nThe RX7 production continued until 1986. As time had progressed and as a bi-product of racing, the RX-7 had been much improved. However, the field of affordable sports cars was increasing and the RX-7 was in need of a replacement.\nThe Second Generation RX7\nChief Project Engineer Akio Uchiyama had traveled to the United States to become better acquainted with the demands of the RX-7's largest market. His interviews and the comments and suggestions received from the owners and prospective owners influenced the design of the second series of the RX-7.\nBy June 1981 the project was started. Akio Uchiyama chose the name P747 to represent this task. Various designs were created, each targeting different markets. The designs were labeled 'Realistic Sports Car', 'Technologically Advanced Sports Car', and a 'Civilised Sports Car'. The designs ranged from a hard-core sports car to designs that offered plush amenities and hints at its sporty-roots. The price of these potential cars were estimated to fall between $9000 through $13000 depending on the design chosen. In total there were around twenty designs created each representing different ideas of the next generation RX7. Two designs were chosen as 'favorites' and full-size clay models were developed and shown to consumers.\nBy February of 1983 a design was chosen. Takashi Ono was tasked with designing and building the exterior of the vehicle. Most of the demands made by Ono were carried through but a few needed to be redesigned based on consumer reaction and to accommodate mechanical components. The resulting prototypes achieved a 0.29 CD of aerodynamic efficiency. This was the result of a low hood and a 63.5 degree angle windshield.\nJiro Maebayshi was tasked with designing the suspension. The resulting mechanics was borrowed from a truck suspension created by Takao Kijima. The front and rear suspension were independent with the front incorporating McPherson struts. To make the car more maneuverable, four wheel steering was experimented with but unfortunately the results were not promising. Instead a system was adopted that allowed a small degree of rear steer to be created by the rear suspension during cornering. The rear wheels would steer in the same direction as the front increasing stability at high speeds. At low speeds the rear wheels would steer in the opposite direction of the front wheels. The system was dubbed the 'Dynamic Tracking System Suspension' and 'Triaxial Floating Hub'. The system did increase noise so to compensate the final drive system and rear suspension were mounted separately on the rear subframe. To reduce the noise caused by the subframe and the chassis, Rubber bushings were used. The rack-and-pinion steering and the updated suspension addressed the major pitfall of the first generation RX-7.\nThe second generation came with options, such as brake sizes and wheels. Standard were 9.8 inch ventilated disc brakes with the 10.3 inch disc with single piston floating iron calipers offered as optional equipment. Anti-lock braking system was not offered at the introduction of the vehicle but became available at a later date. The RX-7 could be purchased with a five-speed manual or a four-speed automatic transmission. A turbocharger system increased torque by nearly 30 percent.\nA luxury version was offered outfitted with cruise control, air conditioning, leather seats, power windows and a security system.\nThe 13B engine had been introduced in the first generation RX-7. It produced 135 horsepower and by reshaping the plenum, 11 extra horsepower was achieved. The plenum was curved again for the P747 in increase the power even further. Other modifications included the addition of a second fuel injection, new rotor apex seal, digitally controlled Bosch L-Jetronic, larger air cleaner, and wider throttle intake and valves. Through these and other efforts, more horsepower and better fuel economy was achieved, and the engine became more durable. At the end the engine produced nearly 150 horsepower and 138 foot-pounds of torque. This meant the vehicle could propel from zero to sixty in just eight seconds and top speed was achieved at nearly 130 mph. The turbocharged 13B version was rated at 182 horsepower and 183 foot-pounds of torque. The fuel economy was nearly identical to the non-turbo charged version, 17 city and 23 highway.\nThe interior was convenient, ergonomic, and modern. There were orange instrument needles, red lettering, 8000 RPM tachometer, four auxiliary dials for oil pressure, battery charge, fuel level and coolant temperature. The turbocharged versions had a boost gauge in place of the battery charge.\nThe RX-7 was offered in two-seater and 2+2 configuration, however the rear seats were small and was best used for luggage rather than transporting extra passengers.\nAfter design and development of the prototype P747 and before official approval to begin mass development the P747 ran into a problem. The United States would enforce a tax on all vehicles that weighed over 2875 pounds and did not meet a 22 mpg combined city/highway rating. P747 was too heavy and did not meet the combined gas rating and nearing the point where the project would be discontinued. Upper management allowed one month to reduce the weight and to improve fuel economy.\nEvery designer and engineer began removing items, replacing others with a lighter material, and searching for ways to reduce the weight. The cast iron wheel hubs were replaced with alloy and the spare tire jack was replaced with an aluminum unit. The final drive cover was replaced with an aluminum material and the suspension arms became forged aluminum. The weight-saving measures continued and in the end P747 weighed 2630 pounds, still a hundred pounds more than the first generation RX7 but it did include many mechanical and electrical improvements and features. The major downside to using the lightweight material was that it was more expensive than the steel that it replaced.\nThe name RX-7 was retained, although many believed that it would have been given the name RX-8, the next logical succession in the Mazda naming convention.\nIntroduced in 1986 it was immediate successful. Sales were strong and higher than any other year for the RX-7. The 13B 1.3 liter rotary engine producing 146 horsepower was standard as was the four-wheel disc brakes. The turbo version, named the 'Turbo II', increased the horsepower to 182 horsepower. Zero to sixty was achieved in 6.8 seconds in the turbocharged version while the naturally aspirated engines achieved 60 mph in 7.7 seconds.\nFor 1987 sales slowed but this was expected. Improvements were added, defects were fixed, and the RX-7 continued to evolve. The luxury and turbo versions were outfitted with antilock brakes as standard equipment. A convertible option became available from the factory. The rear window was made of glass and had a defrost mechanism built-in. In America the Convertible option came with the naturally aspirated engine and a manual gear box. Anything more and the car would have been too heavy, qualifying for the Gas Guzzler Tax. In other countries, the RX-7 Convertible could be purchased with the Turbo and other optional equipment.\nThroughout the years Mazda introduced various specialty versions to commemorate special occasions, to offer an exclusive line-up, and to improve sales. A tenth Anniversary special edition honored the ten years of production for the RX-7.\nBy the close of the 1980's, the 13B naturally aspirated engine had been improved to produce 160 horsepower, the turbo version producing as high as 200 horsepower. The axle and gear ratios were improved to handle the increase in power. The gear shift mechanism was changed in favor of a shorter-throw unit. Steering was improved through the use of engine speed sensing instead of the prior speed-sensing steering.\nIn 1989 the Mazda Miata was introduced, revitalizing sales for the small, simple, two-seater sports car market. Many believe it stole sales away from the RX-7, which for 1990 saw sales slowing down. The RX-7 was still the choice for sports car performance while the Miata became the cheap sports car options.\nBy 1992 the production of the second generation RX-7 had came to an end. 1990 was the final year for the GXL 2+2 hatchback. From 1991 onward all Mazda RX-7's were two seaters. Since the redesigned 1993 RX-7 model was introduced early, there were no official 1992 RX-7's.\nThe Third Generation RX7\nDebuted in 1993, the third generation Mazda RX-7 was available only as a two-door hatchback. Under the hood was a new twin-sequential turbocharged 13B-REW rotary engine producing an astonishing 255 horsepower. A five speed manual and four-speed automatic were offered. On all four corners were Anti-Lock disc brakes. Safety was improved with the introduction of a drivers-side airbag.\nWeighing 190 pounds less than its predecessor and offering 50/50 weight distribution, the powerful and redesigned third generation RX-7 was a performance machine.\nThe RX-7 was offered with two packages that could not be combined. The first was the R-1 designed for those searching for the ultimate performance from their RX-7. The package added body spoilers and dual oil coolers. The Touring Package was offered for those seeking luxury from their sports car. This package added leather seats, Bose speakers, steering wheel mounted cruise control, and a power sunroof.\nIn 1994 safety was enhanced with the addition of a passenger side airbag. Map pockets and a revised dashboard were also new for 1994. The performance package was now called the R-2. A new package was offered called the Popular Equipment package. This included power sunroof, rear cargo cover and leather seats.\nCompared to the prior versions, the third generation RX-7 was short lived. Its performance, handling, low weight, and styling continued the legacy established by the first and second generation. The downfall for the third generation RX-7 was its sticker price costing over $35,000 in 1995. 1995 would be the last year the RX-7 was produced. Ending a legacy and bringing to end the production of the rotary engine, at least for a while. With the introduction of the Rx8, the rotary engine has been reintroduced. A new chapter is beginning.By Daniel Vaughan | Sep 2007\nThe most famous aspect of this vehicle is probably the engine. It was a revolutionary engine created by Felix Wankel and named the 'Wankel Rotary Engine.' Inside an elongated chamber, a rotor with three curved sides revolves around a central driveshaft. Air and fuel enter from the sides and are compressed as the rotor spins. The result is the equivalent of a conventional combustion chamber.\nDuring the design and planning of the engine it was believed to have so much more to offer than the traditional engine. It has fewer moving parts and no pistons making power delivery smoother. There were very high-hopes for it. However, after it was built it was plagued with technical problems mainly leaks in the combustion chamber and rotor tip wear. These issues were addressed but they took time. Many of the issues were ironed out by the time the RX-7 was ready for production. The next issue was poor fuel economy and inadequate power at lower speeds.\nThe design was done by Mazda's Matasaburo Maeda. It was very appealing, sleek, and sporty. This, coupled with the new engine created a successful combination.\nThe first-generation was in production for seven years. During that time only minor aesthetic changes were introduced. Mechanical enhancements, on the other-hand, were more frequent. In 1981 the car was given more horsepower, and then again in 1983 with the electronically fuel-injected limited edition Turbo. During its production run, nearly half-a-million units were built.\nThe second generation RX-7 came into existence in 1985.By Daniel Vaughan | Sep 2007\nFor more information and related vehicles, click here""]"	['<urn:uuid:0e3e5e1f-8dae-4be3-afe4-9a905c7a24e1>']	factoid	direct	short-search-query	distant-from-document	single-doc	expert	2025-05-01T23:55:16.606337	6	27	2679
484	Between women's promotion and workplace education rules, which faces more legal restrictions?	Employment education requirements face more legal restrictions. Multiple federal laws limit educational discrimination, including requirements for English fluency and training programs. While there are laws protecting women's advancement and equal pay, studies show bias persists with men outnumbering women 4-to-1 in top executive positions despite women holding 34% of senior management roles.	"[""Gerry Connolly on Civil Rights\nENDA: prohibit employment discrimination for gays.\nConnolly signed H.R.3017&S.1584\nProhibits employment discrimination on the basis of actual or perceived sexual orientation or gender identity by covered entities (employers, employment agencies, labor organizations, or joint labor-management committees). Prohibits preferential treatment or quotas. Allows only disparate treatment claims. Prohibits related retaliation.\nMakes this Act inapplicable to:\nSource: Employment Non-Discrimination Act 09-HR3017 on Jun 24, 2009\n- religious organizations; and\n- the relationship between the United States and members of the Armed Forces.\nConstitutional Amendment for women's equal rights.\nConnolly signed Equal Rights Amendment for men and women\nJOINT RESOLUTION: Proposing an amendment to the Constitution of the United States relative to equal rights for men and women. Constitutional Amendment: Prohibits denying or abridging equality of rights under the law by the United States or by any state on account of sex.\nResolved by the Senate and House of Representatives: That the following article is proposed as an amendment to the Constitution of the United States, which shall be valid to all intents and purposes as part of the Constitution when ratified by the legislatures of 3/4ths of the several States:\n- Equality of rights under the law shall not be denied or abridged by the United States or by any State on account of sex.\n- The Congress shall have the power to enforce, by appropriate legislation, the provisions of this article.\n- This amendment shall take effect two years after the date of ratification.\n[Explanatory note from Wikipedia.com and OnTheIssues.org]:\nThe Equal Rights Amendment (ERA) was a proposed amendment to the United States Constitution. The ERA was originally written by Alice Paul and, in 1923, it was introduced in the Congress for the first time. In 1972, it passed both houses of Congress, but failed to gain ratification before its June 30, 1982 deadline. This new proposed amendment is identical in wording to the original 1972 proposed amendment. It was proposed in Congress in every session from 1923 through 1970 prior to passing in 1972; and has been re-introduced in Congress in every session since 1982 after its failure at ratification. The current version removes the Congressionally imposed deadline for ratification of the Equal Rights Amendment, so that if the bill passes Congress, states have no deadline as they did in 1982.\nSource: HJR69&SJR21 11-HJR69 on Jun 22, 2011\nProhibit sexual-identity discrimination at schools.\nConnolly signed Student Non-Discrimination Act\nStudent Non-Discrimination Act of 2011:\nSource: HR.998&S.555 11-HR0998 on Mar 10, 2011\n- Prohibits public school students from being excluded from participating in, or subject to discrimination under, any federally-assisted educational program on the basis of their actual or perceived sexual orientation or gender identity or that of their associates.\n- Considers harassment to be a form of discrimination.\n- Prohibits retaliation against anyone for opposing conduct they reasonably believe to be unlawful under this Act.\n- Authorizes federal departments and agencies to enforce these prohibitions by cutting off the educational assistance of recipients found to be violating them.\nAllows an aggrieved individual to assert a violation of this Act in a judicial proceeding and recover reasonable attorney's fees should they prevail.\n- Deems a state's receipt of federal educational assistance for a program to constitute a waiver of sovereign immunity for conduct prohibited under this Act regarding such program.\nEnforce against wage discrimination based on gender.\nConnolly co-sponsored Paycheck Fairness Act\nCongress finds the following:\nSource: S.84&H.R.377 13-HR0377 on Jan 23, 2013\n- Women have entered the workforce in record numbers over the past 50 years.\n- Despite the enactment of the Equal Pay Act in 1963, many women continue to earn significantly lower pay than men for equal work. These pay disparities exist in both the private and governmental sectors. In many instances, the pay disparities can only be due to continued intentional discrimination or the lingering effects of past discrimination.\n- The existence of such pay disparities depresses the wages of working families who rely on the wages of all members of the family to make ends meet; and undermines women's retirement security.\n- Artificial barriers to the elimination of discrimination in the payment of wages on the basis of sex continue to exist decades after the enactment of the Fair Labor Standards Act of 1938. These barriers have resulted because the Equal Pay Act has not worked as Congress originally intended.\nThe Department of Labor and the Equal Employment Opportunity Commission have important and unique responsibilities to help ensure that women receive equal pay for equal work.\n- The Department of Labor is responsible for investigating and prosecuting equal pay violations, especially systemic violations, and in enforcing all of its mandates.\n- The Equal Employment Opportunity Commission is the primary enforcement agency for claims made under the Equal Pay Act.\n- With a stronger commitment [to enforcement], increased information on wage data and more effective remedies, women will be better able to recognize and enforce their rights.\n- Certain employers have already made great strides in eradicating unfair pay disparities in the workplace and their achievements should be recognized.\nGive domestic partnership benefits to Federal employees.\nConnolly signed Domestic Partnership Benefits and Obligations Act\nA federal employee who has a same-sex domestic partner and the domestic partner of the employee shall be entitled to benefits available to, and shall be subject to obligations imposed upon, a married employee and the spouse of the employee. In order to obtain benefits and assume obligations under this Act, an employee shall file an affidavit of eligibility certifying that the employee and the domestic partner of the employee:\n- are each other's sole domestic partner and intend to remain so indefinitely;\n- have a common residence, and intend to continue the arrangement;\n- are at least\n18 years of age and mentally competent to consent to contract;\n- share responsibility for a significant measure of each other's common welfare and financial obligations\n- are not married to or domestic partners with anyone else;\n- are same sex domestic partners, and not related in a way that, if the two were of opposite sex, would prohibit legal marriage in the State in which they reside; and\n- understand that willful falsification of information within the affidavit may lead to disciplinary action and the recovery of the cost of benefits received related to such falsification and may constitute a criminal violation.\nAn employee or domestic partner of an employee who obtains benefits under this Act shall file a statement of dissolution of the domestic partnership not later than 30 days after the death of the employee or the domestic partner or the date of dissolution of the domestic partnership.\nSource: H.R.2517 2009-H2517 on May 20, 2009\nHonor the 100th anniversary of the NAACP.\nConnolly signed bill honoring the 100th anniversary of the NAACP\n- Whereas the National Association for the Advancement of Colored People, NAACP, originally known as the National Negro Committee, was founded in New York City on February 12, 1909, the centennial of Abraham Lincoln's birth, by a multiracial group of activists who met in a national conference to discuss the civil and political rights of African-Americans;\n- Whereas the NAACP is the oldest and largest civil rights organization in the United States;\n- Whereas the mission of the NAACP is to ensure the political, educational, social, and economic equality of rights of all persons and to eliminate racial hatred and racial discrimination;\n- Whereas the NAACP is committed to achieving its goals through nonviolence;\nWhereas the NAACP advances its mission through reliance upon the press, the petition, the ballot, and the courts, and has been persistent in the use of legal and moral persuasion, even in the face of overt and violent racial hostility;\n- Whereas the NAACP has used political pressure, marches, demonstrations, and effective lobbying to serve as the voice, as well as the shield, for minority Americans;\nNow, therefore, be it Resolved by the Congress\nSource: SCR.3&HCR.35 2009-SCR3 on Jan 28, 2009\n- Recognizes the 100th anniversary of the historic founding of the NAACP.\n- Honors and praises the NAACP on the occasion of its anniversary for its work to ensure the political, educational, social, and economic equality of all persons.\nPage last updated: Apr 09, 2013"", 'Many employers require you to have a specific type and level of education to qualify for certain jobs. Workplace educational discrimination happens when an employer requires that you have a level of education that isn’t necessary for the job. While there are laws to prohibit educational discrimination, some biases can still emerge in the workplace.\nCalling It Even\nEducation discrimination involves academic-related requirements set by employers that may violate the law. For example, discrimination might be the case if an employer is advertising for “college graduates” to apply because such advertising can deter otherwise qualified non-graduates from applying. Any tests of your skills or knowledge that an employer requires you to take must be necessary and job-relevant as well.\nCivil rights laws in the U.S. prohibit educational institutions from discriminating against you on the basis of race, gender, national origin, disability or age. You can’t be denied the opportunity to get your GED because you’re 50-years old any more than the opportunity to complete a Ph.D. because you’re a woman. Still, discrimination can happen when an employer understands the educational demographics of people in the job market, or educational backgrounds of particular individuals, and sets requirements for hiring or promotion that are meant to exclude certain individuals or groups.\nLaws and Learning\nMany federal laws focus on preventing education discrimination. For example, the Age Discrimination in Employment Act requires that employers let you enter training or apprenticeship programs despite your age. Title VII of the Civil Rights Act of 1964 prevents employers from requiring you to be fluent in English before hiring you for a job unless the employer can prove that speaking English is essential to performing that job. Employers also can’t hold a learning disability against you. They can only decide whether to hire you or not based on your qualifications and capability to do the job.\nMore women than men attribute educational credentials, along with hard work and long hours, as keys to getting promotions at work, according to a 2010 study by the Center for Work-Life Policy. Still, even though the study found that women held 34 percent of senior management positions, men outnumbered women in top executive positions by four to one. Bias against promoting educated and hard-working women all the way to the top is still prevalent in workplaces throughout the U.S. despite widespread improvements to workplace equality in general.\n- FindLaw: How to File a Discrimination Complaint With the Government\n- U.S. Equal Employment Opportunity Commission: Federal Laws Prohibiting Job Discrimination Questions and Answers\n- Center for Work-Life Policy: Harvard Business Review Research Report: The Sponsor Effect: Breaking Through the Last Glass Ceiling\n- U.S. Equal Employment Opportunity Commission: Prohibited Employment Policies/Practices\n- Jupiterimages/Stockbyte/Getty Images\n- What Does EOE Mean in Reference to a Job?\n- The Objectives for a Teaching Resume\n- Define Workplace Discrimination\n- Strategy to Stop Discrimination in the Workplace\n- Promotion Discrimination in the Workplace\n- Age Requirements for the U.S. Army Rangers\n- Can My Boss Force Me to Go to Employee Counseling?\n- Security Guard Training Requirements']"	['<urn:uuid:b5b17ac0-05a6-47ab-8a43-0e25cc0f135b>', '<urn:uuid:0255e196-c5f6-420f-bc4c-da342e27ac03>']	factoid	with-premise	concise-and-natural	distant-from-document	comparison	novice	2025-05-01T23:55:16.606337	12	52	1885
488	what genetic data format did 23andme use to project customers onto hgdp data set visualization	23andMe used a visualization that projected customers onto an invariant HGDP (Human Genome Diversity Project) data set. However, this representation had limitations since users couldn't mix and match different populations to explore various relationships.	['Note: please read the the earlier post on this topic if you haven’t.\nThe above image is from 23andMe. It’s from a feature which seems to have been marginalized a bit with their ancestry composition. Basically it is projecting 23andMe customers on a visualization of genetic variation from the HGDP data set. This is actually a rather informative sort of representation of variation. But there has always been an issue with the 23andMe representation: you are projected onto their invariant data set. In other words, you can’t mix & match the populations so as to explore different relationships. The nature of the algorithm and representation produces strange results, so varying the population sets is often useful in smoking out the true shape of things.\nWith the MDS feature I wrote about yesterday you can now compute positions with different weights of populations and mixes. This post will focus on how to manipulate the overall data set. You should have PHYLO from the the earlier post. Open up the .fam file. It should look like this:\nMalayan A382 0 0 1 -9\nPaniya D36 0 0 1 -9\nBiakaPygmies HGDP00479 0 0 1 -9\nBiakaPygmies HGDP00985 0 0 1 -9\nBiakaPygmies HGDP01094 0 0 1 -9\nMbutiPygmies HGDP00982 0 0 1 -9\nMandenkas HGDP00911 0 0 1 -9\nMandenkas HGDP01202 0 0 1 -9\nYorubas HGDP00927 0 0 1 -9\nBiakaPygmies HGDP00461 0 0 1 -9\nBiakaPygmies HGDP00986 0 0 1 -9\nMbutiPygmies HGDP00449 0 0 1 -9\nMandenkas HGDP00912 0 0 1 -9\nMandenkas HGDP01283 0 0 1 -9\nYorubas HGDP00928 0 0 2 -9\nAnd so forth. PHYLO has 1,500+ individuals. This is a bit much, which is why the – -genome command took so long. To ask particular questions it is often useful to prune the population down. I have a friend who is 1/4 Filipino who is curious as to whether his ancestry was more Chinese or native Filipino. How to answer this?\n– You want a range of East Asian populations, north to south.\n– You want a good out group. I’ll use the Utah whites.\nAll you need to do is go through the .fam file and keep only those lines you want, and put them into a new file, keep.txt. Then you run this command:\nplink – -noweb – -bfile PHYLO – -keep keep.txt – -make-bed – -out PHYLONARROW\nSo I’ve now made a new pedigree data set which is a subset of the original. Now I merged my friend and my daughter’s genotype into this data set. What about if I wanted to remove some individuals, for examples, the ones in keep.txt? You do it like so:\nplink – -noweb – -bfile PHYLO – -remove keep.txt – -make-bed – -out PHYLOAFEWGONE\nWith – -keep and – -remove, and making files drawn from the .fam file(s), you can customize your own data set for your own purposes. Again you want to produce an MDS, so run:\n– -plink – -noweb – -bfile PHYLONARROW – -genome\n-plink – -noweb – -bfile PHYLONARROW – -read-genome plink.genome – -mds-plot 6\nThis time – -genome will run very fast, because there are far fewer individuals. Here is my plot of the result of the outcome (my friend is “RF,” my daughter is “RD”):\nNote that RF is aligned straight toward the “Dai” population, an ethnic group from South China, but not Han (they are related to the Thai). It seems plausible that my friend is of mixed Chinese and Filipino background. My daughter’s minimal East Asian ancestry is indeed Southeast Asian, and this is clear from this plot, as she is shifted further toward the Cambodians (this may be due to South Asian affinities as well).\nThe point is not to rely on one plot, but to generate many so as to explore the possibilities, and develop and intuition.']	['<urn:uuid:6a878f95-b57a-4210-af69-0bc4a7cbb414>']	factoid	direct	long-search-query	similar-to-document	single-doc	novice	2025-05-01T23:55:16.606337	15	34	641
490	tree branch vs rose cutting angle differences	When cutting tree branches, you should cut at a straight angle, making bottom and top cuts to prevent tearing. For climbing roses, the cuts should be made at a 45-degree angle facing the inside of the rose bush when removing unmarked canes, while straight cuts are used for marked canes that are being shortened.	['Generally the landscaping around a home has some shrubs and other vegetation with woody branches, and over time these limbs can grow long and look unkempt. To ensure a neat appearance around your lawn and keep shrubbery healthy, it is a good idea to prune back branches and selectively cut out some stems to provide more air flow. This is a simple process, but does require a little bit of time.\nSnip thin branches from trees with extended pruning snips. Make the cut 1 inch in front of a leaf node or just above where another stem branches off. Prune trees in the fall when the tree is going dormant and there is little energy going toward growth. If trimming for pruning purposes, do not take off more than one-third of the length of a branch.\nCut back thicker branches with a pruning saw or bow saw. Slice into the branch from the bottom first, cutting halfway through the branch, and then repeat from above the branch. By cutting the bottom first, you prevent the branch from tearing. Cut branches back no more than one-third if you are pruning, but if you need to remove a damaged limb due to disease or weather, cut back to 2 inches from the trunk. Never cut flush with the bark.\nTrim limbs higher off the ground with a pole saw, which can extend upward and get some of the hard to reach branches. Make your cuts in a similar fashion, but since it is higher, you cannot get the saw at the correct angle for exact top and bottom cuts. Instead make the bottom cut slightly to one side, and then do the top cut above the branch and slightly on the other side. Keep an eye on the branch as you near completion of the cut, and get out of the way of falling branches.\nTrim nonflowering as well as summer and fall flowering shrubs in late fall, when cooler weather prevents new growth. Shape the shrub as you wish by clipping back stems to just above a leaf node. With shrubs this is easy, since there are so many leaves on a single limb. Snip at a slight angle on the stem to encourage regrowth. Be mindful of the angle, since stems tend to grow off of the cut in the direction of the angle. Prune spring flowering shrubs in the same manner as other shrubs, but make your cuts soon after the blooms fall off the stems. If you wait until fall, the shrubs will already have new buds being prepared for bloom in the spring. By trimming at that time, your shrub may not have any blooms the next year.\nSelect limbs around the shrub at even intervals, and trim them further back into the bush. Do not cut them back more than one-third the length of the limb. By cutting some limbs back further, you open more of the inner parts of the shrub to light and air circulation, promoting green growth further in.\nThings You Will Need\n- Pruning snips\n- Pruning saw or bow saw\n- Pole pruner\n- Rope (optional)\n- Remove or prune back tree branches that rub against each other, grow downward or that are too close together.\n- One way to avoid worrying over falling branches when cutting higher limbs is to use rope. Tie a loop on one end of the rope and toss it over the branch you are planning to cut. Take hold of the loop end after it falls and feed the other end through the loop. Pull on the unlooped end of the rope to cinch the loop end upward, securing it around the branch you are cutting. Throw the unlooped end over a different branch that is close by to the one the rope is attached to. Let someone hold the end of the rope while you cut the branch. When the branch falls free, it will not fall far due to the rope, and the other person can lower it safely to the ground.\n- If your tree is near power lines, be careful not to trim close to the wires. Leave that to professionals such as the utility company. If you are concerned about some of the branches around the power lines, give the power company a call. They will come out and assess the situation and determine if pruning is necessary and cut the limbs themselves.\n- For branches higher than you can reach with a pole saw, it is best to call in professional tree trimmers. Climbing ladders and hanging out on limbs to cut branches is not safe and should not be attempted.\n- Thinkstock Images/Comstock/Getty Images', 'Climbing roses (Rosa), also known as rambling roses, grow in U.S. Department of Agriculture hardiness zones 3 through 10 depending on the variety. Prune climbing roses to control size and disease, remove diseased or dead branches, and to promote more vigorous growth the next season. These bushes produce flowers on canes from the previous year and from the current season. Older canes seldom produce an abundant show of flowers. Spring pruning is done early in the season before the bush breaks dormancy.\nCut off any suckers that are growing below the graft union. Make the cuts flush with the main stem. The graft union is the part of the stem where the top of the rose bush was secured to the root stock of another rose bush. Many rose bushes are grafted onto the bottom of another rose bush to promote a healthier bush.\nRemove dead or diseased canes from the climbing rose bush. Cut the canes as close to the base of the main stem as possible. Prune away any broken canes or those damaged by crossing branches and stems.\nUse a strip of colored marking tape to tag four to six healthy canes that are evenly spaced around the central root system. For a large climbing rose, you may wish to retain eight canes.\nPrune the unmarked canes as close to the main stem as possible. Make the cut at a 45-degree angle with the slanted part of the cut facing the inside of the rose bush. The angle keeps water from settling on the fresh wound and causing rot.\nReduce the length of the marked canes by about one third. Make the cut straight across, not at an angle, and at least one quarter of an inch above a bud. This allows the bud to generate new growth for the following year.\nReposition the canes on the trellis or climbing support as you desire, and fasten with new ties. Use a plastic-coated wire to avoid damaging the stems. Coat each of the open cuts with a small amount of all-purpose glue to keep disease and pests from infecting the tender, exposed wood.\nRake up the pruned canes and bundle them together with garden twine. Dispose of them in your compost pile or as required by your trash collector. Clean the area around the climbing rose bush to keep pests to a minimum. Discard infested or diseased clippings and canes as yard waste; do not add to the compost pile.\nThings You Will Need\n- Heavy work gloves\n- Marking tape\n- Pruning shears\n- Plastic-coated support ties\n- All-purpose glue\n- Garden twine\n- Prune the climbing rose bush after its third year of growth to allow the bush to establish itself.\n- Ed Hume Seeds: March is Rose Pruning Time\n- Texas A&M Agrilife Extension: Pruning Methods\n- Rhode Island Rose Society: Introduction to Climbing Roses\n- University of California Cooperative Extension -- Tulare and Kings Co.: Pruning Climbing Roses\n- University of California Cooperative Extension -- Napa County: Pruning Rose Bushes\n- Jupiterimages/Comstock/Getty Images']	['<urn:uuid:ace9e0cd-13b4-41c4-beac-27ee1581be39>', '<urn:uuid:4d9ab0ca-958c-4903-b2bc-5d39f1569674>']	factoid	with-premise	short-search-query	distant-from-document	comparison	novice	2025-05-01T23:55:16.606337	7	54	1295
492	How did historical German flutes vary in their pitch levels, and what were the efforts made to standardize musical pitch across different regions?	German flutes from different periods and regions showed significant pitch variations. For instance, many flutes had corps de rechange (interchangeable center joints) to allow playing at different pitch levels - like the Braun flute which could play at approximately A=435, A=440, and A=446. Regarding standardization efforts, there was widespread variation in pitch levels across Europe until the 19th century. In 1859, the French government made the first major standardization attempt by setting A above middle C at 435 Hz (diapason normal). This was later superseded by the current standard of A=440 Hz, which was recommended in 1939 and officially adopted by the International Organization for Standardization in 1955. Despite this standardization, some variation still exists in practice since orchestras tune to an oboe rather than electronic devices.	"['There were many centers of flute making in Germany, and many types of simple system flutes of instruments made over the century. Our survey cannot be complete but is directed in large part by the instruments in the author\'s collection.\nWe start with two typical examples of Prussian eight-keyed flutes from Beethoven\'s lifetime.\nA. F. Piering (Berlin, c.1815–20)\n(A one-key flute, by Griesling & Schlott of Berlin, made at about the same time as these eight-key flutes can be seen on the page about classical flutes. It has a similar look and playing qualities.)\nJ. G. Freyer\'s father, C. F. Freyer, had collaborated with Quantz to build flutes for Frederick the Great. (The silver embouchure bushing on the Freyer is probably a repair. The foot joint on the Freyer is unstamped; see the page on classical flutes for a photo of the Freyer in a period case.)\nThe two flutes are similar in design. Both have eight keys and the G# key on the lower center. The finger hole placement and other dimensions are almost identical. But the Piering is later than the Freyer as can be inferred from the shapes of the keys, and the Piering is slightly louder and brighter in tone. The keys on the Piering are more \'modern\', being smoother and less ornate, without the decorative touches.\nBoth flutes originally had three-piece corps de rechange. The Piering survives only with center joint number 2. The silver linings to the wooden blocks on the Piering are not original, but part of a restoration.\nThe following flute by Braun is typical of the early 19th century Mannheim style.\nThe keys are mounted in saddles attached to the wood with screws. The Braun is lighter than the previous flutes, with thinner walls, somewhat like French flutes. I like to imagine that one can detect from the look, feel, and playing qualities (including easy high notes) of the Braun flute that Mannheim is much closer to France than is Berlin, without looking at a map.\nLike the Prussian flutes, the flute has no tuning head but a three-center corps de rechange. Curiously, there is no long C key on the longest center. The pitches are approximately A=435, A=440, and A=446.\nThe second holes of the three centers can be seen below. The shortest joint (A=446) is on the left; it has received by far the most use, and the holes are worn. The A=435 joint on the right, on the other hand, is in like-new condition and was possibly never played.\nA flute by Streitwolf has a B-foot but still retains the four piece construction, so the long b key is attached only on the foot (instead if pivoting on a pin higher up, near hole 4, as on later flutes) and the leverage is a bit awkward.\nA distinctive feature on the Streitwolf is the elongated, rectangular embouchure. The flute on the left is the Streitwolf; the one on the right is a Liebel from Dresden from about the same time.\nStreitwolf provided duplicate keys that control the same holes. This is not unusual for F and Bb, but the small lever for the left hand thumb (under the flute) that raises the long C key is not common.\nThe interesting nine-key flute below is from the collection of Harry Bower. It is stamped G. Hartmann / Hamburg, and presumably made before his death in 1835. This is an early example of what would become the most common construction for better German simple system flutes: three sections, the head joint including a tuning barrel, the lower section with the right hand finger holes and a B-foot, and the G# key on the middle section with the left hand finger holes. The touch of the c\'# key is given to LH4 on the Hartmann, however, and this would not be part of the standard construction, which would give the b key to LH4—see below.\nThe Hartmann is also an early example of a German flute with cupped keys, rather than flat flaps for leathers, and an early example of the use of nickel-silver for keys, rather than silver or brass.\nThe seven-key flute by B. Pentenrieder below has a common shape for Munich flutes, completely straight except for the narrow rings and small wooden blocks for the keys. We will have more to say about Pentenrieder\'s innovations elsewhere. I know of a number of other Munich flutes with a C#-foot. I often imagine that the low C# key was included more for the sake of an alternate fingering for c\'\'# and other useful fingerings than for the low c\'# itself.\nInexpensive (but not necessarily badly made) German flutes may have horn mounts. These are dark; sometimes they have a grain, and at other times, may be smooth and almost look like black plastic.\nBelow are two midcentury flutes with the mature German form (three sections with tuning head). At first, cupped keys were still mounted in integral wooden blocks, as on these flutes, but post mounting would become more common over the period 1850 to 1870 or so (depending on location).\n9-key flute by A. Euler (Frankfurt, c.1860)\nBelow are four late (circa 1870–1930) German simple system flutes, with between 11 and 13 keys. The basic German simple system flute did not change dramatically in this period, and it is often difficult to accurately estimate the date of an instrument of this type, especially if anonymous. However, one helpful clue in the case of the top two instruments is that they have what I believe to be black bakelite rollers on the touches of the low C# and C keys; this material, one of the first plastics, was patented and produced starting about 1910.\nThe Euler and the Hammig are very fine players; the others, in their current conditions with possible leaks, have serious problems (poor response, tone quality, and intonation in the first octaves). But the Euler is very bright, while the sturdy Hammig is quite a bit louder with more body, and is warmer sounding. The difference in timbre is in part due to the pitches. The Euler is at ""high pitch"" and plays at A=450 or so, while the Hammig is at ""low pitch"" of A=435 (diapason normal).\nThe production of musical instruments has been important in the area including Markneukirchen in the southeastern Vogtland since the 17th century. A huge number of late 19C/early 20C flutes were made there, many of which were exported. C.f. the c.1895 catalog of the firm of A. & G. Klemm.\nThe most usual form of an 11-key German flute is described on the pages on 5, 8, and 11-key flutes and 19th century simple system flutes, I. The twelfth key on the Hammig is a second key for G# for the left hand thumb, which can be seen in the photo above as the key most protruding beneath the center joint. (In addition to these, the Hüller also has a key for C#/B and other trills.)\nU.S. trade laws required imported goods to be stamped with the name of the country of origin starting March 1, 1891. Thanks to Al Rice for pointing this out to me; click here for the reference. It is my understanding that the words ""made in"" were also required after about 1923. Below is the stamp of a flute (not shown here) by Kohlert. It reads ""V. Kohlert Sons / makers / Graslitz"" in gold, and below, ""Austria / D"". So this flute probably was probably made between 1890 and 1923. (The Bohemian town of Graslitz [Kraslice], which is not far from the Vogtland region of Germany, became part of Czechoslovakia by 1919, so we can be sure that the flute was made before then and thus probably before WW I.)\nThe stamp on the Hüller is shown below. There is a lyre and the initials GH inside an S. Below that is ""made in Germany / C / L.P."" As it is unlikely that the words ""made in"" would have been used before they were required, this allows us to date the instrument after 1923.\nThe ""L.P."" stamped on the Hüller also appears (in another place) on the Kohlert, and stands for ""low pitch"", A=435 in the case of these flutes. These two instruments are the same size and play at the same pitch. Yet one is stamped ""D"" and the other ""C"". Why? The Kohlert is stamped ""D"" because of the long-standing and perfectly logical idea that the standard size flute was ""in D"" because its basic scale was D major. The Hüller is stamped ""C"" because the way terms were used was changing and it became appropriate to say the flute was ""in C"" because it was the standard size and not a transposing instrument.\n* * *\nTwo important German makers deserve a page of their own. They are (click on the photos to go to the pages) W. Liebel of Dresden [to be implemented soon]. . .\nand H. F. Meyer of Hannover [working now].', 'As modified by Aligned Harmonics from Wikipedia, the free encyclopedia.\nPerception of pitch\nPitch is something perceived by the human ear, as opposed to frequency, the physical measurement of vibration. The note A above middle C played on any instrument is perceived to be of the same pitch as a pure tone of 440 Hz, but does not necessarily contain that frequency or only that frequency. Furthermore, a slight change in frequency need not lead to a perceived change in pitch, but a change in pitch implies a change in frequency. In fact, the just noticeable difference (the threshold at which a change in pitch is perceived) is about five cents, but varies over the range of hearing and is more precise when the two pitches are played simultaneously. Like other human stimuli, the perception of pitch also can be explained by the Weber-Fechner law. Pitch also depends on the amplitude of the sound, especially at low frequencies. For instance, a low bass note will sound lower in pitch if it is louder. Like other senses, the relative perception of pitch can be fooled, resulting in ""audio illusions"". There are several of these, such as the tritone paradox, but most notably the Shepard scale, where a continuous or discrete sequence of specially formed tones can be made to sound like this sequence continues ascending forever, when this in fact is a clever audio illusion.\nThe A above middle C is nowadays set at 440 Hz (often written as ""A = 440 Hz"", and known as concert pitch), although this has not always been the case (see ""Historical pitch standards""). Pitch is often cited as one of the fundamental aspects of music.\nPitches may be described in various ways, including high or low, as discrete or indiscrete, pitch that changes with time (chirping) and the manner in which this change with time occurs: gliding; portamento; or vibrato, and as determinate or indeterminate. Pitch is often measured by frequency or wavelength, but is most often discussed either through musical notation and the accompanying letter labels (C#). Musically the frequency of specific pitches is not as important as their relationships to other frequencies - the difference between two pitches can be expressed by a ratio or measured in cents. People with a sense of these relationships are said to have relative pitch while people who have a sense of the actual frequencies independent of other pitches are said to have absolute pitch, less accurately called perfect pitch.\nThe relative pitches of individual notes in a scale may be determined by one of a number of tuning systems. In the west, the twelve-note chromatic scale is the most common method of organization, with equal temperament now the most widely used method of tuning that scale. In it, the pitch ratio between any two successive notes of the scale is exactly the twelfth root of two (or about 1.05946). In well-tempered systems (as used in the time of Johann Sebastian Bach, for example), different methods of musical tuning were used. Almost all of these systems have one interval in common, the octave, where the pitch of one note is double the frequency of another. For example, if the A above middle C is 440 Hz, the A an octave above that will be 880 Hz.\nOther musical meanings of pitch\nIn atonal, twelve tone, or musical set theory a ""pitch"" is a specific frequency while a pitch class is all the octaves of a frequency. Pitches are named with integers because of octave and enharmonic equivalency (for example, C# and Db are the same pitch while C4 and C5 are functionally the same, one octave apart).\nDiscrete pitches, rather than continuously variable pitches, are virtually universal, with exceptions including ""tumbling strains"" (Sachs & Kunst, 1962) and ""indeterminate-pitch chants"" (Malm, 1967). Gliding pitches are used in most cultures, but are related to the discrete pitches they reference or embellish. (Burns, 1999)\nHistorical pitch standards\nAs well as various systems of musical tuning being used to determine the relative frequency of notes in a scale, various pitch standards have been used historically to fix the absolute position of the scale. In 1955, the International Organization for Standardization fixed the frequency of the A above middle C at 440 Hz, but in the past, various frequencies have been used.\nUntil the 19th century, there was no concerted effort to standardize musical pitch and the levels across Europe varied widely. Even within one church, the pitch used could vary over time because of the way organs were tuned. Generally, the end of an organ pipe would be hammered inwards to a cone, or flared outwards to raise or lower the pitch. When the pipe ends became frayed by this constant process, they were all trimmed down, thus raising the overall pitch of the organ.\nSome idea of the variance in pitches can be gained by examining old tuning forks, organ pipes and other sources. For example, an English pitchpipe from 1720 plays the A above middle C at 380 Hz, while the organs played by Johann Sebastian Bach in Hamburg, Leipzig and Weimar were pitched at A = 480 Hz, a difference of around four semitones. In other words, the A produced by the 1720 pitchpipe would have been at the same frequency as the F on one of Bach\'s organs.\nPitch levels did not just vary from place to place, or over time - pitch levels could vary even within the same city. The pitch used for an English cathedral organ in the 17th century for example, could be as much as five semitones lower than that used for a domestic keyboard instrument in the same city.\nNeed to standardize pitch\nThe need to standardize pitch levels, at least within one city or country, rose as performance of music which combined the organ with instrumental ensembles became more popular. One way in which pitch could be controlled was with the use of tuning forks, although even here there was variation - a tuning fork associated with Handel, dating from 1740, is pitched at A = 422.5 Hz, while a later one from 1780 is pitched at A = 409 Hz, almost a semitone lower. Nonetheless, there was a tendency towards the end of the 18th century for the frequency of the A above middle C to be in the range of 400 to 450 Hz.\nThroughout the first half of the 19th century, there was a tendency for the pitch used by orchestras to rise. This was probably largely due to orchestras competing with each other, each attempting to fill increasingly large concert halls with a brighter, more ""brilliant"", sound than that of their rivals. They were helped in this endeavour by the improved durability of the violins\' E-strings - in the 16th century, Michael Praetorius had rejected various high pitch standards as leading to snapped strings, but the new strings could take the higher tension without breaking.\nThe rise in pitch at this time can be seen reflected in tuning forks. A 1815 tuning fork from the Dresden opera house gives A = 423.2 Hz, while one of eleven years later from the same opera house gives A = 435 Hz. At La Scala in Milan, the A above middle C rose as high as 451 Hz.\nThe most vocal opponents of the upward tendency in pitch were singers, who complained that it was putting a strain on their voices. Largely due to their protestations, the French government passed a law on February 16, 1859 which set the A above middle C at 435 Hz. This was the first attempt to standardize pitch on such a scale, and was known as the diapason normal. It became quite a popular pitch standard outside of France as well.\nThere were still variations, however. The diapason normal resulted in middle C being tuned at approximately 258.65 Hz. An alternative pitch standard known as philosophical or scientific pitch, which fixed middle C at exactly 256 Hz (that is, 28 Hz), and resulted in the A above it being tuned to approximately 430.54 Hz, gained some popularity due to its mathematical convenience (the frequencies of all the Cs being a power of two). This never received the same official recognition as A = 435, however, and was not as widely used.\nIn 1939, an international conference recommended that the A above middle C be tuned to 440 Hz. This standard was taken up by the International Organization for Standardization in 1955 (and was reaffirmed by them in 1975) as ISO 16. The difference between this and the diapason normal is due to confusion over which temperature the French standard should be measured at. The initial standard was A = 439 Hz, but this was superseded by A = 440 Hz after complaints that 439 Hz was difficult to reproduce in a laboratory owing to 439 being a prime number.\nDespite such confusion, A = 440 Hz is now used virtually world wide, at least in theory. In practice, as orchestras still tune to a note given out by the oboe, rather than to an electronic tuning device (which would be more reliable), and as the oboist himself may not have used such a device to tune in the first place, there is still some variance in the exact pitch used. Solo instruments such as the piano (which an orchestra may tune to if they are playing together) are also not universally tuned to A = 440 Hz. Overall, it is thought that the general trend since the middle of the 20th century has been for standard pitch to rise, though it has certainly been rising far more slowly than it has in the past...\nReaders should also consult Helmholtz: \'On the sensations of tone\'.\nCHANGING THE FREQUENCY OF A VIBRATING STRING\nThere are three ways to change the frequency of a Piano. Pianos are tuned by varying the strings\' tension because adjusting length or mass per unit length is impractical.\nFrequency can be adjusted by varying the length of the string. A longer string will result in a lower pitch and vice versa. The change in frequency is inversely proportional to the change in length.\nA string twice as long will produce a tone an octave lower.\nPitch can be adjusted by varying the tension of the string. A string with less tension (looser) will result in a lower pitch, while a string with greater tension (tighter) will result in a higher pitch. The change in frequency is proportional to the square root of the change in tension:\nThe pitch of a string can also be varied by changing the density of the string. The change in frequency is inversely proportional to the square root of the change in density:\nBurns, Edward M. (1999). ""Intervals, Scales, and Tuning"", The Psychology of Music second edition. Deutsch, Diana, ed. San Diego: Academic Press. ISBN 0122135644.\nSachs, C. and Kunst, J. (1962). In The wellsprings of music, ed. Kunst, J. The Hague: Marinus Nijhoff.\nMalm, W.P. (1967). Music Cultures of the Pacific, the Near East, and Asia. Englewood Cliffs, NJ: Prentice-Hall.\nHelmholtz, Hermann. (2005). On the Sensations of Tone as a Physiological Basis for the Theory of Music, Kessinger Publishing. ISBN 1419178938\nAthenaUtility Pitch Converter (AUpc) An athenaCL netTool for on-line, web-based pitch conversion from a variety of formats.\nCopyright (c) Aligned Harmonics\nPermission is granted to copy, distribute and/or modify this document under the terms of the GNU Free Documentation License, Version 1.2 or any later version published by the Free Software Foundation; with no Invariant Sections, no Front-Cover Texts, and no Back-Cover Texts. A copy of the license is included in the section entitled ""GNU Free Documentation License"".\nGNU Free Documentation License']"	['<urn:uuid:8ed95d9d-899f-4726-ae26-5d2ec8bd3a80>', '<urn:uuid:074cd2aa-5638-41dc-9d03-f9cf9c4ff212>']	open-ended	direct	verbose-and-natural	similar-to-document	multi-aspect	novice	2025-05-01T23:55:16.606337	23	127	3464
496	I frequently work with both ventricular drainage and JP drains in post-surgical care. What are the essential positioning requirements for both types of drains to ensure proper fluid drainage and prevent complications?	For JP drains, the bulb must be positioned below the incision site - never in a shirt pocket as this elevation will impede proper drainage and slow healing. For ventricular drainage systems, it's crucial to position the transducer at the same level as the patient's ventricular system to ensure proper reference levels in the manometer tube for accurate calibration. Additionally, drainage should always be performed against a positive pressure head of approximately 20 cm H2O or 15 mm Hg to prevent ventricular collapse and possible tentorial herniation.	['The importance of Jackson Pratt drains\nFollowing surgery, you may have drainage from the wound that needs to be removed to prevent fluid, hematoma, and/or abscesses from forming. Mostly, the expelled fluid is a combination of mucus and small blood clots. It is critical to keep the surgical area free of fluid and a Jackson Pratt drain is designed to simply suction fluids away.\nHow the Jackson Pratt drain does its job\nA small drainage line is installed during the final portion of surgery. One end is secured to your skin using sutures, and the other is firmly attached to a lemon-sized pliable bulb. The bulb creates suction when the air is squeezed out of the bulb and a small air cap is tightened. Really, a very simple concept and very effective at keeping wound areas dry and healthy.\nWhat to do with fluid inside the Jackson Pratt bulb\nFollowing surgery, you will need to empty the bulb on a schedule recommended by your discharge team. Firmly hold tubing near the insertion site (close to your skin) and using the index finger and thumb, squeeze the tubing. Slide your index finger and thumb down the tube toward the bulb, moving fluid in the tube to the bulb. Now, uncap the bulb and pour the contents into a measuring receptacle. Calculate how many ccs or mls of fluid were drained and record the amount on a data log. Dispose of the fluid in the toilet. Once the bulb is empty, squeeze the bulb while replacing the cap. This should create suction and the bulb should look indented.\nPay attention to fluid color and measurements\nDrainage is bloody following surgery, but as time passes it should become straw-colored, then clear. Discharge should never look cloudy or like pus. If it does, contact your physician. The amount of fluid will decrease as time passes. Your surgeon will monitor the fluid output, and once it’s reached a certain level – drains will be removed.\nSecuring Jackson Pratt drains and drain tubes\nDischarge nurses usually provide safety pins and recommend that a patient slip the bulb’s plastic loop over the pin and attach to gown or clothing. If you choose this method, be careful to remember bulbs are attached when changing gowns or clothing. A safer and painless way to secure drains is to use management tool like KILI Medical Drain Carrier. It’s apron-like construction easily holds the bulbs and provides easy access when drains need to be emptied. And because it’s made of mesh material, it can be worn when bathing. More information is available here.\nHow long you should expect to wear the drains\nThat’s entirely up to your surgical team, based on your rate of recovery. Some procedures require drains be worn for 24 hours or less. However, more intrusive surgeries are going to take longer to heal, and could mean drains will remain with the patient for 2 to 4 weeks, if not longer.\n- The first time you empty your drains, have someone there to help you. You will likely find it difficult to move around and remove/replace the bandages, etc.\n- Don’t keep the bulb in a shirt pocket. This is too high, and the fluid won’t drain properly, slowing your healing time. The bulb should be kept below the incision site.\n- Don’t touch the spout opening or the plug with your hands or anything else. You don’t want germs getting inside the bulb.', 'Indications, Safety, and Warnings\nIt’s important for the healthcare provider to be familiar with all indications, warnings, and precautions for this device.\nDraining and monitoring of cerebrospinal fluid (CSF) flow from the lateral ventricles or lumbar subarachnoid space is indicated in selected patients:\n- To reduce intracranial pressure (ICP), e.g., pre-, intra-, or postoperative\n- To monitor CSF chemistry, cytology, and physiology\n- To provide temporary CSF drainage in patients with infected cerebrospinal fluid shunts\n- Undergoing open descending thoracic aortic aneurysm (open TAA) or open descending thoraco-abdominal aortic aneurysm (open TAAA) repair surgery\n- Post TAA/TAAA repair that become symptomatic with neurological deficit such as paraplegia\nMonitoring of intracranial pressure (ICP) is indicated in selected patients with:\n- Severe head injury\n- Subarachnoid hemorrhage graded III, IV, or V preoperatively\n- Reyes syndrome or similar encephalopathies\n- Intracranial hemorrhage\n- Miscellaneous problems when drainage is to be used as a therapeutic maneuver.\nMonitoring can also be used to evaluate the status pre- and postoperatively for space-occupying lesions.\nIntracranial pressure monitoring with a ventricular or lumbar catheter is contraindicated in patients receiving anticoagulants or who are known to have a bleeding diathesis. The use of a ventricular catheter is contraindicated if scalp infection is present. A patient undergoing external drainage and monitoring must be kept under continuous, close supervision. The use of a ventricular or lumbar drainage catheter, or a Duet™ EDMS, is contraindicated where trained personnel are not available to supervise monitoring and drainage on a 24-hour-a-day basis.\nThe use of a lumbar catheter for drainage and monitoring of cerebrospinal fluid is not recommended for patients with non-communicating hydrocephalus; where lumbar puncture is contraindicated; in the presence of large intracranial mass lesions, tumors, hematomas, or cysts; in the presence of infections in the surrounding area which includes the skin, subcutaneous tissue, bone and the epidural space; and patients who have demonstrated blockage of cerebrospinal fluid to the subarachnoid space due to trauma, hematoma, fracture or tumor. The use of a lumbar catheter under these conditions for external drainage and monitoring is at the discretion of the physician.\nMonitoring pressure from the lumbar subarachnoid space can be done only in instances where lumbar puncture does not pose a danger to the patient.\nWarnings & Precautions\n- Failure to appropriately adjust the rate of CSF outflow through the external drainage system may result in potentially serious injury to the patient.\n- Patients undergoing external drainage and/or intracranial pressure monitoring must be kept under constant supervision in an intensive care unit staffed with trained personnel familiar with the use of intracranial and lumbar pressure monitoring techniques.\n- Improper vigilance or improper drainage system setup can lead to overdrainage or underdrainage and potentially serious injury to the patient. Intracranial and lumbar pressure monitoring has been associated with intracranial infection, meningitis and ventriculitis. This hazard has been quoted at less than 1% to more than 5%. The risk of infection is probably influenced both by the number of times a system is opened and by the duration of the monitoring. Prolonged steroid therapy can also increase the risk of infection.\n- It is possible that the puncture of the ventricle or the opening of the dura will result in an intracranial hemorrhage.\n- It is possible that if too much CSF is removed from the ventricles, either during a drainage procedure or when the ventricle is first punctured, the ventricle may collapse and occlude the catheter.\n- It is possible that the monitoring system may give a false pressure reading either due to a pressure line becoming clogged or kinked or from an air bubble lodged in the system. An incorrect pressure reading may lead to the wrong therapy being given to the patient. The irrigation of the catheter or the performance of a Volume Pressure Relationship (VPR) study may induce pressure waves in the patient. For this reason, irrigation or VPR studies should be done only by, or on the order of, a physician.\n- In order to minimize the possibility of infection, meningitis or ventriculitis, several steps should be observed. First, the injection sites should always be cleaned with alcohol and the alcohol allowed to dry before a needle is inserted into them. Second, sterile technique should be observed in setting up the system and in the placement of the catheter. Third, subgaleal tunneling of the ventricular catheter should be approximately one to two inches.\n- In order to avoid possible cracking of the Luer connectors after cleaning with alcohol, allow to air dry completely prior to connecting the system.\n- Leakage from the system, which can result from damaged system components or improper use or handling, can potentially result in overdrainage, the need to replace the drainage system and/or other complications to the patient.\n- In order to ensure against ventricular collapse and the possible consequence of tentorial herniation, always perform a drainage maneuver against a positive pressure head on the order of 20 cm H2O or 15 mm Hg. In addition, when the ventricle or lumbar subarachnoid space is first punctured during the insertion of the catheter, care should be taken so as little CSF as possible is lost.\n- A double suture tie with silk suture should be used to secure the ventricular or lumbar catheter to the connection fitting. Check to ensure that the connection is tight prior to use.\n- Whenever irrigation of the catheter or the performance of the VPR is decided upon, great care must be used so that pressure waves are not initiated. Only a small volume of saline should ever be injected into the ventricular system, and this only done by, or on the order of, a physician. In general, in monitoring intracranial pressure, one should always be aware of the waveform on the oscilloscope. If the waveform begins to dampen out, it is important that the entire monitoring system be examined. Ensure that the line to the patient is not kinked and that all air bubbles or blood or other debris are removed from the system.\n- Ascertain that the transducer is on the same level as the patient’s ventricular system to ensure the proper reference level in the manometer tube for use in calibration procedures. Pressure monitoring with the manometer may result in overdrainage of the ventricles.\n- Infections, particularly meningitis, ventriculitis, and wound infections\n- Overdrainage, leading to:\n- Intracranial hemorrhage\n- Permanent neurological deficit\n- Frequent punctures of the brain to insert the ventricular catheter can predispose to intracerebral hemorrhage and edema leading to a further rise in Intracranial Pressure (ICP).\n- Poor recording of ICP will result if the catheter, patient line or other components of the monitoring system become clogged with blood clots, brain tissue fragments, or fibrinous debris.\n- Ventricular wall collapse, in small patients, resulting in obstruction of the catheter and predisposing to tentorial herniation. It is therefore important to avoid excessive release of CSF before the system catheter is attached to the patient line.\n- Limiting the duration of monitoring from a single site to less than five days will reduce the infection rate.\nIf monitoring must continue past five days, consider inserting a new catheter at a fresh site and changing the entire system.\nImportant Safety Information\nThis therapy is not for everyone. Please consult your physician. A prescription is required. For more information, please contact us at 1-800-468-9710.\nNot all indications stated are cleared in all geographies. Please contact your local Medtronic Neurosurgery Representative or Designee for further information specific to your geography. In the United States, contact Medtronic at 1-800-468-9710.\nCaution: Federal (USA) law restricts this device to sale by or on the order of a physician. Refer to product package insert for instructions, warnings, precautions and complications.']	['<urn:uuid:ba678232-a6d9-4938-94b2-3575aab2ca0e>', '<urn:uuid:defa88c4-fa4b-4881-aeb3-7946e4bd3d4a>']	factoid	with-premise	verbose-and-natural	similar-to-document	three-doc	expert	2025-05-01T23:55:16.606337	32	87	1863
500	I live in London and heard that air pollution used to be really bad here in the past. How does historical London smog compare to the air pollution problems in modern American cities?	Historical London smog at the turn of the century was caused by water vapor condensing on soot particles in the air, leading to thousands of deaths from pneumonia-like diseases. Modern American cities face a different type of smog - photochemical smog produced when nitrogen oxides and volatile organic compounds from vehicle exhausts react with sunlight. This modern smog affects many major U.S. cities, from California to the mid-Atlantic seaboard, causing health problems like breathing difficulties, asthma, and reduced resistance to lung infections. According to recent data, about 120 million Americans live in areas with unhealthy air, with people of color being 60% more likely to be affected by unhealthy levels of air pollution.	"['This activity lets students create artificial ""smog"" in a jar. Teachers can use this module as an introduction to a planned visit from an air-quality scientist, or as the basis for extended discussions on the health problems associated with smog.\nRecognize that invisible air pollutants and weather conditions are involved in creating smog.\nUnderstand that not all air pollution is visible.\nAppreciate that human activities can cause air pollution.\nGuest presenters could include EPA air quality monitoring specialists, state or local air quality managers, chemists, laboratory technicians, or meteorologists.\nTARGET GRADE LEVEL\n3RD - 5TH\nVolatile Organic Compounds\nClean, dry, wide-mouth glass jar (such as a mayonnaise jar)\nHeavy aluminum foil\nTwo or three ice cubes\nStop watch or watch with a second hand\nThe expression ""smog"" was first used in ""Turn-of-the-Century"" London to describe a combination of ""smoke"" and ""fog"". Smog occurred when water vapor in the air condensed on small particles of soot in the air, forming small smog droplets. Thousands of Londoners died of pneumonia-like diseases due to the poisonous air.\nToday, smog is usually produced photochemically, when chemical pollutants in the air (notably nitrogen oxides and volatile organic compounds (VOC\'s) from automobile exhausts) are baked by the sun and react chemically. Ground-level ozone is produced by a combination of pollutants from many sources such as automobile exhausts, smokestacks, and fumes (VOC\'s) from chemical solvents like paint thinner or pesticides. When these smog-forming pollutants (called ""precursors"") are released into the air, they undergo chemical transformations and produce smog. Weather conditions, such as the lack of wind or a ""thermal inversion"", also cause smog to be trapped over a particular area.\nSmog causes health problems such as difficulty in breathing, asthma, reduced resistance to lung infections, colds, and eye irritation. The ozone in smog also can damage plants and trees, and the haze reduces visibility. This is particularly noticeable from mountains and other beautiful vistas such as National Parks.\nSevere smog and ground-level ozone problems exist in many major cities, including much of California from San Francisco to San Diego, the mid-Atlantic seaboard from Washington, DC to southern Maine, and over most major cities of the South and Midwest.\nWHAT TO DO\nExplain that the class will perform and experiment in which they will create artificial ""smog"" in a jar. Make sure that students understand that the jar is only a model, and models by nature are limited. For example, the purpose of this model is to illustrate the appearance and behavior of smog, not the composition or effects. It is important to understand that smog is not just a ""smoky fog"", but a specific phenomenon.\nSelect students to perform the experiment. Have them cut a strip of paper about 6 inches by 2 inches. Fold the strip in half and twist it into a rope.\nHave them make a snug lid for the jar out of a piece of aluminum foil. Shape a small depression in the foil lid to keep the ice cubes from sliding off. Carefully remove the foil and set it aside.\nHave the students put some water in the jar and swish it around to wet all the inside of the jar. Pour out the extra water.\nHave them light the paper ""rope"" with a match and drop it and the match into the damp jar. Put the foil lid back on the jar and seal it tightly. Put ice cubes on the lid to make it cold. (The ice cubes will make the water vapor in the jar condense.) You must do this step very quickly, perhaps with some assistance.\nTAKE NOTE! Be careful to supervise students using matches. DO NOT let anyone breathe the ""smog"" produced in the experiment, and when the experiment is completed, be sure to release the ""smog"" outside.\nAsk students to describe what they see in the jar. How is this like real smog? What conditions in the jar produced ""smog""? (Moisture plus soot particles from the burning matches plus carbon dioxide and other solvent vapors.)\nAsk the students if they have ever seen smog (not fog). Have they ever breathed air outside that smelled funny?\nSUGGESTED EXTENSIONS (OPTIONAL)\nHave students put a glass thermometer (not plastic) into the jar before they do the experiment. Have them record the temperature before proceeding to step 4. Have them record the temperature during step 5. Ask them to describe what the temperature did and why. Let them try it again without adding water.\nFor grades 7-12, assign students to small groups to answer the following questions and report back to class in two weeks. One group will consider the physical and chemical sciences and the other group will consider the health and ecological sciences. Each group should consider referring to several sources of information to answer the questions. Students could possibly interview the weather reporter or meteorologist at the local television or radio station or airport, or interviewing a health scientist from the city or county health department or air quality agency.\n(a) What conditions are necessary to produce smog in the air? Under what circumstances will these conditions exist in the city? How often are they likely? Can they be predicted in advance?\n(b) What are the health effects of smog on people? On plants and trees? Why doesn\'t everyone in the city get sick or have similar symptoms from smog? What types of people are most sensitive to smog?', 'In the summer of this year the American Lung Association released a report titled, “Driving to Clean Air: Health Benefits of Zero-Emission Cars and Electricity.” Typically a person might not expect that driving personal transportation could result in clean air because gas- and diesel-powered vehicles using internal combustion engines produce unhealthy emissions that are harmful to people and the planet. The report presents a new vision, however, one that foresees an America running on clean, renewable electricity and people driving electric vehicles, meaning all-electric vehicles. This vision is important for a number of reasons, some of which may be surprising to those who are unaware of the harm caused by gas- and diesel-powered vehicle emissions.\nWilliam Barrett, National Senior Director of Advocacy for Clean Air at the American Lung Association, answered some questions about the report for CleanTechnica.\nQ: The report says that switching to 100% zero-emission new passenger vehicles and clean, non-combustion electricity generation by 2050 could result in about 89,300 fewer premature human deaths by reducing air pollution. How did you arrive at that total, and which Americans are most vulnerable to premature death from air pollution exposure?\nA: The report includes a target of 100% zero-emission new passenger vehicle sales by 2035, coupled with non-combustion electricity generation. Cumulatively, the health benefits shown through our modeling of this scenario hit nearly 90,000 premature deaths avoided because the air pollution from these sources will be greatly reduced, though not eliminated fully. We used a series of modeling tools to arrive at these results, and for the health benefits specifically, we used the US EPA’s COBRA model for health benefits analysis.\nQ: The switch to electric vehicles and clean electricity could also provide $978 billion in public health benefits. What are the benefits, and are they distributed across the U.S. or are there areas that will benefit more?\nA: The $978 billion is a national figure, but based in more localized results. For example, the report highlights state-by-state findings that vary depending on local sources of pollution from power plants, refineries or the size of the on-road vehicle populations. Every state shows benefits from this transition to zero-emission technologies. The benefits range from reduced asthma attacks to premature deaths avoided because the air would be cleaner as the result of more non-combustion technologies in the vehicle and power sectors.\nQ: The aforementioned switch could result in 2.2 million fewer asthma attacks. What forms of air pollution linked with gas and diesel-powered vehicles cause asthma attacks? How dangerous are asthma attacks?\nA: Both particle pollution and ozone pollution associated with vehicle exhaust can contribute to asthma attacks. In fact, the Health Effects Institute’s latest comprehensive study on the health harms of transportation pollution re-confirmed the link between the onset of new asthma cases and traffic pollution exposure. Asthma attacks can result in the need for increased medication, emergency department visits, hospitalizations and can be fatal.\nQ: The report also mentions that the switch could result in 10.7 million fewer lost workdays. Why is that the case?\nA: By reducing harmful pollution, workers would be less likely to be too sick to work. Whether that is due to asthma flare ups, cardiovascular illness or other impacts, cleaning the air can remove a significant health risk from people’s daily lives. While not included in the report, there is also a significant benefit in terms of improving children’s health that could mean parents don’t need to stay home from when the child is too ill to attend school, camp or other activities.\nQ: Heart attacks, strokes, and lung cancer can be caused by exposure to air pollution. Is the general public aware of this fact and that the source of the air pollution is combusting fossil fuels such as gasoline, diesel fuel and coal?\nA: The goal for our report is to do just that — to draw attention to the existing health risks posed by the transportation and power sectors. We want people to see the report and make the link to the unacceptable risk posed by fossil fuels in our daily lives, and what the health-related benefits could be through a transition to non-combustion, zero-emission technologies that are healthier, less costly and more efficient in the long run.\nQ: In general, does American air pollution impact people of color more than white people?\nA: Yes, and our State of the Air 2023 report puts a very fine point on this. There are almost 120 million Americans living in a community impacted by unhealthy air, and the majority of those affected are people of color. We found that a person of color in the United States is over 60 percent more likely to live in a community impacted by unhealthy levels of ozone and/or particle pollution than a white person. When we look at the communities with a failing grade in all three of the State of the Air categories, a person of color is 3.7 times more likely than a white person to live with the most unhealthy air. The US EPA has also noted this disparity in that 72 million Americans live in close proximity to a major transportation/freight corridor, and those living along those routes are more exposed to harmful pollution, have lower incomes and are more likely to be people of color.\nA Final Note For Context\n89,300 Americans dying prematurely is quite obviously a huge number of lost lives. The good news is that this enormous loss of life can be prevented. For some context, a little over 58,000 American soldiers lost their lives in the Vietnam War. Air pollution from gas- and diesel-powered vehicles is typically not that visible except for some moments when the vehicles accelerate and it is possible to see a surge of smoke or soot from a vehicle’s tailpipe, bus vertical exhaust pipe, or tractor trailer “smoke stack.” We don’t see most of the tiny, microscopic particulate matter, aka soot, nitrogen oxides, or ozone and so we might not be that aware of it or even think about it. It’s there though, wherever gas and diesel vehicles are being operated, especially in large cities, on and near freeways, and in or near ports. Exposure to toxic exhaust takes quite a toll on human health and results in far too many premature deaths. Eventually, as clean, renewable electricity and electric vehicles replace fossil fuels and the vehicles that use them our nation will be healthier.\nHave a tip for CleanTechnica? Want to advertise? Want to suggest a guest for our CleanTech Talk podcast? Contact us here.\nEV Obsession Daily!\nTesla Sales in 2023, 2024, and 2030\nCleanTechnica uses affiliate links. See our policy here.']"	['<urn:uuid:100c6377-2600-4c2d-ab40-fa5c76850084>', '<urn:uuid:c0f0cc80-7ae0-43e9-b82f-de4b3cea908a>']	open-ended	with-premise	verbose-and-natural	distant-from-document	comparison	novice	2025-05-01T23:55:16.606337	33	113	2012
